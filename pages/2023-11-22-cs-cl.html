<!DOCTYPE html>
<html>
<head>
<title>2023-11-22-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2311.10723">Large Language Models in Finance: A Survey. (arXiv:2311.10723v1 [q-fin.GN])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Li_Y/0/1/0/all/0/1">Yinheng Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_S/0/1/0/all/0/1">Shaofei Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Ding_H/0/1/0/all/0/1">Han Ding</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chen_H/0/1/0/all/0/1">Hang Chen</a></p>
<p>Recent advances in large language models (LLMs) have opened new possibilities
for artificial intelligence applications in finance. In this paper, we provide
a practical survey focused on two key aspects of utilizing LLMs for financial
tasks: existing solutions and guidance for adoption.
</p>
<p>First, we review current approaches employing LLMs in finance, including
leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on
domain-specific data, and training custom LLMs from scratch. We summarize key
models and evaluate their performance improvements on financial natural
language processing tasks.
</p>
<p>Second, we propose a decision framework to guide financial professionals in
selecting the appropriate LLM solution based on their use case constraints
around data, compute, and performance needs. The framework provides a pathway
from lightweight experimentation to heavy investment in customized LLMs.
</p>
<p>Lastly, we discuss limitations and challenges around leveraging LLMs in
financial applications. Overall, this survey aims to synthesize the
state-of-the-art and provide a roadmap for responsibly applying LLMs to advance
financial AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10729">Chatbot-supported Thesis Writing: An Autoethnographic Report. (arXiv:2311.10729v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schwenke_N/0/1/0/all/0/1">Nicolas Schwenke</a>, <a href="http://arxiv.org/find/cs/1/au:+Sobke_H/0/1/0/all/0/1">Heinrich S&#xf6;bke</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraft_E/0/1/0/all/0/1">Eckhard Kraft</a></p>
<p>The release of the large language model based chatbot ChatGPT in November
2022 has brought considerable attention to the subject of artificial
intelligence, not only in the public. From the perspective of higher education,
ChatGPT challenges various learning and assessment formats as it significantly
reduces the effectiveness of their learning and assessment functionalities. In
particular, ChatGPT might be applied to formats that require learners to
generate text, such as bachelor theses or student research papers. Accordingly,
the research question arises to what extent writing of bachelor theses is still
a valid learning and assessment format. Correspondingly, in this study, the
first author was asked to write his bachelor's thesis exploiting ChatGPT. For
tracing the impact of ChatGPT, methodically an autoethnographic approach was
used. First, all considerations on the potential use of ChatGPT were documented
in logs and secondly, all ChatGPT chats were logged. Both logs and chat
histories were analyzed and are presented along to the recommendations for
students regarding the use of ChatGPT suggested by Gimpel et al. (2023). In
conclusion, ChatGPT is beneficial in thesis writing during various activities,
such as brainstorming, structuring and text revision. However, there arise
limitations, e.g., in referencing. Thus, ChatGPT requires a continuous
validation of the outcomes generated fostering learning. Currently, ChatGPT is
to be valued as a beneficial tool in thesis writing. However, writing a
conclusive thesis still requires the learner's meaningful engagement.
Accordingly, writing a thesis is still a valid learning and assessment format.
With further releases of ChatGPT, an increase in capabilities is to be expected
and the research question needs to be reevaluated from time to time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10733">Proceedings of the 3rd International Workshop on Mining and Learning in the Legal Domain (MLLD-23). (arXiv:2311.10733v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Makrehchi_M/0/1/0/all/0/1">Masoud Makrehchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dell Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrova_A/0/1/0/all/0/1">Alina Petrova</a>, <a href="http://arxiv.org/find/cs/1/au:+Armour_J/0/1/0/all/0/1">John Armour</a></p>
<p>This is the Proceedings of the 3rd International Workshop on Mining and
Learning in the Legal Domain (MLLD-23) which took place in conjunction with the
32nd ACM International Conference on Information and Knowledge Management
(CIKM-2023) at the University of Birmingham, Birmingham, UK on Sunday 22nd
October 2023.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10746">EIT: Earnest Insight Toolkit for Evaluating Students&#x27; Earnestness in Interactive Lecture Participation Exercises. (arXiv:2311.10746v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Miroyan_M/0/1/0/all/0/1">Mihran Miroyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_S/0/1/0/all/0/1">Shiny Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Rahul Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1">Lisa Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_N/0/1/0/all/0/1">Narges Norouzi</a></p>
<p>In today's rapidly evolving educational landscape, traditional modes of
passive information delivery are giving way to transformative pedagogical
approaches that prioritize active student engagement. Within the context of
large-scale hybrid classrooms, the challenge lies in fostering meaningful and
active interaction between students and course content. This study delves into
the significance of measuring students' earnestness during interactive lecture
participation exercises. By analyzing students' responses to interactive
lecture poll questions, establishing a clear rubric for evaluating earnestness,
and conducting a comprehensive assessment, we introduce EIT (Earnest Insight
Toolkit), a tool designed to assess students' engagement within interactive
lecture participation exercises - particularly in the context of large-scale
hybrid classrooms. Through the utilization of EIT, our objective is to equip
educators with valuable means of identifying at-risk students for enhancing
intervention and support strategies, as well as measuring students' levels of
engagement with course content.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10749">Measuring Five Accountable Talk Moves to Improve Instruction at Scale. (arXiv:2311.10749v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kupor_A/0/1/0/all/0/1">Ashlee Kupor</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgan_C/0/1/0/all/0/1">Candice Morgan</a>, <a href="http://arxiv.org/find/cs/1/au:+Demszky_D/0/1/0/all/0/1">Dorottya Demszky</a></p>
<p>Providing consistent, individualized feedback to teachers on their
instruction can improve student learning outcomes. Such feedback can especially
benefit novice instructors who teach on online platforms and have limited
access to instructional training. To build scalable measures of instruction, we
fine-tune RoBERTa and GPT models to identify five instructional talk moves
inspired by accountable talk theory: adding on, connecting, eliciting, probing
and revoicing students' ideas. We fine-tune these models on a newly annotated
dataset of 2500 instructor utterances derived from transcripts of small group
instruction in an online computer science course, Code in Place. Although we
find that GPT-3 consistently outperforms RoBERTa in terms of precision, its
recall varies significantly. We correlate the instructors' use of each talk
move with indicators of student engagement and satisfaction, including
students' section attendance, section ratings, and assignment completion rates.
We find that using talk moves generally correlates positively with student
outcomes, and connecting student ideas has the largest positive impact. These
results corroborate previous research on the effectiveness of accountable talk
moves and provide exciting avenues for using these models to provide
instructors with useful, scalable feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10751">ProAgent: From Robotic Process Automation to Agentic Process Automation. (arXiv:2311.10751v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yining Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1">Xin Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Shizuo Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jiannan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yujia Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yaxi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Heyang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huadong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yankai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a></p>
<p>From ancient water wheels to robotic process automation (RPA), automation
technology has evolved throughout history to liberate human beings from arduous
tasks. Yet, RPA struggles with tasks needing human-like intelligence,
especially in elaborate design of workflow construction and dynamic
decision-making in workflow execution. As Large Language Models (LLMs) have
emerged human-like intelligence, this paper introduces Agentic Process
Automation (APA), a groundbreaking automation paradigm using LLM-based agents
for advanced automation by offloading the human labor to agents associated with
construction and execution. We then instantiate ProAgent, an LLM-based agent
designed to craft workflows from human instructions and make intricate
decisions by coordinating specialized agents. Empirical experiments are
conducted to detail its construction and execution procedure of workflow,
showcasing the feasibility of APA, unveiling the possibility of a new paradigm
of automation driven by agents. Our code is public at
https://github.com/OpenBMB/ProAgent.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10757">How Contentious Terms About People and Cultures are Used in Linked Open Data. (arXiv:2311.10757v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nesterov_A/0/1/0/all/0/1">Andrei Nesterov</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Hollink_L/0/1/0/all/0/1">Laura Hollink</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ossenbruggen_J/0/1/0/all/0/1">Jacco van Ossenbruggen</a> (2) ((1) Centrum Wiskunde &amp; Informatica, (2) VU University Amsterdam)</p>
<p>Web resources in linked open data (LOD) are comprehensible to humans through
literal textual values attached to them, such as labels, notes, or comments.
Word choices in literals may not always be neutral. When outdated and
culturally stereotyping terminology is used in literals, they may appear as
offensive to users in interfaces and propagate stereotypes to algorithms
trained on them. We study how frequently and in which literals contentious
terms about people and cultures occur in LOD and whether there are attempts to
mark the usage of such terms. For our analysis, we reuse English and Dutch
terms from a knowledge graph that provides opinions of experts from the
cultural heritage domain about terms' contentiousness. We inspect occurrences
of these terms in four widely used datasets: Wikidata, The Getty Art &amp;
Architecture Thesaurus, Princeton WordNet, and Open Dutch WordNet. Some terms
are ambiguous and contentious only in particular senses. Applying word sense
disambiguation, we generate a set of literals relevant to our analysis. We
found that outdated, derogatory, stereotyping terms frequently appear in
descriptive and labelling literals, such as preferred labels that are usually
displayed in interfaces and used for indexing. In some cases, LOD contributors
mark contentious terms with words and phrases in literals (implicit markers) or
properties linked to resources (explicit markers). However, such marking is
rare and non-consistent in all datasets. Our quantitative and qualitative
insights could be helpful in developing more systematic approaches to address
the propagation of stereotypes via LOD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10760">Non-Parametric Memory Guidance for Multi-Document Summarization. (arXiv:2311.10760v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Baud_F/0/1/0/all/0/1">Florian Baud</a> (LIRIS), <a href="http://arxiv.org/find/cs/1/au:+Aussem_A/0/1/0/all/0/1">Alex Aussem</a> (LIRIS)</p>
<p>Multi-document summarization (MDS) is a difficult task in Natural Language
Processing, aiming to summarize information from several documents. However,
the source documents are often insufficient to obtain a qualitative summary. We
propose a retriever-guided model combined with non-parametric memory for
summary generation. This model retrieves relevant candidates from a database
and then generates the summary considering the candidates with a copy mechanism
and the source documents. The retriever is implemented with Approximate Nearest
Neighbor Search (ANN) to search large databases. Our method is evaluated on the
MultiXScience dataset which includes scientific articles. Finally, we discuss
our results and possible directions for future work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10763">Comparing Generalization in Learning with Limited Numbers of Exemplars: Transformer vs. RNN in Attractor Dynamics. (arXiv:2311.10763v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fukushima_R/0/1/0/all/0/1">Rui Fukushima</a>, <a href="http://arxiv.org/find/cs/1/au:+Tani_J/0/1/0/all/0/1">Jun Tani</a></p>
<p>ChatGPT, a widely-recognized large language model (LLM), has recently gained
substantial attention for its performance scaling, attributed to the billions
of web-sourced natural language sentences used for training. Its underlying
architecture, Transformer, has found applications across diverse fields,
including video, audio signals, and robotic movement. %The crucial question
this raises concerns the Transformer's generalization-in-learning (GIL)
capacity. However, this raises a crucial question about Transformer's
generalization in learning (GIL) capacity. Is ChatGPT's success chiefly due to
the vast dataset used for training, or is there more to the story? To
investigate this, we compared Transformer's GIL capabilities with those of a
traditional Recurrent Neural Network (RNN) in tasks involving attractor
dynamics learning. For performance evaluation, the Dynamic Time Warping (DTW)
method has been employed. Our simulation results suggest that under conditions
of limited data availability, Transformer's GIL abilities are markedly inferior
to those of RNN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10765">Enhancing Machine Translation through Advanced In-Context Learning: A Methodological Strategy for GPT-4 Improvement. (arXiv:2311.10765v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yufeng Chen</a></p>
<p>The challenge of improving translation accuracy in GPT-4 is being addressed
by harnessing a method known as in-context learning. This paper introduces a
strategic approach to utilize in-context learning specifically for machine
translation, aiming to significantly boost accuracy. The crux of this method
lies in the judicious selection of demonstrations that are most effective for
in-context learning. By selecting these examples carefully, GPT-4 can utilize
them to achieve remarkably accurate machine translations, eliminating the need
for task-specific fine-tuning. This technique is anchored in the semantic
similarities between the user's prompt and the chosen dataset. Sentences from
this dataset, carefully picked for their relevance and clarity, serve as potent
demonstrations for in-context learning. This approach not only enhances
translation accuracy but also enriches the understanding of nuanced linguistic
structures. It represents a significant step forward in machine learning,
leveraging the inherent capabilities of GPT-4 to provide translations that are
not only accurate but also contextually rich and linguistically sophisticated.
This method demonstrates the potential of in-context learning in overcoming
language barriers, opening new avenues for cross-cultural communication and
global collaboration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10766">Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values. (arXiv:2311.10766v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jing Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xiaoyuan Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yifan Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>The rapid advancement of Large Language Models (LLMs) has attracted much
attention to value alignment for their responsible development. However, how to
define values in this context remains a largely unexplored question. Existing
work mainly follows the Helpful, Honest, Harmless principle and specifies
values as risk criteria formulated in the AI community, e.g., fairness and
privacy protection, suffering from poor clarity, adaptability and transparency.
Inspired by basic values in humanity and social science across cultures, this
work proposes a novel basic value alignment paradigm and introduces a value
space spanned by basic value dimensions. All LLMs' behaviors can be mapped into
the space by identifying the underlying values, possessing the potential to
address the three challenges. To foster future research, we apply the
representative Schwartz's Theory of Basic Values as an initialized example and
construct FULCRA, a dataset consisting of 5k (LLM output, value vector) pairs.
Our extensive analysis of FULCRA reveals the underlying relation between basic
values and LLMs' behaviors, demonstrating that our approach not only covers
existing mainstream risks but also anticipates possibly unidentified ones.
Additionally, we present an initial implementation of the basic value
evaluation and alignment, paving the way for future research in this line.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10768">Memory Augmented Language Models through Mixture of Word Experts. (arXiv:2311.10768v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Santos_C/0/1/0/all/0/1">Cicero Nogueira dos Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1">James Lee-Thorp</a>, <a href="http://arxiv.org/find/cs/1/au:+Noble_I/0/1/0/all/0/1">Isaac Noble</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chung-Ching Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Uthus_D/0/1/0/all/0/1">David Uthus</a></p>
<p>Scaling up the number of parameters of language models has proven to be an
effective approach to improve performance. For dense models, increasing model
size proportionally increases the model's computation footprint. In this work,
we seek to aggressively decouple learning capacity and FLOPs through
Mixture-of-Experts (MoE) style models with large knowledge-rich vocabulary
based routing functions and experts. Our proposed approach, dubbed Mixture of
Word Experts (MoWE), can be seen as a memory augmented model, where a large set
of word-specific experts play the role of a sparse memory. We demonstrate that
MoWE performs significantly better than the T5 family of models with similar
number of FLOPs in a variety of NLP tasks. Additionally, MoWE outperforms
regular MoE models on knowledge intensive tasks and has similar performance to
more complex memory augmented approaches that often require to invoke custom
mechanisms to search the sparse memory.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10770">Exponentially Faster Language Modelling. (arXiv:2311.10770v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Belcak_P/0/1/0/all/0/1">Peter Belcak</a>, <a href="http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1">Roger Wattenhofer</a></p>
<p>Language models only really need to use an exponential fraction of their
neurons for individual inferences. As proof, we present FastBERT, a BERT
variant that uses 0.3\% of its neurons during inference while performing on par
with similar BERT models. FastBERT selectively engages just 12 out of 4095
neurons for each layer inference. This is achieved by replacing feedforward
networks with fast feedforward networks (FFFs). While no truly efficient
implementation currently exists to unlock the full acceleration potential of
conditional neural execution, we provide high-level CPU code achieving 78x
speedup over the optimized baseline feedforward implementation, and a PyTorch
implementation delivering 40x speedup over the equivalent batched feedforward
inference. We publish our training code, benchmarking setup, and model weights.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10771">Automatic Restoration of Diacritics for Speech Data Sets. (arXiv:2311.10771v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shatnawi_S/0/1/0/all/0/1">Sara Shatnawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alqahtani_S/0/1/0/all/0/1">Sawsan Alqahtani</a>, <a href="http://arxiv.org/find/cs/1/au:+Aldarmaki_H/0/1/0/all/0/1">Hanan Aldarmaki</a></p>
<p>Automatic text-based diacritic restoration models generally have high
diacritic error rates when applied to speech transcripts as a result of domain
and style shifts in spoken language. In this work, we explore the possibility
of improving the performance of automatic diacritic restoration when applied to
speech data by utilizing the parallel spoken utterances. In particular, we use
the pre-trained Whisper ASR model fine-tuned on relatively small amounts of
diacritized Arabic speech data to produce rough diacritized transcripts for the
speech utterances, which we then use as an additional input for a
transformer-based diacritic restoration model. The proposed model consistently
improve diacritic restoration performance compared to an equivalent text-only
model, with at least 5\% absolute reduction in diacritic error rate within the
same domain and on two out-of-domain test sets. Our results underscore the
inadequacy of current text-based diacritic restoration models for speech data
sets and provide a new baseline for speech-based diacritic restoration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10774">MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning. (arXiv:2311.10774v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fuxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Wenlin Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kaiqiang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Sangwoo Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Yacoob_Y/0/1/0/all/0/1">Yaser Yacoob</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dong Yu</a></p>
<p>With the rapid development of large language models (LLMs) and their
integration into large multimodal models (LMMs), there has been impressive
progress in zero-shot completion of user-oriented vision-language tasks.
However, a gap remains in the domain of chart image understanding due to the
distinct abstract components in charts. To address this, we introduce a
large-scale MultiModal Chart Instruction (MMC-Instruction) dataset comprising
600k instances supporting diverse tasks and chart types. Leveraging this data,
we develop MultiModal Chart Assistant (MMCA), an LMM that achieves
state-of-the-art performance on existing chart QA benchmarks. Recognizing the
need for a comprehensive evaluation of LMM chart understanding, we also propose
a MultiModal Chart Benchmark (MMC-Benchmark), a comprehensive human-annotated
benchmark with 9 distinct tasks evaluating reasoning capabilities over charts.
Extensive experiments on MMC-Benchmark reveal the limitations of existing LMMs
on correctly interpreting charts, even for the most recent GPT-4V model. Our
work provides an instruction-tuning methodology and benchmark to advance
multimodal understanding of charts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10775">ToolTalk: Evaluating Tool-Usage in a Conversational Setting. (arXiv:2311.10775v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Farn_N/0/1/0/all/0/1">Nicholas Farn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_R/0/1/0/all/0/1">Richard Shin</a></p>
<p>Large language models (LLMs) have displayed massive improvements in reasoning
and decision-making skills and can hold natural conversations with users. Many
recent works seek to augment LLM-based assistants with external tools so they
can access private or up-to-date information and carry out actions on behalf of
users. To better measure the performance of these assistants, this paper
introduces ToolTalk, a benchmark consisting of complex user intents requiring
multi-step tool usage specified through dialogue. ToolTalk contains 28 tools
grouped into 7 plugins, and includes a complete simulated implementation of
each tool, allowing for fully automated evaluation of assistants that rely on
execution feedback. ToolTalk also emphasizes tools that externally affect the
world rather than only tools for referencing or searching information. We
evaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and
50% respectively. Our analysis of the errors reveals three major categories and
suggests some future directions for improvement. We release ToolTalk at
https://github.com/microsoft/ToolTalk.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10777">A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains, Methods, and Trends. (arXiv:2311.10777v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yan Cathy Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1">Paul Denny</a>, <a href="http://arxiv.org/find/cs/1/au:+Taskova_K/0/1/0/all/0/1">Katerina Taskova</a>, <a href="http://arxiv.org/find/cs/1/au:+Wicker_J/0/1/0/all/0/1">J&#xf6;erg Wicker</a></p>
<p>Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment
analysis (SA) that identifies aspects and the associated opinions from a given
text. In the digital era, ABSA gained increasing popularity and applications in
mining opinionated text data to obtain insights and support decisions. ABSA
research employs linguistic, statistical, and machine-learning approaches and
utilises resources such as labelled datasets, aspect and sentiment lexicons and
ontology. By its nature, ABSA is domain-dependent and can be sensitive to the
impact of misalignment between the resource and application domains. However,
to our knowledge, this topic has not been explored by the existing ABSA
literature reviews. In this paper, we present a Systematic Literature Review
(SLR) of ABSA studies with a focus on the research application domain, dataset
domain, and the research methods to examine their relationships and identify
trends over time. Our results suggest a number of potential systemic issues in
the ABSA research literature, including the predominance of the
``product/service review'' dataset domain among the majority of studies that
did not have a specific research application domain, coupled with the
prevalence of dataset-reliant methods such as supervised machine learning. This
review makes a number of unique contributions to the ABSA research field: 1) To
our knowledge, it is the first SLR that links the research domain, dataset
domain, and research method through a systematic perspective; 2) it is one of
the largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191
search results without time constraint; and 3) our review methodology adopted
an innovative automatic filtering process based on PDF-mining, which enhanced
screening quality and reliability. Suggestions and our review limitations are
also discussed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10781">Can Language Model Moderators Improve the Health of Online Discourse?. (arXiv:2311.10781v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Hyundong Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Taiwei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1">Darpan Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizk_B/0/1/0/all/0/1">Basem Rizk</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuyang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zixun Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_N/0/1/0/all/0/1">Nuan Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gratch_J/0/1/0/all/0/1">Jonathan Gratch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1">Emilio Ferrara</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a></p>
<p>Human moderation of online conversation is essential to maintaining civility
and focus in a dialogue, but is challenging to scale and harmful to moderators.
The inclusion of sophisticated natural language generation modules as a force
multiplier aid moderators is a tantalizing prospect, but adequate evaluation
approaches have so far been elusive. In this paper, we establish a systematic
definition of conversational moderation effectiveness through a
multidisciplinary lens that incorporates insights from social science. We then
propose a comprehensive evaluation framework that uses this definition to asses
models' moderation capabilities independently of human intervention. With our
framework, we conduct the first known study of conversational dialogue models
as moderators, finding that appropriately prompted models can provide specific
and fair feedback on toxic behavior but struggle to influence users to increase
their levels of respect and cooperation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10782">A BERT based Ensemble Approach for Sentiment Classification of Customer Reviews and its Application to Nudge Marketing in e-Commerce. (arXiv:2311.10782v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Putatunda_S/0/1/0/all/0/1">Sayan Putatunda</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhowmik_A/0/1/0/all/0/1">Anwesha Bhowmik</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiruvenkadam_G/0/1/0/all/0/1">Girish Thiruvenkadam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1">Rahul Ghosh</a></p>
<p>According to the literature, Product reviews are an important source of
information for customers to support their buying decision. Product reviews
improve customer trust and loyalty. Reviews help customers in understanding
what other customers think about a particular product and helps in driving
purchase decisions. Therefore, for an e-commerce platform it is important to
understand the sentiments in customer reviews to understand their products and
services, and it also allows them to potentially create positive consumer
interaction as well as long lasting relationships. Reviews also provide
innovative ways to market the products for an ecommerce company. One such
approach is Nudge Marketing. Nudge marketing is a subtle way for an ecommerce
company to help their customers make better decisions without hesitation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10784">ExFake: Towards an Explainable Fake News Detection Based on Content and Social Context Information. (arXiv:2311.10784v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amri_S/0/1/0/all/0/1">Sabrine Amri</a>, <a href="http://arxiv.org/find/cs/1/au:+Boleilanga_H/0/1/0/all/0/1">Henri-Cedric Mputu Boleilanga</a>, <a href="http://arxiv.org/find/cs/1/au:+Aimeur_E/0/1/0/all/0/1">Esma A&#xef;meur</a></p>
<p>ExFake is an explainable fake news detection system based on content and
context-level information. It is concerned with the veracity analysis of online
posts based on their content, social context (i.e., online users' credibility
and historical behaviour), and data coming from trusted entities such as
fact-checking websites and named entities. Unlike state-of-the-art systems, an
Explainable AI (XAI) assistant is also adopted to help online social networks
(OSN) users develop good reflexes when faced with any doubted information that
spreads on social networks. The trustworthiness of OSN users is also addressed
by assigning a credibility score to OSN users, as OSN users are one of the main
culprits for spreading fake news. Experimental analysis on a real-world dataset
demonstrates that ExFake significantly outperforms other baseline methods for
fake news detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10785">Text Sanitization Beyond Specific Domains: Zero-Shot Redaction &amp; Substitution with Large Language Models. (arXiv:2311.10785v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Albanese_F/0/1/0/all/0/1">Federico Albanese</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciolek_D/0/1/0/all/0/1">Daniel Ciolek</a>, <a href="http://arxiv.org/find/cs/1/au:+DIppolito_N/0/1/0/all/0/1">Nicolas D&#x27;Ippolito</a></p>
<p>In the context of information systems, text sanitization techniques are used
to identify and remove sensitive data to comply with security and regulatory
requirements. Even though many methods for privacy preservation have been
proposed, most of them are focused on the detection of entities from specific
domains (e.g., credit card numbers, social security numbers), lacking
generality and requiring customization for each desirable domain. Moreover,
removing words is, in general, a drastic measure, as it can degrade text
coherence and contextual information. Less severe measures include substituting
a word for a safe alternative, yet it can be challenging to automatically find
meaningful substitutions. We present a zero-shot text sanitization technique
that detects and substitutes potentially sensitive information using Large
Language Models. Our evaluation shows that our method excels at protecting
privacy while maintaining text coherence and contextual information, preserving
data utility for downstream tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10797">TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in LLMs through Translation-Assisted Chain-of-Thought Processes. (arXiv:2311.10797v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Upadhayay_B/0/1/0/all/0/1">Bibek Upadhayay</a>, <a href="http://arxiv.org/find/cs/1/au:+Behzadan_V/0/1/0/all/0/1">Vahid Behzadan</a></p>
<p>LLMs such as ChatGPT and PaLM can be utilized to train on a new language and
revitalize low-resource languages. However, it is evidently very costly to
pretrain pr fine-tune LLMs to adopt new languages. Another challenge is the
limitation of benchmark datasets and the metrics used to measure the
performance of models in multilingual settings. This paper proposes
cost-effective solutions to both of the aforementioned challenges. We introduce
the Multilingual Instruction-Tuning Dataset (MITS), which is comprised of the
translation of Alpaca-52K, Dolly-15K, and Vicuna Benchmark in 132 languages.
Also, we propose a new method called \emph{TaCo: Translation-Assisted
Cross-Linguality}, which make uses of translation in a chain-of-thought process
to instruction-tune LLMs on a new languages through a curriculum learning
process. As a proof of concept, we experimented with the instruction-tuned
Guanaco-33B model and performed further instruction tuning using the TaCo
method in three low-resource languages and one high-resource language. Our
results show that the TaCo method impresses the GPT-4 with 82% for a
low-resource language in the Vicuna Benchmark dataset, and boosts performance
by double in contrast to the performance of instruction tuning only. Our
results show that TaCo is a promising method for creating multilingual LLMs,
even for low-resource languages. We have released our datasets and the model
adapters, and encourage the research community to make use of these resources
towards advancing work on multilingual LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10804">A Study on Altering the Latent Space of Pretrained Text to Speech Models for Improved Expressiveness. (arXiv:2311.10804v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1">Mathias Vogel</a></p>
<p>This report explores the challenge of enhancing expressiveness control in
Text-to-Speech (TTS) models by augmenting a frozen pretrained model with a
Diffusion Model that is conditioned on joint semantic audio/text embeddings.
The paper identifies the challenges encountered when working with a VAE-based
TTS model and evaluates different image-to-image methods for altering latent
speech features. Our results offer valuable insights into the complexities of
adding expressiveness control to TTS systems and open avenues for future
research in this direction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10810">Use GPT-J Prompt Generation with RoBERTa for NER Models on Diagnosis Extraction of Periodontal Diagnosis from Electronic Dental Records. (arXiv:2311.10810v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yao-Shun Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoqian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chun-Teh Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Brandon_R/0/1/0/all/0/1">Ryan Brandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1">Duong Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Tokede_O/0/1/0/all/0/1">Oluwabunmi Tokede</a>, <a href="http://arxiv.org/find/cs/1/au:+Walji_M/0/1/0/all/0/1">Muhammad F. Walji</a></p>
<p>This study explored the usability of prompt generation on named entity
recognition (NER) tasks and the performance in different settings of the
prompt. The prompt generation by GPT-J models was utilized to directly test the
gold standard as well as to generate the seed and further fed to the RoBERTa
model with the spaCy package. In the direct test, a lower ratio of negative
examples with higher numbers of examples in prompt achieved the best results
with a F1 score of 0.72. The performance revealed consistency, 0.92-0.97 in the
F1 score, in all settings after training with the RoBERTa model. The study
highlighted the importance of seed quality rather than quantity in feeding NER
models. This research reports on an efficient and accurate way to mine clinical
notes for periodontal diagnoses, allowing researchers to easily and quickly
build a NER model with the prompt generation approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10813">A Language Agent for Autonomous Driving. (arXiv:2311.10813v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1">Jiageng Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Junjie Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yuxi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yue Wang</a></p>
<p>Human-level driving is an ultimate goal of autonomous driving. Conventional
approaches formulate autonomous driving as a perception-prediction-planning
framework, yet their systems do not capitalize on the inherent reasoning
ability and experiential knowledge of humans. In this paper, we propose a
fundamental paradigm shift from current pipelines, exploiting Large Language
Models (LLMs) as a cognitive agent to integrate human-like intelligence into
autonomous driving systems. Our approach, termed Agent-Driver, transforms the
traditional autonomous driving pipeline by introducing a versatile tool library
accessible via function calls, a cognitive memory of common sense and
experiential knowledge for decision-making, and a reasoning engine capable of
chain-of-thought reasoning, task planning, motion planning, and
self-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive
common sense and robust reasoning capabilities, thus enabling a more nuanced,
human-like approach to autonomous driving. We evaluate our approach on the
large-scale nuScenes benchmark, and extensive experiments substantiate that our
Agent-Driver significantly outperforms the state-of-the-art driving methods by
a large margin. Our approach also demonstrates superior interpretability and
few-shot learning ability to these methods. Project page:
\href{https://github.com/USC-GVL/Agent-Driver/blob/main/index.html}{here}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10847">Token-level Adaptation of LoRA Adapters for Downstream Task Generalization. (arXiv:2311.10847v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Belofsky_J/0/1/0/all/0/1">Joshua Belofsky</a></p>
<p>This paper introduces a method for adapting LoRA adapters in smaller-sized
language models to arbitrary downstream tasks. Unlike standard
mixture-of-expert architectures, our method employs a gradient-free routing
function to choose a weighted combination of experts without increasing the
compute requirements for training or inference. The results show that
token-level adaptation of LoRA adapters outperforms the base Llama-2-7b model
across mathematical (GSM8K), scientific (ARC-Challenge), reading comprehension
(SQuAD), and coding (CodeAlpaca-20k) tasks. Further evaluations also show that
the average performance of token-level adaptation outperforms individual models
fine-tuned for each of the tasks with the best performance observed in
adaptation of every-other token during inference. The code for this study is
made available through a public repository.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10862">Formal concept analysis for evaluating intrinsic dimension of a natural language. (arXiv:2311.10862v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kuznetsov_S/0/1/0/all/0/1">Sergei O. Kuznetsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gromov_V/0/1/0/all/0/1">Vasilii A. Gromov</a>, <a href="http://arxiv.org/find/cs/1/au:+Borodin_N/0/1/0/all/0/1">Nikita S. Borodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Divavin_A/0/1/0/all/0/1">Andrei M. Divavin</a></p>
<p>Some results of a computational experiment for determining the intrinsic
dimension of linguistic varieties for the Bengali and Russian languages are
presented. At the same time, both sets of words and sets of bigrams in these
languages were considered separately. The method used to solve this problem was
based on formal concept analysis algorithms. It was found that the intrinsic
dimensions of these languages are significantly less than the dimensions used
in popular neural network models in natural language processing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10883">Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models. (arXiv:2311.10883v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yimeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajabi_N/0/1/0/all/0/1">Navid Rajabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrestha_S/0/1/0/all/0/1">Sulabh Shrestha</a>, <a href="http://arxiv.org/find/cs/1/au:+Reza_M/0/1/0/all/0/1">Md Alimoor Reza</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosecka_J/0/1/0/all/0/1">Jana Kosecka</a></p>
<p>The image annotation stage is a critical and often the most time-consuming
part required for training and evaluating object detection and semantic
segmentation models. Deployment of the existing models in novel environments
often requires detecting novel semantic classes not present in the training
data. Furthermore, indoor scenes contain significant viewpoint variations,
which need to be handled properly by trained perception models. We propose to
leverage the recent advancements in state-of-the-art models for bottom-up
segmentation (SAM), object detection (Detic), and semantic segmentation
(MaskFormer), all trained on large-scale datasets. We aim to develop a
cost-effective labeling approach to obtain pseudo-labels for semantic
segmentation and object instance detection in indoor environments, with the
ultimate goal of facilitating the training of lightweight models for various
downstream tasks. We also propose a multi-view labeling fusion stage, which
considers the setting where multiple views of the scenes are available and can
be used to identify and rectify single-view inconsistencies. We demonstrate the
effectiveness of the proposed approach on the Active Vision dataset and the
ADE20K dataset. We evaluate the quality of our labeling process by comparing it
with human annotations. Also, we demonstrate the effectiveness of the obtained
labels in downstream tasks such as object goal navigation and part discovery.
In the context of object goal navigation, we depict enhanced performance using
this fusion approach compared to a zero-shot baseline that utilizes large
monolithic vision-language pre-trained models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10899">Extraction and Summarization of Explicit Video Content using Multi-Modal Deep Learning. (arXiv:2311.10899v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Shaunak Joshi</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gaggar_R/0/1/0/all/0/1">Raghav Gaggar</a> (1) ((1) University of Southern California)</p>
<p>With the increase in video-sharing platforms across the internet, it is
difficult for humans to moderate the data for explicit content. Hence, an
automated pipeline to scan through video data for explicit content has become
the need of the hour. We propose a novel pipeline that uses multi-modal deep
learning to first extract the explicit segments of input videos and then
summarize their content using text to determine its age appropriateness and age
rating. We also evaluate our pipeline's effectiveness in the end using standard
metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10905">Flexible Model Interpretability through Natural Language Model Editing. (arXiv:2311.10905v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DOosterlinck_K/0/1/0/all/0/1">Karel D&#x27;Oosterlinck</a>, <a href="http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1">Thomas Demeester</a>, <a href="http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1">Chris Develder</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a></p>
<p>Model interpretability and model editing are crucial goals in the age of
large language models. Interestingly, there exists a link between these two
goals: if a method is able to systematically edit model behavior with regard to
a human concept of interest, this editor method can help make internal
representations more interpretable by pointing towards relevant representations
and systematically manipulating them.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10920">Understanding and Mitigating Classification Errors Through Interpretable Token Patterns. (arXiv:2311.10920v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hedderich_M/0/1/0/all/0/1">Michael A. Hedderich</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1">Jonas Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1">Dietrich Klakow</a>, <a href="http://arxiv.org/find/cs/1/au:+Vreeken_J/0/1/0/all/0/1">Jilles Vreeken</a></p>
<p>State-of-the-art NLP methods achieve human-like performance on many tasks,
but make errors nevertheless. Characterizing these errors in easily
interpretable terms gives insight into whether a classifier is prone to making
systematic errors, but also gives a way to act and improve the classifier. We
propose to discover those patterns of tokens that distinguish correct and
erroneous predictions as to obtain global and interpretable descriptions for
arbitrary NLP classifiers. We formulate the problem of finding a succinct and
non-redundant set of such patterns in terms of the Minimum Description Length
principle. Through an extensive set of experiments, we show that our method,
Premise, performs well in practice. Unlike existing solutions, it recovers
ground truth, even on highly imbalanced data over large vocabularies. In VQA
and NER case studies, we confirm that it gives clear and actionable insight
into the systematic errors made by NLP classifiers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10922">Explainable Product Classification for Customs. (arXiv:2311.10922v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Eunji Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sihyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sundong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Soyeon Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Heeja Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1">Meeyoung Cha</a></p>
<p>The task of assigning internationally accepted commodity codes (aka HS codes)
to traded goods is a critical function of customs offices. Like court decisions
made by judges, this task follows the doctrine of precedent and can be
nontrivial even for experienced officers. Together with the Korea Customs
Service (KCS), we propose a first-ever explainable decision supporting model
that suggests the most likely subheadings (i.e., the first six digits) of the
HS code. The model also provides reasoning for its suggestion in the form of a
document that is interpretable by customs officers. We evaluated the model
using 5,000 cases that recently received a classification request. The results
showed that the top-3 suggestions made by our model had an accuracy of 93.9\%
when classifying 925 challenging subheadings. A user study with 32 customs
experts further confirmed that our algorithmic suggestions accompanied by
explainable reasonings, can substantially reduce the time and effort taken by
customs officers for classification reviews.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10928">CAMRA: Copilot for AMR Annotation. (arXiv:2311.10928v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jon Z. Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Shafiuddin Rehan Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonn_J/0/1/0/all/0/1">Julia Bonn</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_Bettner_K/0/1/0/all/0/1">Kristin Wright-Bettner</a>, <a href="http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1">Martha Palmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1">James H. Martin</a></p>
<p>In this paper, we introduce CAMRA (Copilot for AMR Annotatations), a
cutting-edge web-based tool designed for constructing Abstract Meaning
Representation (AMR) from natural language text. CAMRA offers a novel approach
to deep lexical semantics annotation such as AMR, treating AMR annotation akin
to coding in programming languages. Leveraging the familiarity of programming
paradigms, CAMRA encompasses all essential features of existing AMR editors,
including example lookup, while going a step further by integrating Propbank
roleset lookup as an autocomplete feature within the tool. Notably, CAMRA
incorporates AMR parser models as coding co-pilots, greatly enhancing the
efficiency and accuracy of AMR annotators. To demonstrate the tool's
capabilities, we provide a live demo accessible at: https://camra.colorado.edu
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10933">Representing visual classification as a linear combination of words. (arXiv:2311.10933v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Shobhit Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Semenov_Y/0/1/0/all/0/1">Yevgeniy R. Semenov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotter_W/0/1/0/all/0/1">William Lotter</a></p>
<p>Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10943">Partially Randomizing Transformer Weights for Dialogue Response Diversity. (arXiv:2311.10943v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jing Yang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kong Aik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1">Woon-Seng Gan</a></p>
<p>Despite recent progress in generative open-domain dialogue, the issue of low
response diversity persists. Prior works have addressed this issue via either
novel objective functions, alternative learning approaches such as variational
frameworks, or architectural extensions such as the Randomized Link (RL)
Transformer. However, these approaches typically entail either additional
difficulties during training/inference, or a significant increase in model size
and complexity. Hence, we propose the \underline{Pa}rtially
\underline{Ra}ndomized trans\underline{Former} (PaRaFormer), a simple extension
of the transformer which involves freezing the weights of selected layers after
random initialization. Experimental results reveal that the performance of the
PaRaformer is comparable to that of the aforementioned approaches, despite not
entailing any additional training difficulty or increase in model complexity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10944">Deception Detection from Linguistic and Physiological Data Streams Using Bimodal Convolutional Neural Networks. (arXiv:2311.10944v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Panfeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Abouelenien_M/0/1/0/all/0/1">Mohamed Abouelenien</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a></p>
<p>Deception detection is gaining increasing interest due to ethical and
security concerns. This paper explores the application of convolutional neural
networks for the purpose of multimodal deception detection. We use a dataset
built by interviewing 104 subjects about two topics, with one truthful and one
falsified response from each subject about each topic. In particular, we make
three main contributions. First, we extract linguistic and physiological
features from this data to train and construct the neural network models.
Second, we propose a fused convolutional neural network model using both
modalities in order to achieve an improved overall performance. Third, we
compare our new approach with earlier methods designed for multimodal deception
detection. We find that our system outperforms regular classification methods;
our results indicate the feasibility of using neural networks for deception
detection even in the presence of limited amounts of data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10945">An Empirical Bayes Framework for Open-Domain Dialogue Generation. (arXiv:2311.10945v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jing Yang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kong Aik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1">Woon-Seng Gan</a></p>
<p>To engage human users in meaningful conversation, open-domain dialogue agents
are required to generate diverse and contextually coherent dialogue. Despite
recent advancements, which can be attributed to the usage of pretrained
language models, the generation of diverse and coherent dialogue remains an
open research problem. A popular approach to address this issue involves the
adaptation of variational frameworks. However, while these approaches
successfully improve diversity, they tend to compromise on contextual
coherence. Hence, we propose the Bayesian Open-domain Dialogue with Empirical
Bayes (BODEB) framework, an empirical bayes framework for constructing an
Bayesian open-domain dialogue agent by leveraging pretrained parameters to
inform the prior and posterior parameter distributions. Empirical results show
that BODEB achieves better results in terms of both diversity and coherence
compared to variational frameworks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10961">Journey of Hallucination-minimized Generative AI Solutions for Financial Decision Makers. (arXiv:2311.10961v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roychowdhury_S/0/1/0/all/0/1">Sohini Roychowdhury</a></p>
<p>Generative AI has significantly reduced the entry barrier to the domain of AI
owing to the ease of use and core capabilities of automation, translation, and
intelligent actions in our day to day lives. Currently, Large language models
(LLMs) that power such chatbots are being utilized primarily for their
automation capabilities for software monitoring, report generation etc. and for
specific personalized question answering capabilities, on a limited scope and
scale. One major limitation of the currently evolving family of LLMs is
'hallucinations', wherein inaccurate responses are reported as factual.
Hallucinations are primarily caused by biased training data, ambiguous prompts
and inaccurate LLM parameters, and they majorly occur while combining
mathematical facts with language-based context. Thus, monitoring and
controlling for hallucinations becomes necessary when designing solutions that
are meant for decision makers. In this work we present the three major stages
in the journey of designing hallucination-minimized LLM-based solutions that
are specialized for the decision makers of the financial domain, namely:
prototyping, scaling and LLM evolution using human feedback. These three stages
and the novel data to answer generation modules presented in this work are
necessary to ensure that the Generative AI chatbots, autonomous reports and
alerts are reliable and high-quality to aid key decision-making processes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10995">Behavior Optimized Image Generation. (arXiv:2311.10995v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khurana_V/0/1/0/all/0/1">Varun Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1">Yaman K Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_J/0/1/0/all/0/1">Jayakumar Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Rajiv Ratn Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Changyou Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiqiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1">Balaji Krishnamurthy</a></p>
<p>The last few years have witnessed great success on image generation, which
has crossed the acceptance thresholds of aesthetics, making it directly
applicable to personal and commercial applications. However, images, especially
in marketing and advertising applications, are often created as a means to an
end as opposed to just aesthetic concerns. The goal can be increasing sales,
getting more clicks, likes, or image sales (in the case of stock businesses).
Therefore, the generated images need to perform well on these key performance
indicators (KPIs), in addition to being aesthetically good. In this paper, we
make the first endeavor to answer the question of "How can one infuse the
knowledge of the end-goal within the image generation process itself to create
not just better-looking images but also "better-performing'' images?''. We
propose BoigLLM, an LLM that understands both image content and user behavior.
BoigLLM knows how an image should look to get a certain required KPI. We show
that BoigLLM outperforms 13x larger models such as GPT-3.5 and GPT-4 in this
task, demonstrating that while these state-of-the-art models can understand
images, they lack information on how these images perform in the real world. To
generate actual pixels of behavior-conditioned images, we train a
diffusion-based model (BoigSD) to align with a proposed BoigLLM-defined reward.
We show the performance of the overall pipeline on two datasets covering two
different behaviors: a stock dataset with the number of forward actions as the
KPI and a dataset containing tweets with the total likes as the KPI, denoted as
BoigBench. To advance research in the direction of utility-driven image
generation and understanding, we release BoigBench, a benchmark dataset
containing 168 million enterprise tweets with their media, brand account names,
time of post, and total likes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11001">Gendec: A Machine Learning-based Framework for Gender Detection from Japanese Names. (arXiv:2311.11001v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pham_D/0/1/0/all/0/1">Duong Tien Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1">Luan Thanh Nguyen</a></p>
<p>Every human has their own name, a fundamental aspect of their identity and
cultural heritage. The name often conveys a wealth of information, including
details about an individual's background, ethnicity, and, especially, their
gender. By detecting gender through the analysis of names, researchers can
unlock valuable insights into linguistic patterns and cultural norms, which can
be applied to practical applications. Hence, this work presents a novel dataset
for Japanese name gender detection comprising 64,139 full names in romaji,
hiragana, and kanji forms, along with their biological genders. Moreover, we
propose Gendec, a framework for gender detection from Japanese names that
leverages diverse approaches, including traditional machine learning techniques
or cutting-edge transfer learning models, to predict the gender associated with
Japanese names accurately. Through a thorough investigation, the proposed
framework is expected to be effective and serve potential applications in
various domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11009">Joyful: Joint Modality Fusion and Graph Contrastive Learning for Multimodal Emotion Recognition. (arXiv:2311.11009v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yusong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Funakoshi_K/0/1/0/all/0/1">Kotaro Funakoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okumura_M/0/1/0/all/0/1">Manabu Okumura</a></p>
<p>Multimodal emotion recognition aims to recognize emotions for each utterance
of multiple modalities, which has received increasing attention for its
application in human-machine interaction. Current graph-based methods fail to
simultaneously depict global contextual features and local diverse uni-modal
features in a dialogue. Furthermore, with the number of graph layers
increasing, they easily fall into over-smoothing. In this paper, we propose a
method for joint modality fusion and graph contrastive learning for multimodal
emotion recognition (Joyful), where multimodality fusion, contrastive learning,
and emotion recognition are jointly optimized. Specifically, we first design a
new multimodal fusion mechanism that can provide deep interaction and fusion
between the global contextual and uni-modal specific features. Then, we
introduce a graph contrastive learning framework with inter-view and intra-view
contrastive losses to learn more distinguishable representations for samples
with different sentiments. Extensive experiments on three benchmark datasets
indicate that Joyful achieved state-of-the-art (SOTA) performance compared to
all baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11012">Bit Cipher -- A Simple yet Powerful Word Representation System that Integrates Efficiently with Language Models. (arXiv:2311.11012v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoran Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Jake Ryland Williams</a></p>
<p>While Large Language Models (LLMs) become ever more dominant, classic
pre-trained word embeddings sustain their relevance through computational
efficiency and nuanced linguistic interpretation. Drawing from recent studies
demonstrating that the convergence of GloVe and word2vec optimizations all tend
towards log-co-occurrence matrix variants, we construct a novel word
representation system called Bit-cipher that eliminates the need of
backpropagation while leveraging contextual information and hyper-efficient
dimensionality reduction techniques based on unigram frequency, providing
strong interpretability, alongside efficiency. We use the bit-cipher algorithm
to train word vectors via a two-step process that critically relies on a
hyperparameter -- bits -- that controls the vector dimension. While the first
step trains the bit-cipher, the second utilizes it under two different
aggregation modes -- summation or concatenation -- to produce contextually rich
representations from word co-occurrences. We extend our investigation into
bit-cipher's efficacy, performing probing experiments on part-of-speech (POS)
tagging and named entity recognition (NER) to assess its competitiveness with
classic embeddings like word2vec and GloVe. Additionally, we explore its
applicability in LM training and fine-tuning. By replacing embedding layers
with cipher embeddings, our experiments illustrate the notable efficiency of
cipher in accelerating the training process and attaining better optima
compared to conventional training paradigms. Experiments on the integration of
bit-cipher embedding layers with Roberta, T5, and OPT, prior to or as a
substitute for fine-tuning, showcase a promising enhancement to transfer
learning, allowing rapid model convergence while preserving competitive
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1612.04765">CoPaSul Manual -- Contour-based parametric and superpositional intonation stylization. (arXiv:1612.04765v13 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Reichel_U/0/1/0/all/0/1">Uwe D. Reichel</a></p>
<p>The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and
(2) prosodic feature extraction from syllable to utterance level. CoPaSul
stands for contour-based, parametric, superpositional intonation stylization.
In this framework intonation is represented as a superposition of global and
local contours that are described parametrically in terms of polynomial
coefficients. On the global level (usually associated but not necessarily
restricted to intonation phrases) the stylization serves to represent register
in terms of time-varying F0 level and range. On the local level (e.g. accent
groups), local contour shapes are described. From this parameterization several
features related to prosodic boundaries and prominence can be derived.
Furthermore, by coefficient clustering prosodic contour classes can be obtained
in a bottom-up way. Next to the stylization-based feature extraction also
standard F0 and energy measures (e.g. mean and variance) as well as rhythmic
aspects can be calculated. At the current state automatic annotation comprises:
segmentation into interpausal chunks, syllable nucleus extraction, and
unsupervised localization of prosodic phrase boundaries and prominent
syllables. F0 and partly also energy feature sets can be derived for: standard
measurements (as median and IQR), register in terms of F0 level and range,
prosodic boundaries, local contour shapes, bottom-up derived contour classes,
Gestalt of accent groups in terms of their deviation from higher level prosodic
units, as well as for rhythmic aspects quantifying the relation between F0 and
energy contours and prosodic event rates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2105.01311">Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning. (arXiv:2105.01311v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xiangyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiegreffe_S/0/1/0/all/0/1">Sarah Wiegreffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1">Mark Riedl</a></p>
<p>Transformer-based language model approaches to automated story generation
currently provide state-of-the-art results. However, they still suffer from
plot incoherence when generating narratives over time, and critically lack
basic commonsense reasoning. Furthermore, existing methods generally focus only
on single-character stories, or fail to track characters at all. To improve the
coherence of generated narratives and to expand the scope of character-centric
narrative generation, we introduce Commonsense-inference Augmented neural
StoryTelling (CAST), a framework for introducing commonsense reasoning into the
generation process with the option to model the interaction between multiple
characters. We find that our CAST method produces significantly more coherent,
on-topic, enjoyable and fluent stories than existing models in both the
single-character and two-character settings in three storytelling domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.01140">Predicting Influenza A Viral Host Using PSSM and Word Embeddings. (arXiv:2201.01140v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanhua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1">Dominik Wojtczak</a></p>
<p>The rapid mutation of the influenza virus threatens public health.
Reassortment among viruses with different hosts can lead to a fatal pandemic.
However, it is difficult to detect the original host of the virus during or
after an outbreak as influenza viruses can circulate between different species.
Therefore, early and rapid detection of the viral host would help reduce the
further spread of the virus. We use various machine learning models with
features derived from the position-specific scoring matrix (PSSM) and features
learned from word embedding and word encoding to infer the origin host of
viruses. The results show that the performance of the PSSM-based model reaches
the MCC around 95%, and the F1 around 96%. The MCC obtained using the model
with word embedding is around 96%, and the F1 is around 97%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.15439">StyleTTS: A Style-Based Generative Model for Natural and Diverse Text-to-Speech Synthesis. (arXiv:2205.15439v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yinghao Aaron Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Cong Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Mesgarani_N/0/1/0/all/0/1">Nima Mesgarani</a></p>
<p>Text-to-Speech (TTS) has recently seen great progress in synthesizing
high-quality speech owing to the rapid development of parallel TTS systems, but
producing speech with naturalistic prosodic variations, speaking styles and
emotional tones remains challenging. Moreover, since duration and speech are
generated separately, parallel TTS models still have problems finding the best
monotonic alignments that are crucial for naturalistic speech synthesis. Here,
we propose StyleTTS, a style-based generative model for parallel TTS that can
synthesize diverse speech with natural prosody from a reference speech
utterance. With novel Transferable Monotonic Aligner (TMA) and
duration-invariant data augmentation schemes, our method significantly
outperforms state-of-the-art models on both single and multi-speaker datasets
in subjective tests of speech naturalness and speaker similarity. Through
self-supervised learning of the speaking styles, our model can synthesize
speech with the same prosodic and emotional tone as any given reference speech
without the need for explicitly labeling these categories.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.07496">Unsupervised Opinion Summarization Using Approximate Geodesics. (arXiv:2209.07496v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Somnath Basu Roy Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Monath_N/0/1/0/all/0/1">Nicholas Monath</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1">Avinava Dubey</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Amr Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaturvedi_S/0/1/0/all/0/1">Snigdha Chaturvedi</a></p>
<p>Opinion summarization is the task of creating summaries capturing popular
opinions from user reviews. In this paper, we introduce Geodesic Summarizer
(GeoSumm), a novel system to perform unsupervised extractive opinion
summarization. GeoSumm involves an encoder-decoder based representation
learning model, that generates representations of text as a distribution over
latent semantic units. GeoSumm generates these representations by performing
dictionary learning over pre-trained text representations at multiple decoder
layers. We then use these representations to quantify the relevance of review
sentences using a novel approximate geodesic distance based scoring mechanism.
We use the relevance scores to identify popular opinions in order to compose
general and aspect-specific summaries. Our proposed model, GeoSumm, achieves
state-of-the-art performance on three opinion summarization datasets. We
perform additional experiments to analyze the functioning of our model and
showcase the generalization ability of {\X} across different domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.09757">Language Varieties of Italy: Technology Challenges and Opportunities. (arXiv:2209.09757v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramponi_A/0/1/0/all/0/1">Alan Ramponi</a></p>
<p>Italy is characterized by a one-of-a-kind linguistic diversity landscape in
Europe, which implicitly encodes local knowledge, cultural traditions, artistic
expressions and history of its speakers. However, most local languages and
dialects in Italy are at risk of disappearing within few generations. The NLP
community has recently begun to engage with endangered languages, including
those of Italy. Yet, most efforts assume that these varieties are
under-resourced language monoliths with an established written form and
homogeneous functions and needs, and thus highly interchangeable with each
other and with high-resource, standardized languages. In this paper, we
introduce the linguistic context of Italy and challenge the default
machine-centric assumptions of NLP for Italy's language varieties. We advocate
for a shift in the paradigm from machine-centric to speaker-centric NLP, and
provide recommendations and opportunities for work that prioritizes languages
and their speakers over technological advances. To facilitate the process, we
finally propose building a local community towards responsible, participatory
efforts aimed at supporting vitality of languages and dialects of Italy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08358">MEAL: Stable and Active Learning for Few-Shot Prompting. (arXiv:2211.08358v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koksal_A/0/1/0/all/0/1">Abdullatif K&#xf6;ksal</a>, <a href="http://arxiv.org/find/cs/1/au:+Schick_T/0/1/0/all/0/1">Timo Schick</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a></p>
<p>Few-shot classification has made great strides due to foundation models that,
through priming and prompting, are highly effective few-shot learners. However,
this approach has high variance both across different sets of few shots (data
selection) and across different finetuning runs (run variability). This is
problematic not only because it impedes the fair comparison of different
approaches, but especially because it makes few-shot learning too unreliable
for many real-world applications. To alleviate these issues, we make two
contributions for more stable and effective few-shot learning: First, we
propose novel ensembling methods and show that they substantially reduce run
variability. Second, we introduce a new active learning (AL) criterion for data
selection and present the first AL-based approach specifically tailored towards
prompt-based learning. In our experiments, we show that our combined method,
MEAL (Multiprompt finetuning and prediction Ensembling with Active Learning),
improves overall performance of prompt-based finetuning by 2.3 points on five
diverse tasks. We publicly share our code and data splits in
https://github.com/akoksal/MEAL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.11489">Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation. (arXiv:2301.11489v3 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leszczynski_M/0/1/0/all/0/1">Megan Leszczynski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganti_R/0/1/0/all/0/1">Ravi Ganti</a>, <a href="http://arxiv.org/find/cs/1/au:+Balog_K/0/1/0/all/0/1">Krisztian Balog</a>, <a href="http://arxiv.org/find/cs/1/au:+Radlinski_F/0/1/0/all/0/1">Filip Radlinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1">Fernando Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaganty_A/0/1/0/all/0/1">Arun Tejasvi Chaganty</a></p>
<p>Recommender systems are ubiquitous yet often difficult for users to control,
and adjust if recommendation quality is poor. This has motivated conversational
recommender systems (CRSs), with control provided through natural language
feedback. However, as with most application domains, building robust CRSs
requires training data that reflects system usage$\unicode{x2014}$here
conversations with user utterances paired with items that cover a wide range of
preferences. This has proved challenging to collect scalably using conventional
methods. We address the question of whether it can be generated synthetically,
building on recent advances in natural language. We evaluate in the setting of
item set recommendation, noting the increasing attention to this task motivated
by use cases like music, news, and recipe recommendation. We present
TalkTheWalk, which synthesizes realistic high-quality conversational data by
leveraging domain expertise encoded in widely available curated item
collections, generating a sequence of hypothetical yet plausible item sets,
then using a language model to produce corresponding user utterances. We
generate over one million diverse playlist curation conversations in the music
domain, and show these contain consistent utterances with relevant item sets
nearly matching the quality of an existing but small human-collected dataset
for this task. We demonstrate the utility of the generated synthetic dataset on
a conversational item retrieval task and show that it improves over both
unsupervised baselines and systems trained on a real dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.03169">Data Selection for Language Models via Importance Resampling. (arXiv:2302.03169v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Sang Michael Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Santurkar_S/0/1/0/all/0/1">Shibani Santurkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a></p>
<p>Selecting a suitable pretraining dataset is crucial for both general-domain
(e.g., GPT-3) and domain-specific (e.g., Codex) language models (LMs). We
formalize this problem as selecting a subset of a large raw unlabeled dataset
to match a desired target distribution given unlabeled target samples. Due to
the scale and dimensionality of the raw text data, existing methods use simple
heuristics or require human experts to manually curate data. Instead, we extend
the classic importance resampling approach used in low-dimensions for LM data
selection. We propose Data Selection with Importance Resampling (DSIR), an
efficient and scalable framework that estimates importance weights in a reduced
feature space for tractability and selects data with importance resampling
according to these weights. We instantiate the DSIR framework with hashed
n-gram features for efficiency, enabling the selection of 100M documents from
the full Pile dataset in 4.5 hours. To measure whether hashed n-gram features
preserve the aspects of the data that are relevant to the target, we define KL
reduction, a data metric that measures the proximity between the selected
pretraining data and the target on some feature space. Across 8 data selection
methods (including expert selection), KL reduction on hashed n-gram features
highly correlates with average downstream accuracy (r=0.82). When selecting
data for continued pretraining on a specific domain, DSIR performs comparably
to expert curation across 8 target distributions. When pretraining
general-domain models (target is Wikipedia and books), DSIR improves over
random selection and heuristic filtering baselines by 2-2.5% on the GLUE
benchmark. Code is available at https://github.com/p-lambda/dsir.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.05507">Language Decision Transformers with Exponential Tilt for Interactive Text Environments. (arXiv:2302.05507v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gontier_N/0/1/0/all/0/1">Nicolas Gontier</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1">Pau Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1">Issam Laradji</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazquez_D/0/1/0/all/0/1">David Vazquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a></p>
<p>Text-based game environments are challenging because agents must deal with
long sequences of text, execute compositional actions using text and learn from
sparse rewards. We address these challenges by proposing Language Decision
Transformers (LDTs), a framework that is based on transformer language models
and decision transformers (DTs). Our LDTs extend DTs with 3 components: (1)
exponential tilt to guide the agent towards high obtainable goals, (2) novel
goal conditioning methods yielding better results than the traditional
return-to-go (sum of all future rewards), and (3) a model of future
observations that improves agent performance. LDTs are the first to address
offline RL with DTs on these challenging games. Our experiments show that LDTs
achieve the highest scores among many different types of agents on some of the
most challenging Jericho games, such as Enchanter.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06476">Is ChatGPT a General-Purpose Natural Language Processing Task Solver?. (arXiv:2302.06476v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chengwei Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aston Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1">Michihiro Yasunaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Diyi Yang</a></p>
<p>Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.08143">Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?. (arXiv:2302.08143v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chengwei Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ruochen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a></p>
<p>Prompt tuning (PT) which only tunes the embeddings of an additional sequence
of tokens per task, keeping the pre-trained language model (PLM) frozen, has
shown remarkable performance in few-shot learning. Despite this, PT has been
shown to rely heavily on good initialization of the prompt embeddings. In this
work, we study meta prompt tuning (MPT) to systematically explore how
meta-learning can help improve (if it can) cross-task generalization in PT
through learning to initialize the prompt embeddings from other relevant tasks.
We empirically analyze a representative set of meta learning algorithms in a
wide range of adaptation settings with different source/target task
configurations on a large set of few-shot tasks. With extensive experiments and
analysis, we demonstrate the effectiveness of MPT. We find the improvement to
be significant particularly on classification tasks. For other kinds of tasks
such as question answering, we observe that while MPT can outperform PT in most
cases, it does not always outperform multi-task learning. We further provide an
in-depth analysis from the perspective of task similarity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.15445">IRFL: Image Recognition of Figurative Language. (arXiv:2303.15445v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yosef_R/0/1/0/all/0/1">Ron Yosef</a>, <a href="http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1">Yonatan Bitton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahaf_D/0/1/0/all/0/1">Dafna Shahaf</a></p>
<p>Figures of speech such as metaphors, similes, and idioms are integral parts
of human communication. They are ubiquitous in many forms of discourse,
allowing people to convey complex, abstract ideas and evoke emotion. As
figurative forms are often conveyed through multiple modalities (e.g., both
text and images), understanding multimodal figurative language is an important
AI challenge, weaving together profound vision, language, commonsense and
cultural knowledge.
</p>
<p>In this work, we develop the Image Recognition of Figurative Language (IRFL)
dataset. We leverage human annotation and an automatic pipeline we created to
generate a multimodal dataset, and introduce two novel tasks as a benchmark for
multimodal figurative language understanding. We experimented with
state-of-the-art vision and language models and found that the best (22%)
performed substantially worse than humans (97%). We release our dataset,
benchmark, and code, in hopes of driving the development of models that can
better understand figurative language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.13867">Transferring Procedural Knowledge across Commonsense Tasks. (arXiv:2304.13867v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yifan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1">Filip Ilievski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kaixin Ma</a></p>
<p>Stories about everyday situations are an essential part of human
communication, motivating the need to develop AI agents that can reliably
understand these stories. Despite the long list of supervised methods for story
completion and procedural understanding, current AI has no mechanisms to
automatically track and explain procedures in unseen stories. To bridge this
gap, we study the ability of AI models to transfer procedural knowledge to
novel narrative tasks in a transparent manner. We design LEAP: a comprehensive
framework that integrates state-of-the-art modeling architectures, training
regimes, and augmentation strategies based on both natural and synthetic
stories. To address the lack of densely annotated training data, we devise a
robust automatic labeler based on few-shot prompting to enhance the augmented
data. Our experiments with in- and out-of-domain tasks reveal insights into the
interplay of different architectures, training regimes, and augmentation
strategies. LEAP's labeler has a clear positive impact on out-of-domain
datasets, while the resulting dense annotation provides native explainability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13302">Language-Agnostic Bias Detection in Language Models with Bias Probing. (arXiv:2305.13302v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koksal_A/0/1/0/all/0/1">Abdullatif K&#xf6;ksal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yalcin_O/0/1/0/all/0/1">Omer Faruk Yalcin</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbiyik_A/0/1/0/all/0/1">Ahmet Akbiyik</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilavuz_M/0/1/0/all/0/1">M. Tahir Kilavuz</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a></p>
<p>Pretrained language models (PLMs) are key components in NLP, but they contain
strong social biases. Quantifying these biases is challenging because current
methods focusing on fill-the-mask objectives are sensitive to slight changes in
input. To address this, we propose a bias probing technique called LABDet, for
evaluating social bias in PLMs with a robust and language-agnostic method. For
nationality as a case study, we show that LABDet `surfaces' nationality bias by
training a classifier on top of a frozen PLM on non-nationality sentiment
detection. We find consistent patterns of nationality bias across monolingual
PLMs in six languages that align with historical and political context. We also
show for English BERT that bias surfaced by LABDet correlates well with bias in
the pretraining data; thus, our work is one of the few studies that directly
links pretraining data to PLM behavior. Finally, we verify LABDet's reliability
and applicability to different templates and languages through an extensive set
of robustness checks. We publicly share our code and dataset in
https://github.com/akoksal/LABDet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14681">Emergent inabilities? Inverse scaling over the course of pretraining. (arXiv:2305.14681v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Michaelov_J/0/1/0/all/0/1">James A. Michaelov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1">Benjamin K. Bergen</a></p>
<p>Does inverse scaling only occur as a function of model size, or can it also
occur over the course of training? We carry out an exploratory study
investigating whether the performance of language models on specific tasks can
decrease (while general performance remains high) during training on the
language modeling task. We find 8 tasks on which Pythia 12B (Biderman et al.,
2023) shows decreased performance over the course of training. Five of these
tasks (TruthfulQA-MC1, TruthfulQA-MC2, Hindsight Neglect, Memo Trap, and
Pattern Match Suppression) additionally show a consistent relationship whereby
larger language models show a greater decrease in performance the more they are
trained, despite showing standard (positive) scaling overall. This highlights
the importance of testing performance at all relevant benchmarks any time
models are trained on additional data, even if their overall performance
improves
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14864">How To Train Your (Compressed) Large Language Model. (arXiv:2305.14864v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1">Ananya Harsh Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1">Tom Sherborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Walsh_E/0/1/0/all/0/1">Evan Pete Walsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Groeneveld_D/0/1/0/all/0/1">Dirk Groeneveld</a>, <a href="http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1">Emma Strubell</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1">Iz Beltagy</a></p>
<p>With the increase in the size of large language models (LLMs), we need
compression methods that can reduce the model size while preserving the
generality and zero-shot promptability of the model. This goal is more
ambitious than the typical compression setup, which reduces the model's size at
the expense of specializing it to a specific end-task. To study this, we
develop a task-agnostic compression pipeline with a large-scale evaluation
comprising language modeling perplexity and 12 zero-shot end-tasks. Our results
show that a simple layer-wise pruning followed by continued language model
pretraining matches or outperforms three existing state-of-the-art baselines
while being 1.5x more computationally efficient. However, unlike typical
task-specialized compression, our best-compressed model significantly
underperforms a similar-sized model trained from scratch. We posit the
half-sized pretrained model as an upper bound for task-agnostic compression and
call for future work to bridge this gap under a reasonable token budget. Our
findings highlight the inadequacy of existing compression methods for LLMs and
establish a requirement for new methods that preserve a model's generality and
zero-shot promptability under compression. We release our code and evaluation
setup to facilitate reproducibility and help iterate on method design.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16300">Landmark Attention: Random-Access Infinite Context Length for Transformers. (arXiv:2305.16300v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mohtashami_A/0/1/0/all/0/1">Amirkeivan Mohtashami</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a></p>
<p>While Transformers have shown remarkable success in natural language
processing, their attention mechanism's large memory requirements have limited
their ability to handle longer contexts. Prior approaches, such as recurrent
memory or retrieval-based augmentation, have either compromised the
random-access flexibility of attention (i.e., the capability to select any
token in the entire context) or relied on separate mechanisms for relevant
context retrieval, which may not be compatible with the model's attention. In
this paper, we present a novel approach that allows access to the complete
context while retaining random-access flexibility, closely resembling running
attention on the entire context. Our method uses a landmark token to represent
each block of the input and trains the attention to use it for selecting
relevant blocks, enabling retrieval of blocks directly through the attention
mechanism instead of by relying on a separate mechanism. Our approach
seamlessly integrates with specialized data structures and the system's memory
hierarchy, enabling processing of arbitrarily long context lengths. We
demonstrate that our method can obtain comparable performance with
Transformer-XL while significantly reducing the number of retrieved tokens in
each step. Finally, we show that fine-tuning LLaMA 7B with our method
successfully extends its context length capacity to over 32k tokens, allowing
for inference at the context lengths of GPT-4. We release the implementation of
landmark attention and the code to reproduce our experiments at
https://github.com/epfml/landmark-attention/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02080">Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models. (arXiv:2306.02080v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jindong Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhen Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yunpu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a></p>
<p>Various adaptation methods, such as LoRA, prompts, and adapters, have been
proposed to enhance the performance of pre-trained vision-language models in
specific domains. The robustness of these adaptation methods against
distribution shifts have not been studied. In this study, we assess the
robustness of 11 widely-used adaptation methods across 4 vision-language
datasets under multimodal corruptions. Concretely, we introduce 7 benchmark
datasets, including 96 visual and 87 textual corruptions, to investigate the
robustness of different adaptation methods, the impact of available adaptation
examples, and the influence of trainable parameter size during adaptation. Our
analysis reveals that: 1) Adaptation methods are more sensitive to text
corruptions than visual corruptions. 2) Full fine-tuning does not consistently
provide the highest robustness; instead, adapters can achieve better robustness
with comparable clean performance. 3) Contrary to expectations, our findings
indicate that increasing the number of adaptation data and parameters does not
guarantee enhanced robustness; instead it results in even lower robustness. We
hope this study could benefit future research in the development of robust
multimodal adaptation methods. The benchmark, code, and dataset used in this
study can be accessed at https://adarobustness.github.io .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07691">StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models. (arXiv:2306.07691v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yinghao Aaron Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Cong Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Raghavan_V/0/1/0/all/0/1">Vinay S. Raghavan</a>, <a href="http://arxiv.org/find/eess/1/au:+Mischler_G/0/1/0/all/0/1">Gavin Mischler</a>, <a href="http://arxiv.org/find/eess/1/au:+Mesgarani_N/0/1/0/all/0/1">Nima Mesgarani</a></p>
<p>In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that
leverages style diffusion and adversarial training with large speech language
models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its
predecessor by modeling styles as a latent random variable through diffusion
models to generate the most suitable style for the text without requiring
reference speech, achieving efficient latent diffusion while benefiting from
the diverse speech synthesis offered by diffusion models. Furthermore, we
employ large pre-trained SLMs, such as WavLM, as discriminators with our novel
differentiable duration modeling for end-to-end training, resulting in improved
speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker
LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by
native English speakers. Moreover, when trained on the LibriTTS dataset, our
model outperforms previous publicly available models for zero-shot speaker
adaptation. This work achieves the first human-level TTS on both single and
multispeaker datasets, showcasing the potential of style diffusion and
adversarial training with large SLMs. The audio demos and source code are
available at https://styletts2.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04823">Evaluating the Generation Capabilities of Large Chinese Language Models. (arXiv:2308.04823v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1">Hui Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jingyuan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_M/0/1/0/all/0/1">Meng Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_B/0/1/0/all/0/1">Bin Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Na Zhang</a></p>
<p>This paper presents CG-Eval, the first comprehensive evaluation of the
generation capabilities of large Chinese language models across a wide range of
academic disciplines. The models' performance was assessed based on their
ability to generate accurate and relevant responses to different types of
questions in six disciplines, namely, Science and Engineering, Humanities and
Social Sciences, Mathematical Calculations, Medical Practitioner Qualification
Examination, Judicial Examination, and Certified Public Accountant Examination.
This paper also presents Gscore, a composite index derived from the weighted
sum of multiple metrics to measure the quality of model's generation against a
reference. The test data and test results can be found at
<a href="http://cgeval.besteasy.com/.">this http URL</a>
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.15363">Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation. (arXiv:2308.15363v4 [cs.DB] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1">Dawei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haibin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiuyu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yichen Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1">Bolin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a></p>
<p>Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL
task. However, the absence of a systematical benchmark inhibits the development
of designing effective, efficient and economic LLM-based Text-to-SQL solutions.
To address this challenge, in this paper, we first conduct a systematical and
extensive comparison over existing prompt engineering methods, including
question representation, example selection and example organization, and with
these experimental results, we elaborate their pros and cons. Based on these
findings, we propose a new integrated solution, named DAIL-SQL, which refreshes
the Spider leaderboard with 86.6% execution accuracy and sets a new bar. To
explore the potential of open-source LLM, we investigate them in various
scenarios, and further enhance their performance with supervised fine-tuning.
Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well
as the advantages and disadvantages of the supervised fine-tuning.
Additionally, towards an efficient and economic LLM-based Text-to-SQL solution,
we emphasize the token efficiency in prompt engineering and compare the prior
studies under this metric. We hope that our work provides a deeper
understanding of Text-to-SQL with LLMs, and inspires further investigations and
broad applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05619">Effective Proxy for Human Labeling: Ensemble Disagreement Scores in Large Language Models for Industrial NLP. (arXiv:2309.05619v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1">Wei Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Advani_L/0/1/0/all/0/1">Laksh Advani</a>, <a href="http://arxiv.org/find/cs/1/au:+Gambhir_Y/0/1/0/all/0/1">Yashmeet Gambhir</a>, <a href="http://arxiv.org/find/cs/1/au:+Perry_D/0/1/0/all/0/1">Daniel J Perry</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiralkar_P/0/1/0/all/0/1">Prashant Shiralkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhengzheng Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Colak_A/0/1/0/all/0/1">Aaron Colak</a></p>
<p>Large language models (LLMs) have demonstrated significant capability to
generalize across a large number of NLP tasks. For industry applications, it is
imperative to assess the performance of the LLM on unlabeled production data
from time to time to validate for a real-world setting. Human labeling to
assess model error requires considerable expense and time delay. Here we
demonstrate that ensemble disagreement scores work well as a proxy for human
labeling for language models in zero-shot, few-shot, and fine-tuned settings,
per our evaluation on keyphrase extraction (KPE) task. We measure fidelity of
the results by comparing to true error measured from human labeled ground
truth. We contrast with the alternative of using another LLM as a source of
machine labels, or silver labels. Results across various languages and domains
show disagreement scores provide a better estimation of model performance with
mean average error (MAE) as low as 0.4% and on average 13.8% better than using
silver labels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10003">A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models. (arXiv:2309.10003v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1">S&#xe9;bastien Ragot</a></p>
<p>This work proposes to measure the scope of a patent claim as the reciprocal
of the self-information contained in this claim. A probability of occurrence of
the claim is obtained from a language model and this probability is used to
compute the self-information. Grounded in information theory, this approach is
based on the assumption that an unlikely concept is more informative than a
usual concept, insofar as it is more surprising. In turn, the more surprising
the information required to defined the claim, the narrower its scope. Five
language models are considered, ranging from simplest models (each word or
character is assigned an identical probability) to intermediate models (using
average word or character frequencies), to a large language model (GPT2).
Interestingly, the scope resulting from the simplest language models is
proportional to the reciprocal of the number of words or characters involved in
the claim, a metric already used in previous works. Application is made to
multiple series of patent claims directed to distinct inventions, where each
series consists of claims devised to have a gradually decreasing scope. The
performance of the language models is assessed with respect to several ad hoc
tests. The more sophisticated the model, the better the results. I.e., the GPT2
probability model outperforms models based on word and character frequencies,
which themselves outdo the simplest models based on word or character counts.
Still, the character count appears to be a more reliable indicator than the
word count.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08365">From Large Language Models to Knowledge Graphs for Biomarker Discovery in Cancer. (arXiv:2310.08365v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Comet_L/0/1/0/all/0/1">Lina Molinas Comet</a>, <a href="http://arxiv.org/find/cs/1/au:+Shajalal_M/0/1/0/all/0/1">Md Shajalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyan_O/0/1/0/all/0/1">Oya Deniz Beyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rebholz_Schuhmann_D/0/1/0/all/0/1">Dietrich Rebholz-Schuhmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a></p>
<p>Domain experts often rely on most recent knowledge for apprehending and
disseminating specific biological processes that help them design strategies
for developing prevention and therapeutic decision-making in various disease
scenarios. A challenging scenarios for artificial intelligence (AI) is using
biomedical data (e.g., texts, imaging, omics, and clinical) to provide
diagnosis and treatment recommendations for cancerous conditions.~Data and
knowledge about biomedical entities like cancer, drugs, genes, proteins, and
their mechanism is spread across structured (knowledge bases (KBs)) and
unstructured (e.g., scientific articles) sources. A large-scale knowledge graph
(KG) can be constructed by integrating and extracting facts about semantically
interrelated entities and relations. Such a KG not only allows exploration and
question answering (QA) but also enables domain experts to deduce new
knowledge. However, exploring and querying large-scale KGs is tedious for
non-domain users due to their lack of understanding of the data assets and
semantic technologies. In this paper, we develop a domain KG to leverage
cancer-specific biomarker discovery and interactive QA. For this, we
constructed a domain ontology called OncoNet Ontology (ONO), which enables
semantic reasoning for validating gene-disease (different types of cancer)
relations. The KG is further enriched by harmonizing the ONO, metadata,
controlled vocabularies, and biomedical concepts from scientific articles by
employing BioBERT- and SciBERT-based information extractors. Further, since the
biomedical domain is evolving, where new findings often replace old ones,
without having access to up-to-date scientific findings, there is a high chance
an AI system exhibits concept drift while providing diagnosis and treatment.
Therefore, we fine-tune the KG using large language models (LLMs) based on more
recent articles and KBs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09590">Solving Math Word Problems with Reexamination. (arXiv:2310.09590v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bin_Y/0/1/0/all/0/1">Yi Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Wenhao Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yujuan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_S/0/1/0/all/0/1">See-Kiong Ng</a></p>
<p>Math word problem (MWP) solving aims to understand the descriptive math
problem and calculate the result, for which previous efforts are mostly devoted
to upgrade different technical modules. This paper brings a different
perspective of \textit{reexamination process} during training by introducing a
pseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual)
learning scheme to model such process, which is model-agnostic thus can be
adapted to any existing MWP solvers. The pseudo-dual task is specifically
defined as filling the numbers in the expression back into the original word
problem with numbers masked. To facilitate the effective joint learning of the
two tasks, we further design a scheduled fusion strategy for the number
infilling task, which smoothly switches the input from the ground-truth math
expressions to the predicted ones. Our pseudo-dual learning scheme has been
tested and proven effective when being equipped in several representative MWP
solvers through empirical studies. \textit{The codes and trained models are
available at:} \url{https://github.com/steven640pixel/PsedualMWP}.
\end{abstract}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09886">Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation. (arXiv:2310.09886v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chengwei Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a></p>
<p>Lifelong sequence generation (LSG), a problem in continual learning, aims to
continually train a model on a sequence of generation tasks to learn constantly
emerging new generation patterns while avoiding the forgetting of previous
knowledge. Existing LSG methods mainly focus on maintaining old knowledge while
paying little attention to knowledge transfer across tasks. In contrast, humans
can better learn new tasks by leveraging previously acquired knowledge from
similar tasks. Inspired by the learning paradigm of humans, we propose Dynamic
Module Expansion and Adaptation (DMEA), which enables the model to dynamically
determine the architecture for acquiring new knowledge based on task
correlation and select the most similar previous tasks to facilitate adaptation
to new tasks. In addition, as the learning process can easily be biased towards
the current task which might cause more severe forgetting of previously learned
knowledge, we propose dynamic gradient scaling to balance the learning of the
current task and replayed tasks. With extensive experiments, we demonstrate
that DMEA can consistently outperform existing methods in different LSG
settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10348">Attribution Patching Outperforms Automated Circuit Discovery. (arXiv:2310.10348v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Syed_A/0/1/0/all/0/1">Aaquib Syed</a>, <a href="http://arxiv.org/find/cs/1/au:+Rager_C/0/1/0/all/0/1">Can Rager</a>, <a href="http://arxiv.org/find/cs/1/au:+Conmy_A/0/1/0/all/0/1">Arthur Conmy</a></p>
<p>Automated interpretability research has recently attracted attention as a
potential research direction that could scale explanations of neural network
behavior to large models. Existing automated circuit discovery work applies
activation patching to identify subnetworks responsible for solving specific
tasks (circuits). In this work, we show that a simple method based on
attribution patching outperforms all existing methods while requiring just two
forward passes and a backward pass. We apply a linear approximation to
activation patching to estimate the importance of each edge in the
computational subgraph. Using this approximation, we prune the least important
edges of the network. We survey the performance and limitations of this method,
finding that averaged over all tasks our method has greater AUC from circuit
recovery than other methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11732">Investigating Uncertainty Calibration of Aligned Language Models under the Multiple-Choice Setting. (arXiv:2310.11732v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1">Guande He</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1">Peng Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianfei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenbo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a></p>
<p>Despite the significant progress made in practical applications of aligned
language models (LMs), they tend to be overconfident in output answers compared
to the corresponding pre-trained LMs. In this work, we systematically evaluate
the impact of the alignment process on logit-based uncertainty calibration of
LMs under the multiple-choice setting. We first conduct a thoughtful empirical
study on how aligned LMs differ in calibration from their pre-trained
counterparts. Experimental results reveal that there are two distinct
uncertainties in LMs under the multiple-choice setting, which are responsible
for the answer decision and the format preference of the LMs, respectively.
Then, we investigate the role of these two uncertainties on aligned LM's
calibration through fine-tuning in simple synthetic alignment schemes and
conclude that one reason for aligned LMs' overconfidence is the conflation of
these two types of uncertainty. Furthermore, we examine the utility of common
post-hoc calibration methods for aligned LMs and propose an easy-to-implement
and sample-efficient method to calibrate aligned LMs. We hope our findings
could provide insights into the design of more reliable alignment processes for
LMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.14360">Is ChatGPT a game changer for geocoding -- a benchmark for geocoding address parsing techniques. (arXiv:2310.14360v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhengcong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Diya Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_D/0/1/0/all/0/1">Daniel W. Goldberg</a></p>
<p>The remarkable success of GPT models across various tasks, including toponymy
recognition motivates us to assess the performance of the GPT-3 model in the
geocoding address parsing task. To ensure that the evaluation more accurately
mirrors performance in real-world scenarios with diverse user input qualities
and resolve the pressing need for a 'gold standard' evaluation dataset for
geocoding systems, we introduce a benchmark dataset of low-quality address
descriptions synthesized based on human input patterns mining from actual input
logs of a geocoding system in production. This dataset has 21 different input
errors and variations; contains over 239,000 address records that are uniquely
selected from streets across all U.S. 50 states and D.C.; and consists of three
subsets to be used as training, validation, and testing sets. Building on this,
we train and gauge the performance of the GPT-3 model in extracting address
components, contrasting its performance with transformer-based and LSTM-based
models. The evaluation results indicate that Bidirectional LSTM-CRF model has
achieved the best performance over these transformer-based models and GPT-3
model. Transformer-based models demonstrate very comparable results compared to
the Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in
performance, showcases potential in the address parsing task with few-shot
examples, exhibiting room for improvement with additional fine-tuning. We open
source the code and data of this presented benchmark so that researchers can
utilize it for future model development or extend it to evaluate similar tasks,
such as document geocoding.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15127">Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models. (arXiv:2310.15127v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarch_G/0/1/0/all/0/1">Gabriel Sarch</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarr_M/0/1/0/all/0/1">Michael J. Tarr</a>, <a href="http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1">Katerina Fragkiadaki</a></p>
<p>Pre-trained and frozen large language models (LLMs) can effectively map
simple scene rearrangement instructions to programs over a robot's visuomotor
functions through appropriate few-shot example prompting. To parse open-domain
natural language and adapt to a user's idiosyncratic procedures, not known
during prompt engineering time, fixed prompts fall short. In this paper, we
introduce HELPER, an embodied agent equipped with an external memory of
language-program pairs that parses free-form human-robot dialogue into action
programs through retrieval-augmented LLM prompting: relevant memories are
retrieved based on the current dialogue, instruction, correction, or VLM
description, and used as in-context prompt examples for LLM querying. The
memory is expanded during deployment to include pairs of user's language and
action plans, to assist future inferences and personalize them to the user's
language and routines. HELPER sets a new state-of-the-art in the TEACh
benchmark in both Execution from Dialog History (EDH) and Trajectory from
Dialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for
TfD. Our models, code, and video results can be found in our project's website:
https://helper-agent-llm.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.16676">SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations. (arXiv:2310.16676v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Tao Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiao Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yaoyuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1">Xinyi Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shao-Lun Huang</a></p>
<p>Emotion recognition in conversations (ERC) is a rapidly evolving task within
the natural language processing community, which aims to detect the emotions
expressed by speakers during a conversation. Recently, a growing number of ERC
methods have focused on leveraging supervised contrastive learning (SCL) to
enhance the robustness and generalizability of learned features. However,
current SCL-based approaches in ERC are impeded by the constraint of large
batch sizes and the lack of compatibility with most existing ERC models. To
address these challenges, we propose an efficient and model-agnostic SCL
framework named Supervised Sample-Label Contrastive Learning with Soft-HGR
Maximal Correlation (SSLCL), which eliminates the need for a large batch size
and can be seamlessly integrated with existing ERC models without introducing
any model-specific assumptions. Specifically, we introduce a novel perspective
on utilizing label representations by projecting discrete labels into dense
embeddings through a shallow multilayer perceptron, and formulate the training
objective to maximize the similarity between sample features and their
corresponding ground-truth label embeddings, while minimizing the similarity
between sample features and label embeddings of disparate classes. Moreover, we
innovatively adopt the Soft-HGR maximal correlation as a measure of similarity
between sample features and label embeddings, leading to significant
performance improvements over conventional similarity measures. Additionally,
multimodal cues of utterances are effectively leveraged by SSLCL as data
augmentations to boost model performances. Extensive experiments on two ERC
benchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and
superiority of our proposed SSLCL framework compared to existing
state-of-the-art SCL methods. Our code is available at
\url{https://github.com/TaoShi1998/SSLCL}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18365">Using GPT-4 to Augment Unbalanced Data for Automatic Scoring. (arXiv:2310.18365v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Luyang Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gyeong-Geon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaoming Zhai</a></p>
<p>Machine learning-based automatic scoring can be challenging if students'
responses are unbalanced across scoring categories, as it introduces
uncertainty in the machine training process. To meet this challenge, we
introduce a novel text data augmentation framework using GPT-4, a generative
large language model, specifically tailored for unbalanced datasets in
automatic scoring. Our experimental dataset comprised student-written responses
to two science items. We crafted prompts for GPT-4 to generate responses
resembling student-written answers, particularly for the minority scoring
classes, to augment the data. We then finetuned DistillBERT for automatic
scoring based on the augmented and original datasets. Model performance was
assessed using accuracy, precision, recall, and F1 score. We incorporate varied
amounts of augmented data to examine scoring performance, and our findings
revealed remarkedly improved model performance. The average maximum increase
observed across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for
recall, and 24.2% for F1 score. Notably, using just 5% of the augmented data
led to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,
the extent of improvement varied depending on specific datasets. Moreover, we
found that a varying amount of augmented data (5%-40%) was needed to obtain a
stable improvement. We also compare models trained with GPT-4 augmented data
and those trained with additional student-written responses. The findings
indicate that former ones match or even exceed the performance of the latter.
Specifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for
four metrics separately. This research underscores the potential and
effectiveness of data augmentation techniques utilizing GPT-4 in addressing
unbalanced datasets within automated assessment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19130">Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender. (arXiv:2310.19130v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sabir_A/0/1/0/all/0/1">Ahmed Sabir</a>, <a href="http://arxiv.org/find/cs/1/au:+Padro_L/0/1/0/all/0/1">Llu&#xed;s Padr&#xf3;</a></p>
<p>In this paper, we investigate the impact of objects on gender bias in image
captioning systems. Our results show that only gender-specific objects have a
strong gender bias (e.g., women-lipstick). In addition, we propose a visual
semantic-based gender score that measures the degree of bias and can be used as
a plug-in for any image captioning system. Our experiments demonstrate the
utility of the gender score, since we observe that our score can measure the
bias relation between a caption and its related gender; therefore, our score
can be used as an additional metric to the existing Object Gender Co-Occ
approach. Code and data are publicly available at
\url{https://github.com/ahmedssabir/GenderScore}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19727">Generating Medical Prescriptions with Conditional Transformer. (arXiv:2310.19727v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Belkadi_S/0/1/0/all/0/1">Samuel Belkadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Micheletti_N/0/1/0/all/0/1">Nicolo Micheletti</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lifeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Del_Pinto_W/0/1/0/all/0/1">Warren Del-Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1">Goran Nenadic</a></p>
<p>Access to real-world medication prescriptions is essential for medical
research and healthcare quality improvement. However, access to real medication
prescriptions is often limited due to the sensitive nature of the information
expressed. Additionally, manually labelling these instructions for training and
fine-tuning Natural Language Processing (NLP) models can be tedious and
expensive. We introduce a novel task-specific model architecture,
Label-To-Text-Transformer (\textbf{LT3}), tailored to generate synthetic
medication prescriptions based on provided labels, such as a vocabulary list of
medications and their attributes. LT3 is trained on a set of around 2K lines of
medication prescriptions extracted from the MIMIC-III database, allowing the
model to produce valuable synthetic medication prescriptions. We evaluate LT3's
performance by contrasting it with a state-of-the-art Pre-trained Language
Model (PLM), T5, analysing the quality and diversity of generated texts. We
deploy the generated synthetic data to train the SpacyNER model for the Named
Entity Recognition (NER) task over the n2c2-2018 dataset. The experiments show
that the model trained on synthetic data can achieve a 96-98\% F1 score at
Label Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and
data will be shared at
\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.04666">Pre-training LLMs using human-like development data corpus. (arXiv:2311.04666v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhardwaj_K/0/1/0/all/0/1">Khushi Bhardwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Raj Sanjay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Varma_S/0/1/0/all/0/1">Sashank Varma</a></p>
<p>Pre-trained Large Language Models (LLMs) have shown success in a diverse set
of language inference and understanding tasks. The pre-training stage of LLMs
looks at a large corpus of raw textual data. The BabyLM shared task compares
LLM pre-training to human language acquisition, where the number of tokens seen
by 13-year-old kids is magnitudes smaller than the number of tokens seen by
LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn
contextual word representations using roughly the same number of tokens as seen
by children. We provide a strong set of baselines; with different
architectures, evaluation of changes in performance across epochs, and reported
pre-training metrics for the strict small and strict tracks of the task. We
also try to loosely replicate the RoBERTa baseline given by the task organizers
to observe the training robustness to hyperparameter selection and
replicability. We provide the submission details to the strict and strict-small
tracks in this report.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.06453">DocGen: Generating Detailed Parameter Docstrings in Python. (arXiv:2311.06453v3 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Venkatkrishna_V/0/1/0/all/0/1">Vatsal Venkatkrishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagabushanam_D/0/1/0/all/0/1">Durga Shree Nagabushanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Simon_E/0/1/0/all/0/1">Emmanuel Iko-Ojo Simon</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidoni_M/0/1/0/all/0/1">Melina Vidoni</a></p>
<p>Documentation debt hinders the effective utilization of open-source software.
Although code summarization tools have been helpful for developers, most would
prefer a detailed account of each parameter in a function rather than a
high-level summary. However, generating such a summary is too intricate for a
single generative model to produce reliably due to the lack of high-quality
training data. Thus, we propose a multi-step approach that combines multiple
task-specific models, each adept at producing a specific section of a
docstring. The combination of these models ensures the inclusion of each
section in the final docstring. We compared the results from our approach with
existing generative models using both automatic metrics and a human-centred
evaluation with 17 participating developers, which proves the superiority of
our approach over existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07723">Generalization Analogies: A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains. (arXiv:2311.07723v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Clymer_J/0/1/0/all/0/1">Joshua Clymer</a>, <a href="http://arxiv.org/find/cs/1/au:+Baker_G/0/1/0/all/0/1">Garrett Baker</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramani_R/0/1/0/all/0/1">Rohan Subramani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sam Wang</a></p>
<p>As AI systems become more intelligent and their behavior becomes more
challenging to assess, they may learn to game the flaws of human feedback
instead of genuinely striving to follow instructions; however, this risk can be
mitigated by controlling how LLMs generalize human feedback to situations where
it is unreliable. To better understand how reward models generalize, we craft
69 distribution shifts spanning 8 categories. We find that reward models do not
learn to evaluate `instruction-following' by default and instead favor personas
that resemble internet text. Techniques for interpreting reward models'
internal representations achieve better generalization than standard
fine-tuning, but still frequently fail to distinguish instruction-following
from conflated behaviors. We consolidate the 15 most challenging distribution
shifts into the GENeralization analogIES (GENIES) benchmark, which we hope will
enable progress toward controlling reward model generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07772">In-context Learning and Gradient Descent Revisited. (arXiv:2311.07772v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deutch_G/0/1/0/all/0/1">Gilad Deutch</a>, <a href="http://arxiv.org/find/cs/1/au:+Magar_N/0/1/0/all/0/1">Nadav Magar</a>, <a href="http://arxiv.org/find/cs/1/au:+Natan_T/0/1/0/all/0/1">Tomer Bar Natan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1">Guy Dar</a></p>
<p>In-context learning (ICL) has shown impressive results in few-shot learning
tasks, yet its underlying mechanism is still not fully understood. Recent works
suggest that ICL can be thought of as a gradient descent (GD) based
optimization process. While promising, these results mainly focus on simplified
settings of ICL and provide only a preliminary evaluation of the similarities
between the two methods. In this work, we revisit the comparison between ICL
and GD-based finetuning and study what properties of ICL an equivalent process
must follow. We highlight a major difference in the flow of information between
ICL and standard finetuning. Namely, ICL can only rely on information from
lower layers at every point, while finetuning depends on loss gradients from
deeper layers. We refer to this discrepancy as Layer Causality and show that a
layer causal variant of the finetuning process aligns with ICL on par with
vanilla finetuning and is even better in most cases across relevant metrics. To
the best of our knowledge, this is the first work to discuss this discrepancy
explicitly and suggest a solution that tackles this problem with minimal
changes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07989">A Survey on Language Models for Code. (arXiv:2311.07989v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziyin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bingchang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Cong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zi Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a></p>
<p>In this work we systematically review the recent advancements in code
processing with language models, covering 50+ models, 30+ evaluation tasks,
150+ datasets, and 550 related works. We break down code processing models into
general language models represented by the GPT family and specialized models
that are specifically pretrained on code, often with tailored objectives. We
discuss the relations and differences between these models, and highlight the
historical transition of code modeling from statistical models and RNNs to
pretrained Transformers and LLMs, which is exactly the same course that had
been taken by NLP. We also discuss code-specific features such as AST, CFG, and
unit tests, along with their application in training code language models, and
identify key challenges and potential future directions in this domain. We keep
the survey open and updated on GitHub repository at
https://github.com/codefuse-ai/Awesome-Code-LLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09889">Language Generation from Human Brain Activities. (arXiv:2311.09889v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Ziyi Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yiqun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lioma_C/0/1/0/all/0/1">Christina Lioma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruotsalo_T/0/1/0/all/0/1">Tuukka Ruotsalo</a></p>
<p>Generating human language through non-invasive brain-computer interfaces
(BCIs) has the potential to unlock many applications, such as serving disabled
patients and improving communication. Currently, however, generating language
via BCIs has been previously successful only within a classification setup for
selecting pre-generated sentence continuation candidates with the most likely
cortical semantic representation. Inspired by recent research that revealed
associations between the brain and the large computational language models, we
propose a generative language BCI that utilizes the capacity of a large
language model (LLM) jointly with a semantic brain decoder to directly generate
language from functional magnetic resonance imaging (fMRI) input. The proposed
model can generate coherent language sequences aligned with the semantic
content of visual or auditory language stimuli perceived, without prior
knowledge of any pre-generated candidates. We compare the language generated
from the presented model with a random control, pre-generated language
selection approach, and a standard LLM, which generates common coherent text
solely based on the next word likelihood according to statistical language
training data. The proposed model is found to generate language that is more
aligned with semantic stimulus in response to which brain input is sampled. Our
findings demonstrate the potential and feasibility of employing BCIs in direct
language generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10057">The Song Describer Dataset: a Corpus of Audio Captions for Music-and-Language Evaluation. (arXiv:2311.10057v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manco_I/0/1/0/all/0/1">Ilaria Manco</a>, <a href="http://arxiv.org/find/cs/1/au:+Weck_B/0/1/0/all/0/1">Benno Weck</a>, <a href="http://arxiv.org/find/cs/1/au:+Doh_S/0/1/0/all/0/1">SeungHeon Doh</a>, <a href="http://arxiv.org/find/cs/1/au:+Won_M/0/1/0/all/0/1">Minz Won</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yixiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodganov_D/0/1/0/all/0/1">Dmitry Bodganov</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yusong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tovstogan_P/0/1/0/all/0/1">Philip Tovstogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1">Emmanouil Benetos</a>, <a href="http://arxiv.org/find/cs/1/au:+Quinton_E/0/1/0/all/0/1">Elio Quinton</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazekas_G/0/1/0/all/0/1">Gy&#xf6;rgy Fazekas</a>, <a href="http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1">Juhan Nam</a></p>
<p>We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of
high-quality audio-caption pairs, designed for the evaluation of
music-and-language models. The dataset consists of 1.1k human-written natural
language descriptions of 706 music recordings, all publicly accessible and
released under Creative Common licenses. To showcase the use of our dataset, we
benchmark popular models on three key music-and-language tasks (music
captioning, text-to-music generation and music-language retrieval). Our
experiments highlight the importance of cross-dataset evaluation and offer
insights into how researchers can use SDD to gain a broader understanding of
model performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10217">A Language and Its Dimensions: Intrinsic Dimensions of Language Fractal Structures. (arXiv:2311.10217v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gromov_V/0/1/0/all/0/1">Vasilii A. Gromov</a>, <a href="http://arxiv.org/find/cs/1/au:+Borodin_N/0/1/0/all/0/1">Nikita S. Borodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yerbolova_A/0/1/0/all/0/1">Asel S. Yerbolova</a></p>
<p>The present paper introduces a novel object of study - a language fractal
structure. We hypothesize that a set of embeddings of all $n$-grams of a
natural language constitutes a representative sample of this fractal set. (We
use the term Hailonakea to refer to the sum total of all language fractal
structures, over all $n$). The paper estimates intrinsic (genuine) dimensions
of language fractal structures for the Russian and English languages. To this
end, we employ methods based on (1) topological data analysis and (2) a minimum
spanning tree of a data graph for a cloud of points considered (Steele
theorem). For both languages, for all $n$, the intrinsic dimensions appear to
be non-integer values (typical for fractal sets), close to 9 for both of the
Russian and English language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10702">Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2. (arXiv:2311.10702v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ivison_H/0/1/0/all/0/1">Hamish Ivison</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1">Valentina Pyatkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lambert_N/0/1/0/all/0/1">Nathan Lambert</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_M/0/1/0/all/0/1">Matthew Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasigi_P/0/1/0/all/0/1">Pradeep Dasigi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1">Joel Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1">David Wadden</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1">Iz Beltagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a></p>
<p>Since the release of T\"ULU [Wang et al., 2023b], open resources for
instruction tuning have developed quickly, from better base models to new
finetuning techniques. We test and incorporate a number of these advances into
T\"ULU, resulting in T\"ULU 2, a suite of improved T\"ULU models for advancing
the understanding and best practices of adapting pretrained language models to
downstream tasks and user preferences. Concretely, we release: (1)
T\"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2)
T\"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\"ULU 2+DPO, T\"ULU
2 models trained with direct preference optimization (DPO), including the
largest DPO-trained model to date (T\"ULU 2+DPO 70B); (4) CODE T\"ULU 2, CODE
LLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its
instruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple
perspectives shows that the T\"ULU 2 suite achieves state-of-the-art
performance among open models and matches or exceeds the performance of
GPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data,
training and evaluation code to facilitate future open efforts on adapting
large language models.
</p>
</p>
</div>

    </div>
    </body>
    