<!DOCTYPE html>
<html>
<head>
<title>2024-01-26-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.12987">TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation. (arXiv:2401.12987v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1">Taeyang Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1">Hyunkuk Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jeonghwan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Min Song</a></p>
<p>Emotion Recognition in Conversation (ERC) plays a crucial role in enabling
dialogue systems to effectively respond to user requests. The emotions in a
conversation can be identified by the representations from various modalities,
such as audio, visual, and text. However, due to the weak contribution of
non-verbal modalities to recognize emotions, multimodal ERC has always been
considered a challenging task. In this paper, we propose Teacher-leading
Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal
knowledge distillation to transfer information from a language model acting as
the teacher to the non-verbal students, thereby optimizing the efficacy of the
weak modalities. We then combine multimodal features using a shifting fusion
approach in which student networks support the teacher. TelME achieves
state-of-the-art performance in MELD, a multi-speaker conversation dataset for
ERC. Finally, we demonstrate the effectiveness of our components through
additional experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12990">Topic Modelling: Going Beyond Token Outputs. (arXiv:2401.12990v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1">Lowri Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Anthi_E/0/1/0/all/0/1">Eirini Anthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Arman_L/0/1/0/all/0/1">Laura Arman</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnap_P/0/1/0/all/0/1">Pete Burnap</a></p>
<p>Topic modelling is a text mining technique for identifying salient themes
from a number of documents. The output is commonly a set of topics consisting
of isolated tokens that often co-occur in such documents. Manual effort is
often associated with interpreting a topic's description from such tokens.
However, from a human's perspective, such outputs may not adequately provide
enough information to infer the meaning of the topics; thus, their
interpretability is often inaccurately understood. Although several studies
have attempted to automatically extend topic descriptions as a means of
enhancing the interpretation of topic models, they rely on external language
sources that may become unavailable, must be kept up-to-date to generate
relevant results, and present privacy issues when training on or processing
data. This paper presents a novel approach towards extending the output of
traditional topic modelling methods beyond a list of isolated tokens. This
approach removes the dependence on external sources by using the textual data
itself by extracting high-scoring keywords and mapping them to the topic
model's token outputs. To measure the interpretability of the proposed outputs
against those of the traditional topic modelling approach, independent
annotators manually scored each output based on their quality and usefulness,
as well as the efficiency of the annotation task. The proposed approach
demonstrated higher quality and usefulness, as well as higher efficiency in the
annotation task, in comparison to the outputs of a traditional topic modelling
method, demonstrating an increase in their interpretability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12996">A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes. (arXiv:2401.12996v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Workman_T/0/1/0/all/0/1">Terri Elizabeth Workman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kupersmith_J/0/1/0/all/0/1">Joel Kupersmith</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1">Phillip Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Spevak_C/0/1/0/all/0/1">Christopher Spevak</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandbrink_F/0/1/0/all/0/1">Friedhelm Sandbrink</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Treitler_Y/0/1/0/all/0/1">Yan Cheng Qing Zeng-Treitler</a></p>
<p>Background: Electronic health records (EHRs) are a data source for opioid
research. Opioid use disorder is known to be under-coded as a diagnosis, yet
problematic opioid use can be documented in clinical notes.
</p>
<p>Objectives: Our goals were 1) to identify problematic opioid use from a full
range of clinical notes; and 2) to compare the characteristics of patients
identified as having problematic opioid use, exclusively documented in clinical
notes, to those having documented ICD opioid use disorder diagnostic codes.
</p>
<p>Materials and Methods: We developed and applied a natural language processing
(NLP) tool to the clinical notes of a patient cohort (n=222,371) from two
Veteran Affairs service regions to identify patients with problematic opioid
use. We also used a set of ICD diagnostic codes to identify patients with
opioid use disorder from the same cohort. We compared the demographic and
clinical characteristics of patients identified only through NLP, to those of
patients identified through ICD codes.
</p>
<p>Results: NLP exclusively identified 57,331 patients; 6,997 patients had
positive ICD code identifications. Patients exclusively identified through NLP
were more likely to be women. Those identified through ICD codes were more
likely to be male, younger, have concurrent benzodiazepine prescriptions, more
comorbidities, more care encounters, and less likely to be married. Patients in
the NLP and ICD groups had substantially elevated comorbidity levels compared
to patients not documented as experiencing problematic opioid use.
</p>
<p>Conclusions: NLP is a feasible approach for identifying problematic opioid
use not otherwise recorded by ICD codes. Clinicians may be reluctant to code
for opioid use disorder. It is therefore incumbent on the healthcare team to
search for documentation of opioid concerns within clinical notes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12999">Quantum-Inspired Machine Learning for Molecular Docking. (arXiv:2401.12999v1 [physics.chem-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Shu_R/0/1/0/all/0/1">Runqiu Shu</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_B/0/1/0/all/0/1">Bowen Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Xiong_Z/0/1/0/all/0/1">Zhaoping Xiong</a>, <a href="http://arxiv.org/find/physics/1/au:+Cui_X/0/1/0/all/0/1">Xiaopeng Cui</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_Y/0/1/0/all/0/1">Yunting Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Cui_W/0/1/0/all/0/1">Wei Cui</a>, <a href="http://arxiv.org/find/physics/1/au:+Yung_M/0/1/0/all/0/1">Man-Hong Yung</a>, <a href="http://arxiv.org/find/physics/1/au:+Qiao_N/0/1/0/all/0/1">Nan Qiao</a></p>
<p>Molecular docking is an important tool for structure-based drug design,
accelerating the efficiency of drug development. Complex and dynamic binding
processes between proteins and small molecules require searching and sampling
over a wide spatial range. Traditional docking by searching for possible
binding sites and conformations is computationally complex and results poorly
under blind docking. Quantum-inspired algorithms combining quantum properties
and annealing show great advantages in solving combinatorial optimization
problems. Inspired by this, we achieve an improved in blind docking by using
quantum-inspired combined with gradients learned by deep learning in the
encoded molecular space. Numerical simulation shows that our method outperforms
traditional docking algorithms and deep learning-based algorithms over 10\%.
Compared to the current state-of-the-art deep learning-based docking algorithm
DiffDock, the success rate of Top-1 (RMSD&lt;2) achieves an improvement from 33\%
to 35\% in our same setup. In particular, a 6\% improvement is realized in the
high-precision region(RMSD&lt;1) on molecules data unseen in DiffDock, which
demonstrates the well-generalized of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13001">PatternPortrait: Draw Me Like One of Your Scribbles. (arXiv:2401.13001v1 [cs.GR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wieluch_S/0/1/0/all/0/1">Sabine Wieluch</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwenker_F/0/1/0/all/0/1">Friedhelm Schwenker</a></p>
<p>This paper introduces a process for generating abstract portrait drawings
from pictures. Their unique style is created by utilizing single freehand
pattern sketches as references to generate unique patterns for shading. The
method involves extracting facial and body features from images and
transforming them into vector lines. A key aspect of the research is the
development of a graph neural network architecture designed to learn sketch
stroke representations in vector form, enabling the generation of diverse
stroke variations. The combination of these two approaches creates joyful
abstract drawings that are realized via a pen plotter. The presented process
garnered positive feedback from an audience of approximately 280 participants.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13006">CIMGEN: Controlled Image Manipulation by Finetuning Pretrained Generative Models on Limited Data. (arXiv:2401.13006v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gudavalli_C/0/1/0/all/0/1">Chandrakanth Gudavalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosten_E/0/1/0/all/0/1">Erik Rosten</a>, <a href="http://arxiv.org/find/cs/1/au:+Nataraj_L/0/1/0/all/0/1">Lakshmanan Nataraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_S/0/1/0/all/0/1">Shivkumar Chandrasekaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Manjunath_B/0/1/0/all/0/1">B. S. Manjunath</a></p>
<p>Content creation and image editing can benefit from flexible user controls. A
common intermediate representation for conditional image generation is a
semantic map, that has information of objects present in the image. When
compared to raw RGB pixels, the modification of semantic map is much easier.
One can take a semantic map and easily modify the map to selectively insert,
remove, or replace objects in the map. The method proposed in this paper takes
in the modified semantic map and alter the original image in accordance to the
modified map. The method leverages traditional pre-trained image-to-image
translation GANs, such as CycleGAN or Pix2Pix GAN, that are fine-tuned on a
limited dataset of reference images associated with the semantic maps. We
discuss the qualitative and quantitative performance of our technique to
illustrate its capacity and possible applications in the fields of image
forgery and image editing. We also demonstrate the effectiveness of the
proposed image forgery technique in thwarting the numerous deep learning-based
image forensic techniques, highlighting the urgent need to develop robust and
generalizable image forensic tools in the fight against the spread of fake
media.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13009">Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders. (arXiv:2401.13009v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lorbeer_B/0/1/0/all/0/1">Boris Lorbeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohsen_M/0/1/0/all/0/1">Mustafa Mohsen</a></p>
<p>Nowadays, the need for causal discovery is ubiquitous. A better understanding
of not just the stochastic dependencies between parts of a system, but also the
actual cause-effect relations, is essential for all parts of science. Thus, the
need for reliable methods to detect causal directions is growing constantly. In
the last 50 years, many causal discovery algorithms have emerged, but most of
them are applicable only under the assumption that the systems have no feedback
loops and that they are causally sufficient, i.e. that there are no unmeasured
subsystems that can affect multiple measured variables. This is unfortunate
since those restrictions can often not be presumed in practice. Feedback is an
integral feature of many processes, and real-world systems are rarely
completely isolated and fully measured. Fortunately, in recent years, several
techniques, that can cope with cyclic, causally insufficient systems, have been
developed. And with multiple methods available, a practical application of
those algorithms now requires knowledge of the respective strengths and
weaknesses. Here, we focus on the problem of causal discovery for sparse linear
models which are allowed to have cycles and hidden confounders. We have
prepared a comprehensive and thorough comparative study of four causal
discovery techniques: two versions of the LLC method [10] and two variants of
the ASP-based algorithm [11]. The evaluation investigates the performance of
those techniques for various experiments with multiple interventional setups
and different dataset sizes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13020">A Safe Reinforcement Learning Algorithm for Supervisory Control of Power Plants. (arXiv:2401.13020v1 [cs.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yixuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Khairy_S/0/1/0/all/0/1">Sami Khairy</a>, <a href="http://arxiv.org/find/cs/1/au:+Vilim_R/0/1/0/all/0/1">Richard B. Vilim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Rui Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1">Akshay J. Dave</a></p>
<p>Traditional control theory-based methods require tailored engineering for
each system and constant fine-tuning. In power plant control, one often needs
to obtain a precise representation of the system dynamics and carefully design
the control scheme accordingly. Model-free Reinforcement learning (RL) has
emerged as a promising solution for control tasks due to its ability to learn
from trial-and-error interactions with the environment. It eliminates the need
for explicitly modeling the environment's dynamics, which is potentially
inaccurate. However, the direct imposition of state constraints in power plant
control raises challenges for standard RL methods. To address this, we propose
a chance-constrained RL algorithm based on Proximal Policy Optimization for
supervisory control. Our method employs Lagrangian relaxation to convert the
constrained optimization problem into an unconstrained objective, where
trainable Lagrange multipliers enforce the state constraints. Our approach
achieves the smallest distance of violation and violation rate in a load-follow
maneuver for an advanced Nuclear Power Plant design.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13034">Locality Sensitive Sparse Encoding for Learning World Models Online. (arXiv:2401.13034v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zichen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1">Chao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wee Sun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Min Lin</a></p>
<p>Acquiring an accurate world model online for model-based reinforcement
learning (MBRL) is challenging due to data nonstationarity, which typically
causes catastrophic forgetting for neural networks (NNs). From the online
learning perspective, a Follow-The-Leader (FTL) world model is desirable, which
optimally fits all previous experiences at each round. Unfortunately, NN-based
models need re-training on all accumulated data at every interaction step to
achieve FTL, which is computationally expensive for lifelong agents. In this
paper, we revisit models that can achieve FTL with incremental updates.
Specifically, our world model is a linear regression model supported by
nonlinear random features. The linear part ensures efficient FTL update while
the nonlinear random feature empowers the fitting of complex environments. To
best trade off model capacity and computation efficiency, we introduce a
locality sensitive sparse encoding, which allows us to conduct efficient sparse
updates even with very high dimensional nonlinear features. We validate the
representation power of our encoding and verify that it allows efficient online
learning under data covariate shift. We also show, in the Dyna MBRL setting,
that our world models learned online using a single pass of trajectory data
either surpass or match the performance of deep world models trained with
replay and other continual learning methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13045">Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?. (arXiv:2401.13045v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Edelstein_R/0/1/0/all/0/1">Rachel Edelstein</a>, <a href="http://arxiv.org/find/stat/1/au:+Gutterman_S/0/1/0/all/0/1">Sterling Gutterman</a>, <a href="http://arxiv.org/find/stat/1/au:+Newman_B/0/1/0/all/0/1">Benjamin Newman</a>, <a href="http://arxiv.org/find/stat/1/au:+Horn_J/0/1/0/all/0/1">John Darrell Van Horn</a></p>
<p>Over the past decade, the intricacies of sports-related concussions among
female athletes have become readily apparent. Traditional clinical methods for
diagnosing concussions suffer limitations when applied to female athletes,
often failing to capture subtle changes in brain structure and function.
Advanced neuroinformatics techniques and machine learning models have become
invaluable assets in this endeavor. While these technologies have been
extensively employed in understanding concussion in male athletes, there
remains a significant gap in our comprehension of their effectiveness for
female athletes. With its remarkable data analysis capacity, machine learning
offers a promising avenue to bridge this deficit. By harnessing the power of
machine learning, researchers can link observed phenotypic neuroimaging data to
sex-specific biological mechanisms, unraveling the mysteries of concussions in
female athletes. Furthermore, embedding methods within machine learning enable
examining brain architecture and its alterations beyond the conventional
anatomical reference frame. In turn, allows researchers to gain deeper insights
into the dynamics of concussions, treatment responses, and recovery processes.
To guarantee that female athletes receive the optimal care they deserve,
researchers must employ advanced neuroimaging techniques and sophisticated
machine-learning models. These tools enable an in-depth investigation of the
underlying mechanisms responsible for concussion symptoms stemming from
neuronal dysfunction in female athletes. This paper endeavors to address the
crucial issue of sex differences in multimodal neuroimaging experimental design
and machine learning approaches within female athlete populations, ultimately
ensuring that they receive the tailored care they require when facing the
challenges of concussions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13049">CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention. (arXiv:2401.13049v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Imran_M/0/1/0/all/0/1">Muhammad Imran</a>, <a href="http://arxiv.org/find/eess/1/au:+Krebs_J/0/1/0/all/0/1">Jonathan R Krebs</a>, <a href="http://arxiv.org/find/eess/1/au:+Gopu_V/0/1/0/all/0/1">Veera Rajasekhar Reddy Gopu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fazzone_B/0/1/0/all/0/1">Brian Fazzone</a>, <a href="http://arxiv.org/find/eess/1/au:+Sivaraman_V/0/1/0/all/0/1">Vishal Balaji Sivaraman</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Amarjeet Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Viscardi_C/0/1/0/all/0/1">Chelsea Viscardi</a>, <a href="http://arxiv.org/find/eess/1/au:+Heithaus_R/0/1/0/all/0/1">Robert Evans Heithaus</a>, <a href="http://arxiv.org/find/eess/1/au:+Shickel_B/0/1/0/all/0/1">Benjamin Shickel</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Cooper_M/0/1/0/all/0/1">Michol A Cooper</a>, <a href="http://arxiv.org/find/eess/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a></p>
<p>Advancements in medical imaging and endovascular grafting have facilitated
minimally invasive treatments for aortic diseases. Accurate 3D segmentation of
the aorta and its branches is crucial for interventions, as inaccurate
segmentation can lead to erroneous surgical planning and endograft
construction. Previous methods simplified aortic segmentation as a binary image
segmentation problem, overlooking the necessity of distinguishing between
individual aortic branches. In this paper, we introduce Context Infused
Swin-UNet (CIS-UNet), a deep learning model designed for multi-class
segmentation of the aorta and thirteen aortic branches. Combining the strengths
of Convolutional Neural Networks (CNNs) and Swin transformers, CIS-UNet adopts
a hierarchical encoder-decoder structure comprising a CNN encoder, symmetric
decoder, skip connections, and a novel Context-aware Shifted Window
Self-Attention (CSW-SA) as the bottleneck block. Notably, CSW-SA introduces a
unique utilization of the patch merging layer, distinct from conventional Swin
transformers. It efficiently condenses the feature map, providing a global
spatial context and enhancing performance when applied at the bottleneck layer,
offering superior computational efficiency and segmentation accuracy compared
to the Swin transformers. We trained our model on computed tomography (CT)
scans from 44 patients and tested it on 15 patients. CIS-UNet outperformed the
state-of-the-art SwinUNetR segmentation model, which is solely based on Swin
transformers, by achieving a superior mean Dice coefficient of 0.713 compared
to 0.697, and a mean surface distance of 2.78 mm compared to 3.39 mm.
CIS-UNet's superior 3D aortic segmentation offers improved precision and
optimization for planning endovascular treatments. Our dataset and code will be
publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13054">Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs. (arXiv:2401.13054v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1">Enzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fadlallah_B/0/1/0/all/0/1">Bilal Fadlallah</a></p>
<p>A hypergraph is a generalization of a graph that arises naturally when
attribute-sharing among entities is considered. Although a hypergraph can be
converted into a graph by expanding its hyperedges into fully connected
subgraphs, going the reverse way is computationally complex and NP-complete. We
therefore hypothesize that a hypergraph contains more information than a graph.
In addition, it is more convenient to manipulate a hypergraph directly, rather
than expand it into a graph. An open problem in hypergraphs is how to
accurately and efficiently calculate their node distances. Estimating node
distances enables us to find a node's nearest neighbors, and perform label
propagation on hypergraphs using a K-nearest neighbors (KNN) approach. In this
paper, we propose a novel approach based on random walks to achieve label
propagation on hypergraphs. We estimate node distances as the expected hitting
times of random walks. We note that simple random walks (SRW) cannot accurately
describe highly complex real-world hypergraphs, which motivates us to introduce
frustrated random walks (FRW) to better describe them. We further benchmark our
method against DeepWalk, and show that while the latter can achieve comparable
results, FRW has a distinct computational advantage in cases where the number
of targets is fairly small. For such cases, we show that FRW runs in
significantly shorter time than DeepWalk. Finally, we analyze the time
complexity of our method, and show that for large and sparse hypergraphs, the
complexity is approximately linear, rendering it superior to the DeepWalk
alternative.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13085">IndiText Boost: Text Augmentation for Low Resource India Languages. (arXiv:2401.13085v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Litake_O/0/1/0/all/0/1">Onkar Litake</a>, <a href="http://arxiv.org/find/cs/1/au:+Yagnik_N/0/1/0/all/0/1">Niraj Yagnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Labhsetwar_S/0/1/0/all/0/1">Shreyas Labhsetwar</a></p>
<p>Text Augmentation is an important task for low-resource languages. It helps
deal with the problem of data scarcity. A data augmentation strategy is used to
deal with the problem of data scarcity. Through the years, much work has been
done on data augmentation for the English language. In contrast, very less work
has been done on Indian languages. This is contrary to the fact that data
augmentation is used to deal with data scarcity. In this work, we focus on
implementing techniques like Easy Data Augmentation, Back Translation,
Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for
text classification on different languages. We focus on 6 Indian languages
namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to
our knowledge, no such work exists for text augmentation on Indian languages.
We carry out binary as well as multi-class text classification to make our
results more comparable. We get surprising results as basic data augmentation
techniques surpass LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13086">Towards Trustable Language Models: Investigating Information Quality of Large Language Models. (arXiv:2401.13086v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rejeleene_R/0/1/0/all/0/1">Rick Rejeleene</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaowei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Talburt_J/0/1/0/all/0/1">John Talburt</a></p>
<p>Large language models (LLM) are generating information at a rapid pace,
requiring users to increasingly rely and trust the data. Despite remarkable
advances of LLM, Information generated by LLM is not completely trustworthy,
due to challenges in information quality. Specifically, integrity of
Information quality decreases due to unreliable, biased, tokenization during
pre-training of LLM. Moreover, due to decreased information quality issues, has
led towards hallucination, fabricated information. Unreliable information can
lead towards flawed decisions in businesses, which impacts economic activity.
In this work, we introduce novel mathematical information quality evaluation of
LLM, we furthermore analyze and highlight information quality challenges,
scaling laws to systematically scale language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13096">Probabilistic Demand Forecasting with Graph Neural Networks. (arXiv:2401.13096v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kozodoi_N/0/1/0/all/0/1">Nikita Kozodoi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zinovyeva_E/0/1/0/all/0/1">Elizaveta Zinovyeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Valentin_S/0/1/0/all/0/1">Simon Valentin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_J/0/1/0/all/0/1">Jo&#xe3;o Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Agundez_R/0/1/0/all/0/1">Rodrigo Agundez</a></p>
<p>Demand forecasting is a prominent business use case that allows retailers to
optimize inventory planning, logistics, and core business decisions. One of the
key challenges in demand forecasting is accounting for relationships and
interactions between articles. Most modern forecasting approaches provide
independent article-level predictions that do not consider the impact of
related articles. Recent research has attempted addressing this challenge using
Graph Neural Networks (GNNs) and showed promising results. This paper builds on
previous research on GNNs and makes two contributions. First, we integrate a
GNN encoder into a state-of-the-art DeepAR model. The combined model produces
probabilistic forecasts, which are crucial for decision-making under
uncertainty. Second, we propose to build graphs using article attribute
similarity, which avoids reliance on a pre-defined graph structure. Experiments
on three real-world datasets show that the proposed approach consistently
outperforms non-graph benchmarks. We also show that our approach produces
article embeddings that encode article similarity and demand dynamics and are
useful for other downstream business tasks beyond forecasting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13098">Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge. (arXiv:2401.13098v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Ruixin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Spadon_G/0/1/0/all/0/1">Gabriel Spadon</a>, <a href="http://arxiv.org/find/cs/1/au:+Bailey_S/0/1/0/all/0/1">Sarah Bailey</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelot_R/0/1/0/all/0/1">Ronald Pelot</a>, <a href="http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1">Stan Matwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_A/0/1/0/all/0/1">Amilcar Soares</a></p>
<p>Invasive species in water bodies pose a major threat to the environment and
biodiversity globally. Due to increased transportation and trade, non-native
species have been introduced to new environments, causing damage to ecosystems
and leading to economic losses in agriculture, forestry, and fisheries.
Therefore, there is a pressing need for risk assessment and management
techniques to mitigate the impact of these invasions. This study aims to
develop a new physics-inspired model to forecast maritime shipping traffic and
thus inform risk assessment of invasive species spread through global
transportation networks. Inspired by the gravity model for international
trades, our model considers various factors that influence the likelihood and
impact of vessel activities, such as shipping flux density, distance between
ports, trade flow, and centrality measures of transportation hubs.
Additionally, by analyzing the risk network of invasive species, we provide a
comprehensive framework for assessing the invasion threat level given a pair of
origin and destination. Accordingly, this paper introduces transformers to
gravity models to rebuild the short- and long-term dependencies that make the
risk analysis feasible. Thus, we introduce a physics-inspired framework that
achieves an 89% segmentation accuracy for existing and non-existing
trajectories and an 84.8% accuracy for the number of vessels flowing between
key port areas, representing more than 10% improvement over the traditional
deep-gravity model. Along these lines, this research contributes to a better
understanding of invasive species risk assessment. It allows policymakers,
conservationists, and stakeholders to prioritize management actions by
identifying high-risk invasion pathways. Besides, our model is versatile and
can include new data sources, making it suitable for assessing species invasion
risks in a changing global landscape.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13099">Sparse identification of nonlinear dynamics in the presence of library and system uncertainty. (arXiv:2401.13099v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+OBrien_A/0/1/0/all/0/1">Andrew O&#x27;Brien</a></p>
<p>The SINDy algorithm has been successfully used to identify the governing
equations of dynamical systems from time series data. However, SINDy assumes
the user has prior knowledge of the variables in the system and of a function
library that can act as a basis for the system. In this paper, we demonstrate
on real world data how the Augmented SINDy algorithm outperforms SINDy in the
presence of system variable uncertainty. We then show SINDy can be further
augmented to perform robustly when both kinds of uncertainty are present.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13115">Contractive Diffusion Probabilistic Models. (arXiv:2401.13115v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1">Wenpin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hanyang Zhao</a></p>
<p>Diffusion probabilistic models (DPMs) have emerged as a promising technology
in generative modeling. The success of DPMs relies on two ingredients: time
reversal of Markov diffusion processes and score matching. Most existing work
implicitly assumes that score matching is close to perfect, while this
assumption is questionable. In view of possibly unguaranteed score matching, we
propose a new criterion -- the contraction of backward sampling in the design
of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including
contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance
preserving (sub-VP) stochastic differential equations (SDEs). The key insight
is that the contraction in the backward process narrows score matching errors,
as well as discretization error. Thus, the proposed CDPMs are robust to both
sources of error. Our proposal is supported by theoretical results, and is
corroborated by experiments. Notably, contractive sub-VP shows the best
performance among all known SDE-based DPMs on the CIFAR-10 dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13148">NLBAC: A Neural Ordinary Differential Equations-based Framework for Stable and Safe Reinforcement Learning. (arXiv:2401.13148v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liqun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_K/0/1/0/all/0/1">Keyan Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatsis_K/0/1/0/all/0/1">Konstantinos Gatsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Papachristodoulou_A/0/1/0/all/0/1">Antonis Papachristodoulou</a></p>
<p>Reinforcement learning (RL) excels in applications such as video games and
robotics, but ensuring safety and stability remains challenging when using RL
to control real-world systems where using model-free algorithms suffering from
low sample efficiency might be prohibitive. This paper first provides safety
and stability definitions for the RL system, and then introduces a Neural
ordinary differential equations-based Lyapunov-Barrier Actor-Critic (NLBAC)
framework that leverages Neural Ordinary Differential Equations (NODEs) to
approximate system dynamics and integrates the Control Barrier Function (CBF)
and Control Lyapunov Function (CLF) frameworks with the actor-critic method to
assist in maintaining the safety and stability for the system. Within this
framework, we employ the augmented Lagrangian method to update the RL-based
controller parameters. Additionally, we introduce an extra backup controller in
situations where CBF constraints for safety and the CLF constraint for
stability cannot be satisfied simultaneously. Simulation results demonstrate
that the framework leads the system to approach the desired state and allows
fewer violations of safety constraints with better sample efficiency compared
to other methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13157">Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence. (arXiv:2401.13157v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Coskunuzer_B/0/1/0/all/0/1">Baris Coskunuzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Segovia_Dominguez_I/0/1/0/all/0/1">Ignacio Segovia-Dominguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuzhou Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gel_Y/0/1/0/all/0/1">Yulia R. Gel</a></p>
<p>Learning time-evolving objects such as multivariate time series and dynamic
networks requires the development of novel knowledge representation mechanisms
and neural network architectures, which allow for capturing implicit
time-dependent information contained in the data. Such information is typically
not directly observed but plays a key role in the learning task performance. In
turn, lack of time dimension in knowledge encoding mechanisms for
time-dependent data leads to frequent model updates, poor learning performance,
and, as a result, subpar decision-making. Here we propose a new approach to a
time-aware knowledge representation mechanism that notably focuses on implicit
time-dependent topological information along multiple geometric dimensions. In
particular, we propose a new approach, named \textit{Temporal MultiPersistence}
(TMP), which produces multidimensional topological fingerprints of the data by
using the existing single parameter topological summaries. The main idea behind
TMP is to merge the two newest directions in topological representation
learning, that is, multi-persistence which simultaneously describes data shape
evolution along multiple key parameters, and zigzag persistence to enable us to
extract the most salient data shape information over time. We derive
theoretical guarantees of TMP vectorizations and show its utility, in
application to forecasting on benchmark traffic flow, Ethereum blockchain, and
electrocardiogram datasets, demonstrating the competitive performance,
especially, in scenarios of limited data records. In addition, our TMP method
improves the computational efficiency of the state-of-the-art multipersistence
summaries up to 59.5 times.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13160">SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection. (arXiv:2401.13160v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1">Ke Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Heinrich Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1">Afshin Rostamizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Ayan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+DeSalvo_G/0/1/0/all/0/1">Giulia DeSalvo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kagy_J/0/1/0/all/0/1">Jean-Fran&#xe7;ois Kagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Karydas_L/0/1/0/all/0/1">Lazaros Karydas</a>, <a href="http://arxiv.org/find/cs/1/au:+Citovsky_G/0/1/0/all/0/1">Gui Citovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a></p>
<p>Pre-training large language models is known to be extremely resource
intensive and often times inefficient, under-utilizing the information
encapsulated in the training text sequences. In this paper, we present SpacTor,
a new training procedure consisting of (1) a hybrid objective combining span
corruption (SC) and token replacement detection (RTD), and (2) a two-stage
curriculum that optimizes the hybrid objective over the initial $\tau$
iterations, then transitions to standard SC loss. We show empirically that the
effectiveness of the hybrid objective is tied to the two-stage pre-training
schedule, and provide extensive analysis on why this is the case. In our
experiments with encoder-decoder architectures (T5) on a variety of NLP tasks,
SpacTor-T5 yields the same downstream performance as standard SC pre-training,
while enabling a 50% reduction in pre-training iterations and 40% reduction in
total FLOPs. Alternatively, given the same amount of computing budget, we find
that SpacTor results in significantly improved downstream benchmark
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13171">Compositional Generative Inverse Design. (arXiv:2401.13171v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tailin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruyama_T/0/1/0/all/0/1">Takashi Maruyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Long Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yilun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Iaccarino_G/0/1/0/all/0/1">Gianluca Iaccarino</a>, <a href="http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1">Jure Leskovec</a></p>
<p>Inverse design, where we seek to design input variables in order to optimize
an underlying objective function, is an important problem that arises across
fields such as mechanical engineering to aerospace engineering. Inverse design
is typically formulated as an optimization problem, with recent works
leveraging optimization across learned dynamics models. However, as models are
optimized they tend to fall into adversarial modes, preventing effective
sampling. We illustrate that by instead optimizing over the learned energy
function captured by the diffusion model, we can avoid such adversarial
examples and significantly improve design performance. We further illustrate
how such a design system is compositional, enabling us to combine multiple
different diffusion models representing subcomponents of our desired system to
design systems with every specified component. In an N-body interaction task
and a challenging 2D multi-airfoil design task, we demonstrate that by
composing the learned diffusion model at test time, our method allows us to
design initial states and boundary shapes that are more complex than those in
the training data. Our method outperforms state-of-the-art neural inverse
design method by an average of 41.5% in prediction MAE and 14.3% in design
objective for the N-body dataset and discovers formation flying to minimize
drag in the multi-airfoil design task. Project website and code can be found at
https://github.com/AI4Science-WestlakeU/cindm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13177">Deep Learning Model Reuse in the HuggingFace Community: Challenges, Benefit and Trends. (arXiv:2401.13177v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Taraghi_M/0/1/0/all/0/1">Mina Taraghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorcelus_G/0/1/0/all/0/1">Gianolli Dorcelus</a>, <a href="http://arxiv.org/find/cs/1/au:+Foundjem_A/0/1/0/all/0/1">Armstrong Foundjem</a>, <a href="http://arxiv.org/find/cs/1/au:+Tambon_F/0/1/0/all/0/1">Florian Tambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a></p>
<p>The ubiquity of large-scale Pre-Trained Models (PTMs) is on the rise,
sparking interest in model hubs, and dedicated platforms for hosting PTMs.
Despite this trend, a comprehensive exploration of the challenges that users
encounter and how the community leverages PTMs remains lacking. To address this
gap, we conducted an extensive mixed-methods empirical study by focusing on
discussion forums and the model hub of HuggingFace, the largest public model
hub. Based on our qualitative analysis, we present a taxonomy of the challenges
and benefits associated with PTM reuse within this community. We then conduct a
quantitative study to track model-type trends and model documentation evolution
over time. Our findings highlight prevalent challenges such as limited guidance
for beginner users, struggles with model output comprehensibility in training
or inference, and a lack of model understanding. We also identified interesting
trends among models where some models maintain high upload rates despite a
decline in topics related to them. Additionally, we found that despite the
introduction of model documentation tools, its quantity has not increased over
time, leading to difficulties in model comprehension and selection among users.
Our study sheds light on new challenges in reusing PTMs that were not reported
before and we provide recommendations for various stakeholders involved in PTM
reuse.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13178">AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents. (arXiv:2401.13178v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junlei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yujiu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yaohui Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1">Zhenzhong Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1">Lingpeng Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Junxian He</a></p>
<p>Evaluating large language models (LLMs) as general-purpose agents is
essential for understanding their capabilities and facilitating their
integration into practical applications. However, the evaluation process
presents substantial challenges. A primary obstacle is the benchmarking of
agent performance across diverse scenarios within a unified framework,
especially in maintaining partially-observable environments and ensuring
multi-round interactions. Moreover, current evaluation frameworks mostly focus
on the final success rate, revealing few insights during the process and
failing to provide a deep understanding of the model abilities. To address
these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark
and accompanied open-source evaluation framework tailored to analytical
evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric
that captures incremental advancements as well as a comprehensive evaluation
toolkit that features easy assessment of agents for multi-faceted analysis
through interactive visualization. This not only sheds light on the
capabilities and limitations of LLM agents but also propels the
interpretability of their performance to the forefront. Ultimately, AgentBoard
serves as a significant step towards demystifying agent behaviors and
accelerating the development of stronger LLM agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13185">Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments. (arXiv:2401.13185v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Engstrom_O/0/1/0/all/0/1">Ole-Christian Galbo Engstr&#xf8;m</a></p>
<p>Cross-validation is a widely used technique for assessing the performance of
predictive models on unseen data. Many predictive models, such as Kernel-Based
Partial Least-Squares (PLS) models, require the computation of
$\mathbf{X}^{\mathbf{T}}\mathbf{X}$ and $\mathbf{X}^{\mathbf{T}}\mathbf{Y}$
using only training set samples from the input and output matrices,
$\mathbf{X}$ and $\mathbf{Y}$, respectively. In this work, we present three
algorithms that efficiently compute these matrices. The first one allows no
column-wise preprocessing. The second one allows column-wise centering around
the training set means. The third one allows column-wise centering and
column-wise scaling around the training set means and standard deviations.
Demonstrating correctness and superior computational complexity, they offer
significant cross-validation speedup compared with straight-forward
cross-validation and previous work on fast cross-validation - all without data
leakage. Their suitability for parallelization is highlighted with an
open-source Python implementation combining our algorithms with Improved Kernel
PLS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13192">Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model. (arXiv:2401.13192v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhelin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mrad_R/0/1/0/all/0/1">Rami Mrad</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_R/0/1/0/all/0/1">Runxian Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_J/0/1/0/all/0/1">Jun Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_S/0/1/0/all/0/1">Shibing Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuanping Chen</a></p>
<p>Efficiently generating energetically stable crystal structures has long been
a challenge in material design, primarily due to the immense arrangement of
atoms in a crystal lattice. To facilitate the discovery of stable material, we
present a framework for the generation of synthesizable materials, leveraging a
point cloud representation to encode intricate structural information. At the
heart of this framework lies the introduction of a diffusion model as its
foundational pillar. To gauge the efficacy of our approach, we employ it to
reconstruct input structures from our training datasets, rigorously validating
its high reconstruction performance. Furthermore, we demonstrate the profound
potential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely
new materials, emphasizing their synthesizability. Our research stands as a
noteworthy contribution to the advancement of materials design and synthesis
through the cutting-edge avenue of generative design instead of the
conventional substitution or experience-based discovery.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13200">Topology-aware Embedding Memory for Learning on Expanding Graphs. (arXiv:2401.13200v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xikun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dongjin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yixin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a></p>
<p>Memory replay based techniques have shown great success for continual
learning with incrementally accumulated Euclidean data. Directly applying them
to continually expanding graphs, however, leads to the potential memory
explosion problem due to the need to buffer representative nodes and their
associated topological neighborhood structures. To this end, we systematically
analyze the key challenges in the memory explosion problem, and present a
general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs)
with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed
framework not only reduces the memory space complexity from $\mathcal{O}(nd^L)$
to $\mathcal{O}(n)$~\footnote{$n$: memory budget, $d$: average node degree,
$L$: the radius of the GNN receptive field}, but also fully utilizes the
topological information for memory replay. Specifically, PDGNNs decouple
trainable parameters from the computation ego-subgraph via
\textit{Topology-aware Embeddings} (TEs), which compress ego-subgraphs into
compact vectors (i.e., TEs) to reduce the memory consumption. Based on this
framework, we discover a unique \textit{pseudo-training effect} in continual
learning on expanding graphs and this effect motivates us to develop a novel
\textit{coverage maximization sampling} strategy that can enhance the
performance with a tight memory budget. Thorough empirical studies demonstrate
that, by tackling the memory explosion problem and incorporating topological
information into memory replay, PDGNNs with TEM significantly outperform
state-of-the-art techniques, especially in the challenging class-incremental
setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13206">Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification. (arXiv:2401.13206v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyun-Suk Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Do-Yup Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_K/0/1/0/all/0/1">Kyungsik Min</a></p>
<p>This paper presents a groundbreaking self-improving interference management
framework tailored for wireless communications, integrating deep learning with
uncertainty quantification to enhance overall system performance. Our approach
addresses the computational challenges inherent in traditional
optimization-based algorithms by harnessing deep learning models to predict
optimal interference management solutions. A significant breakthrough of our
framework is its acknowledgment of the limitations inherent in data-driven
models, particularly in scenarios not adequately represented by the training
dataset. To overcome these challenges, we propose a method for uncertainty
quantification, accompanied by a qualifying criterion, to assess the
trustworthiness of model predictions. This framework strategically alternates
between model-generated solutions and traditional algorithms, guided by a
criterion that assesses the prediction credibility based on quantified
uncertainties. Experimental results validate the framework's efficacy,
demonstrating its superiority over traditional deep learning models, notably in
scenarios underrepresented in the training dataset. This work marks a
pioneering endeavor in harnessing self-improving deep learning for interference
management, through the lens of uncertainty quantification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13210">Multitask Active Learning for Graph Anomaly Detection. (arXiv:2401.13210v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1">Wenjing Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kay Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kaize Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jianjun Yu</a></p>
<p>In the web era, graph machine learning has been widely used on ubiquitous
graph-structured data. As a pivotal component for bolstering web security and
enhancing the robustness of graph-based applications, the significance of graph
anomaly detection is continually increasing. While Graph Neural Networks (GNNs)
have demonstrated efficacy in supervised and semi-supervised graph anomaly
detection, their performance is contingent upon the availability of sufficient
ground truth labels. The labor-intensive nature of identifying anomalies from
complex graph structures poses a significant challenge in real-world
applications. Despite that, the indirect supervision signals from other tasks
(e.g., node classification) are relatively abundant. In this paper, we propose
a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE.
Firstly, by coupling node classification tasks, MITIGATE obtains the capability
to detect out-of-distribution nodes without known anomalies. Secondly, MITIGATE
quantifies the informativeness of nodes by the confidence difference across
tasks, allowing samples with conflicting predictions to provide informative yet
not excessively challenging information for subsequent training. Finally, to
enhance the likelihood of selecting representative nodes that are distant from
known patterns, MITIGATE adopts a masked aggregation mechanism for distance
measurement, considering both inherent features of nodes and current labeled
status. Empirical studies on four datasets demonstrate that MITIGATE
significantly outperforms the state-of-the-art methods for anomaly detection.
Our code is publicly available at: https://github.com/AhaChang/MITIGATE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13212">AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation. (arXiv:2401.13212v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Lulan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Edalati_A/0/1/0/all/0/1">Ali Edalati</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_B/0/1/0/all/0/1">Brett Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gross_W/0/1/0/all/0/1">Warren Gross</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1">James J. Clark</a></p>
<p>This paper describes a simple yet effective technique for refining a
pretrained classifier network. The proposed AdCorDA method is based on
modification of the training set and making use of the duality between network
weights and layer inputs. We call this input space training. The method
consists of two stages - adversarial correction followed by domain adaptation.
Adversarial correction uses adversarial attacks to correct incorrect
training-set classifications. The incorrectly classified samples of the
training set are removed and replaced with the adversarially corrected samples
to form a new training set, and then, in the second stage, domain adaptation is
performed back to the original training set. Extensive experimental validations
show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The
technique can be straightforwardly applied to refinement of weight-quantized
neural networks, where experiments show substantial enhancement in performance
over the baseline. The adversarial correction technique also results in
enhanced robustness to adversarial attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13214">AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network. (arXiv:2401.13214v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Junkai Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Aihua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhua Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhilong Lin</a></p>
<p>Recently, methods based on deep learning have been successfully applied to
ship detection for synthetic aperture radar (SAR) images. Despite the
development of numerous ship detection methodologies, detecting small and
coastal ships remains a significant challenge due to the limited features and
clutter in coastal environments. For that, a novel adaptive multi-hierarchical
attention module (AMAM) is proposed to learn multi-scale features and
adaptively aggregate salient features from various feature layers, even in
complex environments. Specifically, we first fuse information from adjacent
feature layers to enhance the detection of smaller targets, thereby achieving
multi-scale feature enhancement. Then, to filter out the adverse effects of
complex backgrounds, we dissect the previously fused multi-level features on
the channel, individually excavate the salient regions, and adaptively
amalgamate features originating from different channels. Thirdly, we present a
novel adaptive multi-hierarchical attention network (AMANet) by embedding the
AMAM between the backbone network and the feature pyramid network (FPN).
Besides, the AMAM can be readily inserted between different frameworks to
improve object detection. Lastly, extensive experiments on two large-scale SAR
ship detection datasets demonstrate that our AMANet method is superior to
state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13216">On Principled Local Optimization Methods for Federated Learning. (arXiv:2401.13216v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Honglin Yuan</a></p>
<p>Federated Learning (FL), a distributed learning paradigm that scales
on-device learning collaboratively, has emerged as a promising approach for
decentralized AI applications. Local optimization methods such as Federated
Averaging (FedAvg) are the most prominent methods for FL applications. Despite
their simplicity and popularity, the theoretical understanding of local
optimization methods is far from clear. This dissertation aims to advance the
theoretical foundation of local methods in the following three directions.
</p>
<p>First, we establish sharp bounds for FedAvg, the most popular algorithm in
Federated Learning. We demonstrate how FedAvg may suffer from a notion we call
iterate bias, and how an additional third-order smoothness assumption may
mitigate this effect and lead to better convergence rates. We explain this
phenomenon from a Stochastic Differential Equation (SDE) perspective.
</p>
<p>Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc),
the first principled acceleration of FedAvg, which provably improves the
convergence rate and communication efficiency. Our technique uses on a
potential-based perturbed iterate analysis, a novel stability analysis of
generalized accelerated SGD, and a strategic tradeoff between acceleration and
stability.
</p>
<p>Third, we study the Federated Composite Optimization problem, which extends
the classic smooth setting by incorporating a shared non-smooth regularizer. We
show that direct extensions of FedAvg may suffer from the "curse of primal
averaging," resulting in slow convergence. As a solution, we propose a new
primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of
primal averaging by employing a novel inter-client dual averaging procedure.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13219">TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification. (arXiv:2401.13219v1 [q-bio.GN])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Aakur_S/0/1/0/all/0/1">Sathyanarayanan Aakur</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Laguduva_V/0/1/0/all/0/1">Vishalini R. Laguduva</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ramamurthy_P/0/1/0/all/0/1">Priyadharsini Ramamurthy</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ramachandran_A/0/1/0/all/0/1">Akhilesh Ramachandran</a></p>
<p>A species' genetic code or genome encodes valuable evolutionary, biological,
and phylogenetic information that aids in species recognition, taxonomic
classification, and understanding genetic predispositions like drug resistance
and virulence. However, the vast number of potential species poses significant
challenges in developing a general-purpose whole genome classification tool.
Traditional bioinformatics tools have made notable progress but lack
scalability and are computationally expensive. Machine learning-based
frameworks show promise but must address the issue of large classification
vocabularies with long-tail distributions. In this study, we propose addressing
this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding
and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a
taxonomy-aware embedding space for reasoning and classification. This embedding
space captures compositional and phylogenetic relationships of species,
enabling predictions in extensive search spaces. We evaluate TEPI using two
rigorous zero-shot settings and demonstrate its generalization capabilities
qualitatively on curated, large-scale, publicly sourced data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13227">Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models. (arXiv:2401.13227v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1">Baolong Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shenghua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_L/0/1/0/all/0/1">Lingrui Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xueqi Chen</a></p>
<p>Exploring the application of large-scale language models to graph learning is
a novel endeavor. However, the vast amount of information inherent in large
graphs poses significant challenges to this process. This paper focuses on the
link prediction task and introduces LPNL (Link Prediction via Natural
Language), a framework based on a large language model designed for scalable
link prediction on large-scale heterogeneous graphs.We design novel prompts for
link prediction that articulate graph details in natural language. We propose a
two-stage sampling pipeline to extract crucial information from large-scale
heterogeneous graphs, and a divide-and-conquer strategy to control the input
token count within predefined limits, addressing the challenge of overwhelming
information. We fine-tune a T5 model based on our self-supervised learning
designed for for link prediction. Extensive experiments on a large public
heterogeneous graphs demonstrate that LPNL outperforms various advanced
baselines, highlighting its remarkable performance in link prediction tasks on
large-scale graphs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13229">From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning. (arXiv:2401.13229v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alcoforado_A/0/1/0/all/0/1">Alexandre Alcoforado</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraz_T/0/1/0/all/0/1">Thomas Palmeira Ferraz</a>, <a href="http://arxiv.org/find/cs/1/au:+Okamura_L/0/1/0/all/0/1">Lucas Hideki Okamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Fama_I/0/1/0/all/0/1">Israel Campos Fama</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavado_A/0/1/0/all/0/1">Arnold Moya Lavado</a>, <a href="http://arxiv.org/find/cs/1/au:+Bueno_B/0/1/0/all/0/1">B&#xe1;rbara Dias Bueno</a>, <a href="http://arxiv.org/find/cs/1/au:+Veloso_B/0/1/0/all/0/1">Bruno Veloso</a>, <a href="http://arxiv.org/find/cs/1/au:+Costa_A/0/1/0/all/0/1">Anna Helena Reali Costa</a></p>
<p>A major challenge in Natural Language Processing is obtaining annotated data
for supervised learning. An option is the use of crowdsourcing platforms for
data annotation. However, crowdsourcing introduces issues related to the
annotator's experience, consistency, and biases. An alternative is to use
zero-shot methods, which in turn have limitations compared to their few-shot or
fully supervised counterparts. Recent advancements driven by large language
models show potential, but struggle to adapt to specialized domains with
severely limited data. The most common approaches therefore involve the human
itself randomly annotating a set of datapoints to build initial datasets. But
randomly sampling data to be annotated is often inefficient as it ignores the
characteristics of the data and the specific needs of the model. The situation
worsens when working with imbalanced datasets, as random sampling tends to
heavily bias towards the majority classes, leading to excessive annotated data.
To address these issues, this paper contributes an automatic and informed data
selection architecture to build a small dataset for few-shot learning. Our
proposal minimizes the quantity and maximizes diversity of data selected for
human annotation, while improving model performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13236">How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning. (arXiv:2401.13236v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kountouris_M/0/1/0/all/0/1">Marios Kountouris</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a></p>
<p>Federated learning (FL) has attracted vivid attention as a privacy-preserving
distributed learning framework. In this work, we focus on cross-silo FL, where
clients become the model owners after training and are only concerned about the
model's generalization performance on their local data. Due to the data
heterogeneity issue, asking all the clients to join a single FL training
process may result in model performance degradation. To investigate the
effectiveness of collaboration, we first derive a generalization bound for each
client when collaborating with others or when training independently. We show
that the generalization performance of a client can be improved only by
collaborating with other clients that have more training data and similar data
distribution. Our analysis allows us to formulate a client utility maximization
problem by partitioning clients into multiple collaborating groups. A
hierarchical clustering-based collaborative training (HCCT) scheme is then
proposed, which does not need to fix in advance the number of groups. We
further analyze the convergence of HCCT for general non-convex loss functions
which unveils the effect of data similarity among clients. Extensive
simulations show that HCCT achieves better generalization performance than
baseline schemes, whereas it degenerates to independent training and
conventional FL in specific scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13239">Adaptive Crowdsourcing Via Self-Supervised Learning. (arXiv:2401.13239v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kagrecha_A/0/1/0/all/0/1">Anmol Kagrecha</a>, <a href="http://arxiv.org/find/cs/1/au:+Marklund_H/0/1/0/all/0/1">Henrik Marklund</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1">Hong Jun Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeckhauser_R/0/1/0/all/0/1">Richard Zeckhauser</a></p>
<p>Common crowdsourcing systems average estimates of a latent quantity of
interest provided by many crowdworkers to produce a group estimate. We develop
a new approach -- just-predict-others -- that leverages self-supervised
learning and a novel aggregation scheme. This approach adapts weights assigned
to crowdworkers based on estimates they provided for previous quantities. When
skills vary across crowdworkers or their estimates correlate, the weighted sum
offers a more accurate group estimate than the average. Existing algorithms
such as expectation maximization can, at least in principle, produce similarly
accurate group estimates. However, their computational requirements become
onerous when complex models, such as neural networks, are required to express
relationships among crowdworkers. Just-predict-others accommodates such
complexity as well as many other practical challenges. We analyze the efficacy
of just-predict-others through theoretical and computational studies. Among
other things, we establish asymptotic optimality as the number of engagements
per crowdworker grows.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13282">RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing. (arXiv:2401.13282v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Farooq_J/0/1/0/all/0/1">Junaid Farooq</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafiq_D/0/1/0/all/0/1">Danish Rafiq</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachas_P/0/1/0/all/0/1">Pantelis R. Vlachas</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazaz_M/0/1/0/all/0/1">Mohammad Abid Bazaz</a></p>
<p>Forecasting complex system dynamics, particularly for long-term predictions,
is persistently hindered by error accumulation and computational burdens. This
study presents RefreshNet, a multiscale framework developed to overcome these
challenges, delivering an unprecedented balance between computational
efficiency and predictive accuracy. RefreshNet incorporates convolutional
autoencoders to identify a reduced order latent space capturing essential
features of the dynamics, and strategically employs multiple recurrent neural
network (RNN) blocks operating at varying temporal resolutions within the
latent space, thus allowing the capture of latent dynamics at multiple temporal
scales. The unique "refreshing" mechanism in RefreshNet allows coarser blocks
to reset inputs of finer blocks, effectively controlling and alleviating error
accumulation. This design demonstrates superiority over existing techniques
regarding computational efficiency and predictive accuracy, especially in
long-term forecasting. The framework is validated using three benchmark
applications: the FitzHugh-Nagumo system, the Reaction-Diffusion equation, and
Kuramoto-Sivashinsky dynamics. RefreshNet significantly outperforms
state-of-the-art methods in long-term forecasting accuracy and speed, marking a
significant advancement in modeling complex systems and opening new avenues in
understanding and predicting their behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13301">Classification of Radiologically Isolated Syndrome and Clinically Isolated Syndrome with Machine-Learning Techniques. (arXiv:2401.13301v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mato_Abad_V/0/1/0/all/0/1">V Mato-Abad</a>, <a href="http://arxiv.org/find/cs/1/au:+Labiano_Fontcuberta_A/0/1/0/all/0/1">A Labiano-Fontcuberta</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Yanez_S/0/1/0/all/0/1">S Rodriguez-Yanez</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Vazquez_R/0/1/0/all/0/1">R Garcia-Vazquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Munteanu_C/0/1/0/all/0/1">CR Munteanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrade_Garda_J/0/1/0/all/0/1">J Andrade-Garda</a>, <a href="http://arxiv.org/find/cs/1/au:+Domingo_Santos_A/0/1/0/all/0/1">A Domingo-Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_Seco_V/0/1/0/all/0/1">V Galan Sanchez-Seco</a>, <a href="http://arxiv.org/find/cs/1/au:+Aladro_Y/0/1/0/all/0/1">Y Aladro</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_Gines_M/0/1/0/all/0/1">ML Martinez-Gines</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayuso_L/0/1/0/all/0/1">L Ayuso</a>, <a href="http://arxiv.org/find/cs/1/au:+Benito_Leon_J/0/1/0/all/0/1">J Benito-Leon</a></p>
<p>Background and purpose: The unanticipated detection by magnetic resonance
imaging (MRI) in the brain of asymptomatic subjects of white matter lesions
suggestive of multiple sclerosis (MS) has been named radiologically isolated
syndrome (RIS). As the difference between early MS [i.e. clinically isolated
syndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical to
improve detection of the subclinical form without interfering with MRI as there
are radiological diagnostic criteria for that. Our objective was to use
machine-learning classification methods to identify morphometric measures that
help to discriminate patients with RIS from those with CIS.
</p>
<p>Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers
(cortical thickness, cortical and subcortical grey matter volume, and white
matter integrity) of a cohort of 17 patients with RIS and 17 patients with CIS
for single-subject level classification.
</p>
<p>Results: The best proposed models to predict the diagnosis of CIS and RIS
were based on the Naive Bayes, Bagging and Multilayer Perceptron classifiers
using only three features: the left rostral middle frontal gyrus volume and the
fractional anisotropy values in the right amygdala and right lingual gyrus. The
Naive Bayes obtained the highest accuracy [overall classification, 0.765; area
under the receiver operating characteristic (AUROC), 0.782].
</p>
<p>Conclusions: A machine-learning approach applied to multimodal MRI data may
differentiate between the earliest clinical expressions of MS (CIS and RIS)
with an accuracy of 78%.
</p>
<p>Keywords: Bagging; Multilayer Perceptron; Naive Bayes classifier; clinically
isolated syndrome; diffusion tensor imaging; machine-learning; magnetic
resonance imaging; multiple sclerosis; radiologically isolated syndrome.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13311">ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models. (arXiv:2401.13311v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wadhawan_R/0/1/0/all/0/1">Rohan Wadhawan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1">Hritik Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a></p>
<p>Recent advancements in AI have led to the development of large multimodal
models (LMMs) capable of processing complex tasks involving joint reasoning
over text and visual content in the image (e.g., navigating maps in public
places). This paper introduces ConTextual, a novel benchmark comprising
instructions designed explicitly to evaluate LMMs' ability to perform
context-sensitive text-rich visual reasoning. ConTextual emphasizes diverse
real-world scenarios (e.g., time-reading, navigation, shopping and more)
demanding a deeper understanding of the interactions between textual and visual
elements. Our findings reveal a significant performance gap of 30.8% between
the best-performing LMM, GPT-4V(ision), and human capabilities using human
evaluation indicating substantial room for improvement in context-sensitive
text-rich visual reasoning. Notably, while GPT-4V excelled in abstract
categories like meme and quote interpretation, its overall performance still
lagged behind humans. In addition to human evaluations, we also employed
automatic evaluation metrics using GPT-4, uncovering similar trends in
performance disparities. We also perform a fine-grained evaluation across
diverse visual contexts and provide qualitative analysis which provides a
robust framework for future advancements in the LMM design.
https://con-textual.github.io/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13327">Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable Stress Detection. (arXiv:2401.13327v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lange_L/0/1/0/all/0/1">Lucas Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenzlitschke_N/0/1/0/all/0/1">Nils Wenzlitschke</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahm_E/0/1/0/all/0/1">Erhard Rahm</a></p>
<p>Smartwatch health sensor data is increasingly utilized in smart health
applications and patient monitoring, including stress detection. However, such
medical data often comprises sensitive personal information and is
resource-intensive to acquire for research purposes. In response to this
challenge, we introduce the privacy-aware synthetization of multi-sensor
smartwatch health readings related to moments of stress. Our method involves
the generation of synthetic sequence data through Generative Adversarial
Networks (GANs), coupled with the implementation of Differential Privacy (DP)
safeguards for protecting patient information during model training. To ensure
the integrity of our synthetic data, we employ a range of quality assessments
and monitor the plausibility between synthetic and original data. To test the
usefulness, we create private machine learning models on a commonly used,
albeit small, stress detection dataset, exploring strategies for enhancing the
existing data foundation with our synthetic data. Through our GAN-based
augmentation methods, we observe improvements in model performance, both in
non-private (0.45% F1) and private (11.90-15.48% F1) training scenarios. We
underline the potential of differentially private synthetic data in optimizing
utility-privacy trade-offs, especially with limited availability of real
training samples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13330">NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks. (arXiv:2401.13330v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gambella_M/0/1/0/all/0/1">Matteo Gambella</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomponi_J/0/1/0/all/0/1">Jary Pomponi</a>, <a href="http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1">Simone Scardapane</a>, <a href="http://arxiv.org/find/cs/1/au:+Roveri_M/0/1/0/all/0/1">Manuel Roveri</a></p>
<p>Early Exit Neural Networks (EENNs) endow astandard Deep Neural Network (DNN)
with Early Exit Classifiers (EECs), to provide predictions at intermediate
points of the processing when enough confidence in classification is achieved.
This leads to many benefits in terms of effectiveness and efficiency.
Currently, the design of EENNs is carried out manually by experts, a complex
and time-consuming task that requires accounting for many aspects, including
the correct placement, the thresholding, and the computational overhead of the
EECs. For this reason, the research is exploring the use of Neural Architecture
Search (NAS) to automatize the design of EENNs. Currently, few comprehensive
NAS solutions for EENNs have been proposed in the literature, and a fully
automated, joint design strategy taking into consideration both the backbone
and the EECs remains an open problem. To this end, this work presents Neural
Architecture Search for Hardware Constrained Early Exit Neural Networks
(NACHOS), the first NAS framework for the design of optimal EENNs satisfying
constraints on the accuracy and the number of Multiply and Accumulate (MAC)
operations performed by the EENNs at inference time. In particular, this
provides the joint design of backbone and EECs to select a set of admissible
(i.e., respecting the constraints) Pareto Optimal Solutions in terms of best
tradeoff between the accuracy and number of MACs. The results show that the
models designed by NACHOS are competitive with the state-of-the-art EENNs.
Additionally, this work investigates the effectiveness of two novel
regularization terms designed for the optimization of the auxiliary classifiers
of the EENN
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13334">Explainable Bayesian Optimization. (arXiv:2401.13334v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1">Tanmay Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1">Christin Seifert</a>, <a href="http://arxiv.org/find/cs/1/au:+Wirth_C/0/1/0/all/0/1">Christian Wirth</a></p>
<p>In industry, Bayesian optimization (BO) is widely applied in the human-AI
collaborative parameter tuning of cyber-physical systems. However, BO's
solutions may deviate from human experts' actual goal due to approximation
errors and simplified objectives, requiring subsequent tuning. The black-box
nature of BO limits the collaborative tuning process because the expert does
not trust the BO recommendations. Current explainable AI (XAI) methods are not
tailored for optimization and thus fall short of addressing this gap. To bridge
this gap, we propose TNTRules (TUNE-NOTUNE Rules), a post-hoc, rule-based
explainability method that produces high quality explanations through
multiobjective optimization. Our evaluation of benchmark optimization problems
and real-world hyperparameter optimization tasks demonstrates TNTRules'
superiority over state-of-the-art XAI methods in generating high quality
explanations. This work contributes to the intersection of BO and XAI,
providing interpretable optimization techniques for real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13335">Full Bayesian Significance Testing for Neural Networks. (arXiv:2401.13335v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Liu_Z/0/1/0/all/0/1">Zehua Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1">Zimeng Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jingyuan Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1">Yue He</a></p>
<p>Significance testing aims to determine whether a proposition about the
population distribution is the truth or not given observations. However,
traditional significance testing often needs to derive the distribution of the
testing statistic, failing to deal with complex nonlinear relationships. In
this paper, we propose to conduct Full Bayesian Significance Testing for neural
networks, called \textit{n}FBST, to overcome the limitation in relationship
characterization of traditional approaches. A Bayesian neural network is
utilized to fit the nonlinear and multi-dimensional relationships with small
errors and avoid hard theoretical derivation by computing the evidence value.
Besides, \textit{n}FBST can test not only global significance but also local
and instance-wise significance, which previous testing methods don't focus on.
Moreover, \textit{n}FBST is a general framework that can be extended based on
the measures selected, such as Grad-\textit{n}FBST, LRP-\textit{n}FBST,
DeepLIFT-\textit{n}FBST, LIME-\textit{n}FBST. A range of experiments on both
simulated and real data are conducted to show the advantages of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13343">Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD. (arXiv:2401.13343v1 [cs.SC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rio_T/0/1/0/all/0/1">Tereso del R&#xed;o</a>, <a href="http://arxiv.org/find/cs/1/au:+England_M/0/1/0/all/0/1">Matthew England</a></p>
<p>Symbolic Computation algorithms and their implementation in computer algebra
systems often contain choices which do not affect the correctness of the output
but can significantly impact the resources required: such choices can benefit
from having them made separately for each problem via a machine learning model.
This study reports lessons on such use of machine learning in symbolic
computation, in particular on the importance of analysing datasets prior to
machine learning and on the different machine learning paradigms that may be
utilised. We present results for a particular case study, the selection of
variable ordering for cylindrical algebraic decomposition, but expect that the
lessons learned are applicable to other decisions in symbolic computation.
</p>
<p>We utilise an existing dataset of examples derived from applications which
was found to be imbalanced with respect to the variable ordering decision. We
introduce an augmentation technique for polynomial systems problems that allows
us to balance and further augment the dataset, improving the machine learning
results by 28\% and 38\% on average, respectively. We then demonstrate how the
existing machine learning methodology used for the problem $-$ classification
$-$ might be recast into the regression paradigm. While this does not have a
radical change on the performance, it does widen the scope in which the
methodology can be applied to make choices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13360">Debiased Sample Selection for Combating Noisy Labels. (arXiv:2401.13360v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_Q/0/1/0/all/0/1">Qi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haobo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a></p>
<p>Learning with noisy labels aims to ensure model generalization given a
label-corrupted training set. The sample selection strategy achieves promising
performance by selecting a label-reliable subset for model training. In this
paper, we empirically reveal that existing sample selection methods suffer from
both data and training bias that are represented as imbalanced selected sets
and accumulation errors in practice, respectively. However, only the training
bias was handled in previous studies. To address this limitation, we propose a
noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection.
Specifically, to mitigate the training bias, we design a robust network
architecture that integrates with multiple experts. Compared with the
prevailing double-branch network, our network exhibits better performance of
selection and prediction by ensembling these experts while training with fewer
parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling
strategy based on two weight-based data samplers. By training on the mixture of
two class-discriminative mini-batches, the model mitigates the effect of the
imbalanced training set while avoiding sparse representations that are easily
caused by sampling strategies. Extensive experiments and analyses demonstrate
the effectiveness of ITEM. Our code is available at this url
\href{https://github.com/1998v7/ITEM}{ITEM}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13366">Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems. (arXiv:2401.13366v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jikun Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mavromatis_I/0/1/0/all/0/1">Ioannis Mavromatis</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peizheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Carnelli_P/0/1/0/all/0/1">Pietro Carnelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Aftab Khan</a></p>
<p>Federated learning (FL) systems face performance challenges in dealing with
heterogeneous devices and non-identically distributed data across clients. We
propose a dynamic global model aggregation method within Asynchronous Federated
Learning (AFL) deployments to address these issues. Our aggregation method
scores and adjusts the weighting of client model updates based on their upload
frequency to accommodate differences in device capabilities. Additionally, we
also immediately provide an updated global model to clients after they upload
their local models to reduce idle time and improve training efficiency. We
evaluate our approach within an AFL deployment consisting of 10 simulated
clients with heterogeneous compute constraints and non-IID data. The simulation
results, using the FashionMNIST dataset, demonstrate over 10% and 19%
improvement in global model accuracy compared to state-of-the-art methods
PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows
reliable global model training despite limiting client resources and
statistical data heterogeneity. This improves robustness and scalability for
real-world FL deployments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13391">Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely on between-group metrics. (arXiv:2401.13391v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goethals_S/0/1/0/all/0/1">Sofie Goethals</a>, <a href="http://arxiv.org/find/cs/1/au:+Calders_T/0/1/0/all/0/1">Toon Calders</a>, <a href="http://arxiv.org/find/cs/1/au:+Martens_D/0/1/0/all/0/1">David Martens</a></p>
<p>Artificial Intelligence (AI) finds widespread applications across various
domains, sparking concerns about fairness in its deployment. While fairness in
AI remains a central concern, the prevailing discourse often emphasizes
outcome-based metrics without a nuanced consideration of the differential
impacts within subgroups. Bias mitigation techniques do not only affect the
ranking of pairs of instances across sensitive groups, but often also
significantly affect the ranking of instances within these groups. Such changes
are hard to explain and raise concerns regarding the validity of the
intervention. Unfortunately, these effects largely remain under the radar in
the accuracy-fairness evaluation framework that is usually applied. This paper
challenges the prevailing metrics for assessing bias mitigation techniques,
arguing that they do not take into account the changes within-groups and that
the resulting prediction labels fall short of reflecting real-world scenarios.
We propose a paradigm shift: initially, we should focus on generating the most
precise ranking for each subgroup. Following this, individuals should be chosen
from these rankings to meet both fairness standards and practical
considerations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13398">Text Categorization Can Enhance Domain-Agnostic Stopword Extraction. (arXiv:2401.13398v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Turki_H/0/1/0/all/0/1">Houcemeddine Turki</a>, <a href="http://arxiv.org/find/cs/1/au:+Etori_N/0/1/0/all/0/1">Naome A. Etori</a>, <a href="http://arxiv.org/find/cs/1/au:+Taieb_M/0/1/0/all/0/1">Mohamed Ali Hadj Taieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Omotayo_A/0/1/0/all/0/1">Abdul-Hakeem Omotayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Emezue_C/0/1/0/all/0/1">Chris Chinenye Emezue</a>, <a href="http://arxiv.org/find/cs/1/au:+Aouicha_M/0/1/0/all/0/1">Mohamed Ben Aouicha</a>, <a href="http://arxiv.org/find/cs/1/au:+Awokoya_A/0/1/0/all/0/1">Ayodele Awokoya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawan_F/0/1/0/all/0/1">Falalu Ibrahim Lawan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nixdorf_D/0/1/0/all/0/1">Doreen Nixdorf</a></p>
<p>This paper investigates the role of text categorization in streamlining
stopword extraction in natural language processing (NLP), specifically focusing
on nine African languages alongside French. By leveraging the MasakhaNEWS,
African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that
text categorization effectively identifies domain-agnostic stopwords with over
80% detection success rate for most examined languages. Nevertheless,
linguistic variances result in lower detection rates for certain languages.
Interestingly, we find that while over 40% of stopwords are common across news
categories, less than 15% are unique to a single category. Uncommon stopwords
add depth to text but their classification as stopwords depends on context.
Therefore combining statistical and linguistic approaches creates comprehensive
stopword lists, highlighting the value of our hybrid method. This research
enhances NLP for African languages and underscores the importance of text
categorization in stopword extraction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13410">How to Forget Clients in Federated Online Learning to Rank?. (arXiv:2401.13410v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuccon_G/0/1/0/all/0/1">Guido Zuccon</a></p>
<p>Data protection legislation like the European Union's General Data Protection
Regulation (GDPR) establishes the \textit{right to be forgotten}: a user
(client) can request contributions made using their data to be removed from
learned models. In this paper, we study how to remove the contributions made by
a client participating in a Federated Online Learning to Rank (FOLTR) system.
In a FOLTR system, a ranker is learned by aggregating local updates to the
global ranking model. Local updates are learned in an online manner at a
client-level using queries and implicit interactions that have occurred within
that specific client. By doing so, each client's local data is not shared with
other clients or with a centralised search service, while at the same time
clients can benefit from an effective global ranking model learned from
contributions of each client in the federation.
</p>
<p>In this paper, we study an effective and efficient unlearning method that can
remove a client's contribution without compromising the overall ranker
effectiveness and without needing to retrain the global ranker from scratch. A
key challenge is how to measure whether the model has unlearned the
contributions from the client $c^*$ that has requested removal. For this, we
instruct $c^*$ to perform a poisoning attack (add noise to this client updates)
and then we measure whether the impact of the attack is lessened when the
unlearning process has taken place. Through experiments on four datasets, we
demonstrate the effectiveness and efficiency of the unlearning strategy under
different combinations of parameter settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13421">Federated learning with distributed fixed design quantum chips and quantum channels. (arXiv:2401.13421v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Daskin_A/0/1/0/all/0/1">Ammar Daskin</a></p>
<p>The privacy in classical federated learning can be breached through the use
of local gradient results by using engineered queries from the clients.
However, quantum communication channels are considered more secure because the
use of measurements in the data causes some loss of information, which can be
detected. Therefore, the quantum version of federated learning can be used to
provide more privacy. Additionally, sending an $N$ dimensional data vector
through a quantum channel requires sending $\log N$ entangled qubits, which can
provide exponential efficiency if the data vector is obtained as quantum
states.
</p>
<p>In this paper, we propose a quantum federated learning model where fixed
design quantum chips are operated based on the quantum states sent by a
centralized server. Based on the coming superposition states, the clients
compute and then send their local gradients as quantum states to the server,
where they are aggregated to update parameters. Since the server does not send
model parameters, but instead sends the operator as a quantum state, the
clients are not required to share the model. This allows for the creation of
asynchronous learning models. In addition, the model as a quantum state is fed
into client-side chips directly; therefore, it does not require measurements on
the upcoming quantum state to obtain model parameters in order to compute
gradients. This can provide efficiency over the models where parameter vector
is sent via classical or quantum channels and local gradients are obtained
through the obtained values of these parameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13429">Detection of Correlated Random Vectors. (arXiv:2401.13429v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Elimelech_D/0/1/0/all/0/1">Dor Elimelech</a>, <a href="http://arxiv.org/find/cs/1/au:+Huleihel_W/0/1/0/all/0/1">Wasim Huleihel</a></p>
<p>In this paper, we investigate the problem of deciding whether two standard
normal random vectors $\mathsf{X}\in\mathbb{R}^{n}$ and
$\mathsf{Y}\in\mathbb{R}^{n}$ are correlated or not. This is formulated as a
hypothesis testing problem, where under the null hypothesis, these vectors are
statistically independent, while under the alternative, $\mathsf{X}$ and a
randomly and uniformly permuted version of $\mathsf{Y}$, are correlated with
correlation $\rho$. We analyze the thresholds at which optimal testing is
information-theoretically impossible and possible, as a function of $n$ and
$\rho$. To derive our information-theoretic lower bounds, we develop a novel
technique for evaluating the second moment of the likelihood ratio using an
orthogonal polynomials expansion, which among other things, reveals a
surprising connection to integer partition functions. We also study a
multi-dimensional generalization of the above setting, where rather than two
vectors we observe two databases/matrices, and furthermore allow for partial
correlations between these two.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13447">Symbolic Equation Solving via Reinforcement Learning. (arXiv:2401.13447v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dabelow_L/0/1/0/all/0/1">Lennart Dabelow</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1">Masahito Ueda</a></p>
<p>Machine-learning methods are gradually being adopted in a great variety of
social, economic, and scientific contexts, yet they are notorious for
struggling with exact mathematics. A typical example is computer algebra, which
includes tasks like simplifying mathematical terms, calculating formal
derivatives, or finding exact solutions of algebraic equations. Traditional
software packages for these purposes are commonly based on a huge database of
rules for how a specific operation (e.g., differentiation) transforms a certain
term (e.g., sine function) into another one (e.g., cosine function). Thus far,
these rules have usually needed to be discovered and subsequently programmed by
humans. Focusing on the paradigmatic example of solving linear equations in
symbolic form, we demonstrate how the process of finding elementary
transformation rules and step-by-step solutions can be automated using
reinforcement learning with deep neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13460">Multi-Agent Diagnostics for Robustness via Illuminated Diversity. (arXiv:2401.13460v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Samvelyan_M/0/1/0/all/0/1">Mikayel Samvelyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Paglieri_D/0/1/0/all/0/1">Davide Paglieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Minqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1">Tim Rockt&#xe4;schel</a></p>
<p>In the rapidly advancing field of multi-agent systems, ensuring robustness in
unfamiliar and adversarial settings is crucial. Notwithstanding their
outstanding performance in familiar environments, these systems often falter in
new situations due to overfitting during the training phase. This is especially
pronounced in settings where both cooperative and competitive behaviours are
present, encapsulating a dual nature of overfitting and generalisation
challenges. To address this issue, we present Multi-Agent Diagnostics for
Robustness via Illuminated Diversity (MADRID), a novel approach for generating
diverse adversarial scenarios that expose strategic vulnerabilities in
pre-trained multi-agent policies. Leveraging the concepts from open-ended
learning, MADRID navigates the vast space of adversarial settings, employing a
target policy's regret to gauge the vulnerabilities of these settings. We
evaluate the effectiveness of MADRID on the 11vs11 version of Google Research
Football, one of the most complex environments for multi-agent reinforcement
learning. Specifically, we employ MADRID for generating a diverse array of
adversarial settings for TiZero, the state-of-the-art approach which "masters"
the game through 45 days of training on a large-scale distributed
infrastructure. We expose key shortcomings in TiZero's tactical
decision-making, underlining the crucial importance of rigorous evaluation in
multi-agent systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13486">Separable Physics-Informed Neural Networks for the solution of elasticity problems. (arXiv:2401.13486v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Eskin_V/0/1/0/all/0/1">Vasiliy A. Es&#x27;kin</a>, <a href="http://arxiv.org/find/math/1/au:+Davydov_D/0/1/0/all/0/1">Danil V. Davydov</a>, <a href="http://arxiv.org/find/math/1/au:+Gureva_J/0/1/0/all/0/1">Julia V. Gur&#x27;eva</a>, <a href="http://arxiv.org/find/math/1/au:+Malkhanov_A/0/1/0/all/0/1">Alexey O. Malkhanov</a>, <a href="http://arxiv.org/find/math/1/au:+Smorkalov_M/0/1/0/all/0/1">Mikhail E. Smorkalov</a></p>
<p>A method for solving elasticity problems based on separable physics-informed
neural networks (SPINN) in conjunction with the deep energy method (DEM) is
presented. Numerical experiments have been carried out for a number of problems
showing that this method has a significantly higher convergence rate and
accuracy than the vanilla physics-informed neural networks (PINN) and even
SPINN based on a system of partial differential equations (PDEs). In addition,
using the SPINN in the framework of DEM approach it is possible to solve
problems of the linear theory of elasticity on complex geometries, which is
unachievable with the help of PINNs in frames of partial differential
equations. Considered problems are very close to the industrial problems in
terms of geometry, loading, and material parameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13498">Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting. (arXiv:2401.13498v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hounsu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Soonbeom Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1">Juhan Nam</a></p>
<p>Synthesizing performing guitar sound is a highly challenging task due to the
polyphony and high variability in expression. Recently, deep generative models
have shown promising results in synthesizing expressive polyphonic instrument
sounds from music scores, often using a generic MIDI input. In this work, we
propose an expressive acoustic guitar sound synthesis model with a customized
input representation to the instrument, which we call guitarroll. We implement
the proposed approach using diffusion-based outpainting which can generate
audio with long-term consistency. To overcome the lack of MIDI/audio-paired
datasets, we used not only an existing guitar dataset but also collected data
from a high quality sample-based guitar synthesizer. Through quantitative and
qualitative evaluations, we show that our proposed model has higher audio
quality than the baseline model and generates more realistic timbre sounds than
the previous leading work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13511">Tissue Cross-Section and Pen Marking Segmentation in Whole Slide Images. (arXiv:2401.13511v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Lucassen_R/0/1/0/all/0/1">Ruben T. Lucassen</a>, <a href="http://arxiv.org/find/eess/1/au:+Blokx_W/0/1/0/all/0/1">Willeke A. M. Blokx</a>, <a href="http://arxiv.org/find/eess/1/au:+Veta_M/0/1/0/all/0/1">Mitko Veta</a></p>
<p>Tissue segmentation is a routine preprocessing step to reduce the
computational cost of whole slide image (WSI) analysis by excluding background
regions. Traditional image processing techniques are commonly used for tissue
segmentation, but often require manual adjustments to parameter values for
atypical cases, fail to exclude all slide and scanning artifacts from the
background, and are unable to segment adipose tissue. Pen marking artifacts in
particular can be a potential source of bias for subsequent analyses if not
removed. In addition, several applications require the separation of individual
cross-sections, which can be challenging due to tissue fragmentation and
adjacent positioning. To address these problems, we develop a convolutional
neural network for tissue and pen marking segmentation using a dataset of 200
H&amp;E stained WSIs. For separating tissue cross-sections, we propose a novel
post-processing method based on clustering predicted centroid locations of the
cross-sections in a 2D histogram. On an independent test set, the model
achieved a mean Dice score of 0.981$\pm$0.033 for tissue segmentation and a
mean Dice score of 0.912$\pm$0.090 for pen marking segmentation. The mean
absolute difference between the number of annotated and separated
cross-sections was 0.075$\pm$0.350. Our results demonstrate that the proposed
model can accurately segment H&amp;E stained tissue cross-sections and pen markings
in WSIs while being robust to many common slide and scanning artifacts. The
model with trained model parameters and post-processing method are made
publicly available as a Python package called SlideSegmenter.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13530">Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space. (arXiv:2401.13530v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yi_M/0/1/0/all/0/1">Mingyang Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bohan Wang</a></p>
<p>Recently, optimization on the Riemannian manifold has provided new insights
to the optimization community. In this regard, the manifold taken as the
probability measure metric space equipped with the second-order Wasserstein
distance is of particular interest, since optimization on it can be linked to
practical sampling processes. In general, the oracle (continuous) optimization
method on Wasserstein space is Riemannian gradient flow (i.e., Langevin
dynamics when minimizing KL divergence). In this paper, we aim to enrich the
continuous optimization methods in the Wasserstein space by extending the
gradient flow into the stochastic gradient descent (SGD) flow and stochastic
variance reduction gradient (SVRG) flow. The two flows on Euclidean space are
standard stochastic optimization methods, while their Riemannian counterparts
are not explored yet. By leveraging the structures in Wasserstein space, we
construct a stochastic differential equation (SDE) to approximate the discrete
dynamics of desired stochastic methods in the corresponded random vector space.
Then, the flows of probability measures are naturally obtained by applying
Fokker-Planck equation to such SDE. Furthermore, the convergence rates of the
proposed Riemannian stochastic flows are proven, and they match the results in
Euclidean space.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13536">Finetuning Foundation Models for Joint Analysis Optimization. (arXiv:2401.13536v1 [hep-ex])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ex/1/au:+Vig_M/0/1/0/all/0/1">Matthias Vig</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Hartman_N/0/1/0/all/0/1">Nicole Hartman</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Heinrich_L/0/1/0/all/0/1">Lukas Heinrich</a></p>
<p>In this work we demonstrate that significant gains in performance and data
efficiency can be achieved in High Energy Physics (HEP) by moving beyond the
standard paradigm of sequential optimization or reconstruction and analysis
components. We conceptually connect HEP reconstruction and analysis to modern
machine learning workflows such as pretraining, finetuning, domain adaptation
and high-dimensional embedding spaces and quantify the gains in the example
usecase of searches of heavy resonances decaying via an intermediate di-Higgs
system to four $b$-jets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13537">Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models. (arXiv:2401.13537v1 [hep-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ph/1/au:+Heinrich_L/0/1/0/all/0/1">Lukas Heinrich</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Kagan_M/0/1/0/all/0/1">Michael Kagan</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Klein_S/0/1/0/all/0/1">Samuel Klein</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Leigh_M/0/1/0/all/0/1">Matthew Leigh</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Golling_T/0/1/0/all/0/1">Tobias Golling</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Raine_J/0/1/0/all/0/1">John Andrew Raine</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Osadchy_M/0/1/0/all/0/1">Margarita Osadchy</a></p>
<p>We propose \textit{masked particle modeling} (MPM) as a self-supervised
method for learning generic, transferable, and reusable representations on
unordered sets of inputs for use in high energy physics (HEP) scientific data.
This work provides a novel scheme to perform masked modeling based pre-training
to learn permutation invariant functions on sets. More generally, this work
provides a step towards building large foundation models for HEP that can be
generically pre-trained with self-supervised learning and later fine-tuned for
a variety of down-stream tasks. In MPM, particles in a set are masked and the
training objective is to recover their identity, as defined by a discretized
token representation of a pre-trained vector quantized variational autoencoder.
We study the efficacy of the method in samples of high energy jets at collider
physics experiments, including studies on the impact of discretization,
permutation invariance, and ordering. We also study the fine-tuning capability
of the model, showing that it can be adapted to tasks such as supervised and
weakly supervised jet classification, and that the model can transfer
efficiently with small fine-tuning data sets to new classes and new data
domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13544">Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?. (arXiv:2401.13544v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Laguna_S/0/1/0/all/0/1">Sonia Laguna</a>, <a href="http://arxiv.org/find/cs/1/au:+Vandenhirtz_M/0/1/0/all/0/1">Moritz Vandenhirtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1">Julia E. Vogt</a></p>
<p>Recently, interpretable machine learning has re-explored concept bottleneck
models (CBM), comprising step-by-step prediction of the high-level concepts
from the raw features and the target variable from the predicted concepts. A
compelling advantage of this model class is the user's ability to intervene on
the predicted concept values, affecting the model's downstream output. In this
work, we introduce a method to perform such concept-based interventions on
already-trained neural networks, which are not interpretable by design, given
an annotated validation set. Furthermore, we formalise the model's
intervenability as a measure of the effectiveness of concept-based
interventions and leverage this definition to fine-tune black-box models.
Empirically, we explore the intervenability of black-box classifiers on
synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning
improves intervention effectiveness and often yields better-calibrated
predictions. To showcase the practical utility of the proposed techniques, we
apply them to deep chest X-ray classifiers and show that fine-tuned black boxes
can be as intervenable and more performant than CBMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13555">Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Laszkiewicz_M/0/1/0/all/0/1">Mike Laszkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Daunhawer_I/0/1/0/all/0/1">Imant Daunhawer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1">Julia E. Vogt</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1">Asja Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lederer_J/0/1/0/all/0/1">Johannes Lederer</a></p>
<p>Recent years have witnessed a rapid development of deep generative models for
creating synthetic media, such as images and videos. While the practical
applications of these models in everyday tasks are enticing, it is crucial to
assess the inherent risks regarding their fairness. In this work, we introduce
a comprehensive framework for benchmarking the performance and fairness of
conditional generative models. We develop a set of
metrics$\unicode{x2013}$inspired by their supervised fairness
counterparts$\unicode{x2013}$to evaluate the models on their fairness and
diversity. Focusing on the specific application of image upsampling, we create
a benchmark covering a wide variety of modern upsampling methods. As part of
the benchmark, we introduce UnfairFace, a subset of FairFace that replicates
the racial distribution of common large-scale face datasets. Our empirical
study highlights the importance of using an unbiased training set and reveals
variations in how the algorithms respond to dataset imbalances. Alarmingly, we
find that none of the considered methods produces statistically fair and
diverse results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13558">Task structure and nonlinearity jointly determine learned representational geometry. (arXiv:2401.13558v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alleman_M/0/1/0/all/0/1">Matteo Alleman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindsey_J/0/1/0/all/0/1">Jack W Lindsey</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusi_S/0/1/0/all/0/1">Stefano Fusi</a></p>
<p>The utility of a learned neural representation depends on how well its
geometry supports performance in downstream tasks. This geometry depends on the
structure of the inputs, the structure of the target outputs, and the
architecture of the network. By studying the learning dynamics of networks with
one hidden layer, we discovered that the network's activation function has an
unexpectedly strong impact on the representational geometry: Tanh networks tend
to learn representations that reflect the structure of the target outputs,
while ReLU networks retain more information about the structure of the raw
inputs. This difference is consistently observed across a broad class of
parameterized tasks in which we modulated the degree of alignment between the
geometry of the task inputs and that of the task labels. We analyzed the
learning dynamics in weight space and show how the differences between the
networks with Tanh and ReLU nonlinearities arise from the asymmetric asymptotic
behavior of ReLU, which leads feature neurons to specialize for different
regions of input space. By contrast, feature neurons in Tanh networks tend to
inherit the task label structure. Consequently, when the target outputs are low
dimensional, Tanh networks generate neural representations that are more
disentangled than those obtained with a ReLU nonlinearity. Our findings shed
light on the interplay between input-output geometry, nonlinearity, and learned
representations in neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13570">Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials. (arXiv:2401.13570v1 [cs.CE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yanyan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lili Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaoya Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yunkai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ligang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiao-Ming Fu</a></p>
<p>Mechanical metamaterial is a synthetic material that can possess
extraordinary physical characteristics, such as abnormal elasticity, stiffness,
and stability, by carefully designing its internal structure. To make
metamaterials contain delicate local structures with unique mechanical
properties, it is a potential method to represent them through high-resolution
voxels. However, it brings a substantial computational burden. To this end,
this paper proposes a fast inverse design method, whose core is an advanced
deep generative AI algorithm, to generate voxel-based mechanical metamaterials.
Specifically, we use the self-conditioned diffusion model, capable of
generating a microstructure with a resolution of $128^3$ to approach the
specified homogenized tensor matrix in just 3 seconds. Accordingly, this rapid
reverse design tool facilitates the exploration of extreme metamaterials, the
sequence interpolation in metamaterials, and the generation of diverse
microstructures for multi-scale design. This flexible and adaptive generative
tool is of great value in structural engineering or other mechanical systems
and can stimulate more subsequent research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13575">CNN architecture extraction on edge GPU. (arXiv:2401.13575v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Horvath_P/0/1/0/all/0/1">Peter Horvath</a>, <a href="http://arxiv.org/find/cs/1/au:+Chmielewski_L/0/1/0/all/0/1">Lukasz Chmielewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Weissbart_L/0/1/0/all/0/1">Leo Weissbart</a>, <a href="http://arxiv.org/find/cs/1/au:+Batina_L/0/1/0/all/0/1">Lejla Batina</a>, <a href="http://arxiv.org/find/cs/1/au:+Yarom_Y/0/1/0/all/0/1">Yuval Yarom</a></p>
<p>Neural networks have become popular due to their versatility and
state-of-the-art results in many applications, such as image classification,
natural language processing, speech recognition, forecasting, etc. These
applications are also used in resource-constrained environments such as
embedded devices. In this work, the susceptibility of neural network
implementations to reverse engineering is explored on the NVIDIA Jetson Nano
microcomputer via side-channel analysis. To this end, an architecture
extraction attack is presented. In the attack, 15 popular convolutional neural
network architectures (EfficientNets, MobileNets, NasNet, etc.) are implemented
on the GPU of Jetson Nano and the electromagnetic radiation of the GPU is
analyzed during the inference operation of the neural networks. The results of
the analysis show that neural network architectures are easily distinguishable
using deep learning-based side-channel analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13586">Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huerta_Enochian_M/0/1/0/all/0/1">Mathew Huerta-Enochian</a></p>
<p>We present a small study analyzing how prompt token classification loss
weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on
instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1
and LLaMA 2 using multiple instruction datasets. We found that models
fine-tuned on our short-completion dataset have a negative quadratic
relationship with PLW while models fine-tuned on long-completion datasets were
unaffected by PLW.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13624">Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint. (arXiv:2401.13624v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Shi_Z/0/1/0/all/0/1">Zhongjie Shi</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_F/0/1/0/all/0/1">Fanghui Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Cao_Y/0/1/0/all/0/1">Yuan Cao</a>, <a href="http://arxiv.org/find/stat/1/au:+Suykens_J/0/1/0/all/0/1">Johan A.K. Suykens</a></p>
<p>Adversarial training is a widely used method to improve the robustness of
deep neural networks (DNNs) over adversarial perturbations. However, it is
empirically observed that adversarial training on over-parameterized networks
often suffers from the \textit{robust overfitting}: it can achieve almost zero
adversarial training error while the robust generalization performance is not
promising. In this paper, we provide a theoretical understanding of the
question of whether overfitted DNNs in adversarial training can generalize from
an approximation viewpoint. Specifically, our main results are summarized into
three folds: i) For classification, we prove by construction the existence of
infinitely many adversarial training classifiers on over-parameterized DNNs
that obtain arbitrarily small adversarial training error (overfitting), whereas
achieving good robust generalization error under certain conditions concerning
the data quality, well separated, and perturbation level. ii) Linear
over-parameterization (meaning that the number of parameters is only slightly
larger than the sample size) is enough to ensure such existence if the target
function is smooth enough. iii) For regression, our results demonstrate that
there also exist infinitely many overfitted DNNs with linear
over-parameterization in adversarial training that can achieve almost optimal
rates of convergence for the standard generalization error. Overall, our
analysis points out that robust overfitting can be avoided but the required
model capacity will depend on the smoothness of the target function, while a
robust generalization gap is inevitable. We hope our analysis will give a
better understanding of the mathematical foundations of robustness in DNNs from
an approximation view.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13641">How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability. (arXiv:2401.13641v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DeAndres_Tame_I/0/1/0/all/0/1">Ivan DeAndres-Tame</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1">Ruben Tolosana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1">Ruben Vera-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_Garcia_J/0/1/0/all/0/1">Javier Ortega-Garcia</a></p>
<p>Large Language Models (LLMs) such as GPT developed by OpenAI, have already
shown astonishing results, introducing quick changes in our society. This has
been intensified by the release of ChatGPT which allows anyone to interact in a
simple conversational way with LLMs, without any experience in the field
needed. As a result, ChatGPT has been rapidly applied to many different tasks
such as code- and song-writer, education, virtual assistants, etc., showing
impressive results for tasks for which it was not trained (zero-shot learning).
</p>
<p>The present study aims to explore the ability of ChatGPT, based on the recent
GPT-4 multimodal LLM, for the task of face biometrics. In particular, we
analyze the ability of ChatGPT to perform tasks such as face verification,
soft-biometrics estimation, and explainability of the results. ChatGPT could be
very valuable to further increase the explainability and transparency of the
automatic decisions in human scenarios. Experiments are carried out in order to
evaluate the performance and robustness of ChatGPT, using popular public
benchmarks and comparing the results with state-of-the-art methods in the
field. The results achieved in this study show the potential of LLMs such as
ChatGPT for face biometrics, especially to enhance explainability. For
reproducibility reasons, we release all the code in GitHub.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13649">VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks. (arXiv:2401.13649v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1">Jing Yu Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1">Robert Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_L/0/1/0/all/0/1">Lawrence Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duvvur_V/0/1/0/all/0/1">Vikram Duvvur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1">Ming Chong Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Po-Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuyan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1">Daniel Fried</a></p>
<p>Autonomous agents capable of planning, reasoning, and executing actions on
the web offer a promising avenue for automating computer tasks. However, the
majority of existing benchmarks primarily focus on text-based agents,
neglecting many natural tasks that require visual information to effectively
solve. Given that most computer interfaces cater to human perception, visual
information often augments textual data in ways that text-only models struggle
to harness effectively. To bridge this gap, we introduce VisualWebArena, a
benchmark designed to assess the performance of multimodal web agents on
realistic \textit{visually grounded tasks}. VisualWebArena comprises of a set
of diverse and complex web-based tasks that evaluate various capabilities of
autonomous multimodal agents. To perform on this benchmark, agents need to
accurately process image-text inputs, interpret natural language instructions,
and execute actions on websites to accomplish user-defined objectives. We
conduct an extensive evaluation of state-of-the-art LLM-based autonomous
agents, including several multimodal models. Through extensive quantitative and
qualitative analysis, we identify several limitations of text-only LLM agents,
and reveal gaps in the capabilities of state-of-the-art multimodal language
agents. VisualWebArena provides a framework for evaluating multimodal
autonomous language agents, and offers insights towards building stronger
autonomous agents for the web. Our code, baseline models, and data is publicly
available at https://jykoh.com/vwa.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13652">Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors. (arXiv:2401.13652v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Santa_F/0/1/0/all/0/1">Francesco Della Santa</a>, <a href="http://arxiv.org/find/cs/1/au:+Pieraccini_S/0/1/0/all/0/1">Sandra Pieraccini</a></p>
<p>In this paper, we present a novel approach for detecting the discontinuity
interfaces of a discontinuous function. This approach leverages Graph-Informed
Neural Networks (GINNs) and sparse grids to address discontinuity detection
also in domains of dimension larger than 3. GINNs, trained to identify troubled
points on sparse grids, exploit graph structures built on the grids to achieve
efficient and accurate discontinuity detection performances. We also introduce
a recursive algorithm for general sparse grid-based detectors, characterized by
convergence properties and easy applicability. Numerical experiments on
functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust
generalization of GINNs in detecting discontinuity interfaces. Notably, the
trained GINNs offer portability and versatility, allowing integration into
various algorithms and sharing among users.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13657">Inadequacy of common stochastic neural networks for reliable clinical decision support. (arXiv:2401.13657v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lindenmeyer_A/0/1/0/all/0/1">Adrian Lindenmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Blattmann_M/0/1/0/all/0/1">Malte Blattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Franke_S/0/1/0/all/0/1">Stefan Franke</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumuth_T/0/1/0/all/0/1">Thomas Neumuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_D/0/1/0/all/0/1">Daniel Schneider</a></p>
<p>Widespread adoption of AI for medical decision making is still hindered due
to ethical and safety-related concerns. For AI-based decision support systems
in healthcare settings it is paramount to be reliable and trustworthy. Common
deep learning approaches, however, have the tendency towards overconfidence
under data shift. Such inappropriate extrapolation beyond evidence-based
scenarios may have dire consequences. This highlights the importance of
reliable estimation of local uncertainty and its communication to the end user.
While stochastic neural networks have been heralded as a potential solution to
these issues, this study investigates their actual reliability in clinical
applications. We centered our analysis on the exemplary use case of mortality
prediction for ICU hospitalizations using EHR from MIMIC3 study. For
predictions on the EHR time series, Encoder-Only Transformer models were
employed. Stochasticity of model functions was achieved by incorporating common
methods such as Bayesian neural network layers and model ensembles. Our models
achieve state of the art performance in terms of discrimination performance
(AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality
prediction benchmark. However, epistemic uncertainty is critically
underestimated by the selected stochastic deep learning methods. A heuristic
proof for the responsible collapse of the posterior distribution is provided.
Our findings reveal the inadequacy of commonly used stochastic deep learning
approaches to reliably recognize OoD samples. In both methods, unsubstantiated
model confidence is not prevented due to strongly biased functional posteriors,
rendering them inappropriate for reliable clinical decision support. This
highlights the need for approaches with more strictly enforced or inherent
distance-awareness to known data points, e.g., using kernel-based techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13660">MambaByte: Token-free Selective State Space Model. (arXiv:2401.13660v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junxiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangavarapu_T/0/1/0/all/0/1">Tushaar Gangavarapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jing Nathan Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1">Alexander M Rush</a></p>
<p>Token-free language models learn directly from raw bytes and remove the bias
of subword tokenization. Operating on bytes, however, results in significantly
longer sequences, and standard autoregressive Transformers scale poorly in such
settings. We experiment with MambaByte, a token-free adaptation of the Mamba
state space model, trained autoregressively on byte sequences. Our experiments
indicate the computational efficiency of MambaByte compared to other byte-level
models. We also find MambaByte to be competitive with and even outperform
state-of-the-art subword Transformers. Furthermore, owing to linear scaling in
length, MambaByte benefits from fast inference compared to Transformers. Our
findings establish the viability of MambaByte in enabling token-free language
modeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13662">The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations. (arXiv:2401.13662v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lehmann_M/0/1/0/all/0/1">Matthias Lehmann</a></p>
<p>In recent years, various powerful policy gradient algorithms have been
proposed in deep reinforcement learning. While all these algorithms build on
the Policy Gradient Theorem, the specific design choices differ significantly
across algorithms. We provide a holistic overview of on-policy policy gradient
algorithms to facilitate the understanding of both their theoretical
foundations and their practical implementations. In this overview, we include a
detailed proof of the continuous version of the Policy Gradient Theorem,
convergence results and a comprehensive discussion of practical algorithms. We
compare the most prominent algorithms on continuous control environments and
provide insights on the benefits of regularization. All code is available at
https://github.com/Matt00n/PolicyGradientsJax.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1802.03308">The Power of Linear Recurrent Neural Networks. (arXiv:1802.03308v9 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1">Frieder Stolzenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Litz_S/0/1/0/all/0/1">Sandra Litz</a>, <a href="http://arxiv.org/find/cs/1/au:+Michael_O/0/1/0/all/0/1">Olivia Michael</a>, <a href="http://arxiv.org/find/cs/1/au:+Obst_O/0/1/0/all/0/1">Oliver Obst</a></p>
<p>Recurrent neural networks are a powerful means to cope with time series. We
show how autoregressive linear, i.e., linearly activated recurrent neural
networks (LRNNs) can approximate any time-dependent function f(t). The
approximation can effectively be learned by simply solving a linear equation
system; no backpropagation or similar methods are needed. Furthermore, and this
is the main contribution of this article, the size of an LRNN can be reduced
significantly in one step after inspecting the spectrum of the network
transition matrix, i.e., its eigenvalues, by taking only the most relevant
components. Therefore, in contrast to other approaches, we do not only learn
network weights but also the network architecture. LRNNs have interesting
properties: They end up in ellipse trajectories in the long run and allow the
prediction of further values and compact representations of functions. We
demonstrate this by several experiments, among them multiple superimposed
oscillators (MSO), robotic soccer (RoboCup), and stock price prediction. LRNNs
outperform the previous state-of-the-art for the MSO task with a minimal number
of units.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2011.05001">MMD-Regularized Unbalanced Optimal Transport. (arXiv:2011.05001v9 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manupriya_P/0/1/0/all/0/1">Piyushi Manupriya</a> (IIT Hyderabad, INDIA), <a href="http://arxiv.org/find/cs/1/au:+Nath_J/0/1/0/all/0/1">J. Saketha Nath</a> (IIT Hyderabad, INDIA), <a href="http://arxiv.org/find/cs/1/au:+Jawanpuria_P/0/1/0/all/0/1">Pratik Jawanpuria</a> (Microsoft IDC, INDIA)</p>
<p>We study the unbalanced optimal transport (UOT) problem, where the marginal
constraints are enforced using Maximum Mean Discrepancy (MMD) regularization.
Our work is motivated by the observation that the literature on UOT is focused
on regularization based on $\phi$-divergence (e.g., KL divergence). Despite the
popularity of MMD, its role as a regularizer in the context of UOT seems less
understood. We begin by deriving a specific dual of MMD-regularized UOT
(MMD-UOT), which helps us prove several useful properties. One interesting
outcome of this duality result is that MMD-UOT induces novel metrics, which not
only lift the ground metric like the Wasserstein but are also sample-wise
efficient to estimate like the MMD. Further, for real-world applications
involving non-discrete measures, we present an estimator for the transport plan
that is supported only on the given ($m$) samples. Under certain conditions, we
prove that the estimation error with this finitely-supported transport plan is
also $\mathcal{O}(1/\sqrt{m})$. As far as we know, such error bounds that are
free from the curse of dimensionality are not known for $\phi$-divergence
regularized UOT. Finally, we discuss how the proposed estimator can be computed
efficiently using accelerated gradient descent. Our experiments show that
MMD-UOT consistently outperforms popular baselines, including KL-regularized
UOT and MMD, in diverse machine learning applications. Our codes are publicly
available at https://github.com/Piyushi-0/MMD-reg-OT
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.01135">MNL-Bandit with Knapsacks: a near-optimal algorithm. (arXiv:2106.01135v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aznag_A/0/1/0/all/0/1">Abdellah Aznag</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1">Vineet Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Perivier_N/0/1/0/all/0/1">Noemie Perivier</a></p>
<p>We consider a dynamic assortment selection problem where a seller has a fixed
inventory of $N$ substitutable products and faces an unknown demand that
arrives sequentially over $T$ periods. In each period, the seller needs to
decide on the assortment of products (satisfying certain constraints) to offer
to the customers. The customer's response follows an unknown multinomial logit
model (MNL) with parameter $\boldsymbol{v}$. If customer selects product $i \in
[N]$, the seller receives revenue $r_i$. The goal of the seller is to maximize
the total expected revenue from the $T$ customers given the fixed initial
inventory of $N$ products. We present MNLwK-UCB, a UCB-based algorithm and
characterize its regret under different regimes of inventory size. We show that
when the inventory size grows quasi-linearly in time, MNLwK-UCB achieves a
$\tilde{O}(N + \sqrt{NT})$ regret bound. We also show that for a smaller
inventory (with growth $\sim T^{\alpha}$, $\alpha &lt; 1$), MNLwK-UCB achieves a
$\tilde{O}(N(1 + T^{\frac{1 - \alpha}{2}}) + \sqrt{NT})$. In particular, over a
long time horizon $T$, the rate $\tilde{O}(\sqrt{NT})$ is always achieved
regardless of the constraints and the size of the inventory.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.07289">Decentralized Personalized Federated Learning for Min-Max Problems. (arXiv:2106.07289v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Borodich_E/0/1/0/all/0/1">Ekaterina Borodich</a>, <a href="http://arxiv.org/find/cs/1/au:+Beznosikov_A/0/1/0/all/0/1">Aleksandr Beznosikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadiev_A/0/1/0/all/0/1">Abdurakhmon Sadiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sushko_V/0/1/0/all/0/1">Vadim Sushko</a>, <a href="http://arxiv.org/find/cs/1/au:+Savelyev_N/0/1/0/all/0/1">Nikolay Savelyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1">Martin Tak&#xe1;&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasnikov_A/0/1/0/all/0/1">Alexander Gasnikov</a></p>
<p>Personalized Federated Learning (PFL) has witnessed remarkable advancements,
enabling the development of innovative machine learning applications that
preserve the privacy of training data. However, existing theoretical research
in this field has primarily focused on distributed optimization for
minimization problems. This paper is the first to study PFL for saddle point
problems encompassing a broader range of optimization problems, that require
more than just solving minimization problems. In this work, we consider a
recently proposed PFL setting with the mixing objective function, an approach
combining the learning of a global model together with locally distributed
learners. Unlike most previous work, which considered only the centralized
setting, we work in a more general and decentralized setup that allows us to
design and analyze more practical and federated ways to connect devices to the
network. We proposed new algorithms to address this problem and provide a
theoretical analysis of the smooth (strongly) convex-(strongly) concave saddle
point problems in stochastic and deterministic cases. Numerical experiments for
bilinear problems and neural networks with adversarial noise demonstrate the
effectiveness of the proposed methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.13883">Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities. (arXiv:2203.13883v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1">Sara Abdali</a>, <a href="http://arxiv.org/find/cs/1/au:+shaham_S/0/1/0/all/0/1">Sina shaham</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamachari_B/0/1/0/all/0/1">Bhaskar Krishnamachari</a></p>
<p>As social media platforms are evolving from text-based forums into
multi-modal environments, the nature of misinformation in social media is also
transforming accordingly. Taking advantage of the fact that visual modalities
such as images and videos are more favorable and attractive to the users and
textual contents are sometimes skimmed carelessly, misinformation spreaders
have recently targeted contextual connections between the modalities e.g., text
and image. Hence many researchers have developed automatic techniques for
detecting possible cross-modal discordance in web-based content. We analyze,
categorize and identify existing approaches in addition to challenges and
shortcomings they face in order to unearth new research opportunities in the
field of multi-modal misinformation detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.06009">Relative Policy-Transition Optimization for Fast Policy Transfer. (arXiv:2206.06009v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiawei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Cheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baoxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lei Han</a></p>
<p>We consider the problem of policy transfer between two Markov Decision
Processes (MDPs). We introduce a lemma based on existing theoretical results in
reinforcement learning to measure the relativity gap between two arbitrary
MDPs, that is the difference between any two cumulative expected returns
defined on different policies and environment dynamics. Based on this lemma, we
propose two new algorithms referred to as Relative Policy Optimization (RPO)
and Relative Transition Optimization (RTO), which offer fast policy transfer
and dynamics modelling, respectively. RPO transfers the policy evaluated in one
environment to maximize the return in another, while RTO updates the
parameterized dynamics model to reduce the gap between the dynamics of the two
environments. Integrating the two algorithms results in the complete Relative
Policy-Transition Optimization (RPTO) algorithm, in which the policy interacts
with the two environments simultaneously, such that data collections from two
environments, policy and transition updates are completed in one closed loop to
form a principled learning framework for policy transfer. We demonstrate the
effectiveness of RPTO on a set of MuJoCo continuous control tasks by creating
policy transfer problems via variant dynamics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.14359">TE2Rules: Explaining Tree Ensembles using Rules. (arXiv:2206.14359v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lal_G/0/1/0/all/0/1">G Roshan Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaotong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mithal_V/0/1/0/all/0/1">Varun Mithal</a></p>
<p>Tree Ensemble (TE) models, such as Gradient Boosted Trees, often achieve
optimal performance on tabular datasets, yet their lack of transparency poses
challenges for comprehending their decision logic. This paper introduces
TE2Rules (Tree Ensemble to Rules), a novel approach for explaining binary
classification tree ensemble models through a list of rules, particularly
focusing on explaining the minority class. Many state-of-the-art explainers
struggle with minority class explanations, making TE2Rules valuable in such
cases. The rules generated by TE2Rules closely approximate the original model,
ensuring high fidelity, providing an accurate and interpretable means to
understand decision-making. Experimental results demonstrate that TE2Rules
scales effectively to tree ensembles with hundreds of trees, achieving higher
fidelity within runtimes comparable to baselines. TE2Rules allows for a
trade-off between runtime and fidelity, enhancing its practical applicability.
The implementation is available here: https://github.com/linkedin/TE2Rules.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.02389">Risk-Aware Linear Bandits: Theory and Applications in Smart Order Routing. (arXiv:2208.02389v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jingwei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Renyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Ruihao Zhu</a></p>
<p>Motivated by practical considerations in machine learning for financial
decision-making, such as risk aversion and large action space, we consider
risk-aware bandits optimization with applications in smart order routing (SOR).
Specifically, based on preliminary observations of linear price impacts made
from the NASDAQ ITCH dataset, we initiate the study of risk-aware linear
bandits. In this setting, we aim at minimizing regret, which measures our
performance deficit compared to the optimum's, under the mean-variance metric
when facing a set of actions whose rewards are linear functions of (initially)
unknown parameters. Driven by the variance-minimizing globally-optimal
(G-optimal) design, we propose the novel instance-independent Risk-Aware
Explore-then-Commit (RISE) algorithm and the instance-dependent Risk-Aware
Successive Elimination (RISE++) algorithm. Then, we rigorously analyze their
near-optimal regret upper bounds to show that, by leveraging the linear
structure, our algorithms can dramatically reduce the regret when compared to
existing methods. Finally, we demonstrate the performance of the algorithms by
conducting extensive numerical experiments in the SOR setup using both
synthetic datasets and the NASDAQ ITCH dataset. Our results reveal that 1) The
linear structure assumption can indeed be well supported by the Nasdaq dataset;
and more importantly 2) Both RISE and RISE++ can significantly outperform the
competing methods, in terms of regret, especially in complex decision-making
scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08262">A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v4 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Saves_P/0/1/0/all/0/1">P. Saves</a>, <a href="http://arxiv.org/find/math/1/au:+Diouane_Y/0/1/0/all/0/1">Y. Diouane</a>, <a href="http://arxiv.org/find/math/1/au:+Bartoli_N/0/1/0/all/0/1">N. Bartoli</a>, <a href="http://arxiv.org/find/math/1/au:+Lefebvre_T/0/1/0/all/0/1">T. Lefebvre</a>, <a href="http://arxiv.org/find/math/1/au:+Morlier_J/0/1/0/all/0/1">J. Morlier</a></p>
<p>Recently, there has been a growing interest for mixed-categorical meta-models
based on Gaussian process (GP) surrogates. In this setting, several existing
approaches use different strategies either by using continuous kernels (e.g.,
continuous relaxation and Gower distance based GP) or by using a direct
estimation of the correlation matrix. In this paper, we present a kernel-based
approach that extends continuous exponential kernels to handle
mixed-categorical variables. The proposed kernel leads to a new GP surrogate
that generalizes both the continuous relaxation and the Gower distance based GP
models. We demonstrate, on both analytical and engineering problems, that our
proposed GP model gives a higher likelihood and a smaller residual error than
the other kernel-based state-of-the-art models. Our method is available in the
open-source software SMT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.10227">Adversarial Detection by Approximation of Ensemble Boundary. (arXiv:2211.10227v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Windeatt_T/0/1/0/all/0/1">T. Windeatt</a></p>
<p>A new method of detecting adversarial attacks is proposed for an ensemble of
Deep Neural Networks (DNNs) solving two-class pattern recognition problems. The
ensemble is combined using Walsh coefficients which are capable of
approximating Boolean functions and thereby controlling the complexity of the
ensemble decision boundary. The hypothesis in this paper is that decision
boundaries with high curvature allow adversarial perturbations to be found, but
change the curvature of the decision boundary, which is then approximated in a
different way by Walsh coefficients compared to the clean images. By observing
the difference in Walsh coefficient approximation between clean and adversarial
images, it is shown experimentally that transferability of attack may be used
for detection. Furthermore, approximating the decision boundary may aid in
understanding the learning and transferability properties of DNNs. While the
experiments here use images, the proposed approach of modelling two-class
ensemble decision boundaries could in principle be applied to any application
area. Code for approximating Boolean functions using Walsh coefficients:
https://doi.org/10.24433/CO.3695905.v1
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.12343">Diffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems. (arXiv:2211.12343v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1">Xiangming Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kabashima_Y/0/1/0/all/0/1">Yoshiyuki Kabashima</a></p>
<p>We consider the ubiquitous linear inverse problems with additive Gaussian
noise and propose an unsupervised sampling approach called diffusion model
based posterior sampling (DMPS) to reconstruct the unknown signal from noisy
linear measurements. Specifically, using one diffusion model (DM) as an
implicit prior, the fundamental difficulty in performing posterior sampling is
that the noise-perturbed likelihood score, i.e., gradient of an annealed
likelihood function, is intractable. To circumvent this problem, we introduce a
simple yet effective closed-form approximation using an uninformative prior
assumption. Extensive experiments are conducted on a variety of noisy linear
inverse problems such as noisy super-resolution, denoising, deblurring, and
colorization. In all tasks, the proposed DMPS demonstrates highly competitive
or even better performances on various tasks while being 3 times faster than
the state-of-the-art competitor diffusion posterior sampling (DPS).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.01068">Fast Algorithm for Constrained Linear Inverse Problems. (arXiv:2212.01068v6 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Sheriff_M/0/1/0/all/0/1">Mohammed Rayyan Sheriff</a>, <a href="http://arxiv.org/find/math/1/au:+Redel_F/0/1/0/all/0/1">Floor Fenne Redel</a>, <a href="http://arxiv.org/find/math/1/au:+Esfahani_P/0/1/0/all/0/1">Peyman Mohajerin Esfahani</a></p>
<p>We consider the constrained Linear Inverse Problem (LIP), where a certain
atomic norm (like the $\ell_1 $ norm) is minimized subject to a quadratic
constraint. Typically, such cost functions are non-differentiable which makes
them not amenable to the fast optimization methods existing in practice. We
propose two equivalent reformulations of the constrained LIP with improved
convex regularity: (i) a smooth convex minimization problem, and (ii) a
strongly convex min-max problem. These problems could be solved by applying
existing acceleration-based convex optimization methods which provide better $
O \left( \frac{1}{k^2} \right) $ theoretical convergence guarantee, improving
upon the current best rate of $ O \left( \frac{1}{k} \right) $. We also provide
a novel algorithm named the Fast Linear Inverse Problem Solver (FLIPS), which
is tailored to maximally exploit the structure of the reformulations. We
demonstrate the performance of FLIPS on the classical problems of Binary
Selection, Compressed Sensing, and Image Denoising. We also provide open source
\texttt{MATLAB} package for these three examples, which can be easily adapted
to other LIPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.02344">TrojanPuzzle: Covertly Poisoning Code-Suggestion Models. (arXiv:2301.02344v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aghakhani_H/0/1/0/all/0/1">Hojjat Aghakhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wei Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Manoel_A/0/1/0/all/0/1">Andre Manoel</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_X/0/1/0/all/0/1">Xavier Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharkar_A/0/1/0/all/0/1">Anant Kharkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kruegel_C/0/1/0/all/0/1">Christopher Kruegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vigna_G/0/1/0/all/0/1">Giovanni Vigna</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1">David Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Zorn_B/0/1/0/all/0/1">Ben Zorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1">Robert Sim</a></p>
<p>With tools like GitHub Copilot, automatic code suggestion is no longer a
dream in software engineering. These tools, based on large language models, are
typically trained on massive corpora of code mined from unvetted public
sources. As a result, these models are susceptible to data poisoning attacks
where an adversary manipulates the model's training by injecting malicious
data. Poisoning attacks could be designed to influence the model's suggestions
at run time for chosen contexts, such as inducing the model into suggesting
insecure code payloads. To achieve this, prior attacks explicitly inject the
insecure code payload into the training data, making the poison data detectable
by static analysis tools that can remove such malicious data from the training
set. In this work, we demonstrate two novel attacks, COVERT and TROJANPUZZLE,
that can bypass static analysis by planting malicious poison data in
out-of-context regions such as docstrings. Our most novel attack, TROJANPUZZLE,
goes one step further in generating less suspicious poison data by never
explicitly including certain (suspicious) parts of the payload in the poison
data, while still inducing a model that suggests the entire payload when
completing code (i.e., outside docstrings). This makes TROJANPUZZLE robust
against signature-based dataset-cleansing methods that can filter out
suspicious sequences from the training data. Our evaluation against models of
two sizes demonstrates that both COVERT and TROJANPUZZLE have significant
implications for practitioners when selecting code used to train or tune
code-suggestion models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.11824">PECAN: A Deterministic Certified Defense Against Backdoor Attacks. (arXiv:2301.11824v3 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Albarghouthi_A/0/1/0/all/0/1">Aws Albarghouthi</a>, <a href="http://arxiv.org/find/cs/1/au:+DAntoni_L/0/1/0/all/0/1">Loris D&#x27;Antoni</a></p>
<p>Neural networks are vulnerable to backdoor poisoning attacks, where the
attackers maliciously poison the training set and insert triggers into the test
input to change the prediction of the victim model. Existing defenses for
backdoor attacks either provide no formal guarantees or come with
expensive-to-compute and ineffective probabilistic guarantees. We present
PECAN, an efficient and certified approach for defending against backdoor
attacks. The key insight powering PECAN is to apply off-the-shelf test-time
evasion certification techniques on a set of neural networks trained on
disjoint partitions of the data. We evaluate PECAN on image classification and
malware detection datasets. Our results demonstrate that PECAN can (1)
significantly outperform the state-of-the-art certified backdoor defense, both
in defense strength and efficiency, and (2) on real back-door attacks, PECAN
can reduce attack success rate by order of magnitude when compared to a range
of baselines from the literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.08298">Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization. (arXiv:2302.08298v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiayu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Renyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1">Shenghao Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zheng Wang</a></p>
<p>Bayesian optimization (BO) is widely used to optimize expensive-to-evaluate
black-box functions.BO first builds a surrogate model to represent the
objective function and assesses its uncertainty. It then decides where to
sample by maximizing an acquisition function (AF) based on the surrogate model.
However, when dealing with high-dimensional problems, finding the global
maximum of the AF becomes increasingly challenging. In such cases, the
initialization of the AF maximizer plays a pivotal role, as an inadequate setup
can severely hinder the effectiveness of the AF.
</p>
<p>This paper investigates a largely understudied problem concerning the impact
of AF maximizer initialization on exploiting AFs' capability. Our large-scale
empirical study shows that the widely used random initialization strategy often
fails to harness the potential of an AF. In light of this, we propose a better
initialization approach by employing multiple heuristic optimizers to leverage
the historical data of black-box optimization to generate initial points for
the AF maximize. We evaluate our approach with a range of heavily studied
synthetic functions and real-world applications. Experimental results show that
our techniques, while simple, can significantly enhance the standard BO and
outperform state-of-the-art methods by a large margin in most test cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.12838">A Multimodal Graph Neural Network Framework of Cancer Molecular Subtype Classification. (arXiv:2302.12838v2 [q-bio.GN] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Li_B/0/1/0/all/0/1">Bingjun Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Nabavi_S/0/1/0/all/0/1">Sheida Nabavi</a></p>
<p>The recent development of high-throughput sequencing creates a large
collection of multi-omics data, which enables researchers to better investigate
cancer molecular profiles and cancer taxonomy based on molecular subtypes.
Integrating multi-omics data has been proven to be effective for building more
precise classification models. Current multi-omics integrative models mainly
use early fusion by concatenation or late fusion based on deep neural networks.
Due to the nature of biological systems, graphs are a better representation of
bio-medical data. Although few graph neural network (GNN) based multi-omics
integrative methods have been proposed, they suffer from three common
disadvantages. One is most of them use only one type of connection, either
inter-omics or intra-omic connection; second, they only consider one kind of
GNN layer, either graph convolution network (GCN) or graph attention network
(GAT); and third, most of these methods lack testing on a more complex cancer
classification task. We propose a novel end-to-end multi-omics GNN framework
for accurate and robust cancer subtype classification. The proposed model
utilizes multi-omics data in the form of heterogeneous multi-layer graphs that
combines both inter-omics and intra-omic connections from established
biological knowledge. The proposed model incorporates learned graph features
and global genome features for accurate classification. We test the proposed
model on TCGA Pan-cancer dataset and TCGA breast cancer dataset for molecular
subtype and cancer subtype classification, respectively. The proposed model
outperforms four current state-of-the-art baseline models in multiple
evaluation metrics. The comparative analysis of GAT-based models and GCN-based
models reveals that GAT-based models are preferred for smaller graphs with less
information and GCN-based models are preferred for larger graphs with extra
information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.13711">Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters. (arXiv:2302.13711v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arts_M/0/1/0/all/0/1">Marloes Arts</a>, <a href="http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1">Jes Frellsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Boomsma_W/0/1/0/all/0/1">Wouter Boomsma</a></p>
<p>After the recent ground-breaking advances in protein structure prediction,
one of the remaining challenges in protein machine learning is to reliably
predict distributions of structural states. Parametric models of fluctuations
are difficult to fit due to complex covariance structures between degrees of
freedom in the protein chain, often causing models to either violate local or
global structural constraints. In this paper, we present a new strategy for
modelling protein densities in internal coordinates, which uses constraints in
3D space to induce covariance structure between the internal degrees of
freedom. We illustrate the potential of the procedure by constructing a
variational autoencoder with full covariance output induced by the constraints
implied by the conditional mean in 3D, and demonstrate that our approach makes
it possible to scale density models of internal coordinates to full protein
backbones in two settings: 1) a unimodal setting for proteins exhibiting small
fluctuations and limited amounts of available data, and 2) a multimodal setting
for larger conformational changes in a high data regime.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.14648">Digital Over-the-Air Federated Learning in Multi-Antenna Systems. (arXiv:2302.14648v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sihua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingzhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Cong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Changchuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1">Christopher G. Brinton</a></p>
<p>In this paper, the performance optimization of federated learning (FL), when
deployed over a realistic wireless multiple-input multiple-output (MIMO)
communication system with digital modulation and over-the-air computation
(AirComp) is studied. In particular, a MIMO system is considered in which edge
devices transmit their local FL models (trained using their locally collected
data) to a parameter server (PS) using beamforming to maximize the number of
devices scheduled for transmission. The PS, acting as a central controller,
generates a global FL model using the received local FL models and broadcasts
it back to all devices. Due to the limited bandwidth in a wireless network,
AirComp is adopted to enable efficient wireless data aggregation. However,
fading of wireless channels can produce aggregate distortions in an
AirComp-based FL scheme. To tackle this challenge, we propose a modified
federated averaging (FedAvg) algorithm that combines digital modulation with
AirComp to mitigate wireless fading while ensuring the communication
efficiency. This is achieved by a joint transmit and receive beamforming
design, which is formulated as an optimization problem to dynamically adjust
the beamforming matrices based on current FL model parameters so as to minimize
the transmitting error and ensure the FL performance. To achieve this goal, we
first analytically characterize how the beamforming matrices affect the
performance of the FedAvg in different iterations. Based on this relationship,
an artificial neural network (ANN) is used to estimate the local FL models of
all devices and adjust the beamforming matrices at the PS for future model
transmission. The algorithmic advantages and improved performance of the
proposed methodologies are demonstrated through extensive numerical
experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.04878">DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks. (arXiv:2303.04878v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aghababaeyan_Z/0/1/0/all/0/1">Zohreh Aghababaeyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdellatif_M/0/1/0/all/0/1">Manel Abdellatif</a>, <a href="http://arxiv.org/find/cs/1/au:+Dadkhah_M/0/1/0/all/0/1">Mahboubeh Dadkhah</a>, <a href="http://arxiv.org/find/cs/1/au:+Briand_L/0/1/0/all/0/1">Lionel Briand</a></p>
<p>Deep neural networks (DNNs) are widely used in various application domains
such as image processing, speech recognition, and natural language processing.
However, testing DNN models may be challenging due to the complexity and size
of their input domain. Particularly, testing DNN models often requires
generating or exploring large unlabeled datasets. In practice, DNN test
oracles, which identify the correct outputs for inputs, often require expensive
manual effort to label test data, possibly involving multiple experts to ensure
labeling correctness. In this paper, we propose DeepGD, a black-box
multi-objective test selection approach for DNN models. It reduces the cost of
labeling by prioritizing the selection of test inputs with high fault revealing
power from large unlabeled datasets. DeepGD not only selects test inputs with
high uncertainty scores to trigger as many mispredicted inputs as possible but
also maximizes the probability of revealing distinct faults in the DNN model by
selecting diverse mispredicted inputs. The experimental results conducted on
four widely used datasets and five DNN models show that in terms of
fault-revealing ability: (1) White-box, coverage-based approaches fare poorly,
(2) DeepGD outperforms existing black-box test selection approaches in terms of
fault detection, and (3) DeepGD also leads to better guidance for DNN model
retraining when using selected inputs to augment the training set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.09599">cito: An R package for training neural networks using torch. (arXiv:2303.09599v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amesoeder_C/0/1/0/all/0/1">Christian Amesoeder</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartig_F/0/1/0/all/0/1">Florian Hartig</a>, <a href="http://arxiv.org/find/cs/1/au:+Pichler_M/0/1/0/all/0/1">Maximilian Pichler</a></p>
<p>Deep Neural Networks (DNN) have become a central method in ecology. Most
current deep learning (DL) applications rely on one of the major deep learning
frameworks, in particular Torch or TensorFlow, to build and train DNN. Using
these frameworks, however, requires substantially more experience and time than
typical regression functions in the R environment. Here, we present 'cito', a
user-friendly R package for DL that allows specifying DNNs in the familiar
formula syntax used by many R packages. To fit the models, 'cito' uses 'torch',
taking advantage of the numerically optimized torch library, including the
ability to switch between training models on the CPU or the graphics processing
unit (GPU) (which allows to efficiently train large DNN). Moreover, 'cito'
includes many user-friendly functions for model plotting and analysis,
including optional confidence intervals (CIs) based on bootstraps for
predictions and explainable AI (xAI) metrics for effect sizes and variable
importance with CIs and p-values. To showcase a typical analysis pipeline using
'cito', including its built-in xAI features to explore the trained DNN, we
build a species distribution model of the African elephant. We hope that by
providing a user-friendly R framework to specify, deploy and interpret DNN,
'cito' will make this interesting model class more accessible to ecological
data analysis. A stable version of 'cito' can be installed from the
comprehensive R archive network (CRAN).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10728">Training Deep Boltzmann Networks with Sparse Ising Machines. (arXiv:2303.10728v2 [cs.ET] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Niazi_S/0/1/0/all/0/1">Shaila Niazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Aadit_N/0/1/0/all/0/1">Navid Anjum Aadit</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohseni_M/0/1/0/all/0/1">Masoud Mohseni</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shuvro Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Camsari_K/0/1/0/all/0/1">Kerem Y. Camsari</a></p>
<p>The slowing down of Moore's law has driven the development of unconventional
computing paradigms, such as specialized Ising machines tailored to solve
combinatorial optimization problems. In this paper, we show a new application
domain for probabilistic bit (p-bit) based Ising machines by training deep
generative AI models with them. Using sparse, asynchronous, and massively
parallel Ising machines we train deep Boltzmann networks in a hybrid
probabilistic-classical computing setup. We use the full MNIST and Fashion
MNIST (FMNIST) dataset without any downsampling and a reduced version of
CIFAR-10 dataset in hardware-aware network topologies implemented in moderately
sized Field Programmable Gate Arrays (FPGA). For MNIST, our machine using only
4,264 nodes (p-bits) and about 30,000 parameters achieves the same
classification accuracy (90%) as an optimized software-based restricted
Boltzmann Machine (RBM) with approximately 3.25 million parameters. Similar
results follow for FMNIST and CIFAR-10. Additionally, the sparse deep Boltzmann
network can generate new handwritten digits and fashion products, a task the
3.25 million parameter RBM fails at despite achieving the same accuracy. Our
hybrid computer takes a measured 50 to 64 billion probabilistic flips per
second, which is at least an order of magnitude faster than superficially
similar Graphics and Tensor Processing Unit (GPU/TPU) based implementations.
The massively parallel architecture can comfortably perform the contrastive
divergence algorithm (CD-n) with up to n = 10 million sweeps per update, beyond
the capabilities of existing software implementations. These results
demonstrate the potential of using Ising machines for traditionally
hard-to-train deep generative Boltzmann networks, with further possible
improvement in nanodevice-based realizations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.15991">Efficient Parallel Split Learning over Resource-constrained Wireless Edge Networks. (arXiv:2303.15991v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1">Guangyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yiqin Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xianhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaibin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuguang Fang</a></p>
<p>The increasingly deeper neural networks hinder the democratization of
privacy-enhancing distributed learning, such as federated learning (FL), to
resource-constrained devices. To overcome this challenge, in this paper, we
advocate the integration of edge computing paradigm and parallel split learning
(PSL), allowing multiple client devices to offload substantial training
workloads to an edge server via layer-wise model split. By observing that
existing PSL schemes incur excessive training latency and large volume of data
transmissions, we propose an innovative PSL framework, namely, efficient
parallel split learning (EPSL), to accelerate model training. To be specific,
EPSL parallelizes client-side model training and reduces the dimension of local
gradients for back propagation (BP) via last-layer gradient aggregation,
leading to a significant reduction in server-side training and communication
latency. Moreover, by considering the heterogeneous channel conditions and
computing capabilities at client devices, we jointly optimize subchannel
allocation, power control, and cut layer selection to minimize the per-round
latency. Simulation results show that the proposed EPSL framework significantly
decreases the training latency needed to achieve a target accuracy compared
with the state-of-the-art benchmarks, and the tailored resource management and
layer split strategy can considerably reduce latency than the counterpart
without optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.03468">Toward Practical Entity Alignment Method Design: Insights from New Highly Heterogeneous Knowledge Graph Datasets. (arXiv:2304.03468v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xuhui Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chengjin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yinghan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuanzhuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_F/0/1/0/all/0/1">Fenglong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zixuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhichao Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huawei Shen</a></p>
<p>The flourishing of knowledge graph applications has driven the need for
entity alignment (EA) across KGs. However, the heterogeneity of practical KGs,
characterized by differing scales, structures, and limited overlapping
entities, greatly surpasses that of existing EA datasets. This discrepancy
highlights an oversimplified heterogeneity in current EA datasets, which
obstructs a full understanding of the advancements achieved by recent EA
methods. In this paper, we study the performance of EA methods in practical
settings, specifically focusing on the alignment of highly heterogeneous KGs
(HHKGs). Firstly, we address the oversimplified heterogeneity settings of
current datasets and propose two new HHKG datasets that closely mimic practical
EA scenarios. Then, based on these datasets, we conduct extensive experiments
to evaluate previous representative EA methods. Our findings reveal that, in
aligning HHKGs, valuable structure information can hardly be exploited through
message-passing and aggregation mechanisms. This phenomenon leads to inferior
performance of existing EA methods, especially those based on GNNs. These
findings shed light on the potential problems associated with the conventional
application of GNN-based methods as a panacea for all EA datasets.
Consequently, in light of these observations and to elucidate what EA
methodology is genuinely beneficial in practical scenarios, we undertake an
in-depth analysis by implementing a simple but effective approach: Simple-HHEA.
This method adaptly integrates entity name, structure, and temporal information
to navigate the challenges posed by HHKGs. Our experiment results conclude that
the key to the future EA model design in practice lies in their adaptability
and efficiency to varying information quality conditions, as well as their
capability to capture patterns across HHKGs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.00557">Collective Relational Inference for learning heterogeneous interactions. (arXiv:2305.00557v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhichao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Fink_O/0/1/0/all/0/1">Olga Fink</a>, <a href="http://arxiv.org/find/cs/1/au:+Kammer_D/0/1/0/all/0/1">David S. Kammer</a></p>
<p>Interacting systems are ubiquitous in nature and engineering, ranging from
particle dynamics in physics to functionally connected brain regions. These
interacting systems can be modeled by graphs where edges correspond to the
interactions between interactive entities. Revealing interaction laws is of
fundamental importance but also particularly challenging due to underlying
configurational complexities. The associated challenges become exacerbated for
heterogeneous systems that are prevalent in reality, where multiple interaction
types coexist simultaneously and relational inference is required. Here, we
propose a novel probabilistic method for relational inference, which possesses
two distinctive characteristics compared to existing methods. First, it infers
the interaction types of different edges collectively by explicitly encoding
the correlation among incoming interactions with a joint distribution, and
second, it allows handling systems with variable topological structure over
time. We evaluate the proposed methodology across several benchmark datasets
and demonstrate that it outperforms existing methods in accurately inferring
interaction types. We further show that when combined with known constraints,
it allows us, for example, to discover physics-consistent interaction laws of
particle systems. Overall the proposed model is data-efficient and
generalizable to large systems when trained on smaller ones. The developed
methodology constitutes a key element for understanding interacting systems and
may find application in graph structure learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02803">Tensor PCA from basis in tensor space. (arXiv:2305.02803v3 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Turchetti_C/0/1/0/all/0/1">Claudio Turchetti</a>, <a href="http://arxiv.org/find/math/1/au:+Falaschetti_L/0/1/0/all/0/1">Laura Falaschetti</a></p>
<p>The aim of this paper is to present a mathematical framework for tensor PCA.
The proposed approach is able to overcome the limitations of previous methods
that extract a low dimensional subspace by iteratively solving an optimization
problem. The core of the proposed approach is the derivation of a basis in
tensor space from a real self-adjoint tensor operator, thus reducing the
problem of deriving a basis to an eigenvalue problem. Three different cases
have been studied to derive: i) a basis from a self-adjoint tensor operator;
ii) a rank-1 basis; iii) a basis in a subspace. In particular, the equivalence
between eigenvalue equation for a real self-adjoint tensor operator and
standard matrix eigenvalue equation has been proven. For all the three cases
considered, a subspace approach has been adopted to derive a tensor PCA.
Experiments on image datasets validate the proposed mathematical framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.07730">Learning in Inverse Optimization: Incenter Cost, Augmented Suboptimality Loss, and Algorithms. (arXiv:2305.07730v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Scroccaro_P/0/1/0/all/0/1">Pedro Zattoni Scroccaro</a>, <a href="http://arxiv.org/find/math/1/au:+Atasoy_B/0/1/0/all/0/1">Bilge Atasoy</a>, <a href="http://arxiv.org/find/math/1/au:+Esfahani_P/0/1/0/all/0/1">Peyman Mohajerin Esfahani</a></p>
<p>In Inverse Optimization (IO), an expert agent solves an optimization problem
parametric in an exogenous signal. From a learning perspective, the goal is to
learn the expert's cost function given a dataset of signals and corresponding
optimal actions. Motivated by the geometry of the IO set of consistent cost
vectors, we introduce the "incenter" concept, a new notion akin to circumcenter
recently proposed by Besbes et al. (2023). Discussing the geometric and
robustness interpretation of the incenter cost vector, we develop corresponding
tractable convex reformulations, which are in contrast with the circumcenter,
which we show is equivalent to an intractable optimization program. We further
propose a novel loss function called Augmented Suboptimality Loss (ASL), a
relaxation of the incenter concept for problems with inconsistent data.
Exploiting the structure of the ASL, we propose a novel first-order algorithm,
which we name Stochastic Approximate Mirror Descent. This algorithm combines
stochastic and approximate subgradient evaluations, together with mirror
descent update steps, which is provably efficient for the IO problems with
discrete feasible sets with high cardinality. We implement the IO approaches
developed in this paper as a Python package called InvOpt. Our numerical
experiments are reproducible, and the underlying source code is available as
examples in the InvOpt package.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13998">SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and Mixed Variables Gaussian Processes. (arXiv:2305.13998v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saves_P/0/1/0/all/0/1">Paul Saves</a>, <a href="http://arxiv.org/find/cs/1/au:+Lafage_R/0/1/0/all/0/1">Remi Lafage</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartoli_N/0/1/0/all/0/1">Nathalie Bartoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Diouane_Y/0/1/0/all/0/1">Youssef Diouane</a>, <a href="http://arxiv.org/find/cs/1/au:+Bussemaker_J/0/1/0/all/0/1">Jasper Bussemaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lefebvre_T/0/1/0/all/0/1">Thierry Lefebvre</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">John T. Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Morlier_J/0/1/0/all/0/1">Joseph Morlier</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_J/0/1/0/all/0/1">Joaquim R. R. A. Martins</a></p>
<p>The Surrogate Modeling Toolbox (SMT) is an open-source Python package that
offers a collection of surrogate modeling methods, sampling techniques, and a
set of sample problems. This paper presents SMT 2.0, a major new release of SMT
that introduces significant upgrades and new features to the toolbox. This
release adds the capability to handle mixed-variable surrogate models and
hierarchical variables. These types of variables are becoming increasingly
important in several surrogate modeling applications. SMT 2.0 also improves SMT
by extending sampling methods, adding new surrogate models, and computing
variance and kernel derivatives for Kriging. This release also includes new
functions to handle noisy and use multifidelity data. To the best of our
knowledge, SMT 2.0 is the first open-source surrogate library to propose
surrogate models for hierarchical and mixed inputs. This open-source software
is distributed under the New BSD license.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15901">Consistent Optimal Transport with Empirical Conditional Measures. (arXiv:2305.15901v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manupriya_P/0/1/0/all/0/1">Piyushi Manupriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1">Rachit Keerti Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sayantan Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagarlapudi_S/0/1/0/all/0/1">Saketha Nath Jagarlapudi</a></p>
<p>Given samples from two joint distributions, we consider the problem of
Optimal Transportation (OT) between them when conditioned on a common variable.
We focus on the general setting where the conditioned variable may be
continuous, and the marginals of this variable in the two joint distributions
may not be the same. In such settings, standard OT variants cannot be employed,
and novel estimation techniques are necessary. Since the main challenge is that
the conditional distributions are not explicitly available, the key idea in our
OT formulation is to employ kernelized-least-squares terms computed over the
joint samples, which implicitly match the transport plan's marginals with the
empirical conditionals. Under mild conditions, we prove that our estimated
transport plans, as a function of the conditioned variable, are asymptotically
optimal. For finite samples, we show that the deviation in terms of our
regularized objective is bounded by $O(1/m^{1/4})$, where $m$ is the number of
samples. We also discuss how the conditional transport plan could be modelled
using explicit probabilistic models as well as using implicit generative ones.
We empirically verify the consistency of our estimator on synthetic datasets,
where the optimal plan is analytically known. When employed in applications
like prompt learning for few-shot classification and conditional-generation in
the context of predicting cell responses to treatment, our methodology improves
upon state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15936">Learning DAGs from Data with Few Root Causes. (arXiv:2305.15936v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Misiakos_P/0/1/0/all/0/1">Panagiotis Misiakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wendler_C/0/1/0/all/0/1">Chris Wendler</a>, <a href="http://arxiv.org/find/cs/1/au:+Puschel_M/0/1/0/all/0/1">Markus P&#xfc;schel</a></p>
<p>We present a novel perspective and algorithm for learning directed acyclic
graphs (DAGs) from data generated by a linear structural equation model (SEM).
First, we show that a linear SEM can be viewed as a linear transform that, in
prior work, computes the data from a dense input vector of random valued root
causes (as we will call them) associated with the nodes. Instead, we consider
the case of (approximately) few root causes and also introduce noise in the
measurement of the data. Intuitively, this means that the DAG data is produced
by few data-generating events whose effect percolates through the DAG. We prove
identifiability in this new setting and show that the true DAG is the global
minimizer of the $L^0$-norm of the vector of root causes. For data with few
root causes, with and without noise, we show superior performance compared to
prior DAG learning methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.08013">TopP&amp;R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models. (arXiv:2306.08013v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_P/0/1/0/all/0/1">Pum Jun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_Y/0/1/0/all/0/1">Yoojin Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jisu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1">Jaejun Yoo</a></p>
<p>We propose a robust and reliable evaluation metric for generative models by
introducing topological and statistical treatments for rigorous support
estimation. Existing metrics, such as Inception Score (IS), Frechet Inception
Distance (FID), and the variants of Precision and Recall (P&amp;R), heavily rely on
supports that are estimated from sample features. However, the reliability of
their estimation has not been seriously discussed (and overlooked) even though
the quality of the evaluation entirely depends on it. In this paper, we propose
Topological Precision and Recall (TopP&amp;R, pronounced 'topper'), which provides
a systematic approach to estimating supports, retaining only topologically and
statistically important features with a certain level of confidence. This not
only makes TopP&amp;R strong for noisy features, but also provides statistical
consistency. Our theoretical and experimental results show that TopP&amp;R is
robust to outliers and non-independent and identically distributed (Non-IID)
perturbations, while accurately capturing the true trend of change in samples.
To the best of our knowledge, this is the first evaluation metric focused on
the robust estimation of the support and provides its statistical consistency
under noise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09205">Reward-Free Curricula for Training Robust World Models. (arXiv:2306.09205v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rigter_M/0/1/0/all/0/1">Marc Rigter</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Minqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Posner_I/0/1/0/all/0/1">Ingmar Posner</a></p>
<p>There has been a recent surge of interest in developing generally-capable
agents that can adapt to new tasks without additional training in the
environment. Learning world models from reward-free exploration is a promising
approach, and enables policies to be trained using imagined experience for new
tasks. However, achieving a general agent requires robustness across different
environments. In this work, we address the novel problem of generating
curricula in the reward-free setting to train robust world models. We consider
robustness in terms of minimax regret over all environment instantiations and
show that the minimax regret can be connected to minimising the maximum error
in the world model across environment instances. This result informs our
algorithm, WAKER: Weighted Acquisition of Knowledge across Environments for
Robustness. WAKER selects environments for data collection based on the
estimated error of the world model for each environment. Our experiments
demonstrate that WAKER outperforms several baselines, resulting in improved
robustness, efficiency, and generalisation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09800">$\pi2\text{vec}$: Policy Representations with Successor Features. (arXiv:2306.09800v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Scarpellini_G/0/1/0/all/0/1">Gianluca Scarpellini</a>, <a href="http://arxiv.org/find/cs/1/au:+Konyushkova_K/0/1/0/all/0/1">Ksenia Konyushkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Fantacci_C/0/1/0/all/0/1">Claudio Fantacci</a>, <a href="http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1">Tom Le Paine</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yutian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Denil_M/0/1/0/all/0/1">Misha Denil</a></p>
<p>This paper describes $\pi2\text{vec}$, a method for representing behaviors of
black box policies as feature vectors. The policy representations capture how
the statistics of foundation model features change in response to the policy
behavior in a task agnostic way, and can be trained from offline data, allowing
them to be used in offline policy selection. This work provides a key piece of
a recipe for fusing together three modern lines of research: Offline policy
evaluation as a counterpart to offline RL, foundation models as generic and
powerful state representations, and efficient policy selection in resource
constrained environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12194">Split Learning in 6G Edge Networks. (arXiv:2306.12194v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_G/0/1/0/all/0/1">Guanqiao Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xianhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaibin Huang</a></p>
<p>With the proliferation of distributed edge computing resources, the 6G mobile
network will evolve into a network for connected intelligence. Along this line,
the proposal to incorporate federated learning into the mobile edge has gained
considerable interest in recent years. However, the deployment of federated
learning faces substantial challenges as massive resource-limited IoT devices
can hardly support on-device model training. This leads to the emergence of
split learning (SL) which enables servers to handle the major training workload
while still enhancing data privacy. In this article, we offer a brief overview
of key advancements in SL and articulate its seamless integration with wireless
edge networks. We begin by illustrating the tailored 6G architecture to support
edge SL. Then, we examine the critical design issues for edge SL, including
innovative resource-efficient learning frameworks and resource management
strategies under a single edge server. Additionally, we expand the scope to
multi-edge scenarios, exploring multi-edge collaboration and mobility
management from a networking perspective. Finally, we discuss open problems for
edge SL, including convergence analysis, asynchronous SL and U-shaped SL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15865">Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Papachristou_M/0/1/0/all/0/1">Marios Papachristou</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahimian_M/0/1/0/all/0/1">M. Amin Rahimian</a></p>
<p>We study distributed estimation and learning problems in a networked
environment in which agents exchange information to estimate unknown
statistical properties of random variables from their privately observed
samples. The agents can collectively estimate the unknown quantities by
exchanging information about their private observations, but they also face
privacy risks. Our novel algorithms extend the existing distributed estimation
literature and enable the participating agents to estimate a complete
sufficient statistic from private signals acquired offline or online over time
and to preserve the privacy of their signals and network neighborhoods. This is
achieved through linear aggregation schemes with adjusted randomization schemes
that add noise to the exchanged estimates subject to differential privacy (DP)
constraints, both in an offline and online manner. We provide convergence rate
analysis and tight finite-time convergence bounds. We show that the noise that
minimizes the convergence time to the best estimates is the Laplace noise, with
parameters corresponding to each agent's sensitivity to their signal and
network characteristics. Our algorithms are further amenable to dynamic
topologies and balancing privacy and accuracy trade-offs. Finally, to
supplement and validate our theoretical results, we run experiments on
real-world data from the US Power Grid Network and electric consumption data
from German Households to estimate the average power consumption of power
stations and households under all privacy regimes and show that our method
outperforms existing first-order privacy-aware distributed optimization
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00527">Graph Neural Networks based Log Anomaly Detection and Explanation. (arXiv:2307.00527v3 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiayang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeuwen_M/0/1/0/all/0/1">Matthijs van Leeuwen</a></p>
<p>Event logs are widely used to record the status of high-tech systems, making
log anomaly detection important for monitoring those systems. Most existing log
anomaly detection methods take a log event count matrix or log event sequences
as input, exploiting quantitative and/or sequential relationships between log
events to detect anomalies. Unfortunately, only considering quantitative or
sequential relationships may result in low detection accuracy. To alleviate
this problem, we propose a graph-based method for unsupervised log anomaly
detection, dubbed Logs2Graphs, which first converts event logs into attributed,
directed, and weighted graphs, and then leverages graph neural networks to
perform graph-level anomaly detection. Specifically, we introduce One-Class
Digraph Inception Convolutional Networks, abbreviated as OCDiGCN, a novel graph
neural network model for detecting graph-level anomalies in a collection of
attributed, directed, and weighted graphs. By coupling the graph representation
and anomaly detection steps, OCDiGCN can learn a representation that is
especially suited for anomaly detection, resulting in a high detection
accuracy. Importantly, for each identified anomaly, we additionally provide a
small subset of nodes that play a crucial role in OCDiGCN's prediction as
explanations, which can offer valuable cues for subsequent root cause
diagnosis. Experiments on five benchmark datasets show that Logs2Graphs
performs at least on par with state-of-the-art log anomaly detection methods on
simple datasets while largely outperforming state-of-the-art log anomaly
detection methods on complicated datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08097">EasyTPP: Towards Open Benchmarking Temporal Point Processes. (arXiv:2307.08097v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1">Siqiao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiaoming Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1">Zhixuan Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1">Hongyan Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Fan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Caigao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1">Chen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">James Y. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1">Qingsong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1">Hongyuan Mei</a></p>
<p>Continuous-time event sequences play a vital role in real-world domains such
as healthcare, finance, online shopping, social networks, and so on. To model
such data, temporal point processes (TPPs) have emerged as the most natural and
competitive models, making a significant impact in both academic and
application communities. Despite the emergence of many powerful models in
recent years, there hasn't been a central benchmark for these models and future
research endeavors. This lack of standardization impedes researchers and
practitioners from comparing methods and reproducing results, potentially
slowing down progress in this field. In this paper, we present EasyTPP, the
first central repository of research assets (e.g., data, models, evaluation
programs, documentations) in the area of event sequence modeling. Our EasyTPP
makes several unique contributions to this area: a unified interface of using
existing datasets and adding new datasets; a wide range of evaluation programs
that are easy to use and extend as well as facilitate reproducible research;
implementations of popular neural TPPs, together with a rich library of modules
by composing which one could quickly build complex models. All the data and
implementation can be found at
https://github.com/ant-research/EasyTemporalPointProcess. We will actively
maintain this benchmark and welcome contributions from other researchers and
practitioners. Our benchmark will help promote reproducible research in this
field, thus accelerating research progress as well as making more significant
real-world impacts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.15398">The Initial Screening Order Problem. (arXiv:2307.15398v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1">Jose M. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Mastropietro_A/0/1/0/all/0/1">Antonio Mastropietro</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruggieri_S/0/1/0/all/0/1">Salvatore Ruggieri</a></p>
<p>We investigate the role of the initial screening order (ISO) in candidate
screening processes, such as hiring and academic admissions. ISO refers to the
order in which the screener sorts the candidate pool before the evaluation. It
has been largely overlooked in the literature, despite its potential impact on
the optimality and fairness of the chosen set, especially under a human
screener. We define two problem formulations: best-$k$, where the screener
chooses the $k$ best candidates, and good-$k$, where the screener chooses the
first $k$ good-enough candidates. To study the impact of ISO, we introduce a
human-like screener and compare to its algorithmic counterpart. The human-like
screener is conceived to be inconsistent over time due to fatigue. Our analysis
shows that the ISO under a human-like screener hinders individual fairness
despite meeting group level fairness. This is due to the position bias, where a
candidate's evaluation is affected by its position within ISO. We report
extensive simulated experiments exploring the parameters of the problem
formulations both for algorithmic and human-like screeners. This work is
motivated by a real world candidate screening problem studied in collaboration
with a large European company.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10623">GaitPT: Skeletons Are All You Need For Gait Recognition. (arXiv:2308.10623v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Catruna_A/0/1/0/all/0/1">Andy Catruna</a>, <a href="http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1">Adrian Cosma</a>, <a href="http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1">Emilian Radoi</a></p>
<p>The analysis of patterns of walking is an important area of research that has
numerous applications in security, healthcare, sports and human-computer
interaction. Lately, walking patterns have been regarded as a unique
fingerprinting method for automatic person identification at a distance. In
this work, we propose a novel gait recognition architecture called Gait Pyramid
Transformer (GaitPT) that leverages pose estimation skeletons to capture unique
walking patterns, without relying on appearance information. GaitPT adopts a
hierarchical transformer architecture that effectively extracts both spatial
and temporal features of movement in an anatomically consistent manner, guided
by the structure of the human skeleton. Our results show that GaitPT achieves
state-of-the-art performance compared to other skeleton-based gait recognition
works, in both controlled and in-the-wild scenarios. GaitPT obtains 82.6%
average accuracy on CASIA-B, surpassing other works by a margin of 6%.
Moreover, it obtains 52.16% Rank-1 accuracy on GREW, outperforming both
skeleton-based and appearance-based approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12539">CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1">Vipul Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1">Pranav Narayanan Venkit</a>, <a href="http://arxiv.org/find/cs/1/au:+Laurencon_H/0/1/0/all/0/1">Hugo Lauren&#xe7;on</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1">Shomir Wilson</a>, <a href="http://arxiv.org/find/cs/1/au:+Passonneau_R/0/1/0/all/0/1">Rebecca J. Passonneau</a></p>
<p>As language models (LMs) become increasingly powerful and widely used, it is
important to quantify them for sociodemographic bias with potential for harm.
Prior measures of bias are sensitive to perturbations in the templates designed
to compare performance across social groups, due to factors such as low
diversity or limited number of templates. Also, most previous work considers
only one NLP task. We introduce Comprehensive Assessment of Language Models
(CALM) for robust measurement of two types of universally relevant
sociodemographic bias, gender and race. CALM integrates sixteen datasets for
question-answering, sentiment analysis and natural language inference. Examples
from each dataset are filtered to produce 224 templates with high diversity
(e.g., length, vocabulary). We assemble 50 highly frequent person names for
each of seven distinct demographic groups to generate 78,400 prompts covering
the three NLP tasks. Our empirical evaluation shows that CALM bias scores are
more robust and far less sensitive than previous bias measurements to
perturbations in the templates, such as synonym substitution, or to random
subset selection of templates. We apply CALM to 20 large language models, and
find that for 2 language model series, larger parameter models tend to be more
biased than smaller ones. The T0 series is the least biased model families, of
the 20 LLMs investigated here. The code is available at
https://github.com/vipulgupta1011/CALM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.15812">Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models. (arXiv:2308.15812v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1">Hritik Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_J/0/1/0/all/0/1">John Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a></p>
<p>Aligning large language models (LLMs) with human values and intents
critically involves the use of human or AI feedback. While dense feedback
annotations are expensive to acquire and integrate, sparse feedback presents a
structural design choice between ratings (e.g., score Response A on a scale of
1-7) and rankings (e.g., is Response A better than Response B?). In this work,
we analyze the effect of this design choice for the alignment and evaluation of
LLMs. We uncover an inconsistency problem wherein the preferences inferred from
ratings and rankings significantly disagree 60% for both human and AI
annotators. Our subsequent analysis identifies various facets of annotator
biases that explain this phenomena, such as human annotators would rate denser
responses higher while preferring accuracy during pairwise judgments. To our
surprise, we also observe that the choice of feedback protocol also has a
significant effect on the evaluation of aligned LLMs. In particular, we find
that LLMs that leverage rankings data for alignment (say model X) are preferred
over those that leverage ratings data (say model Y), with a rank-based
evaluation protocol (is X/Y's response better than reference response?) but not
with a rating-based evaluation protocol (score Rank X/Y's response on a scale
of 1-7). Our findings thus shed light on critical gaps in methods for
evaluating the real-world utility of language models and their strong
dependence on the feedback protocol used for alignment. Our code and data are
available at https://github.com/Hritikbansal/sparse_feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.00976">Pure Message Passing Can Estimate Common Neighbor for Link Prediction. (arXiv:2309.00976v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_K/0/1/0/all/0/1">Kaiwen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhichun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1">Nitesh V. Chawla</a></p>
<p>Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto}
standard in graph representation learning. However, when it comes to link
prediction, they often struggle, surpassed by simple heuristics such as Common
Neighbor (CN). This discrepancy stems from a fundamental limitation: while
MPNNs excel in node-level representation, they stumble with encoding the joint
structural features essential to link prediction, like CN. To bridge this gap,
we posit that, by harnessing the orthogonality of input vectors, pure
message-passing can indeed capture joint structural features. Specifically, we
study the proficiency of MPNNs in approximating CN heuristics. Based on our
findings, we introduce the Message Passing Link Predictor (MPLP), a novel link
prediction model. MPLP taps into quasi-orthogonal vectors to estimate
link-level structural features, all while preserving the node-level
complexities. Moreover, our approach demonstrates that leveraging
message-passing to capture structural features could offset MPNNs'
expressiveness limitations at the expense of estimation variance. We conduct
experiments on benchmark datasets from various domains, where our method
consistently outperforms the baseline methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.02292">Inferring effective couplings with Restricted Boltzmann Machines. (arXiv:2309.02292v3 [cond-mat.dis-nn] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Decelle_A/0/1/0/all/0/1">Aur&#xe9;lien Decelle</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Furtlehner_C/0/1/0/all/0/1">Cyril Furtlehner</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Gomez_A/0/1/0/all/0/1">Alfonso De Jesus Navas G&#xf3;mez</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Seoane_B/0/1/0/all/0/1">Beatriz Seoane</a></p>
<p>Generative models offer a direct way of modeling complex data. Energy-based
models attempt to encode the statistical correlations observed in the data at
the level of the Boltzmann weight associated with an energy function in the
form of a neural network. We address here the challenge of understanding the
physical interpretation of such models. In this study, we propose a simple
solution by implementing a direct mapping between the Restricted Boltzmann
Machine and an effective Ising spin Hamiltonian. This mapping includes
interactions of all possible orders, going beyond the conventional pairwise
interactions typically considered in the inverse Ising (or Boltzmann Machine)
approach, and allowing the description of complex datasets. Earlier works
attempted to achieve this goal, but the proposed mappings were inaccurate for
inference applications, did not properly treat the complexity of the problem,
or did not provide precise prescriptions for practical application. To validate
our method, we performed several controlled inverse numerical experiments in
which we trained the RBMs using equilibrium samples of predefined models with
local external fields, 2-body and 3-body interactions in different sparse
topologies. The results demonstrate the effectiveness of our proposed approach
in learning the correct interaction network and pave the way for its
application in modeling interesting binary variable datasets. We also evaluate
the quality of the inferred model based on different training methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03619">Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction. (arXiv:2309.03619v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brima_Y/0/1/0/all/0/1">Yusuf Brima</a>, <a href="http://arxiv.org/find/cs/1/au:+Krumnack_U/0/1/0/all/0/1">Ulf Krumnack</a>, <a href="http://arxiv.org/find/cs/1/au:+Pika_S/0/1/0/all/0/1">Simone Pika</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidemann_G/0/1/0/all/0/1">Gunther Heidemann</a></p>
<p>Self-supervised learning (SSL) has emerged as a promising paradigm for
learning flexible speech representations from unlabeled data. By designing
pretext tasks that exploit statistical regularities, SSL models can capture
useful representations that are transferable to downstream tasks. This study
provides an empirical analysis of Barlow Twins (BT), an SSL technique inspired
by theories of redundancy reduction in human perception. On downstream tasks,
BT representations accelerated learning and transferred across domains.
However, limitations exist in disentangling key explanatory factors, with
redundancy reduction and invariance alone insufficient for factorization of
learned latents into modular, compact, and informative codes. Our ablations
study isolated gains from invariance constraints, but the gains were
context-dependent. Overall, this work substantiates the potential of Barlow
Twins for sample-efficient speech encoding. However, challenges remain in
achieving fully hierarchical representations. The analysis methodology and
insights pave a path for extensions incorporating further inductive priors and
perceptual principles to further enhance the BT self-supervision framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07937">Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks. (arXiv:2309.07937v3 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Maiti_S/0/1/0/all/0/1">Soumi Maiti</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_Y/0/1/0/all/0/1">Yifan Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Choi_S/0/1/0/all/0/1">Shukjae Choi</a>, <a href="http://arxiv.org/find/eess/1/au:+Jung_J/0/1/0/all/0/1">Jee-weon Jung</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_X/0/1/0/all/0/1">Xuankai Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a></p>
<p>We propose a decoder-only language model, VoxtLM, that can perform four
tasks: speech recognition, speech synthesis, text generation, and speech
continuation. VoxtLM integrates text vocabulary with discrete speech tokens
from self-supervised speech features and uses special tokens to enable
multitask learning. Compared to a single-task model, VoxtLM exhibits a
significant improvement in speech synthesis, with improvements in both speech
intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90.
VoxtLM also improves speech generation and speech recognition performance over
the single-task counterpart. Further, VoxtLM is trained with publicly available
data and training recipes and model checkpoints are open-sourced to make fully
reproducible work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.14808">Revisiting Softmax Masking: Stop Gradient for Enhancing Stability in Replay-based Continual Learning. (arXiv:2309.14808v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoyong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_M/0/1/0/all/0/1">Minchan Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kangil Kim</a></p>
<p>In replay-based methods for continual learning, replaying input samples in
episodic memory has shown its effectiveness in alleviating catastrophic
forgetting. However, the potential key factor of cross-entropy loss with
softmax in causing catastrophic forgetting has been underexplored. In this
paper, we analyze the effect of softmax and revisit softmax masking with
negative infinity to shed light on its ability to mitigate catastrophic
forgetting. Based on the analyses, it is found that negative infinity masked
softmax is not always compatible with dark knowledge. To improve the
compatibility, we propose a general masked softmax that controls the stability
by adjusting the gradient scale to old and new classes. We demonstrate that
utilizing our method on other replay-based methods results in better
performance, primarily by enhancing model stability in continual learning
benchmarks, even when the buffer size is set to an extremely small value.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.15717">Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription. (arXiv:2309.15717v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Cwitkowitz_F/0/1/0/all/0/1">Frank Cwitkowitz</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheuk_K/0/1/0/all/0/1">Kin Wai Cheuk</a>, <a href="http://arxiv.org/find/eess/1/au:+Choi_W/0/1/0/all/0/1">Woosung Choi</a>, <a href="http://arxiv.org/find/eess/1/au:+Martinez_Ramirez_M/0/1/0/all/0/1">Marco A. Mart&#xed;nez-Ram&#xed;rez</a>, <a href="http://arxiv.org/find/eess/1/au:+Toyama_K/0/1/0/all/0/1">Keisuke Toyama</a>, <a href="http://arxiv.org/find/eess/1/au:+Liao_W/0/1/0/all/0/1">Wei-Hsiang Liao</a>, <a href="http://arxiv.org/find/eess/1/au:+Mitsufuji_Y/0/1/0/all/0/1">Yuki Mitsufuji</a></p>
<p>In recent years, research on music transcription has focused mainly on
architecture design and instrument-specific data acquisition. With the lack of
availability of diverse datasets, progress is often limited to solo-instrument
tasks such as piano transcription. Several works have explored multi-instrument
transcription as a means to bolster the performance of models on low-resource
tasks, but these methods face the same data availability issues. We propose
Timbre-Trap, a novel framework which unifies music transcription and audio
reconstruction by exploiting the strong separability between pitch and timbre.
We train a single autoencoder to simultaneously estimate pitch salience and
reconstruct complex spectral coefficients, selecting between either output
during the decoding stage via a simple switch mechanism. In this way, the model
learns to produce coefficients corresponding to timbre-less audio, which can be
interpreted as pitch salience. We demonstrate that the framework leads to
performance comparable to state-of-the-art instrument-agnostic transcription
methods, while only requiring a small amount of annotated data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.17249">Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering. (arXiv:2309.17249v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Han Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xingchen Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Proleev_L/0/1/0/all/0/1">Lev Proleev</a>, <a href="http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1">Diana Mincu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1">Katherine Heller</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhrajit Roy</a></p>
<p>Prompting and in-context learning (ICL) have become efficient learning
paradigms for large language models (LLMs). However, LLMs suffer from prompt
brittleness and various bias factors in the prompt, including but not limited
to the formatting, the choice verbalizers, and the ICL examples. To address
this problem that results in unexpected performance degradation, calibration
methods have been developed to mitigate the effects of these biases while
recovering LLM performance. In this work, we first conduct a systematic
analysis of the existing calibration methods, where we both provide a unified
view and reveal the failure cases. Inspired by these analyses, we propose Batch
Calibration (BC), a simple yet intuitive method that controls the contextual
bias from the batched input, unifies various prior approaches, and effectively
addresses the aforementioned issues. BC is zero-shot, inference-only, and
incurs negligible additional costs. In the few-shot setup, we further extend BC
to allow it to learn the contextual bias from labeled data. We validate the
effectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate
state-of-the-art performance over previous calibration baselines across more
than 10 natural language understanding and image classification tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.17371">Adversarial Imitation Learning from Visual Observations using Latent Information. (arXiv:2309.17371v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Giammarino_V/0/1/0/all/0/1">Vittorio Giammarino</a>, <a href="http://arxiv.org/find/cs/1/au:+Queeney_J/0/1/0/all/0/1">James Queeney</a>, <a href="http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1">Ioannis Ch. Paschalidis</a></p>
<p>We focus on the problem of imitation learning from visual observations, where
the learning agent has access to videos of experts as its sole learning source.
The challenges of this framework include the absence of expert actions and the
partial observability of the environment, as the ground-truth states can only
be inferred from pixels. To tackle this problem, we first conduct a theoretical
analysis of imitation learning in partially observable environments. We
establish upper bounds on the suboptimality of the learning agent with respect
to the divergence between the expert and the agent latent state-transition
distributions. Motivated by this analysis, we introduce an algorithm called
Latent Adversarial Imitation from Observations, which combines off-policy
adversarial imitation techniques with a learned latent representation of the
agent's state from sequences of observations. In experiments on
high-dimensional continuous robotic tasks, we show that our algorithm matches
state-of-the-art performance while providing significant computational
advantages. Additionally, we show how our method can be used to improve the
efficiency of reinforcement learning from pixels by leveraging expert videos.
To ensure reproducibility, we provide free access to our code.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.03258">Assessing Electricity Service Unfairness with Transfer Counterfactual Learning. (arXiv:2310.03258v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Song Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xiangrui Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1">Alinson Santos Xavier</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Shixiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_F/0/1/0/all/0/1">Feng Qiu</a></p>
<p>Energy justice is a growing area of interest in interdisciplinary energy
research. However, identifying systematic biases in the energy sector remains
challenging due to confounding variables, intricate heterogeneity in
counterfactual effects, and limited data availability. First, this paper
demonstrates how one can evaluate counterfactual unfairness in a power system
by analyzing the average causal effect of a specific protected attribute.
Subsequently, we use subgroup analysis to handle model heterogeneity and
introduce a novel method for estimating counterfactual unfairness based on
transfer learning, which helps to alleviate the data scarcity in each subgroup.
In our numerical analysis, we apply our method to a unique large-scale
customer-level power outage data set and investigate the counterfactual effect
of demographic factors, such as income and age of the population, on power
outage durations. Our results indicate that low-income and elderly-populated
areas consistently experience longer power outages under both daily and
post-disaster operations, and such discrimination is exacerbated under severe
conditions. These findings suggest a widespread, systematic issue of injustice
in the power service systems and emphasize the necessity for focused
interventions in disadvantaged communities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.06343">Boosting Continuous Control with Consistency Policy. (arXiv:2310.06343v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuhui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongbin Zhao</a></p>
<p>Due to its training stability and strong expression, the diffusion model has
attracted considerable attention in offline reinforcement learning. However,
several challenges have also come with it: 1) The demand for a large number of
diffusion steps makes the diffusion-model-based methods time inefficient and
limits their applications in real-time control; 2) How to achieve policy
improvement with accurate guidance for diffusion model-based policy is still an
open problem. Inspired by the consistency model, we propose a novel
time-efficiency method named Consistency Policy with Q-Learning (CPQL), which
derives action from noise by a single step. By establishing a mapping from the
reverse diffusion trajectories to the desired policy, we simultaneously address
the issues of time efficiency and inaccurate guidance when updating diffusion
model-based policy with the learned Q-function. We demonstrate that CPQL can
achieve policy improvement with accurate guidance for offline reinforcement
learning, and can be seamlessly extended for online RL tasks. Experimental
results indicate that CPQL achieves new state-of-the-art performance on 11
offline and 21 online tasks, significantly improving inference speed by nearly
45 times compared to Diffusion-QL. We will release our code later.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07223">Bidirectional recurrent imputation and abundance estimation of LULC classes with MODIS multispectral time series and geo-topographic and climatic data. (arXiv:2310.07223v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Ortega_J/0/1/0/all/0/1">Jos&#xe9; Rodr&#xed;guez-Ortega</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Khaldi_R/0/1/0/all/0/1">Rohaifa Khaldi</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Alcaraz_Segura_D/0/1/0/all/0/1">Domingo Alcaraz-Segura</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Tabik_S/0/1/0/all/0/1">Siham Tabik</a> (1) ((1) Department of Computer Science and Artificial Intelligence, DaSCI, University of Granada, Granada, Spain, (2) LifeWatch-ERIC ICT Core, Seville, Spain, (3) Department of Botany, Faculty of Science, University of Granada, Granada, Spain)</p>
<p>Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC)
types. Spectral unmixing (SU) is a key technique that disentangles mixed pixels
into constituent LULC types and their abundance fractions. While existing
studies on Deep Learning (DL) for SU typically focus on single time-step
hyperspectral (HS) or multispectral (MS) data, our work pioneers SU using MODIS
MS time series, addressing missing data with end-to-end DL models. Our approach
enhances a Long-Short Term Memory (LSTM)-based model by incorporating
geographic, topographic (geo-topographic), and climatic ancillary information.
Notably, our method eliminates the need for explicit endmember extraction,
instead learning the input-output relationship between mixed spectra and LULC
abundances through supervised learning. Experimental results demonstrate that
integrating spectral-temporal input data with geo-topographic and climatic
information significantly improves the estimation of LULC abundances in mixed
pixels. To facilitate this study, we curated a novel labeled dataset for
Andalusia (Spain) with monthly MODIS multispectral time series at 460m
resolution for 2013. Named Andalusia MultiSpectral MultiTemporal Unmixing
(Andalusia-MSMTU), this dataset provides pixel-level annotations of LULC
abundances along with ancillary information. The dataset
(https://zenodo.org/records/7752348) and code
(https://github.com/jrodriguezortega/MSMTU) are available to the public.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10280">Mimicking the Maestro: Exploring the Efficacy of a Virtual AI Teacher in Fine Motor Skill Acquisition. (arXiv:2310.10280v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mulian_H/0/1/0/all/0/1">Hadar Mulian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlomov_S/0/1/0/all/0/1">Segev Shlomov</a>, <a href="http://arxiv.org/find/cs/1/au:+Limonad_L/0/1/0/all/0/1">Lior Limonad</a>, <a href="http://arxiv.org/find/cs/1/au:+Noccaro_A/0/1/0/all/0/1">Alessia Noccaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Buscaglione_S/0/1/0/all/0/1">Silvia Buscaglione</a></p>
<p>Motor skills, especially fine motor skills like handwriting, play an
essential role in academic pursuits and everyday life. Traditional methods to
teach these skills, although effective, can be time-consuming and inconsistent.
With the rise of advanced technologies like robotics and artificial
intelligence, there is increasing interest in automating such teaching
processes using these technologies, via human-robot and human-computer
interactions. In this study, we examine the potential of a virtual AI teacher
in emulating the techniques of human educators for motor skill acquisition. We
introduce an AI teacher model that captures the distinct characteristics of
human instructors. Using a Reinforcement Learning environment tailored to mimic
teacher-learner interactions, we tested our AI model against four guiding
hypotheses, emphasizing improved learner performance, enhanced rate of skill
acquisition, and reduced variability in learning outcomes. Our findings,
validated on synthetic learners, revealed significant improvements across all
tested hypotheses. Notably, our model showcased robustness across different
learners and settings and demonstrated adaptability to handwriting. This
research underscores the potential of integrating Reinforcement Learning and
Imitation Learning models with robotics in revolutionizing the teaching of
critical motor skills.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18612">Efficient kernel surrogates for neural network-based regression. (arXiv:2310.18612v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qadeer_S/0/1/0/all/0/1">Saad Qadeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Engel_A/0/1/0/all/0/1">Andrew Engel</a>, <a href="http://arxiv.org/find/cs/1/au:+Howard_A/0/1/0/all/0/1">Amanda Howard</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsou_A/0/1/0/all/0/1">Adam Tsou</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_M/0/1/0/all/0/1">Max Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Stinis_P/0/1/0/all/0/1">Panos Stinis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_T/0/1/0/all/0/1">Tony Chiang</a></p>
<p>Despite their immense promise in performing a variety of learning tasks, a
theoretical understanding of the limitations of Deep Neural Networks (DNNs) has
so far eluded practitioners. This is partly due to the inability to determine
the closed forms of the learned functions, making it harder to study their
generalization properties on unseen datasets. Recent work has shown that
randomly initialized DNNs in the infinite width limit converge to kernel
machines relying on a Neural Tangent Kernel (NTK) with known closed form. These
results suggest, and experimental evidence corroborates, that empirical kernel
machines can also act as surrogates for finite width DNNs. The high
computational cost of assembling the full NTK, however, makes this approach
infeasible in practice, motivating the need for low-cost approximations. In the
current work, we study the performance of the Conjugate Kernel (CK), an
efficient approximation to the NTK that has been observed to yield fairly
similar results. For the regression problem of smooth functions and logistic
regression classification, we show that the CK performance is only marginally
worse than that of the NTK and, in certain cases, is shown to be superior. In
particular, we establish bounds for the relative test losses, verify them with
numerical tests, and identify the regularity of the kernel as the key
determinant of performance. In addition to providing a theoretical grounding
for using CKs instead of NTKs, our framework suggests a recipe for improving
DNN accuracy inexpensively. We present a demonstration of this on the
foundation model GPT-2 by comparing its performance on a classification task
using a conventional approach and our prescription. We also show how our
approach can be used to improve physics-informed operator network training for
regression tasks as well as convolutional neural network training for vision
classification tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05836">UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields. (arXiv:2311.05836v5 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hu_J/0/1/0/all/0/1">Jing Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_Q/0/1/0/all/0/1">Qinrui Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_S/0/1/0/all/0/1">Shu Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lyu_S/0/1/0/all/0/1">Siwei Lyu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1">Xi Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a></p>
<p>In the field of clinical medicine, computed tomography (CT) is an effective
medical imaging modality for the diagnosis of various pathologies. Compared
with X-ray images, CT images can provide more information, including
multi-planar slices and three-dimensional structures for clinical diagnosis.
However, CT imaging requires patients to be exposed to large doses of ionizing
radiation for a long time, which may cause irreversible physical harm. In this
paper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on
generated radiation fields. The network can learn a continuous representation
of CT projections from 2D X-ray images by obtaining the internal structure and
depth information and using adaptive loss weights to ensure the quality of the
generated images. Our model is trained on publicly available knee and chest
datasets, and we show the results of CT projection rendering with a single
X-ray and compare our method with other methods based on generated radiation
fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10795">How False Data Affects Machine Learning Models in Electrochemistry?. (arXiv:2311.10795v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deshsorna_K/0/1/0/all/0/1">Krittapong Deshsorna</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawtrakul_L/0/1/0/all/0/1">Luckhana Lawtrakul</a>, <a href="http://arxiv.org/find/cs/1/au:+Iamprasertkun_P/0/1/0/all/0/1">Pawin Iamprasertkun</a></p>
<p>Recently, the selection of machine learning model based on only the data
distribution without concerning the noise of the data. This study aims to
distinguish, which models perform well under noisy data, and establish whether
stacking machine learning models actually provide robustness to otherwise
weak-to-noise models. The electrochemical data were tested with 12 standalone
models and stacking model. This includes XGB, LGBM, RF, GB, ADA, NN, ELAS,
LASS, RIDGE, SVM, KNN, DT, and the stacking model. It is found that linear
models handle noise well with the average error of (slope) to 1.75 F g-1 up to
error per 100% percent noise added; but it suffers from prediction accuracy due
to having an average of 60.19 F g-1 estimated at minimal error at 0% noise
added. Tree-based models fail in terms of noise handling (average slope is
55.24 F g-1 at 100% percent noise), but it can provide higher prediction
accuracy (lowest error of 23.9 F g-1) than that of linear. To address the
controversial between prediction accuracy and error handling, the stacking
model was constructed, which is not only show high accuracy (intercept of 25.03
F g-1), but it also exhibits good noise handling (slope of 43.58 F g-1), making
stacking models a relatively low risk and viable choice for beginner and
experienced machine learning research in electrochemistry. Even though neural
networks (NN) are gaining popularity in the electrochemistry field. However,
this study presents that NN is not suitable for electrochemical data, and
improper tuning resulting in a model that is susceptible to noise. Thus, STACK
models should provide better benefits in that even with untuned base models,
they can achieve an accurate and noise-tolerant model. Overall, this work
provides insight into machine learning model selection for electrochemical
data, which should aid the understanding of data science in chemistry context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13541">Linear Log-Normal Attention with Unbiased Concentration. (arXiv:2311.13541v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nahshan_Y/0/1/0/all/0/1">Yury Nahshan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kampeas_J/0/1/0/all/0/1">Joseph Kampeas</a>, <a href="http://arxiv.org/find/cs/1/au:+Haleva_E/0/1/0/all/0/1">Emir Haleva</a></p>
<p>Transformer models have achieved remarkable results in a wide range of
applications. However, their scalability is hampered by the quadratic time and
memory complexity of the self-attention mechanism concerning the sequence
length. This limitation poses a substantial obstacle when dealing with long
documents or high-resolution images. In this work, we study the self-attention
mechanism by analyzing the distribution of the attention matrix and its
concentration ability. Furthermore, we propose instruments to measure these
quantities and introduce a novel self-attention mechanism, Linear Log-Normal
Attention, designed to emulate the distribution and concentration behavior of
the original self-attention. Our experimental results on popular natural
language benchmarks reveal that our proposed Linear Log-Normal Attention
outperforms other linearized attention alternatives, offering a promising
avenue for enhancing the scalability of transformer models. Our code is
available in supplementary materials.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14743">A Baseline Analysis of Reward Models&#x27; Ability To Accurately Analyze Foundation Models Under Distribution Shift. (arXiv:2311.14743v7 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1">Will LeVine</a>, <a href="http://arxiv.org/find/cs/1/au:+Pikus_B/0/1/0/all/0/1">Benjamin Pikus</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anthony Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendryx_S/0/1/0/all/0/1">Sean Hendryx</a></p>
<p>Foundation models, specifically Large Language Models (LLMs), have lately
gained wide-spread attention and adoption. Reinforcement Learning with Human
Feedback (RLHF) involves training a reward model to capture desired behaviors,
which is then used to align LLM's. These reward models are additionally used at
inference-time to estimate LLM responses' adherence to those desired behaviors.
However, there is little work measuring how robust these reward models are to
distribution shifts. In this work, we evaluate how reward model performance -
measured via accuracy and calibration (i.e. alignment between accuracy and
confidence) - is affected by distribution shift. We show novel calibration
patterns and accuracy drops due to OOD prompts and responses, and that the
reward model is more sensitive to shifts in responses than prompts.
Additionally, we adapt an OOD detection technique commonly used in
classification to the reward model setting to detect these distribution shifts
in prompts and responses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14828">Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning. (arXiv:2311.14828v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Baldwin_McDonald_T/0/1/0/all/0/1">Thomas Baldwin-McDonald</a>, <a href="http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1">Mauricio A. &#xc1;lvarez</a></p>
<p>Modelling the behaviour of highly nonlinear dynamical systems with robust
uncertainty quantification is a challenging task which typically requires
approaches specifically designed to address the problem at hand. We introduce a
domain-agnostic model to address this issue termed the deep latent force model
(DLFM), a deep Gaussian process with physics-informed kernels at each layer,
derived from ordinary differential equations using the framework of process
convolutions. Two distinct formulations of the DLFM are presented which utilise
weight-space and variational inducing points-based Gaussian process
approximations, both of which are amenable to doubly stochastic variational
inference. We present empirical evidence of the capability of the DLFM to
capture the dynamics present in highly nonlinear real-world multi-output time
series data. Additionally, we find that the DLFM is capable of achieving
comparable performance to a range of non-physics-informed probabilistic models
on benchmark univariate regression tasks. We also empirically assess the
negative impact of the inducing points framework on the extrapolation
capabilities of LFM-based models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16093">Visual cognition in multimodal large language models. (arXiv:2311.16093v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Buschoff_L/0/1/0/all/0/1">Luca M. Schulze Buschoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_E/0/1/0/all/0/1">Elif Akata</a>, <a href="http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1">Matthias Bethge</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulz_E/0/1/0/all/0/1">Eric Schulz</a></p>
<p>A chief goal of artificial intelligence is to build machines that think like
people. Yet it has been argued that deep neural network architectures fail to
accomplish this. Researchers have asserted these models' limitations in the
domains of causal reasoning, intuitive physics, and intuitive psychology. Yet
recent advancements, namely the rise of large language models, particularly
those designed for visual processing, have rekindled interest in the potential
to emulate human-like cognitive abilities. This paper evaluates the current
state of vision-based large language models in the domains of intuitive
physics, causal reasoning, and intuitive psychology. Through a series of
controlled experiments, we investigate the extent to which these modern models
grasp complex physical interactions, causal relationships, and intuitive
understanding of others' preferences. Our findings reveal that, while these
models demonstrate a notable proficiency in processing and interpreting visual
data, they still fall short of human capabilities in these areas. The models
exhibit a rudimentary understanding of physical laws and causal relationships,
but their performance is hindered by a lack of deeper insights - a key aspect
of human cognition. Furthermore, in tasks requiring an intuitive theory of
mind, the models fail altogether. Our results emphasize the need for
integrating more robust mechanisms for understanding causality, physical
dynamics, and social cognition into modern-day, vision-based language models,
and point out the importance of cognitively-inspired benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01878">HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xingtong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zemin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinming Zhang</a></p>
<p>Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs)
are prominent techniques for homogeneous and heterogeneous graph representation
learning, yet their performance in an end-to-end supervised framework greatly
depends on the availability of task-specific supervision. To reduce the
labeling cost, pre-training on self-supervised pretext tasks has become a
popular paradigm,but there is often a gap between the pre-trained model and
downstream tasks, stemming from the divergence in their objectives. To bridge
the gap, prompt learning has risen as a promising direction especially in
few-shot settings, without the need to fully fine-tune the pre-trained model.
While there has been some early exploration of prompt-based learning on graphs,
they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs
that are prevalent in downstream applications. In this paper, we propose
HGPROMPT, a novel pre-training and prompting framework to unify not only
pre-training and downstream tasks but also homogeneous and heterogeneous graphs
via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to
assist a downstream task in locating the most relevant prior to bridge the gaps
caused by not only feature variations but also heterogeneity differences across
tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive
experiments on three public datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09084">Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v3 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nazeer_K/0/1/0/all/0/1">Khaleelulla Khan Nazeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schone_M/0/1/0/all/0/1">Mark Sch&#xf6;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherji_R/0/1/0/all/0/1">Rishav Mukherji</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogginger_B/0/1/0/all/0/1">Bernhard Vogginger</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayr_C/0/1/0/all/0/1">Christian Mayr</a>, <a href="http://arxiv.org/find/cs/1/au:+Kappel_D/0/1/0/all/0/1">David Kappel</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramoney_A/0/1/0/all/0/1">Anand Subramoney</a></p>
<p>As large language models continue to scale in size rapidly, so too does the
computational power required to run them. Event-based networks on neuromorphic
devices offer a potential way to reduce energy consumption for inference
significantly. However, to date, most event-based networks that can run on
neuromorphic hardware, including spiking neural networks (SNNs), have not
achieved task performance even on par with LSTM models for language modeling.
As a result, language modeling on neuromorphic devices has seemed a distant
prospect. In this work, we demonstrate the first-ever implementation of a
language model on a neuromorphic device - specifically the SpiNNaker 2 chip -
based on a recently published event-based architecture called the EGRU.
SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale
asynchronous processing, while the EGRU is architected to leverage such
hardware efficiently while maintaining competitive task performance. This
implementation marks the first time a neuromorphic language model matches
LSTMs, setting the stage for taking task performance to the level of large
language models. We also demonstrate results on a gesture recognition task
based on inputs from a DVS camera. Overall, our results showcase the
feasibility of this neuro-inspired neural network in hardware, highlighting
significant gains versus conventional hardware in energy efficiency for the
common use case of single batch inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09442">A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection. (arXiv:2312.09442v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wu_S/0/1/0/all/0/1">Siyang Wu</a></p>
<p>Globally, cardiovascular diseases (CVDs) are the leading cause of mortality,
accounting for an estimated 17.9 million deaths annually. One critical clinical
objective is the early detection of CVDs using electrocardiogram (ECG) data, an
area that has received significant attention from the research community.
Recent advancements based on machine learning and deep learning have achieved
great progress in this domain. However, existing methodologies exhibit inherent
limitations, including inappropriate model evaluations and instances of data
leakage. In this study, we present a streamlined workflow paradigm for
preprocessing ECG signals into consistent 10-second durations, eliminating the
need for manual feature extraction/beat detection. We also propose a hybrid
model of Long Short-Term Memory (LSTM) with Support Vector Machine (SVM) for
fraud detection. This architecture consists of two LSTM layers and an SVM
classifier, which achieves a SOTA results with an Average precision score of
0.9402 on the MIT-BIH arrhythmia dataset and 0.9563 on the MIT-BIH atrial
fibrillation dataset. Based on the results, we believe our method can
significantly benefit the early detection and management of CVDs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12784">Fast Cell Library Characterization for Design Technology Co-Optimization Based on Graph Neural Networks. (arXiv:2312.12784v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tianliang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhihui Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xuguang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_L/0/1/0/all/0/1">Leilai Shao Kainlu Low</a></p>
<p>Design technology co-optimization (DTCO) plays a critical role in achieving
optimal power, performance, and area (PPA) for advanced semiconductor process
development. Cell library characterization is essential in DTCO flow, but
traditional methods are time-consuming and costly. To overcome these
challenges, we propose a graph neural network (GNN)-based machine learning
model for rapid and accurate cell library characterization. Our model
incorporates cell structures and demonstrates high prediction accuracy across
various process-voltage-temperature (PVT) corners and technology parameters.
Validation with 512 unseen technology corners and over one million test data
points shows accurate predictions of delay, power, and input pin capacitance
for 33 types of cells, with a mean absolute percentage error (MAPE) $\le$ 0.95%
and a speed-up of 100X compared with SPICE simulations. Additionally, we
investigate system-level metrics such as worst negative slack (WNS), leakage
power, and dynamic power using predictions obtained from the GNN-based model on
unseen corners. Our model achieves precise predictions, with absolute error
$\le$3.0 ps for WNS, percentage errors $\le$0.60% for leakage power, and
$\le$0.99% for dynamic power, when compared to golden reference. With the
developed model, we further proposed a fine-grained drive strength
interpolation methodology to enhance PPA for small-to-medium-scale designs,
resulting in an approximate 1-3% improvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00496">SAR-RARP50: Segmentation of surgical instrumentation and Action Recognition on Robot-Assisted Radical Prostatectomy Challenge. (arXiv:2401.00496v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Psychogyios_D/0/1/0/all/0/1">Dimitrios Psychogyios</a>, <a href="http://arxiv.org/find/cs/1/au:+Colleoni_E/0/1/0/all/0/1">Emanuele Colleoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Amsterdam_B/0/1/0/all/0/1">Beatrice Van Amsterdam</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chih-Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shu-Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuchong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1">Fucang Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_B/0/1/0/all/0/1">Baosheng Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guotai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Boels_M/0/1/0/all/0/1">Maxence Boels</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1">Jiayu Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sparks_R/0/1/0/all/0/1">Rachel Sparks</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_P/0/1/0/all/0/1">Prokar Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Granados_A/0/1/0/all/0/1">Alejandro Granados</a>, <a href="http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengya Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">An Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yanan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Long Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Hongliang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamada_A/0/1/0/all/0/1">Atsushi Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Harai_Y/0/1/0/all/0/1">Yuriko Harai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_Y/0/1/0/all/0/1">Yuto Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1">Kazuyuki Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Simoens_J/0/1/0/all/0/1">Jente Simoens</a>, <a href="http://arxiv.org/find/cs/1/au:+DeBacker_P/0/1/0/all/0/1">Pieter DeBacker</a>, <a href="http://arxiv.org/find/cs/1/au:+Cisternino_F/0/1/0/all/0/1">Francesco Cisternino</a>, <a href="http://arxiv.org/find/cs/1/au:+Furnari_G/0/1/0/all/0/1">Gabriele Furnari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mottrie_A/0/1/0/all/0/1">Alex Mottrie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraguti_F/0/1/0/all/0/1">Federica Ferraguti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondo_S/0/1/0/all/0/1">Satoshi Kondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasai_S/0/1/0/all/0/1">Satoshi Kasai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirasawa_K/0/1/0/all/0/1">Kousuke Hirasawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soohee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seung Hyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyu Eun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_H/0/1/0/all/0/1">Hyoun-Joong Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1">Kui Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1">Shan An</a>, <a href="http://arxiv.org/find/cs/1/au:+Krell_S/0/1/0/all/0/1">Stefanie Krell</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodenstedt_S/0/1/0/all/0/1">Sebastian Bodenstedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayobi_N/0/1/0/all/0/1">Nicolas Ayobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1">Alejandra Perez</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1">Santiago Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Puentes_J/0/1/0/all/0/1">Juanita Puentes</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohareri_O/0/1/0/all/0/1">Omid Mohareri</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a></p>
<p>Surgical tool segmentation and action recognition are fundamental building
blocks in many computer-assisted intervention applications, ranging from
surgical skills assessment to decision support systems. Nowadays,
learning-based action recognition and segmentation approaches outperform
classical methods, relying, however, on large, annotated datasets. Furthermore,
action recognition and tool segmentation algorithms are often trained and make
predictions in isolation from each other, without exploiting potential
cross-task relationships. With the EndoVis 2022 SAR-RARP50 challenge, we
release the first multimodal, publicly available, in-vivo, dataset for surgical
action recognition and semantic instrumentation segmentation, containing 50
suturing video segments of Robotic Assisted Radical Prostatectomy (RARP). The
aim of the challenge is twofold. First, to enable researchers to leverage the
scale of the provided dataset and develop robust and highly accurate
single-task action recognition and tool segmentation approaches in the surgical
domain. Second, to further explore the potential of multitask-based learning
approaches and determine their comparative advantage against their single-task
counterparts. A total of 12 teams participated in the challenge, contributing 7
action recognition methods, 9 instrument segmentation techniques, and 4
multitask approaches that integrated both action recognition and instrument
segmentation. The complete SAR-RARP50 dataset is available at:
https://rdr.ucl.ac.uk/projects/SARRARP50_Segmentation_of_surgical_instrumentation_and_Action_Recognition_on_Robot-Assisted_Radical_Prostatectomy_Challenge/191091
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05535">Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Dorador_A/0/1/0/all/0/1">Albert Dorador</a></p>
<p>Decades after their inception, random forests continue to provide
state-of-the-art accuracy in a variety of learning problems, outperforming in
this respect alternative machine learning algorithms such as decision trees or
even neural networks. However, being an ensemble method, the one aspect where
random forests tend to severely underperform decision trees is
interpretability. In the present work, we propose a post-hoc approach that aims
to have the best of both worlds: the accuracy of random forests and the
interpretability of decision trees. To this end, we present two forest-pruning
methods to find an optimal sub-forest within a given random forest, and then,
when applicable, combine the selected trees into one. Our first method relies
on constrained exhaustive search, while our second method is based on an
adaptation of the LASSO methodology. Extensive experiments over synthetic and
real world datasets show that, in the majority of scenarios, at least one of
the two methods proposed is more accurate than the original random forest,
while just using a small fraction of the trees, aiding result interpretability.
Compared to current state-of-the-art forest pruning methods, namely sequential
forward selection and (a variation of) sequential backward selection, our
methods tend to outperform both of them, whether in terms of accuracy, number
of trees employed, or both.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07448">Formal Logic Enabled Personalized Federated Learning Through Property Inference. (arXiv:2401.07448v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1">Ziyan An</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_T/0/1/0/all/0/1">Taylor T. Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Meiyi Ma</a></p>
<p>Recent advancements in federated learning (FL) have greatly facilitated the
development of decentralized collaborative applications, particularly in the
domain of Artificial Intelligence of Things (AIoT). However, a critical aspect
missing from the current research landscape is the ability to enable
data-driven client models with symbolic reasoning capabilities. Specifically,
the inherent heterogeneity of participating client devices poses a significant
challenge, as each client exhibits unique logic reasoning properties. Failing
to consider these device-specific specifications can result in critical
properties being missed in the client predictions, leading to suboptimal
performance. In this work, we propose a new training paradigm that leverages
temporal logic reasoning to address this issue. Our approach involves enhancing
the training process by incorporating mechanically generated logic expressions
for each FL client. Additionally, we introduce the concept of aggregation
clusters and develop a partitioning algorithm to effectively group clients
based on the alignment of their temporal reasoning properties. We evaluate the
proposed method on two tasks: a real-world traffic volume prediction task
consisting of sensory data from fifteen states and a smart city multi-task
prediction utilizing synthetic data. The evaluation results exhibit clear
improvements, with performance accuracy improved by up to 54% across all
sequential prediction models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08318">OpenDPD: An Open-Source End-to-End Learning &amp; Benchmarking Framework for Wideband Power Amplifier Modeling and Digital Pre-Distortion. (arXiv:2401.08318v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yizhuo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gagan Deep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Beikmirza_M/0/1/0/all/0/1">Mohammadreza Beikmirza</a>, <a href="http://arxiv.org/find/cs/1/au:+Vreede_L/0/1/0/all/0/1">Leo C. N. de Vreede</a>, <a href="http://arxiv.org/find/cs/1/au:+Alavi_M/0/1/0/all/0/1">Morteza Alavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chang Gao</a></p>
<p>With the rise in communication capacity, deep neural networks (DNN) for
digital pre-distortion (DPD) to correct non-linearity in wideband power
amplifiers (PAs) have become prominent. Yet, there is a void in open-source and
measurement-setup-independent platforms for fast DPD exploration and objective
DPD model comparison. This paper presents an open-source framework, OpenDPD,
crafted in PyTorch, with an associated dataset for PA modeling and DPD
learning. We introduce a Dense Gated Recurrent Unit (DGRU)-DPD, trained via a
novel end-to-end learning architecture, outperforming previous DPD models on a
digital PA (DPA) in the new digital transmitter (DTX) architecture with
unconventional transfer characteristics compared to analog PAs. Measurements
show our DGRU-DPD achieves an ACPR of -44.69/-44.47 dBc and an EVM of -35.22 dB
for 200 MHz OFDM signals. OpenDPD code, datasets, and documentation are
publicly available at https://github.com/lab-emi/OpenDPD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08534">DiConStruct: Causal Concept-based Explanations through Black-Box Distillation. (arXiv:2401.08534v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moreira_R/0/1/0/all/0/1">Ricardo Moreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Bono_J/0/1/0/all/0/1">Jacopo Bono</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardoso_M/0/1/0/all/0/1">M&#xe1;rio Cardoso</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleiro_P/0/1/0/all/0/1">Pedro Saleiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Figueiredo_M/0/1/0/all/0/1">M&#xe1;rio A. T. Figueiredo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1">Pedro Bizarro</a></p>
<p>Model interpretability plays a central role in human-AI decision-making
systems. Ideally, explanations should be expressed using human-interpretable
semantic concepts. Moreover, the causal relations between these concepts should
be captured by the explainer to allow for reasoning about the explanations.
Lastly, explanation methods should be efficient and not compromise the
performance of the predictive task. Despite the rapid advances in AI
explainability in recent years, as far as we know to date, no method fulfills
these three properties. Indeed, mainstream methods for local concept
explainability do not produce causal explanations and incur a trade-off between
explainability and prediction performance. We present DiConStruct, an
explanation method that is both concept-based and causal, with the goal of
creating more interpretable local explanations in the form of structural causal
models and concept attributions. Our explainer works as a distillation model to
any black-box machine learning model by approximating its predictions while
producing the respective explanations. Because of this, DiConStruct generates
explanations efficiently while not impacting the black-box prediction task. We
validate our method on an image dataset and a tabular dataset, showing that
DiConStruct approximates the black-box models with higher fidelity than other
concept explainability baselines, while providing explanations that include the
causal relations between the concepts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09493">Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification. (arXiv:2401.09493v2 [physics.ao-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Tam_F/0/1/0/all/0/1">Frederick Iat-Hin Tam</a>, <a href="http://arxiv.org/find/physics/1/au:+Beucler_T/0/1/0/all/0/1">Tom Beucler</a>, <a href="http://arxiv.org/find/physics/1/au:+Ruppert_J/0/1/0/all/0/1">James H. Ruppert Jr</a></p>
<p>Cloud radiative feedback impacts early tropical cyclone (TC) intensification,
but limitations in existing diagnostic frameworks make them unsuitable for
studying asymmetric or transient radiative heating. We propose a linear
Variational Encoder-Decoder (VED) to learn the hidden relationship between
radiation and the surface intensification of realistic simulated TCs. Limiting
VED model inputs enables using its uncertainty to identify periods when
radiation has more importance for intensification. A close examination of the
extracted 3D radiative structures suggests that longwave radiative forcing from
inner core deep convection and shallow clouds both contribute to
intensification, with the deep convection having the most impact overall. We
find that deep convection downwind of the shallow clouds is critical to the
intensification of Haiyan. Our work demonstrates that machine learning can
discover thermodynamic-kinematic relationships without relying on axisymmetric
or deterministic assumptions, paving the way towards the objective discovery of
processes leading to TC intensification in realistic conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09793">PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection. (arXiv:2401.09793v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhijie Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiwen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weizheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaixiang Yang</a></p>
<p>Anomaly detection stands as a crucial aspect of time series analysis, aiming
to identify abnormal events in time series samples. The central challenge of
this task lies in effectively learning the representations of normal and
abnormal patterns in a label-lacking scenario. Previous research mostly relied
on reconstruction-based approaches, restricting the representational abilities
of the models. In addition, most of the current deep learning-based methods are
not lightweight enough, which prompts us to design a more efficient framework
for anomaly detection. In this study, we introduce PatchAD, a novel multi-scale
patch-based MLP-Mixer architecture that leverages contrastive learning for
representational extraction and anomaly detection. Specifically, PatchAD is
composed of four distinct MLP Mixers, exclusively utilizing the MLP
architecture for high efficiency and lightweight architecture. Additionally, we
also innovatively crafted a dual project constraint module to mitigate
potential model degradation. Comprehensive experiments demonstrate that PatchAD
achieves state-of-the-art results across multiple real-world multivariate time
series datasets. Our code is publicly available
https://github.com/EmorZz1G/PatchAD
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10451">Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach. (arXiv:2401.10451v3 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Brenner_A/0/1/0/all/0/1">Aron Brenner</a>, <a href="http://arxiv.org/find/eess/1/au:+Khorramfar_R/0/1/0/all/0/1">Rahman Khorramfar</a>, <a href="http://arxiv.org/find/eess/1/au:+Mallapragada_D/0/1/0/all/0/1">Dharik Mallapragada</a>, <a href="http://arxiv.org/find/eess/1/au:+Amin_S/0/1/0/all/0/1">Saurabh Amin</a></p>
<p>Solving large-scale capacity expansion problems (CEPs) is central to
cost-effective decarbonization of regional-scale energy systems. To ensure the
intended outcomes of CEPs, modeling uncertainty due to weather-dependent
variable renewable energy (VRE) supply and energy demand becomes crucially
important. However, the resulting stochastic optimization models are often less
computationally tractable than their deterministic counterparts. Here, we
propose a learning-assisted approximate solution method to tractably solve
two-stage stochastic CEPs. Our method identifies low-cost planning decisions by
constructing and solving a sequence of tractable temporally aggregated
surrogate problems. We adopt a Bayesian optimization approach to searching the
space of time series aggregation hyperparameters and compute approximate
solutions that minimize costs on a validation set of supply-demand projections.
Importantly, we evaluate solved planning outcomes on a held-out set of test
projections. We apply our approach to generation and transmission expansion
planning for a joint power-gas system spanning New England. We show that our
approach yields an estimated cost savings of up to 3.8% in comparison to
benchmark time series aggregation approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10841">Using LLMs to discover emerging coded antisemitic hate-speech in extremist social media. (arXiv:2401.10841v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kikkisetti_D/0/1/0/all/0/1">Dhanush Kikkisetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_R/0/1/0/all/0/1">Raza Ul Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Melillo_W/0/1/0/all/0/1">Wendy Melillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Corizzo_R/0/1/0/all/0/1">Roberto Corizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukouvalas_Z/0/1/0/all/0/1">Zois Boukouvalas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1">Jeff Gill</a>, <a href="http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1">Nathalie Japkowicz</a></p>
<p>Online hate speech proliferation has created a difficult problem for social
media platforms. A particular challenge relates to the use of coded language by
groups interested in both creating a sense of belonging for its users and
evading detection. Coded language evolves quickly and its use varies over time.
This paper proposes a methodology for detecting emerging coded hate-laden
terminology. The methodology is tested in the context of online antisemitic
discourse. The approach considers posts scraped from social media platforms,
often used by extremist users. The posts are scraped using seed expressions
related to previously known discourse of hatred towards Jews. The method begins
by identifying the expressions most representative of each post and calculating
their frequency in the whole corpus. It filters out grammatically incoherent
expressions as well as previously encountered ones so as to focus on emergent
well-formed terminology. This is followed by an assessment of semantic
similarity to known antisemitic terminology using a fine-tuned large language
model, and subsequent filtering out of the expressions that are too distant
from known expressions of hatred. Emergent antisemitic expressions containing
terms clearly relating to Jewish topics are then removed to return only coded
expressions of hatred.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11648">Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation. (arXiv:2401.11648v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koo_H/0/1/0/all/0/1">Heejoon Koo</a></p>
<p>Predicting next visit diagnosis using Electronic Health Records (EHR) is an
essential task in healthcare, critical for devising proactive future plans for
both healthcare providers and patients. Nonetheless, many preceding studies
have not sufficiently addressed the heterogeneous and hierarchical
characteristics inherent in EHR data, inevitably leading to sub-optimal
performance. To this end, we propose NECHO, a novel medical code-centric
multimodal contrastive EHR learning framework with hierarchical regularisation.
First, we integrate multifaceted information encompassing medical codes,
demographics, and clinical notes using a tailored network design and a pair of
bimodal contrastive losses, all of which pivot around a medical code
representation. We also regularise modality-specific encoders using a parental
level information in medical ontology to learn hierarchical structure of EHR
data. A series of experiments on MIMIC-III data demonstrates effectiveness of
our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11694">Parametric Matrix Models. (arXiv:2401.11694v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cook_P/0/1/0/all/0/1">Patrick Cook</a>, <a href="http://arxiv.org/find/cs/1/au:+Jammooa_D/0/1/0/all/0/1">Danny Jammooa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hjorth_Jensen_M/0/1/0/all/0/1">Morten Hjorth-Jensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dean Lee</a></p>
<p>We present a general class of machine learning algorithms called parametric
matrix models. Parametric matrix models are based on matrix equations, and the
design is motivated by the efficiency of reduced basis methods for
approximating solutions of parametric equations. The dependent variables can be
defined implicitly or explicitly, and the equations may use algebraic,
differential, or integral relations. Parametric matrix models can be trained
with empirical data only, and no high-fidelity model calculations are needed.
While originally designed for scientific computing, parametric matrix models
are universal function approximators that can be applied to general machine
learning problems. After introducing the underlying theory, we apply parametric
matrix models to a series of different challenges that show their performance
for a wide range of problems. For all the challenges tested here, parametric
matrix models produce accurate results within a computational framework that
allows for parameter extrapolation and interpretability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11792">Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations. (arXiv:2401.11792v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zuojin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">YongQiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianyu Chen</a></p>
<p>An intelligent driving system should be capable of dynamically formulating
appropriate driving strategies based on the current environment and vehicle
status, while ensuring the security and reliability of the system. However,
existing methods based on reinforcement learning and imitation learning suffer
from low safety, poor generalization, and inefficient sampling. Additionally,
they cannot accurately predict future driving trajectories, and the accurate
prediction of future driving trajectories is a precondition for making optimal
decisions. To solve these problems, in this paper, we introduce a Safe and
Generalized end-to-end Autonomous Driving System (SGADS) for complex and
various scenarios. Our SGADS incorporates variational inference with
normalizing flows, enabling the intelligent vehicle to accurately predict
future driving trajectories. Moreover, we propose the formulation of robust
safety constraints. Furthermore, we combine reinforcement learning with
demonstrations to augment search process of the agent. The experimental results
demonstrate that our SGADS can significantly improve safety performance,
exhibit strong generalization, and enhance the training efficiency of
intelligent vehicles in complex urban scenarios compared to existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11798">Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction. (arXiv:2401.11798v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Izadi_M/0/1/0/all/0/1">Mohammad Izadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Safayani_M/0/1/0/all/0/1">Mehran Safayani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirzaei_A/0/1/0/all/0/1">Abdolreza Mirzaei</a></p>
<p>Efficient real-time traffic prediction is crucial for reducing transportation
time. To predict traffic conditions, we employ a spatio-temporal graph neural
network (ST-GNN) to model our real-time traffic data as temporal graphs.
Despite its capabilities, it often encounters challenges in delivering
efficient real-time predictions for real-world traffic data. Recognizing the
significance of timely prediction due to the dynamic nature of real-time data,
we employ knowledge distillation (KD) as a solution to enhance the execution
time of ST-GNNs for traffic prediction. In this paper, We introduce a cost
function designed to train a network with fewer parameters (the student) using
distilled data from a complex network (the teacher) while maintaining its
accuracy close to that of the teacher. We use knowledge distillation,
incorporating spatial-temporal correlations from the teacher network to enable
the student to learn the complex patterns perceived by the teacher. However, a
challenge arises in determining the student network architecture rather than
considering it inadvertently. To address this challenge, we propose an
algorithm that utilizes the cost function to calculate pruning scores,
addressing small network architecture search issues, and jointly fine-tunes the
network resulting from each pruning stage using KD. Ultimately, we evaluate our
proposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The results
indicate that our method can maintain the student's accuracy close to that of
the teacher, even with the retention of only $3\%$ of network parameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12233">Memorization in Self-Supervised Learning Improves Downstream Generalization. (arXiv:2401.12233v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaleem_M/0/1/0/all/0/1">Muhammad Ahmad Kaleem</a>, <a href="http://arxiv.org/find/cs/1/au:+Dziedzic_A/0/1/0/all/0/1">Adam Dziedzic</a>, <a href="http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1">Michael Backes</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a>, <a href="http://arxiv.org/find/cs/1/au:+Boenisch_F/0/1/0/all/0/1">Franziska Boenisch</a></p>
<p>Self-supervised learning (SSL) has recently received significant attention
due to its ability to train high-performance encoders purely on unlabeled
data-often scraped from the internet. This data can still be sensitive and
empirical evidence suggests that SSL encoders memorize private information of
their training data and can disclose them at inference time. Since existing
theoretical definitions of memorization from supervised learning rely on
labels, they do not transfer to SSL. To address this gap, we propose SSLMem, a
framework for defining memorization within SSL. Our definition compares the
difference in alignment of representations for data points and their augmented
views returned by both encoders that were trained on these data points and
encoders that were not. Through comprehensive empirical analysis on diverse
encoder architectures and datasets we highlight that even though SSL relies on
large datasets and strong augmentations-both known in supervised learning as
regularization techniques that reduce overfitting-still significant fractions
of training data points experience high memorization. Through our empirical
results, we show that this memorization is essential for encoders to achieve
higher generalization performance on different downstream tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12435">Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network. (arXiv:2401.12435v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiayi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongfeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jin Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1">Qingrui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hanbo Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zu_L/0/1/0/all/0/1">Lingyun Zu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaobo Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Hongbin Han</a></p>
<p>The brain extracellular space (ECS), an irregular, extremely tortuous
nanoscale space located between cells or between cells and blood vessels, is
crucial for nerve cell survival. It plays a pivotal role in high-level brain
functions such as memory, emotion, and sensation. However, the specific form of
molecular transport within the ECS remain elusive. To address this challenge,
this paper proposes a novel approach to quantitatively analyze the molecular
transport within the ECS by solving an inverse problem derived from the
advection-diffusion equation (ADE) using a physics-informed neural network
(PINN). PINN provides a streamlined solution to the ADE without the need for
intricate mathematical formulations or grid settings. Additionally, the
optimization of PINN facilitates the automatic computation of the diffusion
coefficient governing long-term molecule transport and the velocity of
molecules driven by advection. Consequently, the proposed method allows for the
quantitative analysis and identification of the specific pattern of molecular
transport within the ECS through the calculation of the Peclet number.
Experimental validation on two datasets of magnetic resonance images (MRIs)
captured at different time points showcases the effectiveness of the proposed
method. Notably, our simulations reveal identical molecular transport patterns
between datasets representing rats with tracer injected into the same brain
region. These findings highlight the potential of PINN as a promising tool for
comprehensively exploring molecular transport within the ECS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12509">Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread. (arXiv:2401.12509v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Puri_P/0/1/0/all/0/1">Prateek Puri</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassler_G/0/1/0/all/0/1">Gabriel Hassler</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenk_A/0/1/0/all/0/1">Anton Shenk</a>, <a href="http://arxiv.org/find/cs/1/au:+Katragadda_S/0/1/0/all/0/1">Sai Katragadda</a></p>
<p>We develop a simulation framework for studying misinformation spread within
online social networks that blends agent-based modeling and natural language
processing techniques. While many other agent-based simulations exist in this
space, questions over their fidelity and generalization to existing networks in
part hinders their ability to provide actionable insights. To partially address
these concerns, we create a 'digital clone' of a known misinformation sharing
network by downloading social media histories for over ten thousand of its
users. We parse these histories to both extract the structure of the network
and model the nuanced ways in which information is shared and spread among its
members. Unlike many other agent-based methods in this space, information
sharing between users in our framework is sensitive to topic of discussion,
user preferences, and online community dynamics. To evaluate the fidelity of
our method, we seed our cloned network with a set of posts recorded in the base
network and compare propagation dynamics between the two, observing reasonable
agreement across the twin networks over a variety of metrics. Lastly, we
explore how the cloned network may serve as a flexible, low-cost testbed for
misinformation countermeasure evaluation and red teaming analysis. We hope the
tools explored here augment existing efforts in the space and unlock new
opportunities for misinformation countermeasure evaluation, a field that may
become increasingly important to consider with the anticipated rise of
misinformation campaigns fueled by generative artificial intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12617">The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model. (arXiv:2401.12617v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1">Daniel Goldfarb</a>, <a href="http://arxiv.org/find/cs/1/au:+Evron_I/0/1/0/all/0/1">Itay Evron</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberger_N/0/1/0/all/0/1">Nir Weinberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1">Daniel Soudry</a>, <a href="http://arxiv.org/find/cs/1/au:+Hand_P/0/1/0/all/0/1">Paul Hand</a></p>
<p>In continual learning, catastrophic forgetting is affected by multiple
aspects of the tasks. Previous works have analyzed separately how forgetting is
affected by either task similarity or overparameterization. In contrast, our
paper examines how task similarity and overparameterization jointly affect
forgetting in an analyzable model. Specifically, we focus on two-task continual
linear regression, where the second task is a random orthogonal transformation
of an arbitrary first task (an abstraction of random permutation tasks). We
derive an exact analytical expression for the expected forgetting - and uncover
a nuanced pattern. In highly overparameterized models, intermediate task
similarity causes the most forgetting. However, near the interpolation
threshold, forgetting decreases monotonically with the expected task
similarity. We validate our findings with linear regression on synthetic data,
and with neural networks on established permutation task benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12722">Falcon: Fair Active Learning using Multi-armed Bandits. (arXiv:2401.12722v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tae_K/0/1/0/all/0/1">Ki Hyun Tae</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hantian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jaeyoung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_K/0/1/0/all/0/1">Kexin Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Whang_S/0/1/0/all/0/1">Steven Euijong Whang</a></p>
<p>Biased data can lead to unfair machine learning models, highlighting the
importance of embedding fairness at the beginning of data analysis,
particularly during dataset curation and labeling. In response, we propose
Falcon, a scalable fair active learning framework. Falcon adopts a data-centric
approach that improves machine learning model fairness via strategic sample
selection. Given a user-specified group fairness measure, Falcon identifies
samples from "target groups" (e.g., (attribute=female, label=positive)) that
are the most informative for improving fairness. However, a challenge arises
since these target groups are defined using ground truth labels that are not
available during sample selection. To handle this, we propose a novel
trial-and-error method, where we postpone using a sample if the predicted label
is different from the expected one and falls outside the target group. We also
observe the trade-off that selecting more informative samples results in higher
likelihood of postponing due to undesired label prediction, and the optimal
balance varies per dataset. We capture the trade-off between informativeness
and postpone rate as policies and propose to automatically select the best
policy using adversarial multi-armed bandit methods, given their computational
efficiency and theoretical guarantees. Experiments show that Falcon
significantly outperforms existing fair active learning approaches in terms of
fairness and accuracy and is more efficient. In particular, only Falcon
supports a proper trade-off between accuracy and fairness where its maximum
fairness score is 1.8-4.5x higher than the second-best results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12764">Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $O(1/k)$ Finite-Sample Complexity. (arXiv:2401.12764v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Doan_T/0/1/0/all/0/1">Thinh T. Doan</a></p>
<p>This paper proposes to develop a new variant of the two-time-scale stochastic
approximation to find the roots of two coupled nonlinear operators, assuming
only noisy samples of these operators can be observed. Our key idea is to
leverage the classic Ruppert-Polyak averaging technique to dynamically estimate
the operators through their samples. The estimated values of these averaging
steps will then be used in the two-time-scale stochastic approximation updates
to find the desired solution. Our main theoretical result is to show that under
the strongly monotone condition of the underlying nonlinear operators the
mean-squared errors of the iterates generated by the proposed method converge
to zero at an optimal rate $O(1/k)$, where $k$ is the number of iterations. Our
result significantly improves the existing result of two-time-scale stochastic
approximation, where the best known finite-time convergence rate is
$O(1/k^{2/3})$.
</p>
</p>
</div>

    </div>
    </body>
    