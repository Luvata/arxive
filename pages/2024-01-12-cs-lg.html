<!DOCTYPE html>
<html>
<head>
<title>2024-01-12-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.04732">A case study of Generative AI in MSX Sales Copilot: Improving seller productivity with a real-time question-answering system for content recommendation. (arXiv:2401.04732v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Manpreet Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasricha_R/0/1/0/all/0/1">Ravdeep Pasricha</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1">Nitish Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1">Ravi Prasad Kondapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+R_M/0/1/0/all/0/1">Manoj R</a>, <a href="http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1">Kiran R</a>, <a href="http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1">Laurent Bou&#xe9;</a></p>
<p>In this paper, we design a real-time question-answering system specifically
targeted for helping sellers get relevant material/documentation they can share
live with their customers or refer to during a call. Taking the Seismic content
repository as a relatively large scale example of a diverse dataset of sales
material, we demonstrate how LLM embeddings of sellers' queries can be matched
with the relevant content. We achieve this by engineering prompts in an
elaborate fashion that makes use of the rich set of meta-features available for
documents and sellers. Using a bi-encoder with cross-encoder re-ranker
architecture, we show how the solution returns the most relevant content
recommendations in just a few seconds even for large datasets. Our recommender
system is deployed as an AML endpoint for real-time inferencing and has been
integrated into a Copilot interface that is now deployed in the production
version of the Dynamics CRM, known as MSX, used daily by Microsoft sellers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04741">Masked AutoEncoder for Graph Clustering without Pre-defined Cluster Number k. (arXiv:2401.04741v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yuanchi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Hui He</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1">Zhongxiang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhendong Niu</a></p>
<p>Graph clustering algorithms with autoencoder structures have recently gained
popularity due to their efficient performance and low training cost. However,
for existing graph autoencoder clustering algorithms based on GCN or GAT, not
only do they lack good generalization ability, but also the number of clusters
clustered by such autoencoder models is difficult to determine automatically.
To solve this problem, we propose a new framework called Graph Clustering with
Masked Autoencoders (GCMA). It employs our designed fusion autoencoder based on
the graph masking method for the fusion coding of graph. It introduces our
improved density-based clustering algorithm as a second decoder while decoding
with multi-target reconstruction. By decoding the mask embedding, our model can
capture more generalized and comprehensive knowledge. The number of clusters
and clustering results can be output end-to-end while improving the
generalization ability. As a nonparametric class method, extensive experiments
demonstrate the superiority of \textit{GCMA} over state-of-the-art baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04744">Testing Spintronics Implemented Monte Carlo Dropout-Based Bayesian Neural Networks. (arXiv:2401.04744v1 [cs.ET])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Soyed Tuhin Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hefenbrock_M/0/1/0/all/0/1">Michael Hefenbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Prenat_G/0/1/0/all/0/1">Guillaume Prenat</a>, <a href="http://arxiv.org/find/cs/1/au:+Anghel_L/0/1/0/all/0/1">Lorena Anghel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tahoori_M/0/1/0/all/0/1">Mehdi B. Tahoori</a></p>
<p>Bayesian Neural Networks (BayNNs) can inherently estimate predictive
uncertainty, facilitating informed decision-making. Dropout-based BayNNs are
increasingly implemented in spintronics-based computation-in-memory
architectures for resource-constrained yet high-performance safety-critical
applications. Although uncertainty estimation is important, the reliability of
Dropout generation and BayNN computation is equally important for target
applications but is overlooked in existing works. However, testing BayNNs is
significantly more challenging compared to conventional NNs, due to their
stochastic nature. In this paper, we present for the first time the model of
the non-idealities of the spintronics-based Dropout module and analyze their
impact on uncertainty estimates and accuracy. Furthermore, we propose a testing
framework based on repeatability ranking for Dropout-based BayNN with up to
$100\%$ fault coverage while using only $0.2\%$ of training data as test
vectors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04746">Skin Cancer Segmentation and Classification Using Vision Transformer for Automatic Analysis in Dermatoscopy-based Non-invasive Digital System. (arXiv:2401.04746v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Himel_G/0/1/0/all/0/1">Galib Muhammad Shahriar Himel</a>, <a href="http://arxiv.org/find/eess/1/au:+Islam_M/0/1/0/all/0/1">Md. Masudul Islam</a>, <a href="http://arxiv.org/find/eess/1/au:+Al_Aff_K/0/1/0/all/0/1">Kh Abdullah Al-Aff</a>, <a href="http://arxiv.org/find/eess/1/au:+Karim_S/0/1/0/all/0/1">Shams Ibne Karim</a>, <a href="http://arxiv.org/find/eess/1/au:+Sikder_M/0/1/0/all/0/1">Md. Kabir Uddin Sikder</a></p>
<p>Skin cancer is a global health concern, necessitating early and accurate
diagnosis for improved patient outcomes. This study introduces a groundbreaking
approach to skin cancer classification, employing the Vision Transformer, a
state-of-the-art deep learning architecture renowned for its success in diverse
image analysis tasks. Utilizing the HAM10000 dataset of 10,015 meticulously
annotated skin lesion images, the model undergoes preprocessing for enhanced
robustness. The Vision Transformer, adapted to the skin cancer classification
task, leverages the self-attention mechanism to capture intricate spatial
dependencies, achieving superior performance over traditional deep learning
architectures. Segment Anything Model aids in precise segmentation of cancerous
areas, attaining high IOU and Dice Coefficient. Extensive experiments highlight
the model's supremacy, particularly the Google-based ViT patch-32 variant,
which achieves 96.15% accuracy and showcases potential as an effective tool for
dermatologists in skin cancer diagnosis, contributing to advancements in
dermatological practices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04748">Convolutional Neural Network Ensemble Learning for Hyperspectral Imaging-based Blackberry Fruit Ripeness Detection in Uncontrolled Farm Environment. (arXiv:2401.04748v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Olisah_C/0/1/0/all/0/1">Chollette C. Olisah</a>, <a href="http://arxiv.org/find/cs/1/au:+Trewhella_B/0/1/0/all/0/1">Ben Trewhella</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1">Melvyn L. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Winstone_B/0/1/0/all/0/1">Benjamin Winstone</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitfield_E/0/1/0/all/0/1">E. Charles Whitfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_F/0/1/0/all/0/1">Felicidad Fern&#xe1;ndez Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Duncalfe_H/0/1/0/all/0/1">Harriet Duncalfe</a></p>
<p>Fruit ripeness estimation models have for decades depended on spectral index
features or colour-based features, such as mean, standard deviation, skewness,
colour moments, and/or histograms for learning traits of fruit ripeness.
Recently, few studies have explored the use of deep learning techniques to
extract features from images of fruits with visible ripeness cues. However, the
blackberry (Rubus fruticosus) fruit does not show obvious and reliable visible
traits of ripeness when mature and therefore poses great difficulty to fruit
pickers. The mature blackberry, to the human eye, is black before, during, and
post-ripening. To address this engineering application challenge, this paper
proposes a novel multi-input convolutional neural network (CNN) ensemble
classifier for detecting subtle traits of ripeness in blackberry fruits. The
multi-input CNN was created from a pre-trained visual geometry group 16-layer
deep convolutional network (VGG16) model trained on the ImageNet dataset. The
fully connected layers were optimized for learning traits of ripeness of mature
blackberry fruits. The resulting model served as the base for building
homogeneous ensemble learners that were ensemble using the stack generalization
ensemble (SGE) framework. The input to the network is images acquired with a
stereo sensor using visible and near-infrared (VIS-NIR) spectral filters at
wavelengths of 700 nm and 770 nm. Through experiments, the proposed model
achieved 95.1% accuracy on unseen sets and 90.2% accuracy with in-field
conditions. Further experiments reveal that machine sensory is highly and
positively correlated to human sensory over blackberry fruit skin texture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04749">LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection. (arXiv:2401.04749v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hongcheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1">Jiaqi Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhoujun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tieqiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+peng_J/0/1/0/all/0/1">Junran peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a></p>
<p>Log anomaly detection is a key component in the field of artificial
intelligence for IT operations (AIOps). Considering log data of variant
domains, retraining the whole network for unknown domains is inefficient in
real industrial scenarios. However, previous deep models merely focused on
extracting the semantics of log sequences in the same domain, leading to poor
generalization on multi-domain logs. To alleviate this issue, we propose a
unified Transformer-based framework for Log anomaly detection (LogFormer) to
improve the generalization ability across different domains, where we establish
a two-stage process including the pre-training and adapter-based tuning stage.
Specifically, our model is first pre-trained on the source domain to obtain
shared semantic knowledge of log data. Then, we transfer such knowledge to the
target domain via shared parameters. Besides, the Log-Attention module is
proposed to supplement the information ignored by the log-paring. The proposed
method is evaluated on three public and one real-world datasets. Experimental
results on multiple benchmarks demonstrate the effectiveness of our LogFormer
with fewer trainable parameters and lower training costs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04751">Identifying Best Practice Melting Patterns in Induction Furnaces: A Data-Driven Approach Using Time Series KMeans Clustering and Multi-Criteria Decision Making. (arXiv:2401.04751v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Howard_D/0/1/0/all/0/1">Daniel Anthony Howard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jorgensen_B/0/1/0/all/0/1">Bo N&#xf8;rregaard J&#xf8;rgensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zheng Ma</a></p>
<p>Improving energy efficiency in industrial production processes is crucial for
competitiveness, and compliance with climate policies. This paper introduces a
data-driven approach to identify optimal melting patterns in induction
furnaces. Through time-series K-means clustering the melting patterns could be
classified into distinct clusters based on temperature profiles. Using the
elbow method, 12 clusters were identified, representing the range of melting
patterns. Performance parameters such as melting time, energy-specific
performance, and carbon cost were established for each cluster, indicating
furnace efficiency and environmental impact. Multiple criteria decision-making
methods including Simple Additive Weighting, Multiplicative Exponential
Weighting, Technique for Order of Preference by Similarity to Ideal Solution,
modified TOPSIS, and VlseKriterijumska Optimizacija I Kompromisno Resenje were
utilized to determine the best-practice cluster. The study successfully
identified the cluster with the best performance. Implementing the best
practice operation resulted in an 8.6 % reduction in electricity costs,
highlighting the potential energy savings in the foundry.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04757">How predictable is language model benchmark performance?. (arXiv:2401.04757v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Owen_D/0/1/0/all/0/1">David Owen</a></p>
<p>We investigate large language model performance across five orders of
magnitude of compute scaling in eleven recent model architectures. We show that
average benchmark performance, aggregating over many individual tasks and
evaluations as in the commonly-used BIG-Bench dataset, is decently predictable
as a function of training compute scale. Specifically, when extrapolating
BIG-Bench Hard performance across one order of magnitude in compute, we observe
average absolute errors of 6 percentage points (pp). By contrast, extrapolation
for individual BIG-Bench tasks across an order of magnitude in compute yields
higher average errors of 18pp. Nonetheless, individual task performance remains
significantly more predictable than chance. Overall, our work suggests compute
scaling provides a promising basis to forecast AI capabilities in diverse
benchmarks, though predicting performance in specific tasks poses challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04778">Generative neural networks for characteristic functions. (arXiv:2401.04778v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Bruck_F/0/1/0/all/0/1">Florian Br&#xfc;ck</a></p>
<p>In this work, we provide a simulation algorithm to simulate from a
(multivariate) characteristic function, which is only accessible in a black-box
format. We construct a generative neural network, whose loss function exploits
a specific representation of the Maximum-Mean-Discrepancy metric to directly
incorporate the targeted characteristic function. The construction is universal
in the sense that it is independent of the dimension and that it does not
require any assumptions on the given characteristic function. Furthermore,
finite sample guarantees on the approximation quality in terms of the
Maximum-Mean Discrepancy metric are derived. The method is illustrated in a
short simulation study.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04783">Hyperbolic Machine Learning Moment Closures for the BGK Equations. (arXiv:2401.04783v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Christlieb_A/0/1/0/all/0/1">Andrew J. Christlieb</a>, <a href="http://arxiv.org/find/math/1/au:+Ding_M/0/1/0/all/0/1">Mingchang Ding</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_J/0/1/0/all/0/1">Juntao Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Krupansky_N/0/1/0/all/0/1">Nicholas A. Krupansky</a></p>
<p>We introduce a hyperbolic closure for the Grad moment expansion of the
Bhatnagar-Gross-Krook's (BGK) kinetic model using a neural network (NN) trained
on BGK's moment data. This closure is motivated by the exact closure for the
free streaming limit that we derived in our paper on closures in transport
\cite{Huang2022-RTE1}. The exact closure relates the gradient of the highest
moment to the gradient of four lower moments. As with our past work, the model
presented here learns the gradient of the highest moment in terms of the
coefficients of gradients for all lower ones. By necessity, this means that the
resulting hyperbolic system is not conservative in the highest moment. For
stability, the output layers of the NN are designed to enforce hyperbolicity
and Galilean invariance. This ensures the model can be run outside of the
training window of the NN. Unlike our previous work on radiation transport that
dealt with linear models, the BGK model's nonlinearity demanded advanced
training tools. These comprised an optimal learning rate discovery, one cycle
training, batch normalization in each neural layer, and the use of the
\texttt{AdamW} optimizer. To address the non-conservative structure of the
hyperbolic model, we adopt the FORCE numerical method to achieve robust
solutions. This results in a comprehensive computing model combining learned
closures with methods for solving hyperbolic models. The proposed model can
capture accurate moment solutions across a broad spectrum of Knudsen numbers.
Our paper details the multi-scale model construction and is run on a range of
test problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04795">First 100 days of pandemic; an interplay of pharmaceutical, behavioral and digital interventions -- A study using agent based modeling. (arXiv:2401.04795v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1">Gauri Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapila_R/0/1/0/all/0/1">Ritvik Kapila</a>, <a href="http://arxiv.org/find/cs/1/au:+Chopra_A/0/1/0/all/0/1">Ayush Chopra</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskar_R/0/1/0/all/0/1">Ramesh Raskar</a></p>
<p>Pandemics, notably the recent COVID-19 outbreak, have impacted both public
health and the global economy. A profound understanding of disease progression
and efficient response strategies is thus needed to prepare for potential
future outbreaks. In this paper, we emphasize the potential of Agent-Based
Models (ABM) in capturing complex infection dynamics and understanding the
impact of interventions. We simulate realistic pharmaceutical, behavioral, and
digital interventions that mirror challenges in real-world policy adoption and
suggest a holistic combination of these interventions for pandemic response.
Using these simulations, we study the trends of emergent behavior on a
large-scale population based on real-world socio-demographic and geo-census
data from Kings County in Washington. Our analysis reveals the pivotal role of
the initial 100 days in dictating a pandemic's course, emphasizing the
importance of quick decision-making and efficient policy development. Further,
we highlight that investing in behavioral and digital interventions can reduce
the burden on pharmaceutical interventions by reducing the total number of
infections and hospitalizations, and by delaying the pandemic's peak. We also
infer that allocating the same amount of dollars towards extensive testing with
contact tracing and self-quarantine offers greater cost efficiency compared to
spending the entire budget on vaccinations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04829">GNNShap: Fast and Accurate GNN Explanations using Shapley Values. (arXiv:2401.04829v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akkas_S/0/1/0/all/0/1">Selahattin Akkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1">Ariful Azad</a></p>
<p>Graph neural networks (GNNs) are popular machine learning models for graphs
with many applications across scientific domains. However, GNNs are considered
black box models, and it is challenging to understand how the model makes
predictions. Game theory-based Shapley value approaches are popular explanation
methods in other domains but are not well-studied for graphs. Some studies have
proposed Shapley value-based GNN explanations, yet they have several
limitations: they consider limited samples to approximate Shapley values; some
mainly focus on small and large coalition sizes, and they are an order of
magnitude slower than other explanation methods, making them inapplicable to
even moderate-size graphs. In this work, we propose GNNShap, which provides
explanations for edges since they provide more natural explanations for graphs
and more fine-grained explanations. We overcome the limitations by sampling
from all coalition sizes, parallelizing the sampling on GPUs, and speeding up
model predictions by batching. GNNShap gives better fidelity scores and faster
explanations than baselines on real-world datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04837">T-PRIME: Transformer-based Protocol Identification for Machine-learning at the Edge. (arXiv:2401.04837v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Belgiovine_M/0/1/0/all/0/1">Mauro Belgiovine</a>, <a href="http://arxiv.org/find/cs/1/au:+Groen_J/0/1/0/all/0/1">Joshua Groen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sirera_M/0/1/0/all/0/1">Miquel Sirera</a>, <a href="http://arxiv.org/find/cs/1/au:+Tassie_C/0/1/0/all/0/1">Chinenye Tassie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yildiz_A/0/1/0/all/0/1">Ayberk Yarkin Yildiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Trudeau_S/0/1/0/all/0/1">Sage Trudeau</a>, <a href="http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1">Stratis Ioannidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_K/0/1/0/all/0/1">Kaushik Chowdhury</a></p>
<p>Spectrum sharing allows different protocols of the same standard (e.g.,
802.11 family) or different standards (e.g., LTE and DVB) to coexist in
overlapping frequency bands. As this paradigm continues to spread, wireless
systems must also evolve to identify active transmitters and unauthorized
waveforms in real time under intentional distortion of preambles, extremely low
signal-to-noise ratios and challenging channel conditions. We overcome
limitations of correlation-based preamble matching methods in such conditions
through the design of T-PRIME: a Transformer-based machine learning approach.
T-PRIME learns the structural design of transmitted frames through its
attention mechanism, looking at sequence patterns that go beyond the preamble
alone. The paper makes three contributions: First, it compares Transformer
models and demonstrates their superiority over traditional methods and
state-of-the-art neural networks. Second, it rigorously analyzes T-PRIME's
real-time feasibility on DeepWave's AIR-T platform. Third, it utilizes an
extensive 66 GB dataset of over-the-air (OTA) WiFi transmissions for training,
which is released along with the code for community use. Results reveal nearly
perfect (i.e. $&gt;98\%$) classification accuracy under simulated scenarios,
showing $100\%$ detection improvement over legacy methods in low SNR ranges,
$97\%$ classification accuracy for OTA single-protocol transmissions and up to
$75\%$ double-protocol classification accuracy in interference scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04847">On the Correctness of the Generalized Isotonic Recursive Partitioning Algorithm. (arXiv:2401.04847v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Won_J/0/1/0/all/0/1">Joong-Ho Won</a>, <a href="http://arxiv.org/find/stat/1/au:+Jung_J/0/1/0/all/0/1">Jinan Jung</a></p>
<p>This paper presents an in-depth analysis of the generalized isotonic
recursive partitioning (GIRP) algorithm for fitting isotonic models under
separable convex losses, proposed by Luss and Rosset [J. Comput. Graph.
Statist., 23 (2014), pp. 192--201] for differentiable losses and extended by
Painsky and Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp.
308-321] for nondifferentiable losses. The GIRP algorithm poseses an attractive
feature that in each step of the algorithm, the intermediate solution satisfies
the isotonicity constraint. The paper begins with an example showing that the
GIRP algorithm as described in the literature may fail to produce an isotonic
model, suggesting that the existence and uniqueness of the solution to the
isotonic regression problem must be carefully addressed. It proceeds with
showing that, among possibly many solutions, there indeed exists a solution
that can be found by recursive binary partitioning of the set of observed data.
A small modification of the GIRP algorithm suffices to obtain a correct
solution and preserve the desired property that all the intermediate solutions
are isotonic. This proposed modification includes a proper choice of
intermediate solutions and a simplification of the partitioning step from
ternary to binary.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04851">Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand &amp; Uncertainties. (arXiv:2401.04851v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Steve Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Witter_J/0/1/0/all/0/1">Jhoel Witter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Souma Chowdhury</a></p>
<p>This paper develops a graph reinforcement learning approach to online
planning of the schedule and destinations of electric aircraft that comprise an
urban air mobility (UAM) fleet operating across multiple vertiports. This fleet
scheduling problem is formulated to consider time-varying demand, constraints
related to vertiport capacity, aircraft capacity and airspace safety
guidelines, uncertainties related to take-off delay, weather-induced route
closures, and unanticipated aircraft downtime. Collectively, such a formulation
presents greater complexity, and potentially increased realism, than in
existing UAM fleet planning implementations. To address these complexities, a
new policy architecture is constructed, primary components of which include:
graph capsule conv-nets for encoding vertiport and aircraft-fleet states both
abstracted as graphs; transformer layers encoding time series information on
demand and passenger fare; and a Multi-head Attention-based decoder that uses
the encoded information to compute the probability of selecting each available
destination for an aircraft. Trained with Proximal Policy Optimization, this
policy architecture shows significantly better performance in terms of daily
averaged profits on unseen test scenarios involving 8 vertiports and 40
aircraft, when compared to a random baseline and genetic algorithm-derived
optimal solutions, while being nearly 1000 times faster in execution than the
latter.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04855">LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control. (arXiv:2401.04855v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Saurav Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Muthukrishnan_R/0/1/0/all/0/1">Ramya Muthukrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gosrich_W/0/1/0/all/0/1">Walker Gosrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vijay Kumar</a></p>
<p>Coverage control is the problem of navigating a robot swarm to
collaboratively monitor features or a phenomenon of interest not known a
priori. The problem is challenging in decentralized settings with robots that
have limited communication and sensing capabilities. This paper proposes a
learnable Perception-Action-Communication (LPAC) architecture for the coverage
control problem. In the proposed solution, a convolution neural network (CNN)
processes localized perception of the environment; a graph neural network (GNN)
enables communication of relevant information between neighboring robots;
finally, a shallow multi-layer perceptron (MLP) computes robot actions. The GNN
in the communication module enables collaboration in the robot swarm by
computing what information to communicate with neighbors and how to use
received information to take appropriate actions. We train models using
imitation learning with a centralized clairvoyant algorithm that is aware of
the entire environment. Evaluations show that the LPAC models outperform
standard decentralized and centralized coverage control algorithms. The learned
policy generalizes to environments different from the training dataset,
transfers to larger environments with an increased number of robots, and is
robust to noisy position estimates. The results indicate that LPAC
architectures are well-suited for decentralized navigation in robot swarms to
achieve collaborative behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04856">A Good Score Does not Lead to A Good Generative Model. (arXiv:2401.04856v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sixu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qin Li</a></p>
<p>Score-based Generative Models (SGMs) is one leading method in generative
modeling, renowned for their ability to generate high-quality samples from
complex, high-dimensional data distributions. The method enjoys empirical
success and is supported by rigorous theoretical convergence properties. In
particular, it has been shown that SGMs can generate samples from a
distribution that is close to the ground-truth if the underlying score function
is learned well, suggesting the success of SGM as a generative model. We
provide a counter-example in this paper. Through the sample complexity
argument, we provide one specific setting where the score function is learned
well. Yet, SGMs in this setting can only output samples that are Gaussian
blurring of training data points, mimicking the effects of kernel density
estimation. The finding resonates a series of recent finding that reveal that
SGMs can demonstrate strong memorization effect and fail to generate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04857">Transportation Market Rate Forecast Using Signature Transform. (arXiv:2401.04857v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Haotian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobs_T/0/1/0/all/0/1">Tim Jacobs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaminsky_P/0/1/0/all/0/1">Philip Kaminsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinyu Li</a></p>
<p>Currently, Amazon relies on third parties for transportation marketplace rate
forecasts, despite the poor quality and lack of interpretability of these
forecasts. While transportation marketplace rates are typically very
challenging to forecast accurately, we have developed a novel signature-based
statistical technique to address these challenges and built a predictive and
adaptive model to forecast marketplace rates. This novel technique is based on
two key properties of the signature transform. The first is its universal
nonlinearity which linearizes the feature space and hence translates the
forecasting problem into a linear regression analysis; the second is the
signature kernel which allows for comparing computationally efficiently
similarities between time series data. Combined, these properties allow for
efficient feature generation and more precise identification of seasonality and
regime switching in the forecasting process. Preliminary result by the model
shows that this new technique leads to far superior forecast accuracy versus
commercially available industry models with better interpretability, even
during the period of Covid-19 and with the sudden onset of the Ukraine war.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04858">User Embedding Model for Personalized Language Prompting. (arXiv:2401.04858v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1">Sumanth Doddapaneni</a>, <a href="http://arxiv.org/find/cs/1/au:+Sayana_K/0/1/0/all/0/1">Krishna Sayana</a>, <a href="http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1">Ambarish Jash</a>, <a href="http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1">Sukhdeep Sodhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1">Dima Kuzmin</a></p>
<p>Modeling long histories plays a pivotal role in enhancing recommendation
systems, allowing to capture user's evolving preferences, resulting in more
precise and personalized recommendations. In this study we tackle the
challenges of modeling long user histories for preference understanding in
natural language. Specifically, we introduce a new User Embedding Module (UEM)
that efficiently processes user history in free-form text by compressing and
representing them as embeddings, to use them as soft prompts to a LM. Our
experiments demonstrate the superior capability of this approach in handling
significantly longer histories compared to conventional text based prompting
methods, yielding substantial improvements in predictive performance. The main
contribution of this research is to demonstrate the ability to bias language
models with user signals represented as embeddings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04872">Knowledge-aware Graph Transformer for Pedestrian Trajectory Prediction. (arXiv:2401.04872v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuexin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kunming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yongliang Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Worrall_S/0/1/0/all/0/1">Stewart Worrall</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">You-Fu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_H/0/1/0/all/0/1">He Kong</a></p>
<p>Predicting pedestrian motion trajectories is crucial for path planning and
motion control of autonomous vehicles. Accurately forecasting crowd
trajectories is challenging due to the uncertain nature of human motions in
different environments. For training, recent deep learning-based prediction
approaches mainly utilize information like trajectory history and interactions
between pedestrians, among others. This can limit the prediction performance
across various scenarios since the discrepancies between training datasets have
not been properly incorporated. To overcome this limitation, this paper
proposes a graph transformer structure to improve prediction performance,
capturing the differences between the various sites and scenarios contained in
the datasets. In particular, a self-attention mechanism and a domain adaption
module have been designed to improve the generalization ability of the model.
Moreover, an additional metric considering cross-dataset sequences is
introduced for training and performance evaluation purposes. The proposed
framework is validated and compared against existing methods using popular
public datasets, i.e., ETH and UCY. Experimental results demonstrate the
improved performance of our proposed scheme.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04874">Feature Network Methods in Machine Learning and Applications. (arXiv:2401.04874v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Mu_X/0/1/0/all/0/1">Xinying Mu</a>, <a href="http://arxiv.org/find/stat/1/au:+Kon_M/0/1/0/all/0/1">Mark Kon</a></p>
<p>A machine learning (ML) feature network is a graph that connects ML features
in learning tasks based on their similarity. This network representation allows
us to view feature vectors as functions on the network. By leveraging function
operations from Fourier analysis and from functional analysis, one can easily
generate new and novel features, making use of the graph structure imposed on
the feature vectors. Such network structures have previously been studied
implicitly in image processing and computational biology. We thus describe
feature networks as graph structures imposed on feature vectors, and provide
applications in machine learning. One application involves graph-based
generalizations of convolutional neural networks, involving structured deep
learning with hierarchical representations of features that have varying depth
or complexity. This extends also to learning algorithms that are able to
generate useful new multilevel features. Additionally, we discuss the use of
feature networks to engineer new features, which can enhance the expressiveness
of the model. We give a specific example of a deep tree-structured feature
network, where hierarchical connections are formed through feature clustering
and feed-forward learning. This results in low learning complexity and
computational efficiency. Unlike "standard" neural features which are limited
to modulated (thresholded) linear combinations of adjacent ones, feature
networks offer more general feedforward dependencies among features. For
example, radial basis functions or graph structure-based dependencies between
features can be utilized.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04890">Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal Dependencies. (arXiv:2401.04890v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Lachapelle_S/0/1/0/all/0/1">S&#xe9;bastien Lachapelle</a>, <a href="http://arxiv.org/find/stat/1/au:+Lopez_P/0/1/0/all/0/1">Pau Rodr&#xed;guez L&#xf3;pez</a>, <a href="http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1">Yash Sharma</a>, <a href="http://arxiv.org/find/stat/1/au:+Everett_K/0/1/0/all/0/1">Katie Everett</a>, <a href="http://arxiv.org/find/stat/1/au:+Priol_R/0/1/0/all/0/1">R&#xe9;mi Le Priol</a>, <a href="http://arxiv.org/find/stat/1/au:+Lacoste_A/0/1/0/all/0/1">Alexandre Lacoste</a>, <a href="http://arxiv.org/find/stat/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a></p>
<p>This work introduces a novel principle for disentanglement we call mechanism
sparsity regularization, which applies when the latent factors of interest
depend sparsely on observed auxiliary variables and/or past latent factors. We
propose a representation learning method that induces disentanglement by
simultaneously learning the latent factors and the sparse causal graphical
model that explains them. We develop a nonparametric identifiability theory
that formalizes this principle and shows that the latent factors can be
recovered by regularizing the learned causal graph to be sparse. More
precisely, we show identifiablity up to a novel equivalence relation we call
"consistency", which allows some latent factors to remain entangled (hence the
term partial disentanglement). To describe the structure of this entanglement,
we introduce the notions of entanglement graphs and graph preserving functions.
We further provide a graphical criterion which guarantees complete
disentanglement, that is identifiability up to permutations and element-wise
transformations. We demonstrate the scope of the mechanism sparsity principle
as well as the assumptions it relies on with several worked out examples. For
instance, the framework shows how one can leverage multi-node interventions
with unknown targets on the latent factors to disentangle them. We further draw
connections between our nonparametric results and the now popular exponential
family assumption. Lastly, we propose an estimation procedure based on
variational autoencoders and a sparsity constraint and demonstrate it on
various synthetic datasets. This work is meant to be a significantly extended
version of Lachapelle et al. (2022).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04900">SPT: Spectral Transformer for Red Giant Stars Age and Mass Estimation. (arXiv:2401.04900v1 [astro-ph.SR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Zhang_M/0/1/0/all/0/1">Mengmeng Zhang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Wu_F/0/1/0/all/0/1">Fan Wu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bu_Y/0/1/0/all/0/1">Yude Bu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Li_S/0/1/0/all/0/1">Shanshan Li</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Yi_Z/0/1/0/all/0/1">Zhenping Yi</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Kong_X/0/1/0/all/0/1">Xiaoming Kong</a></p>
<p>The age and mass of red giants are essential for understanding the structure
and evolution of the Milky Way. Traditional isochrone methods for these
estimations are inherently limited due to overlapping isochrones in the
Hertzsprung-Russell diagram, while asteroseismology, though more precise,
requires high-precision, long-term observations. In response to these
challenges, we developed a novel framework, Spectral Transformer (SPT), to
predict the age and mass of red giants aligned with asteroseismology from their
spectra. A key component of SPT, the Multi-head Hadamard Self-Attention
mechanism, designed specifically for spectra, can capture complex relationships
across different wavelength. Further, we introduced a Mahalanobis
distance-based loss function to address scale imbalance and interaction mode
loss, and incorporated Monte Carlo dropout for quantitative analysis of
prediction uncertainty.Trained and tested on 3,880 red giant spectra from
LAMOST, the SPT achieved remarkable age and mass estimations with average
percentage errors of 17.64% and 6.61%, respectively, and provided uncertainties
for each corresponding prediction. The results significantly outperform those
of traditional machine learning algorithms and demonstrate a high level of
consistency with asteroseismology methods and isochrone fitting techniques. In
the future, our work will leverage datasets from the Chinese Space Station
Telescope and the Large Synoptic Survey Telescope to enhance the precision of
the model and broaden its applicability in the field of astronomy and
astrophysics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04923">Inconsistency-Based Data-Centric Active Open-Set Annotation. (arXiv:2401.04923v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mao_R/0/1/0/all/0/1">Ruiyu Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_O/0/1/0/all/0/1">Ouyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yunhui Guo</a></p>
<p>Active learning is a commonly used approach that reduces the labeling effort
required to train deep neural networks. However, the effectiveness of current
active learning methods is limited by their closed-world assumptions, which
assume that all data in the unlabeled pool comes from a set of predefined known
classes. This assumption is often not valid in practical situations, as there
may be unknown classes in the unlabeled data, leading to the active open-set
annotation problem. The presence of unknown classes in the data can
significantly impact the performance of existing active learning methods due to
the uncertainty they introduce. To address this issue, we propose a novel
data-centric active learning method called NEAT that actively annotates
open-set data. NEAT is designed to label known classes data from a pool of both
known and unknown classes unlabeled data. It utilizes the clusterability of
labels to identify the known classes from the unlabeled pool and selects
informative samples from those classes based on a consistency criterion that
measures inconsistencies between model predictions and local feature
distribution. Unlike the recently proposed learning-centric method for the same
problem, NEAT is much more computationally efficient and is a data-centric
active open-set annotation method. Our experiments demonstrate that NEAT
achieves significantly better performance than state-of-the-art active learning
methods for active open-set annotation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04928">Relaxed Contrastive Learning for Federated Learning. (arXiv:2401.04928v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1">Seonguk Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jinkyu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Geeho Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bohyung Han</a></p>
<p>We propose a novel contrastive learning framework to effectively address the
challenges of data heterogeneity in federated learning. We first analyze the
inconsistency of gradient updates across clients during local training and
establish its dependence on the distribution of feature representations,
leading to the derivation of the supervised contrastive learning (SCL)
objective to mitigate local deviations. In addition, we show that a na\"ive
adoption of SCL in federated learning leads to representation collapse,
resulting in slow convergence and limited performance gains. To address this
issue, we introduce a relaxed contrastive learning loss that imposes a
divergence penalty on excessively similar sample pairs within each class. This
strategy prevents collapsed representations and enhances feature
transferability, facilitating collaborative training and leading to significant
performance improvements. Our framework outperforms all existing federated
learning approaches by huge margins on the standard benchmarks through
extensive experimental results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04929">Learning-Based Difficulty Calibration for Enhanced Membership Inference Attacks. (arXiv:2401.04929v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haonan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_T/0/1/0/all/0/1">Tu Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">An Wang</a></p>
<p>Machine learning models, in particular deep neural networks, are currently an
integral part of various applications, from healthcare to finance. However,
using sensitive data to train these models raises concerns about privacy and
security. One method that has emerged to verify if the trained models are
privacy-preserving is Membership Inference Attacks (MIA), which allows
adversaries to determine whether a specific data point was part of a model's
training dataset. While a series of MIAs have been proposed in the literature,
only a few can achieve high True Positive Rates (TPR) in the low False Positive
Rate (FPR) region (0.01%~1%). This is a crucial factor to consider for an MIA
to be practically useful in real-world settings. In this paper, we present a
novel approach to MIA that is aimed at significantly improving TPR at low FPRs.
Our method, named learning-based difficulty calibration for MIA(LDC-MIA),
characterizes data records by their hardness levels using a neural network
classifier to determine membership. The experiment results show that LDC-MIA
can improve TPR at low FPR by up to 4x compared to the other difficulty
calibration based MIAs. It also has the highest Area Under ROC curve (AUC)
across all datasets. Our method's cost is comparable with most of the existing
MIAs, but is orders of magnitude more efficient than one of the
state-of-the-art methods, LiRA, while achieving similar performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04933">Rethinking Test-time Likelihood: The Likelihood Path Principle and Its Application to OOD Detection. (arXiv:2401.04933v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Sicong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jiawei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Lui_K/0/1/0/all/0/1">Kry Yik Chau Lui</a></p>
<p>While likelihood is attractive in theory, its estimates by deep generative
models (DGMs) are often broken in practice, and perform poorly for out of
distribution (OOD) Detection. Various recent works started to consider
alternative scores and achieved better performances. However, such recipes do
not come with provable guarantees, nor is it clear that their choices extract
sufficient information.
</p>
<p>We attempt to change this by conducting a case study on variational
autoencoders (VAEs). First, we introduce the likelihood path (LPath) principle,
generalizing the likelihood principle. This narrows the search for informative
summary statistics down to the minimal sufficient statistics of VAEs'
conditional likelihoods. Second, introducing new theoretic tools such as nearly
essential support, essential distance and co-Lipschitzness, we obtain
non-asymptotic provable OOD detection guarantees for certain distillation of
the minimal sufficient statistics. The corresponding LPath algorithm
demonstrates SOTA performances, even using simple and small VAEs with poor
likelihood estimates. To our best knowledge, this is the first provable
unsupervised OOD method that delivers excellent empirical results, better than
any other VAEs based techniques. We use the same model as
\cite{xiao2020likelihood}, open sourced from:
https://github.com/XavierXiao/Likelihood-Regret
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04934">Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A Survey. (arXiv:2401.04934v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiechuan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_K/0/1/0/all/0/1">Kefan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zongqing Lu</a></p>
<p>Cooperative multi-agent reinforcement learning is a powerful tool to solve
many real-world cooperative tasks, but restrictions of real-world applications
may require training the agents in a fully decentralized manner. Due to the
lack of information about other agents, it is challenging to derive algorithms
that can converge to the optimal joint policy in a fully decentralized setting.
Thus, this research area has not been thoroughly studied. In this paper, we
seek to systematically review the fully decentralized methods in two settings:
maximizing a shared reward of all agents and maximizing the sum of individual
rewards of all agents, and discuss open questions and future research
directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04938">Advancing ECG Diagnosis Using Reinforcement Learning on Global Waveform Variations Related to P Wave and PR Interval. (arXiv:2401.04938v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Fatima_R/0/1/0/all/0/1">Rumsha Fatima</a>, <a href="http://arxiv.org/find/eess/1/au:+Younis_S/0/1/0/all/0/1">Shahzad Younis</a>, <a href="http://arxiv.org/find/eess/1/au:+Shaikh_F/0/1/0/all/0/1">Faraz Shaikh</a>, <a href="http://arxiv.org/find/eess/1/au:+Imran_H/0/1/0/all/0/1">Hamna Imran</a>, <a href="http://arxiv.org/find/eess/1/au:+Sultan_H/0/1/0/all/0/1">Haseeb Sultan</a>, <a href="http://arxiv.org/find/eess/1/au:+Rasool_S/0/1/0/all/0/1">Shahzad Rasool</a>, <a href="http://arxiv.org/find/eess/1/au:+Rafiq_M/0/1/0/all/0/1">Mehak Rafiq</a></p>
<p>The reliable diagnosis of cardiac conditions through electrocardiogram (ECG)
analysis critically depends on accurately detecting P waves and measuring the
PR interval. However, achieving consistent and generalizable diagnoses across
diverse populations presents challenges due to the inherent global variations
observed in ECG signals. This paper is focused on applying the Q learning
reinforcement algorithm to the various ECG datasets available in the
PhysioNet/Computing in Cardiology Challenge (CinC). Five ECG beats, including
Normal Sinus Rhythm, Atrial Flutter, Atrial Fibrillation, 1st Degree
Atrioventricular Block, and Left Atrial Enlargement, are included to study
variations of P waves and PR Interval on Lead II and Lead V1. Q-Agent
classified 71,672 beat samples in 8,867 patients with an average accuracy of
90.4% and only 9.6% average hamming loss over misclassification. The average
classification time at the 100th episode containing around 40,000 samples is
0.04 seconds. An average training reward of 344.05 is achieved at an alpha,
gamma, and SoftMax temperature rate of 0.001, 0.9, and 0.1, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04960">Why Change Your Controller When You Can Change Your Planner: Drag-Aware Trajectory Generation for Quadrotor Systems. (arXiv:2401.04960v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikanthan_A/0/1/0/all/0/1">Anusha Srikanthan</a>, <a href="http://arxiv.org/find/cs/1/au:+Folk_S/0/1/0/all/0/1">Spencer Folk</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vijay Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Matni_N/0/1/0/all/0/1">Nikolai Matni</a></p>
<p>Motivated by the increasing use of quadrotors for payload delivery, we
consider a joint trajectory generation and feedback control design problem for
a quadrotor experiencing aerodynamic wrenches. Unmodeled aerodynamic drag
forces from carried payloads can lead to catastrophic outcomes. Prior work
model aerodynamic effects as residual dynamics or external disturbances in the
control problem leading to a reactive policy that could be catastrophic.
Moreover, redesigning controllers and tuning control gains on hardware
platforms is a laborious effort. In this paper, we argue that adapting the
trajectory generation component keeping the controller fixed can improve
trajectory tracking for quadrotor systems experiencing drag forces. To achieve
this, we formulate a drag-aware planning problem by applying a suitable
relaxation to an optimal quadrotor control problem, introducing a tracking cost
function which measures the ability of a controller to follow a reference
trajectory. This tracking cost function acts as a regularizer in trajectory
generation and is learned from data obtained from simulation. Our experiments
in both simulation and on the Crazyflie hardware platform show that changing
the planner reduces tracking error by as much as 83%. Evaluation on hardware
demonstrates that our planned path, as opposed to a baseline, avoids controller
saturation and catastrophic outcomes during aggressive maneuvers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04965">ConvConcatNet: a deep convolutional neural network to reconstruct mel spectrogram from the EEG. (arXiv:2401.04965v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1">Xiran Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1">Yujie Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1">Haolin Zhu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zechen Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1">Xihong Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Jing Chen</a></p>
<p>To investigate the processing of speech in the brain, simple linear models
are commonly used to establish a relationship between brain signals and speech
features. However, these linear models are ill-equipped to model a highly
dynamic and complex non-linear system like the brain. Although non-linear
methods with neural networks have been developed recently, reconstructing
unseen stimuli from unseen subjects' EEG is still a highly challenging task.
This work presents a novel method, ConvConcatNet, to reconstruct mel-specgrams
from EEG, in which the deep convolution neural network and extensive
concatenation operation were combined. With our ConvConcatNet model, the
Pearson correlation between the reconstructed and the target mel-spectrogram
can achieve 0.0420, which was ranked as No.1 in the Task 2 of the Auditory EEG
Challenge. The codes and models to implement our work will be available on
Github: https://github.com/xuxiran/ConvConcatNet
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04978">Closed-Form Interpretation of Neural Network Classifiers with Symbolic Regression Gradients. (arXiv:2401.04978v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wetzel_S/0/1/0/all/0/1">Sebastian Johann Wetzel</a></p>
<p>I introduce a unified framework for interpreting neural network classifiers
tailored toward automated scientific discovery. In contrast to neural
network-based regression, for classification, it is in general impossible to
find a one-to-one mapping from the neural network to a symbolic equation even
if the neural network itself bases its classification on a quantity that can be
written as a closed-form equation. In this paper, I embed a trained neural
network into an equivalence class of classifying functions that base their
decisions on the same quantity. I interpret neural networks by finding an
intersection between this equivalence class and human-readable equations
defined by the search space of symbolic regression. The approach is not limited
to classifiers or full neural networks and can be applied to arbitrary neurons
in hidden layers or latent spaces or to simplify the process of interpreting
neural network regressors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04979">Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series. (arXiv:2401.04979v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">YongKyung Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1">Dongyoung Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungil Kim</a></p>
<p>To handle the complexities of irregular and incomplete time series data, we
propose an invertible solution of Neural Differential Equations (NDE)-based
method. While NDE-based methods are a powerful method for analyzing
irregularly-sampled time series, they typically do not guarantee reversible
transformations in their standard form. Our method suggests the variation of
Neural Controlled Differential Equations (Neural CDEs) with Neural Flow, which
ensures invertibility while maintaining a lower computational burden.
Additionally, it enables the training of a dual latent space, enhancing the
modeling of dynamic temporal dynamics. Our research presents an advanced
framework that excels in both classification and interpolation tasks. At the
core of our approach is an enhanced dual latent states architecture, carefully
designed for high precision across various time series tasks. Empirical
analysis demonstrates that our method significantly outperforms existing
models. This work significantly advances irregular time series analysis,
introducing innovative techniques and offering a versatile tool for diverse
practical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04986">Structure-Preserving Physics-Informed Neural Networks With Energy or Lyapunov Structure. (arXiv:2401.04986v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1">Haoyu Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyatake_Y/0/1/0/all/0/1">Yuto Miyatake</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1">Wenjun Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Shikui Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Furihata_D/0/1/0/all/0/1">Daisuke Furihata</a></p>
<p>Recently, there has been growing interest in using physics-informed neural
networks (PINNs) to solve differential equations. However, the preservation of
structure, such as energy and stability, in a suitable manner has yet to be
established. This limitation could be a potential reason why the learning
process for PINNs is not always efficient and the numerical results may suggest
nonphysical behavior. Besides, there is little research on their applications
on downstream tasks. To address these issues, we propose structure-preserving
PINNs to improve their performance and broaden their applications for
downstream tasks. Firstly, by leveraging prior knowledge about the physical
system, a structure-preserving loss function is designed to assist the PINN in
learning the underlying structure. Secondly, a framework that utilizes
structure-preserving PINN for robust image recognition is proposed. Here,
preserving the Lyapunov structure of the underlying system ensures the
stability of the system. Experimental results demonstrate that the proposed
method improves the numerical accuracy of PINNs for partial differential
equations. Furthermore, the robustness of the model against adversarial
perturbations in image data is enhanced.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04993">AdaFed: Fair Federated Learning via Adaptive Common Descent Direction. (arXiv:2401.04993v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hamidi_S/0/1/0/all/0/1">Shayan Mohajer Hamidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">En-Hui Yang</a></p>
<p>Federated learning (FL) is a promising technology via which some edge
devices/clients collaboratively train a machine learning model orchestrated by
a server. Learning an unfair model is known as a critical problem in federated
learning, where the trained model may unfairly advantage or disadvantage some
of the devices. To tackle this problem, in this work, we propose AdaFed. The
goal of AdaFed is to find an updating direction for the server along which (i)
all the clients' loss functions are decreasing; and (ii) more importantly, the
loss functions for the clients with larger values decrease with a higher rate.
AdaFed adaptively tunes this common direction based on the values of local
gradients and loss functions. We validate the effectiveness of AdaFed on a
suite of federated datasets, and demonstrate that AdaFed outperforms
state-of-the-art fair FL methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05007">Temporal Analysis of World Disaster Risk:A Machine Learning Approach to Cluster Dynamics. (arXiv:2401.05007v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mukendi_C/0/1/0/all/0/1">Christian Mulomba Mukendi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Hyebong Choi</a></p>
<p>he evaluation of the impact of actions undertaken is essential in management.
This paper assesses the impact of efforts considered to mitigate risk and
create safe environments on a global scale. We measure this impact by looking
at the probability of improvement over a specific short period of time. Using
the World Risk Index, we conduct a temporal analysis of global disaster risk
dynamics from 2011 to 2021. This temporal exploration through the lens of the
World Risk Index provides insights into the complex dynamics of disaster risk.
We found that, despite sustained efforts, the global landscape remains divided
into two main clusters: high susceptibility and moderate susceptibility,
regardless of geographical location. This clustering was achieved using a
semi-supervised approach through the Label Spreading algorithm, with 98%
accuracy. We also found that the prediction of clusters achieved through
supervised learning on the period considered in this study (one, three, and
five years) showed that the Logistic regression (almost 99% at each stage)
performed better than other classifiers. This suggests that the current
policies and mechanisms are not effective in helping countries move from a
hazardous position to a safer one during the period considered. In fact,
statistical projections using a scenario analysis indicate that there is only a
1% chance of such a shift occurring within a five-year timeframe. This sobering
reality highlights the need for a paradigm shift. Traditional long-term
disaster management strategies are not effective for countries that are highly
vulnerable. Our findings indicate the need for an innovative approach that is
tailored to the specific vulnerabilities of these nations. As the threat of
vulnerability persists, our research calls for the development of new
strategies that can effectively address the ongoing challenges of disaster risk
management
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05012">HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling for Long-Term Forecasting. (arXiv:2401.05012v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shubao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Ming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zhaoxiang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chengyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zengxiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1">Qingsong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a></p>
<p>Time series forecasting is crucial and challenging in the real world. The
recent surge in interest regarding time series foundation models, which cater
to a diverse array of downstream tasks, is noteworthy. However, existing
methods often overlook the multi-scale nature of time series, an aspect crucial
for precise forecasting. To bridge this gap, we propose HiMTM, a hierarchical
multi-scale masked time series modeling method designed for long-term
forecasting. Specifically, it comprises four integral components: (1)
hierarchical multi-scale transformer (HMT) to capture temporal information at
different scales; (2) decoupled encoder-decoder (DED) forces the encoder to
focus on feature extraction, while the decoder to focus on pretext tasks; (3)
multi-scale masked reconstruction (MMR) provides multi-stage supervision
signals for pre-training; (4) cross-scale attention fine-tuning (CSA-FT) to
capture dependencies between different scales for forecasting. Collectively,
these components enhance multi-scale feature extraction capabilities in masked
time series modeling and contribute to improved prediction accuracy. We conduct
extensive experiments on 7 mainstream datasets to prove that HiMTM has obvious
advantages over contemporary self-supervised and end-to-end learning methods.
The effectiveness of HiMTM is further showcased by its application in the
industry of natural gas demand forecasting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05015">An Information Theoretic Approach to Interaction-Grounded Learning. (arXiv:2401.05015v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaoyan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Farnia_F/0/1/0/all/0/1">Farzan Farnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_H/0/1/0/all/0/1">Ho-fung Leung</a></p>
<p>Reinforcement learning (RL) problems where the learner attempts to infer an
unobserved reward from some feedback variables have been studied in several
recent papers. The setting of Interaction-Grounded Learning (IGL) is an example
of such feedback-based reinforcement learning tasks where the learner optimizes
the return by inferring latent binary rewards from the interaction with the
environment. In the IGL setting, a relevant assumption used in the RL
literature is that the feedback variable $Y$ is conditionally independent of
the context-action $(X,A)$ given the latent reward $R$. In this work, we
propose Variational Information-based IGL (VI-IGL) as an information-theoretic
method to enforce the conditional independence assumption in the IGL-based RL
problem. The VI-IGL framework learns a reward decoder using an
information-based objective based on the conditional mutual information (MI)
between the context-action $(X,A)$ and the feedback variable $Y$ observed from
the environment. To estimate and optimize the information-based terms for the
continuous random variables in the RL problem, VI-IGL leverages the variational
representation of mutual information and results in a min-max optimization
problem. Furthermore, we extend the VI-IGL framework to general $f$-Information
measures in the information theory literature, leading to the generalized
$f$-VI-IGL framework to address the RL problem under the IGL condition.
Finally, we provide the empirical results of applying the VI-IGL method to
several reinforcement learning settings, which indicate an improved performance
in comparison to the previous IGL-based RL algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05041">Learning to Configure Mathematical Programming Solvers by Mathematical Programming. (arXiv:2401.05041v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Iommazzo_G/0/1/0/all/0/1">Gabriele Iommazzo</a>, <a href="http://arxiv.org/find/math/1/au:+DAmbrosio_C/0/1/0/all/0/1">Claudia D&#x27;Ambrosio</a>, <a href="http://arxiv.org/find/math/1/au:+Frangioni_A/0/1/0/all/0/1">Antonio Frangioni</a>, <a href="http://arxiv.org/find/math/1/au:+Liberti_L/0/1/0/all/0/1">Leo Liberti</a></p>
<p>We discuss the issue of finding a good mathematical programming solver
configuration for a particular instance of a given problem, and we propose a
two-phase approach to solve it. In the first phase we learn the relationships
between the instance, the configuration and the performance of the configured
solver on the given instance. A specific difficulty of learning a good solver
configuration is that parameter settings may not all be independent; this
requires enforcing (hard) constraints, something that many widely used
supervised learning methods cannot natively achieve. We tackle this issue in
the second phase of our approach, where we use the learnt information to
construct and solve an optimization problem having an explicit representation
of the dependency/consistency constraints on the configuration parameter
settings. We discuss computational results for two different instantiations of
this approach on a unit commitment problem arising in the short-term planning
of hydro valleys. We use logistic regression as the supervised learning
methodology and consider CPLEX as the solver of interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05043">CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks. (arXiv:2401.05043v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaizheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shariatmadar_K/0/1/0/all/0/1">Keivan Shariatmadar</a>, <a href="http://arxiv.org/find/cs/1/au:+Manchingal_S/0/1/0/all/0/1">Shireen Kudukkil Manchingal</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuzzolin_F/0/1/0/all/0/1">Fabio Cuzzolin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moens_D/0/1/0/all/0/1">David Moens</a>, <a href="http://arxiv.org/find/cs/1/au:+Hallez_H/0/1/0/all/0/1">Hans Hallez</a></p>
<p>Uncertainty estimation is increasingly attractive for improving the
reliability of neural networks. In this work, we present novel credal-set
interval neural networks (CreINNs) designed for classification tasks. CreINNs
preserve the traditional interval neural network structure, capturing weight
uncertainty through deterministic intervals, while forecasting credal sets
using the mathematical framework of probability intervals. Experimental
validations on an out-of-distribution detection benchmark (CIFAR10 vs SVHN)
showcase that CreINNs outperform epistemic uncertainty estimation when compared
to variational Bayesian neural networks (BNNs) and deep ensembles (DEs).
Furthermore, CreINNs exhibit a notable reduction in computational complexity
compared to variational BNNs and demonstrate smaller model sizes than DEs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05049">Content-Aware Depth-Adaptive Image Restoration. (arXiv:2401.05049v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vargis_T/0/1/0/all/0/1">Tom Richard Vargis</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghiasvand_S/0/1/0/all/0/1">Siavash Ghiasvand</a></p>
<p>This work prioritizes building a modular pipeline that utilizes existing
models to systematically restore images, rather than creating new restoration
models from scratch. Restoration is carried out at an object-specific level,
with each object regenerated using its corresponding class label information.
The approach stands out by providing complete user control over the entire
restoration process. Users can select models for specialized restoration steps,
customize the sequence of steps to meet their needs, and refine the resulting
regenerated image with depth awareness. The research provides two distinct
pathways for implementing image regeneration, allowing for a comparison of
their respective strengths and limitations. The most compelling aspect of this
versatile system is its adaptability. This adaptability enables users to target
particular object categories, including medical images, by providing models
that are trained on those object classes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05064">Singer Identity Representation Learning using Self-Supervised Techniques. (arXiv:2401.05064v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Torres_B/0/1/0/all/0/1">Bernardo Torres</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattner_S/0/1/0/all/0/1">Stefan Lattner</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a></p>
<p>Significant strides have been made in creating voice identity representations
using speech data. However, the same level of progress has not been achieved
for singing voices. To bridge this gap, we suggest a framework for training
singer identity encoders to extract representations suitable for various
singing-related tasks, such as singing voice similarity and synthesis. We
explore different self-supervised learning techniques on a large collection of
isolated vocal tracks and apply data augmentations during training to ensure
that the representations are invariant to pitch and content variations. We
evaluate the quality of the resulting representations on singer similarity and
identification tasks across multiple datasets, with a particular emphasis on
out-of-domain generalization. Our proposed framework produces high-quality
embeddings that outperform both speaker verification and wav2vec 2.0
pre-trained baselines on singing voice while operating at 44.1 kHz. We release
our code and trained models to facilitate further research on singing voice and
related areas.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05069">MISS: Multiclass Interpretable Scoring Systems. (arXiv:2401.05069v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Grzeszczyk_M/0/1/0/all/0/1">Michal K. Grzeszczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sitek_A/0/1/0/all/0/1">Arkadiusz Sitek</a></p>
<p>In this work, we present a novel, machine-learning approach for constructing
Multiclass Interpretable Scoring Systems (MISS) - a fully data-driven
methodology for generating single, sparse, and user-friendly scoring systems
for multiclass classification problems. Scoring systems are commonly utilized
as decision support models in healthcare, criminal justice, and other domains
where interpretability of predictions and ease of use are crucial. Prior
methods for data-driven scoring, such as SLIM (Supersparse Linear Integer
Model), were limited to binary classification tasks and extensions to
multiclass domains were primarily accomplished via one-versus-all-type
techniques. The scores produced by our method can be easily transformed into
class probabilities via the softmax function. We demonstrate techniques for
dimensionality reduction and heuristics that enhance the training efficiency
and decrease the optimality gap, a measure that can certify the optimality of
the model. Our approach has been extensively evaluated on datasets from various
domains, and the results indicate that it is competitive with other machine
learning models in terms of classification performance metrics and provides
well-calibrated class probabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05073">Hierarchical Classification of Transversal Skills in Job Ads Based on Sentence Embeddings. (arXiv:2401.05073v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leon_F/0/1/0/all/0/1">Florin Leon</a>, <a href="http://arxiv.org/find/cs/1/au:+Gavrilescu_M/0/1/0/all/0/1">Marius Gavrilescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Floria_S/0/1/0/all/0/1">Sabina-Adriana Floria</a>, <a href="http://arxiv.org/find/cs/1/au:+Minea_A/0/1/0/all/0/1">Alina-Adriana Minea</a></p>
<p>This paper proposes a classification framework aimed at identifying
correlations between job ad requirements and transversal skill sets, with a
focus on predicting the necessary skills for individual job descriptions using
a deep learning model. The approach involves data collection, preprocessing,
and labeling using ESCO (European Skills, Competences, and Occupations)
taxonomy. Hierarchical classification and multi-label strategies are used for
skill identification, while augmentation techniques address data imbalance,
enhancing model robustness. A comparison between results obtained with
English-specific and multi-language sentence embedding models reveals close
accuracy. The experimental case studies detail neural network configurations,
hyperparameters, and cross-validation results, highlighting the efficacy of the
hierarchical approach and the suitability of the multi-language model for the
diverse European job market. Thus, a new approach is proposed for the
hierarchical classification of transversal skills from job ads.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05097">Any-Way Meta Learning. (arXiv:2401.05097v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junhoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yearim Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyunho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1">Nojun Kwak</a></p>
<p>Although meta-learning seems promising performance in the realm of rapid
adaptability, it is constrained by fixed cardinality. When faced with tasks of
varying cardinalities that were unseen during training, the model lacks its
ability. In this paper, we address and resolve this challenge by harnessing
`label equivalence' emerged from stochastic numeric label assignments during
episodic task sampling. Questioning what defines ``true" meta-learning, we
introduce the ``any-way" learning paradigm, an innovative model training
approach that liberates model from fixed cardinality constraints. Surprisingly,
this model not only matches but often outperforms traditional fixed-way models
in terms of performance, convergence speed, and stability. This disrupts
established notions about domain generalization. Furthermore, we argue that the
inherent label equivalence naturally lacks semantic information. To bridge this
semantic information gap arising from label equivalence, we further propose a
mechanism for infusing semantic class information into the model. This would
enhance the model's comprehension and functionality. Experiments conducted on
renowned architectures like MAML and ProtoNet affirm the effectiveness of our
method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05111">Noise-robust zero-shot text-to-speech synthesis conditioned on self-supervised speech-representation model with adapters. (arXiv:2401.05111v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fujita_K/0/1/0/all/0/1">Kenichi Fujita</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_H/0/1/0/all/0/1">Hiroshi Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashihara_T/0/1/0/all/0/1">Takanori Ashihara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanagawa_H/0/1/0/all/0/1">Hiroki Kanagawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Delcroix_M/0/1/0/all/0/1">Marc Delcroix</a>, <a href="http://arxiv.org/find/cs/1/au:+Moriya_T/0/1/0/all/0/1">Takafumi Moriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ijima_Y/0/1/0/all/0/1">Yusuke Ijima</a></p>
<p>The zero-shot text-to-speech (TTS) method, based on speaker embeddings
extracted from reference speech using self-supervised learning (SSL) speech
representations, can reproduce speaker characteristics very accurately.
However, this approach suffers from degradation in speech synthesis quality
when the reference speech contains noise. In this paper, we propose a
noise-robust zero-shot TTS method. We incorporated adapters into the SSL model,
which we fine-tuned with the TTS model using noisy reference speech. In
addition, to further improve performance, we adopted a speech enhancement (SE)
front-end. With these improvements, our proposed SSL-based zero-shot TTS
achieved high-quality speech synthesis with noisy reference speech. Through the
objective and subjective evaluations, we confirmed that the proposed method is
highly robust to noise in reference speech, and effectively works in
combination with SE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05121">Photonics for Sustainable Computing. (arXiv:2401.05121v1 [cs.ET])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fayza_F/0/1/0/all/0/1">Farbin Fayza</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1">Satyavolu Papa Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bunandar_D/0/1/0/all/0/1">Darius Bunandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1">Udit Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Ajay Joshi</a></p>
<p>Photonic integrated circuits are finding use in a variety of applications
including optical transceivers, LIDAR, bio-sensing, photonic quantum computing,
and Machine Learning (ML). In particular, with the exponentially increasing
sizes of ML models, photonics-based accelerators are getting special attention
as a sustainable solution because they can perform ML inferences with multiple
orders of magnitude higher energy efficiency than CMOS-based accelerators.
However, recent studies have shown that hardware manufacturing and
infrastructure contribute significantly to the carbon footprint of computing
devices, even surpassing the emissions generated during their use. For example,
the manufacturing process accounts for 74% of the total carbon emissions from
Apple in 2019. This prompts us to ask -- if we consider both the embodied
(manufacturing) and operational carbon cost of photonics, is it indeed a viable
avenue for a sustainable future? So, in this paper, we build a carbon footprint
model for photonic chips and investigate the sustainability of photonics-based
accelerators by conducting a case study on ADEPT, a photonics-based accelerator
for deep neural network inference. Our analysis shows that photonics can reduce
both operational and embodied carbon footprints with its high energy efficiency
and at least 4$\times$ less fabrication carbon cost per unit area than 28 nm
CMOS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05126">Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving Vision Transformer. (arXiv:2401.05126v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nagamori_T/0/1/0/all/0/1">Teru Nagamori</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiota_S/0/1/0/all/0/1">Sayaka Shiota</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiya_H/0/1/0/all/0/1">Hitoshi Kiya</a></p>
<p>We propose a novel method for privacy-preserving deep neural networks (DNNs)
with the Vision Transformer (ViT). The method allows us not only to train
models and test with visually protected images but to also avoid the
performance degradation caused from the use of encrypted images, whereas
conventional methods cannot avoid the influence of image encryption. A domain
adaptation method is used to efficiently fine-tune ViT with encrypted images.
In experiments, the method is demonstrated to outperform conventional methods
in an image classification task on the CIFAR-10 and ImageNet datasets in terms
of classification accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05145">Machine Learning to Promote Translational Research: Predicting Patent and Clinical Trial Inclusion in Dementia Research. (arXiv:2401.05145v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Beinat_M/0/1/0/all/0/1">Matilda Beinat</a>, <a href="http://arxiv.org/find/cs/1/au:+Beinat_J/0/1/0/all/0/1">Julian Beinat</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoaib_M/0/1/0/all/0/1">Mohammed Shoaib</a>, <a href="http://arxiv.org/find/cs/1/au:+Magenti_J/0/1/0/all/0/1">Jorge Gomez Magenti</a></p>
<p>Projected to impact 1.6 million people in the UK by 2040 and costing
{\pounds}25 billion annually, dementia presents a growing challenge to society.
This study, a pioneering effort to predict the translational potential of
dementia research using machine learning, hopes to address the slow translation
of fundamental discoveries into practical applications despite dementia's
significant societal and economic impact. We used the Dimensions database to
extract data from 43,091 UK dementia research publications between the years
1990-2023, specifically metadata (authors, publication year etc.), concepts
mentioned in the paper, and the paper abstract. To prepare the data for machine
learning we applied methods such as one hot encoding and/or word embeddings. We
trained a CatBoost Classifier to predict if a publication will be cited in a
future patent or clinical trial. We trained several model variations. The model
combining metadata, concept, and abstract embeddings yielded the highest
performance: for patent predictions, an Area Under the Receiver Operating
Characteristic Curve (AUROC) of 0.84 and 77.17% accuracy; for clinical trial
predictions, an AUROC of 0.81 and 75.11% accuracy. The results demonstrate that
integrating machine learning within current research methodologies can uncover
overlooked publications, expediting the identification of promising research
and potentially transforming dementia research by predicting real-world impact
and guiding translational strategies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05146">Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics. (arXiv:2401.05146v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Romandini_N/0/1/0/all/0/1">Nicol&#xf2; Romandini</a>, <a href="http://arxiv.org/find/cs/1/au:+Mora_A/0/1/0/all/0/1">Alessio Mora</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazzocca_C/0/1/0/all/0/1">Carlo Mazzocca</a>, <a href="http://arxiv.org/find/cs/1/au:+Montanari_R/0/1/0/all/0/1">Rebecca Montanari</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellavista_P/0/1/0/all/0/1">Paolo Bellavista</a></p>
<p>Federated Learning (FL) enables collaborative training of a Machine Learning
(ML) model across multiple parties, facilitating the preservation of users' and
institutions' privacy by keeping data stored locally. Instead of centralizing
raw data, FL exchanges locally refined model parameters to build a global model
incrementally. While FL is more compliant with emerging regulations such as the
European General Data Protection Regulation (GDPR), ensuring the right to be
forgotten in this context - allowing FL participants to remove their data
contributions from the learned model - remains unclear. In addition, it is
recognized that malicious clients may inject backdoors into the global model
through updates, e.g. to generate mispredictions on specially crafted data
examples. Consequently, there is the need for mechanisms that can guarantee
individuals the possibility to remove their data and erase malicious
contributions even after aggregation, without compromising the already acquired
"good" knowledge. This highlights the necessity for novel Federated Unlearning
(FU) algorithms, which can efficiently remove specific clients' contributions
without full model retraining. This survey provides background concepts,
empirical evidence, and practical guidelines to design/implement efficient FU
schemes. Our study includes a detailed analysis of the metrics for evaluating
unlearning in FL and presents an in-depth literature review categorizing
state-of-the-art FU contributions under a novel taxonomy. Finally, we outline
the most relevant and still open technical challenges, by identifying the most
promising research directions in the field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05193">Experiment Planning with Function Approximation. (arXiv:2401.05193v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jonathan N. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1">Emma Brunskill</a></p>
<p>We study the problem of experiment planning with function approximation in
contextual bandit problems. In settings where there is a significant overhead
to deploying adaptive algorithms -- for example, when the execution of the data
collection policies is required to be distributed, or a human in the loop is
needed to implement these policies -- producing in advance a set of policies
for data collection is paramount. We study the setting where a large dataset of
contexts but not rewards is available and may be used by the learner to design
an effective data collection strategy. Although when rewards are linear this
problem has been well studied, results are still missing for more complex
reward models. In this work we propose two experiment planning strategies
compatible with function approximation. The first is an eluder planning and
sampling procedure that can recover optimality guarantees depending on the
eluder dimension of the reward function class. For the second, we show that a
uniform sampler achieves competitive optimality rates in the setting where the
number of actions is small. We finalize our results introducing a statistical
gap fleshing out the fundamental differences between planning and adaptive
learning and provide results for planning with model selection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05206">Tailoring Frictional Properties of Surfaces Using Diffusion Models. (arXiv:2401.05206v1 [physics.comp-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Nordhagen_E/0/1/0/all/0/1">Even Marius Nordhagen</a>, <a href="http://arxiv.org/find/physics/1/au:+Sveinsson_H/0/1/0/all/0/1">Henrik Andersen Sveinsson</a>, <a href="http://arxiv.org/find/physics/1/au:+Malthe_Sorenssen_A/0/1/0/all/0/1">Anders Malthe-S&#xf8;renssen</a></p>
<p>This Letter introduces an approach for precisely designing surface friction
properties using a conditional generative machine learning model, specifically
a diffusion denoising probabilistic model (DDPM). We created a dataset of
synthetic surfaces with frictional properties determined by molecular dynamics
simulations, which trained the DDPM to predict surface structures from desired
frictional outcomes. Unlike traditional trial-and-error and numerical
optimization methods, our approach directly yields surface designs meeting
specified frictional criteria with high accuracy and efficiency. This
advancement in material surface engineering demonstrates the potential of
machine learning in reducing the iterative nature of surface design processes.
Our findings not only provide a new pathway for precise surface property
tailoring but also suggest broader applications in material science where
surface characteristics are critical.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05211">Error estimation for physics-informed neural networks with implicit Runge-Kutta methods. (arXiv:2401.05211v1 [physics.comp-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Stiasny_J/0/1/0/all/0/1">Jochen Stiasny</a>, <a href="http://arxiv.org/find/physics/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1">Spyros Chatzivasileiadis</a></p>
<p>The ability to accurately approximate trajectories of dynamical systems
enables their analysis, prediction, and control. Neural network (NN)-based
approximations have attracted significant interest due to fast evaluation with
good accuracy over long integration time steps. In contrast to established
numerical approximation schemes such as Runge-Kutta methods, the estimation of
the error of the NN-based approximations proves to be difficult. In this work,
we propose to use the NN's predictions in a high-order implicit Runge-Kutta
(IRK) method. The residuals in the implicit system of equations can be related
to the NN's prediction error, hence, we can provide an error estimate at
several points along a trajectory. We find that this error estimate highly
correlates with the NN's prediction error and that increasing the order of the
IRK method improves this estimate. We demonstrate this estimation methodology
for Physics-Informed Neural Network (PINNs) on the logistic equation as an
illustrative example and then apply it to a four-state electric generator model
that is regularly used in power system modelling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05218">Invariant Causal Prediction with Locally Linear Models. (arXiv:2401.05218v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mey_A/0/1/0/all/0/1">Alexander Mey</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_R/0/1/0/all/0/1">Rui Manuel Castro</a></p>
<p>We consider the task of identifying the causal parents of a target variable
among a set of candidate variables from observational data. Our main assumption
is that the candidate variables are observed in different environments which
may, for example, correspond to different settings of a machine or different
time intervals in a dynamical process. Under certain assumptions different
environments can be regarded as interventions on the observed system. We assume
a linear relationship between target and covariates, which can be different in
each environment with the only restriction that the causal structure is
invariant across environments. This is an extension of the ICP
($\textbf{I}$nvariant $\textbf{C}$ausal $\textbf{P}$rediction) principle by
Peters et al. [2016], who assumed a fixed linear relationship across all
environments. Within our proposed setting we provide sufficient conditions for
identifiability of the causal parents and introduce a practical method called
LoLICaP ($\textbf{Lo}$cally $\textbf{L}$inear $\textbf{I}$nvariant
$\textbf{Ca}$usal $\textbf{P}$rediction), which is based on a hypothesis test
for parent identification using a ratio of minimum and maximum statistics. We
then show in a simplified setting that the statistical power of LoLICaP
converges exponentially fast in the sample size, and finally we analyze the
behavior of LoLICaP experimentally in more general settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05224">Do Vision and Language Encoders Represent the World Similarly?. (arXiv:2401.05224v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maniparambil_M/0/1/0/all/0/1">Mayug Maniparambil</a>, <a href="http://arxiv.org/find/cs/1/au:+Akshulakov_R/0/1/0/all/0/1">Raiymbek Akshulakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Djilali_Y/0/1/0/all/0/1">Yasser Abdelaziz Dahou Djilali</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1">Sanath Narayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Seddik_M/0/1/0/all/0/1">Mohamed El Amine Seddik</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1">Karttikeya Mangalam</a>, <a href="http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1">Noel E. O&#x27;Connor</a></p>
<p>Aligned text-image encoders such as CLIP have become the de facto model for
vision-language tasks. Furthermore, modality-specific encoders achieve
impressive performances in their respective domains. This raises a central
question: does an alignment exist between uni-modal vision and language
encoders since they fundamentally represent the same physical world? Analyzing
the latent spaces structure of vision and language models on image-caption
benchmarks using the Centered Kernel Alignment (CKA), we find that the
representation spaces of unaligned and aligned encoders are semantically
similar. In the absence of statistical similarity in aligned encoders like
CLIP, we show that a possible matching of unaligned encoders exists without any
training. We frame this as a seeded graph-matching problem exploiting the
semantic similarity between graphs and propose two methods - a Fast Quadratic
Assignment Problem optimization, and a novel localized CKA metric-based
matching/retrieval. We demonstrate the effectiveness of this on several
downstream tasks including cross-lingual, cross-domain caption matching and
image classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05226">Learning effective good variables from physical data. (arXiv:2401.05226v1 [physics.data-an])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Barletta_G/0/1/0/all/0/1">Giulio Barletta</a>, <a href="http://arxiv.org/find/physics/1/au:+Trezza_G/0/1/0/all/0/1">Giovanni Trezza</a>, <a href="http://arxiv.org/find/physics/1/au:+Chiavazzo_E/0/1/0/all/0/1">Eliodoro Chiavazzo</a></p>
<p>We assume that a sufficiently large database is available, where a physical
property of interest and a number of associated ruling primitive variables or
observables are stored. We introduce and test two machine learning approaches
to discover possible groups or combinations of primitive variables: The first
approach is based on regression models whereas the second on classification
models. The variable group (here referred to as the new effective good
variable) can be considered as successfully found, when the physical property
of interest is characterized by the following effective invariant behaviour: In
the first method, invariance of the group implies invariance of the property up
to a given accuracy; in the other method, upon partition of the physical
property values into two or more classes, invariance of the group implies
invariance of the class. For the sake of illustration, the two methods are
successfully applied to two popular empirical correlations describing the
convective heat transfer phenomenon and to the Newton's law of universal
gravitation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05233">Taming &quot;data-hungry&quot; reinforcement learning? Stability in continuous state-action spaces. (arXiv:2401.05233v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yaqi Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wainwright_M/0/1/0/all/0/1">Martin J. Wainwright</a></p>
<p>We introduce a novel framework for analyzing reinforcement learning (RL) in
continuous state-action spaces, and use it to prove fast rates of convergence
in both off-line and on-line settings. Our analysis highlights two key
stability properties, relating to how changes in value functions and/or
policies affect the Bellman operator and occupation measures. We argue that
these properties are satisfied in many continuous state-action Markov decision
processes, and demonstrate how they arise naturally when using linear function
approximation methods. Our analysis offers fresh perspectives on the roles of
pessimism and optimism in off-line and on-line RL, and highlights the
connection between off-line RL and transfer learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05240">Decoupling Decision-Making in Fraud Prevention through Classifier Calibration for Business Logic Action. (arXiv:2401.05240v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luzio_E/0/1/0/all/0/1">Emanuele Luzio</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1">Moacir Antonelli Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Arevalo_C/0/1/0/all/0/1">Christian Ramirez Arevalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Argerich_L/0/1/0/all/0/1">Luis Argerich</a></p>
<p>Machine learning models typically focus on specific targets like creating
classifiers, often based on known population feature distributions in a
business context. However, models calculating individual features adapt over
time to improve precision, introducing the concept of decoupling: shifting from
point evaluation to data distribution. We use calibration strategies as
strategy for decoupling machine learning (ML) classifiers from score-based
actions within business logic frameworks. To evaluate these strategies, we
perform a comparative analysis using a real-world business scenario and
multiple ML models. Our findings highlight the trade-offs and performance
implications of the approach, offering valuable insights for practitioners
seeking to optimize their decoupling efforts. In particular, the Isotonic and
Beta calibration methods stand out for scenarios in which there is shift
between training and testing data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05244">Reliability Analysis of Complex Systems using Subset Simulations with Hamiltonian Neural Networks. (arXiv:2401.05244v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Thaler_D/0/1/0/all/0/1">Denny Thaler</a>, <a href="http://arxiv.org/find/stat/1/au:+Dhulipala_S/0/1/0/all/0/1">Somayajulu L. N. Dhulipala</a>, <a href="http://arxiv.org/find/stat/1/au:+Bamer_F/0/1/0/all/0/1">Franz Bamer</a>, <a href="http://arxiv.org/find/stat/1/au:+Markert_B/0/1/0/all/0/1">Bernd Markert</a>, <a href="http://arxiv.org/find/stat/1/au:+Shields_M/0/1/0/all/0/1">Michael D. Shields</a></p>
<p>We present a new Subset Simulation approach using Hamiltonian neural
network-based Monte Carlo sampling for reliability analysis. The proposed
strategy combines the superior sampling of the Hamiltonian Monte Carlo method
with computationally efficient gradient evaluations using Hamiltonian neural
networks. This combination is especially advantageous because the neural
network architecture conserves the Hamiltonian, which defines the acceptance
criteria of the Hamiltonian Monte Carlo sampler. Hence, this strategy achieves
high acceptance rates at low computational cost. Our approach estimates small
failure probabilities using Subset Simulations. However, in low-probability
sample regions, the gradient evaluation is particularly challenging. The
remarkable accuracy of the proposed strategy is demonstrated on different
reliability problems, and its efficiency is compared to the traditional
Hamiltonian Monte Carlo method. We note that this approach can reach its
limitations for gradient estimations in low-probability regions of complex and
high-dimensional distributions. Thus, we propose techniques to improve gradient
prediction in these particular situations and enable accurate estimations of
the probability of failure. The highlight of this study is the reliability
analysis of a system whose parameter distributions must be inferred with
Bayesian inference problems. In such a case, the Hamiltonian Monte Carlo method
requires a full model evaluation for each gradient evaluation and, therefore,
comes at a very high cost. However, using Hamiltonian neural networks in this
framework replaces the expensive model evaluation, resulting in tremendous
improvements in computational efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05251">ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries. (arXiv:2401.05251v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1">Thomas Rudolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Flogel_D/0/1/0/all/0/1">Daniel Fl&#xf6;gel</a>, <a href="http://arxiv.org/find/cs/1/au:+Schurmann_T/0/1/0/all/0/1">Tobias Sch&#xfc;rmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Suss_S/0/1/0/all/0/1">Simon S&#xfc;&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwab_S/0/1/0/all/0/1">Stefan Schwab</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohmann_S/0/1/0/all/0/1">S&#xf6;ren Hohmann</a></p>
<p>Robust and performant controllers are essential for industrial applications.
However, deriving controller parameters for complex and nonlinear systems is
challenging and time-consuming. To facilitate automatic controller
parametrization, this work presents a novel approach using deep reinforcement
learning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the
control of parameter-variant systems, a class of systems with complex behavior
which depends on the operating conditions. For this system class,
gain-scheduling control structures are widely used in applications across
industries due to well-known design principles. Facilitating the expensive
controller parametrization task regarding these control structures, we deploy
an DRL agent. Based on control system observations, the agent autonomously
decides how to adapt the controller parameters. We make the adaptation process
more efficient by introducing BSGs to map the controller parameters which may
depend on numerous operating conditions. To preprocess time-series data and
extract a fixed-length feature vector, we use a long short-term memory (LSTM)
neural networks. Furthermore, this work contributes actor regularizations that
are relevant to real-world environments which differ from training.
Accordingly, we apply dropout layer normalization to the actor and critic
networks of the truncated quantile critic (TQC) algorithm. To show our
approach's working principle and effectiveness, we train and evaluate the DRL
agent on the parametrization task of an industrial control structure with
parameter lookup tables.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05268">AUTOACT: Automatic Agent Learning from Scratch via Self-Planning. (arXiv:2401.05268v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1">Shuofei Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_R/0/1/0/all/0/1">Runnan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yujie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuchen Eleanor Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1">Chengfei Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a></p>
<p>Language agents have achieved considerable performance on various complex
tasks. Despite the incessant exploration in this field, existing language agent
systems still struggle with costly, non-reproducible data reliance and face the
challenge of compelling a single model for multiple functions. To this end, we
introduce AutoAct, an automatic agent learning framework that does not rely on
large-scale annotated data and synthetic trajectories from closed-source models
(e.g., GPT-4). Given limited data with a tool library, AutoAct first
automatically synthesizes planning trajectories without any assistance from
humans or strong closed-source models. Then, AutoAct leverages a
division-of-labor strategy to automatically differentiate based on the target
task information and synthesized trajectories, producing a sub-agent group to
complete the task. We conduct comprehensive experiments with different LLMs,
which demonstrates that AutoAct yields better or parallel performance compared
to various strong baselines. We even notice that AutoAct, when using the
Llama-2-13b model, can achieve performance comparable to that of the
GPT-3.5-Turbo agent. Code will be available at
https://github.com/zjunlp/AutoAct.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05295">Synthesis of pulses from particle detectors with a Generative Adversarial Network (GAN). (arXiv:2401.05295v1 [physics.ins-det])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Regadio_A/0/1/0/all/0/1">Alberto Regad&#xed;o</a>, <a href="http://arxiv.org/find/physics/1/au:+Esteban_L/0/1/0/all/0/1">Luis Esteban</a>, <a href="http://arxiv.org/find/physics/1/au:+Sanchez_Prieto_S/0/1/0/all/0/1">Sebasti&#xe1;n S&#xe1;nchez-Prieto</a></p>
<p>To address the possible lack or total absence of pulses from particle
detectors during the development of its associate electronics, we propose a
model that can generate them without losing the features of the real ones. This
model is based on artificial neural networks, namely Generative Adversarial
Networks (GAN). We describe the proposed network architecture, its training
methodology and the approach to train the GAN with real pulses from a
scintillator receiving radiation from sources of ${}^{137}$Cs and ${}^{22}$Na.
The Generator was installed in a Xilinx's System-On-Chip (SoC). We show how the
network is capable of generating pulses with the same shape as the real ones
that even match the data distributions in the original pulse-height histogram
data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05304">Can Probabilistic Feedback Drive User Impacts in Online Platforms?. (arXiv:2401.05304v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jessica Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Flanigan_B/0/1/0/all/0/1">Bailey Flanigan</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1">Nika Haghtalab</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagadeesan_M/0/1/0/all/0/1">Meena Jagadeesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1">Chara Podimata</a></p>
<p>A common explanation for negative user impacts of content recommender systems
is misalignment between the platform's objective and user welfare. In this
work, we show that misalignment in the platform's objective is not the only
potential cause of unintended impacts on users: even when the platform's
objective is fully aligned with user welfare, the platform's learning algorithm
can induce negative downstream impacts on users. The source of these user
impacts is that different pieces of content may generate observable user
reactions (feedback information) at different rates; these feedback rates may
correlate with content properties, such as controversiality or demographic
similarity of the creator, that affect the user experience. Since differences
in feedback rates can impact how often the learning algorithm engages with
different content, the learning algorithm may inadvertently promote content
with certain such properties. Using the multi-armed bandit framework with
probabilistic feedback, we examine the relationship between feedback rates and
a learning algorithm's engagement with individual arms for different no-regret
algorithms. We prove that no-regret algorithms can exhibit a wide range of
dependencies: if the feedback rate of an arm increases, some no-regret
algorithms engage with the arm more, some no-regret algorithms engage with the
arm less, and other no-regret algorithms engage with the arm approximately the
same number of times. From a platform design perspective, our results highlight
the importance of looking beyond regret when measuring an algorithm's
performance, and assessing the nature of a learning algorithm's engagement with
different types of content as well as their resulting downstream impacts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05308">Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks. (arXiv:2401.05308v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Farajzadeh_A/0/1/0/all/0/1">Amin Farajzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_A/0/1/0/all/0/1">Animesh Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Yanikomeroglu_H/0/1/0/all/0/1">Halim Yanikomeroglu</a></p>
<p>The deployment of federated learning (FL) within vertical heterogeneous
networks, such as those enabled by high-altitude platform station (HAPS),
offers the opportunity to engage a wide array of clients, each endowed with
distinct communication and computational capabilities. This diversity not only
enhances the training accuracy of FL models but also hastens their convergence.
Yet, applying FL in these expansive networks presents notable challenges,
particularly the significant non-IIDness in client data distributions. Such
data heterogeneity often results in slower convergence rates and reduced
effectiveness in model training performance. Our study introduces a client
selection strategy tailored to address this issue, leveraging user network
traffic behaviour. This strategy involves the prediction and classification of
clients based on their network usage patterns while prioritizing user privacy.
By strategically selecting clients whose data exhibit similar patterns for
participation in FL training, our approach fosters a more uniform and
representative data distribution across the network. Our simulations
demonstrate that this targeted client selection methodology significantly
reduces the training loss of FL models in HAPS networks, thereby effectively
tackling a crucial challenge in implementing large-scale FL systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05322">Arrival Time Prediction for Autonomous Shuttle Services in the Real World: Evidence from Five Cities. (arXiv:2401.05322v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schmidt_C/0/1/0/all/0/1">Carolin Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Tygesen_M/0/1/0/all/0/1">Mathias Tygesen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_F/0/1/0/all/0/1">Filipe Rodrigues</a></p>
<p>Urban mobility is on the cusp of transformation with the emergence of shared,
connected, and cooperative automated vehicles. Yet, for them to be accepted by
customers, trust in their punctuality is vital. Many pilot initiatives operate
without a fixed schedule, thus enhancing the importance of reliable arrival
time (AT) predictions. This study presents an AT prediction system for
autonomous shuttles, utilizing separate models for dwell and running time
predictions, validated on real-world data from five cities. Alongside
established methods such as XGBoost, we explore the benefits of integrating
spatial data using graph neural networks (GNN). To accurately handle the case
of a shuttle bypassing a stop, we propose a hierarchical model combining a
random forest classifier and a GNN. The results for the final AT prediction are
promising, showing low errors even when predicting several stops ahead. Yet, no
single model emerges as universally superior, and we provide insights into the
characteristics of pilot sites that influence the model selection process.
Finally, we identify dwell time prediction as the key determinant in overall AT
prediction accuracy when autonomous shuttles are deployed in low-traffic areas
or under regulatory speed limits. This research provides insights into the
current state of autonomous public transport prediction models and paves the
way for more data-informed decision-making as the field advances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05335">InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes. (arXiv:2401.05335v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shahbazi_M/0/1/0/all/0/1">Mohamad Shahbazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Claessens_L/0/1/0/all/0/1">Liesbeth Claessens</a>, <a href="http://arxiv.org/find/cs/1/au:+Niemeyer_M/0/1/0/all/0/1">Michael Niemeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Collins_E/0/1/0/all/0/1">Edo Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonioni_A/0/1/0/all/0/1">Alessio Tonioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a></p>
<p>We introduce InseRF, a novel method for generative object insertion in the
NeRF reconstructions of 3D scenes. Based on a user-provided textual description
and a 2D bounding box in a reference viewpoint, InseRF generates new objects in
3D scenes. Recently, methods for 3D scene editing have been profoundly
transformed, owing to the use of strong priors of text-to-image diffusion
models in 3D generative modeling. Existing methods are mostly effective in
editing 3D scenes via style and appearance changes or removing existing
objects. Generating new objects, however, remains a challenge for such methods,
which we address in this study. Specifically, we propose grounding the 3D
object insertion to a 2D object insertion in a reference view of the scene. The
2D edit is then lifted to 3D using a single-view object reconstruction method.
The reconstructed object is then inserted into the scene, guided by the priors
of monocular depth estimation methods. We evaluate our method on various 3D
scenes and provide an in-depth analysis of the proposed components. Our
experiments with generative insertion of objects in several 3D scenes indicate
the effectiveness of our method compared to the existing methods. InseRF is
capable of controllable and 3D-consistent object insertion without requiring
explicit 3D information as input. Please visit our project page at
https://mohamad-shahbazi.github.io/inserf.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2002.07756">Hierarchical Correlation Clustering and Tree Preserving Embedding. (arXiv:2002.07756v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chehreghani_M/0/1/0/all/0/1">Morteza Haghir Chehreghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Chehreghani_M/0/1/0/all/0/1">Mostafa Haghir Chehreghani</a></p>
<p>We propose a hierarchical correlation clustering method that extends the
well-known correlation clustering to produce hierarchical clusters applicable
to both positive and negative pairwise dissimilarities. Then, in the following,
we study unsupervised representation learning with such hierarchical
correlation clustering. For this purpose, we first investigate embedding the
respective hierarchy to be used for tree-preserving embedding and feature
extraction. Thereafter, we study the extension of minimax distance measures to
correlation clustering, as another representation learning paradigm. Finally,
we demonstrate the performance of our methods on several datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.04829">Adaptive joint distribution learning. (arXiv:2110.04829v4 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Filipovic_D/0/1/0/all/0/1">Damir Filipovic</a>, <a href="http://arxiv.org/find/stat/1/au:+Multerer_M/0/1/0/all/0/1">Michael Multerer</a>, <a href="http://arxiv.org/find/stat/1/au:+Schneider_P/0/1/0/all/0/1">Paul Schneider</a></p>
<p>We develop a new framework for embedding joint probability distributions in
tensor product reproducing kernel Hilbert spaces (RKHS). Our framework
accommodates a low-dimensional, normalized and positive model of a
Radon-Nikodym derivative, which we estimate from sample sizes of up to several
million data points, alleviating the inherent limitations of RKHS modeling.
Well-defined normalized and positive conditional distributions are natural
by-products to our approach. The embedding is fast to compute and accommodates
learning problems ranging from prediction to classification. Our theoretical
findings are supplemented by favorable numerical results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.11018">A Theoretical View of Linear Backpropagation and Its Convergence. (arXiv:2112.11018v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yiwen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haodi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a></p>
<p>Backpropagation (BP) is widely used for calculating gradients in deep neural
networks (DNNs). Applied often along with stochastic gradient descent (SGD) or
its variants, BP is considered as a de-facto choice in a variety of machine
learning tasks including DNN training and adversarial attack/defense. Recently,
a linear variant of BP named LinBP was introduced for generating more
transferable adversarial examples for performing black-box attacks, by Guo et
al. Although it has been shown empirically effective in black-box attacks,
theoretical studies and convergence analyses of such a method is lacking. This
paper serves as a complement and somewhat an extension to Guo et al.'s paper,
by providing theoretical analyses on LinBP in neural-network-involved learning
tasks, including adversarial attack and model training. We demonstrate that,
somewhat surprisingly, LinBP can lead to faster convergence in these tasks in
the same hyper-parameter settings, compared to BP. We confirm our theoretical
results with extensive experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.09674">Generalized Optimistic Methods for Convex-Concave Saddle Point Problems. (arXiv:2202.09674v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Jiang_R/0/1/0/all/0/1">Ruichen Jiang</a>, <a href="http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1">Aryan Mokhtari</a></p>
<p>The optimistic gradient method has seen increasing popularity for solving
convex-concave saddle point problems. To analyze its iteration complexity, a
recent work [<a href="/abs/1906.01115">arXiv:1906.01115</a>] proposed an interesting perspective that
interprets this method as an approximation to the proximal point method. In
this paper, we follow this approach and distill the underlying idea of optimism
to propose a generalized optimistic method, which includes the optimistic
gradient method as a special case. Our general framework can handle constrained
saddle point problems with composite objective functions and can work with
arbitrary norms using Bregman distances. Moreover, we develop a backtracking
line search scheme to select the step sizes without knowledge of the smoothness
coefficients. We instantiate our method with first-, second- and higher-order
oracles and give best-known global iteration complexity bounds. For our
first-order method, we show that the averaged iterates converge at a rate of
$O(1/N)$ when the objective function is convex-concave, and it achieves linear
convergence when the objective is strongly-convex-strongly-concave. For our
second- and higher-order methods, under the additional assumption that the
distance-generating function has Lipschitz gradient, we prove a complexity
bound of $O(1/\epsilon^\frac{2}{p+1})$ in the convex-concave setting and a
complexity bound of
$O((L_pD^\frac{p-1}{2}/\mu)^\frac{2}{p+1}+\log\log\frac{1}{\epsilon})$ in the
strongly-convex-strongly-concave setting, where $L_p$ ($p\geq 2$) is the
Lipschitz constant of the $p$-th-order derivative, $\mu$ is the strong
convexity parameter, and $D$ is the initial Bregman distance to the saddle
point. Moreover, our line search scheme provably only requires a constant
number of calls to a subproblem solver per iteration on average, making our
first- and second-order methods particularly amenable to implementation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2204.00703">A Reinforcement Learning Approach to Sensing Design in Resource-Constrained Wireless Networked Control Systems. (arXiv:2204.00703v5 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ballotta_L/0/1/0/all/0/1">Luca Ballotta</a>, <a href="http://arxiv.org/find/eess/1/au:+Peserico_G/0/1/0/all/0/1">Giovanni Peserico</a>, <a href="http://arxiv.org/find/eess/1/au:+Zanini_F/0/1/0/all/0/1">Francesco Zanini</a></p>
<p>In this paper, we consider a wireless network of smart sensors (agents) that
monitor a dynamical process and send measurements to a base station that
performs global monitoring and decision-making. Smart sensors are equipped with
both sensing and computation, and can either send raw measurements or process
them prior to transmission. Constrained agent resources raise a fundamental
latency-accuracy trade-off. On the one hand, raw measurements are inaccurate
but fast to produce. On the other hand, data processing on resource-constrained
platforms generates accurate measurements at the cost of non-negligible
computation latency. Further, if processed data are also compressed, latency
caused by wireless communication might be higher for raw measurements. Hence,
it is challenging to decide when and where sensors in the network should
transmit raw measurements or leverage time-consuming local processing. To
tackle this design problem, we propose a Reinforcement Learning approach to
learn an efficient policy that dynamically decides when measurements are to be
processed at each sensor. Effectiveness of our proposed approach is validated
through a numerical simulation with case study on smart sensing motivated by
the Internet of Drones.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.08548">GANDALF: Gated Adaptive Network for Deep Automated Learning of Features. (arXiv:2207.08548v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Joseph_M/0/1/0/all/0/1">Manu Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_H/0/1/0/all/0/1">Harsh Raj</a></p>
<p>We propose a novel high-performance, interpretable, and parameter \&amp;
computationally efficient deep learning architecture for tabular data, Gated
Adaptive Network for Deep Automated Learning of Features (GANDALF). GANDALF
relies on a new tabular processing unit with a gating mechanism and in-built
feature selection called Gated Feature Learning Unit (GFLU) as a feature
representation learning unit. We demonstrate that GANDALF outperforms or stays
at-par with SOTA approaches like XGBoost, SAINT, FT-Transformers, etc. by
experiments on multiple established public benchmarks. We have made available
the code at github.com/manujosephv/pytorch_tabular under MIT License.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.10193">Convergent autoencoder approximation of low bending and low distortion manifold embeddings. (arXiv:2208.10193v2 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Braunsmann_J/0/1/0/all/0/1">Juliane Braunsmann</a>, <a href="http://arxiv.org/find/math/1/au:+Rajkovic_M/0/1/0/all/0/1">Marko Rajkovi&#x107;</a>, <a href="http://arxiv.org/find/math/1/au:+Rumpf_M/0/1/0/all/0/1">Martin Rumpf</a>, <a href="http://arxiv.org/find/math/1/au:+Wirth_B/0/1/0/all/0/1">Benedikt Wirth</a></p>
<p>Autoencoders, which consist of an encoder and a decoder, are widely used in
machine learning for dimension reduction of high-dimensional data. The encoder
embeds the input data manifold into a lower-dimensional latent space, while the
decoder represents the inverse map, providing a parametrization of the data
manifold by the manifold in latent space. A good regularity and structure of
the embedded manifold may substantially simplify further data processing tasks
such as cluster analysis or data interpolation. We propose and analyze a novel
regularization for learning the encoder component of an autoencoder: a loss
functional that prefers isometric, extrinsically flat embeddings and allows to
train the encoder on its own. To perform the training it is assumed that for
pairs of nearby points on the input manifold their local Riemannian distance
and their local Riemannian average can be evaluated. The loss functional is
computed via Monte Carlo integration with different sampling strategies for
pairs of points on the input manifold. Our main theorem identifies a geometric
loss functional of the embedding map as the $\Gamma$-limit of the
sampling-dependent loss functionals. Numerical tests, using image data that
encodes different explicitly given data manifolds, show that smooth manifold
embeddings into latent space are obtained. Due to the promotion of extrinsic
flatness, these embeddings are regular enough such that interpolation between
not too distant points on the manifold is well approximated by linear
interpolation in latent space as one possible postprocessing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.01829">t-SMILES: A Scalable Fragment-based Molecular Representation Framework for De Novo Molecule Generation. (arXiv:2301.01829v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Juan-Ni Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yue Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Li-Juan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hai-Long Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Ru-Qin Yu</a></p>
<p>Effective representation of molecules is a crucial factor affecting the
performance of artificial intelligence models. This study introduces a
flexible, fragment-based, multiscale molecular representation framework called
t-SMILES (tree-based SMILES) with three code algorithms: TSSA (t-SMILES with
Shared Atom), TSDY (t-SMILES with Dummy Atom) and TSID (t-SMILES with ID). It
describes molecules using SMILES-type strings obtained by performing a
breadth-first search on a full binary tree formed from a fragmented molecular
graph. Systematic evaluations using JTVAE, BRICS, MMPA, and Scaffold show the
feasibility to construct a multi-code molecular description system, where
various descriptions complement each other, enhancing the overall performance.
Additionally, it exhibits impressive performance on low-resource datasets,
whether the model is original, data augmented, or pre-training fine-tuned. It
significantly outperforms classical SMILES, DeepSMILES, SELFIES and baseline
models in goal-directed tasks. Furthermore, it surpasses start-of-the-art
fragment, graph and SMILES based approaches on ChEMBL, Zinc, and QM9.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.05158">SemPPL: Predicting pseudo-labels for better contrastive representations. (arXiv:2301.05158v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bosnjak_M/0/1/0/all/0/1">Matko Bo&#x161;njak</a>, <a href="http://arxiv.org/find/cs/1/au:+Richemond_P/0/1/0/all/0/1">Pierre H. Richemond</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomasev_N/0/1/0/all/0/1">Nenad Tomasev</a>, <a href="http://arxiv.org/find/cs/1/au:+Strub_F/0/1/0/all/0/1">Florian Strub</a>, <a href="http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1">Jacob C. Walker</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Buesing_L/0/1/0/all/0/1">Lars Holger Buesing</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1">Charles Blundell</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitrovic_J/0/1/0/all/0/1">Jovana Mitrovic</a></p>
<p>Learning from large amounts of unsupervised data and a small amount of
supervision is an important open problem in computer vision. We propose a new
semi-supervised learning method, Semantic Positives via Pseudo-Labels (SemPPL),
that combines labelled and unlabelled data to learn informative
representations. Our method extends self-supervised contrastive learning --
where representations are shaped by distinguishing whether two samples
represent the same underlying datum (positives) or not (negatives) -- with a
novel approach to selecting positives. To enrich the set of positives, we
leverage the few existing ground-truth labels to predict the missing ones
through a $k$-nearest neighbours classifier by using the learned embeddings of
the labelled data. We thus extend the set of positives with datapoints having
the same pseudo-label and call these semantic positives. We jointly learn the
representation and predict bootstrapped pseudo-labels. This creates a
reinforcing cycle. Strong initial representations enable better pseudo-label
predictions which then improve the selection of semantic positives and lead to
even better representations. SemPPL outperforms competing semi-supervised
methods setting new state-of-the-art performance of $68.5\%$ and $76\%$ top-$1$
accuracy when using a ResNet-$50$ and training on $1\%$ and $10\%$ of labels on
ImageNet, respectively. Furthermore, when using selective kernels, SemPPL
significantly outperforms previous state-of-the-art achieving $72.3\%$ and
$78.3\%$ top-$1$ accuracy on ImageNet with $1\%$ and $10\%$ labels,
respectively, which improves absolute $+7.8\%$ and $+6.2\%$ over previous work.
SemPPL also exhibits state-of-the-art performance over larger ResNet models as
well as strong robustness, out-of-distribution and transfer performance. We
release the checkpoints and the evaluation code at
https://github.com/deepmind/semppl .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.06535">Case-Base Neural Networks: survival analysis with time-varying, higher-order interactions. (arXiv:2301.06535v4 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Islam_J/0/1/0/all/0/1">Jesse Islam</a>, <a href="http://arxiv.org/find/stat/1/au:+Turgeon_M/0/1/0/all/0/1">Maxime Turgeon</a>, <a href="http://arxiv.org/find/stat/1/au:+Sladek_R/0/1/0/all/0/1">Robert Sladek</a>, <a href="http://arxiv.org/find/stat/1/au:+Bhatnagar_S/0/1/0/all/0/1">Sahir Bhatnagar</a></p>
<p>In the context of survival analysis, data-driven neural network-based methods
have been developed to model complex covariate effects. While these methods may
provide better predictive performance than regression-based approaches, not all
can model time-varying interactions and complex baseline hazards. To address
this, we propose Case-Base Neural Networks (CBNNs) as a new approach that
combines the case-base sampling framework with flexible neural network
architectures. Using a novel sampling scheme and data augmentation to naturally
account for censoring, we construct a feed-forward neural network that includes
time as an input. CBNNs predict the probability of an event occurring at a
given moment to estimate the full hazard function. We compare the performance
of CBNNs to regression and neural network-based survival methods in a
simulation and three case studies using two time-dependent metrics. First, we
examine performance on a simulation involving a complex baseline hazard and
time-varying interactions to assess all methods, with CBNN outperforming
competitors. Then, we apply all methods to three real data applications, with
CBNNs outperforming the competing models in two studies and showing similar
performance in the third. Our results highlight the benefit of combining
case-base sampling with deep learning to provide a simple and flexible
framework for data-driven modeling of single event survival outcomes that
estimates time-varying effects and a complex baseline hazard by design. An R
package is available at https://github.com/Jesse-Islam/cbnn.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00704">Pathologies of Predictive Diversity in Deep Ensembles. (arXiv:2302.00704v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abe_T/0/1/0/all/0/1">Taiga Abe</a>, <a href="http://arxiv.org/find/cs/1/au:+Buchanan_E/0/1/0/all/0/1">E. Kelly Buchanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a></p>
<p>Classic results establish that encouraging predictive diversity improves
performance in ensembles of low-capacity models, e.g. through bagging or
boosting. Here we demonstrate that these intuitions do not apply to
high-capacity neural network ensembles (deep ensembles), and in fact the
opposite is often true. In a large scale study of nearly 600 neural network
classification ensembles, we examine a variety of interventions that trade off
component model performance for predictive diversity. While such interventions
can improve the performance of small neural network ensembles (in line with
standard intuitions), they harm the performance of the large neural network
ensembles most often used in practice. Surprisingly, we also find that
discouraging predictive diversity is often benign in large-network ensembles,
fully inverting standard intuitions. Even when diversity-promoting
interventions do not sacrifice component model performance (e.g. using
heterogeneous architectures and training paradigms), we observe an opportunity
cost associated with pursuing increased predictive diversity. Examining over
1000 ensembles, we observe that the performance benefits of diverse
architectures/training procedures are easily dwarfed by the benefits of simply
using higher-capacity models, despite the fact that such higher capacity models
often yield significantly less predictive diversity. Overall, our findings
demonstrate that standard intuitions around predictive diversity, originally
developed for low-capacity ensembles, do not directly apply to modern
high-capacity deep ensembles. This work clarifies fundamental challenges to the
goal of improving deep ensembles by making them more diverse, while suggesting
an alternative path: simply forming ensembles from ever more powerful (and less
diverse) component models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06025">Statistical Complexity and Optimal Algorithms for Non-linear Ridge Bandits. (arXiv:2302.06025v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Rajaraman_N/0/1/0/all/0/1">Nived Rajaraman</a>, <a href="http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1">Yanjun Han</a>, <a href="http://arxiv.org/find/stat/1/au:+Jiao_J/0/1/0/all/0/1">Jiantao Jiao</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1">Kannan Ramchandran</a></p>
<p>We consider the sequential decision-making problem where the mean outcome is
a non-linear function of the chosen action. Compared with the linear model, two
curious phenomena arise in non-linear models: first, in addition to the
"learning phase" with a standard parametric rate for estimation or regret,
there is an "burn-in period" with a fixed cost determined by the non-linear
function; second, achieving the smallest burn-in cost requires new exploration
algorithms. For a special family of non-linear functions named ridge functions
in the literature, we derive upper and lower bounds on the optimal burn-in
cost, and in addition, on the entire learning trajectory during the burn-in
period via differential equations. In particular, a two-stage algorithm that
first finds a good initial action and then treats the problem as locally linear
is statistically optimal. In contrast, several classical algorithms, such as
UCB and algorithms relying on regression oracles, are provably suboptimal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.11510">Selective experience replay compression using coresets for lifelong deep reinforcement learning in medical imaging. (arXiv:2302.11510v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1">Guangyao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobs_M/0/1/0/all/0/1">Michael A. Jacobs</a>, <a href="http://arxiv.org/find/cs/1/au:+Parekh_V/0/1/0/all/0/1">Vishwa S. Parekh</a></p>
<p>Selective experience replay is a popular strategy for integrating lifelong
learning with deep reinforcement learning. Selective experience replay aims to
recount selected experiences from previous tasks to avoid catastrophic
forgetting. Furthermore, selective experience replay based techniques are model
agnostic and allow experiences to be shared across different models. However,
storing experiences from all previous tasks make lifelong learning using
selective experience replay computationally very expensive and impractical as
the number of tasks increase. To that end, we propose a reward
distribution-preserving coreset compression technique for compressing
experience replay buffers stored for selective experience replay.
</p>
<p>We evaluated the coreset compression technique on the brain tumor
segmentation (BRATS) dataset for the task of ventricle localization and on the
whole-body MRI for localization of left knee cap, left kidney, right
trochanter, left lung, and spleen. The coreset lifelong learning models trained
on a sequence of 10 different brain MR imaging environments demonstrated
excellent performance localizing the ventricle with a mean pixel error distance
of 12.93 for the compression ratio of 10x. In comparison, the conventional
lifelong learning model localized the ventricle with a mean pixel distance of
10.87. Similarly, the coreset lifelong learning models trained on whole-body
MRI demonstrated no significant difference (p=0.28) between the 10x compressed
coreset lifelong learning models and conventional lifelong learning models for
all the landmarks. The mean pixel distance for the 10x compressed models across
all the landmarks was 25.30, compared to 19.24 for the conventional lifelong
learning models. Our results demonstrate that the potential of the
coreset-based ERB compression method for compressing experiences without a
significant drop in performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.04887">Memory-adaptive Depth-wise Heterogenous Federated Learning. (arXiv:2303.04887v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yutong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a></p>
<p>Federated learning is a promising paradigm that allows multiple clients to
collaboratively train a model without sharing the local data. However, the
presence of heterogeneous devices in federated learning, such as mobile phones
and IoT devices with varying memory capabilities, would limit the scale and
hence the performance of the model could be trained. The mainstream approaches
to address memory limitations focus on width-slimming techniques, where
different clients train subnetworks with reduced widths locally and then the
server aggregates the subnetworks. The global model produced from these methods
suffers from performance degradation due to the negative impact of the actions
taken to handle the varying subnetwork widths in the aggregation phase. In this
paper, we introduce a memory-adaptive depth-wise learning solution in FL called
FeDepth, which adaptively decomposes the full model into blocks according to
the memory budgets of each client and trains blocks sequentially to obtain a
full inference model. Our method outperforms state-of-the-art approaches,
achieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 and
CIFAR-100, respectively. We also demonstrate the effectiveness of depth-wise
fine-tuning on ViT. Our findings highlight the importance of memory-aware
techniques for federated learning with heterogeneous devices and the success of
depth-wise training strategy in improving the global model's performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.06783">Asynchronous Decentralized Federated Lifelong Learning for Landmark Localization in Medical Imaging. (arXiv:2303.06783v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1">Guangyao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobs_M/0/1/0/all/0/1">Michael A. Jacobs</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Parekh_V/0/1/0/all/0/1">Vishwa S. Parekh</a></p>
<p>Federated learning is a recent development in the machine learning area that
allows a system of devices to train on one or more tasks without sharing their
data to a single location or device. However, this framework still requires a
centralized global model to consolidate individual models into one, and the
devices train synchronously, which both can be potential bottlenecks for using
federated learning. In this paper, we propose a novel method of asynchronous
decentralized federated lifelong learning (ADFLL) method that inherits the
merits of federated learning and can train on multiple tasks simultaneously
without the need for a central node or synchronous training. Thus, overcoming
the potential drawbacks of conventional federated learning. We demonstrate
excellent performance on the brain tumor segmentation (BRATS) dataset for
localizing the left ventricle on multiple image sequences and image
orientation. Our framework allows agents to achieve the best performance with a
mean distance error of 7.81, better than the conventional all-knowing agent's
mean distance error of 11.78, and significantly (p=0.01) better than a
conventional lifelong learning agent with a distance error of 15.17 after eight
rounds of training. In addition, all ADFLL agents have comparable or better
performance than a conventional LL agent. In conclusion, we developed an ADFLL
framework with excellent performance and speed-up compared to conventional RL
agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.15318">Closed-Loop Koopman Operator Approximation. (arXiv:2303.15318v2 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Dahdah_S/0/1/0/all/0/1">Steven Dahdah</a>, <a href="http://arxiv.org/find/eess/1/au:+Forbes_J/0/1/0/all/0/1">James Richard Forbes</a></p>
<p>This paper proposes a method to identify a Koopman model of a
feedback-controlled system given a known controller. The Koopman operator
allows a nonlinear system to be rewritten as an infinite-dimensional linear
system by viewing it in terms of an infinite set of lifting functions. A
finite-dimensional approximation of the Koopman operator can be identified from
data by choosing a finite subset of lifting functions and solving a regression
problem in the lifted space. Existing methods are designed to identify
open-loop systems. However, it is impractical or impossible to run experiments
on some systems, such as unstable systems, in an open-loop fashion. The
proposed method leverages the linearity of the Koopman operator, along with
knowledge of the controller and the structure of the closed-loop system, to
simultaneously identify the closed-loop and plant systems. The advantages of
the proposed closed-loop Koopman operator approximation method are demonstrated
experimentally using a rotary inverted pendulum system. An open-source software
implementation of the proposed method is publicly available, along with the
experimental dataset generated for this paper.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.15939">Generating artificial digital image correlation data using physics-guided adversarial networks. (arXiv:2303.15939v3 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Melching_D/0/1/0/all/0/1">David Melching</a>, <a href="http://arxiv.org/find/eess/1/au:+Schultheis_E/0/1/0/all/0/1">Erik Schultheis</a>, <a href="http://arxiv.org/find/eess/1/au:+Breitbarth_E/0/1/0/all/0/1">Eric Breitbarth</a></p>
<p>Digital image correlation (DIC) has become a valuable tool to monitor and
evaluate mechanical experiments of cracked specimen, but the automatic
detection of cracks is often difficult due to inherent noise and artefacts.
Machine learning models have been extremely successful in detecting crack paths
and crack tips using DIC-measured, interpolated full-field displacements as
input to a convolution-based segmentation model. Still, big data is needed to
train such models. However, scientific data is often scarce as experiments are
expensive and time-consuming. In this work, we present a method to directly
generate large amounts of artificial displacement data of cracked specimen
resembling real interpolated DIC displacements. The approach is based on
generative adversarial networks (GANs). During training, the discriminator
receives physical domain knowledge in the form of the derived von Mises
equivalent strain. We show that this physics-guided approach leads to improved
results in terms of visual quality of samples, sliced Wasserstein distance, and
geometry score when compared to a classical unguided GAN approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.04668">MERMAIDE: Learning to Align Learners using Model-Based Meta-Learning. (arXiv:2304.04668v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Arundhati Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Phade_S/0/1/0/all/0/1">Soham Phade</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Stephan Zheng</a></p>
<p>We study how a principal can efficiently and effectively intervene on the
rewards of a previously unseen learning agent in order to induce desirable
outcomes. This is relevant to many real-world settings like auctions or
taxation, where the principal may not know the learning behavior nor the
rewards of real people. Moreover, the principal should be few-shot adaptable
and minimize the number of interventions, because interventions are often
costly. We introduce MERMAIDE, a model-based meta-learning framework to train a
principal that can quickly adapt to out-of-distribution agents with different
learning strategies and reward functions. We validate this approach
step-by-step. First, in a Stackelberg setting with a best-response agent, we
show that meta-learning enables quick convergence to the theoretically known
Stackelberg equilibrium at test time, although noisy observations severely
increase the sample complexity. We then show that our model-based meta-learning
approach is cost-effective in intervening on bandit agents with unseen
explore-exploit strategies. Finally, we outperform baselines that use either
meta-learning or agent behavior modeling, in both $0$-shot and $K=1$-shot
settings with partial agent information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.12707">Lyapunov-Stable Deep Equilibrium Models. (arXiv:2304.12707v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1">Haoyu Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Shikui Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyatake_Y/0/1/0/all/0/1">Yuto Miyatake</a></p>
<p>Deep equilibrium (DEQ) models have emerged as a promising class of implicit
layer models, which abandon traditional depth by solving for the fixed points
of a single nonlinear layer. Despite their success, the stability of the fixed
points for these models remains poorly understood. By considering DEQ models as
nonlinear dynamic systems, we propose a robust DEQ model named LyaDEQ with
guaranteed provable stability via Lyapunov theory. The crux of our method is
ensuring the Lyapunov stability of the DEQ model's fixed points, which enables
the proposed model to resist minor initial perturbations. To avoid poor
adversarial defense due to Lyapunov-stable fixed points being located near each
other, we orthogonalize the layers after the Lyapunov stability module to
separate different fixed points. We evaluate LyaDEQ models under well-known
adversarial attacks, and experimental results demonstrate significant
improvement in robustness. Furthermore, we show that the LyaDEQ model can be
combined with other defense methods, such as adversarial training, to achieve
even better adversarial robustness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05400">Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Siedel_G/0/1/0/all/0/1">Georg Siedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Weijia Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Vock_S/0/1/0/all/0/1">Silvia Vock</a>, <a href="http://arxiv.org/find/cs/1/au:+Morozov_A/0/1/0/all/0/1">Andrey Morozov</a></p>
<p>Robustness is a fundamental property of machine learning classifiers required
to achieve safety and reliability. In the field of adversarial robustness of
image classifiers, robustness is commonly defined as the stability of a model
to all input changes within a p-norm distance. However, in the field of random
corruption robustness, variations observed in the real world are used, while
p-norm corruptions are rarely considered. This study investigates the use of
random p-norm corruptions to augment the training and test data of image
classifiers. We evaluate the model robustness against imperceptible random
p-norm corruptions and propose a novel robustness metric. We empirically
investigate whether robustness transfers across different p-norms and derive
conclusions on which p-norm corruptions a model should be trained and
evaluated. We find that training data augmentation with a combination of p-norm
corruptions significantly improves corruption robustness, even on top of
state-of-the-art data augmentation schemes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06042">Blockwise Principal Component Analysis for monotone missing data imputation and dimensionality reduction. (arXiv:2305.06042v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1">Tu T. Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_M/0/1/0/all/0/1">Mai Anh Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_T/0/1/0/all/0/1">Tuan L. Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ly_H/0/1/0/all/0/1">Hoang Thien Ly</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/cs/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>, <a href="http://arxiv.org/find/cs/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a></p>
<p>Monotone missing data is a common problem in data analysis. However,
imputation combined with dimensionality reduction can be computationally
expensive, especially with the increasing size of datasets. To address this
issue, we propose a Blockwise principal component analysis Imputation (BPI)
framework for dimensionality reduction and imputation of monotone missing data.
The framework conducts Principal Component Analysis (PCA) on the observed part
of each monotone block of the data and then imputes on merging the obtained
principal components using a chosen imputation technique. BPI can work with
various imputation techniques and can significantly reduce imputation time
compared to conducting dimensionality reduction after imputation. This makes it
a practical and efficient approach for large datasets with monotone missing
data. Our experiments validate the improvement in speed. In addition, our
experiments also show that while applying MICE imputation directly on missing
data may not yield convergence, applying BPI with MICE for the data may lead to
convergence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.09480">Cross-Gate MLP with Protein Complex Invariant Embedding is A One-Shot Antibody Designer. (arXiv:2305.09480v5 [q-bio.BM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Tan_C/0/1/0/all/0/1">Cheng Tan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gao_Z/0/1/0/all/0/1">Zhangyang Gao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xia_J/0/1/0/all/0/1">Jun Xia</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zheng_J/0/1/0/all/0/1">Jiangbin Zheng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_X/0/1/0/all/0/1">Xihong Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_Y/0/1/0/all/0/1">Yue Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hu_B/0/1/0/all/0/1">Bozhen Hu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a></p>
<p>Antibodies are crucial proteins produced by the immune system in response to
foreign substances or antigens. The specificity of an antibody is determined by
its complementarity-determining regions (CDRs), which are located in the
variable domains of the antibody chains and form the antigen-binding site.
Previous studies have utilized complex techniques to generate CDRs, but they
suffer from inadequate geometric modeling. Moreover, the common iterative
refinement strategies lead to an inefficient inference. In this paper, we
propose a \textit{simple yet effective} model that can co-design 1D sequences
and 3D structures of CDRs in a one-shot manner. To achieve this, we decouple
the antibody CDR design problem into two stages: (i) geometric modeling of
protein complex structures and (ii) sequence-structure co-learning. We develop
a novel macromolecular structure invariant embedding, typically for protein
complexes, that captures both intra- and inter-component interactions among the
backbone atoms, including C$\alpha$, N, C, and O atoms, to achieve
comprehensive geometric modeling. Then, we introduce a simple cross-gate MLP
for sequence-structure co-learning, allowing sequence and structure
representations to implicitly refine each other. This enables our model to
design desired sequences and structures in a one-shot manner. Extensive
experiments are conducted to evaluate our results at both the sequence and
structure levels, which demonstrate that our model achieves superior
performance compared to the state-of-the-art antibody CDR design methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.10294">DualFL: A Duality-based Federated Learning Algorithm with Communication Acceleration in the General Convex Regime. (arXiv:2305.10294v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jongho Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jinchao Xu</a></p>
<p>We propose a new training algorithm, named DualFL (Dualized Federated
Learning), for solving distributed optimization problems in federated learning.
DualFL achieves communication acceleration for very general convex cost
functions, thereby providing a solution to an open theoretical problem in
federated learning concerning cost functions that may not be smooth nor
strongly convex. We provide a detailed analysis for the local iteration
complexity of DualFL to ensure the overall computational efficiency of DualFL.
Furthermore, we introduce a completely new approach for the convergence
analysis of federated learning based on a dual formulation. This new technique
enables concise and elegant analysis, which contrasts the complex calculations
used in existing literature on convergence of federated learning algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11241">Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison. (arXiv:2305.11241v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jeffrey_N/0/1/0/all/0/1">Niall Jeffrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Wandelt_B/0/1/0/all/0/1">Benjamin D. Wandelt</a></p>
<p>Evidence Networks can enable Bayesian model comparison when state-of-the-art
methods (e.g. nested sampling) fail and even when likelihoods or priors are
intractable or unknown. Bayesian model comparison, i.e. the computation of
Bayes factors or evidence ratios, can be cast as an optimization problem.
Though the Bayesian interpretation of optimal classification is well-known,
here we change perspective and present classes of loss functions that result in
fast, amortized neural estimators that directly estimate convenient functions
of the Bayes factor. This mitigates numerical inaccuracies associated with
estimating individual model probabilities. We introduce the leaky parity-odd
power (l-POP) transform, leading to the novel ``l-POP-Exponential'' loss
function. We explore neural density estimation for data probability in
different models, showing it to be less accurate and scalable than Evidence
Networks. Multiple real-world and synthetic examples illustrate that Evidence
Networks are explicitly independent of dimensionality of the parameter space
and scale mildly with the complexity of the posterior probability density
function. This simple yet powerful approach has broad implications for model
inference tasks. As an application of Evidence Networks to real-world data we
compute the Bayes factor for two models with gravitational lensing data of the
Dark Energy Survey. We briefly discuss applications of our methods to other,
related problems of model comparison and evaluation in implicit inference
settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15092">FedZero: Leveraging Renewable Excess Energy in Federated Learning. (arXiv:2305.15092v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wiesner_P/0/1/0/all/0/1">Philipp Wiesner</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalili_R/0/1/0/all/0/1">Ramin Khalili</a>, <a href="http://arxiv.org/find/cs/1/au:+Grinwald_D/0/1/0/all/0/1">Dennis Grinwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pratik Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Thamsen_L/0/1/0/all/0/1">Lauritz Thamsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kao_O/0/1/0/all/0/1">Odej Kao</a></p>
<p>Federated Learning (FL) is an emerging machine learning technique that
enables distributed model training across data silos or edge devices without
data sharing. Yet, FL inevitably introduces inefficiencies compared to
centralized model training, which will further increase the already high energy
usage and associated carbon emissions of machine learning in the future. One
idea to reduce FL's carbon footprint is to schedule training jobs based on the
availability of renewable excess energy that can occur at certain times and
places in the grid. However, in the presence of such volatile and unreliable
resources, existing FL schedulers cannot always ensure fast, efficient, and
fair training.
</p>
<p>We propose FedZero, an FL system that operates exclusively on renewable
excess energy and spare capacity of compute infrastructure to effectively
reduce a training's operational carbon emissions to zero. Using energy and load
forecasts, FedZero leverages the spatio-temporal availability of excess
resources by selecting clients for fast convergence and fair participation. Our
evaluation, based on real solar and load traces, shows that FedZero converges
significantly faster than existing approaches under the mentioned constraints
while consuming less energy. Furthermore, it is robust to forecasting errors
and scalable to tens of thousands of clients.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16963">Semantic segmentation of sparse irregular point clouds for leaf/wood discrimination. (arXiv:2305.16963v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yuchen Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_J/0/1/0/all/0/1">Jean-Baptiste Durand</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_G/0/1/0/all/0/1">Gr&#xe9;goire Vincent</a>, <a href="http://arxiv.org/find/cs/1/au:+Forbes_F/0/1/0/all/0/1">Florence Forbes</a></p>
<p>LiDAR (Light Detection and Ranging) has become an essential part of the
remote sensing toolbox used for biosphere monitoring. In particular, LiDAR
provides the opportunity to map forest leaf area with unprecedented accuracy,
while leaf area has remained an important source of uncertainty affecting
models of gas exchanges between the vegetation and the atmosphere. Unmanned
Aerial Vehicles (UAV) are easy to mobilize and therefore allow frequent
revisits to track the response of vegetation to climate change. However,
miniature sensors embarked on UAVs usually provide point clouds of limited
density, which are further affected by a strong decrease in density from top to
bottom of the canopy due to progressively stronger occlusion. In such a
context, discriminating leaf points from wood points presents a significant
challenge due in particular to strong class imbalance and spatially irregular
sampling intensity. Here we introduce a neural network model based on the
Pointnet ++ architecture which makes use of point geometry only (excluding any
spectral information). To cope with local data sparsity, we propose an
innovative sampling scheme which strives to preserve local important geometric
information. We also propose a loss function adapted to the severe class
imbalance. We show that our model outperforms state-of-the-art alternatives on
UAV point clouds. We discuss future possible improvements, particularly
regarding much denser point clouds acquired from below the canopy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19638">A Unified Framework for U-Net Design and Analysis. (arXiv:2305.19638v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Williams_C/0/1/0/all/0/1">Christopher Williams</a>, <a href="http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1">Fabian Falck</a>, <a href="http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1">George Deligiannidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1">Chris Holmes</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>, <a href="http://arxiv.org/find/stat/1/au:+Syed_S/0/1/0/all/0/1">Saifuddin Syed</a></p>
<p>U-Nets are a go-to, state-of-the-art neural architecture across numerous
tasks for continuous signals on a square such as images and Partial
Differential Equations (PDE), however their design and architecture is
understudied. In this paper, we provide a framework for designing and analysing
general U-Net architectures. We present theoretical results which characterise
the role of the encoder and decoder in a U-Net, their high-resolution scaling
limits and their conjugacy to ResNets via preconditioning. We propose
Multi-ResNets, U-Nets with a simplified, wavelet-based encoder without
learnable parameters. Further, we show how to design novel U-Net architectures
which encode function constraints, natural bases, or the geometry of the data.
In diffusion models, our framework enables us to identify that high-frequency
information is dominated by noise exponentially faster, and show how U-Nets
with average pooling exploit this. In our experiments, we demonstrate how
Multi-ResNets achieve competitive and often superior performance compared to
classical U-Nets in image segmentation, PDE surrogate modelling, and generative
modelling with diffusion models. Our U-Net framework paves the way to study the
theoretical properties of U-Nets and design natural, scalable neural
architectures for a multitude of problems beyond the square.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04836">$K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic Control. (arXiv:2306.04836v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Giegrich_M/0/1/0/all/0/1">Michael Giegrich</a>, <a href="http://arxiv.org/find/stat/1/au:+Oomen_R/0/1/0/all/0/1">Roel Oomen</a>, <a href="http://arxiv.org/find/stat/1/au:+Reisinger_C/0/1/0/all/0/1">Christoph Reisinger</a></p>
<p>In this paper, we propose a novel $K$-nearest neighbor resampling procedure
for estimating the performance of a policy from historical data containing
realized episodes of a decision process generated under a different policy. We
provide statistical consistency results under weak conditions. In particular,
we avoid the common assumption of identically and independently distributed
transitions and rewards. Instead, our analysis allows for the sampling of
entire episodes, as is common practice in most applications. To establish the
consistency in this setting, we generalize Stone's Theorem, a well-known result
in nonparametric statistics on local averaging, to include episodic data and
the counterfactual estimation underlying off-policy evaluation (OPE). By
focusing on feedback policies that depend deterministically on the current
state in environments with continuous state-action spaces and system-inherent
stochasticity effected by chosen actions, and relying on trajectory simulation
similar to Monte Carlo methods, the proposed method is particularly well suited
for stochastic control environments. Compared to other OPE methods, our
algorithm does not require optimization, can be efficiently implemented via
tree-based nearest neighbor search and parallelization, and does not explicitly
assume a parametric model for the environment's dynamics. Numerical experiments
demonstrate the effectiveness of the algorithm compared to existing baselines
in a variety of stochastic control settings, including a linear quadratic
regulator, trade execution in limit order books, and online stochastic bin
packing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10835">Online Dynamic Submodular Optimization. (arXiv:2306.10835v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lesage_Landry_A/0/1/0/all/0/1">Antoine Lesage-Landry</a>, <a href="http://arxiv.org/find/math/1/au:+Pallage_J/0/1/0/all/0/1">Julien Pallage</a></p>
<p>We propose new algorithms with provable performance for online binary
optimization subject to general constraints and in dynamic settings. We
consider the subset of problems in which the objective function is submodular.
We propose the online submodular greedy algorithm (OSGA) which solves to
optimality an approximation of the previous round loss function to avoid the
NP-hardness of the original problem. We extend OSGA to a generic approximation
function. We show that OSGA has a dynamic regret bound similar to the tightest
bounds in online convex optimization with respect to the time horizon and the
cumulative round optimum variation. For instances where no approximation exists
or a computationally simpler implementation is desired, we design the online
submodular projected gradient descent (OSPGD) by leveraging the Lova\'sz
extension. We obtain a regret bound that is akin to the conventional online
gradient descent (OGD). Finally, we numerically test our algorithms in two
power system applications: fast-timescale demand response and real-time
distribution network reconfiguration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.13339">TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support. (arXiv:2306.13339v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zheng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_J/0/1/0/all/0/1">Jiahe Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertino_E/0/1/0/all/0/1">Elisa Bertino</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a></p>
<p>Trust evaluation assesses trust relationships between entities and
facilitates decision-making. Machine Learning (ML) shows great potential for
trust evaluation owing to its learning capabilities. In recent years, Graph
Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in
dealing with graph data. This has motivated researchers to explore their use in
trust evaluation, as trust relationships among entities can be modeled as a
graph. However, current trust evaluation methods that employ GNNs fail to fully
satisfy the dynamic nature of trust, overlook the adverse effects of
trust-related attacks, and cannot provide convincing explanations on evaluation
results. To address these problems, we propose TrustGuard, a GNN-based accurate
trust evaluation model that supports trust dynamicity, is robust against
typical attacks, and provides explanations through visualization. Specifically,
TrustGuard is designed with a layered architecture that contains a snapshot
input layer, a spatial aggregation layer, a temporal aggregation layer, and a
prediction layer. Among them, the spatial aggregation layer adopts a defense
mechanism to robustly aggregate local trust, and the temporal aggregation layer
applies an attention mechanism for effective learning of temporal patterns.
Extensive experiments on two real-world datasets show that TrustGuard
outperforms state-of-the-art GNN-based trust evaluation models with respect to
trust prediction across single-timeslot and multi-timeslot, even in the
presence of attacks. In addition, TrustGuard can explain its evaluation results
by visualizing both spatial and temporal views.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15683">Harnessing Data Augmentation to Quantify Uncertainty in the Early Estimation of Single-Photon Source Quality. (arXiv:2306.15683v2 [physics.optics] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Kedziora_D/0/1/0/all/0/1">David Jacob Kedziora</a>, <a href="http://arxiv.org/find/physics/1/au:+Musial_A/0/1/0/all/0/1">Anna Musia&#x142;</a>, <a href="http://arxiv.org/find/physics/1/au:+Rudno_Rudzinski_W/0/1/0/all/0/1">Wojciech Rudno-Rudzi&#x144;ski</a>, <a href="http://arxiv.org/find/physics/1/au:+Gabrys_B/0/1/0/all/0/1">Bogdan Gabrys</a></p>
<p>Novel methods for rapidly estimating single-photon source (SPS) quality have
been promoted in recent literature to address the expensive and time-consuming
nature of experimental validation via intensity interferometry. However, the
frequent lack of uncertainty discussions and reproducible details raises
concerns about their reliability. This study investigates the use of data
augmentation, a machine learning technique, to supplement experimental data
with bootstrapped samples and quantify the uncertainty of such estimates. Eight
datasets obtained from measurements involving a single InGaAs/GaAs epitaxial
quantum dot serve as a proof-of-principle example. Analysis of one of the SPS
quality metrics derived from efficient histogram fitting of the synthetic
samples, i.e. the probability of multi-photon emission events, reveals
significant uncertainty contributed by stochastic variability in the Poisson
processes that describe detection rates. Ignoring this source of error risks
severe overconfidence in both early quality estimates and claims for
state-of-the-art SPS devices. Additionally, this study finds that standard
least-squares fitting is comparable to using a Poisson likelihood, and
expanding averages show some promise for early estimation. Also, reducing
background counts improves fitting accuracy but does not address the
Poisson-process variability. Ultimately, data augmentation demonstrates its
value in supplementing physical experiments; its benefit here is to emphasise
the need for a cautious assessment of SPS quality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00142">BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting. (arXiv:2307.00142v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Emami_P/0/1/0/all/0/1">Patrick Emami</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1">Abhijeet Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Graf_P/0/1/0/all/0/1">Peter Graf</a></p>
<p>Short-term forecasting of residential and commercial building energy
consumption is widely used in power systems and continues to grow in
importance. Data-driven short-term load forecasting (STLF), although promising,
has suffered from a lack of open, large-scale datasets with high building
diversity. This has hindered exploring the pretrain-then-fine-tune paradigm for
STLF. To help address this, we present BuildingsBench, which consists of: 1)
Buildings-900K, a large-scale dataset of 900K simulated buildings representing
the U.S. building stock; and 2) an evaluation platform with over 1,900 real
residential and commercial buildings from 7 open datasets. BuildingsBench
benchmarks two under-explored tasks: zero-shot STLF, where a pretrained model
is evaluated on unseen buildings without fine-tuning, and transfer learning,
where a pretrained model is fine-tuned on a target building. The main finding
of our benchmark analysis is that synthetically pretrained models generalize
surprisingly well to real commercial buildings. An exploration of the effect of
increasing dataset size and diversity on zero-shot commercial building
performance reveals a power-law with diminishing returns. We also show that
fine-tuning pretrained models on real commercial and residential buildings
improves performance for a majority of target buildings. We hope that
BuildingsBench encourages and facilitates future research on generalizable
STLF. All datasets and code can be accessed from
https://github.com/NREL/BuildingsBench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02129">How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. (arXiv:2307.02129v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cagnetta_F/0/1/0/all/0/1">Francesco Cagnetta</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1">Leonardo Petrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomasini_U/0/1/0/all/0/1">Umberto M. Tomasini</a>, <a href="http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1">Alessandro Favero</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1">Matthieu Wyart</a></p>
<p>Deep learning algorithms demonstrate a surprising ability to learn
high-dimensional tasks from limited examples. This is commonly attributed to
the depth of neural networks, enabling them to build a hierarchy of abstract,
low-dimensional data representations. However, how many training examples are
required to learn such representations remains unknown. To quantitatively study
this question, we introduce the Random Hierarchy Model: a family of synthetic
tasks inspired by the hierarchical structure of language and images. The model
is a classification task where each class corresponds to a group of high-level
features, chosen among several equivalent groups associated with the same
class. In turn, each feature corresponds to a group of sub-features chosen
among several equivalent ones and so on, following a hierarchy of composition
rules. We find that deep networks learn the task by developing internal
representations invariant to exchanging equivalent groups. Moreover, the number
of data required corresponds to the point where correlations between low-level
features and classes become detectable. Overall, our results indicate how deep
networks overcome the curse of dimensionality by building invariant
representations, and provide an estimate of the number of data required to
learn a hierarchical task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03176">Learning Curves for Noisy Heterogeneous Feature-Subsampled Ridge Ensembles. (arXiv:2307.03176v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ruben_B/0/1/0/all/0/1">Benjamin S. Ruben</a>, <a href="http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1">Cengiz Pehlevan</a></p>
<p>Feature bagging is a well-established ensembling method which aims to reduce
prediction variance by combining predictions of many estimators trained on
subsets or projections of features. Here, we develop a theory of
feature-bagging in noisy least-squares ridge ensembles and simplify the
resulting learning curves in the special case of equicorrelated data. Using
analytical learning curves, we demonstrate that subsampling shifts the
double-descent peak of a linear predictor. This leads us to introduce
heterogeneous feature ensembling, with estimators built on varying numbers of
feature dimensions, as a computationally efficient method to mitigate
double-descent. Then, we compare the performance of a feature-subsampling
ensemble to a single linear predictor, describing a trade-off between noise
amplification due to subsampling and noise reduction due to ensembling. Our
qualitative insights carry over to linear classifiers applied to image
classification tasks with realistic datasets constructed using a
state-of-the-art deep learning feature map.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10763">Actor-agnostic Multi-label Action Recognition with Multi-modal Query. (arXiv:2307.10763v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1">Anindya Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sauradip Nag</a>, <a href="http://arxiv.org/find/cs/1/au:+Prada_J/0/1/0/all/0/1">Joaquin M Prada</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1">Anjan Dutta</a></p>
<p>Existing action recognition methods are typically actor-specific due to the
intrinsic topological and apparent differences among the actors. This requires
actor-specific pose estimation (e.g., humans vs. animals), leading to
cumbersome model design complexity and high maintenance costs. Moreover, they
often focus on learning the visual modality alone and single-label
classification whilst neglecting other available information sources (e.g.,
class name text) and the concurrent occurrence of multiple actions. To overcome
these limitations, we propose a new approach called 'actor-agnostic multi-modal
multi-label action recognition,' which offers a unified solution for various
types of actors, including humans and animals. We further formulate a novel
Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object
detection framework (e.g., DETR), characterized by leveraging visual and
textual modalities to represent the action classes better. The elimination of
actor-specific model designs is a key advantage, as it removes the need for
actor pose estimation altogether. Extensive experiments on five publicly
available benchmarks show that our MSQNet consistently outperforms the prior
arts of actor-specific alternatives on human and animal single- and multi-label
action recognition tasks by up to 50%. Code is made available at
https://github.com/mondalanindya/MSQNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00473">Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?. (arXiv:2308.00473v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Le_P/0/1/0/all/0/1">Phuong Quynh Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlotterer_J/0/1/0/all/0/1">J&#xf6;rg Schl&#xf6;tterer</a>, <a href="http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1">Christin Seifert</a></p>
<p>Models trained with empirical risk minimization (ERM) are known to learn to
rely on spurious features, i.e., their prediction is based on undesired
auxiliary features which are strongly correlated with class labels but lack
causal reasoning. This behavior particularly degrades accuracy in groups of
samples of the correlated class that are missing the spurious feature or
samples of the opposite class but with the spurious feature present. The
recently proposed Deep Feature Reweighting (DFR) method improves accuracy of
these worst groups. Based on the main argument that ERM mods can learn core
features sufficiently well, DFR only needs to retrain the last layer of the
classification model with a small group-balanced data set. In this work, we
examine the applicability of DFR to realistic data in the medical domain.
Furthermore, we investigate the reasoning behind the effectiveness of
last-layer retraining and show that even though DFR has the potential to
improve the accuracy of the worst group, it remains susceptible to spurious
correlations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04365">SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v6 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1">Matthew J. Vowels</a></p>
<p>Causal inference is a crucial goal of science, enabling researchers to arrive
at meaningful conclusions regarding the predictions of hypothetical
interventions using observational data. Path models, Structural Equation Models
(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to
unambiguously specify assumptions regarding the causal structure underlying a
phenomenon. Unlike DAGs, which make very few assumptions about the functional
and parametric form, SEM assumes linearity. This can result in functional
misspecification which prevents researchers from undertaking reliable effect
size estimation. In contrast, we propose Super Learner Equation Modeling, a
path modeling technique integrating machine learning Super Learner ensembles.
We empirically demonstrate its ability to provide consistent and unbiased
estimates of causal effects, its competitive performance for linear models when
compared with SEM, and highlight its superiority over SEM when dealing with
non-linear relationships. We provide open-source code, and a tutorial notebook
with example usage, accentuating the easy-to-use nature of the method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05194">Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving. (arXiv:2308.05194v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Uhlemann_N/0/1/0/all/0/1">Nico Uhlemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fent_F/0/1/0/all/0/1">Felix Fent</a>, <a href="http://arxiv.org/find/cs/1/au:+Lienkamp_M/0/1/0/all/0/1">Markus Lienkamp</a></p>
<p>In this paper, we assess the state of the art in pedestrian trajectory
prediction within the context of generating single trajectories, a critical
aspect aligning with the requirements in autonomous systems. The evaluation is
conducted on the widely-used ETH/UCY dataset where the Average Displacement
Error (ADE) and the Final Displacement Error (FDE) are reported. Alongside
this, we perform an ablation study to investigate the impact of the observed
motion history on prediction performance. To evaluate the scalability of each
approach when confronted with varying amounts of agents, the inference time of
each model is measured. Following a quantitative analysis, the resulting
predictions are compared in a qualitative manner, giving insight into the
strengths and weaknesses of current approaches. The results demonstrate that
although a constant velocity model (CVM) provides a good approximation of the
overall dynamics in the majority of cases, additional features need to be
incorporated to reflect common pedestrian behavior observed. Therefore, this
study presents a data-driven analysis with the intent to guide the future
development of pedestrian trajectory prediction algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05281">Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zihui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemphill_L/0/1/0/all/0/1">Libby Hemphill</a>, <a href="http://arxiv.org/find/cs/1/au:+Baecher_G/0/1/0/all/0/1">Gregory B. Baecher</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yubai Yuan</a></p>
<p>Effective disaster response is critical for affected communities. Responders
and decision-makers would benefit from reliable, timely measures of the issues
impacting their communities during a disaster, and social media offers a
potentially rich data source. Social media can reflect public concerns and
demands during a disaster, offering valuable insights for decision-makers to
understand evolving situations and optimize resource allocation. We used
Bidirectional Encoder Representations from Transformers (BERT) topic modeling
to cluster topics from Twitter data. Then, we conducted a temporal-spatial
analysis to examine the distribution of these topics across different regions
during the 2020 western U.S. wildfire season. Our results show that Twitter
users mainly focused on three topics:"health impact," "damage," and
"evacuation." We used the Susceptible-Infected-Recovered (SIR) theory to
explore the magnitude and velocity of topic diffusion on Twitter. The results
displayed a clear relationship between topic trends and wildfire propagation
patterns. The estimated parameters obtained from the SIR model in selected
cities revealed that residents exhibited a high level of several concerns
during the wildfire. Our study details how the SIR model and topic modeling
using social media data can provide decision-makers with a quantitative
approach to measure disaster response and support their decision-making
processes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.07520">Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning. (arXiv:2308.07520v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Shuyan Wang</a></p>
<p>The goal of Causal Discovery is to find automated search methods for learning
causal structures from observational data. In some cases all variables of the
interested causal mechanism are measured, and the task is to predict the
effects one measured variable has on another. In contrast, sometimes the
variables of primary interest are not directly observable but instead inferred
from their manifestations in the data. These are referred to as latent
variables. One commonly known example is the psychological construct of
intelligence, which cannot directly measured so researchers try to assess
through various indicators such as IQ tests. In this case, casual discovery
algorithms can uncover underlying patterns and structures to reveal the causal
connections between the latent variables and between the latent and observed
variables. This thesis focuses on two questions in causal discovery: providing
an alternative definition of k-Triangle Faithfulness that (i) is weaker than
strong faithfulness when applied to the Gaussian family of distributions, (ii)
can be applied to non-Gaussian families of distributions, and (iii) under the
assumption that the modified version of Strong Faithfulness holds, can be used
to show the uniform consistency of a modified causal discovery algorithm;
relaxing the sufficiency assumption to learn causal structures with latent
variables. Given the importance of inferring cause-and-effect relationships for
understanding and forecasting complex systems, the work in this thesis of
relaxing various simplification assumptions is expected to extend the causal
discovery method to be applicable in a wider range with diversified causal
mechanism and statistical phenomena.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.09113">Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Tang_H/0/1/0/all/0/1">Hewei Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Kong_Q/0/1/0/all/0/1">Qingkai Kong</a>, <a href="http://arxiv.org/find/stat/1/au:+Morris_J/0/1/0/all/0/1">Joseph P. Morris</a></p>
<p>Deep learning-based surrogate models have been widely applied in geological
carbon storage (GCS) problems to accelerate the prediction of reservoir
pressure and CO2 plume migration. Large amounts of data from physics-based
numerical simulators are required to train a model to accurately predict the
complex physical behaviors associated with this process. In practice, the
available training data are always limited in large-scale 3D problems due to
the high computational cost. Therefore, we propose to use a multi-fidelity
Fourier neural operator (FNO) to solve large-scale GCS problems with more
affordable multi-fidelity training datasets. FNO has a desirable grid-invariant
property, which simplifies the transfer learning procedure between datasets
with different discretization. We first test the model efficacy on a GCS
reservoir model being discretized into 110k grid cells. The multi-fidelity
model can predict with accuracy comparable to a high-fidelity model trained
with the same amount of high-fidelity data with 81% less data generation costs.
We further test the generalizability of the multi-fidelity model on a same
reservoir model with a finer discretization of 1 million grid cells. This case
was made more challenging by employing high-fidelity and low-fidelity datasets
generated by different geostatistical models and reservoir simulators. We
observe that the multi-fidelity FNO model can predict pressure fields with
reasonable accuracy even when the high-fidelity data are extremely limited. The
findings of this study can help for better understanding of the transferability
of multi-fidelity deep learning surrogate models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.00727">Deep learning in medical image registration: introduction and survey. (arXiv:2309.00727v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hammoudeh_A/0/1/0/all/0/1">Ahmad Hammoudeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Dupont_S/0/1/0/all/0/1">St&#xe9;phane Dupont</a></p>
<p>Image registration (IR) is a process that deforms images to align them with
respect to a reference space, making it easier for medical practitioners to
examine various medical images in a standardized reference frame, such as
having the same rotation and scale. This document introduces image registration
using a simple numeric example. It provides a definition of image registration
along with a space-oriented symbolic representation. This review covers various
aspects of image transformations, including affine, deformable, invertible, and
bidirectional transformations, as well as medical image registration algorithms
such as Voxelmorph, Demons, SyN, Iterative Closest Point, and SynthMorph. It
also explores atlas-based registration and multistage image registration
techniques, including coarse-fine and pyramid approaches. Furthermore, this
survey paper discusses medical image registration taxonomies, datasets,
evaluation measures, such as correlation-based metrics, segmentation-based
metrics, processing time, and model size. It also explores applications in
image-guided surgery, motion tracking, and tumor diagnosis. Finally, the
document addresses future research directions, including the further
development of transformers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03199">Matcha-TTS: A fast TTS architecture with conditional flow matching. (arXiv:2309.03199v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mehta_S/0/1/0/all/0/1">Shivam Mehta</a>, <a href="http://arxiv.org/find/eess/1/au:+Tu_R/0/1/0/all/0/1">Ruibo Tu</a>, <a href="http://arxiv.org/find/eess/1/au:+Beskow_J/0/1/0/all/0/1">Jonas Beskow</a>, <a href="http://arxiv.org/find/eess/1/au:+Szekely_E/0/1/0/all/0/1">&#xc9;va Sz&#xe9;kely</a>, <a href="http://arxiv.org/find/eess/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a></p>
<p>We introduce Matcha-TTS, a new encoder-decoder architecture for speedy TTS
acoustic modelling, trained using optimal-transport conditional flow matching
(OT-CFM). This yields an ODE-based decoder capable of high output quality in
fewer synthesis steps than models trained using score matching. Careful design
choices additionally ensure each synthesis step is fast to run. The method is
probabilistic, non-autoregressive, and learns to speak from scratch without
external alignments. Compared to strong pre-trained baseline models, the
Matcha-TTS system has the smallest memory footprint, rivals the speed of the
fastest models on long utterances, and attains the highest mean opinion score
in a listening test. Please see https://shivammehta25.github.io/Matcha-TTS/ for
audio examples, code, and pre-trained models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03851">CenTime: Event-Conditional Modelling of Censoring in Survival Analysis. (arXiv:2309.03851v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shahin_A/0/1/0/all/0/1">Ahmed H. Shahin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1">An Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitehead_A/0/1/0/all/0/1">Alexander C. Whitehead</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1">Daniel C. Alexander</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacob_J/0/1/0/all/0/1">Joseph Jacob</a>, <a href="http://arxiv.org/find/cs/1/au:+Barber_D/0/1/0/all/0/1">David Barber</a></p>
<p>Survival analysis is a valuable tool for estimating the time until specific
events, such as death or cancer recurrence, based on baseline observations.
This is particularly useful in healthcare to prognostically predict clinically
important events based on patient data. However, existing approaches often have
limitations; some focus only on ranking patients by survivability, neglecting
to estimate the actual event time, while others treat the problem as a
classification task, ignoring the inherent time-ordered structure of the
events. Furthermore, the effective utilization of censored samples - training
data points where the exact event time is unknown - is essential for improving
the predictive accuracy of the model. In this paper, we introduce CenTime, a
novel approach to survival analysis that directly estimates the time to event.
Our method features an innovative event-conditional censoring mechanism that
performs robustly even when uncensored data is scarce. We demonstrate that our
approach forms a consistent estimator for the event model parameters, even in
the absence of uncensored data. Furthermore, CenTime is easily integrated with
deep learning models with no restrictions on batch size or the number of
uncensored samples. We compare our approach with standard survival analysis
methods, including the Cox proportional-hazard model and DeepHit. Our results
indicate that CenTime offers state-of-the-art performance in predicting
time-to-death while maintaining comparable ranking performance. Our
implementation is publicly available at
https://github.com/ahmedhshahin/CenTime.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05202">Graph-Aware Contrasting for Multivariate Time-Series Classification. (arXiv:2309.05202v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yucheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuecong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Min Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lihua Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghua Chen</a></p>
<p>Contrastive learning, as a self-supervised learning paradigm, becomes popular
for Multivariate Time-Series (MTS) classification. It ensures the consistency
across different views of unlabeled samples and then learns effective
representations for these samples. Existing contrastive learning methods mainly
focus on achieving temporal consistency with temporal augmentation and
contrasting techniques, aiming to preserve temporal patterns against
perturbations for MTS data. However, they overlook spatial consistency that
requires the stability of individual sensors and their correlations. As MTS
data typically originate from multiple sensors, ensuring spatial consistency
becomes essential for the overall performance of contrastive learning on MTS
data. Thus, we propose Graph-Aware Contrasting for spatial consistency across
MTS data. Specifically, we propose graph augmentations including node and edge
augmentations to preserve the stability of sensors and their correlations,
followed by graph contrasting with both node- and graph-level contrasting to
extract robust sensor- and global-level features. We further introduce
multi-window temporal contrasting to ensure temporal consistency in the data
for each sensor. Extensive experiments demonstrate that our proposed method
achieves state-of-the-art performance on various MTS classification tasks. The
code is available at https://github.com/Frank-Wang-oss/TS-GAC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05305">Fully-Connected Spatial-Temporal Graph for Multivariate Time-Series Data. (arXiv:2309.05305v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yucheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuecong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Min Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lihua Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghua Chen</a></p>
<p>Multivariate Time-Series (MTS) data is crucial in various application fields.
With its sequential and multi-source (multiple sensors) properties, MTS data
inherently exhibits Spatial-Temporal (ST) dependencies, involving temporal
correlations between timestamps and spatial correlations between sensors in
each timestamp. To effectively leverage this information, Graph Neural
Network-based methods (GNNs) have been widely adopted. However, existing
approaches separately capture spatial dependency and temporal dependency and
fail to capture the correlations between Different sEnsors at Different
Timestamps (DEDT). Overlooking such correlations hinders the comprehensive
modelling of ST dependencies within MTS data, thus restricting existing GNNs
from learning effective representations. To address this limitation, we propose
a novel method called Fully-Connected Spatial-Temporal Graph Neural Network
(FC-STGNN), including two key components namely FC graph construction and FC
graph convolution. For graph construction, we design a decay graph to connect
sensors across all timestamps based on their temporal distances, enabling us to
fully model the ST dependencies by considering the correlations between DEDT.
Further, we devise FC graph convolution with a moving-pooling GNN layer to
effectively capture the ST dependencies for learning effective representations.
Extensive experiments show the effectiveness of FC-STGNN on multiple MTS
datasets compared to SOTA methods. The code is available at
https://github.com/Frank-Wang-oss/FCSTGNN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.09737">RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud. (arXiv:2309.09737v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhijun Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Fangqiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1">Hantao Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chris Xiaoxuan Lu</a></p>
<p>Mobile autonomy relies on the precise perception of dynamic environments.
Robustly tracking moving objects in 3D world thus plays a pivotal role for
applications like trajectory prediction, obstacle avoidance, and path planning.
While most current methods utilize LiDARs or cameras for Multiple Object
Tracking (MOT), the capabilities of 4D imaging radars remain largely
unexplored. Recognizing the challenges posed by radar noise and point sparsity
in 4D radar data, we introduce RaTrack, an innovative solution tailored for
radar-based tracking. Bypassing the typical reliance on specific object types
and 3D bounding boxes, our method focuses on motion segmentation and
clustering, enriched by a motion estimation module. Evaluated on the
View-of-Delft dataset, RaTrack showcases superior tracking precision of moving
objects, largely surpassing the performance of the state of the art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10149">Analysis of the Memorization and Generalization Capabilities of AI Agents: Are Continual Learners Robust?. (arXiv:2309.10149v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minsu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1">Walid Saad</a></p>
<p>In continual learning (CL), an AI agent (e.g., autonomous vehicles or
robotics) learns from non-stationary data streams under dynamic environments.
For the practical deployment of such applications, it is important to guarantee
robustness to unseen environments while maintaining past experiences. In this
paper, a novel CL framework is proposed to achieve robust generalization to
dynamic environments while retaining past knowledge. The considered CL agent
uses a capacity-limited memory to save previously observed environmental
information to mitigate forgetting issues. Then, data points are sampled from
the memory to estimate the distribution of risks over environmental change so
as to obtain predictors that are robust with unseen changes. The generalization
and memorization performance of the proposed framework are theoretically
analyzed. This analysis showcases the tradeoff between memorization and
generalization with the memory size. Experiments show that the proposed
algorithm outperforms memory-based CL baselines across all environments while
significantly improving the generalization performance on unseen target
environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.11475">Creating walls to avoid unwanted points in root finding and optimization. (arXiv:2309.11475v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Truong_T/0/1/0/all/0/1">Tuyen Trung Truong</a></p>
<p>In root finding and optimization, there are many cases where there is a
closed set $A$ one likes that the sequence constructed by one's favourite
method will not converge to A (here, we do not assume extra properties on $A$
such as being convex or connected). For example, if one wants to find roots,
and one chooses initial points in the basin of attraction for 1 root $z^*$ (a
fact which one may not know before hand), then one will always end up in that
root. In this case, one would like to have a mechanism to avoid this point
$z^*$ in the next runs of one's algorithm.
</p>
<p>Assume that one already has a method IM for optimization (and root finding)
for non-constrained optimization. We provide a simple modification IM1 of the
method to treat the situation discussed in the previous paragraph. If the
method IM has strong theoretical guarantees, then so is IM1. As applications,
we prove two theoretical applications: one concerns finding roots of a
meromorphic function in an open subset of a Riemann surface, and the other
concerns finding local minima of a function in an open subset of a Euclidean
space inside it the function has at most countably many critical points.
</p>
<p>Along the way, we compare with main existing relevant methods in the current
literature. We provide several examples in various different settings to
illustrate the usefulness of the new approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13500">Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy. (arXiv:2309.13500v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ni_L/0/1/0/all/0/1">Lin Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sijie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zeyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xianda Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1">Paul Denny</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiamou Liu</a></p>
<p>Learnersourcing offers great potential for scalable education through student
content creation. However, predicting student performance on learnersourced
questions, which is essential for personalizing the learning experience, is
challenging due to the inherent noise in student-generated data. Moreover,
while conventional graph-based methods can capture the complex network of
student and question interactions, they often fall short under cold start
conditions where limited student engagement with questions yields sparse data.
To address both challenges, we introduce an innovative strategy that synergizes
the potential of integrating Signed Graph Neural Networks (SGNNs) and Large
Language Model (LLM) embeddings. Our methodology employs a signed bipartite
graph to comprehensively model student answers, complemented by a contrastive
learning framework that enhances noise resilience. Furthermore, LLM's
contribution lies in generating foundational question embeddings, proving
especially advantageous in addressing cold start scenarios characterized by
limited graph data. Validation across five real-world datasets sourced from the
PeerWise platform underscores our approach's effectiveness. Our method
outperforms baselines, showcasing enhanced predictive accuracy and robustness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02567">Improving Automatic VQA Evaluation Using Large Language Models. (arXiv:2310.02567v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manas_O/0/1/0/all/0/1">Oscar Ma&#xf1;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Krojer_B/0/1/0/all/0/1">Benno Krojer</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Aishwarya Agrawal</a></p>
<p>8 years after the visual question answering (VQA) task was proposed, accuracy
remains the primary metric for automatic evaluation. VQA Accuracy has been
effective so far in the IID evaluation setting. However, our community is
undergoing a shift towards open-ended generative models and OOD evaluation. In
this new paradigm, the existing VQA Accuracy metric is overly stringent and
underestimates the performance of VQA systems. Thus, there is a need to develop
more robust automatic VQA metrics that serve as a proxy for human judgment. In
this work, we propose to leverage the in-context learning capabilities of
instruction-tuned large language models (LLMs) to build a better VQA metric. We
formulate VQA evaluation as an answer-rating task where the LLM is instructed
to score the accuracy of a candidate answer given a set of reference answers.
We demonstrate the proposed metric better correlates with human judgment
compared to existing metrics across several VQA models and benchmarks. We hope
wide adoption of our metric will contribute to better estimating the research
progress on the VQA task. We plan to release the evaluation code and collected
human judgments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05181">Unified speech and gesture synthesis using flow matching. (arXiv:2310.05181v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mehta_S/0/1/0/all/0/1">Shivam Mehta</a>, <a href="http://arxiv.org/find/eess/1/au:+Tu_R/0/1/0/all/0/1">Ruibo Tu</a>, <a href="http://arxiv.org/find/eess/1/au:+Alexanderson_S/0/1/0/all/0/1">Simon Alexanderson</a>, <a href="http://arxiv.org/find/eess/1/au:+Beskow_J/0/1/0/all/0/1">Jonas Beskow</a>, <a href="http://arxiv.org/find/eess/1/au:+Szekely_E/0/1/0/all/0/1">&#xc9;va Sz&#xe9;kely</a>, <a href="http://arxiv.org/find/eess/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a></p>
<p>As text-to-speech technologies achieve remarkable naturalness in read-aloud
tasks, there is growing interest in multimodal synthesis of verbal and
non-verbal communicative behaviour, such as spontaneous speech and associated
body gestures. This paper presents a novel, unified architecture for jointly
synthesising speech acoustics and skeleton-based 3D gesture motion from text,
trained using optimal-transport conditional flow matching (OT-CFM). The
proposed architecture is simpler than the previous state of the art, has a
smaller memory footprint, and can capture the joint distribution of speech and
gestures, generating both modalities together in one single process. The new
training regime, meanwhile, enables better synthesis quality in much fewer
steps (network evaluations) than before. Uni- and multimodal subjective tests
demonstrate improved speech naturalness, gesture human-likeness, and
cross-modal appropriateness compared to existing benchmarks. Please see
https://shivammehta25.github.io/Match-TTSG/ for video examples and code.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05365">Molecular De Novo Design through Transformer-based Reinforcement Learning. (arXiv:2310.05365v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Pengcheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1">Tao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1">Tianfan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Laghuvarapu_S/0/1/0/all/0/1">Siddhartha Laghuvarapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a></p>
<p>In this work, we introduce a method to fine-tune a Transformer-based
generative model for molecular de novo design. Leveraging the superior sequence
learning capacity of Transformers over Recurrent Neural Networks (RNNs), our
model can generate molecular structures with desired properties effectively. In
contrast to the traditional RNN-based models, our proposed method exhibits
superior performance in generating compounds predicted to be active against
various biological targets, capturing long-term dependencies in the molecular
structure sequence. The model's efficacy is demonstrated across numerous tasks,
including generating analogues to a query structure and producing compounds
with particular attributes, outperforming the baseline RNN-based methods. Our
approach can be used for scaffold hopping, library expansion starting from a
single molecule, and generating compounds with high predicted activity against
biological targets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10224">Generalizing Medical Image Representations via Quaternion Wavelet Networks. (arXiv:2310.10224v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Sigillo_L/0/1/0/all/0/1">Luigi Sigillo</a>, <a href="http://arxiv.org/find/eess/1/au:+Grassucci_E/0/1/0/all/0/1">Eleonora Grassucci</a>, <a href="http://arxiv.org/find/eess/1/au:+Uncini_A/0/1/0/all/0/1">Aurelio Uncini</a>, <a href="http://arxiv.org/find/eess/1/au:+Comminiello_D/0/1/0/all/0/1">Danilo Comminiello</a></p>
<p>Neural network generalizability is becoming a broad research field due to the
increasing availability of datasets from different sources and for various
tasks. This issue is even wider when processing medical data, where a lack of
methodological standards causes large variations being provided by different
imaging centers or acquired with various devices and cofactors. To overcome
these limitations, we introduce a novel, generalizable, data- and task-agnostic
framework able to extract salient features from medical images. The proposed
quaternion wavelet network (QUAVE) can be easily integrated with any
pre-existing medical image analysis or synthesis task, and it can be involved
with real, quaternion, or hypercomplex-valued models, generalizing their
adoption to single-channel data. QUAVE first extracts different sub-bands
through the quaternion wavelet transform, resulting in both
low-frequency/approximation bands and high-frequency/fine-grained features.
Then, it weighs the most representative set of sub-bands to be involved as
input to any other neural model for image processing, replacing standard data
samples. We conduct an extensive experimental evaluation comprising different
datasets, diverse image analysis, and synthesis tasks including reconstruction,
segmentation, and modality translation. We also evaluate QUAVE in combination
with both real and quaternion-valued models. Results demonstrate the
effectiveness and the generalizability of the proposed framework that improves
network performance while being flexible to be adopted in manifold scenarios
and robust to domain shifts. The full code is available at:
https://github.com/ispamm/QWT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15872">KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models. (arXiv:2310.15872v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhengqi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fan-Keng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Boning_D/0/1/0/all/0/1">Duane S. Boning</a></p>
<p>In this paper, we exploit a fundamental principle of analog electronic
circuitry, Kirchhoff's current law, to introduce a unique class of neural
network models that we refer to as KirchhoffNet. KirchhoffNet establishes close
connections with message passing neural networks and continuous-depth networks.
We demonstrate that even in the absence of any traditional layers (such as
convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test
accuracy on the MNIST dataset, comparable with state of the art (SOTA) results.
What makes KirchhoffNet more intriguing is its potential in the realm of
hardware. Contemporary deep neural networks are conventionally deployed on
GPUs. In contrast, KirchhoffNet can be physically realized by an analog
electronic circuit. Moreover, we justify that irrespective of the number of
parameters within a KirchhoffNet, its forward calculation can always be
completed within 1/f seconds, with f representing the hardware's clock
frequency. This characteristic introduces a promising technology for
implementing ultra-large-scale neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15966">Constructing and Machine Learning Calabi-Yau Five-folds. (arXiv:2310.15966v2 [hep-th] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-th/1/au:+Alawadhi_R/0/1/0/all/0/1">R. Alawadhi</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Angella_D/0/1/0/all/0/1">D. Angella</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Leonardo_A/0/1/0/all/0/1">A. Leonardo</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Gherardini_T/0/1/0/all/0/1">T. Schettini Gherardini</a></p>
<p>We construct all possible complete intersection Calabi-Yau five-folds in a
product of four or less complex projective spaces, with up to four constraints.
We obtain $27068$ spaces, which are not related by permutations of rows and
columns of the configuration matrix, and determine the Euler number for all of
them. Excluding the $3909$ product manifolds among those, we calculate the
cohomological data for $12433$ cases, i.e. $53.7 \%$ of the non-product spaces,
obtaining $2375$ different Hodge diamonds. The dataset containing all the above
information is available at
https://www.dropbox.com/scl/fo/z7ii5idt6qxu36e0b8azq/h?rlkey=0qfhx3tykytduobpld510gsfy&amp;dl=0
. The distributions of the invariants are presented, and a comparison with the
lower-dimensional analogues is discussed. Supervised machine learning is
performed on the cohomological data, via classifier and regressor (both fully
connected and convolutional) neural networks. We find that $h^{1,1}$ can be
learnt very efficiently, with very high $R^2$ score and an accuracy of $96\%$,
i.e. $96 \%$ of the predictions exactly match the correct values. For
$h^{1,4},h^{2,3}, \eta$, we also find very high $R^2$ scores, but the accuracy
is lower, due to the large ranges of possible values.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.17759">Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization. (arXiv:2310.17759v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Junchi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1">Amin Karbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1">Niao He</a></p>
<p>Algorithmic reproducibility measures the deviation in outputs of machine
learning algorithms upon minor changes in the training process. Previous work
suggests that first-order methods would need to trade-off convergence rate
(gradient complexity) for better reproducibility. In this work, we challenge
this perception and demonstrate that both optimal reproducibility and
near-optimal convergence guarantees can be achieved for smooth convex
minimization and smooth convex-concave minimax problems under various
error-prone oracle settings. Particularly, given the inexact initialization
oracle, our regularization-based algorithms achieve the best of both worlds -
optimal reproducibility and near-optimal gradient complexity - for minimization
and minimax optimization. With the inexact gradient oracle, the near-optimal
guarantees also hold for minimax optimization. Additionally, with the
stochastic gradient oracle, we show that stochastic gradient descent ascent is
optimal in terms of both reproducibility and gradient complexity. We believe
our results contribute to an enhanced understanding of the
reproducibility-convergence trade-off in the context of convex optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13538">Speak Like a Native: Prompting Large Language Models in a Native Style. (arXiv:2311.13538v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhicheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yinya Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Jing Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jing Tang</a></p>
<p>In-context learning (ICL) with large language models (LLMs) has become the
modern tools of choice for many natural language processing tasks. However, how
the text style of in-context examples influences the performance of LLMs still
remains under-explored. This paper presents a novel and effective approach,
named \textbf{AlignedCoT}, to improve the reasoning capability of LLMs by
aligning the in-context examples with the native style of LLMs.''Native''
refers to the inherent characteristic of LLMs which can be probed by zero-shot
scenarios.AlignedCoT is widely applicable to ICL methods, making it easy to
combine with state-of-the-art techniques to further improve the LLMs'
performance. We conduct extensive and comprehensive experiments on several
benchmarks on mathematical question-answering, common-sense reasoning, and text
understanding. The empirical results demonstrate that our AlignedCoT
significantly improves performance over the carefully handcrafted
demonstrations. Specifically, with AlignedCoT, we observe an average +3.2\%
improvement for \texttt{gpt-3.5-turbo} compared to the carefully handcrafted
CoT on multi-step reasoning benchmarks.Furthermore, we use AlignedCoT to
rewrite the CoT text style in the training set, which improves the performance
of Retrieval Augmented Generation by 3.6\%.The source code and dataset is
available at https://github.com/yangzhch6/AlignedCoT
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13925">Deep Neural Decision Forest: A Novel Approach for Predicting Recovery or Decease of COVID-19 Patients with Clinical and RT-PCR. (arXiv:2311.13925v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Dehghani_M/0/1/0/all/0/1">Mohammad Dehghani</a>, <a href="http://arxiv.org/find/eess/1/au:+Yazdanparast_Z/0/1/0/all/0/1">Zahra Yazdanparast</a>, <a href="http://arxiv.org/find/eess/1/au:+Samani_R/0/1/0/all/0/1">Rasoul Samani</a></p>
<p>COVID-19 continues to be considered an endemic disease in spite of the World
Health Organization's declaration that the pandemic is over. This pandemic has
disrupted people's lives in unprecedented ways and caused widespread morbidity
and mortality. As a result, it is important for emergency physicians to
identify patients with a higher mortality risk in order to prioritize hospital
equipment, especially in areas with limited medical services. The collected
data from patients is beneficial to predict the outcome of COVID-19 cases,
although there is a question about which data makes the most accurate
predictions. Therefore, this study aims to accomplish two main objectives.
First, we want to examine whether deep learning algorithms can predict a
patient's morality. Second, we investigated the impact of Clinical and RT-PCR
on prediction to determine which one is more reliable. We defined four stages
with different feature sets and used interpretable deep learning methods to
build appropriate model. Based on results, the deep neural decision forest
performed the best across all stages and proved its capability to predict the
recovery and death of patients. Additionally, results indicate that Clinical
alone (without the use of RT-PCR) is the most effective method of diagnosis,
with an accuracy of 80%. It is important to document and understand experiences
from the COVID-19 pandemic in order to aid future medical efforts. This study
can provide guidance for medical professionals in the event of a crisis or
outbreak similar to COVID-19.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14115">A density estimation perspective on learning from pairwise human preferences. (arXiv:2311.14115v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel D. Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Dauphin_Y/0/1/0/all/0/1">Yann Dauphin</a></p>
<p>Learning from human feedback (LHF) -- and in particular learning from
pairwise preferences -- has recently become a crucial ingredient in training
large language models (LLMs), and has been the subject of much research. Most
recent works frame it as a reinforcement learning problem, where a reward
function is learned from pairwise preference data and the LLM is treated as a
policy which is adapted to maximize the rewards, often under additional
regularization constraints. We propose an alternative interpretation which
centers on the generative process for pairwise preferences and treats LHF as a
density estimation problem. We provide theoretical and empirical results
showing that for a family of generative processes defined via preference
behavior distribution equations, training a reward function on pairwise
preferences effectively models an annotator's implicit preference distribution.
Finally, we discuss and present findings on "annotator misspecification" --
failure cases where wrong modeling assumptions are made about annotator
behavior, resulting in poorly-adapted models -- suggesting that approaches that
learn from pairwise human preferences could have trouble learning from a
population of annotators with diverse viewpoints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00102">FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation. (arXiv:2312.00102v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanfei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lele Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a></p>
<p>Federated learning (FL) is an emerging paradigm for decentralized training of
machine learning models on distributed clients, without revealing the data to
the central server. The learning scheme may be horizontal, vertical or hybrid
(both vertical and horizontal). Most existing research work with deep neural
network (DNN) modelling is focused on horizontal data distributions, while
vertical and hybrid schemes are much less studied. In this paper, we propose a
generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based
learning. The idea of our algorithm is characterised by higher inference
accuracy, stronger privacy-preserving properties, and lower client-server
communication bandwidth demands as compared with existing work. The
experimental results show that FedEmb is an effective method to tackle both
split feature &amp; subject space decentralized problems, shows 0.3% to 4.2%
inference accuracy improvement with limited privacy revealing for datasets
stored in local clients, and reduces 88.9 % time complexity over vertical
baseline method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03038">Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit. (arXiv:2312.03038v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanfei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lele Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a></p>
<p>Transformer requires a fixed number of layers and heads which makes them
inflexible to the complexity of individual samples and expensive in training
and inference. To address this, we propose a sample-based Dynamic Hierarchical
Transformer (DHT) model whose layers and heads can be dynamically configured
with single data samples via solving contextual bandit problems. To determine
the number of layers and heads, we use the Uniform Confidence Bound while we
deploy combinatorial Thompson Sampling in order to select specific head
combinations given their number. Different from previous work that focuses on
compressing trained networks for inference only, DHT is not only advantageous
for adaptively optimizing the underlying network architecture during training
but also has a flexible network for efficient inference. To the best of our
knowledge, this is the first comprehensive data-driven dynamic transformer
without any additional auxiliary neural networks that implement the dynamic
system. According to the experiment results, we achieve up to 74% computational
savings for both training and inference with a minimal loss of accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04889">KwaiAgents: Generalized Information-seeking Agent System with Large Language Models. (arXiv:2312.04889v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Haojie Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_Z/0/1/0/all/0/1">Zepeng Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yaojia Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1">Ruiji Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a></p>
<p>Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user's query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system's performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09817">Calibrated One Round Federated Learning with Bayesian Inference in the Predictive Space. (arXiv:2312.09817v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Mohsin Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guojun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1">Kaiyang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1">Pascal Poupart</a></p>
<p>Federated Learning (FL) involves training a model over a dataset distributed
among clients, with the constraint that each client's dataset is localized and
possibly heterogeneous. In FL, small and noisy datasets are common,
highlighting the need for well-calibrated models that represent the uncertainty
of predictions. The closest FL techniques to achieving such goals are the
Bayesian FL methods which collect parameter samples from local posteriors, and
aggregate them to approximate the global posterior. To improve scalability for
larger models, one common Bayesian approach is to approximate the global
predictive posterior by multiplying local predictive posteriors. In this work,
we demonstrate that this method gives systematically overconfident predictions,
and we remedy this by proposing $\beta$-Predictive Bayes, a Bayesian FL
algorithm that interpolates between a mixture and product of the predictive
posteriors, using a tunable parameter $\beta$. This parameter is tuned to
improve the global ensemble's calibration, before it is distilled to a single
model. Our method is evaluated on a variety of regression and classification
datasets to demonstrate its superiority in calibration to other baselines, even
as data heterogeneity increases. Code available at
https://github.com/hasanmohsin/betaPredBayesFL
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10324">Federated Learning with Instance-Dependent Noisy Label. (arXiv:2312.10324v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jieming Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a></p>
<p>Federated learning (FL) with noisy labels poses a significant challenge.
Existing methods designed for handling noisy labels in centralized learning
tend to lose their effectiveness in the FL setting, mainly due to the small
dataset size and the heterogeneity of client data. While some attempts have
been made to tackle FL with noisy labels, they primarily focused on scenarios
involving class-conditional noise. In this paper, we study the more challenging
and practical issue of instance-dependent noise (IDN) in FL. We introduce a
novel algorithm called FedBeat (Federated Learning with Bayesian
Ensemble-Assisted Transition Matrix Estimation). FedBeat aims to build a global
statistically consistent classifier using the IDN transition matrix (IDNTM),
which encompasses three synergistic steps: (1) A federated data extraction step
that constructs a weak global model and extracts high-confidence data using a
Bayesian model ensemble method. (2) A federated transition matrix estimation
step in which clients collaboratively train an IDNTM estimation network based
on the extracted data. (3) A federated classifier correction step that enhances
the global model's performance by training it using a loss function tailored
for noisy labels, leveraging the IDNTM. Experiments conducted on CIFAR-10 and
SVHN verify that the proposed method significantly outperforms state-of-the-art
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10808">Non-Euclidean Spatial Graph Neural Network. (arXiv:2312.10808v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sirui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingcheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Angirekula_A/0/1/0/all/0/1">Abhinav Angirekula</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Allen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a></p>
<p>Spatial networks are networks whose graph topology is constrained by their
embedded spatial space. Understanding the coupled spatial-graph properties is
crucial for extracting powerful representations from spatial networks.
Therefore, merely combining individual spatial and network representations
cannot reveal the underlying interaction mechanism of spatial networks.
Besides, existing spatial network representation learning methods can only
consider networks embedded in Euclidean space, and can not well exploit the
rich geometric information carried by irregular and non-uniform non-Euclidean
space. In order to address this issue, in this paper we propose a novel generic
framework to learn the representation of spatial networks that are embedded in
non-Euclidean manifold space. Specifically, a novel message-passing-based
neural network is proposed to combine graph topology and spatial geometry,
where spatial geometry is extracted as messages on the edges. We theoretically
guarantee that the learned representations are provably invariant to important
symmetries such as rotation or translation, and simultaneously maintain
sufficient ability in distinguishing different geometric structures. The
strength of our proposed method is demonstrated through extensive experiments
on both synthetic and real-world datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12102">I-CEE: Tailoring Explanations of Image Classification Models to User Expertise. (arXiv:2312.12102v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yao Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_P/0/1/0/all/0/1">Peizhu Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Unhelkar_V/0/1/0/all/0/1">Vaibhav Unhelkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1">Enkelejda Kasneci</a></p>
<p>Effectively explaining decisions of black-box machine learning models is
critical to responsible deployment of AI systems that rely on them. Recognizing
their importance, the field of explainable AI (XAI) provides several techniques
to generate these explanations. Yet, there is relatively little emphasis on the
user (the explainee) in this growing body of work and most XAI techniques
generate "one-size-fits-all" explanations. To bridge this gap and achieve a
step closer towards human-centered XAI, we present I-CEE, a framework that
provides Image Classification Explanations tailored to User Expertise. Informed
by existing work, I-CEE explains the decisions of image classification models
by providing the user with an informative subset of training data (i.e.,
example images), corresponding local explanations, and model decisions.
However, unlike prior work, I-CEE models the informativeness of the example
images to depend on user expertise, resulting in different examples for
different users. We posit that by tailoring the example set to user expertise,
I-CEE can better facilitate users' understanding and simulatability of the
model. To evaluate our approach, we conduct detailed experiments in both
simulation and with human participants (N = 100) on multiple datasets.
Experiments with simulated users show that I-CEE improves users' ability to
accurately predict the model's decisions (simulatability) compared to
baselines, providing promising preliminary results. Experiments with human
participants demonstrate that our method significantly improves user
simulatability accuracy, highlighting the importance of human-centered XAI
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.16414">Bellman Optimal Step-size Straightening of Flow-Matching Models. (arXiv:2312.16414v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bao Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Viet Anh Nguyen</a></p>
<p>Flow matching is a powerful framework for generating high-quality samples in
various applications, especially image synthesis. However, the intensive
computational demands of these models, especially during the fine-tuning
process and sampling processes, pose significant challenges for low-resource
scenarios. This paper introduces Bellman Optimal Step-size Straightening (BOSS)
technique for distilling flow-matching generative models: it aims specifically
for a few-step efficient image sampling while adhering to a computational
budget constraint. First, this technique involves a dynamic programming
algorithm that optimizes the step sizes of the pretrained network. Then, it
refines the velocity network to match the optimal step sizes, aiming to
straighten the generation paths. Extensive experimental evaluations across
image generation tasks demonstrate the efficacy of BOSS in terms of both
resource utilization and image quality. Our results reveal that BOSS achieves
substantial gains in efficiency while maintaining competitive sample quality,
effectively bridging the gap between low-resource constraints and the demanding
requirements of flow-matching generative models. Our paper also fortifies the
responsible development of artificial intelligence, offering a more sustainable
generative model that reduces computational costs and environmental footprints.
Our code can be found at https://github.com/nguyenngocbaocmt02/BOSS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.01375">Mapping Walnut Water Stress with High Resolution Multispectral UAV Imagery and Machine Learning. (arXiv:2401.01375v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaitlyn Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yufang Jin</a></p>
<p>Effective monitoring of walnut water status and stress level across the whole
orchard is an essential step towards precision irrigation management of
walnuts, a significant crop in California. This study presents a machine
learning approach using Random Forest (RF) models to map stem water potential
(SWP) by integrating high-resolution multispectral remote sensing imagery from
Unmanned Aerial Vehicle (UAV) flights with weather data. From 2017 to 2018,
five flights of an UAV equipped with a seven-band multispectral camera were
conducted over a commercial walnut orchard, paired with concurrent ground
measurements of sampled walnut plants. The RF regression model, utilizing
vegetation indices derived from orthomosaiced UAV imagery and weather data,
effectively estimated ground-measured SWPs, achieving an $R^2$ of 0.63 and a
mean absolute error (MAE) of 0.80 bars. The integration of weather data was
particularly crucial for consolidating data across various flight dates.
Significant variables for SWP estimation included wind speed and vegetation
indices such as NDVI, NDRE, and PSRI.A reduced RF model excluding red-edge
indices of NDRE and PSRI, demonstrated slightly reduced accuracy ($R^2$ =
0.54). Additionally, the RF classification model predicted water stress levels
in walnut trees with 85% accuracy, surpassing the 80% accuracy of the reduced
classification model. The results affirm the efficacy of UAV-based
multispectral imaging combined with machine learning, incorporating thermal
data, NDVI, red-edge indices, and weather data, in walnut water stress
estimation and assessment. This methodology offers a scalable, cost-effective
tool for data-driven precision irrigation management at an individual plant
level in walnut orchards.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.02771">Powerformer: A Section-adaptive Transformer for Power Flow Adjustment. (arXiv:2401.02771v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kaixuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Wei Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shunyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yaoquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yihe Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qing_Y/0/1/0/all/0/1">Yunpeng Qing</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a></p>
<p>In this paper, we present a novel transformer architecture tailored for
learning robust power system state representations, which strives to optimize
power dispatch for the power flow adjustment across different transmission
sections. Specifically, our proposed approach, named Powerformer, develops a
dedicated section-adaptive attention mechanism, separating itself from the
self-attention used in conventional transformers. This mechanism effectively
integrates power system states with transmission section information, which
facilitates the development of robust state representations. Furthermore, by
considering the graph topology of power system and the electrical attributes of
bus nodes, we introduce two customized strategies to further enhance the
expressiveness: graph neural network propagation and multi-factor attention
mechanism. Extensive evaluations are conducted on three power system scenarios,
including the IEEE 118-bus system, a realistic 300-bus system in China, and a
large-scale European system with 9241 buses, where Powerformer demonstrates its
superior performance over several baseline methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03154">Decentralized Multi-Agent Active Search and Tracking when Targets Outnumber Agents. (arXiv:2401.03154v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Arundhati Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jeff Schneider</a></p>
<p>Multi-agent multi-target tracking has a wide range of applications, including
wildlife patrolling, security surveillance or environment monitoring. Such
algorithms often make restrictive assumptions: the number of targets and/or
their initial locations may be assumed known, or agents may be pre-assigned to
monitor disjoint partitions of the environment, reducing the burden of
exploration. This also limits applicability when there are fewer agents than
targets, since agents are unable to continuously follow the targets in their
fields of view. Multi-agent tracking algorithms additionally assume inter-agent
synchronization of observations, or the presence of a central controller to
coordinate joint actions. Instead, we focus on the setting of decentralized
multi-agent, multi-target, simultaneous active search-and-tracking with
asynchronous inter-agent communication. Our proposed algorithm DecSTER uses a
sequential monte carlo implementation of the probability hypothesis density
filter for posterior inference combined with Thompson sampling for
decentralized multi-agent decision making. We compare different action
selection policies, focusing on scenarios where targets outnumber agents. In
simulation, we demonstrate that DecSTER is robust to unreliable inter-agent
communication and outperforms information-greedy baselines in terms of the
Optimal Sub-Pattern Assignment (OSPA) metric for different numbers of targets
and varying teamsizes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03160">Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving. (arXiv:2401.03160v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zilin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1">Zihao Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chengyuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sikai Chen</a></p>
<p>Despite significant progress in autonomous vehicles (AVs), the development of
driving policies that ensure both the safety of AVs and traffic flow efficiency
has not yet been fully explored. In this paper, we propose an enhanced
human-in-the-loop reinforcement learning method, termed the Human as AI
mentor-based deep reinforcement learning (HAIM-DRL) framework, which
facilitates safe and efficient autonomous driving in mixed traffic platoon.
Drawing inspiration from the human learning process, we first introduce an
innovative learning paradigm that effectively injects human intelligence into
AI, termed Human as AI mentor (HAIM). In this paradigm, the human expert serves
as a mentor to the AI agent. While allowing the agent to sufficiently explore
uncertain environments, the human expert can take control in dangerous
situations and demonstrate correct actions to avoid potential accidents. On the
other hand, the agent could be guided to minimize traffic flow disturbance,
thereby optimizing traffic flow efficiency. In detail, HAIM-DRL leverages data
collected from free exploration and partial human demonstrations as its two
training sources. Remarkably, we circumvent the intricate process of manually
designing reward functions; instead, we directly derive proxy state-action
values from partial human demonstrations to guide the agents' policy learning.
Additionally, we employ a minimal intervention technique to reduce the human
mentor's cognitive load. Comparative results show that HAIM-DRL outperforms
traditional methods in driving safety, sampling efficiency, mitigation of
traffic flow disturbance, and generalizability to unseen traffic scenarios. The
code and demo videos for this paper can be accessed at:
https://zilin-huang.github.io/HAIM-DRL-website/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03397">Predicting the Skies: A Novel Model for Flight-Level Passenger Traffic Forecasting. (arXiv:2401.03397v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ehsani_S/0/1/0/all/0/1">Sina Ehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Sergeeva_E/0/1/0/all/0/1">Elina Sergeeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Murdy_W/0/1/0/all/0/1">Wendy Murdy</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_B/0/1/0/all/0/1">Benjamin Fox</a></p>
<p>Accurate prediction of flight-level passenger traffic is of paramount
importance in airline operations, influencing key decisions from pricing to
route optimization. This study introduces a novel, multimodal deep learning
approach to the challenge of predicting flight-level passenger traffic,
yielding substantial accuracy improvements compared to traditional models.
Leveraging an extensive dataset from American Airlines, our model ingests
historical traffic data, fare closure information, and seasonality attributes
specific to each flight. Our proposed neural network integrates the strengths
of Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN),
exploiting the temporal patterns and spatial relationships within the data to
enhance prediction performance. Crucial to the success of our model is a
comprehensive data processing strategy. We construct 3D tensors to represent
data, apply careful masking strategies to mirror real-world dynamics, and
employ data augmentation techniques to enrich the diversity of our training
set. The efficacy of our approach is borne out in the results: our model
demonstrates an approximate 33\% improvement in Mean Squared Error (MSE)
compared to traditional benchmarks. This study, therefore, highlights the
significant potential of deep learning techniques and meticulous data
processing in advancing the field of flight traffic prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03653">An exploratory study on automatic identification of assumptions in the development of deep learning frameworks. (arXiv:2401.03653v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Peng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zinan Ma</a></p>
<p>Stakeholders constantly make assumptions in the development of deep learning
(DL) frameworks. These assumptions are related to various types of software
artifacts (e.g., requirements, design decisions, and technical debt) and can
turn out to be invalid, leading to system failures. Existing approaches and
tools for assumption management usually depend on manual identification of
assumptions. However, assumptions are scattered in various sources (e.g., code
comments, commits, pull requests, and issues) of DL framework development, and
manually identifying assumptions has high costs (e.g., time and resources). To
overcome the issues of manually identifying assumptions in DL framework
development, we constructed a new and largest dataset (i.e., AssuEval) of
assumptions collected from the TensorFlow and Keras repositories on GitHub;
explored the performance of seven traditional machine learning models (e.g.,
Support Vector Machine, Classification and Regression Trees), a popular DL
model (i.e., ALBERT), and a large language model (i.e., ChatGPT) of identifying
assumptions on the AssuEval dataset. The experiment results show that: ALBERT
achieves the best performance (f1-score: 0.9584) of identifying assumptions on
the AssuEval dataset, which is much better than the other models (the 2nd best
f1-score is 0.6211, achieved by ChatGPT). Though ChatGPT is the most popular
large language model, we do not recommend using it to identify assumptions in
DL framework development because of its low performance on the task.
Fine-tuning ChatGPT specifically for assumption identification could improve
the performance. This study provides researchers with the largest dataset of
assumptions for further research (e.g., assumption classification, evaluation,
and reasoning) and helps practitioners better understand assumptions and how to
manage them in their projects.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03756">Adaptive Experimental Design for Policy Learning. (arXiv:2401.03756v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1">Masahiro Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Okumura_K/0/1/0/all/0/1">Kyohei Okumura</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishihara_T/0/1/0/all/0/1">Takuya Ishihara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitagawa_T/0/1/0/all/0/1">Toru Kitagawa</a></p>
<p>Evidence-based targeting has been a topic of growing interest among the
practitioners of policy and business. Formulating decision-maker's policy
learning as a fixed-budget best arm identification (BAI) problem with
contextual information, we study an optimal adaptive experimental design for
policy learning with multiple treatment arms. In the sampling stage, the
planner assigns treatment arms adaptively over sequentially arriving
experimental units upon observing their contextual information (covariates).
After the experiment, the planner recommends an individualized assignment rule
to the population. Setting the worst-case expected regret as the performance
criterion of adaptive sampling and recommended policies, we derive its
asymptotic lower bounds, and propose a strategy, Adaptive Sampling-Policy
Learning strategy (PLAS), whose leading factor of the regret upper bound aligns
with the lower bound as the size of experimental units increases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03922">Structure-focused Neurodegeneration Convolutional Neural Network for Modeling and Classification of Alzheimer&#x27;s Disease. (arXiv:2401.03922v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Odimayo_S/0/1/0/all/0/1">Simisola Odimayo</a>, <a href="http://arxiv.org/find/eess/1/au:+Olisah_C/0/1/0/all/0/1">Chollette C. Olisah</a>, <a href="http://arxiv.org/find/eess/1/au:+Mohammed_K/0/1/0/all/0/1">Khadija Mohammed</a></p>
<p>Alzheimer's disease (AD), the predominant form of dementia, poses a growing
global challenge and underscores the urgency of accurate and early diagnosis.
The clinical technique radiologists adopt for distinguishing between mild
cognitive impairment (MCI) and AD using Machine Resonance Imaging (MRI)
encounter hurdles because they are not consistent and reliable. Machine
learning has been shown to offer promise for early AD diagnosis. However,
existing models focused on focal fine-grain features without considerations to
focal structural features that give off information on neurodegeneration of the
brain cerebral cortex. Therefore, this paper proposes a machine learning (ML)
framework that integrates Gamma correction, an image enhancement technique, and
includes a structure-focused neurodegeneration convolutional neural network
(CNN) architecture called SNeurodCNN for discriminating between AD and MCI. The
ML framework leverages the mid-sagittal and para-sagittal brain image
viewpoints of the structure-focused Alzheimer's Disease Neuroimaging Initiative
(ADNI) dataset. Through experiments, our proposed machine learning framework
shows exceptional performance. The parasagittal viewpoint set achieves 97.8%
accuracy, with 97.0% specificity and 98.5% sensitivity. The midsagittal
viewpoint is shown to present deeper insights into the structural brain changes
given the increase in accuracy, specificity, and sensitivity, which are 98.1%
97.2%, and 99.0%, respectively. Using GradCAM technique, we show that our
proposed model is capable of capturing the structural dynamics of MCI and AD
which exist about the frontal lobe, occipital lobe, cerebellum, and parietal
lobe. Therefore, our model itself as a potential brain structural change
Digi-Biomarker for early diagnosis of AD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04130">Plug-and-Play Transformer Modules for Test-Time Adaptation. (arXiv:2401.04130v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xiangyu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Sk Miraj Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1">Srikanth V. Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Guler_B/0/1/0/all/0/1">Basak Guler</a>, <a href="http://arxiv.org/find/cs/1/au:+Swami_A/0/1/0/all/0/1">Ananthram Swami</a>, <a href="http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1">Samet Oymak</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1">Amit K. Roy-Chowdhury</a></p>
<p>Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual
Prompt Tuning (VPT) have found success in enabling adaptation to new domains by
tuning small modules within a transformer model. However, the number of domains
encountered during test time can be very large, and the data is usually
unlabeled. Thus, adaptation to new domains is challenging; it is also
impractical to generate customized tuned modules for each such domain. Toward
addressing these challenges, this work introduces PLUTO: a Plug-and-pLay
modUlar Test-time domain adaptatiOn strategy. We pre-train a large set of
modules, each specialized for different source domains, effectively creating a
``module store''. Given a target domain with few-shot unlabeled data, we
introduce an unsupervised test-time adaptation (TTA) method to (1) select a
sparse subset of relevant modules from this store and (2) create a weighted
combination of selected modules without tuning their weights. This
plug-and-play nature enables us to harness multiple most-relevant source
domains in a single inference call. Comprehensive evaluations demonstrate that
PLUTO uniformly outperforms alternative TTA methods and that selecting $\leq$5
modules suffice to extract most of the benefit. At a high level, our method
equips pre-trained transformers with the capability to dynamically adapt to new
domains, motivating a new paradigm for efficient and scalable domain
adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04336">Deep Efficient Private Neighbor Generation for Subgraph Federated Learning. (arXiv:2401.04336v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Ke Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1">Bolin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yiu_S/0/1/0/all/0/1">Siu Ming Yiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a></p>
<p>Behemoth graphs are often fragmented and separately stored by multiple data
owners as distributed subgraphs in many realistic applications. Without harming
data privacy, it is natural to consider the subgraph federated learning
(subgraph FL) scenario, where each local client holds a subgraph of the entire
global graph, to obtain globally generalized graph mining models. To overcome
the unique challenge of incomplete information propagation on local subgraphs
due to missing cross-subgraph neighbors, previous works resort to the
augmentation of local neighborhoods through the joint FL of missing neighbor
generators and GNNs. Yet their technical designs have profound limitations
regarding the utility, efficiency, and privacy goals of FL. In this work, we
propose FedDEP to comprehensively tackle these challenges in subgraph FL.
FedDEP consists of a series of novel technical designs: (1) Deep neighbor
generation through leveraging the GNN embeddings of potential missing
neighbors; (2) Efficient pseudo-FL for neighbor generation through embedding
prototyping; and (3) Privacy protection through noise-less
edge-local-differential-privacy. We analyze the correctness and efficiency of
FedDEP, and provide theoretical guarantees on its privacy. Empirical results on
four real-world datasets justify the clear benefits of proposed techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04679">RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nikdan_M/0/1/0/all/0/1">Mahdi Nikdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabesh_S/0/1/0/all/0/1">Soroush Tabesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a></p>
<p>We investigate parameter-efficient fine-tuning (PEFT) methods that can
provide good accuracy under limited computational and memory budgets in the
context of large language models (LLMs). We present a new PEFT method called
Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA)
that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components
on top of a set of fixed pretrained weights to efficiently approximate the
performance of a full-fine-tuning (FFT) solution. Across a series of
challenging generative tasks such as grade-school math and SQL query
generation, which require fine-tuning for good performance, we show that RoSA
outperforms both LoRA and pure sparse fine-tuning, at the same parameter
budget. We provide system support for RoSA to complement the training
algorithm, specifically in the form of sparse GPU kernels which enable memory-
and computationally-efficient training. Our code will be made available at
https://github.com/IST-DASLab/RoSA}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.17286">Comparative study of clustering models for multivariate time series from connected medical devices. (arXiv:2312.17286v2 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Courrier_V/0/1/0/all/0/1">Violaine Courrier</a> (MODAL), <a href="http://arxiv.org/find/cs/1/au:+Biernacki_C/0/1/0/all/0/1">Christophe Biernacki</a> (MODAL), <a href="http://arxiv.org/find/cs/1/au:+Preda_C/0/1/0/all/0/1">Cristian Preda</a> (MODAL), <a href="http://arxiv.org/find/cs/1/au:+Vittrant_B/0/1/0/all/0/1">Benjamin Vittrant</a></p>
<p>In healthcare, patient data is often collected as multivariate time series,
providing a comprehensive view of a patient's health status over time. While
this data can be sparse, connected devices may enhance its frequency. The goal
is to create patient profiles from these time series. In the absence of labels,
a predictive model can be used to predict future values while forming a latent
cluster space, evaluated based on predictive performance. We compare two models
on Withing's datasets, M AGMAC LUST which clusters entire time series and
DGM${}^2$ which allows the group affiliation of an individual to change over
time (dynamic clustering).
</p>
</p>
</div>

    </div>
    </body>
    