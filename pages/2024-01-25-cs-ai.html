<!DOCTYPE html>
<html>
<head>
<title>2024-01-25-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.12223">The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review. (arXiv:2401.12223v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pachegowda_C/0/1/0/all/0/1">Chandregowda Pachegowda</a></p>
<p>Artificial intelligence (AI) is an emerging technology that has the potential
to transform many aspects of society, including the economy, healthcare, and
transportation. This article synthesizes recent research literature on the
global impact of AI, exploring its potential benefits and risks. The article
highlights the implications of AI, including its impact on economic, ethical,
social, security &amp; privacy, and job displacement aspects. It discusses the
ethical concerns surrounding AI development, including issues of bias,
security, and privacy violations. To ensure the responsible development and
deployment of AI, collaboration between government, industry, and academia is
essential. The article concludes by emphasizing the importance of public
engagement and education to promote awareness and understanding of AI's impact
on society at large.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12224">LLM4EDA: Emerging Progress in Large Language Models for Electronic Design Automation. (arXiv:2401.12224v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1">Ruizhe Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xingbo Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Kai_S/0/1/0/all/0/1">Shixiong Kai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhentao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Siyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhen_H/0/1/0/all/0/1">Hui-Ling Zhen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jianye Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Mingxuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a></p>
<p>Driven by Moore's Law, the complexity and scale of modern chip design are
increasing rapidly. Electronic Design Automation (EDA) has been widely applied
to address the challenges encountered in the full chip design process. However,
the evolution of very large-scale integrated circuits has made chip design
time-consuming and resource-intensive, requiring substantial prior expert
knowledge. Additionally, intermediate human control activities are crucial for
seeking optimal solutions. In system design stage, circuits are usually
represented with Hardware Description Language (HDL) as a textual format.
Recently, Large Language Models (LLMs) have demonstrated their capability in
context understanding, logic reasoning and answer generation. Since circuit can
be represented with HDL in a textual format, it is reasonable to question
whether LLMs can be leveraged in the EDA field to achieve fully automated chip
design and generate circuits with improved power, performance, and area (PPA).
In this paper, we present a systematic study on the application of LLMs in the
EDA field, categorizing it into the following cases: 1) assistant chatbot, 2)
HDL and script generation, and 3) HDL verification and analysis. Additionally,
we highlight the future research direction, focusing on applying LLMs in logic
synthesis, physical design, multi-modal feature extraction and alignment of
circuits. We collect relevant papers up-to-date in this field via the following
link: https://github.com/Thinklab-SJTU/Awesome-LLM4EDA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12244">Large-scale Reinforcement Learning for Diffusion Models. (arXiv:2401.12244v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzeng_E/0/1/0/all/0/1">Eric Tzeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yilun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Kislyuk_D/0/1/0/all/0/1">Dmitry Kislyuk</a></p>
<p>Text-to-image diffusion models are a class of deep generative models that
have demonstrated an impressive capacity for high-quality image generation.
However, these models are susceptible to implicit biases that arise from
web-scale text-image training pairs and may inaccurately model aspects of
images we care about. This can result in suboptimal samples, model bias, and
images that do not align with human ethics and preferences. In this paper, we
present an effective scalable algorithm to improve diffusion models using
Reinforcement Learning (RL) across a diverse set of reward functions, such as
human preference, compositionality, and fairness over millions of images. We
illustrate how our approach substantially outperforms existing methods for
aligning diffusion models with human preferences. We further illustrate how
this substantially improves pretrained Stable Diffusion (SD) models, generating
samples that are preferred by humans 80.3% of the time over those from the base
SD model while simultaneously improving both the composition and diversity of
generated samples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12247">Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure. (arXiv:2401.12247v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xusen Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1">Ying Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarifis_A/0/1/0/all/0/1">Alex Zarifis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_W/0/1/0/all/0/1">Wankun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_J/0/1/0/all/0/1">Jian Mou</a></p>
<p>Artificial intelligence based chatbots have brought unprecedented business
potential. This study aims to explore consumers trust and response to a
text-based chatbot in ecommerce, involving the moderating effects of task
complexity and chatbot identity disclosure. A survey method with 299 useable
responses was conducted in this research. This study adopted the ordinary least
squares regression to test the hypotheses. First, the consumers perception of
both the empathy and friendliness of the chatbot positively impacts their trust
in it. Second, task complexity negatively moderates the relationship between
friendliness and consumers trust. Third, disclosure of the text based chatbot
negatively moderates the relationship between empathy and consumers trust,
while it positively moderates the relationship between friendliness and
consumers trust. Fourth, consumers trust in the chatbot increases their
reliance on the chatbot and decreases their resistance to the chatbot in future
interactions. Adopting the stimulus organism response framework, this study
provides important insights on consumers perception and response to the
text-based chatbot. The findings of this research also make suggestions that
can increase consumers positive responses to text based chatbots. Extant
studies have investigated the effects of automated bots attributes on consumers
perceptions. However, the boundary conditions of these effects are largely
ignored. This research is one of the first attempts to provide a deep
understanding of consumers responses to a chatbot.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12255">Instructional Fingerprinting of Large Language Models. (arXiv:2401.12255v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiashu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Mingyu Derek Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Koh_P/0/1/0/all/0/1">Pang Wei Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muhao Chen</a></p>
<p>The exorbitant cost of training Large language models (LLMs) from scratch
makes it essential to fingerprint the models to protect intellectual property
via ownership authentication and to ensure downstream users and developers
comply with their license terms (e.g. restricting commercial use). In this
study, we present a pilot study on LLM fingerprinting as a form of very
lightweight instruction tuning. Model publisher specifies a confidential
private key and implants it as an instruction backdoor that causes the LLM to
generate specific text when the key is present. Results on 11 popularly-used
LLMs showed that this approach is lightweight and does not affect the normal
behavior of the model. It also prevents publisher overclaim, maintains
robustness against fingerprint guessing and parameter-efficient training, and
supports multi-stage fingerprinting akin to MIT License. Code is available in
https://cnut1648.github.io/Model-Fingerprint/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12258">Emergent Dominance Hierarchies in Reinforcement Learning Agents. (arXiv:2401.12258v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rachum_R/0/1/0/all/0/1">Ram Rachum</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakar_Y/0/1/0/all/0/1">Yonatan Nakar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomlinson_B/0/1/0/all/0/1">Bill Tomlinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Alon_N/0/1/0/all/0/1">Nitay Alon</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirsky_R/0/1/0/all/0/1">Reuth Mirsky</a></p>
<p>Modern Reinforcement Learning (RL) algorithms are able to outperform humans
in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings
present additional challenges, and successful cooperation in mixed-motive
groups of agents depends on a delicate balancing act between individual and
group objectives. Social conventions and norms, often inspired by human
institutions, are used as tools for striking this balance.
</p>
<p>In this paper, we examine a fundamental, well-studied social convention that
underlies cooperation in both animal and human societies: Dominance
hierarchies.
</p>
<p>We adapt the ethological theory of dominance hierarchies to artificial
agents, borrowing the established terminology and definitions with as few
amendments as possible. We demonstrate that populations of RL agents, operating
without explicit programming or intrinsic rewards, can invent, learn, enforce,
and transmit a dominance hierarchy to new populations. The dominance
hierarchies that emerge have a similar structure to those studied in chickens,
mice, fish, and other species.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12259">Agreement Technologies for Coordination in Smart Cities. (arXiv:2401.12259v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Billhardt_H/0/1/0/all/0/1">Holger Billhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_A/0/1/0/all/0/1">Alberto Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lujak_M/0/1/0/all/0/1">Marin Lujak</a>, <a href="http://arxiv.org/find/cs/1/au:+Ossowski_S/0/1/0/all/0/1">Sascha Ossowski</a></p>
<p>Many challenges in today's society can be tackled by distributed open
systems. This is particularly true for domains that are commonly perceived
under the umbrella of smart cities, such as intelligent transportation, smart
energy grids, or participative governance. When designing computer applications
for these domains, it is necessary to account for the fact that the elements of
such systems, often called software agents, are usually made by different
designers and act on behalf of particular stakeholders. Furthermore, it is
unknown at design time when such agents will enter or leave the system, and
what interests new agents will represent. To instil coordination in such
systems is particularly demanding, as usually only part of them can be directly
controlled at runtime. Agreement technologies refer to a sandbox of tools and
mechanisms for the development of such open multiagent systems, which are based
on the notion of agreement. In this paper, we argue that agreement technologies
are a suitable means for achieving coordination in smart city domains, and back
our claim through examples of several real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12261">Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks. (arXiv:2401.12261v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zerui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a></p>
<p>As AI models rapidly evolve, they are frequently released to open
repositories, such as HuggingFace. It is essential to perform quality assurance
validation on these models before integrating them into the production
development lifecycle. In addition to evaluating efficiency in terms of
balanced accuracy and computing costs, adversarial attacks are potential
threats to the robustness and explainability of AI models. Meanwhile, XAI
applies algorithms that approximate inputs to outputs post-hoc to identify the
contributing features. Adversarial perturbations may also degrade the utility
of XAI explanations that require further investigation. In this paper, we
present an integrated process designed for downstream evaluation tasks,
including validating AI model accuracy, evaluating robustness with benchmark
perturbations, comparing explanation utility, and assessing overhead. We
demonstrate an evaluation scenario involving six computer vision models, which
include CNN-based, Transformer-based, and hybrid architectures, three types of
perturbations, and five XAI methods, resulting in ninety unique combinations.
The process reveals the explanation utility among the XAI methods in terms of
the identified key areas responding to the adversarial perturbation. The
process produces aggregated results that illustrate multiple attributes of each
AI model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12273">The Ethics of Interaction: Mitigating Security Threats in LLMs. (arXiv:2401.12273v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ashutosh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sagarika Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Murty_S/0/1/0/all/0/1">Shiv Vignesh Murty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragupathy_S/0/1/0/all/0/1">Swathy Ragupathy</a></p>
<p>This paper comprehensively explores the ethical challenges arising from
security threats to Language Learning Models (LLMs). These intricate digital
repositories are increasingly integrated into our daily lives, making them
prime targets for attacks that can compromise their training data and the
confidentiality of their data sources. The paper delves into the nuanced
ethical repercussions of such security threats on society and individual
privacy. We scrutinize five major threats: prompt injection, jailbreaking,
Personal Identifiable Information (PII) exposure, sexually explicit content,
and hate based content, going beyond mere identification to assess their
critical ethical consequences and the urgency they create for robust defensive
strategies. The escalating reliance on LLMs underscores the crucial need for
ensuring these systems operate within the bounds of ethical norms, particularly
as their misuse can lead to significant societal and individual harm. We
propose conceptualizing and developing an evaluative tool tailored for LLMs,
which would serve a dual purpose, guiding developers and designers in
preemptive fortification of backend systems and scrutinizing the ethical
dimensions of LLM chatbot responses during the testing phase. By comparing LLM
responses with those expected from humans in a moral context, we aim to discern
the degree to which AI behaviors align with the ethical values held by a
broader society. Ultimately, this paper not only underscores the ethical
troubles presented by LLMs, it also highlights a path toward cultivating trust
in these systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12275">Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation. (arXiv:2401.12275v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_C/0/1/0/all/0/1">Chuanbo Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hengbo Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinkyoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Dax_V/0/1/0/all/0/1">Victoria Dax</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1">Mykel J. Kochenderfer</a></p>
<p>Social robot navigation can be helpful in various contexts of daily life but
requires safe human-robot interactions and efficient trajectory planning. While
modeling pairwise relations has been widely studied in multi-agent interacting
systems, the ability to capture larger-scale group-wise activities is limited.
In this paper, we propose a systematic relational reasoning approach with
explicit inference of the underlying dynamically evolving relational
structures, and we demonstrate its effectiveness for multi-agent trajectory
prediction and social robot navigation. In addition to the edges between pairs
of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect
multiple nodes to enable group-wise reasoning in an unsupervised manner. Our
approach infers dynamically evolving relation graphs and hypergraphs to capture
the evolution of relations, which the trajectory predictor employs to generate
future states. Meanwhile, we propose to regularize the sharpness and sparsity
of the learned relations and the smoothness of the relation evolution, which
proves to enhance training stability and model performance. The proposed
approach is validated on synthetic crowd simulations and real-world benchmark
datasets. Experiments demonstrate that the approach infers reasonable relations
and achieves state-of-the-art prediction performance. In addition, we present a
deep reinforcement learning (DRL) framework for social robot navigation, which
incorporates relational reasoning and trajectory prediction systematically. In
a group-based crowd simulation, our method outperforms the strongest baseline
by a significant margin in terms of safety, efficiency, and social compliance
in dense, interactive scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12292">GRATH: Gradual Self-Truthifying for Large Language Models. (arXiv:2401.12292v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weixin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a></p>
<p>Truthfulness is paramount for large language models (LLMs) as they are
increasingly deployed in real-world applications. However, existing LLMs still
struggle with generating truthful answers and content, as evidenced by their
modest performance on benchmarks like TruthfulQA. To address this issue, we
propose GRAdual self-truTHifying (GRATH), a novel post-processing method to
enhance truthfulness of LLMs. GRATH utilizes out-of-domain question prompts to
generate corresponding answers and adaptively optimizes the model via direct
preference optimization (DPO). Note that during this process, GRATH learns
truthfulness in a self-supervised manner without requiring annotated answers.
In particular, GRATH first generates pairwise truthfulness training data by
prompting the LLM itself, with each pair containing a question and its correct
and incorrect answers. The model is then fine-tuned using DPO to learn from the
difference between answer pairs. Subsequently, GRATH iteratively refines the
truthfulness data and optimizes the model, leading to a gradual improvement in
model truthfulness. Empirically, we evaluate GRATH using different 7B-LLMs and
compare with LLMs with similar or even larger sizes on benchmark datasets. Our
results show that GRATH effectively improves LLMs' truthfulness without
compromising other core capabilities. Notably, GRATH achieves state-of-the-art
performance on TruthfulQA, with MC1 accuracy as 54.71% and MC2 accuracy as
69.10%, which even surpass those on larger-scale models, such as
Llama2-Chat-70B, by 23.62% and 24.18%, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12322">Smart Recommendations for Renting Bikes in Bike Sharing Systems. (arXiv:2401.12322v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Billhardt_H/0/1/0/all/0/1">Holger Billhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_A/0/1/0/all/0/1">Alberto Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ossowski_S/0/1/0/all/0/1">Sascha Ossowski</a></p>
<p>Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems
-- have become increasingly popular in big cities in recent years. On the one
hand, they provide a cheaper and environmentally friendlier means of
transportation than private cars, and on the other hand, they satisfy the
individual mobility demands of citizens better than traditional public
transport systems. One of their advantages in this regard is their
availability, e.g., the possibility of taking (or leaving) a vehicle almost
anywhere in a city. This availability obviously depends on different strategic
and operational management decisions and policies, such as the dimension of the
fleet or the (re)distribution of vehicles. Agglutination problems -- where, due
to usage patterns, available vehicles are concentrated in certain areas,
whereas no vehicles are available in others -- are quite common in such
systems, and need to be dealt with. Research has been dedicated to this
problem, specifying different techniques to reduce imbalanced situations. In
this paper, we present and compare strategies for recommending stations to
users who wish to rent or return bikes in station-based bike-sharing systems.
Our first contribution is a novel recommendation strategy based on queuing
theory that recommends stations based on their utility to the user in terms of
lower distance and higher probability of finding a bike or slot. Then, we go
one step further, defining a strategy that recommends stations by combining the
utility of a particular user with the utility of the global system, measured in
terms of the improvement in the distribution of bikes and slots with respect to
the expected future demand, with the aim of implicitly avoiding or alleviating
balancing problems. We present several experiments to evaluate our proposal
with real data from the bike sharing system BiciMAD in Madrid.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12324">Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis. (arXiv:2401.12324v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Billhardt_H/0/1/0/all/0/1">Holger Billhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jos&#xe9;-Antonio Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_A/0/1/0/all/0/1">Alberto Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_M/0/1/0/all/0/1">Mar Moreno</a>, <a href="http://arxiv.org/find/cs/1/au:+Ossowski_S/0/1/0/all/0/1">Sascha Ossowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_J/0/1/0/all/0/1">Jos&#xe9; A. Rodr&#xed;guez</a></p>
<p>In recent years many novel applications have appeared that promote the
provision of services and activities in a collaborative manner. The key idea
behind such systems is to take advantage of idle or underused capacities of
existing resources, in order to provide improved services that assist people in
their daily tasks, with additional functionality, enhanced efficiency, and/or
reduced cost. Particularly in the domain of urban transportation, many
researchers have put forward novel ideas, which are then implemented and
evaluated through prototypes that usually draw upon AI methods and tools.
However, such proposals also bring up multiple non-technical issues that need
to be identified and addressed adequately if such systems are ever meant to be
applied to the real world. While, in practice, legal and ethical aspects
related to such AI-based systems are seldomly considered in the beginning of
the research and development process, we argue that they not only restrict
design decisions, but can also help guiding them. In this manuscript, we set
out from a prototype of a taxi coordination service that mediates between
individual (and autonomous) taxis and potential customers. After representing
key aspects of its operation in a semi-structured manner, we analyse its
viability from the viewpoint of current legal restrictions and constraints, so
as to identify additional non-functional requirements as well as options to
address them. Then, we go one step ahead, and actually modify the existing
prototype to incorporate the previously identified recommendations. Performing
experiments with this improved system helps us identify the most adequate
option among several legally admissible alternatives.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12326">Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. (arXiv:2401.12326v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiong_F/0/1/0/all/0/1">Feng Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Markchom_T/0/1/0/all/0/1">Thanet Markchom</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Ziwei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Subin Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Ojha_V/0/1/0/all/0/1">Varun Ojha</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Huizhi Liang</a></p>
<p>SemEval-2024 Task 8 introduces the challenge of identifying machine-generated
texts from diverse Large Language Models (LLMs) in various languages and
domains. The task comprises three subtasks: binary classification in
monolingual and multilingual (Subtask A), multi-class classification (Subtask
B), and mixed text detection (Subtask C). This paper focuses on Subtask A &amp; B.
Each subtask is supported by three datasets for training, development, and
testing. To tackle this task, two methods: 1) using traditional machine
learning (ML) with natural language preprocessing (NLP) for feature extraction,
and 2) fine-tuning LLMs for text classification. The results show that
transformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in
effectiveness, with majority voting being particularly effective in
multilingual contexts for identifying machine-generated texts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12329">Towards a prioritised use of transportation infrastructures: the case of vehicle-specific dynamic access restrictions to city centres. (arXiv:2401.12329v1 [physics.soc-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Billhardt_H/0/1/0/all/0/1">Holger Billhardt</a>, <a href="http://arxiv.org/find/physics/1/au:+Fernandez_A/0/1/0/all/0/1">Alberto Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/physics/1/au:+Marti_P/0/1/0/all/0/1">Pasqual Mart&#xed;</a>, <a href="http://arxiv.org/find/physics/1/au:+Tejedor_J/0/1/0/all/0/1">Javier Prieto Tejedor</a>, <a href="http://arxiv.org/find/physics/1/au:+Ossowski_S/0/1/0/all/0/1">Sascha Ossowski</a></p>
<p>One of the main problems that local authorities of large cities have to face
is the regulation of urban mobility. They need to provide the means to allow
for the efficient movement of people and distribution of goods. However, the
provisioning of transportation services needs to take into account general
global objectives, like reducing emissions and having more healthy living
environments, which may not always be aligned with individual interests. Urban
mobility is usually provided through a transport infrastructure that includes
all the elements that support mobility. On many occasions, the capacity of the
elements of this infrastructure is lower than the actual demand and thus
different transportation activities compete for their use. In this paper, we
argue that scarce transport infrastructure elements should be assigned
dynamically and in a prioritised manner to transport activities that have a
higher utility from the point of view of society; for example, activities that
produce less pollution and provide more value to society. In this paper, we
define a general model for prioritizing the use of a particular type of
transportation infrastructure element called time-unlimited elements, whose
usage time is unknown a priori, and illustrate its dynamics through two use
cases: vehicle-specific dynamic access restriction in city centres (i) based on
the usage levels of available parking spaces and (ii) to assure sustained
admissible air quality levels in the city centre. We carry out several
experiments using the SUMO traffic simulation tool to evaluate our proposal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12340">Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation. (arXiv:2401.12340v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sami_S/0/1/0/all/0/1">Shoaib Meraj Sami</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md Mahedi Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_R/0/1/0/all/0/1">Raghuveer Rao</a></p>
<p>Annotating automatic target recognition (ATR) is a highly challenging task,
primarily due to the unavailability of labeled data in the target domain.
Hence, it is essential to construct an optimal target domain classifier by
utilizing the labeled information of the source domain images. The transductive
transfer learning (TTL) method that incorporates a CycleGAN-based unpaired
domain translation network has been previously proposed in the literature for
effective ATR annotation. Although this method demonstrates great potential for
ATR, it severely suffers from lower annotation performance, higher Fr\'echet
Inception Distance (FID) score, and the presence of visual artifacts in the
synthetic images. To address these issues, we propose a hybrid contrastive
learning base unpaired domain translation (H-CUT) network that achieves a
significantly lower FID score. It incorporates both attention and entropy to
emphasize the domain-specific region, a noisy feature mixup module to generate
high variational synthetic negative patches, and a modulated noise contrastive
estimation (MoNCE) loss to reweight all negative patches using optimal
transport for better performance. Our proposed contrastive learning and
cycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks
and two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and
identity losses. In C3TTL, two H-CUT networks have been employed through a
bijection mapping to feed the reconstructed source domain images into a
pretrained classifier to guide the optimal target domain classifier. Extensive
experimental analysis conducted on three ATR datasets demonstrates that the
proposed C3TTL method is effective in annotating civilian and military
vehicles, as well as ship targets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12344">OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection. (arXiv:2401.12344v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jannat_F/0/1/0/all/0/1">Fatema-E Jannat</a>, <a href="http://arxiv.org/find/cs/1/au:+Gholami_S/0/1/0/all/0/1">Sina Gholami</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1">Minhaj Nur Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabkhi_H/0/1/0/all/0/1">Hamed Tabkhi</a></p>
<p>Despite the revolutionary impact of AI and the development of locally trained
algorithms, achieving widespread generalized learning from multi-modal data in
medical AI remains a significant challenge. This gap hinders the practical
deployment of scalable medical AI solutions. Addressing this challenge, our
research contributes a self-supervised robust machine learning framework,
OCT-SelfNet, for detecting eye diseases using optical coherence tomography
(OCT) images. In this work, various data sets from various institutions are
combined enabling a more comprehensive range of representation. Our method
addresses the issue using a two-phase training approach that combines
self-supervised pretraining and supervised fine-tuning with a mask autoencoder
based on the SwinV2 backbone by providing a solution for real-world clinical
deployment. Extensive experiments on three datasets with different encoder
backbones, low data settings, unseen data settings, and the effect of
augmentation show that our method outperforms the baseline model, Resnet-50 by
consistently attaining AUC-ROC performance surpassing 77% across all tests,
whereas the baseline model exceeds 54%. Moreover, in terms of the AUC-PR
metric, our proposed method exceeded 42%, showcasing a substantial increase of
at least 10% in performance compared to the baseline, which exceeded only 33%.
This contributes to our understanding of our approach's potential and
emphasizes its usefulness in clinical settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12375">Development of an NLP-driven computer-based test guide for visually impaired students. (arXiv:2401.12375v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nemieboka_T/0/1/0/all/0/1">Tubo Faustinah Nemieboka</a>, <a href="http://arxiv.org/find/cs/1/au:+Onyenwe_I/0/1/0/all/0/1">Ikechukwu E. Onyenwe</a>, <a href="http://arxiv.org/find/cs/1/au:+Asogwa_D/0/1/0/all/0/1">Doris C. Asogwa</a></p>
<p>In recent years, advancements in Natural Language Processing (NLP) techniques
have revolutionized the field of accessibility and exclusivity of testing,
particularly for visually impaired students (VIS). CBT has shown in years back
its relevance in terms of administering exams electronically, making the test
process easier, providing quicker and more accurate results, and offering
greater flexibility and accessibility for candidates. Yet, its relevance was
not felt by the visually impaired students as they cannot access printed
documents. Hence, in this paper, we present an NLP-driven Computer-Based Test
guide for visually impaired students. It employs a speech technology
pre-trained methods to provide real-time assistance and support to visually
impaired students. The system utilizes NLP technologies to convert the
text-based questions and the associated options in a machine-readable format.
Subsequently, the speech technology pre-trained model processes the converted
text enabling the VIS to comprehend and analyze the content. Furthermore, we
validated that this pre-trained model is not perverse by testing for accuracy
using sample audio datasets labels (A, B, C, D, E, F, G) to compare with the
voice recordings obtained from 20 VIS which is been predicted by the system to
attain values for precision, recall, and F1-scores. These metrics are used to
assess the performance of the pre-trained model and have indicated that it is
proficient enough to give its better performance to the evaluated system. The
methodology adopted for this system is Object Oriented Analysis and Design
Methodology (OOADM) where Objects are discussed and built by modeling
real-world instances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12379">Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis. (arXiv:2401.12379v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roberson_R/0/1/0/all/0/1">Richard Roberson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaki_G/0/1/0/all/0/1">Gowtham Kaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1">Ashutosh Trivedi</a></p>
<p>This study investigates various approaches to using Large Language Models
(LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights
derived. Employing the popular Text-to-SQL dataset, spider, the goal was to
input a natural language question along with the database schema and output the
correct SQL SELECT query. The initial approach was to fine-tune a local and
open-source model to generate the SELECT query. After QLoRa fine-tuning
WizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy
for generated queries rose to a high of 61%. With the second approach, using
the fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error
correction), the execution accuracy reached a high of 82.1%. Of all the
incorrect queries, most can be categorized into a seven different categories of
what went wrong: selecting the wrong columns or wrong order of columns,
grouping by the wrong column, predicting the wrong values in conditionals,
using different aggregates than the ground truth, extra or too few JOIN
clauses, inconsistencies in the Spider dataset, and lastly completely incorrect
query structure. Most if not all of the queries fall into these categories and
it is insightful to understanding where the faults still lie with LLM program
synthesis and where they can be improved.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12392">Evaluating Roadside Perception for Autonomous Vehicles: Insights from Field Testing. (arXiv:2401.12392v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rusheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Depu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Shengyin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tinghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karir_T/0/1/0/all/0/1">Tai Karir</a>, <a href="http://arxiv.org/find/cs/1/au:+Maile_M/0/1/0/all/0/1">Michael Maile</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Henry X. Liu</a></p>
<p>Roadside perception systems are increasingly crucial in enhancing traffic
safety and facilitating cooperative driving for autonomous vehicles. Despite
rapid technological advancements, a major challenge persists for this newly
arising field: the absence of standardized evaluation methods and benchmarks
for these systems. This limitation hampers the ability to effectively assess
and compare the performance of different systems, thus constraining progress in
this vital field. This paper introduces a comprehensive evaluation methodology
specifically designed to assess the performance of roadside perception systems.
Our methodology encompasses measurement techniques, metric selection, and
experimental trial design, all grounded in real-world field testing to ensure
the practical applicability of our approach.
</p>
<p>We applied our methodology in Mcity\footnote{\url{https://mcity.umich.edu/}},
a controlled testing environment, to evaluate various off-the-shelf perception
systems. This approach allowed for an in-depth comparative analysis of their
performance in realistic scenarios, offering key insights into their respective
strengths and limitations. The findings of this study are poised to inform the
development of industry-standard benchmarks and evaluation methods, thereby
enhancing the effectiveness of roadside perception system development and
deployment for autonomous vehicles. We anticipate that this paper will
stimulate essential discourse on standardizing evaluation methods for roadside
perception systems, thus pushing the frontiers of this technology. Furthermore,
our results offer both academia and industry a comprehensive understanding of
the capabilities of contemporary infrastructure-based perception systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12393">A Learning-based Declarative Privacy-Preserving Framework for Federated Data Management. (arXiv:2401.12393v1 [cs.DB])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guan_H/0/1/0/all/0/1">Hong Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gautier_S/0/1/0/all/0/1">Summer Gautier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1">Deepti Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambrish_R/0/1/0/all/0/1">Rajan Hari Ambrish</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yancheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakamsani_H/0/1/0/all/0/1">Harsha Lakamsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Giriyan_D/0/1/0/all/0/1">Dhanush Giriyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Maslanka_S/0/1/0/all/0/1">Saajan Maslanka</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yingzhen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Jia Zou</a></p>
<p>It is challenging to balance the privacy and accuracy for federated query
processing over multiple private data silos. In this work, we will demonstrate
an end-to-end workflow for automating an emerging privacy-preserving technique
that uses a deep learning model trained using the Differentially-Private
Stochastic Gradient Descent (DP-SGD) algorithm to replace portions of actual
data to answer a query. Our proposed novel declarative privacy-preserving
workflow allows users to specify "what private information to protect" rather
than "how to protect". Under the hood, the system automatically chooses
query-model transformation plans as well as hyper-parameters. At the same time,
the proposed workflow also allows human experts to review and tune the selected
privacy-preserving mechanism for audit/compliance, and optimization purposes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12406">Enhancing In-context Learning via Linear Probe Calibration. (arXiv:2401.12406v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abbas_M/0/1/0/all/0/1">Momin Abbas</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1">Parikshit Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Baracaldo_N/0/1/0/all/0/1">Nathalie Baracaldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Samulowitz_H/0/1/0/all/0/1">Horst Samulowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Salonidis_T/0/1/0/all/0/1">Theodoros Salonidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianyi Chen</a></p>
<p>In-context learning (ICL) is a new paradigm for natural language processing
that utilizes Generative Pre-trained Transformer (GPT)-like models. This
approach uses prompts that include in-context demonstrations to generate the
corresponding output for a new query input. However, applying ICL in real cases
does not scale with the number of samples, and lacks robustness to different
prompt templates and demonstration permutations. In this paper, we first show
that GPT-like models using ICL result in unreliable predictions based on a new
metric based on Shannon entropy. Then, to solve this problem, we propose a new
technique called the Linear Probe Calibration (LinC), a method that calibrates
the model's output probabilities, resulting in reliable predictions and
improved performance, while requiring only minimal additional samples (as few
as five labeled data samples). LinC significantly enhances the ICL test
performance of GPT models on various benchmark datasets, with an average
improvement of up to 21%, and up to a 50% improvement in some cases, and
significantly boosts the performance of PEFT methods, especially in the low
resource regime. Moreover, LinC achieves lower expected calibration error, and
is highly robust to varying label proportions, prompt templates, and
demonstration permutations. Our code is available at
\url{https://github.com/mominabbass/LinC}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12421">AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space. (arXiv:2401.12421v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mottaghi_A/0/1/0/all/0/1">Ali Mottaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamal_M/0/1/0/all/0/1">Mohammad Abdullah Jamal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1">Serena Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohareri_O/0/1/0/all/0/1">Omid Mohareri</a></p>
<p>Semi-supervised domain adaptation (SSDA) presents a critical hurdle in
computer vision, especially given the frequent scarcity of labeled data in
real-world settings. This scarcity often causes foundation models, trained on
extensive datasets, to underperform when applied to new domains. AdaEmbed, our
newly proposed methodology for SSDA, offers a promising solution to these
challenges. Leveraging the potential of unlabeled data, AdaEmbed facilitates
the transfer of knowledge from a labeled source domain to an unlabeled target
domain by learning a shared embedding space. By generating accurate and uniform
pseudo-labels based on the established embedding space, the model overcomes the
limitations of conventional SSDA, thus enhancing performance significantly. Our
method's effectiveness is validated through extensive experiments on benchmark
datasets such as DomainNet, Office-Home, and VisDA-C, where AdaEmbed
consistently outperforms all the baselines, setting a new state of the art for
SSDA. With its straightforward implementation and high data efficiency,
AdaEmbed stands out as a robust and pragmatic solution for real-world
scenarios, where labeled data is scarce. To foster further research and
application in this area, we are sharing the codebase of our unified framework
for semi-supervised domain adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12435">Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network. (arXiv:2401.12435v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiayi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongfeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jin Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1">Qingrui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hanbo Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zu_L/0/1/0/all/0/1">Lingyun Zu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaobo Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Hongbin Han</a></p>
<p>The brain extracellular space (ECS), an irregular, extremely tortuous
nanoscale space located between cells or between cells and blood vessels, is
crucial for nerve cell survival. It plays a pivotal role in high-level brain
functions such as memory, emotion, and sensation. However, the specific form of
molecular transport within the ECS remain elusive. To address this challenge,
this paper proposes a novel approach to quantitatively analyze the molecular
transport within the ECS by solving an inverse problem derived from the
advection-diffusion equation (ADE) using a physics-informed neural network
(PINN). PINN provides a streamlined solution to the ADE without the need for
intricate mathematical formulations or grid settings. Additionally, the
optimization of PINN facilitates the automatic computation of the diffusion
coefficient governing long-term molecule transport and the velocity of
molecules driven by advection. Consequently, the proposed method allows for the
quantitative analysis and identification of the specific pattern of molecular
transport within the ECS through the calculation of the Peclet number.
Experimental validation on two datasets of magnetic resonance images (MRIs)
captured at different time points showcases the effectiveness of the proposed
method. Notably, our simulations reveal identical molecular transport patterns
between datasets representing rats with tracer injected into the same brain
region. These findings highlight the potential of PINN as a promising tool for
comprehensively exploring molecular transport within the ECS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12451">Methods and strategies for improving the novel view synthesis quality of neural radiation field. (arXiv:2401.12451v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1">Shun Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1">Ming Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xing Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yanna Lv</a></p>
<p>Neural Radiation Field (NeRF) technology can learn a 3D implicit model of a
scene from 2D images and synthesize realistic novel view images. This
technology has received widespread attention from the industry and has good
application prospects. In response to the problem that the rendering quality of
NeRF images needs to be improved, many researchers have proposed various
methods to improve the rendering quality in the past three years. The latest
relevant papers are classified and reviewed, the technical principles behind
quality improvement are analyzed, and the future evolution direction of quality
improvement methods is discussed. This study can help researchers quickly
understand the current state and evolutionary context of technology in this
field, which is helpful in inspiring the development of more efficient
algorithms and promoting the application of NeRF technology in related fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12455">Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management. (arXiv:2401.12455v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saifullah_M/0/1/0/all/0/1">M. Saifullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Papakonstantinou_K/0/1/0/all/0/1">K.G. Papakonstantinou</a>, <a href="http://arxiv.org/find/cs/1/au:+Andriotis_C/0/1/0/all/0/1">C.P. Andriotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoffels_S/0/1/0/all/0/1">S.M. Stoffels</a></p>
<p>We present a multi-agent Deep Reinforcement Learning (DRL) framework for
managing large transportation infrastructure systems over their life-cycle.
Life-cycle management of such engineering systems is a computationally
intensive task, requiring appropriate sequential inspection and maintenance
decisions able to reduce long-term risks and costs, while dealing with
different uncertainties and constraints that lie in high-dimensional spaces. To
date, static age- or condition-based maintenance methods and risk-based or
periodic inspection plans have mostly addressed this class of optimization
problems. However, optimality, scalability, and uncertainty limitations are
often manifested under such approaches. The optimization problem in this work
is cast in the framework of constrained Partially Observable Markov Decision
Processes (POMDPs), which provides a comprehensive mathematical basis for
stochastic sequential decision settings with observation uncertainties, risk
considerations, and limited resources. To address significantly large state and
action spaces, a Deep Decentralized Multi-agent Actor-Critic (DDMAC) DRL method
with Centralized Training and Decentralized Execution (CTDE), termed as
DDMAC-CTDE is developed. The performance strengths of the DDMAC-CTDE method are
demonstrated in a generally representative and realistic example application of
an existing transportation network in Virginia, USA. The network includes
several bridge and pavement components with nonstationary degradation,
agency-imposed constraints, and traffic delay and risk considerations. Compared
to traditional management policies for transportation networks, the proposed
DDMAC-CTDE method vastly outperforms its counterparts. Overall, the proposed
algorithmic framework provides near optimal solutions for transportation
infrastructure management under real-world constraints and complexities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12456">Exploration and Improvement of Nerf-based 3D Scene Editing Techniques. (arXiv:2401.12456v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1">Shun Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1">Ming Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xing Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanan Zhang</a></p>
<p>NeRF's high-quality scene synthesis capability was quickly accepted by
scholars in the years after it was proposed, and significant progress has been
made in 3D scene representation and synthesis. However, the high computational
cost limits intuitive and efficient editing of scenes, making NeRF's
development in the scene editing field facing many challenges. This paper
reviews the preliminary explorations of scholars on NeRF in the scene or object
editing field in recent years, mainly changing the shape and texture of scenes
or objects in new synthesized scenes; through the combination of residual
models such as GaN and Transformer with NeRF, the generalization ability of
NeRF scene editing has been further expanded, including realizing real-time new
perspective editing feedback, multimodal editing of text synthesized 3D scenes,
4D synthesis performance, and in-depth exploration in light and shadow editing,
initially achieving optimization of indirect touch editing and detail
representation in complex scenes. Currently, most NeRF editing methods focus on
the touch points and materials of indirect points, but when dealing with more
complex or larger 3D scenes, it is difficult to balance accuracy, breadth,
efficiency, and quality. Overcoming these challenges may become the direction
of future NeRF 3D scene editing technology.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12459">Towards Socially and Morally Aware RL agent: Reward Design With LLM. (arXiv:2401.12459v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoyue Wang</a></p>
<p>When we design and deploy an Reinforcement Learning (RL) agent, reward
functions motivates agents to achieve an objective. An incorrect or incomplete
specification of the objective can result in behavior that does not align with
human values - failing to adhere with social and moral norms that are ambiguous
and context dependent, and cause undesired outcomes such as negative side
effects and exploration that is unsafe. Previous work have manually defined
reward functions to avoid negative side effects, use human oversight for safe
exploration, or use foundation models as planning tools. This work studies the
ability of leveraging Large Language Models (LLM)' understanding of morality
and social norms on safe exploration augmented RL methods. This work evaluates
language model's result against human feedbacks and demonstrates language
model's capability as direct reward signals.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12467">An open dataset for the evolution of oracle bone characters: EVOBC. (arXiv:2401.12467v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guan_H/0/1/0/all/0/1">Haisu Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1">Jinpeng Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaile Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1">Zhebin Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a></p>
<p>The earliest extant Chinese characters originate from oracle bone
inscriptions, which are closely related to other East Asian languages. These
inscriptions hold immense value for anthropology and archaeology. However,
deciphering oracle bone script remains a formidable challenge, with only
approximately 1,600 of the over 4,500 extant characters elucidated to date.
Further scholarly investigation is required to comprehensively understand this
ancient writing system. Artificial Intelligence technology is a promising
avenue for deciphering oracle bone characters, particularly concerning their
evolution. However, one of the challenges is the lack of datasets mapping the
evolution of these characters over time. In this study, we systematically
collected ancient characters from authoritative texts and websites spanning six
historical stages: Oracle Bone Characters - OBC (15th century B.C.), Bronze
Inscriptions - BI (13th to 221 B.C.), Seal Script - SS (11th to 8th centuries
B.C.), Spring and Autumn period Characters - SAC (770 to 476 B.C.), Warring
States period Characters - WSC (475 B.C. to 221 B.C.), and Clerical Script - CS
(221 B.C. to 220 A.D.). Subsequently, we constructed an extensive dataset,
namely EVolution Oracle Bone Characters (EVOBC), consisting of 229,170 images
representing 13,714 distinct character categories. We conducted validation and
simulated deciphering on the constructed dataset, and the results demonstrate
its high efficacy in aiding the study of oracle bone script. This openly
accessible dataset aims to digitalize ancient Chinese scripts across multiple
eras, facilitating the decipherment of oracle bone script by examining the
evolution of glyph forms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12470">Reinforcement Learning for Graph Coloring: Understanding the Power and Limits of Non-Label Invariant Representations. (arXiv:2401.12470v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cummins_C/0/1/0/all/0/1">Chase Cummins</a>, <a href="http://arxiv.org/find/cs/1/au:+Veras_R/0/1/0/all/0/1">Richard Veras</a></p>
<p>Register allocation is one of the most important problems for modern
compilers. With a practically unlimited number of user variables and a small
number of CPU registers, assigning variables to registers without conflicts is
a complex task. This work demonstrates the use of casting the register
allocation problem as a graph coloring problem. Using technologies such as
PyTorch and OpenAI Gymnasium Environments we will show that a Proximal Policy
Optimization model can learn to solve the graph coloring problem. We will also
show that the labeling of a graph is critical to the performance of the model
by taking the matrix representation of a graph and permuting it. We then test
the model's effectiveness on each of these permutations and show that it is not
effective when given a relabeling of the same graph. Our main contribution lies
in showing the need for label reordering invariant representations of graphs
for machine learning models to achieve consistent performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12478">Mini-batch Submodular Maximization. (arXiv:2401.12478v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schwartzman_G/0/1/0/all/0/1">Gregory Schwartzman</a></p>
<p>We present the first mini-batch algorithm for maximizing a non-negative
monotone decomposable submodular function, $F=\sum_{i=1}^N f^i$, under a set of
constraints. We improve over the sparsifier based approach both in theory and
in practice. We experimentally observe that our algorithm generates solutions
that are far superior to those generated by the sparsifier based approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12485">Adiabatic Quantum Support Vector Machines. (arXiv:2401.12485v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Date_P/0/1/0/all/0/1">Prasanna Date</a>, <a href="http://arxiv.org/find/cs/1/au:+Woun_D/0/1/0/all/0/1">Dong Jun Woun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_K/0/1/0/all/0/1">Kathleen Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1">Eduardo A. Coello Perez</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekhar_M/0/1/0/all/0/1">Mayanka Chandra Shekhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rios_F/0/1/0/all/0/1">Francisco Rios</a>, <a href="http://arxiv.org/find/cs/1/au:+Gounley_J/0/1/0/all/0/1">John Gounley</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_I/0/1/0/all/0/1">In-Saeng Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Humble_T/0/1/0/all/0/1">Travis Humble</a>, <a href="http://arxiv.org/find/cs/1/au:+Tourassi_G/0/1/0/all/0/1">Georgia Tourassi</a></p>
<p>Adiabatic quantum computers can solve difficult optimization problems (e.g.,
the quadratic unconstrained binary optimization problem), and they seem well
suited to train machine learning models. In this paper, we describe an
adiabatic quantum approach for training support vector machines. We show that
the time complexity of our quantum approach is an order of magnitude better
than the classical approach. Next, we compare the test accuracy of our quantum
approach against a classical approach that uses the Scikit-learn library in
Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC),
Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies
on par with the classical approach. Finally, we perform a scalability study in
which we compute the total training times of the quantum approach and the
classical approach with increasing number of features and number of data points
in the training dataset. Our scalability results show that the quantum approach
obtains a 3.5--4.5 times speedup over the classical approach on datasets with
many (millions of) features.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12489">Unsupervised Learning Method for the Wave Equation Based on Finite Difference Residual Constraints Loss. (arXiv:2401.12489v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jia-Xian Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lai-Ping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiao-Gang Deng</a></p>
<p>The wave equation is an important physical partial differential equation, and
in recent years, deep learning has shown promise in accelerating or replacing
traditional numerical methods for solving it. However, existing deep learning
methods suffer from high data acquisition costs, low training efficiency, and
insufficient generalization capability for boundary conditions. To address
these issues, this paper proposes an unsupervised learning method for the wave
equation based on finite difference residual constraints. We construct a novel
finite difference residual constraint based on structured grids and finite
difference methods, as well as an unsupervised training strategy, enabling
convolutional neural networks to train without data and predict the forward
propagation process of waves. Experimental results show that finite difference
residual constraints have advantages over physics-informed neural networks
(PINNs) type physical information constraints, such as easier fitting, lower
computational costs, and stronger source term generalization capability, making
our method more efficient in training and potent in application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12491">Assessing and Understanding Creativity in Large Language Models. (arXiv:2401.12491v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yunpu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Di Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiaming Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shaohui Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1">Yifan Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yuanbo Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zidong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Ling Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunji Chen</a></p>
<p>In the field of natural language processing, the rapid development of large
language model (LLM) has attracted more and more attention. LLMs have shown a
high level of creativity in various tasks, but the methods for assessing such
creativity are inadequate. The assessment of LLM creativity needs to consider
differences from humans, requiring multi-dimensional measurement while
balancing accuracy and efficiency. This paper aims to establish an efficient
framework for assessing the level of creativity in LLMs. By adapting the
modified Torrance Tests of Creative Thinking, the research evaluates the
creative performance of various LLMs across 7 tasks, emphasizing 4 criteria
including Fluency, Flexibility, Originality, and Elaboration. In this context,
we develop a comprehensive dataset of 700 questions for testing and an
LLM-based evaluation method. In addition, this study presents a novel analysis
of LLMs' responses to diverse prompts and role-play situations. We found that
the creativity of LLMs primarily falls short in originality, while excelling in
elaboration. Besides, the use of prompts and the role-play settings of the
model significantly influence creativity. Additionally, the experimental
results also indicate that collaboration among multiple LLMs can enhance
originality. Notably, our findings reveal a consensus between human evaluations
and LLMs regarding the personality traits that influence creativity. The
findings underscore the significant impact of LLM design on creativity and
bridges artificial intelligence and human creativity, offering insights into
LLMs' creativity and potential applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12492">Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?. (arXiv:2401.12492v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Soni_N/0/1/0/all/0/1">Nikita Soni</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1">H. Andrew Schwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1">Dirk Hovy</a></p>
<p>Natural language processing has made progress in incorporating human context
into its models, but whether it is more effective to use group-wise attributes
(e.g., over-45-year-olds) or model individuals remains open. Group attributes
are technically easier but coarse: not all 45-year-olds write the same way. In
contrast, modeling individuals captures the complexity of each person's
identity. It allows for a more personalized representation, but we may have to
model an infinite number of users and require data that may be impossible to
get. We compare modeling human context via group attributes, individual users,
and combined approaches. Combining group and individual features significantly
benefits user-level regression tasks like age estimation or personality
assessment from a user's documents. Modeling individual users significantly
improves the performance of single document-level classification tasks like
stance and topic detection. We also find that individual-user modeling does
well even without user's historical data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12497">Building Minimal and Reusable Causal State Abstractions for Reinforcement Learning. (arXiv:2401.12497v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zizhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Caroline Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xuesu Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1">Peter Stone</a></p>
<p>Two desiderata of reinforcement learning (RL) algorithms are the ability to
learn from relatively little experience and the ability to learn policies that
generalize to a range of problem specifications. In factored state spaces, one
approach towards achieving both goals is to learn state abstractions, which
only keep the necessary variables for learning the tasks at hand. This paper
introduces Causal Bisimulation Modeling (CBM), a method that learns the causal
relationships in the dynamics and reward functions for each task to derive a
minimal, task-specific abstraction. CBM leverages and improves implicit
modeling to train a high-fidelity causal dynamics model that can be reused for
all tasks in the same environment. Empirical validation on manipulation
environments and Deepmind Control Suite reveals that CBM's learned implicit
dynamics models identify the underlying causal relationships and state
abstractions more accurately than explicit ones. Furthermore, the derived state
abstractions allow a task learner to achieve near-oracle levels of sample
efficiency and outperform baselines on all tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12513">Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR. (arXiv:2401.12513v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Turnbull_R/0/1/0/all/0/1">Robert Turnbull</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannix_E/0/1/0/all/0/1">Evelyn Mannix</a></p>
<p>The capacity to isolate and recognize individual characters from facsimile
images of papyrus manuscripts yields rich opportunities for digital analysis.
For this reason the `ICDAR 2023 Competition on Detection and Recognition of
Greek Letters on Papyri' was held as part of the 17th International Conference
on Document Analysis and Recognition. This paper discusses our submission to
the competition. We used an ensemble of YOLOv8 models to detect and classify
individual characters and employed two different approaches for refining the
character predictions, including a transformer based DeiT approach and a
ResNet-50 model trained on a large corpus of unlabelled data using SimCLR, a
self-supervised learning method. Our submission won the recognition challenge
with a mAP of 42.2%, and was runner-up in the detection challenge with a mean
average precision (mAP) of 51.4%. At the more relaxed intersection over union
threshold of 0.5, we achieved the highest mean average precision and mean
average recall results for both detection and classification. We ran our
prediction pipeline on more than 4,500 images from the Oxyrhynchus Papyri to
illustrate the utility of our approach, and we release the results publicly in
multiple formats.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12522">BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models. (arXiv:2401.12522v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Feng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_H/0/1/0/all/0/1">Hanling Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yifan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaotian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Guangming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1">Rong Xiao</a></p>
<p>Large language models (LLMs) commonly employ autoregressive generation during
inference, leading to high memory bandwidth demand and consequently extended
latency. To mitigate this inefficiency, we present Bi-directional Tuning for
lossless Acceleration (BiTA), an innovative method expediting LLMs via
streamlined semi-autoregressive generation and draft verification. Inspired by
the concept of prompt tuning, we enhance LLMs with a parameter-efficient design
called bi-directional tuning for the capability in semi-autoregressive
generation. Employing efficient tree-based decoding, the models perform draft
candidate generation and verification in parallel, ensuring outputs identical
to their autoregressive counterparts under greedy sampling. BiTA serves as a
lightweight plug-in module, seamlessly boosting the inference efficiency of
existing LLMs without requiring additional assistance models or incurring
significant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat
achieves a 2.7$\times$ speedup on the MT-Bench benchmark. Extensive experiments
confirm our method surpasses state-of-the-art acceleration techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12532">DAFA: Distance-Aware Fair Adversarial Training. (arXiv:2401.12532v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyungyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Saehyung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1">Hyemi Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Junsung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bae_H/0/1/0/all/0/1">Ho Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a></p>
<p>The disparity in accuracy between classes in standard training is amplified
during adversarial training, a phenomenon termed the robust fairness problem.
Existing methodologies aimed to enhance robust fairness by sacrificing the
model's performance on easier classes in order to improve its performance on
harder ones. However, we observe that under adversarial attacks, the majority
of the model's predictions for samples from the worst class are biased towards
classes similar to the worst class, rather than towards the easy classes.
Through theoretical and empirical analysis, we demonstrate that robust fairness
deteriorates as the distance between classes decreases. Motivated by these
insights, we introduce the Distance-Aware Fair Adversarial training (DAFA)
methodology, which addresses robust fairness by taking into account the
similarities between classes. Specifically, our method assigns distinct loss
weights and adversarial margins to each class and adjusts them to encourage a
trade-off in robustness among similar classes. Experimental results across
various datasets demonstrate that our method not only maintains average robust
accuracy but also significantly improves the worst robust accuracy, indicating
a marked improvement in robust fairness compared to existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12533">Efficient Constrained $k$-Center Clustering with Background Knowledge. (arXiv:2401.12533v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longkun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chaoqi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_K/0/1/0/all/0/1">Kewen Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhigang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1">Minhui Xue</a></p>
<p>Center-based clustering has attracted significant research interest from both
theory and practice. In many practical applications, input data often contain
background knowledge that can be used to improve clustering results. In this
work, we build on widely adopted $k$-center clustering and model its input
background knowledge as must-link (ML) and cannot-link (CL) constraint sets.
However, most clustering problems including $k$-center are inherently
$\mathcal{NP}$-hard, while the more complex constrained variants are known to
suffer severer approximation and computation barriers that significantly limit
their applicability. By employing a suite of techniques including reverse
dominating sets, linear programming (LP) integral polyhedron, and LP duality,
we arrive at the first efficient approximation algorithm for constrained
$k$-center with the best possible ratio of 2. We also construct competitive
baseline algorithms and empirically evaluate our approximation algorithm
against them on a variety of real datasets. The results validate our
theoretical findings and demonstrate the great advantages of our algorithm in
terms of clustering cost, clustering quality, and running time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12550">UR4NNV: Neural Network Verification, Under-approximation Reachability Works!. (arXiv:2401.12550v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1">Zhen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Taoran Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ran Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1">Bai Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Ji Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenjing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shaojun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanwei Liu</a></p>
<p>Recently, formal verification of deep neural networks (DNNs) has garnered
considerable attention, and over-approximation based methods have become
popular due to their effectiveness and efficiency. However, these strategies
face challenges in addressing the "unknown dilemma" concerning whether the
exact output region or the introduced approximation error violates the property
in question. To address this, this paper introduces the UR4NNV verification
framework, which utilizes under-approximation reachability analysis for DNN
verification for the first time. UR4NNV focuses on DNNs with Rectified Linear
Unit (ReLU) activations and employs a binary tree branch-based
under-approximation algorithm. In each epoch, UR4NNV under-approximates a
sub-polytope of the reachable set and verifies this polytope against the given
property. Through a trial-and-error approach, UR4NNV effectively falsifies DNN
properties while providing confidence levels when reaching verification epoch
bounds and failing falsifying properties. Experimental comparisons with
existing verification methods demonstrate the effectiveness and efficiency of
UR4NNV, significantly reducing the impact of the "unknown dilemma".
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12554">Can Large Language Models Write Parallel Code?. (arXiv:2401.12554v1 [cs.DC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nichols_D/0/1/0/all/0/1">Daniel Nichols</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Joshua H. Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhaojun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaram_A/0/1/0/all/0/1">Arjun Rajaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatele_A/0/1/0/all/0/1">Abhinav Bhatele</a></p>
<p>Large Language Models are becoming an increasingly popular tool for software
development. Their ability to model and generate source code has been
demonstrated in a variety of contexts, including code completion,
summarization, translation, and lookup. However, they often struggle to
generate code for more complex tasks. In this paper, we explore the ability of
state-of-the-art language models to generate parallel code. We propose a
benchmark, PCGBench, consisting of a set of 420 tasks for evaluating the
ability of language models to generate parallel code, and we evaluate the
performance of several state-of-the-art open- and closed-source language models
on these tasks. We introduce novel metrics for comparing parallel code
generation performance and use them to explore how well each LLM performs on
various parallel programming models and computational problem types.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12557">Balancing the AI Strength of Roles in Self-Play Training with Regret Matching+. (arXiv:2401.12557v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoxi Wang</a></p>
<p>When training artificial intelligence for games encompassing multiple roles,
the development of a generalized model capable of controlling any character
within the game presents a viable option. This strategy not only conserves
computational resources and time during the training phase but also reduces
resource requirements during deployment. training such a generalized model
often encounters challenges related to uneven capabilities when controlling
different roles. A simple method is introduced based on Regret Matching+, which
facilitates a more balanced performance of strength by the model when
controlling various roles.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12570">DiffMoog: a Differentiable Modular Synthesizer for Sound Matching. (arXiv:2401.12570v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Uzrad_N/0/1/0/all/0/1">Noy Uzrad</a>, <a href="http://arxiv.org/find/eess/1/au:+Barkan_O/0/1/0/all/0/1">Oren Barkan</a>, <a href="http://arxiv.org/find/eess/1/au:+Elharar_A/0/1/0/all/0/1">Almog Elharar</a>, <a href="http://arxiv.org/find/eess/1/au:+Shvartzman_S/0/1/0/all/0/1">Shlomi Shvartzman</a>, <a href="http://arxiv.org/find/eess/1/au:+Laufer_M/0/1/0/all/0/1">Moshe Laufer</a>, <a href="http://arxiv.org/find/eess/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>, <a href="http://arxiv.org/find/eess/1/au:+Koenigstein_N/0/1/0/all/0/1">Noam Koenigstein</a></p>
<p>This paper presents DiffMoog - a differentiable modular synthesizer with a
comprehensive set of modules typically found in commercial instruments. Being
differentiable, it allows integration into neural networks, enabling automated
sound matching, to replicate a given audio input. Notably, DiffMoog facilitates
modulation capabilities (FM/AM), low-frequency oscillators (LFOs), filters,
envelope shapers, and the ability for users to create custom signal chains. We
introduce an open-source platform that comprises DiffMoog and an end-to-end
sound matching framework. This framework utilizes a novel signal-chain loss and
an encoder network that self-programs its outputs to predict DiffMoogs
parameters based on the user-defined modular architecture. Moreover, we provide
insights and lessons learned towards sound matching using differentiable
synthesis. Combining robust sound capabilities with a holistic platform,
DiffMoog stands as a premier asset for expediting research in audio synthesis
and machine learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12576">LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools. (arXiv:2401.12576v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qianli Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Anikina_T/0/1/0/all/0/1">Tatiana Anikina</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldhus_N/0/1/0/all/0/1">Nils Feldhus</a>, <a href="http://arxiv.org/find/cs/1/au:+Genabith_J/0/1/0/all/0/1">Josef van Genabith</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_L/0/1/0/all/0/1">Leonhard Hennig</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_S/0/1/0/all/0/1">Sebastian M&#xf6;ller</a></p>
<p>Interpretability tools that offer explanations in the form of a dialogue have
demonstrated their efficacy in enhancing users' understanding, as one-off
explanations may occasionally fall short in providing sufficient information to
the user. Current solutions for dialogue-based explanations, however, require
many dependencies and are not easily transferable to tasks they were not
designed for. With LLMCheckup, we present an easily accessible tool that allows
users to chat with any state-of-the-art large language model (LLM) about its
behavior. We enable LLMs to generate all explanations by themselves and take
care of intent recognition without fine-tuning, by connecting them with a broad
spectrum of Explainable AI (XAI) tools, e.g. feature attributions,
embedding-based similarity, and prompting strategies for counterfactual and
rationale generation. LLM (self-)explanations are presented as an interactive
dialogue that supports follow-up questions and generates suggestions.
LLMCheckup provides tutorials for operations available in the system, catering
to individuals with varying levels of expertise in XAI and supports multiple
input modalities. We introduce a new parsing strategy called multi-prompt
parsing substantially enhancing the parsing accuracy of LLMs. Finally, we
showcase the tasks of fact checking and commonsense question answering.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12593">MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels. (arXiv:2401.12593v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gomez_E/0/1/0/all/0/1">Elizabeth G&#xf3;mez</a>, <a href="http://arxiv.org/find/cs/1/au:+Contreras_D/0/1/0/all/0/1">David Contreras</a>, <a href="http://arxiv.org/find/cs/1/au:+Boratto_L/0/1/0/all/0/1">Ludovico Boratto</a>, <a href="http://arxiv.org/find/cs/1/au:+Salamo_M/0/1/0/all/0/1">Maria Salam&#xf3;</a></p>
<p>Multi-Objective Recommender Systems (MORSs) emerged as a paradigm to
guarantee multiple (often conflicting) goals. Besides accuracy, a MORS can
operate at the global level, where additional beyond-accuracy goals are met for
the system as a whole, or at the individual level, meaning that the
recommendations are tailored to the needs of each user. The state-of-the-art
MORSs either operate at the global or individual level, without assuming the
co-existence of the two perspectives. In this study, we show that when global
and individual objectives co-exist, MORSs are not able to meet both types of
goals. To overcome this issue, we present an approach that regulates the
recommendation lists so as to guarantee both global and individual
perspectives, while preserving its effectiveness. Specifically, as individual
perspective, we tackle genre calibration and, as global perspective, provider
fairness. We validate our approach on two real-world datasets, publicly
released with this paper.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12599">Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition. (arXiv:2401.12599v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Demiao Lin</a> (chatdoc.com)</p>
<p>With the rapid development of Large Language Models (LLMs),
Retrieval-Augmented Generation (RAG) has become a predominant method in the
field of professional knowledge-based question answering. Presently, major
foundation model companies have opened up Embedding and Chat API interfaces,
and frameworks like LangChain have already integrated the RAG process. It
appears that the key models and steps in RAG have been resolved, leading to the
question: are professional knowledge QA systems now approaching perfection?
This article discovers that current primary methods depend on the premise of
accessing high-quality text corpora. However, since professional documents are
mainly stored in PDFs, the low accuracy of PDF parsing significantly impacts
the effectiveness of professional knowledge-based QA. We conducted an empirical
RAG experiment across hundreds of questions from the corresponding real-world
professional documents. The results show that, ChatDOC, a RAG system equipped
with a panoptic and pinpoint PDF parser, retrieves more accurate and complete
segments, and thus better answers. Empirical experiments show that ChatDOC is
superior to baseline on nearly 47% of questions, ties for 38% of cases, and
falls short on only 15% of cases. It shows that we may revolutionize RAG with
enhanced PDF structure recognition.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12624">Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control. (arXiv:2401.12624v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yongjun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1">Sejin Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jihong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seong-Lyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Junil Choi</a></p>
<p>In this work, we compare emergent communication (EC) built upon multi-agent
deep reinforcement learning (MADRL) and language-oriented semantic
communication (LSC) empowered by a pre-trained large language model (LLM) using
human language. In a multi-agent remote navigation task, with multimodal input
data comprising location and channel maps, it is shown that EC incurs high
training cost and struggles when using multimodal data, whereas LSC yields high
inference computing cost due to the LLM's large size. To address their
respective bottlenecks, we propose a novel framework of language-guided EC
(LEC) by guiding the EC training using LSC via knowledge distillation (KD).
Simulations corroborate that LEC achieves faster travel time while avoiding
areas with poor channel conditions, as well as speeding up the MADRL training
convergence by up to 61.8% compared to EC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12631">A Reply to Makelov et al. (2023)&#x27;s &quot;Interpretability Illusion&quot; Arguments. (arXiv:2401.12631v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhengxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Atticus Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1">Aryaman Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1">Thomas Icard</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah D. Goodman</a></p>
<p>We respond to the recent paper by Makelov et al. (2023), which reviews
subspace interchange intervention methods like distributed alignment search
(DAS; Geiger et al. 2023) and claims that these methods potentially cause
"interpretability illusions". We first review Makelov et al. (2023)'s technical
notion of what an "interpretability illusion" is, and then we show that even
intuitive and desirable explanations can qualify as illusions in this sense. As
a result, their method of discovering "illusions" can reject explanations they
consider "non-illusory". We then argue that the illusions Makelov et al. (2023)
see in practice are artifacts of their training and evaluation paradigms. We
close by emphasizing that, though we disagree with their core characterization,
Makelov et al. (2023)'s examples and discussion have undoubtedly pushed the
field of interpretability forward.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12632">Modeling Resilience of Collaborative AI Systems. (arXiv:2401.12632v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rimawi_D/0/1/0/all/0/1">Diaeddin Rimawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liotta_A/0/1/0/all/0/1">Antonio Liotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Todescato_M/0/1/0/all/0/1">Marco Todescato</a>, <a href="http://arxiv.org/find/cs/1/au:+Russo_B/0/1/0/all/0/1">Barbara Russo</a></p>
<p>A Collaborative Artificial Intelligence System (CAIS) performs actions in
collaboration with the human to achieve a common goal. CAISs can use a trained
AI model to control human-system interaction, or they can use human interaction
to dynamically learn from humans in an online fashion. In online learning with
human feedback, the AI model evolves by monitoring human interaction through
the system sensors in the learning state, and actuates the autonomous
components of the CAIS based on the learning in the operational state.
Therefore, any disruptive event affecting these sensors may affect the AI
model's ability to make accurate decisions and degrade the CAIS performance.
Consequently, it is of paramount importance for CAIS managers to be able to
automatically track the system performance to understand the resilience of the
CAIS upon such disruptive events. In this paper, we provide a new framework to
model CAIS performance when the system experiences a disruptive event. With our
framework, we introduce a model of performance evolution of CAIS. The model is
equipped with a set of measures that aim to support CAIS managers in the
decision process to achieve the required resilience of the system. We tested
our framework on a real-world case study of a robot collaborating online with
the human, when the system is experiencing a disruptive event. The case study
shows that our framework can be adopted in CAIS and integrated into the online
execution of the CAIS activities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12646">Emergent Cooperation under Uncertain Incentive Alignment. (arXiv:2401.12646v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Orzan_N/0/1/0/all/0/1">Nicole Orzan</a>, <a href="http://arxiv.org/find/cs/1/au:+Acar_E/0/1/0/all/0/1">Erman Acar</a>, <a href="http://arxiv.org/find/cs/1/au:+Grossi_D/0/1/0/all/0/1">Davide Grossi</a>, <a href="http://arxiv.org/find/cs/1/au:+Radulescu_R/0/1/0/all/0/1">Roxana R&#x103;dulescu</a></p>
<p>Understanding the emergence of cooperation in systems of computational agents
is crucial for the development of effective cooperative AI. Interaction among
individuals in real-world settings are often sparse and occur within a broad
spectrum of incentives, which often are only partially known. In this work, we
explore how cooperation can arise among reinforcement learning agents in
scenarios characterised by infrequent encounters, and where agents face
uncertainty about the alignment of their incentives with those of others. To do
so, we train the agents under a wide spectrum of environments ranging from
fully competitive, to fully cooperative, to mixed-motives. Under this type of
uncertainty we study the effects of mechanisms, such as reputation and
intrinsic rewards, that have been proposed in the literature to foster
cooperation in mixed-motives environments. Our findings show that uncertainty
substantially lowers the agents' ability to engage in cooperative behaviour,
when that would be the best course of action. In this scenario, the use of
effective reputation mechanisms and intrinsic rewards boosts the agents'
capability to act nearly-optimally in cooperative environments, while greatly
enhancing cooperation in mixed-motive environments as well.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12662">Integrating Human Expertise in Continuous Spaces: A Novel Interactive Bayesian Optimization Framework with Preference Expected Improvement. (arXiv:2401.12662v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feith_N/0/1/0/all/0/1">Nikolaus Feith</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_E/0/1/0/all/0/1">Elmar Rueckert</a></p>
<p>Interactive Machine Learning (IML) seeks to integrate human expertise into
machine learning processes. However, most existing algorithms cannot be applied
to Realworld Scenarios because their state spaces and/or action spaces are
limited to discrete values. Furthermore, the interaction of all existing
methods is restricted to deciding between multiple proposals. We therefore
propose a novel framework based on Bayesian Optimization (BO). Interactive
Bayesian Optimization (IBO) enables collaboration between machine learning
algorithms and humans. This framework captures user preferences and provides an
interface for users to shape the strategy by hand. Additionally, we've
incorporated a new acquisition function, Preference Expected Improvement (PEI),
to refine the system's efficiency using a probabilistic model of the user
preferences. Our approach is geared towards ensuring that machines can benefit
from human expertise, aiming for a more aligned and effective learning process.
In the course of this work, we applied our method to simulations and in a real
world task using a Franka Panda robot to show human-robot collaboration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12665">ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation. (arXiv:2401.12665v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shengze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jianjian Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1">Peng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yuhan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_C/0/1/0/all/0/1">Chongjun Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tao Chen</a></p>
<p>Recently, foundational models such as CLIP and SAM have shown promising
performance for the task of Zero-Shot Anomaly Segmentation (ZSAS). However,
either CLIP-based or SAM-based ZSAS methods still suffer from non-negligible
key drawbacks: 1) CLIP primarily focuses on global feature alignment across
different inputs, leading to imprecise segmentation of local anomalous parts;
2) SAM tends to generate numerous redundant masks without proper prompt
constraints, resulting in complex post-processing requirements. In this work,
we innovatively propose a CLIP and SAM collaboration framework called ClipSAM
for ZSAS. The insight behind ClipSAM is to employ CLIP's semantic understanding
capability for anomaly localization and rough segmentation, which is further
used as the prompt constraints for SAM to refine the anomaly segmentation
results. In details, we introduce a crucial Unified Multi-scale Cross-modal
Interaction (UMCI) module for interacting language with visual features at
multiple scales of CLIP to reason anomaly positions. Then, we design a novel
Multi-level Mask Refinement (MMR) module, which utilizes the positional
information as multi-level prompts for SAM to acquire hierarchical levels of
masks and merges them. Extensive experiments validate the effectiveness of our
approach, achieving the optimal segmentation performance on the MVTec-AD and
VisA datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12666">EL-VIT: Probing Vision Transformer with Interactive Visualization. (arXiv:2401.12666v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_P/0/1/0/all/0/1">Peifeng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chaoran Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhida Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junjie Li</a></p>
<p>Nowadays, Vision Transformer (ViT) is widely utilized in various computer
vision tasks, owing to its unique self-attention mechanism. However, the model
architecture of ViT is complex and often challenging to comprehend, leading to
a steep learning curve. ViT developers and users frequently encounter
difficulties in interpreting its inner workings. Therefore, a visualization
system is needed to assist ViT users in understanding its functionality. This
paper introduces EL-VIT, an interactive visual analytics system designed to
probe the Vision Transformer and facilitate a better understanding of its
operations. The system consists of four layers of visualization views. The
first three layers include model overview, knowledge background graph, and
model detail view. These three layers elucidate the operation process of ViT
from three perspectives: the overall model architecture, detailed explanation,
and mathematical operations, enabling users to understand the underlying
principles and the transition process between layers. The fourth interpretation
view helps ViT users and experts gain a deeper understanding by calculating the
cosine similarity between patches. Our two usage scenarios demonstrate the
effectiveness and usability of EL-VIT in helping ViT users understand the
working mechanism of ViT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12672">ChatGraph: Chat with Your Graphs. (arXiv:2401.12672v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Sen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lyu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaojun Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yafei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jianliang Xu</a></p>
<p>Graph analysis is fundamental in real-world applications. Traditional
approaches rely on SPARQL-like languages or clicking-and-dragging interfaces to
interact with graph data. However, these methods either require users to
possess high programming skills or support only a limited range of graph
analysis functionalities. To address the limitations, we propose a large
language model (LLM)-based framework called ChatGraph. With ChatGraph, users
can interact with graphs through natural language, making it easier to use and
more flexible than traditional approaches. The core of ChatGraph lies in
generating chains of graph analysis APIs based on the understanding of the
texts and graphs inputted in the user prompts. To achieve this, ChatGraph
consists of three main modules: an API retrieval module that searches for
relevant APIs, a graph-aware LLM module that enables the LLM to comprehend
graphs, and an API chain-oriented finetuning module that guides the LLM in
generating API chains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12681">Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning. (arXiv:2401.12681v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhishuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yunhao Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziyue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yisheng Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Rui Zhao</a></p>
<p>Kriging aims at estimating the attributes of unsampled geo-locations from
observations in the spatial vicinity or physical connections, which helps
mitigate skewed monitoring caused by under-deployed sensors. Existing works
assume that neighbors' information offers the basis for estimating the
attributes of the unobserved target while ignoring non-neighbors. However,
non-neighbors could also offer constructive information, and neighbors could
also be misleading. To this end, we propose ``Contrastive-Prototypical''
self-supervised learning for Kriging (KCP) to refine valuable information from
neighbors and recycle the one from non-neighbors. As a pre-trained paradigm, we
conduct the Kriging task from a new perspective of representation: we aim to
first learn robust and general representations and then recover attributes from
representations. A neighboring contrastive module is designed that coarsely
learns the representations by narrowing the representation distance between the
target and its neighbors while pushing away the non-neighbors. In parallel, a
prototypical module is introduced to identify similar representations via
exchanged prediction, thus refining the misleading neighbors and recycling the
useful non-neighbors from the neighboring contrast component. As a result, not
all the neighbors and some of the non-neighbors will be used to infer the
target. To encourage the two modules above to learn general and robust
representations, we design an adaptive augmentation module that incorporates
data-driven attribute augmentation and centrality-based topology augmentation
over the spatiotemporal Kriging graph data. Extensive experiments on real-world
datasets demonstrate the superior performance of KCP compared to its peers with
6% improvements and exceptional transferability and robustness. The code is
available at https://github.com/bonaldli/KCP
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12686">Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach. (arXiv:2401.12686v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fabian_C/0/1/0/all/0/1">Christian Fabian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1">Kai Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Koeppl_H/0/1/0/all/0/1">Heinz Koeppl</a></p>
<p>Learning the behavior of large agent populations is an important task for
numerous research areas. Although the field of multi-agent reinforcement
learning (MARL) has made significant progress towards solving these systems,
solutions for many agents often remain computationally infeasible and lack
theoretical guarantees. Mean Field Games (MFGs) address both of these issues
and can be extended to Graphon MFGs (GMFGs) to include network structures
between agents. Despite their merits, the real world applicability of GMFGs is
limited by the fact that graphons only capture dense graphs. Since most
empirically observed networks show some degree of sparsity, such as power law
graphs, the GMFG framework is insufficient for capturing these network
topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which
builds on the graph theoretical concept of graphexes. Graphexes are the
limiting objects to sparse graph sequences that also have other desirable
features such as the small world property. Learning equilibria in these games
is challenging due to the rich and sparse structure of the underlying graphs.
To tackle these challenges, we design a new learning algorithm tailored to the
GXMFG setup. This hybrid graphex learning approach leverages that the system
mainly consists of a highly connected core and a sparse periphery. After
defining the system and providing a theoretical analysis, we state our learning
approach and demonstrate its learning capabilities on both synthetic graphs and
real-world networks. This comparison shows that our GXMFG learning algorithm
successfully extends MFGs to a highly relevant class of hard, realistic
learning problems that are not accurately addressed by current MARL and MFG
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12689">Energy-based Automated Model Evaluation. (arXiv:2401.12689v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1">Ru Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1">Heming Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haobo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yawen Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zenan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Junbo Zhao</a></p>
<p>The conventional evaluation protocols on machine learning models rely heavily
on a labeled, i.i.d-assumed testing dataset, which is not often present in real
world applications. The Automated Model Evaluation (AutoEval) shows an
alternative to this traditional workflow, by forming a proximal prediction
pipeline of the testing performance without the presence of ground-truth
labels. Despite its recent successes, the AutoEval frameworks still suffer from
an overconfidence issue, substantial storage and computational cost. In that
regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that
allows the AutoEval framework to be both more efficient and effective. The core
of the MDE is to establish a meta-distribution statistic, on the information
(energy) associated with individual samples, then offer a smoother
representation enabled by energy-based learning. We further provide our
theoretical insights by connecting the MDE with the classification loss. We
provide extensive experiments across modalities, datasets and different
architectural backbones to validate MDE's validity, together with its
superiority compared with prior approaches. We also prove MDE's versatility by
showing its seamless integration with large-scale models, and easy adaption to
learning scenarios with noisy- or imbalanced- labels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12700">Securing Recommender System via Cooperative Training. (arXiv:2401.12700v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenwang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1">Defu Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a></p>
<p>Recommender systems are often susceptible to well-crafted fake profiles,
leading to biased recommendations. Among existing defense methods,
data-processing-based methods inevitably exclude normal samples, while
model-based methods struggle to enjoy both generalization and robustness. To
this end, we suggest integrating data processing and the robust model to
propose a general framework, Triple Cooperative Defense (TCD), which employs
three cooperative models that mutually enhance data and thereby improve
recommendation robustness. Furthermore, Considering that existing attacks
struggle to balance bi-level optimization and efficiency, we revisit poisoning
attacks in recommender systems and introduce an efficient attack strategy,
Co-training Attack (Co-Attack), which cooperatively optimizes the attack
optimization and model training, considering the bi-level setting while
maintaining attack efficiency. Moreover, we reveal a potential reason for the
insufficient threat of existing attacks is their default assumption of
optimizing attacks in undefended scenarios. This overly optimistic setting
limits the potential of attacks. Consequently, we put forth a Game-based
Co-training Attack (GCoAttack), which frames the proposed CoAttack and TCD as a
game-theoretic process, thoroughly exploring CoAttack's attack potential in the
cooperative training of attack and defense. Extensive experiments on three real
datasets demonstrate TCD's superiority in enhancing model robustness.
Additionally, we verify that the two proposed attack strategies significantly
outperform existing attacks, with game-based GCoAttack posing a greater
poisoning threat than CoAttack.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12708">Deep Neural Network Benchmarks for Selective Classification. (arXiv:2401.12708v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pugnana_A/0/1/0/all/0/1">Andrea Pugnana</a>, <a href="http://arxiv.org/find/cs/1/au:+Perini_L/0/1/0/all/0/1">Lorenzo Perini</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jesse Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruggieri_S/0/1/0/all/0/1">Salvatore Ruggieri</a></p>
<p>With the increasing deployment of machine learning models in many
socially-sensitive tasks, there is a growing demand for reliable and
trustworthy predictions. One way to accomplish these requirements is to allow a
model to abstain from making a prediction when there is a high risk of making
an error. This requires adding a selection mechanism to the model, which
selects those examples for which the model will provide a prediction. The
selective classification framework aims to design a mechanism that balances the
fraction of rejected predictions (i.e., the proportion of examples for which
the model does not make a prediction) versus the improvement in predictive
performance on the selected predictions. Multiple selective classification
frameworks exist, most of which rely on deep neural network architectures.
However, the empirical evaluation of the existing approaches is still limited
to partial comparisons among methods and settings, providing practitioners with
little insight into their relative merits. We fill this gap by benchmarking 18
baselines on a diverse set of 44 datasets that includes both image and tabular
data. Moreover, there is a mix of binary and multiclass tasks. We evaluate
these approaches using several criteria, including selective error rate,
empirical coverage, distribution of rejected instance's classes, and
performance on out-of-distribution instances. The results indicate that there
is not a single clear winner among the surveyed baselines, and the best method
depends on the users' objectives.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12714">Evaluation of large language models for assessing code maintainability. (arXiv:2401.12714v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dillmann_M/0/1/0/all/0/1">Marc Dillmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebert_J/0/1/0/all/0/1">Julien Siebert</a>, <a href="http://arxiv.org/find/cs/1/au:+Trendowicz_A/0/1/0/all/0/1">Adam Trendowicz</a></p>
<p>Increased availability of open-source software repositories and recent
advances in code analysis using large language models (LLMs) has triggered a
wave of new work to automate software engineering tasks that were previously
very difficult to automate. In this paper, we investigate a recent line of work
that hypothesises that comparing the probability of code generated by LLMs with
the probability the current code would have had can indicate potential quality
problems. We investigate the association between the cross-entropy of code
generated by ten different models (based on GPT2 and Llama2) and the following
quality aspects: readability, understandability, complexity, modularisation,
and overall maintainability assessed by experts and available in an benchmark
dataset. Our results show that, controlling for the number of logical lines of
codes (LLOC), cross-entropy computed by LLMs is indeed a predictor of
maintainability on a class level (the higher the cross-entropy the lower the
maintainability). However, this relation is reversed when one does not control
for LLOC (e.g., comparing small classes with longer ones). Furthermore, while
the complexity of LLMs affects the range of cross-entropy (smaller models tend
to have a wider range of cross-entropy), this plays a significant role in
predicting maintainability aspects. Our study limits itself on ten different
pretrained models (based on GPT2 and Llama2) and on maintainability aspects
collected by Schnappinger et al. When controlling for logical lines of code
(LLOC), cross-entropy is a predictor of maintainability. However, while related
work has shown the potential usefulness of cross-entropy at the level of tokens
or short sequences, at the class level this criterion alone may prove
insufficient to predict maintainability and further research is needed to make
best use of this information in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12731">The Distributional Uncertainty of the SHAP score in Explainable Machine Learning. (arXiv:2401.12731v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cifuentes_S/0/1/0/all/0/1">Santiago Cifuentes</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertossi_L/0/1/0/all/0/1">Leopoldo Bertossi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pardal_N/0/1/0/all/0/1">Nina Pardal</a>, <a href="http://arxiv.org/find/cs/1/au:+Abriola_S/0/1/0/all/0/1">Sergio Abriola</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_M/0/1/0/all/0/1">Maria Vanina Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_M/0/1/0/all/0/1">Miguel Romero</a></p>
<p>Attribution scores reflect how important the feature values in an input
entity are for the output of a machine learning model. One of the most popular
attribution scores is the SHAP score, which is an instantiation of the general
Shapley value used in coalition game theory. The definition of this score
relies on a probability distribution on the entity population. Since the exact
distribution is generally unknown, it needs to be assigned subjectively or be
estimated from data, which may lead to misleading feature scores. In this
paper, we propose a principled framework for reasoning on SHAP scores under
unknown entity population distributions. In our framework, we consider an
uncertainty region that contains the potential distributions, and the SHAP
score of a feature becomes a function defined over this region. We study the
basic problems of finding maxima and minima of this function, which allows us
to determine tight ranges for the SHAP scores of all features. In particular,
we pinpoint the complexity of these problems, and other related ones, showing
them to be NP-complete. Finally, we present experiments on a real-world
dataset, showing that our framework may contribute to a more robust feature
scoring.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12756">What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition. (arXiv:2401.12756v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Holtermann_C/0/1/0/all/0/1">Carolin Holtermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Frohmann_M/0/1/0/all/0/1">Markus Frohmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1">Navid Rekabsaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a></p>
<p>The knowledge encapsulated in a model is the core factor determining its
final performance on downstream tasks. Much research in NLP has focused on
efficient methods for storing and adapting different types of knowledge, e.g.,
in dedicated modularized structures, and on how to effectively combine these,
e.g., by learning additional parameters. However, given the many possible
options, a thorough understanding of the mechanisms involved in these
compositions is missing, and hence it remains unclear which strategies to
utilize. To address this research gap, we propose a novel framework for
zero-shot module composition, which encompasses existing and some novel
variations for selecting, weighting, and combining parameter modules under a
single unified notion. Focusing on the scenario of domain knowledge and adapter
layers, our framework provides a systematic unification of concepts, allowing
us to conduct the first comprehensive benchmarking study of various zero-shot
knowledge composition strategies. In particular, we test two module combination
methods and five selection and weighting strategies for their effectiveness and
efficiency in an extensive experimental setup. Our results highlight the
efficacy of ensembling but also hint at the power of simple though
often-ignored weighting methods. Further in-depth analyses allow us to
understand the role of weighting vs. top-k selection, and show that, to a
certain extent, the performance of adapter composition can even be predicted.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12771">Deep Learning-based Intraoperative MRI Reconstruction. (arXiv:2401.12771v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ottesen_J/0/1/0/all/0/1">Jon Andr&#xe9; Ottesen</a>, <a href="http://arxiv.org/find/eess/1/au:+Storas_T/0/1/0/all/0/1">Tryggve Storas</a>, <a href="http://arxiv.org/find/eess/1/au:+Vatnehol_S/0/1/0/all/0/1">Svein Are Sirirud Vatnehol</a>, <a href="http://arxiv.org/find/eess/1/au:+Lovland_G/0/1/0/all/0/1">Grethe L&#xf8;vland</a>, <a href="http://arxiv.org/find/eess/1/au:+Vik_Mo_E/0/1/0/all/0/1">Einar O. Vik-Mo</a>, <a href="http://arxiv.org/find/eess/1/au:+Schellhorn_T/0/1/0/all/0/1">Till Schellhorn</a>, <a href="http://arxiv.org/find/eess/1/au:+Skogen_K/0/1/0/all/0/1">Karoline Skogen</a>, <a href="http://arxiv.org/find/eess/1/au:+Larsson_C/0/1/0/all/0/1">Christopher Larsson</a>, <a href="http://arxiv.org/find/eess/1/au:+Bjornerud_A/0/1/0/all/0/1">Atle Bj&#xf8;rnerud</a>, <a href="http://arxiv.org/find/eess/1/au:+Groote_Eindbaas_I/0/1/0/all/0/1">Inge Rasmus Groote-Eindbaas</a>, <a href="http://arxiv.org/find/eess/1/au:+Caan_M/0/1/0/all/0/1">Matthan W.A. Caan</a></p>
<p>Purpose: To evaluate the quality of deep learning reconstruction for
prospectively accelerated intraoperative magnetic resonance imaging (iMRI)
during resective brain tumor surgery.
</p>
<p>Materials and Methods: Accelerated iMRI was performed during brain surgery
using dual surface coils positioned around the area of resection. A deep
learning (DL) model was trained on the fastMRI neuro dataset to mimic the data
from the iMRI protocol. Evaluation was performed on imaging material from 40
patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during
tumor resection surgery. A comparative analysis was conducted between the
conventional compressed sense (CS) method and the trained DL reconstruction
method. Blinded evaluation of multiple image quality metrics was performed by
two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert
scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the
favored reconstruction variant.
</p>
<p>Results: The DL reconstruction was strongly favored or favored over the CS
reconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3,
respectively. Two of three readers consistently assigned higher ratings for the
DL reconstructions, and the DL reconstructions had a higher score than their
respective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2,
and 3, respectively. Still, the DL reconstructions exhibited shortcomings such
as a striping artifact and reduced signal.
</p>
<p>Conclusion: DL shows promise to allow for high-quality reconstructions of
intraoperative MRI with equal to or improved perceived spatial resolution,
signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, and
spatial resolution compared to compressed sense.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12783">A Review of Deep Learning Methods for Photoplethysmography Data. (arXiv:2401.12783v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1">Guangkun Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiabao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Gongzheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Deyun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1">Shijia Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qinghao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1">Shenda Hong</a></p>
<p>Photoplethysmography (PPG) is a highly promising device due to its advantages
in portability, user-friendly operation, and non-invasive capabilities to
measure a wide range of physiological information. Recent advancements in deep
learning have demonstrated remarkable outcomes by leveraging PPG signals for
tasks related to personal health management and other multifaceted
applications. In this review, we systematically reviewed papers that applied
deep learning models to process PPG data between January 1st of 2017 and July
31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed
from three key perspectives: tasks, models, and data. We finally extracted 193
papers where different deep learning frameworks were used to process PPG
signals. Based on the tasks addressed in these papers, we categorized them into
two major groups: medical-related, and non-medical-related. The medical-related
tasks were further divided into seven subgroups, including blood pressure
analysis, cardiovascular monitoring and diagnosis, sleep health, mental health,
respiratory monitoring and analysis, blood glucose analysis, as well as others.
The non-medical-related tasks were divided into four subgroups, which encompass
signal processing, biometric identification, electrocardiogram reconstruction,
and human activity recognition. In conclusion, significant progress has been
made in the field of using deep learning methods to process PPG data recently.
This allows for a more thorough exploration and utilization of the information
contained in PPG signals. However, challenges remain, such as limited quantity
and quality of publicly available databases, a lack of effective validation in
real-world scenarios, and concerns about the interpretability, scalability, and
complexity of deep learning models. Moreover, there are still emerging research
areas that require further investigation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12803">Enhancements for 5G NR PRACH Reception: An AI/ML Approach. (arXiv:2401.12803v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rohit Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yerrapragada_A/0/1/0/all/0/1">Anil Kumar Yerrapragada</a>, <a href="http://arxiv.org/find/cs/1/au:+S_J/0/1/0/all/0/1">Jeeva Keshav S</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganti_R/0/1/0/all/0/1">Radha Krishna Ganti</a></p>
<p>Random Access is an important step in enabling the initial attachment of a
User Equipment (UE) to a Base Station (gNB). The UE identifies itself by
embedding a Preamble Index (RAPID) in the phase rotation of a known base
sequence, which it transmits on the Physical Random Access Channel (PRACH). The
signal on the PRACH also enables the estimation of propagation delay, often
known as Timing Advance (TA), which is induced by virtue of the UE's position.
Traditional receivers estimate the RAPID and TA using correlation-based
techniques. This paper presents an alternative receiver approach that uses
AI/ML models, wherein two neural networks are proposed, one for the RAPID and
one for the TA. Different from other works, these two models can run in
parallel as opposed to sequentially. Experiments with both simulated data and
over-the-air hardware captures highlight the improved performance of the
proposed AI/ML-based techniques compared to conventional correlation methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12806">Binary structured physics-informed neural networks for solving equations with rapidly changing solutions. (arXiv:2401.12806v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanzhi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Ruifan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Ying Jiang</a></p>
<p>Physics-informed neural networks (PINNs), rooted in deep learning, have
emerged as a promising approach for solving partial differential equations
(PDEs). By embedding the physical information described by PDEs into
feedforward neural networks, PINNs are trained as surrogate models to
approximate solutions without the need for label data. Nevertheless, even
though PINNs have shown remarkable performance, they can face difficulties,
especially when dealing with equations featuring rapidly changing solutions.
These difficulties encompass slow convergence, susceptibility to becoming
trapped in local minima, and reduced solution accuracy. To address these
issues, we propose a binary structured physics-informed neural network (BsPINN)
framework, which employs binary structured neural network (BsNN) as the neural
network component. By leveraging a binary structure that reduces inter-neuron
connections compared to fully connected neural networks, BsPINNs excel in
capturing the local features of solutions more effectively and efficiently.
These features are particularly crucial for learning the rapidly changing in
the nature of solutions. In a series of numerical experiments solving Burgers
equation, Euler equation, Helmholtz equation, and high-dimension Poisson
equation, BsPINNs exhibit superior convergence speed and heightened accuracy
compared to PINNs. From these experiments, we discover that BsPINNs resolve the
issues caused by increased hidden layers in PINNs resulting in over-smoothing,
and prevent the decline in accuracy due to non-smoothness of PDEs solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12819">Dynamic Layer Tying for Parameter-Efficient Transformers. (arXiv:2401.12819v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hay_T/0/1/0/all/0/1">Tamir David Hay</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a></p>
<p>In the pursuit of reducing the number of trainable parameters in deep
transformer networks, we employ Reinforcement Learning to dynamically select
layers during training and tie them together. Every few iterations, the RL
agent is asked whether to train each layer $i$ independently or to copy the
weights of a previous layer $j&lt;i$. This facilitates weight sharing, reduces the
number of trainable parameters, and also serves as an effective regularization
technique. Experimental evaluations validate that our model modestly
outperforms the baseline transformer model with regard to perplexity and
drastically reduces the number of trainable parameters. In particular, the
memory consumption during training is up to one order of magnitude less than
the conventional training method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12822">Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms. (arXiv:2401.12822v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mohammadi_E/0/1/0/all/0/1">Esmaeel Mohammadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Stokholm_Bjerregaard_M/0/1/0/all/0/1">Mikkel Stokholm-Bjerregaard</a>, <a href="http://arxiv.org/find/eess/1/au:+Hansen_A/0/1/0/all/0/1">Aviaja Anna Hansen</a>, <a href="http://arxiv.org/find/eess/1/au:+Nielsen_P/0/1/0/all/0/1">Per Halkj&#xe6;r Nielsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ortiz_Arroyo_D/0/1/0/all/0/1">Daniel Ortiz-Arroyo</a>, <a href="http://arxiv.org/find/eess/1/au:+Durdevic_P/0/1/0/all/0/1">Petar Durdevic</a></p>
<p>Phosphorus removal is vital in wastewater treatment to reduce reliance on
limited resources. Deep reinforcement learning (DRL) is a machine learning
technique that can optimize complex and nonlinear systems, including the
processes in wastewater treatment plants, by learning control policies through
trial and error. However, applying DRL to chemical and biological processes is
challenging due to the need for accurate simulators. This study trained six
models to identify the phosphorus removal process and used them to create a
simulator for the DRL environment. Although the models achieved high accuracy
(&gt;97%), uncertainty and incorrect prediction behavior limited their performance
as simulators over longer horizons. Compounding errors in the models'
predictions were identified as one of the causes of this problem. This approach
for improving process control involves creating simulation environments for DRL
algorithms, using data from supervisory control and data acquisition (SCADA)
systems with a sufficient historical horizon without complex system modeling or
parameter estimation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12830">Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data. (arXiv:2401.12830v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Salihoglu_S/0/1/0/all/0/1">Salih Salihoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koksal_G/0/1/0/all/0/1">Gulser Koksal</a>, <a href="http://arxiv.org/find/cs/1/au:+Abar_O/0/1/0/all/0/1">Orhan Abar</a></p>
<p>In the modern transportation industry, accurate prediction of travelers' next
destinations brings multiple benefits to companies, such as customer
satisfaction and targeted marketing. This study focuses on developing a precise
model that captures the sequential patterns and dependencies in travel data,
enabling accurate predictions of individual travelers' future destinations. To
achieve this, a novel model architecture with a sliding window approach based
on Long Short-Term Memory (LSTM) is proposed for destination prediction in the
transportation industry. The experimental results highlight satisfactory
performance and high scores achieved by the proposed model across different
data sizes and performance metrics. This research contributes to advancing
destination prediction methods, empowering companies to deliver personalized
recommendations and optimize customer experiences in the dynamic travel
landscape.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12835">SGTR+: End-to-end Scene Graph Generation with Transformer. (arXiv:2401.12835v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rongjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a></p>
<p>Scene Graph Generation (SGG) remains a challenging visual understanding task
due to its compositional property. Most previous works adopt a bottom-up,
two-stage or point-based, one-stage approach, which often suffers from high
time complexity or suboptimal designs. In this work, we propose a novel SGG
method to address the aforementioned issues, formulating the task as a
bipartite graph construction problem. To address the issues above, we create a
transformer-based end-to-end framework to generate the entity and entity-aware
predicate proposal set, and infer directed edges to form relation triplets.
Moreover, we design a graph assembling module to infer the connectivity of the
bipartite scene graph based on our entity-aware structure, enabling us to
generate the scene graph in an end-to-end manner. Based on bipartite graph
assembling paradigm, we further propose a new technical design to address the
efficacy of entity-aware modeling and optimization stability of graph
assembling. Equipped with the enhanced entity-aware design, our method achieves
optimal performance and time-complexity. Extensive experimental results show
that our design is able to achieve the state-of-the-art or comparable
performance on three challenging benchmarks, surpassing most of the existing
approaches and enjoying higher efficiency in inference. Code is available:
https://github.com/Scarecrow0/SGTR
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12846">How well can large language models explain business processes?. (arXiv:2401.12846v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fahland_D/0/1/0/all/0/1">Dirk Fahland</a>, <a href="http://arxiv.org/find/cs/1/au:+Fournier_F/0/1/0/all/0/1">Fabian Fournier</a>, <a href="http://arxiv.org/find/cs/1/au:+Limonad_L/0/1/0/all/0/1">Lior Limonad</a>, <a href="http://arxiv.org/find/cs/1/au:+Skarbovsky_I/0/1/0/all/0/1">Inna Skarbovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Swevels_A/0/1/0/all/0/1">Ava J.E. Swevels</a></p>
<p>Large Language Models (LLMs) are likely to play a prominent role in future
AI-augmented business process management systems (ABPMSs) catering
functionalities across all system lifecycle stages. One such system's
functionality is Situation-Aware eXplainability (SAX), which relates to
generating causally sound and yet human-interpretable explanations that take
into account the process context in which the explained condition occurred. In
this paper, we present the SAX4BPM framework developed to generate SAX
explanations. The SAX4BPM suite consists of a set of services and a central
knowledge repository. The functionality of these services is to elicit the
various knowledge ingredients that underlie SAX explanations. A key innovative
component among these ingredients is the causal process execution view. In this
work, we integrate the framework with an LLM to leverage its power to
synthesize the various input ingredients for the sake of improved SAX
explanations. Since the use of LLMs for SAX is also accompanied by a certain
degree of doubt related to its capacity to adequately fulfill SAX along with
its tendency for hallucination and lack of inherent capacity to reason, we
pursued a methodological evaluation of the quality of the generated
explanations. To this aim, we developed a designated scale and conducted a
rigorous user study. Our findings show that the input presented to the LLMs
aided with the guard-railing of its performance, yielding SAX explanations
having better-perceived fidelity. This improvement is moderated by the
perception of trust and curiosity. More so, this improvement comes at the cost
of the perceived interpretability of the explanation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12850">Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization. (arXiv:2401.12850v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Singh_P/0/1/0/all/0/1">Prachi Singh</a>, <a href="http://arxiv.org/find/eess/1/au:+Ganapathy_S/0/1/0/all/0/1">Sriram Ganapathy</a></p>
<p>Speaker diarization, the task of segmenting an audio recording based on
speaker identity, constitutes an important speech pre-processing step for
several downstream applications. The conventional approach to diarization
involves multiple steps of embedding extraction and clustering, which are often
optimized in an isolated fashion. While end-to-end diarization systems attempt
to learn a single model for the task, they are often cumbersome to train and
require large supervised datasets. In this paper, we propose an end-to-end
supervised hierarchical clustering algorithm based on graph neural networks
(GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). The
E-SHARC approach uses front-end mel-filterbank features as input and jointly
learns an embedding extractor and the GNN clustering module, performing
representation learning, metric learning, and clustering with end-to-end
optimization. Further, with additional inputs from an external overlap
detector, the E-SHARC approach is capable of predicting the speakers in the
overlapping speech regions. The experimental evaluation on several benchmark
datasets like AMI, VoxConverse and DISPLACE, illustrates that the proposed
E-SHARC framework improves significantly over the state-of-art diarization
systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12851">Classification of grapevine varieties using UAV hyperspectral imaging. (arXiv:2401.12851v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1">Alfonso L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogayar_C/0/1/0/all/0/1">Carlos Javier Ogayar</a>, <a href="http://arxiv.org/find/cs/1/au:+Feito_F/0/1/0/all/0/1">Francisco Ram&#xf3;n Feito</a>, <a href="http://arxiv.org/find/cs/1/au:+Sousa_J/0/1/0/all/0/1">Joaquim Jo&#xe3;o Sousa</a></p>
<p>The classification of different grapevine varieties is a relevant phenotyping
task in Precision Viticulture since it enables estimating the growth of
vineyard rows dedicated to different varieties, among other applications
concerning the wine industry. This task can be performed with destructive
methods that require time-consuming tasks, including data collection and
analysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a
more efficient and less prohibitive approach to collecting hyperspectral data,
despite acquiring noisier data. Therefore, the first task is the processing of
these data to correct and downsample large amounts of data. In addition, the
hyperspectral signatures of grape varieties are very similar. In this work, a
Convolutional Neural Network (CNN) is proposed for classifying seventeen
varieties of red and white grape variants. Rather than classifying single
samples, these are processed together with their neighbourhood. Hence, the
extraction of spatial and spectral features is addressed with 1) a spatial
attention layer and 2) Inception blocks. The pipeline goes from processing to
dataset elaboration, finishing with the training phase. The fitted model is
evaluated in terms of response time, accuracy and data separability, and
compared with other state-of-the-art CNNs for classifying hyperspectral data.
Our network was proven to be much more lightweight with a reduced number of
input bands, a lower number of trainable weights and therefore, reduced
training time. Despite this, the evaluated metrics showed much better results
for our network (~99% overall accuracy), in comparison with previous works
barely achieving 81% OA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12862">FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units. (arXiv:2401.12862v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1">Shaoheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zuhong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yafei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Siheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanfeng Wang</a></p>
<p>Roadside unit (RSU) can significantly improve the safety and robustness of
autonomous vehicles through Vehicle-to-Everything (V2X) communication.
Currently, the usage of a single RSU mainly focuses on real-time inference and
V2X collaboration, while neglecting the potential value of the high-quality
data collected by RSU sensors. Integrating the vast amounts of data from
numerous RSUs can provide a rich source of data for model training. However,
the absence of ground truth annotations and the difficulty of transmitting
enormous volumes of data are two inevitable barriers to fully exploiting this
hidden value. In this paper, we introduce FedRSU, an innovative federated
learning framework for self-supervised scene flow estimation. In FedRSU, we
present a recurrent self-supervision training paradigm, where for each RSU, the
scene flow prediction of points at every timestamp can be supervised by its
subsequent future multi-modality observation. Another key component of FedRSU
is federated learning, where multiple devices collaboratively train an ML model
while keeping the training data local and private. With the power of the
recurrent self-supervised learning paradigm, FL is able to leverage innumerable
underutilized data from RSU. To verify the FedRSU framework, we construct a
large-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSU
clients, covering various scenarios, modalities, and sensor settings. Based on
RSU-SF, we show that FedRSU can greatly improve model performance in ITS and
provide a comprehensive benchmark under diverse FL scenarios. To the best of
our knowledge, we provide the first real-world LiDAR-camera multi-modal dataset
and benchmark for the FL community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12863">KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning. (arXiv:2401.12863v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1">Debjyoti Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1">Suraj Modi</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_S/0/1/0/all/0/1">Subhadarshi Panda</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rituraj Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_G/0/1/0/all/0/1">Godawari Sudhakar Rao</a></p>
<p>Large Language Models (LLMs) have demonstrated impressive performance in
natural language processing tasks by leveraging chain of thought (CoT) that
enables step-by-step thinking. Extending LLMs with multimodal capabilities is
the recent interest, but incurs computational cost and requires substantial
hardware resources. To address these challenges, we propose KAM-CoT a framework
that integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities
for a comprehensive understanding of multimodal tasks. KAM-CoT adopts a
two-stage training process with KG grounding to generate effective rationales
and answers. By incorporating external knowledge from KGs during reasoning, the
model gains a deeper contextual understanding reducing hallucinations and
enhancing the quality of answers. This knowledge-augmented CoT reasoning
empowers the model to handle questions requiring external context, providing
more informed answers. Experimental findings show KAM-CoT outperforms the
state-of-the-art methods. On the ScienceQA dataset, we achieve an average
accuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by
10%. Remarkably, KAM-CoT achieves these results with only 280M trainable
parameters at a time, demonstrating its cost-efficiency and effectiveness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12866">Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing. (arXiv:2401.12866v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bruns_R/0/1/0/all/0/1">Ralf Bruns</a>, <a href="http://arxiv.org/find/cs/1/au:+Dotterl_J/0/1/0/all/0/1">Jeremias D&#xf6;tterl</a>, <a href="http://arxiv.org/find/cs/1/au:+Dunkel_J/0/1/0/all/0/1">J&#xfc;rgen Dunkel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ossowski_S/0/1/0/all/0/1">Sascha Ossowski</a></p>
<p>Mobile crowdsourcing refers to systems where the completion of tasks
necessarily requires physical movement of crowdworkers in an on-demand
workforce. Evidence suggests that in such systems, tasks often get assigned to
crowdworkers who struggle to complete those tasks successfully, resulting in
high failure rates and low service quality. A promising solution to ensure
higher quality of service is to continuously adapt the assignment and respond
to failure-causing events by transferring tasks to better-suited workers who
use different routes or vehicles. However, implementing task transfers in
mobile crowdsourcing is difficult because workers are autonomous and may reject
transfer requests. Moreover, task outcomes are uncertain and need to be
predicted. In this paper, we propose different mechanisms to achieve outcome
prediction and task coordination in mobile crowdsourcing. First, we analyze
different data stream learning approaches for the prediction of task outcomes.
Second, based on the suggested prediction model, we propose and evaluate two
different approaches for task coordination with different degrees of autonomy:
an opportunistic approach for crowdshipping with collaborative, but
non-autonomous workers, and a market-based model with autonomous workers for
crowdsensing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12869">TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks. (arXiv:2401.12869v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiruo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1">Daniel Fried</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a></p>
<p>Language models (LMs) can solve tasks such as answering questions about
tables or images by writing programs. However, using primitive functions often
leads to verbose and error-prone programs, and higher-level functions require
expert design. To enable better solutions without human labor, we ask code LMs
to curate reusable high-level functions, and use them to write solutions. We
present TROVE, a training-free method of inducing a verifiable and efficient
toolbox of functions, by generating via using, growing, and periodically
trimming the toolbox. On 11 datasets from math, table question answering, and
image reasoning tasks, TROVE consistently yields simpler solutions with higher
accuracy than baselines using CODELLAMA and previous methods using GPT, while
using 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more
accurate human verification than baselines. With the same pipeline, it creates
diverse functions for varied tasks and datasets, providing insights into their
individual characteristics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12873">Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model. (arXiv:2401.12873v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhiwei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1">Wenxiang Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuming Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a></p>
<p>Insufficient modeling of human preferences within the reward model is a major
obstacle for leveraging human feedback to improve translation quality.
Fortunately, quality estimation (QE), which predicts the quality of a given
translation without reference, has achieved impressive alignment with human
evaluations in the last two years. In this work, we investigate the potential
of employing the QE model as the reward model (the QE-based reward model) to
predict human preferences for feedback training. We first identify the
overoptimization problem during QE-based feedback training, manifested as an
increase in reward while translation quality declines. We examine the problem
and argue that the vulnerability of the QE model might lead to high rewards for
incorrect translations, resulting in overoptimization and error propagation. To
address the problem, we adopt a simple yet effective method that uses heuristic
rules to detect the incorrect translations and assigns a penalty term to the
QE-based rewards for the detected incorrect translations. Experimental results
show that the proposed QE-based feedback training achieves consistent and
significant improvements across various settings, further verified through
human preference studies. Our subsequent analysis demonstrates the high data
efficiency of the proposed QE-based feedback training: the proposed approach
using a small amount of monolingual data can outperform systems using larger
parallel corpora.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12874">From Understanding to Utilization: A Survey on Explainability for Large Language Models. (arXiv:2401.12874v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haoyan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1">Lucia Specia</a></p>
<p>This survey paper delves into the burgeoning field of explainability for
Large Language Models (LLMs), a critical yet challenging aspect of natural
language processing. With LLMs playing a pivotal role in various applications,
their "black-box" nature raises concerns about transparency and ethical use.
This paper emphasizes the necessity for enhanced explainability in LLMs,
addressing both the general public's trust and the technical community's need
for a deeper understanding of these models. We concentrate on pre-trained
Transformer-based LLMs, such as LLaMA, which present unique interpretability
challenges due to their scale and complexity. Our review categorizes existing
explainability methods and discusses their application in improving model
transparency and reliability. We also discuss representative evaluation
methods, highlighting their strengths and limitations. The goal of this survey
is to bridge the gap between theoretical understanding and practical
application, offering insights for future research and development in the field
of LLM explainability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12914">Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things. (arXiv:2401.12914v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mostafa_S/0/1/0/all/0/1">Salwa Mostafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Mota_M/0/1/0/all/0/1">Mateus P. Mota</a>, <a href="http://arxiv.org/find/cs/1/au:+Valcarce_A/0/1/0/all/0/1">Alvaro Valcarce</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a></p>
<p>In this paper, we leverage a multi-agent reinforcement learning (MARL)
framework to jointly learn a computation offloading decision and multichannel
access policy with corresponding signaling. Specifically, the base station and
industrial Internet of Things mobile devices are reinforcement learning agents
that need to cooperate to execute their computation tasks within a deadline
constraint. We adopt an emergent communication protocol learning framework to
solve this problem. The numerical results illustrate the effectiveness of
emergent communication in improving the channel access success rate and the
number of successfully computed tasks compared to contention-based,
contention-free, and no-communication approaches. Moreover, the proposed task
offloading policy outperforms remote and local computation baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12915">Red Teaming Visual Language Models. (arXiv:2401.12915v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mukai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yuwei Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1">Masood Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenguang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a></p>
<p>VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language
Models) to accept multimodal inputs. Since it has been verified that LLMs can
be induced to generate harmful or inaccurate content through specific test
cases (termed as Red Teaming), how VLMs perform in similar scenarios,
especially with their combination of textual and visual inputs, remains a
question. To explore this problem, we present a novel red teaming dataset
RTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal
jail-breaking, face fairness, etc) under 4 primary aspects (faithfulness,
privacy, safety, fairness). Our RTVLM is the first red-teaming dataset to
benchmark current VLMs in terms of these 4 different aspects. Detailed analysis
shows that 10 prominent open-sourced VLMs struggle with the red teaming in
different degrees and have up to 31% performance gap with GPT-4V. Additionally,
we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning
(SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLM
test set, 13% in MM-Hal, and without noticeable decline in MM-Bench,
overpassing other LLaVA-based models with regular alignment data. This reveals
that current open-sourced VLMs still lack red teaming alignment. Our code and
datasets will be open-source.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12917">Active Inference as a Model of Agency. (arXiv:2401.12917v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Costa_L/0/1/0/all/0/1">Lancelot Da Costa</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenka_S/0/1/0/all/0/1">Samuel Tenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dominic Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sajid_N/0/1/0/all/0/1">Noor Sajid</a></p>
<p>Is there a canonical way to think of agency beyond reward maximisation? In
this paper, we show that any type of behaviour complying with physically sound
assumptions about how macroscopic biological agents interact with the world
canonically integrates exploration and exploitation in the sense of minimising
risk and ambiguity about states of the world. This description, known as active
inference, refines the free energy principle, a popular descriptive framework
for action and perception originating in neuroscience. Active inference
provides a normative Bayesian framework to simulate and model agency that is
widely used in behavioural neuroscience, reinforcement learning (RL) and
robotics. The usefulness of active inference for RL is three-fold. \emph{a})
Active inference provides a principled solution to the exploration-exploitation
dilemma that usefully simulates biological agency. \emph{b}) It provides an
explainable recipe to simulate behaviour, whence behaviour follows as an
explainable mixture of exploration and exploitation under a generative world
model, and all differences in behaviour are explicit in differences in world
model. \emph{c}) This framework is universal in the sense that it is
theoretically possible to rewrite any RL algorithm conforming to the
descriptive assumptions of active inference as an active inference algorithm.
Thus, active inference can be used as a tool to uncover and compare the
commitments and assumptions of more specific models of agency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12920">Truck Parking Usage Prediction with Decomposed Graph Neural Networks. (arXiv:2401.12920v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tamaru_R/0/1/0/all/0/1">Rei Tamaru</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_S/0/1/0/all/0/1">Steven Parker</a>, <a href="http://arxiv.org/find/cs/1/au:+Perry_E/0/1/0/all/0/1">Ernie Perry</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_B/0/1/0/all/0/1">Bin Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Soyoung Ahn</a></p>
<p>Truck parking on freight corridors faces various challenges, such as
insufficient parking spaces and compliance with Hour-of-Service (HOS)
regulations. These constraints often result in unauthorized parking practices,
causing safety concerns. To enhance the safety of freight operations, providing
accurate parking usage prediction proves to be a cost-effective solution.
Despite the existing research demonstrating satisfactory accuracy for
predicting individual truck parking site usage, few approaches have been
proposed for predicting usage with spatial dependencies of multiple truck
parking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN)
as a predictive framework for assessing parking usage across the entire state
to provide better truck parking information and mitigate unauthorized parking.
The framework leverages the topological structures of truck parking site
distributions and historical parking data to predict occupancy rates across a
state. To achieve this, we introduce a Regional Decomposition approach, which
effectively captures the geographical characteristics. We also introduce the
spatial module working efficiently with the temporal module. Evaluation results
demonstrate that the proposed model surpasses other baseline models, improving
the performance by more than $20\%$ compared with the original model. The
proposed model allows truck parking sites' percipience of the topological
structures and provides higher performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12947">Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion. (arXiv:2401.12947v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dylan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tigges_C/0/1/0/all/0/1">Curt Tigges</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zory Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1">Stella Biderman</a>, <a href="http://arxiv.org/find/cs/1/au:+Raginsky_M/0/1/0/all/0/1">Maxim Raginsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ringer_T/0/1/0/all/0/1">Talia Ringer</a></p>
<p>This paper investigates the ability of transformer-based models to learn
structural recursion from examples. Recursion is a universal concept in both
natural and formal languages. Structural recursion is central to the
programming language and formal mathematics tasks where symbolic tools
currently excel beyond neural models, such as inferring semantic relations
between datatypes and emulating program behavior. We introduce a general
framework that nicely connects the abstract concepts of structural recursion in
the programming language domain to concrete sequence modeling problems and
learned models' behavior. The framework includes a representation that captures
the general \textit{syntax} of structural recursion, coupled with two different
frameworks for understanding their \textit{semantics} -- one that is more
natural from a programming languages perspective and one that helps bridge that
perspective with a mechanistic understanding of the underlying transformer
architecture.
</p>
<p>With our framework as a powerful conceptual tool, we identify different
issues under various set-ups. The models trained to emulate recursive
computations cannot fully capture the recursion yet instead fit short-cut
algorithms and thus cannot solve certain edge cases that are under-represented
in the training distribution. In addition, it is difficult for state-of-the-art
large language models (LLMs) to mine recursive rules from in-context
demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating
reduction (step-wise computation) of the recursive function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12954">Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding. (arXiv:2401.12954v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Suzgun_M/0/1/0/all/0/1">Mirac Suzgun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1">Adam Tauman Kalai</a></p>
<p>We introduce meta-prompting, an effective scaffolding technique designed to
enhance the functionality of language models (LMs). This approach transforms a
single LM into a multi-faceted conductor, adept at managing and integrating
multiple independent LM queries. By employing high-level instructions,
meta-prompting guides the LM to break down complex tasks into smaller, more
manageable subtasks. These subtasks are then handled by distinct "expert"
instances of the same LM, each operating under specific, tailored instructions.
Central to this process is the LM itself, in its role as the conductor, which
ensures seamless communication and effective integration of the outputs from
these expert models. It additionally employs its inherent critical thinking and
robust verification processes to refine and authenticate the end result. This
collaborative prompting approach empowers a single LM to simultaneously act as
a comprehensive orchestrator and a panel of diverse experts, significantly
enhancing its performance across a wide array of tasks. The zero-shot,
task-agnostic nature of meta-prompting greatly simplifies user interaction by
obviating the need for detailed, task-specific instructions. Furthermore, our
research demonstrates the seamless integration of external tools, such as a
Python interpreter, into the meta-prompting framework, thereby broadening its
applicability and utility. Through rigorous experimentation with GPT-4, we
establish the superiority of meta-prompting over conventional scaffolding
methods: When averaged across all tasks, including the Game of 24,
Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented
with a Python interpreter functionality, surpasses standard prompting by 17.1%,
expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.12963">AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents. (arXiv:2401.12963v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahn_M/0/1/0/all/0/1">Michael Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1">Debidatta Dwibedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Arenas_M/0/1/0/all/0/1">Montse Gonzalez Arenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1">Keerthana Gopalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1">Karol Hausman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1">Brian Ichter</a>, <a href="http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1">Alex Irpan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nikhil Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1">Ryan Julian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirmani_S/0/1/0/all/0/1">Sean Kirmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_I/0/1/0/all/0/1">Isabel Leal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Edward Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_I/0/1/0/all/0/1">Isabel Leal</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddineni_S/0/1/0/all/0/1">Sharath Maddineni</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1">Kanishka Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1">Dorsa Sadigh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanketi_P/0/1/0/all/0/1">Pannag Sanketi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1">Pierre Sermanet</a>, <a href="http://arxiv.org/find/cs/1/au:+Vuong_Q/0/1/0/all/0/1">Quan Vuong</a>, <a href="http://arxiv.org/find/cs/1/au:+Welker_S/0/1/0/all/0/1">Stefan Welker</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Ted Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Steve Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhuo Xu</a></p>
<p>Foundation models that incorporate language, vision, and more recently
actions have revolutionized the ability to harness internet scale data to
reason about useful tasks. However, one of the key challenges of training
embodied foundation models is the lack of data grounded in the physical world.
In this paper, we propose AutoRT, a system that leverages existing foundation
models to scale up the deployment of operational robots in completely unseen
scenarios with minimal human supervision. AutoRT leverages vision-language
models (VLMs) for scene understanding and grounding, and further uses large
language models (LLMs) for proposing diverse and novel instructions to be
performed by a fleet of robots. Guiding data collection by tapping into the
knowledge of foundation models enables AutoRT to effectively reason about
autonomy tradeoffs and safety while significantly scaling up data collection
for robot learning. We demonstrate AutoRT proposing instructions to over 20
robots across multiple buildings and collecting 77k real robot episodes via
both teleoperation and autonomous robot policies. We experimentally show that
such "in-the-wild" data collected by AutoRT is significantly more diverse, and
that AutoRT's use of LLMs allows for instruction following data collection
robots that can align to human preferences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2102.04107">An extended Knowledge Compilation Map for Conditional Preference Statements-based and Generalized Additive Utilities-based Languages. (arXiv:2102.04107v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fargier_H/0/1/0/all/0/1">H&#xe9;l&#xe8;ne Fargier</a> (IRIT-ADRIA), <a href="http://arxiv.org/find/cs/1/au:+Mengel_S/0/1/0/all/0/1">Stefan Mengel</a> (CRIL), <a href="http://arxiv.org/find/cs/1/au:+Mengin_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Mengin</a> (IRIT-ADRIA)</p>
<p>Conditional preference statements have been used to compactly represent
preferences over combinatorial domains. They are at the core of CP-nets and
their generalizations, and lexicographic preference trees. Several works have
addressed the complexity of some queries (optimization, dominance in
particular). We extend in this paper some of these results, and study other
queries which have not been addressed so far, like equivalence, and
transformations, like conditioning and variable elimination, thereby
contributing to a knowledge compilation map for languages based on conditional
preference statements. We also study the expressiveness and complexity of
queries and transformations for generalized additive utilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.11334">Generalized Out-of-Distribution Detection: A Survey. (arXiv:2110.11334v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a></p>
<p>Out-of-distribution (OOD) detection is critical to ensuring the reliability
and safety of machine learning systems. For instance, in autonomous driving, we
would like the driving system to issue an alert and hand over the control to
humans when it detects unusual scenes or objects that it has never seen during
training time and cannot make a safe decision. The term, OOD detection, first
emerged in 2017 and since then has received increasing attention from the
research community, leading to a plethora of methods developed, ranging from
classification-based to density-based to distance-based ones. Meanwhile,
several other problems, including anomaly detection (AD), novelty detection
(ND), open set recognition (OSR), and outlier detection (OD), are closely
related to OOD detection in terms of motivation and methodology. Despite common
goals, these topics develop in isolation, and their subtle differences in
definition and problem setting often confuse readers and practitioners. In this
survey, we first present a unified framework called generalized OOD detection,
which encompasses the five aforementioned problems, i.e., AD, ND, OSR, OOD
detection, and OD. Under our framework, these five problems can be seen as
special cases or sub-tasks, and are easier to distinguish. We then review each
of these five areas by summarizing their recent technical developments, with a
special focus on OOD detection methodologies. We conclude this survey with open
challenges and potential research directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.13883">Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities. (arXiv:2203.13883v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1">Sara Abdali</a></p>
<p>As social media platforms are evolving from text-based forums into
multi-modal environments, the nature of misinformation in social media is also
transforming accordingly. Taking advantage of the fact that visual modalities
such as images and videos are more favorable and attractive to the users and
textual contents are sometimes skimmed carelessly, misinformation spreaders
have recently targeted contextual connections between the modalities e.g., text
and image. Hence many researchers have developed automatic techniques for
detecting possible cross-modal discordance in web-based content. We analyze,
categorize and identify existing approaches in addition to challenges and
shortcomings they face in order to unearth new research opportunities in the
field of multi-modal misinformation detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.13743">Personalized Algorithmic Recourse with Preference Elicitation. (arXiv:2205.13743v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Toni_G/0/1/0/all/0/1">Giovanni De Toni</a>, <a href="http://arxiv.org/find/cs/1/au:+Viappiani_P/0/1/0/all/0/1">Paolo Viappiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1">Stefano Teso</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepri_B/0/1/0/all/0/1">Bruno Lepri</a>, <a href="http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1">Andrea Passerini</a></p>
<p>Algorithmic Recourse (AR) is the problem of computing a sequence of actions
that -- once performed by a user -- overturns an undesirable machine decision.
It is paramount that the sequence of actions does not require too much effort
for users to implement. Yet, most approaches to AR assume that actions cost the
same for all users, and thus may recommend unfairly expensive recourse plans to
certain users. Prompted by this observation, we introduce PEAR, the first
human-in-the-loop approach capable of providing personalized algorithmic
recourse tailored to the needs of any end-user. PEAR builds on insights from
Bayesian Preference Elicitation to iteratively refine an estimate of the costs
of actions by asking choice set queries to the target user. The queries
themselves are computed by maximizing the Expected Utility of Selection, a
principled measure of information gain accounting for uncertainty on both the
cost estimate and the user's responses. PEAR integrates elicitation into a
Reinforcement Learning agent coupled with Monte Carlo Tree Search to quickly
identify promising recourse plans. Our empirical evaluation on real-world
datasets highlights how PEAR produces high-quality personalized recourse in
only a handful of iterations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.02059">Empowering GNNs via Edge-Aware Weisfeiler-Leman Algorithm. (arXiv:2206.02059v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Haiyang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a></p>
<p>Message passing graph neural networks (GNNs) are known to have their
expressiveness upper-bounded by 1-dimensional Weisfeiler-Leman (1-WL)
algorithm. To achieve more powerful GNNs, existing attempts either require ad
hoc features, or involve operations that incur high time and space
complexities. In this work, we propose a general and provably powerful GNN
framework that preserves the scalability of the message passing scheme. In
particular, we first propose to empower 1-WL for graph isomorphism test by
considering edges among neighbors, giving rise to NC-1-WL. The expressiveness
of NC-1-WL is shown to be strictly above 1-WL and below 3-WL theoretically.
Further, we propose the NC-GNN framework as a differentiable neural version of
NC-1-WL. Our simple implementation of NC-GNN is provably as powerful as
NC-1-WL. Experiments demonstrate that our NC-GNN performs effectively and
efficiently on various benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.04883">Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsukamoto_H/0/1/0/all/0/1">Hiroyasu Tsukamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1">Soon-Jo Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Donitz_B/0/1/0/all/0/1">Benjamin Donitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingham_M/0/1/0/all/0/1">Michel Ingham</a>, <a href="http://arxiv.org/find/cs/1/au:+Mages_D/0/1/0/all/0/1">Declan Mages</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakka_Y/0/1/0/all/0/1">Yashwanth Kumar Nakka</a></p>
<p>Interstellar objects (ISOs) are likely representatives of primitive materials
invaluable in understanding exoplanetary star systems. Due to their poorly
constrained orbits with generally high inclinations and relative velocities,
however, exploring ISOs with conventional human-in-the-loop approaches is
significantly challenging. This paper presents Neural-Rendezvous, a deep
learning-based guidance and control framework for encountering fast-moving
objects, including ISOs, robustly, accurately, and autonomously in real time.
It uses pointwise minimum norm tracking control on top of a guidance policy
modeled by a spectrally-normalized deep neural network, where its
hyperparameters are tuned with a loss function directly penalizing the MPC
state trajectory tracking error. We show that Neural-Rendezvous provides a high
probability exponential bound on the expected spacecraft delivery error, the
proof of which leverages stochastic incremental stability analysis. In
particular, it is used to construct a non-negative function with a
supermartingale property, explicitly accounting for the ISO state uncertainty
and the local nature of nonlinear state estimation guarantees. In numerical
simulations, Neural-Rendezvous is demonstrated to satisfy the expected error
bound for 100 ISO candidates. This performance is also empirically validated
using our spacecraft simulator and in high-conflict and distributed UAV swarm
reconfiguration with up to 20 UAVs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.04631">The Normalized Cross Density Functional: A Framework to Quantify Statistical Dependence for Random Processes. (arXiv:2212.04631v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1">Jose C. Principe</a></p>
<p>This paper proposes a novel multivariate definition of statistical dependence
between two continuous random processes (r.p.) using a functional methodology
inspired by Alfr\'ed R\'enyi. The argument of the logarithm of mutual
information between pairs of samples of a r.p., named here the normalized cross
density (NCD), defines a symmetric and self-adjoint positive definite function.
We show that maximizing the alternating covariance estimation (ACE) recursion,
applied to each of the joint probability density of input sample pairs, obeys
all the properties of Renyi's maximal correlation. We propose the NCD's
eigenspectrum as a novel multivariate measure of the statistical dependence
between the input and output r.p.
</p>
<p>The multivariate statistical dependence can also be estimated directly from
r.p. realizations. The proposed functional maximum correlation algorithm (FMCA)
is applied to a machine learning architecture built from two neural networks
that learn concurrently by approximating each others' outputs. We prove that
the FMCA optimal solution is an equilibrium point that estimates the
eigenspectrum of the cross density kernel. Preliminary results with synthetic
data and medium size image datasets corroborate the theory. Four different
strategies of applying the cross density kernel are proposed and thoroughly
discussed to show the versatility and stability of the methodology, which
transcends supervised learning. More specifically, when the two random
processes are high-dimensional real-world images and a white uniform noise
process, the algorithm learns a factorial code i.e., the occurrence of a code
guarantees that a certain input in the training image set was present, which is
quite important for feature learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.12970">Refined Edge Usage of Graph Neural Networks for Edge Prediction. (arXiv:2212.12970v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiarui Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yangkun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Q/0/1/0/all/0/1">Quan Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xiang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1">David Wipf</a></p>
<p>Graph Neural Networks (GNNs), originally proposed for node classification,
have also motivated many recent works on edge prediction (a.k.a., link
prediction). However, existing methods lack elaborate design regarding the
distinctions between two tasks that have been frequently overlooked: (i) edges
only constitute the topology in the node classification task but can be used as
both the topology and the supervisions (i.e., labels) in the edge prediction
task; (ii) the node classification makes prediction over each individual node,
while the edge prediction is determinated by each pair of nodes. To this end,
we propose a novel edge prediction paradigm named Edge-aware Message PassIng
neuRal nEtworks (EMPIRE). Concretely, we first introduce an edge splitting
technique to specify use of each edge where each edge is solely used as either
the topology or the supervision (named as topology edge or supervision edge).
We then develop a new message passing mechanism that generates the messages to
source nodes (through topology edges) being aware of target nodes (through
supervision edges). In order to emphasize the differences between pairs
connected by supervision edges and pairs unconnected, we further weight the
messages to highlight the relative ones that can reflect the differences. In
addition, we design a novel negative node-pair sampling trick that efficiently
samples 'hard' negative instances in the supervision instances, and can
significantly improve the performance. Experimental results verify that the
proposed method can significantly outperform existing state-of-the-art models
regarding the edge prediction task on multiple homogeneous and heterogeneous
graph datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.07846">Sample-efficient Adversarial Imitation Learning. (arXiv:2303.07846v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1">Dahuin Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyungyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a></p>
<p>Imitation learning, in which learning is performed by demonstration, has been
studied and advanced for sequential decision-making tasks in which a reward
function is not predefined. However, imitation learning methods still require
numerous expert demonstration samples to successfully imitate an expert's
behavior. To improve sample efficiency, we utilize self-supervised
representation learning, which can generate vast training signals from the
given data. In this study, we propose a self-supervised representation-based
adversarial imitation learning method to learn state and action representations
that are robust to diverse distortions and temporally predictive, on non-image
control tasks. In particular, in comparison with existing self-supervised
learning methods for tabular data, we propose a different corruption method for
state and action representations that is robust to diverse distortions. We
theoretically and empirically observe that making an informative feature
manifold with less sample complexity significantly improves the performance of
imitation learning. The proposed method shows a 39% relative improvement over
existing adversarial imitation learning methods on MuJoCo in a setting limited
to 100 expert state-action pairs. Moreover, we conduct comprehensive ablations
and additional experiments using demonstrations with varying optimality to
provide insights into a range of factors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06470">Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes. (arXiv:2304.06470v5 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Borji_A/0/1/0/all/0/1">Ali Borji</a></p>
<p>The ability of image and video generation models to create photorealistic
images has reached unprecedented heights, making it difficult to distinguish
between real and fake images in many cases. However, despite this progress, a
gap remains between the quality of generated images and those found in the real
world. To address this, we have reviewed a vast body of literature from both
academic publications and social media to identify qualitative shortcomings in
image generation models, which we have classified into five categories. By
understanding these failures, we can identify areas where these models need
improvement, as well as develop strategies for detecting deep fakes. The
prevalence of deep fakes in today's society is a serious concern, and our
findings can help mitigate their negative impact.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09970">Learning policies for resource allocation in business processes. (arXiv:2304.09970v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Middelhuis_J/0/1/0/all/0/1">J. Middelhuis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianco_R/0/1/0/all/0/1">R. Lo Bianco</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherzer_E/0/1/0/all/0/1">E. Scherzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukhsh_Z/0/1/0/all/0/1">Z. A. Bukhsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Adan_I/0/1/0/all/0/1">I. J. B. F. Adan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijkman_R/0/1/0/all/0/1">R. M. Dijkman</a></p>
<p>Efficient allocation of resources to activities is pivotal in executing
business processes but remains challenging. While resource allocation
methodologies are well-established in domains like manufacturing, their
application within business process management remains limited. Existing
methods often do not scale well to large processes with numerous activities or
optimize across multiple cases. This paper aims to address this gap by
proposing two learning-based methods for resource allocation in business
processes. The first method leverages Deep Reinforcement Learning (DRL) to
learn near-optimal policies by taking action in the business process. The
second method is a score-based value function approximation approach, which
learns the weights of a set of curated features to prioritize resource
assignments. To evaluate the proposed approaches, we first designed six
distinct business processes with archetypal process flows and characteristics.
These business processes were then connected to form three realistically sized
business processes. We benchmarked our methods against traditional heuristics
and existing resource allocation methods. The results show that our methods
learn adaptive resource allocation policies that outperform or are competitive
with the benchmarks in five out of six individual business processes. The DRL
approach outperforms all benchmarks in all three composite business processes
and finds a policy that is, on average, 13.1% better than the best-performing
benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.14391">Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v4 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gkanatsios_N/0/1/0/all/0/1">Nikolaos Gkanatsios</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ayush Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Xian_Z/0/1/0/all/0/1">Zhou Xian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunchu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Atkeson_C/0/1/0/all/0/1">Christopher Atkeson</a>, <a href="http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1">Katerina Fragkiadaki</a></p>
<p>Language is compositional; an instruction can express multiple relation
constraints to hold among objects in a scene that a robot is tasked to
rearrange. Our focus in this work is an instructable scene-rearranging
framework that generalizes to longer instructions and to spatial concept
compositions never seen at training time. We propose to represent
language-instructed spatial concepts with energy functions over relative object
arrangements. A language parser maps instructions to corresponding energy
functions and an open-vocabulary visual-language model grounds their arguments
to relevant objects in the scene. We generate goal scene configurations by
gradient descent on the sum of energy functions, one per language predicate in
the instruction. Local vision-based policies then re-locate objects to the
inferred goal locations. We test our model on established instruction-guided
manipulation benchmarks, as well as benchmarks of compositional instructions we
introduce. We show our model can execute highly compositional instructions
zero-shot in simulation and in the real world. It outperforms
language-to-action reactive policies and Large Language Model planners by a
large margin, especially for long instructions that involve compositions of
multiple spatial concepts. Simulation and real-world robot execution videos, as
well as our code and datasets are publicly available on our website:
https://ebmplanner.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13208">Iterative Adversarial Attack on Image-guided Story Ending Generation. (arXiv:2305.13208v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Youze Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenbo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_R/0/1/0/all/0/1">Richang Hong</a></p>
<p>Multimodal learning involves developing models that can integrate information
from various sources like images and texts. In this field, multimodal text
generation is a crucial aspect that involves processing data from multiple
modalities and outputting text. The image-guided story ending generation
(IgSEG) is a particularly significant task, targeting on an understanding of
complex relationships between text and image data with a complete story text
ending. Unfortunately, deep neural networks, which are the backbone of recent
IgSEG models, are vulnerable to adversarial samples. Current adversarial attack
methods mainly focus on single-modality data and do not analyze adversarial
attacks for multimodal text generation tasks that use cross-modal information.
To this end, we propose an iterative adversarial attack method
(Iterative-attack) that fuses image and text modality attacks, allowing for an
attack search for adversarial text and image in an more effective iterative
way. Experimental results demonstrate that the proposed method outperforms
existing single-modal and non-iterative multimodal attack methods, indicating
the potential for improving the adversarial robustness of multimodal text
generation models, such as multimodal machine translation, multimodal question
answering, etc.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14259">Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1">Doug Downey</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a></p>
<p>Literature-Based Discovery (LBD) aims to discover new scientific knowledge by
mining papers and generating hypotheses. Standard LBD is limited to predicting
pairwise relations between discrete concepts (e.g., drug-disease links), and
ignores critical contexts like experimental settings (e.g., a specific patient
population where a drug is evaluated) and background motivations (e.g., to find
drugs without specific side effects). We address these limitations with a novel
formulation of contextualized-LBD (C-LBD): generating scientific hypotheses in
natural language, while grounding them in a context that controls the
hypothesis search space. We present a modeling framework using retrieval of
``inspirations'' from past scientific papers. Our evaluations reveal that GPT-4
tends to generate ideas with overall low technical depth and novelty, while our
inspiration prompting approaches partially mitigate this issue. Our work
represents a first step toward building language models that generate new ideas
derived from scientific literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02869">Data-Driven Online Model Selection With Regret Guarantees. (arXiv:2306.02869v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Dann_C/0/1/0/all/0/1">Christoph Dann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gentile_C/0/1/0/all/0/1">Claudio Gentile</a></p>
<p>We consider model selection for sequential decision making in stochastic
environments with bandit feedback, where a meta-learner has at its disposal a
pool of base learners, and decides on the fly which action to take based on the
policies recommended by each base learner. Model selection is performed by
regret balancing but, unlike the recent literature on this subject, we do not
assume any prior knowledge about the base learners like candidate regret
guarantees; instead, we uncover these quantities in a data-driven manner. The
meta-learner is therefore able to leverage the realized regret incurred by each
base learner for the learning environment at hand (as opposed to the expected
regret), and single out the best such regret. We design two model selection
algorithms operating with this more ambitious notion of regret and, besides
proving model selection guarantees via regret balancing, we experimentally
demonstrate the compelling practical benefits of dealing with actual regrets
instead of candidate regret bounds.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09549">QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules. (arXiv:2306.09549v3 [physics.chem-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Yu_H/0/1/0/all/0/1">Haiyang Yu</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/physics/1/au:+Strasser_A/0/1/0/all/0/1">Alex Strasser</a>, <a href="http://arxiv.org/find/physics/1/au:+Qian_X/0/1/0/all/0/1">Xiaofeng Qian</a>, <a href="http://arxiv.org/find/physics/1/au:+Qian_X/0/1/0/all/0/1">Xiaoning Qian</a>, <a href="http://arxiv.org/find/physics/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a></p>
<p>Supervised machine learning approaches have been increasingly used in
accelerating electronic structure prediction as surrogates of first-principle
computational methods, such as density functional theory (DFT). While numerous
quantum chemistry datasets focus on chemical properties and atomic forces, the
ability to achieve accurate and efficient prediction of the Hamiltonian matrix
is highly desired, as it is the most important and fundamental physical
quantity that determines the quantum states of physical systems and chemical
properties. In this work, we generate a new Quantum Hamiltonian dataset, named
as QH9, to provide precise Hamiltonian matrices for 999 molecular dynamics
trajectories and 130,831 stable molecular geometries, based on the QM9 dataset.
By designing benchmark tasks with various molecules, we show that current
machine learning models have the capacity to predict Hamiltonian matrices for
arbitrary molecules. Both the QH9 dataset and the baseline models are provided
to the community through an open-source benchmark, which can be highly valuable
for developing machine learning methods and accelerating molecular and
materials design for scientific and technological applications. Our benchmark
is publicly available at
https://github.com/divelab/AIRS/tree/main/OpenDFT/QHBench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00384">CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis. (arXiv:2307.00384v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alshantti_A/0/1/0/all/0/1">Abdallah Alshantti</a>, <a href="http://arxiv.org/find/cs/1/au:+Varagnolo_D/0/1/0/all/0/1">Damiano Varagnolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_A/0/1/0/all/0/1">Adil Rasheed</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmati_A/0/1/0/all/0/1">Aria Rahmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Westad_F/0/1/0/all/0/1">Frank Westad</a></p>
<p>Generative adversarial networks (GANs) have drawn considerable attention in
recent years for their proven capability in generating synthetic data which can
be utilised for multiple purposes. While GANs have demonstrated tremendous
successes in producing synthetic data samples that replicate the dynamics of
the original datasets, the validity of the synthetic data and the underlying
privacy concerns represent major challenges which are not sufficiently
addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN)
for generating realistic tabular data with a specific focus on the validity of
the output. In this context, validity refers to the the dependency between
features that can be found in the real data, but is typically misrepresented by
traditional generative models. Our key idea entails that employing a cascaded
architecture in which a dedicated generator samples each feature, the synthetic
output becomes more representative of the real data. Our experimental results
demonstrate that our model is capable of generating synthetic tabular data that
can be used for fitting machine learning models. In addition, our model
captures well the constraints and the correlations between the features of the
real data, especially the high dimensional datasets. Furthermore, we evaluate
the risk of white-box privacy attacks on our model and subsequently show that
applying some perturbations to the auxiliary learners in CasTGAN increases the
overall robustness of our model against targeted attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03212">Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings. (arXiv:2307.03212v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1">Weiliang Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Q/0/1/0/all/0/1">Qianqian Ren</a></p>
<p>Urban region embedding is an important and yet highly challenging issue due
to the complexity and constantly changing nature of urban data. To address the
challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER)
to capture multi-view dependencies and learn expressive representations of
urban regions without the constraints of rigid neighbourhood region conditions.
Our model focus on learn urban region representation from multi-source urban
data. First, we capture the multi-view correlations from mobility flow
patterns, POI semantics and check-in dynamics. Then, we adopt global graph
attention networks to learn similarity of any two vertices in graphs. To
comprehensively consider and share features of multiple views, a two-stage
fusion module is further proposed to learn weights with external attention to
fuse multi-view embeddings. Extensive experiments for two downstream tasks on
real-world datasets demonstrate that our model outperforms state-of-the-art
methods by up to 17\% improvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10487">Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees. (arXiv:2308.10487v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1">Lue Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Xuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wang-Zhou Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuan Jiang</a></p>
<p>Neuro-symbolic hybrid systems are promising for integrating machine learning
and symbolic reasoning, where perception models are facilitated with
information inferred from a symbolic knowledge base through logical reasoning.
Despite empirical evidence showing the ability of hybrid systems to learn
accurate perception models, the theoretical understanding of learnability is
still lacking. Hence, it remains unclear why a hybrid system succeeds for a
specific task and when it may fail given a different knowledge base. In this
paper, we introduce a novel way of characterising supervision signals from a
knowledge base, and establish a criterion for determining the knowledge's
efficacy in facilitating successful learning. This, for the first time, allows
us to address the two questions above by inspecting the knowledge base under
investigation. Our analysis suggests that many knowledge bases satisfy the
criterion, thus enabling effective learning, while some fail to satisfy it,
indicating potential failures. Comprehensive experiments confirm the utility of
our criterion on benchmark tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.11477">An improved column-generation-based matheuristic for learning classification trees. (arXiv:2308.11477v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1">Krunal Kishor Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Desaulniers_G/0/1/0/all/0/1">Guy Desaulniers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1">Andrea Lodi</a></p>
<p>Decision trees are highly interpretable models for solving classification
problems in machine learning (ML). The standard ML algorithms for training
decision trees are fast but generate suboptimal trees in terms of accuracy.
Other discrete optimization models in the literature address the optimality
problem but only work well on relatively small datasets. \cite{firat2020column}
proposed a column-generation-based heuristic approach for learning decision
trees. This approach improves scalability and can work with large datasets. In
this paper, we describe improvements to this column generation approach. First,
we modify the subproblem model to significantly reduce the number of
subproblems in multiclass classification instances. Next, we show that the
data-dependent constraints in the master problem are implied, and use them as
cutting planes. Furthermore, we describe a separation model to generate data
points for which the linear programming relaxation solution violates their
corresponding constraints. We conclude by presenting computational results that
show that these modifications result in better scalability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.11624">Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks. (arXiv:2308.11624v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_G/0/1/0/all/0/1">Guangxi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Leilai Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_K/0/1/0/all/0/1">Kain Lu Low</a></p>
<p>An innovative methodology that leverages artificial intelligence (AI) and
graph representation for semiconductor device encoding in TCAD device
simulation is proposed. A graph-based universal encoding scheme is presented
that not only considers material-level and device-level embeddings, but also
introduces a novel spatial relationship embedding inspired by interpolation
operations typically used in finite element meshing. Universal physical laws
from device simulations are leveraged for comprehensive data-driven modeling,
which encompasses surrogate Poisson emulation and current-voltage (IV)
prediction based on drift-diffusion model. Both are achieved using a novel
graph attention network, referred to as RelGAT. Comprehensive technical details
based on the device simulator Sentaurus TCAD are presented, empowering
researchers to adopt the proposed AI-driven Electronic Design Automation (EDA)
solution at the device level.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12890">Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1">David Oniani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1">Jordan Hilsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1">Fengyi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1">Shiven Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanshan Wang</a></p>
<p>The emergence of generative Large Language Models (LLMs) emphasizes the need
for accurate and efficient prompting approaches. LLMs are often applied in
Few-Shot Learning (FSL) contexts, where tasks are executed with minimal
training data. FSL has become popular in many Artificial Intelligence (AI)
subdomains, including AI for health. Rare diseases affect a small fraction of
the population. Rare disease identification from clinical notes inherently
requires FSL techniques due to limited data availability. Manual data
collection and annotation is both expensive and time-consuming. In this paper,
we propose Models-Vote Prompting (MVP), a flexible prompting approach for
improving the performance of LLM queries in FSL settings. MVP works by
prompting numerous LLMs to perform the same tasks and then conducting a
majority vote on the resulting outputs. This method achieves improved results
to any one model in the ensemble on one-shot rare disease identification and
classification tasks. We also release a novel rare disease dataset for FSL,
available to those who signed the MIMIC-IV Data Use Agreement (DUA).
Furthermore, in using MVP, each model is prompted multiple times, substantially
increasing the time needed for manual annotation, and to address this, we
assess the feasibility of using JSON for automating generative LLM evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.14190">Score-Based Generative Models for PET Image Reconstruction. (arXiv:2308.14190v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Singh_I/0/1/0/all/0/1">Imraj RD Singh</a>, <a href="http://arxiv.org/find/eess/1/au:+Denker_A/0/1/0/all/0/1">Alexander Denker</a>, <a href="http://arxiv.org/find/eess/1/au:+Barbano_R/0/1/0/all/0/1">Riccardo Barbano</a>, <a href="http://arxiv.org/find/eess/1/au:+Kereta_Z/0/1/0/all/0/1">&#x17d;eljko Kereta</a>, <a href="http://arxiv.org/find/eess/1/au:+Jin_B/0/1/0/all/0/1">Bangti Jin</a>, <a href="http://arxiv.org/find/eess/1/au:+Thielemans_K/0/1/0/all/0/1">Kris Thielemans</a>, <a href="http://arxiv.org/find/eess/1/au:+Maass_P/0/1/0/all/0/1">Peter Maass</a>, <a href="http://arxiv.org/find/eess/1/au:+Arridge_S/0/1/0/all/0/1">Simon Arridge</a></p>
<p>Score-based generative models have demonstrated highly promising results for
medical image reconstruction tasks in magnetic resonance imaging or computed
tomography. However, their application to Positron Emission Tomography (PET) is
still largely unexplored. PET image reconstruction involves a variety of
challenges, including Poisson noise with high variance and a wide dynamic
range. To address these challenges, we propose several PET-specific adaptations
of score-based generative models. The proposed framework is developed for both
2D and 3D PET. In addition, we provide an extension to guided reconstruction
using magnetic resonance images. We validate the approach through extensive 2D
and 3D $\textit{in-silico}$ experiments with a model trained on
patient-realistic data without lesions, and evaluate on data without lesions as
well as out-of-distribution data with lesions. This demonstrates the proposed
method's robustness and significant potential for improved PET reconstruction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.14284">Prompt to Transfer: Sim-to-Real Transfer for Traffic Signal Control with Prompt Learning. (arXiv:2308.14284v6 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Da_L/0/1/0/all/0/1">Longchao Da</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1">Minquan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1">Hao Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Hua Wei</a></p>
<p>Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks
aiming to provide efficient transportation and mitigate congestion waste. In
recent, promising results have been attained by Reinforcement Learning (RL)
methods through trial and error in simulators, bringing confidence in solving
cities' congestion headaches. However, there still exist performance gaps when
simulator-trained policies are deployed to the real world. This issue is mainly
introduced by the system dynamic difference between the training simulator and
the real-world environments. The Large Language Models (LLMs) are trained on
mass knowledge and proved to be equipped with astonishing inference abilities.
In this work, we leverage LLMs to understand and profile the system dynamics by
a prompt-based grounded action transformation. Accepting the cloze prompt
template, and then filling in the answer based on accessible context, the
pre-trained LLM's inference ability is exploited and applied to understand how
weather conditions, traffic states, and road types influence traffic dynamics,
being aware of this, the policies' action is taken and grounded based on
realistic dynamics, thus help the agent learn a more realistic policy. We
conduct experiments using DQN to show the effectiveness of the proposed
PromptGAT's ability in mitigating the performance gap from simulation to
reality (sim-to-real).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.06801">Defensive Alliances in Signed Networks. (arXiv:2309.06801v2 [cs.CC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arrighi_E/0/1/0/all/0/1">Emmanuel Arrighi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhidan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernau_H/0/1/0/all/0/1">Henning Fernau</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_K/0/1/0/all/0/1">Kevin Mann</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xingqin Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_P/0/1/0/all/0/1">Petra Wolf</a></p>
<p>The analysis of (social) networks and multi-agent systems is a central theme
in Artificial Intelligence. Some line of research deals with finding groups of
agents that could work together to achieve a certain goal. To this end,
different notions of so-called clusters or communities have been introduced in
the literature of graphs and networks. Among these, defensive alliance is a
kind of quantitative group structure. However, all studies on the alliance so
for have ignored one aspect that is central to the formation of alliances on a
very intuitive level, assuming that the agents are preconditioned concerning
their attitude towards other agents: they prefer to be in some group (alliance)
together with the agents they like, so that they are happy to help each other
towards their common aim, possibly then working against the agents outside of
their group that they dislike. Signed networks were introduced in the
psychology literature to model liking and disliking between agents,
generalizing graphs in a natural way. Hence, we propose the novel notion of a
defensive alliance in the context of signed networks. We then investigate
several natural algorithmic questions related to this notion. These, and also
combinatorial findings, connect our notion to that of correlation clustering,
which is a well-established idea of finding groups of agents within a signed
network. Also, we introduce a new structural parameter for signed graphs,
signed neighborhood diversity snd, and exhibit a parameterized algorithm that
finds a smallest defensive alliance in a signed graph.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.09552">A Multitask Training Approach to Enhance Whisper with Contextual Biasing and Open-Vocabulary Keyword Spotting. (arXiv:2309.09552v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yinglu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1">Mengxin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1">Xiaosong Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiaofeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Piao_M/0/1/0/all/0/1">Mengyao Piao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiawei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xinglin Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Miaomiao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yanqing Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a></p>
<p>End-to-end automatic speech recognition (ASR) systems often struggle to
recognize rare name entities, such as personal names, organizations, and
terminologies not frequently encountered in the training data. This paper
presents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on
OpenAI's Whisper model that can recognize user-defined name entities by
performing open-vocabulary keyword-spotting (OV-KWS) using the hidden states of
Whisper encoder. The recognized entities are used as prompts for the Whisper
decoder. We first propose a multitask training approach with OV-KWS and ASR
tasks to optimize the model. Experiments show that this approach substantially
improves the entity recalls compared to the original Whisper model on Chinese
Aishell hot word subsets and two internal code-switch test sets. However, we
observed a slight increase in mixed-error-rate (MER) on internal test sets due
to catastrophic forgetting. To address this problem and use different sizes of
the Whisper model without finetuning, we propose to use OV-KWS as a separate
module and construct a spoken form prompt to prevent hallucination. The OV-KWS
module consistently improves MER and Entity Recall for whisper-small, medium,
and large models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10016">Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction. (arXiv:2309.10016v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shaika Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaganapathy_S/0/1/0/all/0/1">Sivaraman Rajaganapathy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerhan_J/0/1/0/all/0/1">James Cerhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_N/0/1/0/all/0/1">Nansu Zong</a></p>
<p>In this study, we investigated the potential of GPT-3 for the anti-cancer
drug sensitivity prediction task using structured pharmacogenomics data across
five tissue types and evaluated its performance with zero-shot prompting and
fine-tuning paradigms. The drug's smile representation and cell line's genomic
mutation features were predictive of the drug response. The results from this
study have the potential to pave the way for designing more efficient treatment
protocols in precision oncology.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.16606">&quot;AI enhances our performance, I have no doubt this one will do the same&quot;: The Placebo effect is robust to negative descriptions of AI. (arXiv:2309.16606v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kloft_A/0/1/0/all/0/1">Agnes M. Kloft</a>, <a href="http://arxiv.org/find/cs/1/au:+Welsch_R/0/1/0/all/0/1">Robin Welsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosch_T/0/1/0/all/0/1">Thomas Kosch</a>, <a href="http://arxiv.org/find/cs/1/au:+Villa_S/0/1/0/all/0/1">Steeven Villa</a></p>
<p>Heightened AI expectations facilitate performance in human-AI interactions
through placebo effects. While lowering expectations to control for placebo
effects is advisable, overly negative expectations could induce nocebo effects.
In a letter discrimination task, we informed participants that an AI would
either increase or decrease their performance by adapting the interface, but in
reality, no AI was present in any condition. A Bayesian analysis showed that
participants had high expectations and performed descriptively better
irrespective of the AI description when a sham-AI was present. Using cognitive
modeling, we could trace this advantage back to participants gathering more
information. A replication study verified that negative AI descriptions do not
alter expectations, suggesting that performance expectations with AI are biased
and robust to negative verbal descriptions. We discuss the impact of user
expectations on AI interactions and evaluation and provide a behavioral placebo
marker for human-AI interaction
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00737">GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models. (arXiv:2310.00737v3 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1">Emilio Ferrara</a></p>
<p>Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)
are marvels of technology; celebrated for their prowess in natural language
processing and multimodal content generation, they promise a transformative
future. But as with all powerful tools, they come with their shadows. Picture
living in a world where deepfakes are indistinguishable from reality, where
synthetic identities orchestrate malicious campaigns, and where targeted
misinformation or scams are crafted with unparalleled precision. Welcome to the
darker side of GenAI applications. This article is not just a journey through
the meanders of potential misuse of GenAI and LLMs, but also a call to
recognize the urgency of the challenges ahead. As we navigate the seas of
misinformation campaigns, malicious content generation, and the eerie creation
of sophisticated malware, we'll uncover the societal implications that ripple
through the GenAI revolution we are witnessing. From AI-powered botnets on
social media platforms to the unnerving potential of AI to generate fabricated
identities, or alibis made of synthetic realities, the stakes have never been
higher. The lines between the virtual and the real worlds are blurring, and the
consequences of potential GenAI's nefarious applications impact us all. This
article serves both as a synthesis of rigorous research presented on the risks
of GenAI and misuse of LLMs and as a thought-provoking vision of the different
types of harmful GenAI applications we might encounter in the near future, and
some ways we can prepare for them.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.03025">Retrieval meets Long Context Large Language Models. (arXiv:2310.03025v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xianchao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1">Lawrence McAfee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_S/0/1/0/all/0/1">Sandeep Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakhturina_E/0/1/0/all/0/1">Evelina Bakhturina</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a></p>
<p>Extending the context window of large language models (LLMs) is getting
popular recently, while the solution of augmenting LLMs with retrieval has
existed for years. The natural questions are: i) Retrieval-augmentation versus
long context window, which one is better for downstream tasks? ii) Can both
methods be combined to get the best of both worlds? In this work, we answer
these questions by studying both solutions using two state-of-the-art
pretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps
surprisingly, we find that LLM with 4K context window using simple
retrieval-augmentation at generation can achieve comparable performance to
finetuned LLM with 16K context window via positional interpolation on long
context tasks, while taking much less computation. More importantly, we
demonstrate that retrieval can significantly improve the performance of LLMs
regardless of their extended context window sizes. Our best model,
retrieval-augmented Llama2-70B with 32K context window, outperforms
GPT-3.5-turbo-16k and Davinci003 in terms of average score on nine long context
tasks including question answering, query-based summarization, and in-context
few-shot learning tasks. It also outperforms its non-retrieval Llama2-70B-32k
baseline by a margin, while being much faster at generation. Our study provides
general insights on the choice of retrieval-augmentation versus long context
extension of LLM for practitioners.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05207">Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction. (arXiv:2310.05207v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shang_Z/0/1/0/all/0/1">Ziqiao Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Li Yu</a></p>
<p>Recently how to introduce large amounts of unlabeled facial images in the
wild into supervised Facial Action Unit (AU) detection frameworks has become a
challenging problem. In this paper, we propose a new AU detection framework
where multi-task learning is introduced to jointly learn AU domain separation
and reconstruction and facial landmark detection by sharing the parameters of
homostructural facial extraction modules. In addition, we propose a new feature
alignment scheme based on contrastive learning by simple projectors and an
improved contrastive loss, which adds four additional intermediate supervisors
to promote the feature reconstruction process. Experimental results on two
benchmarks demonstrate our superiority against the state-of-the-art methods for
AU detection in the wild.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08276">Direction-Oriented Visual-semantic Embedding Model for Remote Sensing Image-text Retrieval. (arXiv:2310.08276v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1">Qing Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jiancheng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_C/0/1/0/all/0/1">Cong Bai</a></p>
<p>Image-text retrieval has developed rapidly in recent years. However, it is
still a challenge in remote sensing due to visual-semantic imbalance, which
leads to incorrect matching of non-semantic visual and textual features. To
solve this problem, we propose a novel Direction-Oriented Visual-semantic
Embedding Model (DOVE) to mine the relationship between vision and language.
Our highlight is to conduct visual and textual representations in latent space,
directing them as close as possible to a redundancy-free regional visual
representation. Concretely, a Regional-Oriented Attention Module (ROAM)
adaptively adjusts the distance between the final visual and textual embeddings
in the latent semantic space, oriented by regional visual features. Meanwhile,
a lightweight Digging Text Genome Assistant (DTGA) is designed to expand the
range of tractable textual representation and enhance global word-level
semantic connections using less attention operations. Ultimately, we exploit a
global visual-semantic constraint to reduce single visual dependency and serve
as an external constraint for the final visual and textual representations. The
effectiveness and superiority of our method are verified by extensive
experiments including parameter evaluation, quantitative comparison, ablation
studies and visual analysis, on two benchmark datasets, RSICD and RSITMD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08535">Formally Specifying the High-Level Behavior of LLM-Based Agents. (arXiv:2310.08535v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1">Maxwell Crouse</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1">Ibrahim Abdelaziz</a>, <a href="http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1">Ramon Astudillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_K/0/1/0/all/0/1">Kinjal Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1">Soham Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumaravel_S/0/1/0/all/0/1">Sadhana Kumaravel</a>, <a href="http://arxiv.org/find/cs/1/au:+Fokoue_A/0/1/0/all/0/1">Achille Fokoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1">Pavan Kapanipathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1">Salim Roukos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lastras_L/0/1/0/all/0/1">Luis Lastras</a></p>
<p>Autonomous, goal-driven agents powered by LLMs have recently emerged as
promising tools for solving challenging problems without the need for
task-specific finetuned models that can be expensive to procure. Currently, the
design and implementation of such agents is ad hoc, as the wide variety of
tasks that LLM-based agents may be applied to naturally means there can be no
one-size-fits-all approach to agent design. In this work we aim to alleviate
the difficulty of designing and implementing new agents by proposing a
minimalistic generation framework that simplifies the process of building
agents. The framework we introduce allows the user to define desired agent
behaviors in a high-level, declarative specification that is then used to
construct a decoding monitor which guarantees the LLM will produce an output
exhibiting the desired behavior. Our declarative approach, in which the
behavior is described without concern for how it should be implemented or
enforced, enables rapid design, implementation, and experimentation with
different LLM-based agents. We demonstrate how the proposed framework can be
used to implement recent LLM-based agents (e.g., ReACT), and show how the
flexibility of our approach can be leveraged to define a new agent with more
complex behavior, the Plan-Act-Summarize-Solve (PASS) agent. Lastly, we
demonstrate that our method outperforms other agents on multiple popular
reasoning-centric question-answering benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.13712">Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception. (arXiv:2310.13712v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_H/0/1/0/all/0/1">Harsh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Musabirov_I/0/1/0/all/0/1">Ilya Musabirov</a>, <a href="http://arxiv.org/find/cs/1/au:+Reza_M/0/1/0/all/0/1">Mohi Reza</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiakai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Joseph Jay Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzminykh_A/0/1/0/all/0/1">Anastasia Kuzminykh</a>, <a href="http://arxiv.org/find/cs/1/au:+Liut_M/0/1/0/all/0/1">Michael Liut</a></p>
<p>Personalized chatbot-based teaching assistants can be crucial in addressing
increasing classroom sizes, especially where direct teacher presence is
limited. Large language models (LLMs) offer a promising avenue, with increasing
research exploring their educational utility. However, the challenge lies not
only in establishing the efficacy of LLMs but also in discerning the nuances of
interaction between learners and these models, which impact learners'
engagement and results. We conducted a formative study in an undergraduate
computer science classroom (N=145) and a controlled experiment on Prolific
(N=356) to explore the impact of four pedagogically informed guidance
strategies on the learners' performance, confidence and trust in LLMs. Direct
LLM answers marginally improved performance, while refining student solutions
fostered trust. Structured guidance reduced random queries as well as instances
of students copy-pasting assignment questions to the LLM. Our work highlights
the role that teachers can play in shaping LLM-supported learning environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15318">HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks. (arXiv:2310.15318v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yihong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_N/0/1/0/all/0/1">Ning Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiayu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mortazavi_M/0/1/0/all/0/1">Masood Mortazavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1">Nitesh V. Chawla</a></p>
<p>Graphs have emerged as a natural choice to represent and analyze the
intricate patterns and rich information of the Web, enabling applications such
as online page classification and social recommendation. The prevailing
"pre-train, fine-tune" paradigm has been widely adopted in graph machine
learning tasks, particularly in scenarios with limited labeled nodes. However,
this approach often exhibits a misalignment between the training objectives of
pretext tasks and those of downstream tasks. This gap can result in the
"negative transfer" problem, wherein the knowledge gained from pre-training
adversely affects performance in the downstream tasks. The surge in
prompt-based learning within Natural Language Processing (NLP) suggests the
potential of adapting a "pre-train, prompt" paradigm to graphs as an
alternative. However, existing graph prompting techniques are tailored to
homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To
bridge this gap, we propose HetGPT, a general post-training prompting framework
to improve the predictive performance of pre-trained heterogeneous graph neural
networks (HGNNs). The key is the design of a novel prompting function that
integrates a virtual class prompt and a heterogeneous feature prompt, with the
aim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT
introduces a multi-view neighborhood aggregation mechanism, capturing the
complex neighborhood structure in heterogeneous graphs. Extensive experiments
on three benchmark datasets demonstrate HetGPT's capability to enhance the
performance of state-of-the-art HGNNs on semi-supervised node classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.17715">Outlier Dimensions Encode Task-Specific Knowledge. (arXiv:2310.17715v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rudman_W/0/1/0/all/0/1">William Rudman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Catherine Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a></p>
<p>Representations from large language models (LLMs) are known to be dominated
by a small subset of dimensions with exceedingly high variance. Previous works
have argued that although ablating these outlier dimensions in LLM
representations hurts downstream performance, outlier dimensions are
detrimental to the representational quality of embeddings. In this study, we
investigate how fine-tuning impacts outlier dimensions and show that 1) outlier
dimensions that occur in pre-training persist in fine-tuned models and 2) a
single outlier dimension can complete downstream tasks with a minimal error
rate. Our results suggest that outlier dimensions can encode crucial
task-specific knowledge and that the value of a representation in a single
outlier dimension drives downstream model decisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18304">A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chengpiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaizheng Wang</a></p>
<p>We develop a versatile framework for statistical learning in non-stationary
environments. In each time period, our approach applies a stability principle
to select a look-back window that maximizes the utilization of historical data
while keeping the cumulative bias within an acceptable range relative to the
stochastic error. Our theory showcases the adaptability of this approach to
unknown non-stationarity. The regret bound is minimax optimal up to logarithmic
factors when the population losses are strongly convex, or Lipschitz only. At
the heart of our analysis lie two novel components: a measure of similarity
between functions and a segmentation technique for dividing the non-stationary
data sequence into quasi-stationary pieces.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.02099">A Safe Preference Learning Approach for Personalization with Applications to Autonomous Vehicles. (arXiv:2311.02099v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Karagulle_R/0/1/0/all/0/1">Ruya Karagulle</a>, <a href="http://arxiv.org/find/cs/1/au:+Arechiga_N/0/1/0/all/0/1">Nikos Arechiga</a>, <a href="http://arxiv.org/find/cs/1/au:+Best_A/0/1/0/all/0/1">Andrew Best</a>, <a href="http://arxiv.org/find/cs/1/au:+DeCastro_J/0/1/0/all/0/1">Jonathan DeCastro</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozay_N/0/1/0/all/0/1">Necmiye Ozay</a></p>
<p>This work introduces a preference learning method that ensures adherence to
given specifications, with an application to autonomous vehicles. Our approach
incorporates the priority ordering of Signal Temporal Logic (STL) formulas
describing traffic rules into a learning framework. By leveraging Parametric
Weighted Signal Temporal Logic (PWSTL), we formulate the problem of
safety-guaranteed preference learning based on pairwise comparisons and propose
an approach to solve this learning problem. Our approach finds a feasible
valuation for the weights of the given PWSTL formula such that, with these
weights, preferred signals have weighted quantitative satisfaction measures
greater than their non-preferred counterparts. The feasible valuation of
weights given by our approach leads to a weighted STL formula that can be used
in correct-and-custom-by-construction controller synthesis. We demonstrate the
performance of our method with a pilot human subject study in two different
simulated driving scenarios involving a stop sign and a pedestrian crossing.
Our approach yields competitive results compared to existing preference
learning methods in terms of capturing preferences, and notably outperforms
them when safety is considered.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13884">Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach. (arXiv:2311.13884v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Hangyu Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_J/0/1/0/all/0/1">Jingqing Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Ying Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dapeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziyue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Rui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lijuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_G/0/1/0/all/0/1">Guoliang Fan</a></p>
<p>The remarkable progress in Large Language Models (LLMs) opens up new avenues
for addressing planning and decision-making problems in Multi-Agent Systems
(MAS). However, as the number of agents increases, the issues of hallucination
in LLMs and coordination in MAS have become increasingly prominent.
Additionally, the efficient utilization of tokens emerges as a critical
consideration when employing LLMs to facilitate the interactions among a
substantial number of agents. In this paper, we develop a modular framework
called LLaMAC to mitigate these challenges. LLaMAC implements a value
distribution encoding similar to that found in the human brain, utilizing
internal and external feedback mechanisms to facilitate collaboration and
iterative reasoning among its modules. Through evaluations involving system
resource allocation and robot grid transportation, we demonstrate the
considerable advantages afforded by our proposed approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16716">GraphPro: Graph Pre-training and Prompt Learning for Recommendation. (arXiv:2311.16716v4 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1">Lianghao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1">Da Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kangyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a></p>
<p>GNN-based recommenders have excelled in modeling intricate user-item
interactions through multi-hop message passing. However, existing methods often
overlook the dynamic nature of evolving user-item interactions, which impedes
the adaption to changing user preferences and distribution shifts in newly
arriving data. Thus, their scalability and performances in real-world dynamic
environments are limited. In this study, we propose GraphPro, a framework that
incorporates parameter-efficient and dynamic graph pre-training with prompt
learning. This novel combination empowers GNNs to effectively capture both
long-term user preferences and short-term behavior dynamics, enabling the
delivery of accurate and timely recommendations. Our GraphPro framework
addresses the challenge of evolving user preferences by seamlessly integrating
a temporal prompt mechanism and a graph-structural prompt learning mechanism
into the pre-trained GNN model. The temporal prompt mechanism encodes time
information on user-item interaction, allowing the model to naturally capture
temporal context, while the graph-structural prompt learning mechanism enables
the transfer of pre-trained knowledge to adapt to behavior dynamics without the
need for continuous incremental training. We further bring in a dynamic
evaluation setting for recommendation to mimic real-world dynamic scenarios and
bridge the offline-online gap to a better level. Our extensive experiments
including a large-scale industrial deployment showcases the lightweight plug-in
scalability of our GraphPro when integrated with various state-of-the-art
recommenders, emphasizing the advantages of GraphPro in terms of effectiveness,
robustness and efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01185">A ripple in time: a discontinuity in American history. (arXiv:2312.01185v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kolpakov_A/0/1/0/all/0/1">Alexander Kolpakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivin_I/0/1/0/all/0/1">Igor Rivin</a></p>
<p>In this note we use the State of the Union Address (SOTU) dataset from Kaggle
to make some surprising (and some not so surprising) observations pertaining to
the general timeline of American history, and the character and nature of the
addresses themselves. Our main approach is using vector embeddings, such as
BERT (DistilBERT) and GPT-2.
</p>
<p>While it is widely believed that BERT (and its variations) is most suitable
for NLP classification tasks, we find out that GPT-2 in conjunction with
nonlinear dimension reduction methods such as UMAP provide better separation
and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In
our case, no model fine-tuning is required, and the pre-trained out-of-the-box
GPT-2 model is enough.
</p>
<p>We also used a fine-tuned DistilBERT model for classification detecting which
President delivered which address, with very good results (accuracy 93% - 95%
depending on the run). An analogous task was performed to determine the year of
writing, and we were able to pin it down to about 4 years (which is a single
presidential term).
</p>
<p>It is worth noting that SOTU addresses provide relatively small writing
samples (with about 8'000 words on average, and varying widely from under 2'000
words to more than 20'000), and that the number of authors is relatively large
(we used SOTU addresses of 42 US presidents). This shows that the techniques
employed turn out to be rather efficient, while all the computations described
in this note can be performed using a single GPU instance of Google Colab.
</p>
<p>The accompanying code is available on GitHub.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.02246">Conditional Variational Diffusion Models. (arXiv:2312.02246v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maggiora_G/0/1/0/all/0/1">Gabriel della Maggiora</a>, <a href="http://arxiv.org/find/cs/1/au:+Croquevielle_L/0/1/0/all/0/1">Luis Alberto Croquevielle</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_N/0/1/0/all/0/1">Nikita Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Horsley_H/0/1/0/all/0/1">Harry Horsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinis_T/0/1/0/all/0/1">Thomas Heinis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yakimovich_A/0/1/0/all/0/1">Artur Yakimovich</a></p>
<p>Inverse problems aim to determine parameters from observations, a crucial
task in engineering and science. Lately, generative models, especially
diffusion models, have gained popularity in this area for their ability to
produce realistic solutions and their good mathematical properties. Despite
their success, an important drawback of diffusion models is their sensitivity
to the choice of variance schedule, which controls the dynamics of the
diffusion process. Fine-tuning this schedule for specific applications is
crucial but time-costly and does not guarantee an optimal result. We propose a
novel approach for learning the schedule as part of the training process. Our
method supports probabilistic conditioning on data, provides high-quality
solutions, and is flexible, proving able to adapt to different applications
with minimum overhead. This approach is tested in two unrelated inverse
problems: super-resolution microscopy and quantitative phase imaging, yielding
comparable or superior results to previous methods and fine-tuned diffusion
models. We conclude that fine-tuning the schedule by experimentation should be
avoided because it can be learned during training in a stable way that yields
better results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12433">Tracking Any Object Amodally. (arXiv:2312.12433v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cheng-Yen Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Khurana_T/0/1/0/all/0/1">Tarasha Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1">Achal Dave</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a></p>
<p>Amodal perception, the ability to comprehend complete object structures from
partial visibility, is a fundamental skill, even for infants. Its significance
extends to applications like autonomous driving, where a clear understanding of
heavily occluded objects is essential. However, modern detection and tracking
algorithms often overlook this critical capability, perhaps due to the
prevalence of modal annotations in most datasets. To address the scarcity of
amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse
categories in thousands of video sequences. Our dataset includes amodal and
modal bounding boxes for visible and occluded objects, including objects that
are partially out-of-frame. To enhance amodal tracking with object permanence,
we leverage a lightweight plug-in module, the amodal expander, to transform
standard, modal trackers into amodal ones through fine-tuning on a few hundred
video sequences with data augmentation. We achieve a 3.3\% and 1.6\%
improvement on the detection and tracking of occluded objects on TAO-Amodal.
When evaluated on people, our method produces dramatic improvements of 2x
compared to state-of-the-art modal baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14794">An Empirical Study on Compliance with Ranking Transparency in the Software Documentation of EU Online Platforms. (arXiv:2312.14794v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sovrano_F/0/1/0/all/0/1">Francesco Sovrano</a>, <a href="http://arxiv.org/find/cs/1/au:+Lognoul_M/0/1/0/all/0/1">Micha&#xeb;l Lognoul</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacchelli_A/0/1/0/all/0/1">Alberto Bacchelli</a></p>
<p>Compliance with the European Union's Platform-to-Business (P2B) Regulation is
challenging for online platforms, and assessing their compliance can be
difficult for public authorities. This is partly due to the lack of automated
tools for assessing the information (e.g., software documentation) platforms
provide concerning ranking transparency. Our study tackles this issue in two
ways. First, we empirically evaluate the compliance of six major platforms
(Amazon, Bing, Booking, Google, Tripadvisor, and Yahoo), revealing substantial
differences in their documentation. Second, we introduce and test automated
compliance assessment tools based on ChatGPT and information retrieval
technology. These tools are evaluated against human judgments, showing
promising results as reliable proxies for compliance assessments. Our findings
could help enhance regulatory compliance and align with the United Nations
Sustainable Development Goal 10.3, which seeks to reduce inequality, including
business disparities, on these platforms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.01651">AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI. (arXiv:2401.01651v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1">Fanda Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chunjie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wanling Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1">Jianfeng Zhan</a></p>
<p>The burgeoning field of Artificial Intelligence Generated Content (AIGC) is
witnessing rapid advancements, particularly in video generation. This paper
introduces AIGCBench, a pioneering comprehensive and scalable benchmark
designed to evaluate a variety of video generation tasks, with a primary focus
on Image-to-Video (I2V) generation. AIGCBench tackles the limitations of
existing benchmarks, which suffer from a lack of diverse datasets, by including
a varied and open-domain image-text dataset that evaluates different
state-of-the-art algorithms under equivalent conditions. We employ a novel text
combiner and GPT-4 to create rich text prompts, which are then used to generate
images via advanced Text-to-Image models. To establish a unified evaluation
framework for video generation tasks, our benchmark includes 11 metrics
spanning four dimensions to assess algorithm performance. These dimensions are
control-video alignment, motion effects, temporal consistency, and video
quality. These metrics are both reference video-dependent and video-free,
ensuring a comprehensive evaluation strategy. The evaluation standard proposed
correlates well with human judgment, providing insights into the strengths and
weaknesses of current I2V algorithms. The findings from our extensive
experiments aim to stimulate further research and development in the I2V field.
AIGCBench represents a significant step toward creating standardized benchmarks
for the broader AIGC landscape, proposing an adaptable and equitable framework
for future assessments of video generation tasks. We have open-sourced the
dataset and evaluation code on the project website:
https://www.benchcouncil.org/AIGCBench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.02994">Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaoding Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zongyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1">Adian Liusie</a>, <a href="http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1">Vyas Raina</a>, <a href="http://arxiv.org/find/cs/1/au:+Mudupalli_V/0/1/0/all/0/1">Vineet Mudupalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Beauchamp_W/0/1/0/all/0/1">William Beauchamp</a></p>
<p>In conversational AI research, there's a noticeable trend towards developing
models with a larger number of parameters, exemplified by models like ChatGPT.
While these expansive models tend to generate increasingly better chat
responses, they demand significant computational resources and memory. This
study explores a pertinent question: Can a combination of smaller models
collaboratively achieve comparable or enhanced performance relative to a
singular large model? We introduce an approach termed "blending", a
straightforward yet effective method of integrating multiple chat AIs. Our
empirical evidence suggests that when specific smaller models are
synergistically blended, they can potentially outperform or match the
capabilities of much larger counterparts. For instance, integrating just three
models of moderate size (6B/13B paramaeters) can rival or even surpass the
performance metrics of a substantially larger model like ChatGPT (175B+
paramaters). This hypothesis is rigorously tested using A/B testing
methodologies with a large user base on the Chai research platform over a span
of thirty days. The findings underscore the potential of the "blending"
strategy as a viable approach for enhancing chat AI efficacy without a
corresponding surge in computational demands.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04867">An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue Systems. (arXiv:2401.04867v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Koji Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Lala_D/0/1/0/all/0/1">Divesh Lala</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochi_K/0/1/0/all/0/1">Keiko Ochi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1">Tatsuya Kawahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Skantze_G/0/1/0/all/0/1">Gabriel Skantze</a></p>
<p>Establishing evaluation schemes for spoken dialogue systems is important, but
it can also be challenging. While subjective evaluations are commonly used in
user experiments, objective evaluations are necessary for research comparison
and reproducibility. To address this issue, we propose a framework for
indirectly but objectively evaluating systems based on users' behaviors. In
this paper, to this end, we investigate the relationship between user behaviors
and subjective evaluation scores in social dialogue tasks: attentive listening,
job interview, and first-meeting conversation. The results reveal that in
dialogue tasks where user utterances are primary, such as attentive listening
and job interview, indicators like the number of utterances and words play a
significant role in evaluation. Observing disfluency also can indicate the
effectiveness of formal tasks, such as job interview. On the other hand, in
dialogue tasks with high interactivity, such as first-meeting conversation,
behaviors related to turn-taking, like average switch pause length, become more
important. These findings suggest that selecting appropriate user behaviors can
provide valuable insights for objective evaluation in each social dialogue
task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06827">APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning. (arXiv:2401.06827v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_G/0/1/0/all/0/1">Guiming Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Kaize Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Hong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huaiwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guandong Xu</a></p>
<p>Pre-trained Vision-Language (V-L) models set the benchmark for generalization
to downstream tasks among the noteworthy contenders. Many characteristics of
the V-L model have been explored in existing research including the challenge
of the sensitivity to text input and the tuning process across multi-modal
prompts. With the advanced utilization of the V-L model like CLIP, recent
approaches deploy learnable prompts instead of hand-craft prompts to boost the
generalization performance and address the aforementioned challenges. Inspired
by layer-wise training, which is wildly used in image fusion, we note that
using a sequential training process to adapt different modalities branches of
CLIP efficiently facilitates the improvement of generalization. In the context
of addressing the multi-modal prompting challenge, we propose Token-wise
Adaptive for Multi-modal Prompt Learning (APLe) for tuning both modalities
prompts, vision and language, as tokens in a sequential manner. APLe addresses
the challenges in V-L models to promote prompt learning across both modalities,
which indicates a competitive generalization performance in line with the
state-of-the-art. Preeminently, APLe shows robustness and favourable
performance in prompt-length experiments with an absolute advantage in adopting
the V-L models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07709">Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks. (arXiv:2401.07709v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1">Siyu Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiji Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yiyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jing He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chaoyi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rongsheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiaoshuai Sun</a></p>
<p>Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which
often applies a semantic mask to control the target area for diffusion-based
editing. However, most existing solutions obtain these masks via manual
operations or off-line processing, greatly reducing their efficiency. In this
paper, we propose a novel and efficient image editing method for Text-to-Image
(T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In
particular, InstDiffEdit aims to employ the cross-modal attention ability of
existing diffusion models to achieve instant mask guidance during the diffusion
steps. To reduce the noise of attention maps and realize the full automatics,
we equip InstDiffEdit with a training-free refinement scheme to adaptively
aggregate the attention distributions for the automatic yet accurate mask
generation. Meanwhile, to supplement the existing evaluations of DIE, we
propose a new benchmark called Editing-Mask to examine the mask accuracy and
local editing ability of existing methods. To validate InstDiffEdit, we also
conduct extensive experiments on ImageNet and Imagen, and compare it with a
bunch of the SOTA methods. The experimental results show that InstDiffEdit not
only outperforms the SOTA methods in both image quality and editing results,
but also has a much faster inference speed, i.e., +5 to +6 times.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08517">Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring. (arXiv:2401.08517v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abu_Rasheed_H/0/1/0/all/0/1">Hasan Abu-Rasheed</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdulsalam_M/0/1/0/all/0/1">Mohamad Hussam Abdulsalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1">Christian Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathi_M/0/1/0/all/0/1">Madjid Fathi</a></p>
<p>Student commitment towards a learning recommendation is not separable from
their understanding of the reasons it was recommended to them; and their
ability to modify it based on that understanding. Among explainability
approaches, chatbots offer the potential to engage the student in a
conversation, similar to a discussion with a peer or a mentor. The capabilities
of chatbots, however, are still not sufficient to replace a human mentor,
despite the advancements of generative AI (GenAI) and large language models
(LLM). Therefore, we propose an approach to utilize chatbots as mediators of
the conversation and sources of limited and controlled generation of
explanations, to harvest the potential of LLMs while reducing their potential
risks at the same time. The proposed LLM-based chatbot supports students in
understanding learning-paths recommendations. We use a knowledge graph (KG) as
a human-curated source of information, to regulate the LLM's output through
defining its prompt's context. A group chat approach is developed to connect
students with human mentors, either on demand or in cases that exceed the
chatbot's pre-defined tasks. We evaluate the chatbot with a user study, to
provide a proof-of-concept and highlight the potential requirements and
limitations of utilizing chatbots in conversational explainability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09479">Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning. (arXiv:2401.09479v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vishwakarma_R/0/1/0/all/0/1">Rahul Vishwakarma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaei_A/0/1/0/all/0/1">Amin Rezaei</a></p>
<p>The risk of hardware Trojans being inserted at various stages of chip
production has increased in a zero-trust fabless era. To counter this, various
machine learning solutions have been developed for the detection of hardware
Trojans. While most of the focus has been on either a statistical or deep
learning approach, the limited number of Trojan-infected benchmarks affects the
detection accuracy and restricts the possibility of detecting zero-day Trojans.
To close the gap, we first employ generative adversarial networks to amplify
our data in two alternative representation modalities, a graph and a tabular,
ensuring that the dataset is distributed in a representative manner. Further,
we propose a multimodal deep learning approach to detect hardware Trojans and
evaluate the results from both early fusion and late fusion strategies. We also
estimate the uncertainty quantification metrics of each prediction for
risk-aware decision-making. The outcomes not only confirms the efficacy of our
proposed hardware Trojan detection method but also opens a new door for future
studies employing multimodality and uncertainty quantification to address other
hardware security challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10225">ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1">Rajarshi Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chankyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a></p>
<p>In this work, we introduce ChatQA, a family of conversational question
answering (QA) models that obtain GPT-4 level accuracies. Specifically, we
propose a two-stage instruction tuning method that can significantly improve
the zero-shot conversational QA results from large language models (LLMs). To
handle retrieval-augmented generation in conversational QA, we fine-tune a
dense retriever on a multi-turn QA dataset, which provides comparable results
to using the state-of-the-art query rewriting model while largely reducing
deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of
average score on 10 conversational QA datasets (54.14 vs. 53.90), without
relying on any synthetic data from OpenAI GPT models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11624">In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Man Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1">Panupong Pasupat</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1">Mehran Kazemi</a></p>
<p>Language models, especially pre-trained large language models, have showcased
remarkable abilities as few-shot in-context learners (ICL), adept at adapting
to new tasks with just a few demonstrations in the input context. However, the
model's ability to perform ICL is sensitive to the choice of the few-shot
demonstrations. Instead of using a fixed set of demonstrations, one recent
development is to retrieve demonstrations tailored to each input query. The
implementation of demonstration retrieval is relatively straightforward,
leveraging existing databases and retrieval systems. This not only improves the
efficiency and scalability of the learning process but also has been shown to
reduce biases inherent in manual example selection. In light of the encouraging
results and growing research in ICL with retrieved demonstrations, we conduct
an extensive review of studies in this area. In this survey, we discuss and
compare different design choices for retrieval models, retrieval training
procedures, and inference algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11748">GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?. (arXiv:2401.11748v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+sun_Y/0/1/0/all/0/1">Yu sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_G/0/1/0/all/0/1">Gaojian Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xianxun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kailang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jian Cui</a></p>
<p>Deep gradient inversion attacks expose a serious threat to Federated Learning
(FL) by accurately recovering private data from shared gradients. However, the
state-of-the-art heavily relies on impractical assumptions to access excessive
auxiliary data, which violates the basic data partitioning principle of FL. In
this paper, a novel method, Gradient Inversion Attack using Practical Image
Prior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits
anomaly detection models to capture the underlying distribution from fewer
data, while GAN-based methods consume significant more data to synthesize
images. The extracted distribution is then leveraged to regulate the attack
process as Anomaly Score loss. Experimental results show that GI-PIP achieves a
16.12 dB PSNR recovery using only 3.8% data of ImageNet, while GAN-based
methods necessitate over 70%. Moreover, GI-PIP exhibits superior capability on
distribution generalization compared to GAN-based methods. Our approach
significantly alleviates the auxiliary data requirement on both amount and
distribution in gradient inversion attacks, hence posing more substantial
threat to real-world FL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11792">Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations. (arXiv:2401.11792v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zuojin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">YongQiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianyu Chen</a></p>
<p>An intelligent driving system should be capable of dynamically formulating
appropriate driving strategies based on the current environment and vehicle
status, while ensuring the security and reliability of the system. However,
existing methods based on reinforcement learning and imitation learning suffer
from low safety, poor generalization, and inefficient sampling. Additionally,
they cannot accurately predict future driving trajectories, and the accurate
prediction of future driving trajectories is a precondition for making optimal
decisions. To solve these problems, in this paper, we introduce a Safe and
Generalized end-to-end Autonomous Driving System (SGADS) for complex and
various scenarios. Our SGADS incorporates variational inference with
normalizing flows, enabling the intelligent vehicle to accurately predict
future driving trajectories. Moreover, we propose the formulation of robust
safety constraints. Furthermore, we combine reinforcement learning with
demonstrations to augment search process of the agent. The experimental results
demonstrate that our SGADS can significantly improve safety performance,
exhibit strong generalization, and enhance the training efficiency of
intelligent vehicles in complex urban scenarios compared to existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11851">BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge. (arXiv:2401.11851v2 [cs.AR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yuhao Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1">Chao Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongfeng Wang</a></p>
<p>Existing binary Transformers are promising in edge deployment due to their
compact model size, low computational complexity, and considerable inference
accuracy. However, deploying binary Transformers faces challenges on prior
processors due to inefficient execution of quantized matrix multiplication
(QMM) and the energy consumption overhead caused by multi-precision
activations. To tackle the challenges above, we first develop a computation
flow abstraction method for binary Transformers to improve QMM execution
efficiency by optimizing the computation order. Furthermore, a binarized
energy-efficient Transformer accelerator, namely BETA, is proposed to boost the
efficient deployment at the edge. Notably, BETA features a configurable QMM
engine, accommodating diverse activation precisions of binary Transformers and
offering high-parallelism and high-speed for QMMs with impressive energy
efficiency. Experimental results evaluated on ZCU102 FPGA show BETA achieves an
average energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than prior
FPGA-based accelerators, showing BETA's good potential for edge Transformer
acceleration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09994">Improving Urban Flood Prediction using LSTM-DeepLabv3+ and Bayesian Optimization with Spatiotemporal feature fusion. (arXiv:2304.09994v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Situ_Z/0/1/0/all/0/1">Zuxiang Situ</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_S/0/1/0/all/0/1">Shuai Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wanen Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gongfa Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qianqian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1">Guangtao Fu</a></p>
<p>Deep learning models have become increasingly popular for flood prediction
due to their superior accuracy and efficiency compared to traditional methods.
However, current machine learning methods often rely on separate spatial or
temporal feature analysis and have limitations on the types, number, and
dimensions of input data. This study presented a CNN-RNN hybrid feature fusion
modelling approach for urban flood prediction, which integrated the strengths
of CNNs in processing spatial features and RNNs in analyzing different
dimensions of time sequences. This approach allowed for both static and dynamic
flood predictions. Bayesian optimization was applied to identify the seven most
influential flood-driven factors and determine the best combination strategy.
By combining four CNNs (FCN, UNet, SegNet, DeepLabv3+) and three RNNs (LSTM,
BiLSTM, GRU), the optimal hybrid model was identified as LSTM-DeepLabv3+. This
model achieved the highest prediction accuracy (MAE, RMSE, NSE, and KGE were
0.007, 0.025, 0.973 and 0.755, respectively) under various rainfall input
conditions. Additionally, the processing speed was significantly improved, with
an inference time of 1.158s (approximately 1/125 of the traditional computation
time) compared to the physically-based models.
</p>
</p>
</div>

    </div>
    </body>
    