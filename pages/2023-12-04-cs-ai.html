<!DOCTYPE html>
<html>
<head>
<title>2023-12-04-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2311.17943">LayerCollapse: Adaptive compression of neural networks. (arXiv:2311.17943v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shabgahi_S/0/1/0/all/0/1">Soheil Zibakhsh Shabgahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shariff_M/0/1/0/all/0/1">Mohammad Soheil Shariff</a>, <a href="http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1">Farinaz Koushanfar</a></p>
<p>Handling the ever-increasing scale of contemporary deep learning and
transformer-based models poses a significant challenge. Although great strides
have been made in optimizing model compression techniques such as model
architecture search and knowledge distillation, the availability of data and
computational resources remains a considerable hurdle for these optimizations.
This paper introduces LayerCollapse, a novel alternative adaptive model
compression methodology. LayerCollapse works by eliminating non-linearities
within the network and collapsing two consecutive fully connected layers into a
single linear transformation. This approach simultaneously reduces both the
number of layers and the parameter count, thereby enhancing model efficiency.
We also introduce a compression aware regularizer, which compresses the model
in alignment with the dataset quality and model expressiveness, consequently
reducing overfitting across tasks. Our results demonstrate LayerCollapse's
effective compression and regularization capabilities in multiple fine-grained
classification benchmarks, achieving up to 74% post training compression with
minimal accuracy loss. We compare this method with knowledge distillation on
the same target network, showcasing a five-fold increase in computational
efficiency and 8% improvement in overall accuracy on the ImageNet dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17946">DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback. (arXiv:2311.17946v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1">Deqing Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yushi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Su Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rassin_R/0/1/0/all/0/1">Royi Rassin</a>, <a href="http://arxiv.org/find/cs/1/au:+Juan_D/0/1/0/all/0/1">Da-Cheng Juan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alon_D/0/1/0/all/0/1">Dana Alon</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrmann_C/0/1/0/all/0/1">Charles Herrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Steenkiste_S/0/1/0/all/0/1">Sjoerd van Steenkiste</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashtchian_C/0/1/0/all/0/1">Cyrus Rashtchian</a></p>
<p>Despite their wide-spread success, Text-to-Image models (T2I) still struggle
to produce images that are both aesthetically pleasing and faithful to the
user's input text. We introduce DreamSync, a model-agnostic training algorithm
by design that improves T2I models to be faithful to the text input. DreamSync
builds off a recent insight from TIFA's evaluation framework -- that large
vision-language models (VLMs) can effectively identify the fine-grained
discrepancies between generated images and the text inputs. DreamSync uses this
insight to train T2I models without any labeled data; it improves T2I models
using its own generations. First, it prompts the model to generate several
candidate images for a given input text. Then, it uses two VLMs to select the
best generation: a Visual Question Answering model that measures the alignment
of generated images to the text, and another that measures the generation's
aesthetic quality. After selection, we use LoRA to iteratively finetune the T2I
model to guide its generation towards the selected best generations. DreamSync
does not need any additional human annotation. model architecture changes, or
reinforcement learning. Despite its simplicity, DreamSync improves both the
semantic alignment and aesthetic appeal of two diffusion-based T2I models,
evidenced by multiple benchmarks (+1.7% on TIFA, +2.9% on DSG1K, +3.4% on VILA
aesthetic) and human evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17950">Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching. (arXiv:2311.17950v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1">Shitong Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zeyuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Muxin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xindong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhiqiang Shen</a></p>
<p>The lightweight "local-match-global" matching introduced by SRe2L
successfully creates a distilled dataset with comprehensive information on the
full 224x224 ImageNet-1k. However, this one-sided approach is limited to a
particular backbone, layer, and statistics, which limits the improvement of the
generalization of a distilled dataset. We suggest that sufficient and various
"local-match-global" matching are more precise and effective than a single one
and has the ability to create a distilled dataset with richer information and
better generalization. We call this perspective "generalized matching" and
propose Generalized Various Backbone and Statistical Matching (G-VBSM) in this
work, which aims to create a synthetic dataset with densities, ensuring
consistency with the complete dataset across various backbones, layers, and
statistics. As experimentally demonstrated, G-VBSM is the first algorithm to
obtain strong performance across both small-scale and large-scale datasets.
Specifically, G-VBSM achieves a performance of 38.7% on CIFAR-100 with
128-width ConvNet, 47.6% on Tiny-ImageNet with ResNet18, and 31.4% on the full
224x224 ImageNet-1k with ResNet18, under images per class (IPC) 10, 50, and 10,
respectively. These results surpass all SOTA methods by margins of 3.9%, 6.5%,
and 10.1%, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17958">CommunityAI: Towards Community-based Federated Learning. (arXiv:2311.17958v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Murturi_I/0/1/0/all/0/1">Ilir Murturi</a>, <a href="http://arxiv.org/find/cs/1/au:+Donta_P/0/1/0/all/0/1">Praveen Kumar Donta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dustdar_S/0/1/0/all/0/1">Schahram Dustdar</a></p>
<p>Federated Learning (FL) has emerged as a promising paradigm to train machine
learning models collaboratively while preserving data privacy. However, its
widespread adoption faces several challenges, including scalability,
heterogeneous data and devices, resource constraints, and security concerns.
Despite its promise, FL has not been specifically adapted for community
domains, primarily due to the wide-ranging differences in data types and
context, devices and operational conditions, environmental factors, and
stakeholders. In response to these challenges, we present a novel framework for
Community-based Federated Learning called CommunityAI. CommunityAI enables
participants to be organized into communities based on their shared interests,
expertise, or data characteristics. Community participants collectively
contribute to training and refining learning models while maintaining data and
participant privacy within their respective groups. Within this paper, we
discuss the conceptual architecture, system requirements, processes, and future
challenges that must be solved. Finally, our goal within this paper is to
present our vision regarding enabling a collaborative learning process within
various communities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17959">Transformer Based Model for Predicting Rapid Impact Compaction Outcomes: A Case Study of Utapao International Airport. (arXiv:2311.17959v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Youwai_S/0/1/0/all/0/1">Sompote Youwai</a>, <a href="http://arxiv.org/find/cs/1/au:+Detcheewa_S/0/1/0/all/0/1">Sirasak Detcheewa</a></p>
<p>This paper introduces a novel deep learning approach to predict the
engineering properties of the ground improved by Rapid Impact Compaction (RIC),
which is a ground improvement technique that uses a drop hammer to compact the
soil and fill layers. The proposed approach uses transformer-based neural
networks to capture the complex nonlinear relationships between the input
features, such as the hammer energy, drop height, and number of blows, and the
output variables, such as the cone resistance. The approach is applied to a
real-world dataset from a trial test section for the new apron construction of
the Utapao International Airport in Thailand. The results show that the
proposed approach outperforms the existing methods in terms of prediction
accuracy and efficiency and provides interpretable attention maps that reveal
the importance of different features for RIC prediction. The paper also
discusses the limitations and future directions of applying deep learning
methods to RIC prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17961">Skilful Precipitation Nowcasting Using NowcastNet. (arXiv:2311.17961v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Kumar_A/0/1/0/all/0/1">Ajitabh Kumar</a></p>
<p>Designing early warning system for precipitation requires accurate short-term
forecasting system. Climate change has led to an increase in frequency of
extreme weather events, and hence such systems can prevent disasters and loss
of life. Managing such events remain a challenge for both public and private
institutions. Precipitation nowcasting can help relevant institutions to better
prepare for such events as they impact agriculture, transport, public health
and safety, etc. Physics-based numerical weather prediction (NWP) is unable to
perform well for nowcasting because of large computational turn-around time.
Deep-learning based models on the other hand are able to give predictions
within seconds. We use recently proposed NowcastNet, a physics-conditioned deep
generative network, to forecast precipitation for different regions of Europe
using satellite images. Both spatial and temporal transfer learning is done by
forecasting for the unseen regions and year. Model makes realistic predictions
and is able to outperform baseline for such a prediction task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17968">Latent Alignment with Deep Set EEG Decoders. (arXiv:2311.17968v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Bakas_S/0/1/0/all/0/1">Stylianos Bakas</a>, <a href="http://arxiv.org/find/eess/1/au:+Ludwig_S/0/1/0/all/0/1">Siegfried Ludwig</a>, <a href="http://arxiv.org/find/eess/1/au:+Adamos_D/0/1/0/all/0/1">Dimitrios A. Adamos</a>, <a href="http://arxiv.org/find/eess/1/au:+Laskaris_N/0/1/0/all/0/1">Nikolaos Laskaris</a>, <a href="http://arxiv.org/find/eess/1/au:+Panagakis_Y/0/1/0/all/0/1">Yannis Panagakis</a>, <a href="http://arxiv.org/find/eess/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a></p>
<p>The variability in EEG signals between different individuals poses a
significant challenge when implementing brain-computer interfaces (BCI).
Commonly proposed solutions to this problem include deep learning models, due
to their increased capacity and generalization, as well as explicit domain
adaptation techniques. Here, we introduce the Latent Alignment method that won
the Benchmarks for EEG Transfer Learning (BEETL) competition and present its
formulation as a deep set applied on the set of trials from a given subject.
Its performance is compared to recent statistical domain adaptation techniques
under various conditions. The experimental paradigms include motor imagery
(MI), oddball event-related potentials (ERP) and sleep stage classification,
where different well-established deep learning models are applied on each task.
Our experimental results show that performing statistical distribution
alignment at later stages in a deep learning model is beneficial to the
classification accuracy, yielding the highest performance for our proposed
method. We further investigate practical considerations that arise in the
context of using deep learning and statistical alignment for EEG decoding. In
this regard, we study class-discriminative artifacts that can spuriously
improve results for deep learning models, as well as the impact of
class-imbalance on alignment. We delineate a trade-off relationship between
increased classification accuracy when alignment is performed at later modeling
stages, and susceptibility to class-imbalance in the set of trials that the
statistics are computed on.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17973">Homogeneous Artificial Neural Network. (arXiv:2311.17973v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Polyakov_A/0/1/0/all/0/1">Andrey Polyakov</a></p>
<p>The paper proposes an artificial neural network (ANN) being a global
approximator for a special class of functions, which are known as generalized
homogeneous. The homogeneity means a symmetry of a function with respect to a
group of transformations having topological characterization of a dilation. In
this paper, a class of the so-called linear dilations is considered. A
homogeneous universal approximation theorem is proven. Procedures for an
upgrade of an existing ANN to a homogeneous one are developed. Theoretical
results are supported by examples from the various domains (computer science,
systems theory and automatic control).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17983">Improving Faithfulness for Vision Transformers. (arXiv:2311.17983v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lijie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ninghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huai_M/0/1/0/all/0/1">Mengdi Huai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a></p>
<p>Vision Transformers (ViTs) have achieved state-of-the-art performance for
various vision tasks. One reason behind the success lies in their ability to
provide plausible innate explanations for the behavior of neural architectures.
However, ViTs suffer from issues with explanation faithfulness, as their focal
points are fragile to adversarial attacks and can be easily changed with even
slight perturbations on the input image. In this paper, we propose a rigorous
approach to mitigate these issues by introducing Faithful ViTs (FViTs). Briefly
speaking, an FViT should have the following two properties: (1) The top-$k$
indices of its self-attention vector should remain mostly unchanged under input
perturbation, indicating stable explanations; (2) The prediction distribution
should be robust to perturbations. To achieve this, we propose a new method
called Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing
and diffusion-based denoising. We theoretically prove that processing ViTs
directly with DDS can turn them into FViTs. We also show that Gaussian noise is
nearly optimal for both $\ell_2$ and $\ell_\infty$-norm cases. Finally, we
demonstrate the effectiveness of our approach through comprehensive experiments
and evaluations. Specifically, we compare our FViTs with other baselines
through visual interpretation and robustness accuracy under adversarial
attacks. Results show that FViTs are more robust against adversarial attacks
while maintaining the explainability of attention, indicating higher
faithfulness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18021">Understanding and Improving In-Context Learning on Vision-language Models. (arXiv:2311.18021v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhen Han</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bailan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1">Mark Buckley</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jindong Gu</a></p>
<p>Recently, in-context learning (ICL) on large language models (LLMs) has
received great attention, and this technique can also be applied to
vision-language models (VLMs) built upon LLMs. These VLMs can respond to
queries by conditioning responses on a series of multimodal demonstrations,
which comprise images, queries, and answers. Though ICL has been extensively
studied on LLMs, its research on VLMs remains limited. The inclusion of
additional visual information in the demonstrations motivates the following
research questions: which of the two modalities in the demonstration is more
significant? How can we select effective multimodal demonstrations to enhance
ICL performance? This study investigates the significance of both visual and
language information. Our findings indicate that ICL in VLMs is predominantly
driven by the textual information in the demonstrations whereas the visual
information in the demonstrations barely affects the ICL performance.
Subsequently, we provide an understanding of the findings by analyzing the
model information flow and comparing model inner states given different ICL
settings. Motivated by our analysis, we propose a simple yet effective
approach, termed Mixed Modality In-Context Example Selection (MMICES), which
considers both visual and language modalities when selecting demonstrations and
shows better ICL performance. Extensive experiments are conducted to support
our findings, understanding, and improvement of the ICL performance of VLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18022">A trainable manifold for accurate approximation with ReLU Networks. (arXiv:2311.18022v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Milkert_M/0/1/0/all/0/1">Max Milkert</a>, <a href="http://arxiv.org/find/cs/1/au:+Laine_F/0/1/0/all/0/1">Forrest Laine</a></p>
<p>We present a novel technique for exercising greater control of the weights of
ReLU activated neural networks to produce more accurate function
approximations. Many theoretical works encode complex operations into ReLU
networks using smaller base components. In these works, a common base component
is a constant width approximation to x^2, which has exponentially decaying
error with respect to depth. We extend this block to represent a greater range
of convex one-dimensional functions. We derive a manifold of weights such that
the output of these new networks utilizes exponentially many piecewise-linear
segments. This manifold guides their training process to overcome drawbacks
associated with random initialization and unassisted gradient descent. We train
these networks to approximate functions which do not necessarily lie on the
manifold, showing a significant reduction of error values over conventional
approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18028">Filtered Semi-Markov CRF. (arXiv:2311.18028v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zaratiana_U/0/1/0/all/0/1">Urchade Zaratiana</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomeh_N/0/1/0/all/0/1">Nadi Tomeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Khbir_N/0/1/0/all/0/1">Niama El Khbir</a>, <a href="http://arxiv.org/find/cs/1/au:+Holat_P/0/1/0/all/0/1">Pierre Holat</a>, <a href="http://arxiv.org/find/cs/1/au:+Charnois_T/0/1/0/all/0/1">Thierry Charnois</a></p>
<p>Semi-Markov CRF has been proposed as an alternative to the traditional Linear
Chain CRF for text segmentation tasks such as Named Entity Recognition (NER).
Unlike CRF, which treats text segmentation as token-level prediction, Semi-CRF
considers segments as the basic unit, making it more expressive. However,
Semi-CRF suffers from two major drawbacks: (1) quadratic complexity over
sequence length, as it operates on every span of the input sequence, and (2)
inferior performance compared to CRF for sequence labeling tasks like NER. In
this paper, we introduce Filtered Semi-Markov CRF, a variant of Semi-CRF that
addresses these issues by incorporating a filtering step to eliminate
irrelevant segments, reducing complexity and search space. Our approach is
evaluated on several NER benchmarks, where it outperforms both CRF and Semi-CRF
while being significantly faster. The implementation of our method is available
on \href{https://github.com/urchade/Filtered-Semi-Markov-CRF}{Github}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18029">A Bag of Receptive Fields for Time Series Extrinsic Predictions. (arXiv:2311.18029v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Spinnato_F/0/1/0/all/0/1">Francesco Spinnato</a>, <a href="http://arxiv.org/find/cs/1/au:+Guidotti_R/0/1/0/all/0/1">Riccardo Guidotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Monreale_A/0/1/0/all/0/1">Anna Monreale</a>, <a href="http://arxiv.org/find/cs/1/au:+Nanni_M/0/1/0/all/0/1">Mirco Nanni</a></p>
<p>High-dimensional time series data poses challenges due to its dynamic nature,
varying lengths, and presence of missing values. This kind of data requires
extensive preprocessing, limiting the applicability of existing Time Series
Classification and Time Series Extrinsic Regression techniques. For this
reason, we propose BORF, a Bag-Of-Receptive-Fields model, which incorporates
notions from time series convolution and 1D-SAX to handle univariate and
multivariate time series with varying lengths and missing values. We evaluate
BORF on Time Series Classification and Time Series Extrinsic Regression tasks
using the full UEA and UCR repositories, demonstrating its competitive
performance against state-of-the-art methods. Finally, we outline how this
representation can naturally provide saliency and feature-based explanations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18046">Making Data Work Count. (arXiv:2311.18046v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chandhiramowuli_S/0/1/0/all/0/1">Srravya Chandhiramowuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_A/0/1/0/all/0/1">Alex Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Heitlinger_S/0/1/0/all/0/1">Sara Heitlinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Ding Wang</a></p>
<p>In this paper, we examine the work of data annotation. Specifically, we focus
on the role of counting or quantification in organising annotation work. Based
on an ethnographic study of data annotation in two outsourcing centres in
India, we observe that counting practices and its associated logics are an
integral part of day-to-day annotation activities. In particular, we call
attention to the presumption of total countability observed in annotation - the
notion that everything, from tasks, datasets and deliverables, to workers, work
time, quality and performance, can be managed by applying the logics of
counting. To examine this, we draw on sociological and socio-technical
scholarship on quantification and develop the lens of a 'regime of counting'
that makes explicit the specific counts, practices, actors and structures that
underpin the pervasive counting in annotation. We find that within the AI
supply chain and data work, counting regimes aid the assertion of authority by
the AI clients (also called requesters) over annotation processes, constituting
them as reductive, standardised, and homogenous. We illustrate how this has
implications for i) how annotation work and workers get valued, ii) the role
human discretion plays in annotation, and iii) broader efforts to introduce
accountable and more just practices in AI. Through these implications, we
illustrate the limits of operating within the logic of total countability.
Instead, we argue for a view of counting as partial - located in distinct
geographies, shaped by specific interests and accountable in only limited ways.
This, we propose, sets the stage for a fundamentally different orientation to
counting and what counts in data annotation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18054">I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text. (arXiv:2311.18054v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Keles_K/0/1/0/all/0/1">Kaan Efe Kele&#x15f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurbuz_O/0/1/0/all/0/1">&#xd6;mer Kaan G&#xfc;rb&#xfc;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutlu_M/0/1/0/all/0/1">Mucahid Kutlu</a></p>
<p>Potential harms of Large Language Models such as mass misinformation and
plagiarism can be partially mitigated if there exists a reliable way to detect
machine generated text. In this paper, we propose a new watermarking method to
detect machine-generated texts. Our method embeds a unique pattern within the
generated text, ensuring that while the content remains coherent and natural to
human readers, it carries distinct markers that can be identified
algorithmically. Specifically, we intervene with the token sampling process in
a way which enables us to trace back our token choices during the detection
phase. We show how watermarking affects textual quality and compare our
proposed method with a state-of-the-art watermarking method in terms of
robustness and detectability. Through extensive experiments, we demonstrate the
effectiveness of our watermarking scheme in distinguishing between watermarked
and non-watermarked text, achieving high detection rates while maintaining
textual quality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18062">Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation. (arXiv:2311.18062v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xijia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yue Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Stepputtis_S/0/1/0/all/0/1">Simon Stepputtis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1">Katia Sycara</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_J/0/1/0/all/0/1">Joseph Campbell</a></p>
<p>Intelligent agents such as robots are increasingly deployed in real-world,
safety-critical settings. It is vital that these agents are able to explain the
reasoning behind their decisions to human counterparts; however, their behavior
is often produced by uninterpretable models such as deep neural networks. We
propose an approach to generate natural language explanations for an agent's
behavior based only on observations of states and actions, thus making our
method independent from the underlying model's representation. For such models,
we first learn a behavior representation and subsequently use it to produce
plausible explanations with minimal hallucination while affording user
interaction with a pre-trained large language model. We evaluate our method in
a multi-agent search-and-rescue environment and demonstrate the effectiveness
of our explanations for agents executing various behaviors. Through user
studies and empirical experiments, we show that our approach generates
explanations as helpful as those produced by a human domain expert while
enabling beneficial interactions such as clarification and counterfactual
queries.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18094">Self-Driving Telescopes: Autonomous Scheduling of Astronomical Observation Campaigns with Offline Reinforcement Learning. (arXiv:2311.18094v1 [astro-ph.IM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Terranova_F/0/1/0/all/0/1">Franco Terranova</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Voetberg_M/0/1/0/all/0/1">M. Voetberg</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1">Brian Nord</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Pagul_A/0/1/0/all/0/1">Amanda Pagul</a></p>
<p>Modern astronomical experiments are designed to achieve multiple scientific
goals, from studies of galaxy evolution to cosmic acceleration. These goals
require data of many different classes of night-sky objects, each of which has
a particular set of observational needs. These observational needs are
typically in strong competition with one another. This poses a challenging
multi-objective optimization problem that remains unsolved. The effectiveness
of Reinforcement Learning (RL) as a valuable paradigm for training autonomous
systems has been well-demonstrated, and it may provide the basis for
self-driving telescopes capable of optimizing the scheduling for astronomy
campaigns. Simulated datasets containing examples of interactions between a
telescope and a discrete set of sky locations on the celestial sphere can be
used to train an RL model to sequentially gather data from these several
locations to maximize a cumulative reward as a measure of the quality of the
data gathered. We use simulated data to test and compare multiple
implementations of a Deep Q-Network (DQN) for the task of optimizing the
schedule of observations from the Stone Edge Observatory (SEO). We combine
multiple improvements on the DQN and adjustments to the dataset, showing that
DQNs can achieve an average reward of 87%+-6% of the maximum achievable reward
in each state on the test set. This is the first comparison of offline RL
algorithms for a particular astronomical challenge and the first open-source
framework for performing such a comparison and assessment task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18102">PatchBMI-Net: Lightweight Facial Patch-based Ensemble for BMI Prediction. (arXiv:2311.18102v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aarotale_P/0/1/0/all/0/1">Parshuram N. Aarotale</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_T/0/1/0/all/0/1">Twyla Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Rattani_A/0/1/0/all/0/1">Ajita Rattani</a></p>
<p>Due to an alarming trend related to obesity affecting 93.3 million adults in
the United States alone, body mass index (BMI) and body weight have drawn
significant interest in various health monitoring applications. Consequently,
several studies have proposed self-diagnostic facial image-based BMI prediction
methods for healthy weight monitoring. These methods have mostly used
convolutional neural network (CNN) based regression baselines, such as VGG19,
ResNet50, and Efficient-NetB0, for BMI prediction from facial images. However,
the high computational requirement of these heavy-weight CNN models limits
their deployment to resource-constrained mobile devices, thus deterring weight
monitoring using smartphones. This paper aims to develop a lightweight facial
patch-based ensemble (PatchBMI-Net) for BMI prediction to facilitate the
deployment and weight monitoring using smartphones. Extensive experiments on
BMI-annotated facial image datasets suggest that our proposed PatchBMI-Net
model can obtain Mean Absolute Error (MAE) in the range [3.58, 6.51] with a
size of about 3.3 million parameters. On cross-comparison with heavyweight
models, such as ResNet-50 and Xception, trained for BMI prediction from facial
images, our proposed PatchBMI-Net obtains equivalent MAE along with the model
size reduction of about 5.4x and the average inference time reduction of about
3x when deployed on Apple-14 smartphone. Thus, demonstrating performance
efficiency as well as low latency for on-device deployment and weight
monitoring using smartphone applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18114">Composition of Nondeterministic and Stochastic Services for LTLf Task Specifications. (arXiv:2311.18114v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Giacomo_G/0/1/0/all/0/1">Giuseppe De Giacomo</a>, <a href="http://arxiv.org/find/cs/1/au:+Favorito_M/0/1/0/all/0/1">Marco Favorito</a>, <a href="http://arxiv.org/find/cs/1/au:+Silo_L/0/1/0/all/0/1">Luciana Silo</a></p>
<p>In this paper, we study the composition of services so as to obtain runs
satisfying a task specification in Linear Temporal Logic on finite traces
(LTLf). We study the problem in the case services are nondeterministic and the
LTLf specification can be exactly met, and in the case services are stochastic,
where we are interested in maximizing the probability of satisfaction of the
LTLf specification and, simultaneously, minimizing the utilization cost of the
services. To do so, we combine techniques from LTLf synthesis, service
composition \`a la Roman Model, reactive synthesis, and bi-objective
lexicographic optimization on MDPs. This framework has several interesting
applications, including Smart Manufacturing and Digital Twins.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18138">Algorithmic Persuasion Through Simulation: Information Design in the Age of Generative AI. (arXiv:2311.18138v1 [cs.GT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Harris_K/0/1/0/all/0/1">Keegan Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Immorlica_N/0/1/0/all/0/1">Nicole Immorlica</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucier_B/0/1/0/all/0/1">Brendan Lucier</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a></p>
<p>How can an informed sender persuade a receiver, having only limited
information about the receiver's beliefs? Motivated by research showing
generative AI can simulate economic agents, we initiate the study of
information design with an oracle. We assume the sender can learn more about
the receiver by querying this oracle, e.g., by simulating the receiver's
behavior. Aside from AI motivations such as general-purpose Large Language
Models (LLMs) and problem-specific machine learning models, alternate
motivations include customer surveys and querying a small pool of live users.
</p>
<p>Specifically, we study Bayesian Persuasion where the sender has a
second-order prior over the receiver's beliefs. After a fixed number of queries
to an oracle to refine this prior, the sender commits to an information
structure. Upon receiving the message, the receiver takes a payoff-relevant
action maximizing her expected utility given her posterior beliefs. We design
polynomial-time querying algorithms that optimize the sender's expected utility
in this Bayesian Persuasion game. As a technical contribution, we show that
queries form partitions of the space of receiver beliefs that can be used to
quantify the sender's knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18190">Toward the Tradeoffs between Privacy, Fairness and Utility in Federated Learning. (arXiv:2311.18190v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1">Kangkang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaojin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gaolei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianhua Li</a></p>
<p>Federated Learning (FL) is a novel privacy-protection distributed machine
learning paradigm that guarantees user privacy and prevents the risk of data
leakage due to the advantage of the client's local training. Researchers have
struggled to design fair FL systems that ensure fairness of results. However,
the interplay between fairness and privacy has been less studied. Increasing
the fairness of FL systems can have an impact on user privacy, while an
increase in user privacy can affect fairness. In this work, on the client side,
we use fairness metrics, such as Demographic Parity (DemP), Equalized Odds
(EOs), and Disparate Impact (DI), to construct the local fair model. To protect
the privacy of the client model, we propose a privacy-protection fairness FL
method. The results show that the accuracy of the fair model with privacy
increases because privacy breaks the constraints of the fairness metrics. In
our experiments, we conclude the relationship between privacy, fairness and
utility, and there is a tradeoff between these.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18206">SCOPE-RL: A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation. (arXiv:2311.18206v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kiyohara_H/0/1/0/all/0/1">Haruka Kiyohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kishimoto_R/0/1/0/all/0/1">Ren Kishimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawakami_K/0/1/0/all/0/1">Kosuke Kawakami</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_K/0/1/0/all/0/1">Ken Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1">Kazuhide Nakata</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1">Yuta Saito</a></p>
<p>This paper introduces SCOPE-RL, a comprehensive open-source Python software
designed for offline reinforcement learning (offline RL), off-policy evaluation
(OPE), and selection (OPS). Unlike most existing libraries that focus solely on
either policy learning or evaluation, SCOPE-RL seamlessly integrates these two
key aspects, facilitating flexible and complete implementations of both offline
RL and OPE processes. SCOPE-RL put particular emphasis on its OPE modules,
offering a range of OPE estimators and robust evaluation-of-OPE protocols. This
approach enables more in-depth and reliable OPE compared to other packages. For
instance, SCOPE-RL enhances OPE by estimating the entire reward distribution
under a policy rather than its mere point-wise expected value. Additionally,
SCOPE-RL provides a more thorough evaluation-of-OPE by presenting the
risk-return tradeoff in OPE results, extending beyond mere accuracy evaluations
in existing OPE literature. SCOPE-RL is designed with user accessibility in
mind. Its user-friendly APIs, comprehensive documentation, and a variety of
easy-to-follow examples assist researchers and practitioners in efficiently
implementing and experimenting with various offline RL methods and OPE
estimators, tailored to their specific problem contexts. The documentation of
SCOPE-RL is available at https://scope-rl.readthedocs.io/en/latest/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18207">Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation. (arXiv:2311.18207v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kiyohara_H/0/1/0/all/0/1">Haruka Kiyohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kishimoto_R/0/1/0/all/0/1">Ren Kishimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawakami_K/0/1/0/all/0/1">Kosuke Kawakami</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_K/0/1/0/all/0/1">Ken Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1">Kazuhide Nakata</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1">Yuta Saito</a></p>
<p>Off-Policy Evaluation (OPE) aims to assess the effectiveness of
counterfactual policies using only offline logged data and is often used to
identify the top-k promising policies for deployment in online A/B tests.
Existing evaluation metrics for OPE estimators primarily focus on the
"accuracy" of OPE or that of downstream policy selection, neglecting
risk-return tradeoff in the subsequent online policy deployment. To address
this issue, we draw inspiration from portfolio evaluation in finance and
develop a new metric, called SharpeRatio@k, which measures the risk-return
tradeoff of policy portfolios formed by an OPE estimator under varying online
evaluation budgets (k). We validate our metric in two example scenarios,
demonstrating its ability to effectively distinguish between low-risk and
high-risk estimators and to accurately identify the most efficient estimator.
This efficient estimator is characterized by its capability to form the most
advantageous policy portfolios, maximizing returns while minimizing risks
during online deployment, a nuance that existing metrics typically overlook. To
facilitate a quick, accurate, and consistent evaluation of OPE via
SharpeRatio@k, we have also integrated this metric into an open-source
software, SCOPE-RL. Employing SharpeRatio@k and SCOPE-RL, we conduct
comprehensive benchmarking experiments on various estimators and RL tasks,
focusing on their risk-return tradeoff. These experiments offer several
interesting directions and suggestions for future OPE research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18213">Beyond Two-Tower Matching: Learning Sparse Retrievable Cross-Interactions for Recommendation. (arXiv:2311.18213v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Liangcai Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_F/0/1/0/all/0/1">Fan Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jieming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_H/0/1/0/all/0/1">Haoyi Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zhenhua Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Ruiming Tang</a></p>
<p>Two-tower models are a prevalent matching framework for recommendation, which
have been widely deployed in industrial applications. The success of two-tower
matching attributes to its efficiency in retrieval among a large number of
items, since the item tower can be precomputed and used for fast Approximate
Nearest Neighbor (ANN) search. However, it suffers two main challenges,
including limited feature interaction capability and reduced accuracy in online
serving. Existing approaches attempt to design novel late interactions instead
of dot products, but they still fail to support complex feature interactions or
lose retrieval efficiency. To address these challenges, we propose a new
matching paradigm named SparCode, which supports not only sophisticated feature
interactions but also efficient retrieval. Specifically, SparCode introduces an
all-to-all interaction module to model fine-grained query-item interactions.
Besides, we design a discrete code-based sparse inverted index jointly trained
with the model to achieve effective and efficient model inference. Extensive
experiments have been conducted on open benchmark datasets to demonstrate the
superiority of our framework. The results show that SparCode significantly
improves the accuracy of candidate item matching while retaining the same level
of retrieval efficiency with two-tower models. Our source code will be
available at MindSpore/models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18224">Reasoning with the Theory of Mind for Pragmatic Semantic Communication. (arXiv:2311.18224v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thomas_C/0/1/0/all/0/1">Christo Kurisummoottil Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Strinati_E/0/1/0/all/0/1">Emilio Calvanese Strinati</a>, <a href="http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1">Walid Saad</a></p>
<p>In this paper, a pragmatic semantic communication framework that enables
effective goal-oriented information sharing between two-intelligent agents is
proposed. In particular, semantics is defined as the causal state that
encapsulates the fundamental causal relationships and dependencies among
different features extracted from data. The proposed framework leverages the
emerging concept in machine learning (ML) called theory of mind (ToM). It
employs a dynamic two-level (wireless and semantic) feedback mechanism to
continuously fine-tune neural network components at the transmitter. Thanks to
the ToM, the transmitter mimics the actual mental state of the receiver's
reasoning neural network operating semantic interpretation. Then, the estimated
mental state at the receiver is dynamically updated thanks to the proposed
dynamic two-level feedback mechanism. At the lower level, conventional channel
quality metrics are used to optimize the channel encoding process based on the
wireless communication channel's quality, ensuring an efficient mapping of
semantic representations to a finite constellation. Additionally, a semantic
feedback level is introduced, providing information on the receiver's perceived
semantic effectiveness with minimal overhead. Numerical evaluations demonstrate
the framework's ability to achieve efficient communication with a reduced
amount of bits while maintaining the same semantics, outperforming conventional
systems that do not exploit the ToM-based reasoning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18232">LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models. (arXiv:2311.18232v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1">Marwa Abdulhai</a>, <a href="http://arxiv.org/find/cs/1/au:+White_I/0/1/0/all/0/1">Isadora White</a>, <a href="http://arxiv.org/find/cs/1/au:+Snell_C/0/1/0/all/0/1">Charlie Snell</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Charles Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Joey Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1">Yuexiang Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kelvin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a></p>
<p>Large language models (LLMs) provide excellent text-generation capabilities,
but standard prompting and generation methods generally do not lead to
intentional or goal-directed agents and might necessitate considerable prompt
tuning. This becomes particularly apparent in multi-turn conversations: even
the best current LLMs rarely ask clarifying questions, engage in explicit
information gathering, or take actions now that lead to better decisions after
multiple turns. Reinforcement learning has the potential to leverage the
powerful modeling capabilities of LLMs, as well as their internal
representation of textual interactions, to create capable goal-directed
language agents. This can enable intentional and temporally extended
interactions, such as with humans, through coordinated persuasion and carefully
crafted questions, or in goal-directed play through text games to bring about
desired final outcomes. However, enabling this requires the community to
develop stable and reliable reinforcement learning algorithms that can
effectively train LLMs. Developing such algorithms requires tasks that can
gauge progress on algorithm design, provide accessible and reproducible
evaluations for multi-turn interactions, and cover a range of task properties
and challenges in improving reinforcement learning algorithms. Our paper
introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,
together with an open-source research framework containing a basic toolkit for
getting started on multi-turn RL with offline value-based and policy-based RL
methods. Our benchmark consists of 8 different language tasks, which require
multiple rounds of language interaction and cover a range of tasks in
open-ended dialogue and text games.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18241">LLVMs4Protest: Harnessing the Power of Large Language and Vision Models for Deciphering Protests in the News. (arXiv:2311.18241v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongjun Zhang</a></p>
<p>Large language and vision models have transformed how social movements
scholars identify protest and extract key protest attributes from multi-modal
data such as texts, images, and videos. This article documents how we
fine-tuned two large pretrained transformer models, including longformer and
swin-transformer v2, to infer potential protests in news articles using textual
and imagery data. First, the longformer model was fine-tuned using the Dynamic
of Collective Action (DoCA) Corpus. We matched the New York Times articles with
the DoCA database to obtain a training dataset for downstream tasks. Second,
the swin-transformer v2 models was trained on UCLA-protest imagery data.
UCLA-protest project contains labeled imagery data with information such as
protest, violence, and sign. Both fine-tuned models will be available via
\url{https://github.com/Joshzyj/llvms4protest}. We release this short technical
report for social movement scholars who are interested in using LLVMs to infer
protests in textual and imagery data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18252">Navigating Privacy and Copyright Challenges Across the Data Lifecycle of Generative AI. (arXiv:2311.18252v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dawen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_B/0/1/0/all/0/1">Boming Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1">Thong Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhenchang Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Staples_M/0/1/0/all/0/1">Mark Staples</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qinghua Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Liming Zhu</a></p>
<p>The advent of Generative AI has marked a significant milestone in artificial
intelligence, demonstrating remarkable capabilities in generating realistic
images, texts, and data patterns. However, these advancements come with
heightened concerns over data privacy and copyright infringement, primarily due
to the reliance on vast datasets for model training. Traditional approaches
like differential privacy, machine unlearning, and data poisoning only offer
fragmented solutions to these complex issues. Our paper delves into the
multifaceted challenges of privacy and copyright protection within the data
lifecycle. We advocate for integrated approaches that combines technical
innovation with ethical foresight, holistically addressing these concerns by
investigating and devising solutions that are informed by the lifecycle
perspective. This work aims to catalyze a broader discussion and inspire
concerted efforts towards data privacy and copyright integrity in Generative
AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18254">Sketch Input Method Editor: A Comprehensive Dataset and Methodology for Systematic Input Recognition. (arXiv:2311.18254v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1">Guangming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Siyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1">Qing Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kelong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a></p>
<p>With the recent surge in the use of touchscreen devices, free-hand sketching
has emerged as a promising modality for human-computer interaction. While
previous research has focused on tasks such as recognition, retrieval, and
generation of familiar everyday objects, this study aims to create a Sketch
Input Method Editor (SketchIME) specifically designed for a professional C4I
system. Within this system, sketches are utilized as low-fidelity prototypes
for recommending standardized symbols in the creation of comprehensive
situation maps. This paper also presents a systematic dataset comprising 374
specialized sketch types, and proposes a simultaneous recognition and
segmentation architecture with multilevel supervision between recognition and
segmentation to improve performance and enhance interpretability. By
incorporating few-shot domain adaptation and class-incremental learning, the
network's ability to adapt to new users and extend to new task-specific classes
is significantly enhanced. Results from experiments conducted on both the
proposed dataset and the SPG dataset illustrate the superior performance of the
proposed architecture. Our dataset and code are publicly available at
https://github.com/Anony517/SketchIME.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18259">Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives. (arXiv:2311.18259v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1">Kristen Grauman</a>, <a href="http://arxiv.org/find/cs/1/au:+Westbury_A/0/1/0/all/0/1">Andrew Westbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1">Lorenzo Torresani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris Kitani</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Afouras_T/0/1/0/all/0/1">Triantafyllos Afouras</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashutosh_K/0/1/0/all/0/1">Kumar Ashutosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baiyya_V/0/1/0/all/0/1">Vijay Baiyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_S/0/1/0/all/0/1">Siddhant Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Boote_B/0/1/0/all/0/1">Bikram Boote</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrne_E/0/1/0/all/0/1">Eugene Byrne</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavis_Z/0/1/0/all/0/1">Zach Chavis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Joya Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1">Feng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_F/0/1/0/all/0/1">Fu-Jen Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Crane_S/0/1/0/all/0/1">Sean Crane</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1">Avijit Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Escobar_M/0/1/0/all/0/1">Maria Escobar</a>, <a href="http://arxiv.org/find/cs/1/au:+Forigua_C/0/1/0/all/0/1">Cristhian Forigua</a>, <a href="http://arxiv.org/find/cs/1/au:+Gebreselasie_A/0/1/0/all/0/1">Abrham Gebreselasie</a>, <a href="http://arxiv.org/find/cs/1/au:+Haresh_S/0/1/0/all/0/1">Sanjay Haresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Md Mohaiminul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Suyog Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Khirodkar_R/0/1/0/all/0/1">Rawal Khirodkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kukreja_D/0/1/0/all/0/1">Devansh Kukreja</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1">Kevin J Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jia-Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_S/0/1/0/all/0/1">Sagnik Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yongsen Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_M/0/1/0/all/0/1">Miguel Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mavroudi_E/0/1/0/all/0/1">Effrosyni Mavroudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagarajan_T/0/1/0/all/0/1">Tushar Nagarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragusa_F/0/1/0/all/0/1">Francesco Ragusa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_S/0/1/0/all/0/1">Santhosh Kumar Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Seminara_L/0/1/0/all/0/1">Luigi Seminara</a>, <a href="http://arxiv.org/find/cs/1/au:+Somayazulu_A/0/1/0/all/0/1">Arjun Somayazulu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yale Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1">Shan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1">Zihui Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1">Edward Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jinxu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_A/0/1/0/all/0/1">Angela Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Changan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xinzhu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Furuta_R/0/1/0/all/0/1">Ryosuke Furuta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_C/0/1/0/all/0/1">Cristina Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1">Prince Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jiabo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yifei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khoo_W/0/1/0/all/0/1">Weslie Khoo</a>, et al. (48 additional authors not shown)</p>
<p>We present Ego-Exo4D, a diverse, large-scale multimodal multiview video
dataset and benchmark challenge. Ego-Exo4D centers around
simultaneously-captured egocentric and exocentric video of skilled human
activities (e.g., sports, music, dance, bike repair). More than 800
participants from 13 cities worldwide performed these activities in 131
different natural scene contexts, yielding long-form captures from 1 to 42
minutes each and 1,422 hours of video combined. The multimodal nature of the
dataset is unprecedented: the video is accompanied by multichannel audio, eye
gaze, 3D point clouds, camera poses, IMU, and multiple paired language
descriptions -- including a novel "expert commentary" done by coaches and
teachers and tailored to the skilled-activity domain. To push the frontier of
first-person video understanding of skilled human activity, we also present a
suite of benchmark tasks and their annotations, including fine-grained activity
understanding, proficiency estimation, cross-view translation, and 3D hand/body
pose. All resources will be open sourced to fuel new research in the community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18296">Perceptual Group Tokenizer: Building Perception with Iterative Grouping. (arXiv:2311.18296v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhiwei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a></p>
<p>Human visual recognition system shows astonishing capability of compressing
visual information into a set of tokens containing rich representations without
label supervision. One critical driving principle behind it is perceptual
grouping. Despite being widely used in computer vision in the early 2010s, it
remains a mystery whether perceptual grouping can be leveraged to derive a
neural visual recognition backbone that generates as powerful representations.
In this paper, we propose the Perceptual Group Tokenizer, a model that entirely
relies on grouping operations to extract visual features and perform
self-supervised representation learning, where a series of grouping operations
are used to iteratively hypothesize the context for pixels or superpixels to
refine feature representations. We show that the proposed model can achieve
competitive performance compared to state-of-the-art vision architectures, and
inherits desirable properties including adaptive computation without
re-training, and interpretability. Specifically, Perceptual Group Tokenizer
achieves 80.3% on ImageNet-1K self-supervised learning benchmark with linear
probe evaluation, marking a new progress under this paradigm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18297">TrustMark: Universal Watermarking for Arbitrary Resolution Images. (arXiv:2311.18297v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tu Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Shruti Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1">John Collomosse</a></p>
<p>Imperceptible digital watermarking is important in copyright protection,
misinformation prevention, and responsible generative AI. We propose TrustMark
- a GAN-based watermarking method with novel design in architecture and
spatio-spectra losses to balance the trade-off between watermarked image
quality with the watermark recovery accuracy. Our model is trained with
robustness in mind, withstanding various in- and out-place perturbations on the
encoded image. Additionally, we introduce TrustMark-RM - a watermark remover
method useful for re-watermarking. Our methods achieve state-of-art performance
on 3 benchmarks comprising arbitrary resolution images.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18328">Advances in 3D Neural Stylization: A Survey. (arXiv:2311.18328v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_G/0/1/0/all/0/1">Guocheng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_K/0/1/0/all/0/1">Ka Chun Shum</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1">Binh-Son Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1">Sai-Kit Yeung</a></p>
<p>Modern artificial intelligence provides a novel way of producing digital art
in styles. The expressive power of neural networks enables the realm of visual
style transfer methods, which can be used to edit images, videos, and 3D data
to make them more artistic and diverse. This paper reports on recent advances
in neural stylization for 3D data. We provide a taxonomy for neural stylization
by considering several important design choices, including scene
representation, guidance data, optimization strategies, and output styles.
Building on such taxonomy, our survey first revisits the background of neural
stylization on 2D images, and then provides in-depth discussions on recent
neural stylization methods for 3D data, where we also provide a mini-benchmark
on artistic stylization methods. Based on the insights gained from the survey,
we then discuss open challenges, future research, and potential applications
and impacts of neural stylization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18331">MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation. (arXiv:2311.18331v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Udupa_S/0/1/0/all/0/1">Sumanth Udupa</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurunath_P/0/1/0/all/0/1">Prajwal Gurunath</a>, <a href="http://arxiv.org/find/cs/1/au:+Sikdar_A/0/1/0/all/0/1">Aniruddh Sikdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1">Suresh Sundaram</a></p>
<p>Deep neural networks have shown exemplary performance on semantic scene
understanding tasks on source domains, but due to the absence of style
diversity during training, enhancing performance on unseen target domains using
only single source domain data remains a challenging task. Generation of
simulated data is a feasible alternative to retrieving large style-diverse
real-world datasets as it is a cumbersome and budget-intensive process.
However, the large domain-specific inconsistencies between simulated and
real-world data pose a significant generalization challenge in semantic
segmentation. In this work, to alleviate this problem, we propose a novel
MultiResolution Feature Perturbation (MRFP) technique to randomize
domain-specific fine-grained features and perturb style of coarse features. Our
experimental results on various urban-scene segmentation datasets clearly
indicate that, along with the perturbation of style-information, perturbation
of fine-feature components is paramount to learn domain invariant robust
feature maps for semantic segmentation models. MRFP is a simple and
computationally efficient, transferable module with no additional learnable
parameters or objective functions, that helps state-of-the-art deep neural
networks to learn robust domain invariant features for simulation-to-real
semantic segmentation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18403">Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image Transformations. (arXiv:2311.18403v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xianlong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengshan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Minghui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhifei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Ziqi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Leo Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hai Jin</a></p>
<p>Unlearnable datasets lead to a drastic drop in the generalization performance
of models trained on them by introducing elaborate and imperceptible
perturbations into clean training sets. Many existing defenses, e.g., JPEG
compression and adversarial training, effectively counter UDs based on
norm-constrained additive noise. However, a fire-new type of convolution-based
UDs have been proposed and render existing defenses all ineffective, presenting
a greater challenge to defenders. To address this, we express the
convolution-based unlearnable sample as the result of multiplying a matrix by a
clean sample in a simplified scenario, and formalize the intra-class matrix
inconsistency as $\Theta_{imi}$, inter-class matrix consistency as
$\Theta_{imc}$ to investigate the working mechanism of the convolution-based
UDs. We conjecture that increasing both of these metrics will mitigate the
unlearnability effect. Through validation experiments that commendably support
our hypothesis, we further design a random matrix to boost both $\Theta_{imi}$
and $\Theta_{imc}$, achieving a notable degree of defense effect. Hence, by
building upon and extending these facts, we first propose a brand-new image
COrruption that employs randomly multiplicative transformation via
INterpolation operation to successfully defend against convolution-based UDs.
Our approach leverages global pixel random interpolations, effectively
suppressing the impact of multiplicative noise in convolution-based UDs.
Additionally, we have also designed two new forms of convolution-based UDs, and
find that our defense is the most effective against them.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18424">Multiple Disciplinary Data Work Practices in Artificial Intelligence Research: a Healthcare Case Study in the UK. (arXiv:2311.18424v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Henkin_R/0/1/0/all/0/1">Rafael Henkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Remfry_E/0/1/0/all/0/1">Elizabeth Remfry</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_D/0/1/0/all/0/1">Duncan J. Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Clinch_M/0/1/0/all/0/1">Megan Clinch</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_M/0/1/0/all/0/1">Michael R. Barnes</a></p>
<p>Developing artificial intelligence (AI) tools for healthcare is a multiple
disciplinary effort, bringing data scientists, clinicians, patients and other
disciplines together. In this paper, we explore the AI development workflow and
how participants navigate the challenges and tensions of sharing and generating
knowledge across disciplines. Through an inductive thematic analysis of 13
semi-structured interviews with participants in a large research consortia, our
findings suggest that multiple disciplinarity heavily impacts work practices.
Participants faced challenges to learn the languages of other disciplines and
needed to adapt the tools used for sharing and communicating with their
audience, particularly those from a clinical or patient perspective. Large
health datasets also posed certain restrictions on work practices. We
identified meetings as a key platform for facilitating exchanges between
disciplines and allowing for the blending and creation of knowledge. Finally,
we discuss design implications for data science and collaborative tools, and
recommendations for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18460">Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework. (arXiv:2311.18460v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schroder_M/0/1/0/all/0/1">Maresa Schr&#xf6;der</a>, <a href="http://arxiv.org/find/cs/1/au:+Frauen_D/0/1/0/all/0/1">Dennis Frauen</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1">Stefan Feuerriegel</a></p>
<p>Fairness for machine learning predictions is widely required in practice for
legal, ethical, and societal reasons. Existing work typically focuses on
settings without unobserved confounding, even though unobserved confounding can
lead to severe violations of causal fairness and, thus, unfair predictions. In
this work, we analyze the sensitivity of causal fairness to unobserved
confounding. Our contributions are three-fold. First, we derive bounds for
causal fairness metrics under different sources of unobserved confounding. This
enables practitioners to examine the sensitivity of their machine learning
models to unobserved confounding in fairness-critical applications. Second, we
propose a novel neural framework for learning fair predictions, which allows us
to offer worst-case guarantees of the extent to which causal fairness can be
violated due to unobserved confounding. Third, we demonstrate the effectiveness
of our framework in a series of experiments, including a real-world case study
about predicting prison sentences. To the best of our knowledge, ours is the
first work to study causal fairness under unobserved confounding. To this end,
our work is of direct practical value as a refutation strategy to ensure the
fairness of predictions in high-stakes applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18481">ESG Accountability Made Easy: DocQA at Your Service. (arXiv:2311.18481v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mishra_L/0/1/0/all/0/1">Lokesh Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Berrospi_C/0/1/0/all/0/1">Cesar Berrospi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinkla_K/0/1/0/all/0/1">Kasper Dinkla</a>, <a href="http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1">Diego Antognini</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1">Francesco Fusco</a>, <a href="http://arxiv.org/find/cs/1/au:+Bothur_B/0/1/0/all/0/1">Benedikt Bothur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lysak_M/0/1/0/all/0/1">Maksym Lysak</a>, <a href="http://arxiv.org/find/cs/1/au:+Livathinos_N/0/1/0/all/0/1">Nikolaos Livathinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassar_A/0/1/0/all/0/1">Ahmed Nassar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vagenas_P/0/1/0/all/0/1">Panagiotis Vagenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Morin_L/0/1/0/all/0/1">Lucas Morin</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_C/0/1/0/all/0/1">Christoph Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolfi_M/0/1/0/all/0/1">Michele Dolfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Staar_P/0/1/0/all/0/1">Peter Staar</a></p>
<p>We present Deep Search DocQA. This application enables information extraction
from documents via a question-answering conversational assistant. The system
integrates several technologies from different AI disciplines consisting of
document conversion to machine-readable format (via computer vision), finding
relevant data (via natural language processing), and formulating an eloquent
response (via large language models). Users can explore over 10,000
Environmental, Social, and Governance (ESG) disclosure reports from over 2000
corporations. The Deep Search platform can be accessed at:
https://ds4sd.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18486">New Perspectives on the Evaluation of Link Prediction Algorithms for Dynamic Graphs. (arXiv:2311.18486v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Romero_R/0/1/0/all/0/1">Rapha&#xeb;l Romero</a>, <a href="http://arxiv.org/find/cs/1/au:+Bie_T/0/1/0/all/0/1">Tijl De Bie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lijffijt_J/0/1/0/all/0/1">Jefrey Lijffijt</a></p>
<p>There is a fast-growing body of research on predicting future links in
dynamic networks, with many new algorithms. Some benchmark data exists, and
performance evaluations commonly rely on comparing the scores of observed
network events (positives) with those of randomly generated ones (negatives).
These evaluation measures depend on both the predictive ability of the model
and, crucially, the type of negative samples used. Besides, as generally the
case with temporal data, prediction quality may vary over time. This creates a
complex evaluation space. In this work, we catalog the possibilities for
negative sampling and introduce novel visualization methods that can yield
insight into prediction performance and the dynamics of temporal networks. We
leverage these visualization tools to investigate the effect of negative
sampling on the predictive performance, at the node and edge level. We validate
empirically, on datasets extracted from recent benchmarks that the error is
typically not evenly distributed across different data segments. Finally, we
argue that such visualization tools can serve as powerful guides to evaluate
dynamic link prediction methods at different levels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18491">ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs. (arXiv:2311.18491v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_V/0/1/0/all/0/1">Violeta Men&#xe9;ndez Gonz&#xe1;lez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilbert_A/0/1/0/all/0/1">Andrew Gilbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillipson_G/0/1/0/all/0/1">Graeme Phillipson</a>, <a href="http://arxiv.org/find/cs/1/au:+Jolly_S/0/1/0/all/0/1">Stephen Jolly</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_S/0/1/0/all/0/1">Simon Hadfield</a></p>
<p>In the field of media production, video editing techniques play a pivotal
role. Recent approaches have had great success at performing novel view image
synthesis of static scenes. But adding temporal information adds an extra layer
of complexity. Previous models have focused on implicitly representing static
and dynamic scenes using NeRF. These models achieve impressive results but are
costly at training and inference time. They overfit an MLP to describe the
scene implicitly as a function of position. This paper proposes ZeST-NeRF, a
new approach that can produce temporal NeRFs for new scenes without retraining.
We can accurately reconstruct novel views using multi-view synthesis techniques
and scene flow-field estimation, trained only with unrelated scenes. We
demonstrate how existing state-of-the-art approaches from a range of fields
cannot adequately solve this new task and demonstrate the efficacy of our
solution. The resulting network improves quantitatively by 15% and produces
significantly better visual results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18518">Color-Emotion Associations in Art: Fuzzy Approach. (arXiv:2311.18518v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shamoi_P/0/1/0/all/0/1">Pakizar Shamoi</a>, <a href="http://arxiv.org/find/cs/1/au:+Muratbekova_M/0/1/0/all/0/1">Muragul Muratbekova</a></p>
<p>Art objects can evoke certain emotions. Color is a fundamental element of
visual art and plays a significant role in how art is perceived. This paper
introduces a novel approach to classifying emotions in art using Fuzzy Sets. We
employ a fuzzy approach because it aligns well with human judgments' imprecise
and subjective nature. Extensive fuzzy colors (n=120) and a broad emotional
spectrum (n=10) allow for a more human-consistent and context-aware exploration
of emotions inherent in paintings. First, we introduce the fuzzy color
representation model. Then, at the fuzzification stage, we process the Wiki Art
Dataset of paintings tagged with emotions, extracting fuzzy dominant colors
linked to specific emotions. This results in fuzzy color distributions for ten
emotions. Finally, we convert them back to a crisp domain, obtaining a
knowledge base of color-emotion associations in primary colors. Our findings
reveal strong associations between specific emotions and colors; for instance,
gratitude strongly correlates with green, brown, and orange. Other noteworthy
associations include brown and anger, orange with shame, yellow with happiness,
and gray with fear. Using these associations and Jaccard similarity, we can
find the emotions in the arbitrary untagged image. We conducted a 2AFC
experiment involving human subjects to evaluate the proposed method. The
average hit rate of 0.77 indicates a significant correlation between the
method's predictions and human perception. The proposed method is simple to
adapt to art painting retrieval systems. The study contributes to the
theoretical understanding of color-emotion associations in art, offering
valuable insights for various practical applications besides art, like
marketing, design, and psychology.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18520">Calibration-free online test-time adaptation for electroencephalography motor imagery decoding. (arXiv:2311.18520v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wimpff_M/0/1/0/all/0/1">Martin Wimpff</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobler_M/0/1/0/all/0/1">Mario D&#xf6;bler</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bin Yang</a></p>
<p>Providing a promising pathway to link the human brain with external devices,
Brain-Computer Interfaces (BCIs) have seen notable advancements in decoding
capabilities, primarily driven by increasingly sophisticated techniques,
especially deep learning. However, achieving high accuracy in real-world
scenarios remains a challenge due to the distribution shift between sessions
and subjects. In this paper we will explore the concept of online test-time
adaptation (OTTA) to continuously adapt the model in an unsupervised fashion
during inference time. Our approach guarantees the preservation of privacy by
eliminating the requirement to access the source data during the adaptation
process. Additionally, OTTA achieves calibration-free operation by not
requiring any session- or subject-specific data. We will investigate the task
of electroencephalography (EEG) motor imagery decoding using a lightweight
architecture together with different OTTA techniques like alignment, adaptive
batch normalization, and entropy minimization. We examine two datasets and
three distinct data settings for a comprehensive analysis. Our adaptation
methods produce state-of-the-art results, potentially instigating a shift in
transfer learning for BCI decoding towards online adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18531">Dataset Distillation via the Wasserstein Metric. (arXiv:2311.18531v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haoyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_T/0/1/0/all/0/1">Tiancheng Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Luwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalal_V/0/1/0/all/0/1">Vibhu Dalal</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jingrui He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haohan Wang</a></p>
<p>Dataset distillation (DD) offers a compelling approach in computer vision,
with the goal of condensing extensive datasets into smaller synthetic versions
without sacrificing much of the model performance. In this paper, we continue
to study the methods for DD, by addressing its conceptually core objective: how
to capture the essential representation of extensive datasets in smaller,
synthetic forms.
</p>
<p>We propose a novel approach utilizing the Wasserstein distance, a metric
rooted in optimal transport theory, to enhance distribution matching in DD. Our
method leverages the Wasserstein barycenter, offering a geometrically
meaningful way to quantify distribution differences and effectively capture the
centroid of a set of distributions. Our approach retains the computational
benefits of distribution matching-based methods while achieving new
state-of-the-art performance on several benchmarks.
</p>
<p>To provide useful prior for learning the images, we embed the synthetic data
into the feature space of pretrained classification models to conduct
distribution matching. Extensive testing on various high-resolution datasets
confirms the effectiveness and adaptability of our method, indicating the
promising yet unexplored capabilities of Wasserstein metrics in dataset
distillation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18547">Real-Time Vibration-Based Bearing Fault Diagnosis Under Time-Varying Speed Conditions. (arXiv:2311.18547v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jalonen_T/0/1/0/all/0/1">Tuomas Jalonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Sad_M/0/1/0/all/0/1">Mohammad Al-Sa&#x27;d</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiranyaz_S/0/1/0/all/0/1">Serkan Kiranyaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a></p>
<p>Detection of rolling-element bearing faults is crucial for implementing
proactive maintenance strategies and for minimizing the economic and
operational consequences of unexpected failures. However, many existing
techniques are developed and tested under strictly controlled conditions,
limiting their adaptability to the diverse and dynamic settings encountered in
practical applications. This paper presents an efficient real-time
convolutional neural network (CNN) for diagnosing multiple bearing faults under
various noise levels and time-varying rotational speeds. Additionally, we
propose a novel Fisher-based spectral separability analysis (SSA) method to
elucidate the effectiveness of the designed CNN model. We conducted experiments
on both healthy bearings and bearings afflicted with inner race, outer race,
and roller ball faults. The experimental results show the superiority of our
model over the current state-of-the-art approach in three folds: it achieves
substantial accuracy gains of up to 15.8%, it is robust to noise with high
performance across various signal-to-noise ratios, and it runs in real-time
with processing durations five times less than acquisition. Additionally, by
using the proposed SSA technique, we offer insights into the model's
performance and underscore its effectiveness in tackling real-world challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18550">Search Still Matters: Information Retrieval in the Era of Generative AI. (arXiv:2311.18550v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hersh_W/0/1/0/all/0/1">William R. Hersh</a></p>
<p>Objective: Information retrieval (IR, also known as search) systems are
ubiquitous in modern times. How does the emergence of generative artificial
intelligence (AI), based on large language models (LLMs), fit into the IR
process? Process: This perspective explores the use of generative AI in the
context of the motivations, considerations, and outcomes of the IR process with
a focus on the academic use of such systems. Conclusions: There are many
information needs, from simple to complex, that motivate use of IR. Users of
such systems, particularly academics, have concerns for authoritativeness,
timeliness, and contextualization of search. While LLMs may provide
functionality that aids the IR process, the continued need for search systems,
and research into their improvement, remains essential.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18576">Fingerprint Matching with Localized Deep Representation. (arXiv:2311.18576v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yongjie Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhiyu Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianjiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a></p>
<p>Compared to minutia-based fingerprint representations, fixed-length
representations are attractive due to simple and efficient matching. However,
fixed-length fingerprint representations are limited in accuracy when matching
fingerprints with different visible areas, which can occur due to different
finger poses or acquisition methods. To address this issue, we propose a
localized deep representation of fingerprint, named LDRF. By focusing on the
discriminative characteristics within local regions, LDRF provides a more
robust and accurate fixed-length representation for fingerprints with variable
visible areas. LDRF can be adapted to retain information within any valid area,
making it highly flexible. The matching scores produced by LDRF also exhibit
intuitive statistical characteristics, which led us to propose a matching score
normalization technique to mitigate the uncertainty in the cases of very small
overlapping area. With this new technique, we can maintain a high level of
accuracy and reliability in our fingerprint matching, even as the size of the
database grows rapidly. Our experimental results on 21 datasets containing over
140K fingerprints of various finger poses and impression types show that LDRF
outperforms other fixed-length representations and is robust to sensing
technologies and impression types. Besides, the proposed matching score
normalization effectively reduces the false match rate (FMR) in large-scale
identification experiments comprising over 5.11 million fingerprints.
Specifically, this technique results in a reduction of two orders of magnitude
compared to matching without matching score normalization and five orders of
magnitude compared to prior works.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18578">Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum. (arXiv:2311.18578v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zaccone_R/0/1/0/all/0/1">Riccardo Zaccone</a>, <a href="http://arxiv.org/find/cs/1/au:+Masone_C/0/1/0/all/0/1">Carlo Masone</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciccone_M/0/1/0/all/0/1">Marco Ciccone</a></p>
<p>Federated Learning (FL) is the state-of-the-art approach for learning from
decentralized data in privacy-constrained scenarios. As the current literature
reports, the main problems associated with FL refer to system and statistical
challenges: the former ones demand for efficient learning from edge devices,
including lowering communication bandwidth and frequency, while the latter
require algorithms robust to non-iidness. State-of-art approaches either
guarantee convergence at increased communication cost or are not sufficiently
robust to handle extreme heterogeneous local distributions. In this work we
propose a novel generalization of the heavy-ball momentum, and present FedHBM
to effectively address statistical heterogeneity in FL without introducing any
communication overhead. We conduct extensive experimentation on common FL
vision and NLP datasets, showing that our FedHBM algorithm empirically yields
better model quality and higher convergence speed w.r.t. the state-of-art,
especially in pathological non-iid scenarios. While being designed for
cross-silo settings, we show how FedHBM is applicable in moderate-to-high
cross-device scenarios, and how good model initializations (e.g. pre-training)
can be exploited for prompt acceleration. Extended experimentation on
large-scale real-world federated datasets further corroborates the
effectiveness of our approach for real-world FL applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18587">Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural Networks. (arXiv:2311.18587v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yun_J/0/1/0/all/0/1">Juyoung Yun</a></p>
<p>In the field of deep learning, the prevalence of models initially trained
with 32-bit precision is a testament to its robustness and accuracy. However,
the continuous evolution of these models often demands further training, which
can be resource-intensive. This study introduces a novel approach where we
continue the training of these pre-existing 32-bit models using 16-bit
precision. This technique not only caters to the need for efficiency in
computational resources but also significantly improves the speed of additional
training phases. By adopting 16-bit precision for ongoing training, we are able
to substantially decrease memory requirements and computational burden, thereby
accelerating the training process in a resource-limited setting. Our
experiments show that this method maintains the high standards of accuracy set
by the original 32-bit training while providing a much-needed boost in training
speed. This approach is especially pertinent in today's context, where most
models are initially trained in 32-bit and require periodic updates and
refinements. The findings from our research suggest that this strategy of
16-bit continuation training can be a key solution for sustainable and
efficient deep learning, offering a practical way to enhance pre-trained models
rapidly and in a resource-conscious manner.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18592">Semantic-Aware Frame-Event Fusion based Pattern Recognition via Large Vision-Language Models. (arXiv:2311.18592v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiandong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yanlin Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yaoyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Bin Luo</a></p>
<p>Pattern recognition through the fusion of RGB frames and Event streams has
emerged as a novel research area in recent years. Current methods typically
employ backbone networks to individually extract the features of RGB frames and
event streams, and subsequently fuse these features for pattern recognition.
However, we posit that these methods may suffer from key issues like sematic
gaps and small-scale backbone networks. In this study, we introduce a novel
pattern recognition framework that consolidates the semantic labels, RGB
frames, and event streams, leveraging pre-trained large-scale vision-language
models. Specifically, given the input RGB frames, event streams, and all the
predefined semantic labels, we employ a pre-trained large-scale vision model
(CLIP vision encoder) to extract the RGB and event features. To handle the
semantic labels, we initially convert them into language descriptions through
prompt engineering, and then obtain the semantic features using the pre-trained
large-scale language model (CLIP text encoder). Subsequently, we integrate the
RGB/Event features and semantic features using multimodal Transformer networks.
The resulting frame and event tokens are further amplified using self-attention
layers. Concurrently, we propose to enhance the interactions between text
tokens and RGB/Event tokens via cross-attention. Finally, we consolidate all
three modalities using self-attention and feed-forward layers for recognition.
Comprehensive experiments on the HARDVS and PokerEvent datasets fully
substantiate the efficacy of our proposed SAFE model. The source code will be
made available at https://github.com/Event-AHU/SAFE_LargeVLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18598">Generalisable Agents for Neural Network Optimisation. (arXiv:2311.18598v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tessera_K/0/1/0/all/0/1">Kale-ab Tessera</a>, <a href="http://arxiv.org/find/cs/1/au:+Tilbury_C/0/1/0/all/0/1">Callum Rhys Tilbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Abramowitz_S/0/1/0/all/0/1">Sasha Abramowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kock_R/0/1/0/all/0/1">Ruan de Kock</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahjoub_O/0/1/0/all/0/1">Omayma Mahjoub</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1">Benjamin Rosman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>, <a href="http://arxiv.org/find/cs/1/au:+Pretorius_A/0/1/0/all/0/1">Arnu Pretorius</a></p>
<p>Optimising deep neural networks is a challenging task due to complex training
dynamics, high computational requirements, and long training times. To address
this difficulty, we propose the framework of Generalisable Agents for Neural
Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL)
approach that learns to improve neural network optimisation by dynamically and
responsively scheduling hyperparameters during training. GANNO utilises an
agent per layer that observes localised network dynamics and accordingly takes
actions to adjust these dynamics at a layerwise level to collectively improve
global performance. In this paper, we use GANNO to control the layerwise
learning rate and show that the framework can yield useful and responsive
schedules that are competitive with handcrafted heuristics. Furthermore, GANNO
is shown to perform robustly across a wide variety of unseen initial
conditions, and can successfully generalise to harder problems than it was
trained on. Our work presents an overview of the opportunities that this
paradigm offers for training neural networks, along with key challenges that
remain to be overcome.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18599">Joint Detection Algorithm for Multiple Cognitive Users in Spectrum Sensing. (arXiv:2311.18599v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Meng_F/0/1/0/all/0/1">Fanfei Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1">Lele Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yingxin Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Demeter_D/0/1/0/all/0/1">David Demeter</a></p>
<p>Spectrum sensing technology is a crucial aspect of modern communication
technology, serving as one of the essential techniques for efficiently
utilizing scarce information resources in tight frequency bands. This paper
first introduces three common logical circuit decision criteria in hard
decisions and analyzes their decision rigor. Building upon hard decisions, the
paper further introduces a method for multi-user spectrum sensing based on soft
decisions. Then the paper simulates the false alarm probability and detection
probability curves corresponding to the three criteria. The simulated results
of multi-user collaborative sensing indicate that the simulation process
significantly reduces false alarm probability and enhances detection
probability. This approach effectively detects spectrum resources unoccupied
during idle periods, leveraging the concept of time-division multiplexing and
rationalizing the redistribution of information resources. The entire
computation process relies on the calculation principles of power spectral
density in communication theory, involving threshold decision detection for
noise power and the sum of noise and signal power. It provides a secondary
decision detection, reflecting the perceptual decision performance of logical
detection methods with relative accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18608">Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing. (arXiv:2311.18608v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nam_H/0/1/0/all/0/1">Hyelin Nam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1">Gihyun Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_G/0/1/0/all/0/1">Geon Yeong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a></p>
<p>With the remarkable advent of text-to-image diffusion models, image editing
methods have become more diverse and continue to evolve. A promising recent
approach in this realm is Delta Denoising Score (DDS) - an image editing
technique based on Score Distillation Sampling (SDS) framework that leverages
the rich generative prior of text-to-image diffusion models. However, relying
solely on the difference between scoring functions is insufficient for
preserving specific structural elements from the original image, a crucial
aspect of image editing. Inspired by the similarity and importance differences
between DDS and the contrastive learning for unpaired image-to-image
translation (CUT), here we present an embarrassingly simple yet very powerful
modification of DDS, called Contrastive Denoising Score (CDS), for latent
diffusion models (LDM). Specifically, to enforce structural correspondence
between the input and output while maintaining the controllability of contents,
we introduce a straightforward approach to regulate structural consistency
using CUT loss within the DDS framework. To calculate this loss, instead of
employing auxiliary networks, we utilize the intermediate features of LDM, in
particular, those from the self-attention layers, which possesses rich spatial
information. Our approach enables zero-shot image-to-image translation and
neural radiance field (NeRF) editing, achieving a well-balanced interplay
between maintaining the structural details and transforming content.
Qualitative results and comparisons demonstrates the effectiveness of our
proposed method. Project page with code is available at
https://hyelinnam.github.io/CDS/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18620">Data-driven prediction of tool wear using Bayesian-regularized artificial neural networks. (arXiv:2311.18620v1 [cs.CE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Tam T. Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Airao_J/0/1/0/all/0/1">Jay Airao</a>, <a href="http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1">Panagiotis Karras</a>, <a href="http://arxiv.org/find/cs/1/au:+Hojati_F/0/1/0/all/0/1">Faramarz Hojati</a>, <a href="http://arxiv.org/find/cs/1/au:+Azarhoushang_B/0/1/0/all/0/1">Bahman Azarhoushang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aghababaei_R/0/1/0/all/0/1">Ramin Aghababaei</a></p>
<p>The prediction of tool wear helps minimize costs and enhance product quality
in manufacturing. While existing data-driven models using machine learning and
deep learning have contributed to the accurate prediction of tool wear, they
often lack generality and require substantial training data for high accuracy.
In this paper, we propose a new data-driven model that uses Bayesian
Regularized Artificial Neural Networks (BRANNs) to precisely predict milling
tool wear. BRANNs combine the strengths and leverage the benefits of artificial
neural networks (ANNs) and Bayesian regularization, whereby ANNs learn complex
patterns and Bayesian regularization handles uncertainty and prevents
overfitting, resulting in a more generalized model. We treat both process
parameters and monitoring sensor signals as BRANN input parameters. We
conducted an extensive experimental study featuring four different experimental
data sets, including the NASA Ames milling dataset, the 2010 PHM Data Challenge
dataset, the NUAA Ideahouse tool wear dataset, and an in-house performed
end-milling of the Ti6Al4V dataset. We inspect the impact of input features,
training data size, hidden units, training algorithms, and transfer functions
on the performance of the proposed BRANN model and demonstrate that it
outperforms existing state-of-the-art models in terms of accuracy and
reliability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18636">End-to-end Autonomous Driving using Deep Learning: A Systematic Review. (arXiv:2311.18636v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Apoorv Singh</a></p>
<p>End-to-end autonomous driving is a fully differentiable machine learning
system that takes raw sensor input data and other metadata as prior information
and directly outputs the ego vehicle's control signals or planned trajectories.
This paper attempts to systematically review all recent Machine Learning-based
techniques to perform this end-to-end task, including, but not limited to,
object detection, semantic scene understanding, object tracking, trajectory
predictions, trajectory planning, vehicle control, social behavior, and
communications. This paper focuses on recent fully differentiable end-to-end
reinforcement learning and deep learning-based techniques. Our paper also
builds taxonomies of the significant approaches by sub-grouping them and
showcasing their research trends. Finally, this survey highlights the open
challenges and points out possible future directions to enlighten further
research on the topic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18644">Exploring the hierarchical structure of human plans via program generation. (arXiv:2311.18644v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Correa_C/0/1/0/all/0/1">Carlos G. Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanborn_S/0/1/0/all/0/1">Sophia Sanborn</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_M/0/1/0/all/0/1">Mark K. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Callaway_F/0/1/0/all/0/1">Frederick Callaway</a>, <a href="http://arxiv.org/find/cs/1/au:+Daw_N/0/1/0/all/0/1">Nathaniel D. Daw</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a></p>
<p>Human behavior is inherently hierarchical, resulting from the decomposition
of a task into subtasks or an abstract action into concrete actions. However,
behavior is typically measured as a sequence of actions, which makes it
difficult to infer its hierarchical structure. In this paper, we explore how
people form hierarchically-structured plans, using an experimental paradigm
that makes hierarchical representations observable: participants create
programs that produce sequences of actions in a language with explicit
hierarchical structure. This task lets us test two well-established principles
of human behavior: utility maximization (i.e. using fewer actions) and minimum
description length (MDL; i.e. having a shorter program). We find that humans
are sensitive to both metrics, but that both accounts fail to predict a
qualitative feature of human-created programs, namely that people prefer
programs with reuse over and above the predictions of MDL. We formalize this
preference for reuse by extending the MDL account into a generative model over
programs, modeling hierarchy choice as the induction of a grammar over actions.
Our account can explain the preference for reuse and provides the best
prediction of human behavior, going beyond simple accounts of compressibility
to highlight a principle that guides hierarchical planning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18645">Stochastic Vision Transformers with Wasserstein Distance-Aware Attention. (arXiv:2311.18645v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Erick_F/0/1/0/all/0/1">Franciskus Xaverius Erick</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1">Mina Rezaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_J/0/1/0/all/0/1">Johanna Paula M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a></p>
<p>Self-supervised learning is one of the most promising approaches to acquiring
knowledge from limited labeled data. Despite the substantial advancements made
in recent years, self-supervised models have posed a challenge to
practitioners, as they do not readily provide insight into the model's
confidence and uncertainty. Tackling this issue is no simple feat, primarily
due to the complexity involved in implementing techniques that can make use of
the latent representations learned during pre-training without relying on
explicit labels. Motivated by this, we introduce a new stochastic vision
transformer that integrates uncertainty and distance awareness into
self-supervised learning (SSL) pipelines. Instead of the conventional
deterministic vector embedding, our novel stochastic vision transformer encodes
image patches into elliptical Gaussian distributional embeddings. Notably, the
attention matrices of these stochastic representational embeddings are computed
using Wasserstein distance-based attention, effectively capitalizing on the
distributional nature of these embeddings. Additionally, we propose a
regularization term based on Wasserstein distance for both pre-training and
fine-tuning processes, thereby incorporating distance awareness into latent
representations. We perform extensive experiments across different tasks such
as in-distribution generalization, out-of-distribution detection, dataset
corruption, semi-supervised settings, and transfer learning to other datasets
and tasks. Our proposed method achieves superior accuracy and calibration,
surpassing the self-supervised baseline in a wide range of experiments on a
variety of datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18654">Detailed Human-Centric Text Description-Driven Large Scene Synthesis. (arXiv:2311.18654v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gwanghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1">Dong Un Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_H/0/1/0/all/0/1">Hoigi Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hayeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Se Young Chun</a></p>
<p>Text-driven large scene image synthesis has made significant progress with
diffusion models, but controlling it is challenging. While using additional
spatial controls with corresponding texts has improved the controllability of
large scene synthesis, it is still challenging to faithfully reflect detailed
text descriptions without user-provided controls. Here, we propose
DetText2Scene, a novel text-driven large-scale image synthesis with high
faithfulness, controllability, and naturalness in a global context for the
detailed human-centric text description. Our DetText2Scene consists of 1)
hierarchical keypoint-box layout generation from the detailed description by
leveraging large language model (LLM), 2) view-wise conditioned joint diffusion
process to synthesize a large scene from the given detailed text with
LLM-generated grounded keypoint-box layout and 3) pixel perturbation-based
pyramidal interpolation to progressively refine the large scene for global
coherence. Our DetText2Scene significantly outperforms prior arts in
text-to-large scene synthesis qualitatively and quantitatively, demonstrating
strong faithfulness with detailed descriptions, superior controllability, and
excellent naturalness in a global context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18662">Solving the Team Orienteering Problem with Transformers. (arXiv:2311.18662v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fuertes_D/0/1/0/all/0/1">Daniel Fuertes</a>, <a href="http://arxiv.org/find/cs/1/au:+del_Blanco_C/0/1/0/all/0/1">Carlos R. del-Blanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaureguizar_F/0/1/0/all/0/1">Fernando Jaureguizar</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_N/0/1/0/all/0/1">Narciso Garc&#xed;a</a></p>
<p>Route planning for a fleet of vehicles is an important task in applications
such as package delivery, surveillance, or transportation. This problem is
usually modeled as a Combinatorial Optimization problem named as Team
Orienteering Problem. The most popular Team Orienteering Problem solvers are
mainly based on either linear programming, which provides accurate solutions by
employing a large computation time that grows with the size of the problem, or
heuristic methods, which usually find suboptimal solutions in a shorter amount
of time. In this paper, a multi-agent route planning system capable of solving
the Team Orienteering Problem in a very fast and accurate manner is presented.
The proposed system is based on a centralized Transformer neural network that
can learn to encode the scenario (modeled as a graph) and the context of the
agents to provide fast and accurate solutions. Several experiments have been
performed to demonstrate that the presented system can outperform most of the
state-of-the-art works in terms of computation speed. In addition, the code is
publicly available at \url{<a href="http://gti.ssr.upm.es/data">this http URL</a>}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18663">Choosing the parameter of the Fermat distance: navigating geometry and noise. (arXiv:2311.18663v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Chazal_F/0/1/0/all/0/1">Fr&#xe9;d&#xe9;ric Chazal</a>, <a href="http://arxiv.org/find/stat/1/au:+Ferraris_L/0/1/0/all/0/1">Laure Ferraris</a>, <a href="http://arxiv.org/find/stat/1/au:+Groisman_P/0/1/0/all/0/1">Pablo Groisman</a>, <a href="http://arxiv.org/find/stat/1/au:+Jonckheere_M/0/1/0/all/0/1">Matthieu Jonckheere</a>, <a href="http://arxiv.org/find/stat/1/au:+Pascal_F/0/1/0/all/0/1">Fr&#xe9;d&#xe9;ric Pascal</a>, <a href="http://arxiv.org/find/stat/1/au:+Sapienza_F/0/1/0/all/0/1">Facundo Sapienza</a></p>
<p>The Fermat distance has been recently established as a useful tool for
machine learning tasks when a natural distance is not directly available to the
practitioner or to improve the results given by Euclidean distances by
exploding the geometrical and statistical properties of the dataset. This
distance depends on a parameter $\alpha$ that greatly impacts the performance
of subsequent tasks. Ideally, the value of $\alpha$ should be large enough to
navigate the geometric intricacies inherent to the problem. At the same, it
should remain restrained enough to sidestep any deleterious ramifications
stemming from noise during the process of distance estimation. We study both
theoretically and through simulations how to select this parameter.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18664">Multi-task learning with cross-task consistency for improved depth estimation in colonoscopy. (arXiv:2311.18664v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Solano_P/0/1/0/all/0/1">Pedro Esteban Chavarrias Solano</a>, <a href="http://arxiv.org/find/cs/1/au:+Bulpitt_A/0/1/0/all/0/1">Andrew Bulpitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1">Venkataraman Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sharib Ali</a></p>
<p>Colonoscopy screening is the gold standard procedure for assessing
abnormalities in the colon and rectum, such as ulcers and cancerous polyps.
Measuring the abnormal mucosal area and its 3D reconstruction can help quantify
the surveyed area and objectively evaluate disease burden. However, due to the
complex topology of these organs and variable physical conditions, for example,
lighting, large homogeneous texture, and image modality estimating distance
from the camera aka depth) is highly challenging. Moreover, most colonoscopic
video acquisition is monocular, making the depth estimation a non-trivial
problem. While methods in computer vision for depth estimation have been
proposed and advanced on natural scene datasets, the efficacy of these
techniques has not been widely quantified on colonoscopy datasets. As the
colonic mucosa has several low-texture regions that are not well pronounced,
learning representations from an auxiliary task can improve salient feature
extraction, allowing estimation of accurate camera depths. In this work, we
propose to develop a novel multi-task learning (MTL) approach with a shared
encoder and two decoders, namely a surface normal decoder and a depth estimator
decoder. Our depth estimator incorporates attention mechanisms to enhance
global context awareness. We leverage the surface normal prediction to improve
geometric feature extraction. Also, we apply a cross-task consistency loss
among the two geometrically related tasks, surface normal and camera depth. We
demonstrate an improvement of 14.17% on relative error and 10.4% improvement on
$\delta_{1}$ accuracy over the most accurate baseline state-of-the-art BTS
approach. All experiments are conducted on a recently released C3VD dataset;
thus, we provide a first benchmark of state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18676">DQSSA: A Quantum-Inspired Solution for Maximizing Influence in Online Social Networks (Student Abstract). (arXiv:2311.18676v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Aryaman Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Parth Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vishwakarma_D/0/1/0/all/0/1">Dinesh Kumar Vishwakarma</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_M/0/1/0/all/0/1">Mukesh Prasad</a></p>
<p>Influence Maximization is the task of selecting optimal nodes maximising the
influence spread in social networks. This study proposes a Discretized
Quantum-based Salp Swarm Algorithm (DQSSA) for optimizing influence diffusion
in social networks. By discretizing meta-heuristic algorithms and infusing them
with quantum-inspired enhancements, we address issues like premature
convergence and low efficacy. The proposed method, guided by quantum
principles, offers a promising solution for Influence Maximisation. Experiments
on four real-world datasets reveal DQSSA's superior performance as compared to
established cutting-edge algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18702">CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable Evaluation of Large Language Model Generation. (arXiv:2311.18702v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ke_P/0/1/0/all/0/1">Pei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1">Bosi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhuoer Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xuanyu Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jiale Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Aohan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongning Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a></p>
<p>Since the natural language processing (NLP) community started to make large
language models (LLMs), such as GPT-4, act as a critic to evaluate the quality
of generated texts, most of them only train a critique generation model of a
specific scale on specific datasets. We argue that a comprehensive
investigation on the key factor of LLM-based evaluation models, such as scaling
properties, is lacking, so that it is still inconclusive whether these models
have potential to replace GPT-4's evaluation in practical scenarios. In this
paper, we propose a new critique generation model called CritiqueLLM, which
includes a dialogue-based prompting method for high-quality referenced /
reference-free evaluation data. Experimental results show that our model can
achieve comparable evaluation performance to GPT-4 especially in system-level
correlations, and even outperform GPT-4 in 3 out of 8 tasks in a challenging
reference-free setting. We conduct detailed analysis to show promising scaling
properties of our model in the quality of generated critiques. We also
demonstrate that our generated critiques can act as scalable feedback to
directly improve the generation quality of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18703">Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization. (arXiv:2311.18703v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ornia_D/0/1/0/all/0/1">Daniel Jarne Ornia</a>, <a href="http://arxiv.org/find/cs/1/au:+Delimpaltadakis_G/0/1/0/all/0/1">Giannis Delimpaltadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kober_J/0/1/0/all/0/1">Jens Kober</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_Mora_J/0/1/0/all/0/1">Javier Alonso-Mora</a></p>
<p>In Reinforcement Learning (RL), agents have no incentive to exhibit
predictable behaviors, and are often pushed (through e.g. policy entropy
regularization) to randomize their actions in favor of exploration. From a
human perspective, this makes RL agents hard to interpret and predict, and from
a safety perspective, even harder to formally verify. We propose a novel method
to induce predictable behavior in RL agents, referred to as
Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate
as a predictability measure. We show how the entropy rate can be formulated as
an average reward objective, and since its entropy reward function is
policy-dependent, we introduce an action-dependent surrogate entropy enabling
the use of PG methods. We prove that deterministic policies minimizing the
average surrogate reward exist and also minimize the actual entropy rate, and
show how, given a learned dynamical model, we are able to approximate the value
function associated to the true entropy rate. Finally, we demonstrate the
effectiveness of the approach in RL tasks inspired by human-robot use-cases,
and show how it produces agents with more predictable behavior while achieving
near-optimal rewards.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2009.05794">BARS-CTR: Open Benchmarking for Click-Through Rate Prediction. (arXiv:2009.05794v5 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jieming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiuqiang He</a></p>
<p>Click-through rate (CTR) prediction is a critical task for many applications,
as its accuracy has a direct impact on user experience and platform revenue. In
recent years, CTR prediction has been widely studied in both academia and
industry, resulting in a wide variety of CTR prediction models. Unfortunately,
there is still a lack of standardized benchmarks and uniform evaluation
protocols for CTR prediction research. This leads to non-reproducible or even
inconsistent experimental results among existing studies, which largely limits
the practical value and potential impact of their research. In this work, we
aim to perform open benchmarking for CTR prediction and present a rigorous
comparison of different models in a reproducible manner. To this end, we ran
over 7,000 experiments for more than 12,000 GPU hours in total to re-evaluate
24 existing models on multiple datasets and settings. Surprisingly, our
experiments show that with sufficient hyper-parameter search and model tuning,
many deep models have smaller differences than expected. The results also
reveal that making real progress on the modeling of CTR prediction is indeed a
very challenging research task. We believe that our benchmarking work could not
only allow researchers to gauge the effectiveness of new models conveniently
but also make them fairly compare with the state of the arts. We have publicly
released the benchmarking code, evaluation protocols, and hyper-parameter
settings of our work to promote reproducible research in this field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2109.12613">SimpleX: A Simple and Strong Baseline for Collaborative Filtering. (arXiv:2109.12613v3 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mao_K/0/1/0/all/0/1">Kelong Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jieming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinpeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1">Quanyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zhenhua Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiuqiang He</a></p>
<p>Collaborative filtering (CF) is a widely studied research topic in
recommender systems. The learning of a CF model generally depends on three
major components, namely interaction encoder, loss function, and negative
sampling. While many existing studies focus on the design of more powerful
interaction encoders, the impacts of loss functions and negative sampling
ratios have not yet been well explored. In this work, we show that the choice
of loss function as well as negative sampling ratio is equivalently important.
More specifically, we propose the cosine contrastive loss (CCL) and further
incorporate it to a simple unified CF model, dubbed SimpleX. Extensive
experiments have been conducted on 11 benchmark datasets and compared with 29
existing CF models in total. Surprisingly, the results show that, under our CCL
loss and a large negative sampling ratio, SimpleX can surpass most
sophisticated state-of-the-art models by a large margin (e.g., max 48.5%
improvement in NDCG@20 over LightGCN). We believe that SimpleX could not only
serve as a simple strong baseline to foster future research on CF, but also
shed light on the potential research direction towards improving loss function
and negative sampling. Our source code will be available at
https://reczoo.github.io/SimpleX.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2111.12727">Generating More Pertinent Captions by Leveraging Semantics and Style on Multi-Source Datasets. (arXiv:2111.12727v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1">Marcella Cornia</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1">Lorenzo Baraldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiameni_G/0/1/0/all/0/1">Giuseppe Fiameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a></p>
<p>This paper addresses the task of generating fluent descriptions by training
on a non-uniform combination of data sources, containing both human-annotated
and web-collected captions. Large-scale datasets with noisy image-text pairs,
indeed, provide a sub-optimal source of supervision because of their
low-quality descriptive style, while human-annotated datasets are cleaner but
smaller in scale. To get the best of both worlds, we propose to leverage and
separate semantics and descriptive style through the incorporation of a style
token and keywords extracted through a retrieval component. The proposed model
avoids the need of object detectors, is trained with a single objective of
prompt language modeling, and can replicate the style of human-collected
captions while training on sources with different input styles. Experimentally,
the model shows a strong capability of recognizing real-world concepts and
producing high-quality captions. Extensive experiments are performed on
different image captioning datasets, including CC3M, nocaps, and the
competitive COCO dataset, where our model consistently outperforms baselines
and state-of-the-art approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.03628">GraspCaps: A Capsule Network Approach for Familiar 6DoF Object Grasping. (arXiv:2210.03628v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Velde_T/0/1/0/all/0/1">Tomas van der Velde</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayoobi_H/0/1/0/all/0/1">Hamed Ayoobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasaei_H/0/1/0/all/0/1">Hamidreza Kasaei</a></p>
<p>As robots become more widely available outside industrial settings, the need
for reliable object grasping and manipulation is increasing. In such
environments, robots must be able to grasp and manipulate novel objects in
various situations. This paper presents GraspCaps, a novel architecture based
on Capsule Networks for generating per-point 6D grasp configurations for
familiar objects. GraspCaps extracts a rich feature vector of the objects
present in the point cloud input, which is then used to generate per-point
grasp vectors. This approach allows the network to learn specific grasping
strategies for each object category. In addition to GraspCaps, the paper also
presents a method for generating a large object-grasping dataset using
simulated annealing. The obtained dataset is then used to train the GraspCaps
network. Through extensive experiments, we evaluate the performance of the
proposed approach, particularly in terms of the success rate of grasping
familiar objects in challenging real and simulated scenarios. The experimental
results showed that the overall object-grasping performance of the proposed
approach is significantly better than the selected baseline. This superior
performance highlights the effectiveness of the GraspCaps in achieving
successful object grasping across various scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.06186">Gotcha: Real-Time Video Deepfake Detection via Challenge-Response. (arXiv:2210.06186v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mittal_G/0/1/0/all/0/1">Govind Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1">Chinmay Hegde</a>, <a href="http://arxiv.org/find/cs/1/au:+Memon_N/0/1/0/all/0/1">Nasir Memon</a></p>
<p>With the rise of AI-enabled Real-Time Deepfakes (RTDFs), the integrity of
online video interactions has become a growing concern. RTDFs have now made it
feasible to replace an imposter's face with their victim in live video
interactions. Such advancement in deepfakes also coaxes detection to rise to
the same standard. However, existing deepfake detection techniques are
asynchronous and hence ill-suited for RTDFs. To bridge this gap, we propose a
challenge-response approach that establishes authenticity in live settings. We
focus on talking-head style video interaction and present a taxonomy of
challenges that specifically target inherent limitations of RTDF generation
pipelines. We evaluate representative examples from the taxonomy by collecting
a unique dataset comprising eight challenges, which consistently and visibly
degrades the quality of state-of-the-art deepfake generators. These results are
corroborated both by humans and a new automated scoring function, leading to
88.6\% and 73.2% AUC, respectively. The findings underscore the promising
potential of challenge-response systems for explainable and scalable real-time
deepfake detection in practical scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.06841">Point-DAE: Denoising Autoencoders for Self-supervised Point Cloud Learning. (arXiv:2211.06841v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yabin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jiehong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruihuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a></p>
<p>Masked autoencoder has demonstrated its effectiveness in self-supervised
point cloud learning. Considering that masking is a kind of corruption, in this
work we explore a more general denoising autoencoder for point cloud learning
(Point-DAE) by investigating more types of corruptions beyond masking.
Specifically, we degrade the point cloud with certain corruptions as input, and
learn an encoder-decoder model to reconstruct the original point cloud from its
corrupted version. Three corruption families (\ie, density/masking, noise, and
affine transformation) and a total of fourteen corruption types are
investigated with traditional non-Transformer encoders. Besides the popular
masking corruption, we identify another effective corruption family, \ie,
affine transformation. The affine transformation disturbs all points globally,
which is complementary to the masking corruption where some local regions are
dropped. We also validate the effectiveness of affine transformation corruption
with the Transformer backbones, where we decompose the reconstruction of the
complete point cloud into the reconstructions of detailed local patches and
rough global shape, alleviating the position leakage problem in the
reconstruction. Extensive experiments on tasks of object classification,
few-shot learning, robustness testing, part segmentation, and 3D object
detection validate the effectiveness of the proposed method. The codes are
available at \url{https://github.com/YBZh/Point-DAE}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.13316">Understanding Sample Generation Strategies for Learning Heuristic Functions in Classical Planning. (arXiv:2211.13316v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bettker_R/0/1/0/all/0/1">R. V. Bettker</a>, <a href="http://arxiv.org/find/cs/1/au:+Minini_P/0/1/0/all/0/1">P. P. Minini</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_A/0/1/0/all/0/1">A. G. Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritt_M/0/1/0/all/0/1">M. Ritt</a></p>
<p>We study the problem of learning good heuristic functions for classical
planning tasks with neural networks based on samples represented by states with
their cost-to-goal estimates. The heuristic function is learned for a state
space and goal condition with the number of samples limited to a fraction of
the size of the state space, and must generalize well for all states of the
state space with the same goal condition. Our main goal is to better understand
the influence of sample generation strategies on the performance of a greedy
best-first heuristic search (GBFS) guided by a learned heuristic function. In a
set of controlled experiments, we find that two main factors determine the
quality of the learned heuristic: which states are included in the sample set
and the quality of the cost-to-goal estimates. These two factors are dependent:
having perfect cost-to-goal estimates is insufficient if the samples are not
well distributed across the state space. We also study other effects, such as
adding samples with high-value estimates. Based on our findings, we propose
practical strategies to improve the quality of learned heuristics: three
strategies that aim to generate more representative states and two strategies
that improve the cost-to-goal estimates. Our practical strategies almost double
the mean coverage of a GBFS algorithm guided by a learned heuristic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.09270">Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements. (arXiv:2302.09270v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiawen Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jiale Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhexin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a></p>
<p>As generative large model capabilities advance, safety concerns become more
pronounced in their outputs. To ensure the sustainable growth of the AI
ecosystem, it's imperative to undertake a holistic evaluation and refinement of
associated safety risks. This survey presents a framework for safety research
pertaining to large models, delineating the landscape of safety risks as well
as safety evaluation and improvement methods. We begin by introducing safety
issues of wide concern, then delve into safety evaluation methods for large
models, encompassing preference-based testing, adversarial attack approaches,
issues detection, and other advanced evaluation methods. Additionally, we
explore the strategies for enhancing large model safety from training to
deployment, highlighting cutting-edge safety approaches for each stage in
building large models. Finally, we discuss the core challenges in advancing
towards more responsible AI, including the interpretability of safety
mechanisms, ongoing safety issues, and robustness against malicious attacks.
Through this survey, we aim to provide clear technical guidance for safety
researchers and encourage further study on the safety of large models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.00962">RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding. (arXiv:2304.00962v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1">Runyu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1">Weipeng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xiaojuan Qi</a></p>
<p>We propose a lightweight and scalable Regional Point-Language Contrastive
learning framework, namely \textbf{RegionPLC}, for open-world 3D scene
understanding, aiming to identify and recognize open-set objects and
categories. Specifically, based on our empirical studies, we introduce a
3D-aware SFusion strategy that fuses 3D vision-language pairs derived from
multiple 2D foundation models, yielding high-quality, dense region-level
language descriptions without human 3D annotations. Subsequently, we devise a
region-aware point-discriminative contrastive learning objective to enable
robust and effective 3D learning from dense regional language supervision. We
carry out extensive experiments on ScanNet, ScanNet200, and nuScenes datasets,
and our model outperforms prior 3D open-world scene understanding approaches by
an average of 17.2\% and 9.1\% for semantic and instance segmentation,
respectively, while maintaining greater scalability and lower resource demands.
Furthermore, our method has the flexibility to be effortlessly integrated with
language models to enable open-ended grounded 3D reasoning without extra
task-specific training. Code will be released.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09991">Supporting Human-AI Collaboration in Auditing LLMs with LLMs. (arXiv:2304.09991v3 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rastogi_C/0/1/0/all/0/1">Charvi Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1">Marco Tulio Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+King_N/0/1/0/all/0/1">Nicholas King</a>, <a href="http://arxiv.org/find/cs/1/au:+Nori_H/0/1/0/all/0/1">Harsha Nori</a>, <a href="http://arxiv.org/find/cs/1/au:+Amershi_S/0/1/0/all/0/1">Saleema Amershi</a></p>
<p>Large language models are becoming increasingly pervasive and ubiquitous in
society via deployment in sociotechnical systems. Yet these language models, be
it for classification or generation, have been shown to be biased and behave
irresponsibly, causing harm to people at scale. It is crucial to audit these
language models rigorously. Existing auditing tools leverage either or both
humans and AI to find failures. In this work, we draw upon literature in
human-AI collaboration and sensemaking, and conduct interviews with research
experts in safe and fair AI, to build upon the auditing tool: AdaTest (Ribeiro
and Lundberg, 2022), which is powered by a generative large language model
(LLM). Through the design process we highlight the importance of sensemaking
and human-AI communication to leverage complementary strengths of humans and
generative models in collaborative auditing. To evaluate the effectiveness of
the augmented tool, AdaTest++, we conduct user studies with participants
auditing two commercial language models: OpenAI's GPT-3 and Azure's sentiment
analysis model. Qualitative analysis shows that AdaTest++ effectively leverages
human strengths such as schematization, hypothesis formation and testing.
Further, with our tool, participants identified a variety of failures modes,
covering 26 different topics over 2 tasks, that have been shown before in
formal audits and also those previously under-reported.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.00162">Beyond Prediction: On-street Parking Recommendation using Heterogeneous Graph-based List-wise Ranking. (arXiv:2305.00162v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hanyu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wei Ma</a></p>
<p>To provide real-time parking information, existing studies focus on
predicting parking availability, which seems an indirect approach to saving
drivers' cruising time. In this paper, we first time propose an on-street
parking recommendation (OPR) task to directly recommend a parking space for a
driver. To this end, a learn-to-rank (LTR) based OPR model called OPR-LTR is
built. Specifically, parking recommendation is closely related to the "turnover
events" (state switching between occupied and vacant) of each parking space,
and hence we design a highly efficient heterogeneous graph called ESGraph to
represent historical and real-time meters' turnover events as well as
geographical relations; afterward, a convolution-based event-then-graph network
is used to aggregate and update representations of the heterogeneous graph. A
ranking model is further utilized to learn a score function that helps
recommend a list of ranked parking spots for a specific on-street parking
query. The method is verified using the on-street parking meter data in Hong
Kong and San Francisco. By comparing with the other two types of methods:
prediction-only and prediction-then-recommendation, the proposed
direct-recommendation method achieves satisfactory performance in different
metrics. Extensive experiments also demonstrate that the proposed ESGraph and
the recommendation model are more efficient in terms of computational
efficiency as well as saving drivers' on-street parking time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06988">Self-Chained Image-Language Model for Video Localization and Question Answering. (arXiv:2305.06988v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shoubin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1">Prateek Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a></p>
<p>Recent studies have shown promising results on utilizing large pre-trained
image-language models for video question answering. While these image-language
models can efficiently bootstrap the representation learning of video-language
models, they typically concatenate uniformly sampled video frames as visual
inputs without explicit language-aware, temporal modeling. When only a portion
of a video input is relevant to the language query, such uniform frame sampling
can often lead to missing important visual cues. Although humans often find a
video moment to focus on and rewind the moment to answer questions, training a
query-aware video moment localizer often requires expensive annotations and
high computational costs. To address this issue, we propose Self-Chained Video
Localization-Answering (SeViLA), a novel framework that leverages a single
image-language model (BLIP-2) to tackle both temporal keyframe localization and
QA on videos. SeViLA framework consists of two modules: Localizer and Answerer,
where both are parameter-efficiently fine-tuned from BLIP-2. We propose two
ways of chaining these modules for cascaded inference and self-refinement.
First, in the forward chain, the Localizer finds multiple language-aware
keyframes in a video, which the Answerer uses to predict the answer. Second, in
the reverse chain, the Answerer generates keyframe pseudo-labels to refine the
Localizer, alleviating the need for expensive video moment localization
annotations. Our SeViLA framework outperforms several strong baselines on 5
challenging video QA and event prediction benchmarks, and achieves the
state-of-the-art in both fine-tuning (NExT-QA, STAR) and zero-shot (NExT-QA,
STAR, How2QA, VLEP) settings. We also analyze the impact of Localizer,
comparisons of Localizer with other temporal localization models,
pre-training/self-refinement of Localizer, and varying the number of keyframes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13172">Editing Large Language Models: Problems, Methods, and Opportunities. (arXiv:2305.13172v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yunzhi Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1">Bozhong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Siyuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhoubo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shumin Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a></p>
<p>Despite the ability to train capable LLMs, the methodology for maintaining
their relevancy and rectifying errors remains elusive. To this end, the past
few years have witnessed a surge in techniques for editing LLMs, the objective
of which is to efficiently alter the behavior of LLMs within a specific domain
without negatively impacting performance across other inputs. This paper
embarks on a deep exploration of the problems, methods, and opportunities
related to model editing for LLMs. In particular, we provide an exhaustive
overview of the task definition and challenges associated with model editing,
along with an in-depth empirical analysis of the most progressive methods
currently at our disposal. We also build a new benchmark dataset to facilitate
a more robust evaluation and pinpoint enduring issues intrinsic to existing
techniques. Our objective is to provide valuable insights into the
effectiveness and feasibility of each editing technique, thereby assisting the
community in making informed decisions on the selection of the most appropriate
method for a specific task or context. Code and datasets are available at
https://github.com/zjunlp/EasyEdit.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13236">ADA-GP: Accelerating DNN Training By Adaptive Gradient Prediction. (arXiv:2305.13236v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Janfaza_V/0/1/0/all/0/1">Vahid Janfaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_S/0/1/0/all/0/1">Shantanu Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_F/0/1/0/all/0/1">Farabi Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Muzahid_A/0/1/0/all/0/1">Abdullah Muzahid</a></p>
<p>Neural network training is inherently sequential where the layers finish the
forward propagation in succession, followed by the calculation and
back-propagation of gradients (based on a loss function) starting from the last
layer. The sequential computations significantly slow down neural network
training, especially the deeper ones. Prediction has been successfully used in
many areas of computer architecture to speed up sequential processing.
Therefore, we propose ADA-GP, which uses gradient prediction adaptively to
speed up deep neural network (DNN) training while maintaining accuracy. ADA-GP
works by incorporating a small neural network to predict gradients for
different layers of a DNN model. ADA-GP uses a novel tensor reorganization
method to make it feasible to predict a large number of gradients. ADA-GP
alternates between DNN training using backpropagated gradients and DNN training
using predicted gradients. ADA-GP adaptively adjusts when and for how long
gradient prediction is used to strike a balance between accuracy and
performance. Last but not least, we provide a detailed hardware extension in a
typical DNN accelerator to realize the speed up potential from gradient
prediction. Our extensive experiments with fifteen DNN models show that ADA-GP
can achieve an average speed up of 1.47X with similar or even higher accuracy
than the baseline models. Moreover, it consumes, on average, 34% less energy
due to reduced off-chip memory accesses compared to the baseline accelerator.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18498">ANPL: Towards Natural Programming with Interactive Decomposition. (arXiv:2305.18498v2 [cs.PL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Di Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nan_Z/0/1/0/all/0/1">Ziyuan Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_P/0/1/0/all/0/1">Pengwei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shaohui Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yuanbo Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zidong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1">Yewen Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunji Chen</a></p>
<p>Though LLMs are capable of generating plausible programs, it's challenging to
interact with the LLMs further to revise the program, especially if the user's
specific requirements are different from the initial proposal. In this paper,
we introduce ANPL, an interactive programming system that ensures users can
always refine the generated code towards their specific programmatic intents
via structured decompositions. Borrowing the paradigm of sketching from program
synthesis, an ANPL program consists of a set of input-outputs that it must
satisfy, a ``sketch'' -- control/data flow expressed in precise code (e.g.
Python), and ``holes'' -- sub-modules to be implemented by the LLM specified
with natural language. The user revises an ANPL program by either modifying the
sketch, changing the language used to describe the holes, or providing
additional input-outputs to a particular hole, turning it into a sub-ANPL
program that can be solved recursively. This workflow allows the users to
offload programming burdens to the LLM as much as possible while retaining the
ability to pinpoint and resolve bugs locally, without exposing the rest of the
program to the LLM. We deploy ANPL on the Abstraction and Reasoning Corpus
(ARC), a set of unique tasks that are challenging for state-of-the-art AI
systems, showing it outperforms baseline programming systems that (a) without
the ability to decompose tasks interactively and (b) without the guarantee that
the modules can be correctly composed together. Additional evaluations on APPS,
HumanEval, and real-world programming tasks have validated that the ANPL
framework is applicable to multiple programming domains. We release the ANPL
solutions to the ARC tasks as a dataset, providing insights into how humans
decompose novel tasks programmatically. See our code at
https://iprc-dip.github.io/ANPL/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01286">KL-Divergence Guided Temperature Sampling. (arXiv:2306.01286v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chung-Ching Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Reitter_D/0/1/0/all/0/1">David Reitter</a>, <a href="http://arxiv.org/find/cs/1/au:+Aksitov_R/0/1/0/all/0/1">Renat Aksitov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yun-Hsuan Sung</a></p>
<p>Temperature sampling is a conventional approach to diversify large language
model predictions. As temperature increases, the prediction becomes diverse but
also vulnerable to hallucinations -- generating tokens that are sensible but
not factual. One common approach to mitigate hallucinations is to provide
source/grounding documents and the model is trained to produce predictions that
bind to and are attributable to the provided source. It appears that there is a
trade-off between diversity and attribution. To mitigate any such trade-off, we
propose to relax the constraint of having a fixed temperature over decoding
steps, and a mechanism to guide the dynamic temperature according to its
relevance to the source through KL-divergence. Our experiments justifies the
trade-off, and shows that our sampling algorithm outperforms the conventional
top-k and top-p algorithms in conversational question-answering and
summarization tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04541">Top-Down Knowledge Compilation for Counting Modulo Theories. (arXiv:2306.04541v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Derkinderen_V/0/1/0/all/0/1">Vincent Derkinderen</a>, <a href="http://arxiv.org/find/cs/1/au:+Martires_P/0/1/0/all/0/1">Pedro Zuidberg Dos Martires</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolb_S/0/1/0/all/0/1">Samuel Kolb</a>, <a href="http://arxiv.org/find/cs/1/au:+Morettin_P/0/1/0/all/0/1">Paolo Morettin</a></p>
<p>Propositional model counting (#SAT) can be solved efficiently when the input
formula is in deterministic decomposable negation normal form (d-DNNF).
Translating an arbitrary formula into a representation that allows inference
tasks, such as counting, to be performed efficiently, is called knowledge
compilation. Top-down knowledge compilation is a state-of-the-art technique for
solving #SAT problems that leverages the traces of exhaustive DPLL search to
obtain d-DNNF representations. While knowledge compilation is well studied for
propositional approaches, knowledge compilation for the (quantifier free)
counting modulo theory setting (#SMT) has been studied to a much lesser degree.
In this paper, we discuss compilation strategies for #SMT. We specifically
advocate for a top-down compiler based on the traces of exhaustive DPLL(T)
search.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05846">Motion-DVAE: Unsupervised learning for fast human motion denoising. (arXiv:2306.05846v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fiche_G/0/1/0/all/0/1">Gu&#xe9;nol&#xe9; Fiche</a>, <a href="http://arxiv.org/find/cs/1/au:+Leglaive_S/0/1/0/all/0/1">Simon Leglaive</a>, <a href="http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1">Xavier Alameda-Pineda</a>, <a href="http://arxiv.org/find/cs/1/au:+Seguier_R/0/1/0/all/0/1">Renaud S&#xe9;guier</a></p>
<p>Pose and motion priors are crucial for recovering realistic and accurate
human motion from noisy observations. Substantial progress has been made on
pose and shape estimation from images, and recent works showed impressive
results using priors to refine frame-wise predictions. However, a lot of motion
priors only model transitions between consecutive poses and are used in
time-consuming optimization procedures, which is problematic for many
applications requiring real-time motion capture. We introduce Motion-DVAE, a
motion prior to capture the short-term dependencies of human motion. As part of
the dynamical variational autoencoder (DVAE) models family, Motion-DVAE
combines the generative capability of VAE models and the temporal modeling of
recurrent architectures. Together with Motion-DVAE, we introduce an
unsupervised learned denoising method unifying regression- and
optimization-based approaches in a single framework for real-time 3D human pose
estimation. Experiments show that the proposed approach reaches competitive
performance with state-of-the-art methods while being much faster.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07266">Operator Learning with Neural Fields: Tackling PDEs on General Geometries. (arXiv:2306.07266v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Serrano_L/0/1/0/all/0/1">Louis Serrano</a>, <a href="http://arxiv.org/find/cs/1/au:+Boudec_L/0/1/0/all/0/1">Lise Le Boudec</a>, <a href="http://arxiv.org/find/cs/1/au:+Koupai_A/0/1/0/all/0/1">Armand Kassa&#xef; Koupa&#xef;</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Thomas X Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vittaut_J/0/1/0/all/0/1">Jean-No&#xeb;l Vittaut</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a></p>
<p>Machine learning approaches for solving partial differential equations
require learning mappings between function spaces. While convolutional or graph
neural networks are constrained to discretized functions, neural operators
present a promising milestone toward mapping functions directly. Despite
impressive results they still face challenges with respect to the domain
geometry and typically rely on some form of discretization. In order to
alleviate such limitations, we present CORAL, a new method that leverages
coordinate-based networks for solving PDEs on general geometries. CORAL is
designed to remove constraints on the input mesh, making it applicable to any
spatial sampling and geometry. Its ability extends to diverse problem domains,
including PDE solving, spatio-temporal forecasting, and inverse problems like
geometric design. CORAL demonstrates robust performance across multiple
resolutions and performs well in both convex and non-convex domains, surpassing
or performing on par with state-of-the-art models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.08018">Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v4 [q-bio.QM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Fang_Y/0/1/0/all/0/1">Yin Fang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liang_X/0/1/0/all/0/1">Xiaozhuan Liang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_K/0/1/0/all/0/1">Kangwei Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_R/0/1/0/all/0/1">Rui Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Fan_X/0/1/0/all/0/1">Xiaohui Fan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a></p>
<p>Large Language Models (LLMs), with their remarkable task-handling
capabilities and innovative outputs, have catalyzed significant advancements
across a spectrum of fields. However, their proficiency within specialized
domains such as biomolecular studies remains limited. To address this
challenge, we introduce Mol-Instructions, a comprehensive instruction dataset
designed for the biomolecular domain. Mol-Instructions encompasses three key
components: molecule-oriented instructions, protein-oriented instructions, and
biomolecular text instructions. Each component aims to improve the
understanding and prediction capabilities of LLMs concerning biomolecular
features and behaviors. Through extensive instruction tuning experiments on
LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large
models' performance in the intricate realm of biomolecular studies, thus
fostering progress in the biomolecular research community. Mol-Instructions is
publicly available for ongoing research and will undergo regular updates to
enhance its applicability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10012">MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing. (arXiv:2306.10012v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_L/0/1/0/all/0/1">Lingbo Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yu Su</a></p>
<p>Text-guided image editing is widely needed in daily life, ranging from
personal use to professional applications such as Photoshop. However, existing
methods are either zero-shot or trained on an automatically synthesized
dataset, which contains a high volume of noise. Thus, they still require lots
of manual tuning to produce desirable outcomes in practice. To address this
issue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/),
the first large-scale, manually annotated dataset for instruction-guided real
image editing that covers diverse scenarios: single-turn, multi-turn,
mask-provided, and mask-free editing. MagicBrush comprises over 10K manually
annotated triplets (source image, instruction, target image), which supports
trainining large-scale text-guided image editing models. We fine-tune
InstructPix2Pix on MagicBrush and show that the new model can produce much
better images according to human evaluation. We further conduct extensive
experiments to evaluate current image editing baselines from multiple
dimensions including quantitative, qualitative, and human evaluations. The
results reveal the challenging nature of our dataset and the gap between
current baselines and real-world editing needs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12230">Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training. (arXiv:2306.12230v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nowak_A/0/1/0/all/0/1">Aleksandra I. Nowak</a>, <a href="http://arxiv.org/find/cs/1/au:+Grooten_B/0/1/0/all/0/1">Bram Grooten</a>, <a href="http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1">Decebal Constantin Mocanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1">Jacek Tabor</a></p>
<p>Dynamic Sparse Training (DST) is a rapidly evolving area of research that
seeks to optimize the sparse initialization of a neural network by adapting its
topology during training. It has been shown that under specific conditions, DST
is able to outperform dense models. The key components of this framework are
the pruning and growing criteria, which are repeatedly applied during the
training process to adjust the network's sparse connectivity. While the growing
criterion's impact on DST performance is relatively well studied, the influence
of the pruning criterion remains overlooked. To address this issue, we design
and perform an extensive empirical analysis of various pruning criteria to
better understand their impact on the dynamics of DST solutions. Surprisingly,
we find that most of the studied methods yield similar results. The differences
become more significant in the low-density regime, where the best performance
is predominantly given by the simplest technique: magnitude-based pruning. The
code is provided at https://github.com/alooow/fantastic_weights_paper
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03170">Focused Transformer: Contrastive Training for Context Scaling. (arXiv:2307.03170v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tworkowski_S/0/1/0/all/0/1">Szymon Tworkowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Staniszewski_K/0/1/0/all/0/1">Konrad Staniszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacek_M/0/1/0/all/0/1">Miko&#x142;aj Pacek</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuhuai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1">Henryk Michalewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Milos_P/0/1/0/all/0/1">Piotr Mi&#x142;o&#x15b;</a></p>
<p>Large language models have an exceptional capability to incorporate new
information in a contextual manner. However, the full potential of such an
approach is often restrained due to a limitation in the effective context
length. One solution to this issue is to endow an attention layer with access
to an external memory, which comprises of (key, value) pairs. Yet, as the
number of documents increases, the proportion of relevant keys to irrelevant
ones decreases, leading the model to focus more on the irrelevant keys. We
identify a significant challenge, dubbed the distraction issue, where keys
linked to different semantic values might overlap, making them hard to
distinguish. To tackle this problem, we introduce the Focused Transformer
(FoT), a technique that employs a training process inspired by contrastive
learning. This novel approach enhances the structure of the (key, value) space,
enabling an extension of the context length. Our method allows for fine-tuning
pre-existing, large-scale models to lengthen their effective context. This is
demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The
resulting models, which we name LongLLaMA, exhibit advancements in tasks
requiring a long context. We further illustrate that our LongLLaMA models
adeptly manage a $256 k$ context length for passkey retrieval.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03913">Applying HCAI in developing effective human-AI teaming: A perspective from human-AI joint cognitive systems. (arXiv:2307.03913v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zaifeng Gao</a></p>
<p>Research and application have used human-AI teaming (HAT) as a new paradigm
to develop AI systems. HAT recognizes that AI will function as a teammate
instead of simply a tool in collaboration with humans. Effective human-AI teams
need to be capable of taking advantage of the unique abilities of both humans
and AI while overcoming the known challenges and limitations of each member,
augmenting human capabilities, and raising joint performance beyond that of
either entity. The National AI Research and Strategic Plan 2023 update has
recognized that research programs focusing primarily on the independent
performance of AI systems generally fail to consider the functionality that AI
must provide within the context of dynamic, adaptive, and collaborative teams
and calls for further research on human-AI teaming and collaboration. However,
there has been debate about whether AI can work as a teammate with humans. The
primary concern is that adopting the "teaming" paradigm contradicts the
human-centered AI (HCAI) approach, resulting in humans losing control of AI
systems. This article further analyzes the HAT paradigm and the debates.
Specifically, we elaborate on our proposed conceptual framework of human-AI
joint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI
umbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The
implications and future work for HAIJCS are also discussed.
</p>
<p>Insights: AI has led to the emergence of a new form of human-machine
relationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems;
We must follow a human-centered AI (HCAI) approach when applying HAT as a new
design paradigm; We propose a conceptual framework of human-AI joint cognitive
systems (HAIJCS) to represent and implement HAT for developing effective
human-AI teaming
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00629">Hessian-Aware Bayesian Optimization for Decision Making Systems. (arXiv:2308.00629v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rajpal_M/0/1/0/all/0/1">Mohit Rajpal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_L/0/1/0/all/0/1">Lac Gia Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yehong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1">Bryan Kian Hsiang Low</a></p>
<p>Many approaches for optimizing decision making systems rely on gradient based
methods requiring informative feedback from the environment. However, in the
case where such feedback is sparse or uninformative, such approaches may result
in poor performance. Derivative-free approaches such as Bayesian Optimization
mitigate the dependency on the quality of gradient feedback, but are known to
scale poorly in the high-dimension setting of complex decision making systems.
This problem is exacerbated if the system requires interactions between several
actors cooperating to accomplish a shared goal. To address the dimensionality
challenge, we propose a compact multi-layered architecture modeling the
dynamics of actor interactions through the concept of role. Additionally, we
introduce Hessian-aware Bayesian Optimization to efficiently optimize the
multi-layered architecture parameterized by a large number of parameters.
Experimental results demonstrate that our method (HA-GP-UCB) works effectively
on several benchmarks under resource constraints and malformed feedback
settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10997">MarkovGen: Structured Prediction for Efficient Text-to-Image Generation. (arXiv:2308.10997v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jayasumana_S/0/1/0/all/0/1">Sadeep Jayasumana</a>, <a href="http://arxiv.org/find/cs/1/au:+Glasner_D/0/1/0/all/0/1">Daniel Glasner</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1">Srikumar Ramalingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1">Andreas Veit</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Ayan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a></p>
<p>Modern text-to-image generation models produce high-quality images that are
both photorealistic and faithful to the text prompts. However, this quality
comes at significant computational cost: nearly all of these models are
iterative and require running sampling multiple times with large models. This
iterative process is needed to ensure that different regions of the image are
not only aligned with the text prompt, but also compatible with each other. In
this work, we propose a light-weight approach to achieving this compatibility
between different regions of an image, using a Markov Random Field (MRF) model.
We demonstrate the effectiveness of this method on top of the latent
token-based Muse text-to-image model. The MRF richly encodes the compatibility
among image tokens at different spatial locations to improve quality and
significantly reduce the required number of Muse sampling steps. Inference with
the MRF is significantly cheaper, and its parameters can be quickly learned
through back-propagation by modeling MRF inference as a differentiable
neural-network layer. Our full model, MarkovGen, uses this proposed MRF model
to both speed up Muse by 1.5X and produce higher quality images by decreasing
undesirable image artifacts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03720">A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism. (arXiv:2309.03720v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Svoboda_R/0/1/0/all/0/1">Radek Svoboda</a>, <a href="http://arxiv.org/find/cs/1/au:+Basterrech_S/0/1/0/all/0/1">Sebastian Basterrech</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozal_J/0/1/0/all/0/1">J&#x119;drzej Kozal</a>, <a href="http://arxiv.org/find/cs/1/au:+Platos_J/0/1/0/all/0/1">Jan Plato&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Wozniak_M/0/1/0/all/0/1">Micha&#x142; Wo&#x17a;niak</a></p>
<p>Forecasting natural gas consumption, considering seasonality and trends, is
crucial in planning its supply and consumption and optimizing the cost of
obtaining it, mainly by industrial entities. However, in times of threats to
its supply, it is also a critical element that guarantees the supply of this
raw material to meet individual consumers' needs, ensuring society's energy
security. This article introduces a novel multistep ahead forecasting of
natural gas consumption with change point detection integration for model
collection selection with continual learning capabilities using data stream
processing. The performance of the forecasting models based on the proposed
approach is evaluated in a complex real-world use case of natural gas
consumption forecasting. We employed Hoeffding tree predictors as forecasting
models and the Pruned Exact Linear Time (PELT) algorithm for the change point
detection procedure. The change point detection integration enables selecting a
different model collection for successive time frames. Thus, three model
collection selection procedures (with and without an error feedback loop) are
defined and evaluated for forecasting scenarios with various densities of
detected change points. These models were compared with change point agnostic
baseline approaches. Our experiments show that fewer change points result in a
lower forecasting error regardless of the model collection selection procedure
employed. Also, simpler model collection selection procedures omitting
forecasting error feedback leads to more robust forecasting models suitable for
continual learning tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.09737">Moving Object Detection and Tracking with 4D Radar Point Cloud. (arXiv:2309.09737v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhijun Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Fangqiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1">Hantao Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chris Xiaoxuan Lu</a></p>
<p>Mobile autonomy relies on the precise perception of dynamic environments.
Robustly tracking moving objects in 3D world thus plays a pivotal role for
applications like trajectory prediction, obstacle avoidance, and path planning.
While most current methods utilize LiDARs or cameras for Multiple Object
Tracking (MOT), the capabilities of 4D imaging radars remain largely
unexplored. Recognizing the challenges posed by radar noise and point sparsity
in 4D radar data, we introduce RaTrack, an innovative solution tailored for
radar-based tracking. Bypassing the typical reliance on specific object types
and 3D bounding boxes, our method focuses on motion segmentation and
clustering, enriched by a motion estimation module. Evaluated on the
View-of-Delft dataset, RaTrack showcases superior tracking precision of moving
objects, largely surpassing the performance of the state of the art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.09809">A Continual Learning Paradigm for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks. (arXiv:2309.09809v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1">Wentao Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_N/0/1/0/all/0/1">Nan Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zeqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuojie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Keze Wang</a></p>
<p>Recently, the visual programming framework (VisProg) has emerged as a
significant framework for executing compositional visual tasks due to its
interpretability and flexibility. However, the performance of VisProg on
specific Visual Reasoning (VR) tasks is markedly inferior compared to
well-trained task-specific models since its employed visual sub-modules have
limited generalization capabilities. Due to the non-differentiability of
VisProg, it is quite challenging to improve these visual sub-modules within
VisProg for the specific VR task while maintaining their generalizability on
the un-seen tasks. Attempt to overcome these difficulties, we propose CLVP, a
Continuous Learning paradigm for VisProg across various visual reasoning tasks.
Specifically, our CLVP distills the capabilities of well-trained task-specific
models into the visual sub-modules in a stepwise and anti-forgetting manner.
This can continually improve the performance of VisProg on multiple visual
tasks while preserving the flexibility of VisProg. Extensive and comprehensive
experimental results demonstrate that our CLVP obtains significant performance
gains on specific VR benchmarks, i.e., GQA (+1.4%) and NLVRv2 (+5.6%), compared
to the VisProg baseline, and also maintains a promising generalizability for VR
on un-seen and previous learned tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.11526">Likelihood-based Sensor Calibration using Affine Transformation. (arXiv:2309.11526v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Machhamer_R/0/1/0/all/0/1">R&#xfc;diger Machhamer</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazlic_L/0/1/0/all/0/1">Lejla Begic Fazlic</a>, <a href="http://arxiv.org/find/cs/1/au:+Guven_E/0/1/0/all/0/1">Eray Guven</a>, <a href="http://arxiv.org/find/cs/1/au:+Junk_D/0/1/0/all/0/1">David Junk</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurt_G/0/1/0/all/0/1">Gunes Karabulut Kurt</a>, <a href="http://arxiv.org/find/cs/1/au:+Naumann_S/0/1/0/all/0/1">Stefan Naumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Didas_S/0/1/0/all/0/1">Stephan Didas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gollmer_K/0/1/0/all/0/1">Klaus-Uwe Gollmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmann_R/0/1/0/all/0/1">Ralph Bergmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Timm_I/0/1/0/all/0/1">Ingo J. Timm</a>, <a href="http://arxiv.org/find/cs/1/au:+Dartmann_G/0/1/0/all/0/1">Guido Dartmann</a></p>
<p>An important task in the field of sensor technology is the efficient
implementation of adaptation procedures of measurements from one sensor to
another sensor of identical design. One idea is to use the estimation of an
affine transformation between different systems, which can be improved by the
knowledge of experts. This paper presents an improved solution from Glacier
Research that was published back in 1973. The results demonstrate the
adaptability of this solution for various applications, including software
calibration of sensors, implementation of expert-based adaptation, and paving
the way for future advancements such as distributed learning methods. One idea
here is to use the knowledge of experts for estimating an affine transformation
between different systems. We evaluate our research with simulations and also
with real measured data of a multi-sensor board with 8 identical sensors. Both
data set and evaluation script are provided for download. The results show an
improvement for both the simulation and the experiments with real data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12673">On Sparse Modern Hopfield Model. (arXiv:2309.12673v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jerry Yao-Chieh Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Donglin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dennis Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Han Liu</a></p>
<p>We introduce the sparse modern Hopfield model as a sparse extension of the
modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield
model equips a memory-retrieval dynamics whose one-step approximation
corresponds to the sparse attention mechanism. Theoretically, our key
contribution is a principled derivation of a closed-form sparse Hopfield energy
using the convex conjugate of the sparse entropic regularizer. Building upon
this, we derive the sparse memory retrieval dynamics from the sparse energy
function and show its one-step approximation is equivalent to the
sparse-structured attention. Importantly, we provide a sparsity-dependent
memory retrieval error bound which is provably tighter than its dense analog.
The conditions for the benefits of sparsity to arise are therefore identified
and discussed. In addition, we show that the sparse modern Hopfield model
maintains the robust theoretical properties of its dense counterpart, including
rapid fixed point convergence and exponential memory capacity. Empirically, we
use both synthetic and real-world datasets to demonstrate that the sparse
Hopfield model outperforms its dense counterpart in many situations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12677">TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population. (arXiv:2309.12677v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Ruyi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhibin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yan Ding</a></p>
<p>Understanding trajectory diversity is a fundamental aspect of addressing
practical traffic tasks. However, capturing the diversity of trajectories
presents challenges, particularly with traditional machine learning and
recurrent neural networks due to the requirement of large-scale parameters. The
emerging Transformer technology, renowned for its parallel computation
capabilities enabling the utilization of models with hundreds of millions of
parameters, offers a promising solution. In this study, we apply the
Transformer architecture to traffic tasks, aiming to learn the diversity of
trajectories within vehicle populations. We analyze the Transformer's attention
mechanism and its adaptability to the goals of traffic tasks, and subsequently,
design specific pre-training tasks. To achieve this, we create a data structure
tailored to the attention mechanism and introduce a set of noises that
correspond to spatio-temporal demands, which are incorporated into the
structured data during the pre-training process. The designed pre-training
model demonstrates excellent performance in capturing the spatial distribution
of the vehicle population, with no instances of vehicle overlap and an RMSE of
0.6059 when compared to the ground truth values. In the context of time series
prediction, approximately 95% of the predicted trajectories' speeds closely
align with the true speeds, within a deviation of 7.5144m/s. Furthermore, in
the stability test, the model exhibits robustness by continuously predicting a
time series ten times longer than the input sequence, delivering smooth
trajectories and showcasing diverse driving behaviors. The pre-trained model
also provides a good basis for downstream fine-tuning tasks. The number of
parameters of our model is over 50 million.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.16573">Language Models as a Service: Overview of a New Paradigm and its Challenges. (arXiv:2309.16573v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1">Emanuele La Malfa</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrov_A/0/1/0/all/0/1">Aleksandar Petrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Frieder_S/0/1/0/all/0/1">Simon Frieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinhuber_C/0/1/0/all/0/1">Christoph Weinhuber</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnell_R/0/1/0/all/0/1">Ryan Burnell</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazar_R/0/1/0/all/0/1">Raza Nazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1">Anthony G. Cohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shadbolt_N/0/1/0/all/0/1">Nigel Shadbolt</a>, <a href="http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1">Michael Wooldridge</a></p>
<p>Some of the most powerful language models currently are proprietary systems,
accessible only via (typically restrictive) web or software programming
interfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm. In
contrast with scenarios where full model access is available, as in the case of
open-source models, such closed-off language models present specific challenges
for evaluating, benchmarking, and testing them. This paper has two goals: on
the one hand, we delineate how the aforementioned challenges act as impediments
to the accessibility, replicability, reliability, and trustworthiness of LMaaS.
We systematically examine the issues that arise from a lack of information
about language models for each of these four aspects. We conduct a detailed
analysis of existing solutions and put forth a number of considered
recommendations, and highlight the directions for future advancements. On the
other hand, it serves as a comprehensive resource for existing knowledge on
current, major LMaaS, offering a synthesized overview of the licences and
capabilities their interfaces offer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00533">SELF: Language-Driven Self-Evolution for Large Language Models. (arXiv:2310.00533v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianqiao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1">Wanjun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenyong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yufei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1">Fei Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baojun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weichao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1">Lifeng Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a></p>
<p>Large Language Models (LLMs) have demonstrated remarkable versatility across
various domains. To further advance LLMs, we propose 'SELF' (Self-Evolution
with Language Feedback), a novel approach that enables LLMs to self-improve
through self-reflection, akin to human learning processes. SELF initiates with
a meta-skill learning process that equips the LLMs with capabilities for
self-feedback and self-refinement. Subsequently, the model undergoes an
iterative process of self-evolution. In each iteration, it utilizes an
unlabeled dataset of instructions to generate initial responses. These
responses are enhanced through self-feedback and self-refinement. The model is
then fine-tuned using this enhanced data. The model undergoes progressive
improvement through this iterative self-evolution process. Moreover, the SELF
framework enables the model to apply self-refinement during inference, which
further improves response quality. Our experiments in mathematics and general
tasks demonstrate that SELF can enhance the capabilities of LLMs without human
intervention. The SELF framework indicates a promising direction for the
autonomous evolution of LLMs, transitioning them from passive information
receivers to active participants in their development.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05518">On Double Descent in Reinforcement Learning with LSTD and Random Features. (arXiv:2310.05518v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brellmann_D/0/1/0/all/0/1">David Brellmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Berthier_E/0/1/0/all/0/1">Elo&#xef;se Berthier</a>, <a href="http://arxiv.org/find/cs/1/au:+Filliat_D/0/1/0/all/0/1">David Filliat</a>, <a href="http://arxiv.org/find/cs/1/au:+Frehse_G/0/1/0/all/0/1">Goran Frehse</a></p>
<p>Temporal Difference (TD) algorithms are widely used in Deep Reinforcement
Learning (RL). Their performance is heavily influenced by the size of the
neural network. While in supervised learning, the regime of
over-parameterization and its benefits are well understood, the situation in RL
is much less clear. In this paper, we present a theoretical analysis of the
influence of network size and $l_2$-regularization on performance. We identify
the ratio between the number of parameters and the number of visited states as
a crucial factor and define over-parameterization as the regime when it is
larger than one. Furthermore, we observe a double descent phenomenon, i.e., a
sudden drop in performance around the parameter/state ratio of one. Leveraging
random features and the lazy training regime, we study the regularized
Least-Square Temporal Difference (LSTD) algorithm in an asymptotic regime, as
both the number of parameters and states go to infinity, maintaining a constant
ratio. We derive deterministic limits of both the empirical and the true
Mean-Square Bellman Error (MSBE) that feature correction terms responsible for
the double-descent. Correction terms vanish when the $l_2$-regularization is
increased or the number of unvisited states goes to zero. Numerical experiments
with synthetic and small real-world environments closely match the theoretical
predictions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05566">Aggregated f-average Neural Network for Interpretable Ensembling. (arXiv:2310.05566v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vu_M/0/1/0/all/0/1">Mathieu Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chouzenoux_E/0/1/0/all/0/1">Emilie Chouzenoux</a>, <a href="http://arxiv.org/find/cs/1/au:+Pesquet_J/0/1/0/all/0/1">Jean-Christophe Pesquet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a></p>
<p>Ensemble learning leverages multiple models (i.e., weak learners) on a common
machine learning task to enhance prediction performance. Basic ensembling
approaches average the weak learners outputs, while more sophisticated ones
stack a machine learning model in between the weak learners outputs and the
final prediction. This work fuses both aforementioned frameworks. We introduce
an aggregated f-average (AFA) shallow neural network which models and combines
different types of averages to perform an optimal aggregation of the weak
learners predictions. We emphasise its interpretable architecture and simple
training strategy, and illustrate its good performance on the problem of
few-shot class incremental learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07918">Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deuschel_J/0/1/0/all/0/1">Jannik Deuschel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellington_C/0/1/0/all/0/1">Caleb N. Ellington</a>, <a href="http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1">Benjamin J. Lengerich</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yingtao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Friederich_P/0/1/0/all/0/1">Pascal Friederich</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric P. Xing</a></p>
<p>Interpretable policy learning seeks to estimate intelligible decision
policies from observed actions; however, existing models fall short by forcing
a tradeoff between accuracy and interpretability. This tradeoff limits
data-driven interpretations of human decision-making process. e.g. to audit
medical decisions for biases and suboptimal practices, we require models of
decision processes which provide concise descriptions of complex behaviors.
Fundamentally, existing approaches are burdened by this tradeoff because they
represent the underlying decision process as a universal policy, when in fact
human decisions are dynamic and can change drastically with contextual
information. Thus, we propose Contextualized Policy Recovery (CPR), which
re-frames the problem of modeling complex decision processes as a multi-task
learning problem in which complex decision policies are comprised of
context-specific policies. CPR models each context-specific policy as a linear
observation-to-action mapping, and generates new decision models
$\textit{on-demand}$ as contexts are updated with new observations. CPR is
compatible with fully offline and partially observable decision environments,
and can be tailored to incorporate any recurrent black-box model or
interpretable decision model. We assess CPR through studies on simulated and
real data, achieving state-of-the-art performance on the canonical tasks of
predicting antibiotic prescription in intensive care units ($+22\%$ AUROC vs.
previous SOTA) and predicting MRI prescription for Alzheimer's patients
($+7.7\%$ AUROC vs. previous SOTA). With this improvement in predictive
performance, CPR closes the accuracy gap between interpretable and black-box
methods for policy learning, allowing high-resolution exploration and analysis
of context-specific decision models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08540">Do pretrained Transformers Really Learn In-context by Gradient Descent?. (arXiv:2310.08540v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Lingfeng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1">Aayush Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1">Daniel Khashabi</a></p>
<p>The emergence of In-Context Learning (ICL) in LLMs remains a significant
phenomenon with little understanding. To explain ICL, recent studies try to
shed light on ICL by connecting it to Gradient Descent (GD). However, the
question is, do these hold up in practice in actual pre-trained models?
</p>
<p>We highlight the limiting assumptions in prior works that make their context
considerably different from the practical context in which language models are
trained. For example, the theoretical hand-constructed weights used in these
studies have properties that don't match those of real LLMs. Furthermore, their
experimental verification uses \emph{ICL objective} (training models explicitly
for ICL), which differs from the emergent ICL in the wild.
</p>
<p>We also look for evidence in real models. We observe that ICL and GD have
different sensitivity to the order in which they observe demonstrations.
Finally, we probe and compare the ICL vs. GD hypothesis in a natural setting.
We conduct comprehensive empirical analyses on language models pre-trained on
natural data (LLaMa-7B). Our comparisons of three performance metrics highlight
the inconsistent behavior of ICL and GD as a function of various factors such
as datasets, models, and the number of demonstrations. We observe that ICL and
GD modify the output distribution of language models differently. These results
indicate that the equivalence between ICL and GD remains an open hypothesis and
calls for further studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15065">Synergizing Human-AI Agency: A Guide of 23 Heuristics for Service Co-Creation with LLM-Based Agents. (arXiv:2310.15065v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1">Qingxiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhongwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhry_A/0/1/0/all/0/1">Abhinav Choudhry</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yongming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yun Huang</a></p>
<p>This empirical study serves as a primer for interested service providers to
determine if and how Large Language Models (LLMs) technology will be integrated
for their practitioners and the broader community. We investigate the mutual
learning journey of non-AI experts and AI through CoAGent, a service
co-creation tool with LLM-based agents. Engaging in a three-stage participatory
design processes, we work with with 23 domain experts from public libraries
across the U.S., uncovering their fundamental challenges of integrating AI into
human workflows. Our findings provide 23 actionable "heuristics for service
co-creation with AI", highlighting the nuanced shared responsibilities between
humans and AI. We further exemplar 9 foundational agency aspects for AI,
emphasizing essentials like ownership, fair treatment, and freedom of
expression. Our innovative approach enriches the participatory design model by
incorporating AI as crucial stakeholders and utilizing AI-AI interaction to
identify blind spots. Collectively, these insights pave the way for synergistic
and ethical human-AI co-creation in service contexts, preparing for workforce
ecosystems where AI coexists.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.17940">Unified Segment-to-Segment Framework for Simultaneous Sequence Generation. (arXiv:2310.17940v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaolei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a></p>
<p>Simultaneous sequence generation is a pivotal task for real-time scenarios,
such as streaming speech recognition, simultaneous machine translation and
simultaneous speech translation, where the target sequence is generated while
receiving the source sequence. The crux of achieving high-quality generation
with low latency lies in identifying the optimal moments for generating,
accomplished by learning a mapping between the source and target sequences.
However, existing methods often rely on task-specific heuristics for different
sequence types, limiting the model's capacity to adaptively learn the
source-target mapping and hindering the exploration of multi-task learning for
various simultaneous tasks. In this paper, we propose a unified
segment-to-segment framework (Seg2Seg) for simultaneous sequence generation,
which learns the mapping in an adaptive and unified manner. During the process
of simultaneous generation, the model alternates between waiting for a source
segment and generating a target segment, making the segment serve as the
natural bridge between the source and target. To accomplish this, Seg2Seg
introduces a latent segment as the pivot between source to target and explores
all potential source-target mappings via the proposed expectation training,
thereby learning the optimal moments for generating. Experiments on multiple
simultaneous generation tasks demonstrate that Seg2Seg achieves
state-of-the-art performance and exhibits better generality across various
tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01723">Towards Calibrated Robust Fine-Tuning of Vision-Language Models. (arXiv:2311.01723v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oh_C/0/1/0/all/0/1">Changdae Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Mijoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1">Hyesu Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Junhyeok Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_E/0/1/0/all/0/1">Euiseog Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhi-Qi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kyungwoo Song</a></p>
<p>While fine-tuning unlocks the potential of a pre-trained model for a specific
task, it compromises the model's ability to generalize to out-of-distribution
(OOD) datasets. To mitigate this, robust fine-tuning aims to ensure performance
on OOD datasets as well as on an in-distribution (ID) dataset for which the
model is being tuned. However, another criterion for reliable machine learning
(ML), confidence calibration, has been overlooked despite its increasing demand
for real-world high-stakes ML applications (e.g., autonomous driving and
medical diagnosis). For the first time, we raise concerns about the calibration
of fine-tuned vision-language models (VLMs) under distribution shift by showing
that naive fine-tuning and even state-of-the-art robust fine-tuning methods
hurt the calibration of pre-trained VLMs, especially on OOD datasets. To
address this issue, we provide a simple approach, called calibrated robust
fine-tuning (CaRot), that incentivizes calibration and robustness on both ID
and OOD datasets. Empirical results on ImageNet-1K distribution shift
evaluation verify the effectiveness of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05997">JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models. (arXiv:2311.05997v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zihao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1">Shaofei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anji Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yonggang Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Jinbing Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bowei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haowei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhaofeng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zilong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaojian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yitao Liang</a></p>
<p>Achieving human-like planning and control with multimodal observations in an
open world is a key milestone for more functional generalist agents. Existing
approaches can handle certain long-horizon tasks in an open world. However,
they still struggle when the number of open-world tasks could potentially be
infinite and lack the capability to progressively enhance task completion as
game time progresses. We introduce JARVIS-1, an open-world agent that can
perceive multimodal input (visual observations and human instructions),
generate sophisticated plans, and perform embodied control, all within the
popular yet challenging open-world Minecraft universe. Specifically, we develop
JARVIS-1 on top of pre-trained multimodal language models, which map visual
observations and textual instructions to plans. The plans will be ultimately
dispatched to the goal-conditioned controllers. We outfit JARVIS-1 with a
multimodal memory, which facilitates planning using both pre-trained knowledge
and its actual game survival experiences. JARVIS-1 is the existing most general
agent in Minecraft, capable of completing over 200 different tasks using
control and observation space similar to humans. These tasks range from
short-horizon tasks, e.g., "chopping trees" to long-horizon tasks, e.g.,
"obtaining a diamond pickaxe". JARVIS-1 performs exceptionally well in
short-horizon tasks, achieving nearly perfect performance. In the classic
long-term task of $\texttt{ObtainDiamondPickaxe}$, JARVIS-1 surpasses the
reliability of current state-of-the-art agents by 5 times and can successfully
complete longer-horizon and more challenging tasks. The project page is
available at https://craftjarvis.org/JARVIS-1
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08592">AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications. (arXiv:2311.08592v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Radharapu_B/0/1/0/all/0/1">Bhaktipriya Radharapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_K/0/1/0/all/0/1">Kevin Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Aroyo_L/0/1/0/all/0/1">Lora Aroyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lahoti_P/0/1/0/all/0/1">Preethi Lahoti</a></p>
<p>Adversarial testing of large language models (LLMs) is crucial for their safe
and responsible deployment. We introduce a novel approach for automated
generation of adversarial evaluation datasets to test the safety of LLM
generations on new downstream applications. We call it AI-assisted Red-Teaming
(AART) - an automated alternative to current manual red-teaming efforts. AART
offers a data generation and augmentation pipeline of reusable and customizable
recipes that reduce human effort significantly and enable integration of
adversarial testing earlier in new product development. AART generates
evaluation datasets with high diversity of content characteristics critical for
effective adversarial testing (e.g. sensitive and harmful concepts, specific to
a wide range of cultural and geographic regions and application scenarios). The
data generation is steered by AI-assisted recipes to define, scope and
prioritize diversity within the application context. This feeds into a
structured LLM-generation process that scales up evaluation priorities.
Compared to some state-of-the-art tools, AART shows promising results in terms
of concept coverage and data quality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11810">DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding. (arXiv:2311.11810v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1">Hao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Can Huang</a></p>
<p>This work presents DocPedia, a novel large multimodal model (LMM) for
versatile OCR-free document understanding, capable of parsing images up to
2,560$\times$2,560 resolution. Unlike existing work either struggle with
high-resolution documents or give up the large language model thus vision or
language ability constrained, our DocPedia directly processes visual input in
the frequency domain rather than the pixel space. The unique characteristic
enables DocPedia to capture a greater amount of visual and textual information
using a limited number of visual tokens. To consistently enhance both
perception and comprehension abilities of our model, we develop a dual-stage
training strategy and enrich instructions/annotations of all training tasks
covering multiple document types. Extensive quantitative and qualitative
experiments conducted on various publicly available benchmarks confirm the
mutual benefits of jointly learning perception and comprehension tasks. The
results provide further evidence of the effectiveness and superior performance
of our DocPedia over other methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.12188">ChatGPT and post-test probability. (arXiv:2311.12188v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weisenthal_S/0/1/0/all/0/1">Samuel J. Weisenthal</a></p>
<p>Reinforcement learning-based large language models, such as ChatGPT, are
believed to have potential to aid human experts in many domains, including
healthcare. There is, however, little work on ChatGPT's ability to perform a
key task in healthcare: formal, probabilistic medical diagnostic reasoning.
This type of reasoning is used, for example, to update a pre-test probability
to a post-test probability. In this work, we probe ChatGPT's ability to perform
this task. In particular, we ask ChatGPT to give examples of how to use Bayes
rule for medical diagnosis. Our prompts range from queries that use terminology
from pure probability (e.g., requests for a "posterior probability") to queries
that use terminology from the medical diagnosis literature (e.g., requests for
a "post-test probability"). We show how the introduction of medical variable
names leads to an increase in the number of errors that ChatGPT makes. Given
our results, we also show how one can use prompt engineering to facilitate
ChatGPT's partial avoidance of these errors. We discuss our results in light of
recent commentaries on sensitivity and specificity. We also discuss how our
results might inform new research directions for large language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.12825">A PSO Based Method to Generate Actionable Counterfactuals for High Dimensional Data. (arXiv:2311.12825v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shekhar_S/0/1/0/all/0/1">Shashank Shekhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Salim_A/0/1/0/all/0/1">Asif Salim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansode_A/0/1/0/all/0/1">Adesh Bansode</a>, <a href="http://arxiv.org/find/cs/1/au:+Jinturkar_V/0/1/0/all/0/1">Vivaswan Jinturkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayak_A/0/1/0/all/0/1">Anirudha Nayak</a></p>
<p>Counterfactual explanations (CFE) are methods that explain a machine learning
model by giving an alternate class prediction of a data point with some minimal
changes in its features. It helps the users to identify their data attributes
that caused an undesirable prediction like a loan or credit card rejection. We
describe an efficient and an actionable counterfactual (CF) generation method
based on particle swarm optimization (PSO). We propose a simple objective
function for the optimization of the instance-centric CF generation problem.
The PSO brings in a lot of flexibility in terms of carrying out multi-objective
optimization in large dimensions, capability for multiple CF generation, and
setting box constraints or immutability of data attributes. An algorithm is
proposed that incorporates these features and it enables greater control over
the proximity and sparsity properties over the generated CFs. The proposed
algorithm is evaluated with a set of action-ability metrics in real-world
datasets, and the results were superior compared to that of the
state-of-the-arts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14656">Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs. (arXiv:2311.14656v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roberts_J/0/1/0/all/0/1">Jonathan Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Luddecke_T/0/1/0/all/0/1">Timo L&#xfc;ddecke</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheikh_R/0/1/0/all/0/1">Rehan Sheikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1">Samuel Albanie</a></p>
<p>Multimodal large language models (MLLMs) have shown remarkable capabilities
across a broad range of tasks but their knowledge and abilities in the
geographic and geospatial domains are yet to be explored, despite potential
wide-ranging benefits to navigation, environmental research, urban development,
and disaster response. We conduct a series of experiments exploring various
vision capabilities of MLLMs within these domains, particularly focusing on the
frontier model GPT-4V, and benchmark its performance against open-source
counterparts. Our methodology involves challenging these models with a
small-scale geographic benchmark consisting of a suite of visual tasks, testing
their abilities across a spectrum of complexity. The analysis uncovers not only
where such models excel, including instances where they outperform humans, but
also where they falter, providing a balanced view of their capabilities in the
geographic domain. To enable the comparison and evaluation of future models,
our benchmark will be publicly released.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14948">Effective Backdoor Mitigation Depends on the Pre-training Objective. (arXiv:2311.14948v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1">Sahil Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatt_G/0/1/0/all/0/1">Gantavya Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_S/0/1/0/all/0/1">Soumye Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Arnav Mohanty Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1">Chirag Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John P Dickerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilmes_J/0/1/0/all/0/1">Jeff Bilmes</a></p>
<p>Despite the advanced capabilities of contemporary machine learning (ML)
models, they remain vulnerable to adversarial and backdoor attacks. This
vulnerability is particularly concerning in real-world deployments, where
compromised models may exhibit unpredictable behavior in critical scenarios.
Such risks are heightened by the prevalent practice of collecting massive,
internet-sourced datasets for pre-training multimodal models, as these datasets
may harbor backdoors. Various techniques have been proposed to mitigate the
effects of backdooring in these models such as CleanCLIP which is the current
state-of-the-art approach. In this work, we demonstrate that the efficacy of
CleanCLIP in mitigating backdoors is highly dependent on the particular
objective used during model pre-training. We observe that stronger pre-training
objectives correlate with harder to remove backdoors behaviors. We show this by
training multimodal models on two large datasets consisting of 3 million (CC3M)
and 6 million (CC6M) datapoints, under various pre-training objectives,
followed by poison removal using CleanCLIP. We find that CleanCLIP is
ineffective when stronger pre-training objectives are used, even with extensive
hyperparameter tuning. Our findings underscore critical considerations for ML
practitioners who pre-train models using large-scale web-curated data and are
concerned about potential backdoor threats. Notably, our results suggest that
simpler pre-training objectives are more amenable to effective backdoor
removal. This insight is pivotal for practitioners seeking to balance the
trade-offs between using stronger pre-training objectives and security against
backdoor attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16102">Diffusion-TTA: Test-time Adaptation of Discriminative Models via Generative Feedback. (arXiv:2311.16102v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Prabhudesai_M/0/1/0/all/0/1">Mihir Prabhudesai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_T/0/1/0/all/0/1">Tsung-Wei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Alexander C. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1">Deepak Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1">Katerina Fragkiadaki</a></p>
<p>The advancements in generative modeling, particularly the advent of diffusion
models, have sparked a fundamental question: how can these models be
effectively used for discriminative tasks? In this work, we find that
generative models can be great test-time adapters for discriminative models.
Our method, Diffusion-TTA, adapts pre-trained discriminative models such as
image classifiers, segmenters and depth predictors, to each unlabelled example
in the test set using generative feedback from a diffusion model. We achieve
this by modulating the conditioning of the diffusion model using the output of
the discriminative model. We then maximize the image likelihood objective by
backpropagating the gradients to discriminative model's parameters. We show
Diffusion-TTA significantly enhances the accuracy of various large-scale
pre-trained discriminative models, such as, ImageNet classifiers, CLIP models,
image pixel labellers and image depth predictors. Diffusion-TTA outperforms
existing test-time adaptation methods, including TTT-MAE and TENT, and
particularly shines in online adaptation setups, where the discriminative model
is continually adapted to each example in the test set. We provide access to
code, results, and visualizations on our website:
https://diffusion-tta.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16512">CoSeR: Bridging Image and Language for Cognitive Super-Resolution. (arXiv:2311.16512v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haoze Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jianzhuang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_R/0/1/0/all/0/1">Renjing Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1">Xueyi Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Youliang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yujiu Yang</a></p>
<p>Existing super-resolution (SR) models primarily focus on restoring local
texture details, often neglecting the global semantic information within the
scene. This oversight can lead to the omission of crucial semantic details or
the introduction of inaccurate textures during the recovery process. In our
work, we introduce the Cognitive Super-Resolution (CoSeR) framework, empowering
SR models with the capacity to comprehend low-resolution images. We achieve
this by marrying image appearance and language understanding to generate a
cognitive embedding, which not only activates prior information from large
text-to-image diffusion models but also facilitates the generation of
high-quality reference images to optimize the SR process. To further improve
image fidelity, we propose a novel condition injection scheme called
"All-in-Attention", consolidating all conditional information into a single
module. Consequently, our method successfully restores semantically correct and
photorealistic details, demonstrating state-of-the-art performance across
multiple benchmarks. Code: https://github.com/VINHYU/CoSeR
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16605">LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning. (arXiv:2311.16605v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jintang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_J/0/1/0/all/0/1">Jiawang Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Ruofan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jing Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Sheng Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baokun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1">Changhua Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuchang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zibin Zheng</a></p>
<p>Over the past few years, graph neural networks (GNNs) have become powerful
and practical tools for learning on (static) graph-structure data. However,
many real-world applications, such as social networks and e-commerce, involve
temporal graphs where nodes and edges are dynamically evolving. Temporal graph
neural networks (TGNNs) have progressively emerged as an extension of GNNs to
address time-evolving graphs and have gradually become a trending research
topic in both academics and industry. Advancing research and application in
such an emerging field necessitates the development of new tools to compose
TGNN models and unify their different schemes for dealing with temporal graphs.
In this work, we introduce LasTGL, an industrial framework that integrates
unified and extensible implementations of common temporal graph learning
algorithms for various advanced tasks. The purpose of LasTGL is to provide the
essential building blocks for solving temporal graph learning tasks, focusing
on the guiding principles of user-friendliness and quick prototyping on which
PyTorch is based. In particular, LasTGL provides comprehensive temporal graph
datasets, TGNN models and utilities along with well-documented tutorials,
making it suitable for both absolute beginners and expert deep learning
practitioners alike.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16733">LLMs for Science: Usage for Code Generation and Data Analysis. (arXiv:2311.16733v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nejjar_M/0/1/0/all/0/1">Mohamed Nejjar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zacharias_L/0/1/0/all/0/1">Luca Zacharias</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiehle_F/0/1/0/all/0/1">Fabian Stiehle</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_I/0/1/0/all/0/1">Ingo Weber</a></p>
<p>Large language models (LLMs) have been touted to enable increased
productivity in many areas of today's work life. Scientific research as an area
of work is no exception: the potential of LLM-based tools to assist in the
daily work of scientists has become a highly discussed topic across
disciplines. However, we are only at the very onset of this subject of study.
It is still unclear how the potential of LLMs will materialise in research
practice. With this study, we give first empirical evidence on the use of LLMs
in the research process. We have investigated a set of use cases for LLM-based
tools in scientific research, and conducted a first study to assess to which
degree current tools are helpful. In this paper we report specifically on use
cases related to software engineering, such as generating application code and
developing scripts for data analytics. While we studied seemingly simple use
cases, results across tools differ significantly. Our results highlight the
promise of LLM-based tools in general, yet we also observe various issues,
particularly regarding the integrity of the output these tools provide.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16867">The Falcon Series of Open Language Models. (arXiv:2311.16867v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Almazrouei_E/0/1/0/all/0/1">Ebtesam Almazrouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Alobeidli_H/0/1/0/all/0/1">Hamza Alobeidli</a>, <a href="http://arxiv.org/find/cs/1/au:+Alshamsi_A/0/1/0/all/0/1">Abdulaziz Alshamsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cappelli_A/0/1/0/all/0/1">Alessandro Cappelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Cojocaru_R/0/1/0/all/0/1">Ruxandra Cojocaru</a>, <a href="http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1">M&#xe9;rouane Debbah</a>, <a href="http://arxiv.org/find/cs/1/au:+Goffinet_E/0/1/0/all/0/1">&#xc9;tienne Goffinet</a>, <a href="http://arxiv.org/find/cs/1/au:+Hesslow_D/0/1/0/all/0/1">Daniel Hesslow</a>, <a href="http://arxiv.org/find/cs/1/au:+Launay_J/0/1/0/all/0/1">Julien Launay</a>, <a href="http://arxiv.org/find/cs/1/au:+Malartic_Q/0/1/0/all/0/1">Quentin Malartic</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazzotta_D/0/1/0/all/0/1">Daniele Mazzotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Noune_B/0/1/0/all/0/1">Badreddine Noune</a>, <a href="http://arxiv.org/find/cs/1/au:+Pannier_B/0/1/0/all/0/1">Baptiste Pannier</a>, <a href="http://arxiv.org/find/cs/1/au:+Penedo_G/0/1/0/all/0/1">Guilherme Penedo</a></p>
<p>We introduce the Falcon series: 7B, 40B, and 180B parameters causal
decoder-only models trained on a diverse high-quality corpora predominantly
assembled from web data. The largest model, Falcon-180B, has been trained on
over 3.5 trillion tokens of text--the largest openly documented pretraining
run. Falcon-180B significantly outperforms models such as PaLM or Chinchilla,
and improves upon concurrently developed models such as LLaMA 2 or
Inflection-1. It nears the performance of PaLM-2-Large at a reduced pretraining
and inference cost, making it, to our knowledge, one of the three best language
models in the world along with GPT-4 and PaLM-2-Large. We report detailed
evaluations, as well as a deep dive into the methods and custom tooling
employed to pretrain Falcon. Notably, we report on our custom distributed
training codebase, allowing us to efficiently pretrain these models on up to
4,096 A100s on cloud AWS infrastructure with limited interconnect. We release a
600B tokens extract of our web dataset, as well as the Falcon-7/40/180B models
under a permissive license to foster open-science and accelerate the
development of an open ecosystem of large language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17431">Grounding Foundation Models through Federated Transfer Learning: A General Framework. (arXiv:2311.17431v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yan Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1">Tao Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Hanlin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lixin Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a></p>
<p>Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and
powerful emergent abilities have achieved remarkable success in various natural
language processing and computer vision tasks. Grounding FMs by adapting them
to domain-specific tasks or augmenting them with domain-specific knowledge
enables us to exploit the full potential of FMs. However, grounding FMs faces
several challenges, stemming primarily from constrained computing resources,
data privacy, model heterogeneity, and model ownership. Federated Transfer
Learning (FTL), the combination of federated learning and transfer learning,
provides promising solutions to address these challenges. In recent years, the
need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in
both academia and industry. Motivated by the strong growth in FTL-FM research
and the potential impact of FTL-FM on industrial applications, we propose an
FTL-FM framework that formulates problems of grounding FMs in the federated
learning setting, construct a detailed taxonomy based on the FTL-FM framework
to categorize state-of-the-art FTL-FM works, and comprehensively overview
FTL-FM works based on the proposed taxonomy. We also establish correspondences
between FTL-FM and conventional phases of adapting FM so that FM practitioners
can align their research works with FTL-FM. In addition, we overview advanced
efficiency-improving and privacy-preserving techniques because efficiency and
privacy are critical concerns in FTL-FM. Last, we discuss opportunities and
future research directions of FTL-FM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17438">CLOMO: Counterfactual Logical Modification with Large Language Models. (arXiv:2311.17438v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yinya Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_R/0/1/0/all/0/1">Ruixin Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhicheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Linqi Song</a></p>
<p>In this study, we delve into the realm of counterfactual reasoning
capabilities of large language models (LLMs). Our primary objective is to
cultivate the counterfactual thought processes within LLMs and rigorously
assess these processes for their validity. Specifically, we introduce a novel
task, Counterfactual Logical Modification (CLOMO), and a high-quality
human-annotated benchmark. In this task, LLMs must adeptly alter a given
argumentative text to uphold a predetermined logical relationship. To
effectively evaluate a generation model's counterfactual capabilities, we
propose an innovative evaluation metric, the LogicAware Counterfactual Score to
directly evaluate the natural language output of LLMs instead of modeling the
task as a multiple-choice problem. Analysis shows that the proposed automatic
metric aligns well with human preference. Our experimental results show that
while LLMs demonstrate a notable capacity for logical counterfactual thinking,
there remains a discernible gap between their current abilities and human
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11286">Classification of Radio Galaxies with trainable COSFIRE filters. (arXiv:2311.11286v1 [astro-ph.IM] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Ndungu_S/0/1/0/all/0/1">Steven Ndungu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Grobler_T/0/1/0/all/0/1">Trienko Grobler</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Karastoyanova_S/0/1/0/all/0/1">Stefan J. Wijnholds Dimka Karastoyanova</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Azzopardi_G/0/1/0/all/0/1">George Azzopardi</a></p>
<p>Radio galaxies exhibit a rich diversity of characteristics and emit radio
emissions through a variety of radiation mechanisms, making their
classification into distinct types based on morphology a complex challenge. To
address this challenge effectively, we introduce an innovative approach for
radio galaxy classification using COSFIRE filters. These filters possess the
ability to adapt to both the shape and orientation of prototype patterns within
images. The COSFIRE approach is explainable, learning-free, rotation-tolerant,
efficient, and does not require a huge training set. To assess the efficacy of
our method, we conducted experiments on a benchmark radio galaxy data set
comprising of 1180 training samples and 404 test samples. Notably, our approach
achieved an average accuracy rate of 93.36\%. This achievement outperforms
contemporary deep learning models, and it is the best result ever achieved on
this data set. Additionally, COSFIRE filters offer better computational
performance, $\sim$20$\times$ fewer operations than the DenseNet-based
competing method (when comparing at the same accuracy). Our findings underscore
the effectiveness of the COSFIRE filter-based approach in addressing the
complexities associated with radio galaxy classification. This research
contributes to advancing the field by offering a robust solution that
transcends the orientation challenges intrinsic to radio galaxy observations.
Our method is versatile in that it is applicable to various image
classification approaches.
</p>
</p>
</div>

    </div>
    </body>
    