<!DOCTYPE html>
<html>
<head>
<title>2023-12-24-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2312.13382">DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines. (arXiv:2312.13382v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singhvi_A/0/1/0/all/0/1">Arnav Singhvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_M/0/1/0/all/0/1">Manish Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shangyin Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_K/0/1/0/all/0/1">Koushik Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1">Matei Zaharia</a>, <a href="http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1">Omar Khattab</a></p>
<p>Chaining language model (LM) calls as composable modules is fueling a new
powerful way of programming. However, ensuring that LMs adhere to important
constraints remains a key challenge, one often addressed with heuristic "prompt
engineering". We introduce LM Assertions, a new programming construct for
expressing computational constraints that LMs should satisfy. We integrate our
constructs into the recent DSPy programming model for LMs, and present new
strategies that allow DSPy to compile programs with arbitrary LM Assertions
into systems that are more reliable and more accurate. In DSPy, LM Assertions
can be integrated at compile time, via automatic prompt optimization, and/or at
inference time, via automatic selfrefinement and backtracking. We report on two
early case studies for complex question answering (QA), in which the LM program
must iteratively retrieve information in multiple hops and synthesize a
long-form answer with citations. We find that LM Assertions improve not only
compliance with imposed rules and guidelines but also enhance downstream task
performance, delivering intrinsic and extrinsic gains up to 35.7% and 13.3%,
respectively. Our reference implementation of LM Assertions is integrated into
DSPy at https://github.com/stanfordnlp/dspy
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13401">Time is Encoded in the Weights of Finetuned Language Models. (arXiv:2312.13401v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nylund_K/0/1/0/all/0/1">Kai Nylund</a>, <a href="http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1">Suchin Gururangan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a></p>
<p>We present time vectors, a simple tool to customize language models to new
time periods. Time vectors are created by finetuning a language model on data
from a single time (e.g., a year or month), and then subtracting the weights of
the original pretrained model. This vector specifies a direction in weight
space that, as our experiments show, improves performance on text from that
time period. Time vectors specialized to adjacent time periods appear to be
positioned closer together in a manifold. Using this structure, we interpolate
between time vectors to induce new models that perform better on intervening
and future time periods, without any additional training. We demonstrate the
consistency of our findings across different tasks, domains, model sizes, and
time scales. Our results suggest that time is encoded in the weight space of
finetuned models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13423">VADIS -- a VAriable Detection, Interlinking and Summarization system. (arXiv:2312.13423v1 [cs.DL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kartal_Y/0/1/0/all/0/1">Yavuz Selim Kartal</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahid_M/0/1/0/all/0/1">Muhammad Ahsan Shahid</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeshita_S/0/1/0/all/0/1">Sotaro Takeshita</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsereteli_T/0/1/0/all/0/1">Tornike Tsereteli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_A/0/1/0/all/0/1">Andrea Zielinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zapilko_B/0/1/0/all/0/1">Benjamin Zapilko</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayr_P/0/1/0/all/0/1">Philipp Mayr</a></p>
<p>The VADIS system addresses the demand of providing enhanced information
access in the domain of the social sciences. This is achieved by allowing users
to search and use survey variables in context of their underlying research data
and scholarly publications which have been interlinked with each other.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13437">A General Model for Aggregating Annotations Across Simple, Complex, and Multi-Object Annotation Tasks. (arXiv:2312.13437v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Braylan_A/0/1/0/all/0/1">Alexander Braylan</a>, <a href="http://arxiv.org/find/cs/1/au:+Marabella_M/0/1/0/all/0/1">Madalyn Marabella</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_O/0/1/0/all/0/1">Omar Alonso</a>, <a href="http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1">Matthew Lease</a></p>
<p>Human annotations are vital to supervised learning, yet annotators often
disagree on the correct label, especially as annotation tasks increase in
complexity. A strategy to improve label quality is to ask multiple annotators
to label the same item and aggregate their labels. Many aggregation models have
been proposed for categorical or numerical annotation tasks, but far less work
has considered more complex annotation tasks involving open-ended,
multivariate, or structured responses. While a variety of bespoke models have
been proposed for specific tasks, our work is the first to introduce
aggregation methods that generalize across many diverse complex tasks,
including sequence labeling, translation, syntactic parsing, ranking, bounding
boxes, and keypoints. This generality is achieved by devising a task-agnostic
method to model distances between labels rather than the labels themselves.
</p>
<p>This article extends our prior work with investigation of three new research
questions. First, how do complex annotation properties impact aggregation
accuracy? Second, how should a task owner navigate the many modeling choices to
maximize aggregation accuracy? Finally, what diagnoses can verify that
aggregation models are specified correctly for the given data? To understand
how various factors impact accuracy and to inform model selection, we conduct
simulation studies and experiments on real, complex datasets. Regarding
testing, we introduce unit tests for aggregation models and present a suite of
such tests to ensure that a given model is not mis-specified and exhibits
expected behavior.
</p>
<p>Beyond investigating these research questions above, we discuss the
foundational concept of annotation complexity, present a new aggregation model
as a bridge between traditional models and our own, and contribute a new
semi-supervised learning method for complex label aggregation that outperforms
prior work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13495">Decoupling Representation and Knowledge for Few-Shot Intent Classification and Slot Filling. (arXiv:2312.13495v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jie Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yixiong Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haozhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruixuan Li</a></p>
<p>Few-shot intent classification and slot filling are important but challenging
tasks due to the scarcity of finely labeled data. Therefore, current works
first train a model on source domains with sufficiently labeled data, and then
transfer the model to target domains where only rarely labeled data is
available. However, experience transferring as a whole usually suffers from
gaps that exist among source domains and target domains. For instance,
transferring domain-specific-knowledge-related experience is difficult. To
tackle this problem, we propose a new method that explicitly decouples the
transferring of general-semantic-representation-related experience and the
domain-specific-knowledge-related experience. Specifically, for
domain-specific-knowledge-related experience, we design two modules to capture
intent-slot relation and slot-slot relation respectively. Extensive experiments
on Snips and FewJoint datasets show that our method achieves state-of-the-art
performance. The method improves the joint accuracy metric from 27.72% to
42.20% in the 1-shot setting, and from 46.54% to 60.79% in the 5-shot setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13533">Automated Clinical Coding for Outpatient Departments. (arXiv:2312.13533v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schlegel_V/0/1/0/all/0/1">Viktor Schlegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashyap_A/0/1/0/all/0/1">Abhinav Ramesh Kashyap</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thanh-Tung Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tsung-Han Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwivedi_V/0/1/0/all/0/1">Vijay Prakash Dwivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1">Wei-Hsian Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jeng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Winkle_S/0/1/0/all/0/1">Stefan Winkle</a></p>
<p>Computerised clinical coding approaches aim to automate the process of
assigning a set of codes to medical records. While there is active research
pushing the state of the art on clinical coding for hospitalized patients, the
outpatient setting -- where doctors tend to non-hospitalised patients -- is
overlooked. Although both settings can be formalised as a multi-label
classification task, they present unique and distinct challenges, which raises
the question of whether the success of inpatient clinical coding approaches
translates to the outpatient setting. This paper is the first to investigate
how well state-of-the-art deep learning-based clinical coding approaches work
in the outpatient setting at hospital scale. To this end, we collect a large
outpatient dataset comprising over 7 million notes documenting over half a
million patients. We adapt four state-of-the-art clinical coding approaches to
this setting and evaluate their potential to assist coders. We find evidence
that clinical coding in outpatient settings can benefit from more innovations
in popular inpatient coding benchmarks. A deeper analysis of the factors
contributing to the success -- amount and form of data and choice of document
representation -- reveals the presence of easy-to-solve examples, the coding of
which can be completely automated with a low error rate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13545">Developing Interactive Tourism Planning: A Dialogue Robot System Powered by a Large Language Mode. (arXiv:2312.13545v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoshikawa_K/0/1/0/all/0/1">Katsumasa Yoshikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamazaki_T/0/1/0/all/0/1">Takato Yamazaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohagi_M/0/1/0/all/0/1">Masaya Ohagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mizumoto_T/0/1/0/all/0/1">Tomoya Mizumoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_K/0/1/0/all/0/1">Keiya Sato</a></p>
<p>In recent years, large language models (LLMs) have rapidly proliferated and
have been utilized in various tasks, including research in dialogue systems. We
aimed to construct a system that not only leverages the flexible conversational
abilities of LLMs but also their advanced planning capabilities to reduce the
speaking load on human interlocutors and efficiently plan trips. Furthermore,
we propose a method that divides the complex task of a travel agency into
multiple subtasks, managing each as a separate phase to effectively accomplish
the task. Our proposed system confirmed a certain level of success by achieving
fourth place in the Dialogue Robot Competition 2023 preliminaries rounds. We
report on the challenges identified through the competition.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13547">How to Prune Your Language Model: Recovering Accuracy on the &quot;Sparsity May Cry&#x27;&#x27; Benchmark. (arXiv:2312.13547v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1">Eldar Kurtic</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1">Torsten Hoefler</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a></p>
<p>Pruning large language models (LLMs) from the BERT family has emerged as a
standard compression benchmark, and several pruning methods have been proposed
for this task. The recent ``Sparsity May Cry'' (SMC) benchmark put into
question the validity of all existing methods, exhibiting a more complex setup
where many known pruning methods appear to fail. We revisit the question of
accurate BERT-pruning during fine-tuning on downstream datasets, and propose a
set of general guidelines for successful pruning, even on the challenging SMC
benchmark. First, we perform a cost-vs-benefits analysis of pruning model
components, such as the embeddings and the classification head; second, we
provide a simple-yet-general way of scaling training, sparsification and
learning rate schedules relative to the desired target sparsity; finally, we
investigate the importance of proper parametrization for Knowledge Distillation
in the context of LLMs. Our simple insights lead to state-of-the-art results,
both on classic BERT-pruning benchmarks, as well as on the SMC benchmark,
showing that even classic gradual magnitude pruning (GMP) can yield competitive
results, with the right approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13558">The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction. (arXiv:2312.13558v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Pratyusha Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1">Jordan T. Ash</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1">Dipendra Misra</a></p>
<p>Transformer-based Large Language Models (LLMs) have become a fixture in
modern machine learning. Correspondingly, significant resources are allocated
towards research that aims to further advance this technology, typically
resulting in models of increasing size that are trained on increasing amounts
of data. This work, however, demonstrates the surprising result that it is
often possible to significantly improve the performance of LLMs by selectively
removing higher-order components of their weight matrices. This simple
intervention, which we call LAyer-SElective Rank reduction (LASER), can be done
on a model after training has completed, and requires no additional parameters
or data. We show extensive experiments demonstrating the generality of this
finding across language models and datasets, and provide in-depth analyses
offering insights into both when LASER is effective and the mechanism by which
it operates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13585">Speech Translation with Large Language Models: An Industrial Practice. (arXiv:2312.13585v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhichao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rong Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1">Tom Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qianqian Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Shanbo Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hang Li</a></p>
<p>Given the great success of large language models (LLMs) across various tasks,
in this paper, we introduce LLM-ST, a novel and effective speech translation
model constructed upon a pre-trained LLM. By integrating the large language
model (LLM) with a speech encoder and employing multi-task instruction tuning,
LLM-ST can produce accurate timestamped transcriptions and translations, even
from long audio inputs. Furthermore, our findings indicate that the
implementation of Chain-of-Thought (CoT) prompting can yield advantages in the
context of LLM-ST. Through rigorous experimentation on English and Chinese
datasets, we showcase the exceptional performance of LLM-ST, establishing a new
benchmark in the field of speech translation. Demo:
https://speechtranslation.github.io/llm-st/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13594">Towards More Faithful Natural Language Explanation Using Multi-Level Contrastive Learning in VQA. (arXiv:2312.13594v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chengen Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shengli Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_S/0/1/0/all/0/1">Shiqi Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Sitong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1">Guangneng Hu</a></p>
<p>Natural language explanation in visual question answer (VQA-NLE) aims to
explain the decision-making process of models by generating natural language
sentences to increase users' trust in the black-box systems. Existing post-hoc
methods have achieved significant progress in obtaining a plausible
explanation. However, such post-hoc explanations are not always aligned with
human logical inference, suffering from the issues on: 1) Deductive
unsatisfiability, the generated explanations do not logically lead to the
answer; 2) Factual inconsistency, the model falsifies its counterfactual
explanation for answers without considering the facts in images; and 3)
Semantic perturbation insensitivity, the model can not recognize the semantic
changes caused by small perturbations. These problems reduce the faithfulness
of explanations generated by models. To address the above issues, we propose a
novel self-supervised \textbf{M}ulti-level \textbf{C}ontrastive
\textbf{L}earning based natural language \textbf{E}xplanation model (MCLE) for
VQA with semantic-level, image-level, and instance-level factual and
counterfactual samples. MCLE extracts discriminative features and aligns the
feature spaces from explanations with visual question and answer to generate
more consistent explanations. We conduct extensive experiments, ablation
analysis, and case study to demonstrate the effectiveness of our method on two
VQA-NLE benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13608">Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation. (arXiv:2312.13608v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jiayu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rong Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1">Meng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_R/0/1/0/all/0/1">Ruofei Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhao Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanjing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhongyu Wei</a></p>
<p>Counter-argument generation -- a captivating area in computational
linguistics -- seeks to craft statements that offer opposing views. While most
research has ventured into paragraph-level generation, sentence-level
counter-argument generation beckons with its unique constraints and
brevity-focused challenges. Furthermore, the diverse nature of
counter-arguments poses challenges for evaluating model performance solely
based on n-gram-based metrics. In this paper, we present the ArgTersely
benchmark for sentence-level counter-argument generation, drawing from a
manually annotated dataset from the ChangeMyView debate forum. We also propose
Arg-LlaMA for generating high-quality counter-argument. For better evaluation,
we trained a BERT-based evaluator Arg-Judge with human preference data. We
conducted comparative experiments involving various baselines such as LlaMA,
Alpaca, GPT-3, and others. The results show the competitiveness of our proposed
framework and evaluator in counter-argument generation tasks. Code and data are
available at https://github.com/amazingljy1206/ArgTersely.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13614">Structure-Aware Path Inference for Neural Finite State Transducers. (arXiv:2312.13614v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1">Weiting Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chu-cheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1">Jason Eisner</a></p>
<p>Neural finite-state transducers (NFSTs) form an expressive family of
neurosymbolic sequence transduction models. An NFST models each string pair as
having been generated by a latent path in a finite-state transducer. As they
are deep generative models, both training and inference of NFSTs require
inference networks that approximate posterior distributions over such latent
variables. In this paper, we focus on the resulting challenge of imputing the
latent alignment path that explains a given pair of input and output strings
(e.g., during training). We train three autoregressive approximate models for
amortized inference of the path, which can then be used as proposal
distributions for importance sampling. All three models perform lookahead. Our
most sophisticated (and novel) model leverages the FST structure to consider
the graph of future paths; unfortunately, we find that it loses out to the
simpler approaches -- except on an artificial task that we concocted to confuse
the simpler approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13655">Compositional Zero-Shot Learning for Attribute-Based Object Reference in Human-Robot Interaction. (arXiv:2312.13655v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Jaafar_A/0/1/0/all/0/1">Ahmed Jaafar</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Reily_B/0/1/0/all/0/1">Brian Reily</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Reardon_C/0/1/0/all/0/1">Christopher Reardon</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a> (1) ((1) University of Massachusetts Amherst, (2) DEVCOM Army Research Laboratory, (3) University of Denver)</p>
<p>Language-enabled robots have been widely studied over the past years to
enable natural human-robot interaction and teaming in various real-world
applications. Language-enabled robots must be able to comprehend referring
expressions to identify a particular object from visual perception using a set
of referring attributes extracted from natural language. However, visual
observations of an object may not be available when it is referred to, and the
number of objects and attributes may also be unbounded in open worlds. To
address the challenges, we implement an attribute-based compositional zero-shot
learning method that uses a list of attributes to perform referring expression
comprehension in open worlds. We evaluate the approach on two datasets
including the MIT-States and the Clothing 16K. The preliminary experimental
results show that our implemented approach allows a robot to correctly identify
the objects referred to by human commands.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13671">Text2Analysis: A Benchmark of Table Question Answering with Advanced Data Analysis and Unclear Queries. (arXiv:2312.13671v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xinyi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mengyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinrun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaojun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1">Rui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Lun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ran Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zejian Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a></p>
<p>Tabular data analysis is crucial in various fields, and large language models
show promise in this area. However, current research mostly focuses on
rudimentary tasks like Text2SQL and TableQA, neglecting advanced analysis like
forecasting and chart generation. To address this gap, we developed the
Text2Analysis benchmark, incorporating advanced analysis tasks that go beyond
the SQL-compatible operations and require more in-depth analysis. We also
develop five innovative and effective annotation methods, harnessing the
capabilities of large language models to enhance data quality and quantity.
Additionally, we include unclear queries that resemble real-world user
questions to test how well models can understand and tackle such challenges.
Finally, we collect 2249 query-result pairs with 347 tables. We evaluate five
state-of-the-art models using three different metrics and the results show that
our benchmark presents introduces considerable challenge in the field of
tabular data analysis, paving the way for more advanced research opportunities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13694">Data Transformation to Construct a Dataset for Generating Entity-Relationship Model from Natural Language. (arXiv:2312.13694v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenwen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jian-Guang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tao Xie</a></p>
<p>In order to reduce the manual cost of designing ER models, recent approaches
have been proposed to address the task of NL2ERM, i.e., automatically
generating entity-relationship (ER) models from natural language (NL)
utterances such as software requirements. These approaches are typically
rule-based ones, which rely on rigid heuristic rules; these approaches cannot
generalize well to various linguistic ways of describing the same requirement.
Despite having better generalization capability than rule-based approaches,
deep-learning-based models are lacking for NL2ERM due to lacking a large-scale
dataset. To address this issue, in this paper, we report our insight that there
exists a high similarity between the task of NL2ERM and the increasingly
popular task of text-to-SQL, and propose a data transformation algorithm that
transforms the existing data of text-to-SQL into the data of NL2ERM. We apply
our data transformation algorithm on Spider, one of the most popular
text-to-SQL datasets, and we also collect some data entries with different NL
types, to obtain a large-scale NL2ERM dataset. Because NL2ERM can be seen as a
special information extraction (IE) task, we train two state-of-the-art IE
models on our dataset. The experimental results show that both the two models
achieve high performance and outperform existing baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13764">A Semantic Space is Worth 256 Language Descriptions: Make Stronger Segmentation Models with Descriptive Properties. (arXiv:2312.13764v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Junfei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Ziqi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1">Shiyi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1">Jieru Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Cihang Xie</a></p>
<p>This paper introduces ProLab, a novel approach using property-level label
space for creating strong interpretable segmentation models. Instead of relying
solely on category-specific annotations, ProLab uses descriptive properties
grounded in common sense knowledge for supervising segmentation models. It is
based on two core designs. First, we employ Large Language Models (LLMs) and
carefully crafted prompts to generate descriptions of all involved categories
that carry meaningful common sense knowledge and follow a structured format.
Second, we introduce a description embedding model preserving semantic
correlation across descriptions and then cluster them into a set of descriptive
properties (e.g., 256) using K-Means. These properties are based on
interpretable common sense knowledge consistent with theories of human
recognition. We empirically show that our approach makes segmentation models
perform stronger on five classic benchmarks (e.g., ADE20K, COCO-Stuff, Pascal
Context, Cityscapes, and BDD). Our method also shows better scalability with
extended training steps than category-level supervision. Our interpretable
segmentation framework also emerges with the generalization ability to segment
out-of-domain or unknown categories using only in-domain descriptive
properties. Code is available at https://github.com/lambert-x/ProLab.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13766">Exploiting Contextual Target Attributes for Target Sentiment Classification. (arXiv:2312.13766v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1">Bowen Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1">Ivor W. Tsang</a></p>
<p>Existing PTLM-based models for TSC can be categorized into two groups: 1)
fine-tuning-based models that adopt PTLM as the context encoder; 2)
prompting-based models that transfer the classification task to the text/word
generation task. In this paper, we present a new perspective of leveraging PTLM
for TSC: simultaneously leveraging the merits of both language modeling and
explicit target-context interactions via contextual target attributes.
Specifically, we design the domain- and target-constrained cloze test, which
can leverage the PTLMs' strong language modeling ability to generate the given
target's attributes pertaining to the review context. The attributes contain
the background and property information of the target, which can help to enrich
the semantics of the review context and the target. To exploit the attributes
for tackling TSC, we first construct a heterogeneous information graph by
treating the attributes as nodes and combining them with (1) the syntax graph
automatically produced by the off-the-shelf dependency parser and (2) the
semantics graph of the review context, which is derived from the self-attention
mechanism. Then we propose a heterogeneous information gated graph
convolutional network to model the interactions among the attribute
information, the syntactic information, and the contextual information. The
experimental results on three benchmark datasets demonstrate the superiority of
our model, which achieves new state-of-the-art performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13772">On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning. (arXiv:2312.13772v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengzu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Han Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a></p>
<p>Following the standard supervised fine-tuning (SFT) paradigm, in-context
learning (ICL) has become an efficient approach propelled by the recent
advancements in large language models (LLMs), yielding promising performance
across various tasks in few-shot data setups. However, both paradigms are prone
to suffer from the critical problem of overconfidence (i.e., miscalibration),
especially in such limited data setups. In this work, we deliver an in-depth
analysis of the behavior across different choices of learning methods from the
perspective of both performance and calibration, as well as their interplay.
Through extensive controlled experiments, we find that simultaneous gains for
both task performance and calibration are difficult to achieve, and the problem
of miscalibration exists across all learning methods in low-resource
scenarios.To address this challenging trade-off between performance and
calibration, we then investigate the potential of self-ensembling techniques
applied at different modeling stages (e.g., variations of in-context examples
or variations in prompts or different ensembling strategies). We justify the
feasibility of self-ensembling on SFT in addition to ICL, to make the
predictions more calibrated and have comparable or even better performance. Our
work sheds light on which learning paradigm to choose and how to enhance both
task performance and calibration of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13816">Team Flow at DRC2023: Building Common Ground and Text-based Turn-taking in a Travel Agent Spoken Dialogue System. (arXiv:2312.13816v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hirai_R/0/1/0/all/0/1">Ryu Hirai</a>, <a href="http://arxiv.org/find/cs/1/au:+Iizuka_S/0/1/0/all/0/1">Shinya Iizuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Iseno_H/0/1/0/all/0/1">Haruhisa Iseno</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_A/0/1/0/all/0/1">Ao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jingjing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohashi_A/0/1/0/all/0/1">Atsumoto Ohashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Higashinaka_R/0/1/0/all/0/1">Ryuichiro Higashinaka</a></p>
<p>At the Dialogue Robot Competition 2023 (DRC2023), which was held to improve
the capability of dialogue robots, our team developed a system that could build
common ground and take more natural turns based on user utterance texts. Our
system generated queries for sightseeing spot searches using the common ground
and engaged in dialogue while waiting for user comprehension.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13866">Understanding Inter-Session Intentions via Complex Logical Reasoning. (arXiv:2312.13866v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1">Jiaxin Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Q/0/1/0/all/0/1">Qingyu Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a></p>
<p>Understanding user intentions is crucial for enhancing product
recommendations, navigation suggestions, and query reformulations. However,
user intentions can be complex, involving multiple sessions and attribute
requirements connected by logical operators such as And, Or, and Not. For
example, a user may search for Nike or Adidas running shoes across various
sessions, with a preference for the color purple. In another case, a user may
have purchased a mattress in a previous session and is now seeking a
corresponding bed frame without intending to buy another mattress. Prior
research on session understanding has not sufficiently addressed how to make
product or attribute recommendations for such complex intentions. In this
paper, we introduce the task of logical session complex query answering, where
sessions are treated as hyperedges of items, and we formulate the problem of
complex intention understanding as a task of logical session complex queries
answering (LS-CQA) on an aggregated hypergraph of sessions, items, and
attributes. The proposed task is a special type of complex query answering task
with sessions as ordered hyperedges. We also propose a new model, the Logical
Session Graph Transformer (LSGT), which captures interactions among items
across different sessions and their logical connections using a transformer
structure. We analyze the expressiveness of LSGT and prove the permutation
invariance of the inputs for the logical operators. We evaluate LSGT on three
datasets and demonstrate that it achieves state-of-the-art results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13871">Evaluating Task-oriented Dialogue Systems: A Systematic Review of Measures, Constructs and their Operationalisations. (arXiv:2312.13871v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Braggaar_A/0/1/0/all/0/1">Anouck Braggaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebrecht_C/0/1/0/all/0/1">Christine Liebrecht</a>, <a href="http://arxiv.org/find/cs/1/au:+Miltenburg_E/0/1/0/all/0/1">Emiel van Miltenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Krahmer_E/0/1/0/all/0/1">Emiel Krahmer</a></p>
<p>This review gives an extensive overview of evaluation methods for
task-oriented dialogue systems, paying special attention to practical
applications of dialogue systems, for example for customer service. The review
(1) provides an overview of the used constructs and metrics in previous work,
(2) discusses challenges in the context of dialogue system evaluation and (3)
develops a research agenda for the future of dialogue system evaluation. We
conducted a systematic review of four databases (ACL, ACM, IEEE and Web of
Science), which after screening resulted in 122 studies. Those studies were
carefully analysed for the constructs and methods they proposed for evaluation.
We found a wide variety in both constructs and methods. Especially the
operationalisation is not always clearly reported. We hope that future work
will take a more critical approach to the operationalisation and specification
of the used constructs. To work towards this aim, this review ends with
recommendations for evaluation and suggestions for outstanding questions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13876">Capture the Flag: Uncovering Data Insights with Large Language Models. (arXiv:2312.13876v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1">Issam Laradji</a>, <a href="http://arxiv.org/find/cs/1/au:+Taslakian_P/0/1/0/all/0/1">Perouz Taslakian</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajeswar_S/0/1/0/all/0/1">Sai Rajeswar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zantedeschi_V/0/1/0/all/0/1">Valentina Zantedeschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_A/0/1/0/all/0/1">Alexandre Lacoste</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapados_N/0/1/0/all/0/1">Nicolas Chapados</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazquez_D/0/1/0/all/0/1">David Vazquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1">Alexandre Drouin</a></p>
<p>The extraction of a small number of relevant insights from vast amounts of
data is a crucial component of data-driven decision-making. However,
accomplishing this task requires considerable technical skills, domain
expertise, and human labor. This study explores the potential of using Large
Language Models (LLMs) to automate the discovery of insights in data,
leveraging recent advances in reasoning and code generation techniques. We
propose a new evaluation methodology based on a "capture the flag" principle,
measuring the ability of such models to recognize meaningful and pertinent
information (flags) in a dataset. We further propose two proof-of-concept
agents, with different inner workings, and compare their ability to capture
such flags in a real-world sales dataset. While the work reported here is
preliminary, our results are sufficiently interesting to mandate future
exploration by the community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13881">Diversifying Knowledge Enhancement of Biomedical Language Models using Adapter Modules and Knowledge Graphs. (arXiv:2312.13881v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vladika_J/0/1/0/all/0/1">Juraj Vladika</a>, <a href="http://arxiv.org/find/cs/1/au:+Fichtl_A/0/1/0/all/0/1">Alexander Fichtl</a>, <a href="http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1">Florian Matthes</a></p>
<p>Recent advances in natural language processing (NLP) owe their success to
pre-training language models on large amounts of unstructured data. Still,
there is an increasing effort to combine the unstructured nature of LMs with
structured knowledge and reasoning. Particularly in the rapidly evolving field
of biomedical NLP, knowledge-enhanced language models (KELMs) have emerged as
promising tools to bridge the gap between large language models and
domain-specific knowledge, considering the available biomedical knowledge
graphs (KGs) curated by experts over the decades. In this paper, we develop an
approach that uses lightweight adapter modules to inject structured biomedical
knowledge into pre-trained language models (PLMs). We use two large KGs, the
biomedical knowledge system UMLS and the novel biochemical ontology OntoChem,
with two prominent biomedical PLMs, PubMedBERT and BioLinkBERT. The approach
includes partitioning knowledge graphs into smaller subgraphs, fine-tuning
adapter modules for each subgraph, and combining the knowledge in a fusion
layer. We test the performance on three downstream tasks: document
classification,question answering, and natural language inference. We show that
our methodology leads to performance improvements in several instances while
keeping requirements in computing power low. Finally, we provide a detailed
interpretation of the results and report valuable insights for future work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13905">Domain-Specific Fine-Tuning of Large Language Models for Interactive Robot Programming. (arXiv:2312.13905v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alt_B/0/1/0/all/0/1">Benjamin Alt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kessner_U/0/1/0/all/0/1">Urs Ke&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Taranovic_A/0/1/0/all/0/1">Aleksandar Taranovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Katic_D/0/1/0/all/0/1">Darko Katic</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermann_A/0/1/0/all/0/1">Andreas Hermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakel_R/0/1/0/all/0/1">Rainer J&#xe4;kel</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a></p>
<p>Industrial robots are applied in a widening range of industries, but robot
programming mostly remains a task limited to programming experts. We propose a
natural language-based assistant for programming of advanced, industrial
robotic applications and investigate strategies for domain-specific fine-tuning
of foundation models with limited data and compute.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13933">Structured Probabilistic Coding. (arXiv:2312.13933v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yaxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songlin Hu</a></p>
<p>This paper presents a new supervised representation learning framework,
namely Structured Probabilistic Coding (SPC), to learn compact and informative
representations from input related to the target task. SPC is an encoder-only
probabilistic coding technology with a structured regularization from the
target label space. By extracting compact and informative representations from
input related to the target task, SPC can enhance the generalization ability of
pre-trained language models for better language understanding. Specifically,
the hidden representation is encoded into a Gaussian distribution space, while
maximizing the prior entropy of latent representations concerning label space.
This technique can simultaneously perform information encoding and task
prediction in one module to more fully utilize the effective information from
input data, and use variational inference in the output space to reduce
randomness and uncertainty. To better control the probability distribution in
the latent space, a structured regularization is proposed to promote
class-level uniformity in the latent space. With the regularization term, SPC
can preserve the Gaussian distribution structure of latent code as well as
better cover the hidden space with class uniformly. We conduct evaluations on
12 natural language understanding tasks. The results show that our SPC can
effectively improve the performance of pre-trained language models for various
classification and regression tasks. Experiments demonstrate that SPC can
enhance the generalization capability, robustness to label noise, and
clustering quality of output representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13951">Typhoon: Thai Large Language Models. (arXiv:2312.13951v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pipatanakul_K/0/1/0/all/0/1">Kunat Pipatanakul</a>, <a href="http://arxiv.org/find/cs/1/au:+Jirabovonvisut_P/0/1/0/all/0/1">Phatrasek Jirabovonvisut</a>, <a href="http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1">Potsawee Manakul</a>, <a href="http://arxiv.org/find/cs/1/au:+Sripaisarnmongkol_S/0/1/0/all/0/1">Sittipong Sripaisarnmongkol</a>, <a href="http://arxiv.org/find/cs/1/au:+Patomwong_R/0/1/0/all/0/1">Ruangsak Patomwong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chokchainant_P/0/1/0/all/0/1">Pathomporn Chokchainant</a>, <a href="http://arxiv.org/find/cs/1/au:+Tharnpipitchai_K/0/1/0/all/0/1">Kasima Tharnpipitchai</a></p>
<p>Typhoon is a series of Thai large language models (LLMs) developed
specifically for the Thai language. This technical report presents challenges
and insights in developing Thai LLMs, including data preparation, pretraining,
instruction-tuning, and evaluation. As one of the challenges of low-resource
languages is the amount of pretraining data, we apply continual training to
transfer existing world knowledge from a strong LLM. To evaluate the Thai
knowledge encapsulated in each model from the pretraining stage, we develop
ThaiExam, a benchmark based on examinations for high-school students and
investment professionals in Thailand. In addition, we fine-tune Typhoon to
follow Thai instructions, and we evaluate instruction-tuned models on Thai
instruction datasets as well as translation, summarization, and
question-answering tasks. Experimental results on a suite of Thai benchmarks
show that Typhoon outperforms all open-source Thai language models, and its
performance is on par with GPT-3.5 in Thai while having only 7 billion
parameters and being 2.62 times more efficient in tokenizing Thai text.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13961">ChatGPT as a commenter to the news: can LLMs generate human-like opinions?. (arXiv:2312.13961v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tseng_R/0/1/0/all/0/1">Rayden Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1">Suzan Verberne</a>, <a href="http://arxiv.org/find/cs/1/au:+Putten_P/0/1/0/all/0/1">Peter van der Putten</a></p>
<p>ChatGPT, GPT-3.5, and other large language models (LLMs) have drawn
significant attention since their release, and the abilities of these models
have been investigated for a wide variety of tasks. In this research we
investigate to what extent GPT-3.5 can generate human-like comments on Dutch
news articles. We define human likeness as `not distinguishable from human
comments', approximated by the difficulty of automatic classification between
human and GPT comments. We analyze human likeness across multiple prompting
techniques. In particular, we utilize zero-shot, few-shot and context prompts,
for two generated personas. We found that our fine-tuned BERT models can easily
distinguish human-written comments from GPT-3.5 generated comments, with none
of the used prompting methods performing noticeably better. We further analyzed
that human comments consistently showed higher lexical diversity than
GPT-generated comments. This indicates that although generative LLMs can
generate fluent text, their capability to create human-like opinionated
comments is still limited.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14033">T-Eval: Evaluating the Tool Utilization Capability Step by Step. (arXiv:2312.14033v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zehui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1">Weihua Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kuikun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiangning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Miao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_J/0/1/0/all/0/1">Jingming Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Feng Zhao</a></p>
<p>Large language models (LLM) have achieved remarkable performance on various
NLP tasks and are augmented by tools for broader applications. Yet, how to
evaluate and analyze the tool-utilization capability of LLMs is still
under-explored. In contrast to previous works that evaluate models
holistically, we comprehensively decompose the tool utilization into multiple
sub-processes, including instruction following, planning, reasoning, retrieval,
understanding, and review. Based on that, we further introduce \shortname~to
evaluate the tool utilization capability step by step. \shortname~disentangles
the tool utilization evaluation into several sub-domains along model
capabilities, facilitating the inner understanding of both holistic and
isolated competency of LLMs. We conduct extensive experiments on \shortname~and
in-depth analysis of various LLMs. \shortname~ not only exhibits consistency
with the outcome-oriented evaluation but also provides a more fine-grained
analysis of the capabilities of LLMs, providing a new perspective in LLM
evaluation on tool-utilization ability. The benchmark will be available at
\href{https://github.com/open-compass/T-Eval}{https://github.com/open-compass/T-Eval}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14069">EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models. (arXiv:2312.14069v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seyssel_M/0/1/0/all/0/1">Maureen de Seyssel</a>, <a href="http://arxiv.org/find/cs/1/au:+DAvirro_A/0/1/0/all/0/1">Antony D&#x27;Avirro</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Adina Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1">Emmanuel Dupoux</a></p>
<p>We introduce EmphAssess, a prosodic benchmark designed to evaluate the
capability of speech-to-speech models to encode and reproduce prosodic
emphasis. We apply this to two tasks: speech resynthesis and speech-to-speech
translation. In both cases, the benchmark evaluates the ability of the model to
encode emphasis in the speech input and accurately reproduce it in the output,
potentially across a change of speaker and language. As part of the evaluation
pipeline, we introduce EmphaClass, a new model that classifies emphasis at the
frame or word level.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.09749">Importance Estimation from Multiple Perspectives for Keyphrase Extraction. (arXiv:2110.09749v5 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingyang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1">Liping Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Lin Xiao</a></p>
<p>Keyphrase extraction is a fundamental task in Natural Language Processing,
which usually contains two main parts: candidate keyphrase extraction and
keyphrase importance estimation. From the view of human understanding
documents, we typically measure the importance of phrase according to its
syntactic accuracy, information saliency, and concept consistency
simultaneously. However, most existing keyphrase extraction approaches only
focus on the part of them, which leads to biased results. In this paper, we
propose a new approach to estimate the importance of keyphrase from multiple
perspectives (called as \textit{KIEMP}) and further improve the performance of
keyphrase extraction. Specifically, \textit{KIEMP} estimates the importance of
phrase with three modules: a chunking module to measure its syntactic accuracy,
a ranking module to check its information saliency, and a matching module to
judge the concept (i.e., topic) consistency between phrase and the whole
document. These three modules are seamlessly jointed together via an end-to-end
multi-task learning model, which is helpful for three parts to enhance each
other and balance the effects of three perspectives. Experimental results on
six benchmark datasets show that \textit{KIEMP} outperforms the existing
state-of-the-art keyphrase extraction approaches in most cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.02047">Hyperbolic Relevance Matching for Neural Keyphrase Extraction. (arXiv:2205.02047v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingyang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1">Liping Jing</a></p>
<p>Keyphrase extraction is a fundamental task in natural language processing and
information retrieval that aims to extract a set of phrases with important
information from a source document. Identifying important keyphrase is the
central component of the keyphrase extraction task, and its main challenge is
how to represent information comprehensively and discriminate importance
accurately. In this paper, to address these issues, we design a new hyperbolic
matching model (HyperMatch) to represent phrases and documents in the same
hyperbolic space and explicitly estimate the phrase-document relevance via the
Poincar\'e distance as the important score of each phrase. Specifically, to
capture the hierarchical syntactic and semantic structure information,
HyperMatch takes advantage of the hidden representations in multiple layers of
RoBERTa and integrates them as the word embeddings via an adaptive mixing
layer. Meanwhile, considering the hierarchical structure hidden in the
document, HyperMatch embeds both phrases and documents in the same hyperbolic
space via a hyperbolic phrase encoder and a hyperbolic document encoder. This
strategy can further enhance the estimation of phrase-document relevance due to
the good properties of hyperbolic space. In this setting, the keyphrase
extraction can be taken as a matching problem and effectively implemented by
minimizing a hyperbolic margin-based triplet loss. Extensive experiments are
conducted on six benchmarks and demonstrate that HyperMatch outperforms the
state-of-the-art baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.11326">Towards Faithful Model Explanation in NLP: A Survey. (arXiv:2209.11326v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qing Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Apidianaki_M/0/1/0/all/0/1">Marianna Apidianaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1">Chris Callison-Burch</a></p>
<p>End-to-end neural Natural Language Processing (NLP) models are notoriously
difficult to understand. This has given rise to numerous efforts towards model
explainability in recent years. One desideratum of model explanation is
faithfulness, i.e. an explanation should accurately represent the reasoning
process behind the model's prediction. In this survey, we review over 110 model
explanation methods in NLP through the lens of faithfulness. We first discuss
the definition and evaluation of faithfulness, as well as its significance for
explainability. We then introduce recent advances in faithful explanation,
grouping existing approaches into five categories: similarity-based methods,
analysis of model-internal structures, backpropagation-based methods,
counterfactual intervention, and self-explanatory models. For each category, we
synthesize its representative studies, strengths, and weaknesses. Finally, we
summarize their common virtues and remaining challenges, and reflect on future
work directions towards faithful explainability in NLP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02846">Contrastive variational information bottleneck for aspect-based sentiment analysis. (arXiv:2303.02846v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1">Mingshan Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Min Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1">Qingshan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruifeng Xu</a></p>
<p>Deep learning techniques have dominated the literature on aspect-based
sentiment analysis (ABSA), achieving state-of-the-art performance. However,
deep models generally suffer from spurious correlations between input features
and output labels, which hurts the robustness and generalization capability by
a large margin. In this paper, we propose to reduce spurious correlations for
ABSA, via a novel Contrastive Variational Information Bottleneck framework
(called CVIB). The proposed CVIB framework is composed of an original network
and a self-pruned network, and these two networks are optimized simultaneously
via contrastive learning. Concretely, we employ the Variational Information
Bottleneck (VIB) principle to learn an informative and compressed network
(self-pruned network) from the original network, which discards the superfluous
patterns or spurious correlations between input features and prediction labels.
Then, self-pruning contrastive learning is devised to pull together
semantically similar positive pairs and push away dissimilar pairs, where the
representations of the anchor learned by the original and self-pruned networks
respectively are regarded as a positive pair while the representations of two
different sentences within a mini-batch are treated as a negative pair. To
verify the effectiveness of our CVIB method, we conduct extensive experiments
on five benchmark ABSA datasets and the experimental results show that our
approach achieves better performance than the strong competitors in terms of
overall prediction performance, robustness, and generalization. Code and data
to reproduce the results in this paper is available at:
https://github.com/shesshan/CVIB.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10512">AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning. (arXiv:2303.10512v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minshuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukharin_A/0/1/0/all/0/1">Alexander Bukharin</a>, <a href="http://arxiv.org/find/cs/1/au:+Karampatziakis_N/0/1/0/all/0/1">Nikos Karampatziakis</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a></p>
<p>Fine-tuning large pre-trained language models on downstream tasks has become
an important paradigm in NLP. However, common practice fine-tunes all of the
parameters in a pre-trained model, which becomes prohibitive when a large
number of downstream tasks are present. Therefore, many fine-tuning methods are
proposed to learn incremental updates of pre-trained weights in a parameter
efficient way, e.g., low-rank increments. These methods often evenly distribute
the budget of incremental updates across all pre-trained weight matrices, and
overlook the varying importance of different weight parameters. As a
consequence, the fine-tuning performance is suboptimal. To bridge this gap, we
propose AdaLoRA, which adaptively allocates the parameter budget among weight
matrices according to their importance score. In particular, AdaLoRA
parameterizes the incremental updates in the form of singular value
decomposition. Such a novel approach allows us to effectively prune the
singular values of unimportant updates, which is essentially to reduce their
parameter budget but circumvent intensive exact SVD computations. We conduct
extensive experiments with several pre-trained models on natural language
processing, question answering, and natural language generation to validate the
effectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable
improvement over baselines, especially in the low budget settings. Our code is
publicly available at https://github.com/QingruZhang/AdaLoRA .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.11032">DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4. (arXiv:2303.11032v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaowei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zihao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Chao Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Haixing Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Lin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_P/0/1/0/all/0/1">Peng Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1">Fang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1">Dinggang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Quanzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dajiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a></p>
<p>The digitization of healthcare has facilitated the sharing and re-using of
medical data but has also raised concerns about confidentiality and privacy.
HIPAA (Health Insurance Portability and Accountability Act) mandates removing
re-identifying information before the dissemination of medical records. Thus,
effective and efficient solutions for de-identifying medical data, especially
those in free-text forms, are highly needed. While various computer-assisted
de-identification methods, including both rule-based and learning-based, have
been developed and used in prior practice, such solutions still lack
generalizability or need to be fine-tuned according to different scenarios,
significantly imposing restrictions in wider use. The advancement of large
language models (LLM), such as ChatGPT and GPT-4, have shown great potential in
processing text data in the medical domain with zero-shot in-context learning,
especially in the task of privacy protection, as these models can identify
confidential information by their powerful named entity recognition (NER)
capability. In this work, we developed a novel GPT4-enabled de-identification
framework (``DeID-GPT") to automatically identify and remove the identifying
information. Compared to existing commonly used medical text data
de-identification methods, our developed DeID-GPT showed the highest accuracy
and remarkable reliability in masking private information from the unstructured
medical text while preserving the original structure and meaning of the text.
This study is one of the earliest to utilize ChatGPT and GPT-4 for medical text
data processing and de-identification, which provides insights for further
research and solution development on the use of LLMs such as ChatGPT/GPT-4 in
healthcare. Codes and benchmarking data information are available at
https://github.com/yhydhx/ChatGPT-API.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shijie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Irsoy_O/0/1/0/all/0/1">Ozan Irsoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Steven Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabravolski_V/0/1/0/all/0/1">Vadim Dabravolski</a>, <a href="http://arxiv.org/find/cs/1/au:+Dredze_M/0/1/0/all/0/1">Mark Dredze</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1">Sebastian Gehrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kambadur_P/0/1/0/all/0/1">Prabhanjan Kambadur</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1">David Rosenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_G/0/1/0/all/0/1">Gideon Mann</a></p>
<p>The use of NLP in the realm of financial technology is broad and complex,
with applications ranging from sentiment analysis and named entity recognition
to question answering. Large Language Models (LLMs) have been shown to be
effective on a variety of tasks; however, no LLM specialized for the financial
domain has been reported in literature. In this work, we present BloombergGPT,
a 50 billion parameter language model that is trained on a wide range of
financial data. We construct a 363 billion token dataset based on Bloomberg's
extensive data sources, perhaps the largest domain-specific dataset yet,
augmented with 345 billion tokens from general purpose datasets. We validate
BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite
of internal benchmarks that most accurately reflect our intended usage. Our
mixed dataset training leads to a model that outperforms existing models on
financial tasks by significant margins without sacrificing performance on
general LLM benchmarks. Additionally, we explain our modeling choices, training
process, and evaluation methodology. We release Training Chronicles (Appendix
C) detailing our experience in training BloombergGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06762">Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study. (arXiv:2304.06762v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1">Lawrence McAfee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1">Oleksii Kuchaiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a></p>
<p>Large decoder-only language models (LMs) can be largely improved in terms of
perplexity by retrieval (e.g., RETRO), but its impact on text generation
quality and downstream task accuracy is unclear. Thus, it is still an open
question: shall we pretrain large autoregressive LMs with retrieval? To answer
it, we perform a comprehensive study on a scalable pre-trained
retrieval-augmented LM (i.e., RETRO) compared with standard GPT and
retrieval-augmented GPT incorporated at fine-tuning or inference stages. We
first provide the recipe to reproduce RETRO up to 9.5B parameters while
retrieving a text corpus with 330B tokens. Based on that, we have the following
novel findings: i) RETRO outperforms GPT on text generation with much less
degeneration (i.e., repetition), moderately higher factual accuracy, and
slightly lower toxicity with a nontoxic retrieval database. ii) On the LM
Evaluation Harness benchmark, RETRO largely outperforms GPT on
knowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,
we introduce a simple variant of the model, RETRO++, which largely improves
open-domain QA results of original RETRO (e.g., EM score +8.6 on Natural
Question) and significantly outperforms retrieval-augmented GPT in both
fine-tuning and zero-shot evaluation settings. Our findings highlight the
promising direction of pretraining autoregressive LMs with retrieval as future
foundation models. We release our code and model at:
https://github.com/NVIDIA/Megatron-LM/blob/main/tools/retro/README.md
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05722">Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. (arXiv:2307.05722v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Likang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1">Zhaopeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hengshu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a></p>
<p>Large Language Models (LLMs) have revolutionized natural language processing
tasks, demonstrating their exceptional capabilities in various domains.
However, their potential for behavior graph understanding in job
recommendations remains largely unexplored. This paper focuses on unveiling the
capability of large language models in understanding behavior graphs and
leveraging this understanding to enhance recommendations in online recruitment,
including the promotion of out-of-distribution (OOD) application. We present a
novel framework that harnesses the rich contextual information and semantic
representations provided by large language models to analyze behavior graphs
and uncover underlying patterns and relationships. Specifically, we propose a
meta-path prompt constructor that leverages LLM recommender to understand
behavior graphs for the first time and design a corresponding path augmentation
module to alleviate the prompt bias introduced by path-based sequence input. By
leveraging this capability, our framework enables personalized and accurate job
recommendations for individual users. We evaluate the effectiveness of our
approach on a comprehensive dataset and demonstrate its ability to improve the
relevance and quality of recommended quality. This research not only sheds
light on the untapped potential of large language models but also provides
valuable insights for developing advanced recommendation systems in the
recruitment market. The findings contribute to the growing field of natural
language processing and offer practical implications for enhancing job search
experiences. We release the code at https://github.com/WLiK/GLRec.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10799">Layer-wise Representation Fusion for Compositional Generalization. (arXiv:2307.10799v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yafang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuangtao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yuxuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1">Zhaohong Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1">Biao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yidong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiaodong Shi</a></p>
<p>Existing neural models are demonstrated to struggle with compositional
generalization (CG), i.e., the ability to systematically generalize to unseen
compositions of seen components. A key reason for failure on CG is that the
syntactic and semantic representations of sequences in both the uppermost layer
of the encoder and decoder are entangled. However, previous work concentrates
on separating the learning of syntax and semantics instead of exploring the
reasons behind the representation entanglement (RE) problem to solve it. We
explain why it exists by analyzing the representation evolving mechanism from
the bottom to the top of the Transformer layers. We find that the ``shallow''
residual connections within each layer fail to fuse previous layers'
information effectively, leading to information forgetting between layers and
further the RE problems. Inspired by this, we propose LRF, a novel
\textbf{L}ayer-wise \textbf{R}epresentation \textbf{F}usion framework for CG,
which learns to fuse previous layers' information back into the encoding and
decoding process effectively through introducing a \emph{fuse-attention module}
at each encoder and decoder layer. LRF achieves promising results on two
realistic benchmarks, empirically demonstrating the effectiveness of our
proposal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14367">Prot2Text: Multimodal Protein&#x27;s Function Generation with GNNs and Transformers. (arXiv:2307.14367v2 [q-bio.QM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Abdine_H/0/1/0/all/0/1">Hadi Abdine</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chatzianastasis_M/0/1/0/all/0/1">Michail Chatzianastasis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bouyioukos_C/0/1/0/all/0/1">Costas Bouyioukos</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Vazirgiannis_M/0/1/0/all/0/1">Michalis Vazirgiannis</a></p>
<p>The complex nature of big biological systems pushed some scientists to
classify its understanding under the inconceivable missions. Different leveled
challenges complicated this task, one of is the prediction of a protein's
function. In recent years, significant progress has been made in this field
through the development of various machine learning approaches. However, most
existing methods formulate the task as a multi-classification problem, i.e
assigning predefined labels to proteins. In this work, we propose a novel
approach, \textbf{Prot2Text}, which predicts a protein function's in a free
text style, moving beyond the conventional binary or categorical
classifications. By combining Graph Neural Networks(GNNs) and Large Language
Models(LLMs), in an encoder-decoder framework, our model effectively integrates
diverse data types including proteins' sequences, structures, and textual
annotations. This multimodal approach allows for a holistic representation of
proteins' functions, enabling the generation of detailed and accurate
descriptions. To evaluate our model, we extracted a multimodal protein dataset
from SwissProt, and demonstrate empirically the effectiveness of Prot2Text.
These results highlight the transformative impact of multimodal models,
specifically the fusion of GNNs and LLMs, empowering researchers with powerful
tools for more accurate prediction of proteins' functions. The code, the models
and a demo will be publicly released.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models. (arXiv:2307.15043v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1">Andy Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasr_M/0/1/0/all/0/1">Milad Nasr</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1">Matt Fredrikson</a></p>
<p>Because "out-of-the-box" large language models are capable of generating a
great deal of objectionable content, recent work has focused on aligning these
models in an attempt to prevent undesirable generation. While there has been
some success at circumventing these measures -- so-called "jailbreaks" against
LLMs -- these attacks have required significant human ingenuity and are brittle
in practice. In this paper, we propose a simple and effective attack method
that causes aligned language models to generate objectionable behaviors.
Specifically, our approach finds a suffix that, when attached to a wide range
of queries for an LLM to produce objectionable content, aims to maximize the
probability that the model produces an affirmative response (rather than
refusing to answer). However, instead of relying on manual engineering, our
approach automatically produces these adversarial suffixes by a combination of
greedy and gradient-based search techniques, and also improves over past
automatic prompt generation methods.
</p>
<p>Surprisingly, we find that the adversarial prompts generated by our approach
are quite transferable, including to black-box, publicly released LLMs.
Specifically, we train an adversarial attack suffix on multiple prompts (i.e.,
queries asking for many different types of objectionable content), as well as
multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting
attack suffix is able to induce objectionable content in the public interfaces
to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,
Pythia, Falcon, and others. In total, this work significantly advances the
state-of-the-art in adversarial attacks against aligned language models,
raising important questions about how such systems can be prevented from
producing objectionable information. Code is available at
github.com/llm-attacks/llm-attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10045">An Empirical Study of CLIP for Text-based Person Search. (arXiv:2308.10045v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Min Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Ziyin Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a></p>
<p>Text-based Person Search (TBPS) aims to retrieve the person images using
natural language descriptions. Recently, Contrastive Language Image Pretraining
(CLIP), a universal large cross-modal vision-language pre-training model, has
remarkably performed over various cross-modal downstream tasks due to its
powerful cross-modal semantic learning capacity. TPBS, as a fine-grained
cross-modal retrieval task, is also facing the rise of research on the
CLIP-based TBPS. In order to explore the potential of the visual-language
pre-training model for downstream TBPS tasks, this paper makes the first
attempt to conduct a comprehensive empirical study of CLIP for TBPS and thus
contribute a straightforward, incremental, yet strong TBPS-CLIP baseline to the
TBPS community. We revisit critical design considerations under CLIP, including
data augmentation and loss function. The model, with the aforementioned designs
and practical training tricks, can attain satisfactory performance without any
sophisticated modules. Also, we conduct the probing experiments of TBPS-CLIP in
model generalization and model compression, demonstrating the effectiveness of
TBPS-CLIP from various aspects. This work is expected to provide empirical
insights and highlight future CLIP-based TBPS research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12466">Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis. (arXiv:2308.12466v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Akshat Gupta</a></p>
<p>Since the introduction of ChatGPT and GPT-4, these models have been tested
across a large number of tasks. Their adeptness across domains is evident, but
their aptitude in playing games, and specifically their aptitude in the realm
of poker has remained unexplored. Poker is a game that requires decision making
under uncertainty and incomplete information. In this paper, we put ChatGPT and
GPT-4 through the poker test and evaluate their poker skills. Our findings
reveal that while both models display an advanced understanding of poker,
encompassing concepts like the valuation of starting hands, playing positions
and other intricacies of game theory optimal (GTO) poker, both ChatGPT and
GPT-4 are NOT game theory optimal poker players.
</p>
<p>Profitable strategies in poker are evaluated in expectations over large
samples. Through a series of experiments, we first discover the characteristics
of optimal prompts and model parameters for playing poker with these models.
Our observations then unveil the distinct playing personas of the two models.
We first conclude that GPT-4 is a more advanced poker player than ChatGPT. This
exploration then sheds light on the divergent poker tactics of the two models:
ChatGPT's conservativeness juxtaposed against GPT-4's aggression. In poker
vernacular, when tasked to play GTO poker, ChatGPT plays like a nit, which
means that it has a propensity to only engage with premium hands and folds a
majority of hands. When subjected to the same directive, GPT-4 plays like a
maniac, showcasing a loose and aggressive style of play. Both strategies,
although relatively advanced, are not game theory optimal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.14034">Confucius: Iterative Tool Learning from Introspection Feedback by Easy-to-Difficult Curriculum. (arXiv:2308.14034v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhengliang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Minghang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_B/0/1/0/all/0/1">Bowen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Pengjie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaochun Ren</a></p>
<p>Augmenting large language models (LLMs) with external tools has emerged as a
promising approach to extending the capability of LLMs. Although some works
employ open-source LLMs for the tool learning task, most of them are trained in
a controlled environment in which LLMs only learn to execute the human-provided
tools. However, selecting proper tools from the large toolset is also a crucial
ability for the tool learning model to be applied in real-world applications.
Existing methods usually directly employ self-instruction methods to train the
model, which ignores differences in tool complexity. In this paper, we propose
the Confucius, a novel tool learning framework to train LLM to use complicated
tools in real-world scenarios, which contains two main phases: (1) We first
propose a multi-stage learning method to teach the LLM to use various tools
from an easy-to-difficult curriculum; (2) thenceforth, we propose the Iterative
Self-instruct from Introspective Feedback (ISIF) to dynamically construct the
dataset to improve the ability to use the complicated tool. Extensive
experiments conducted on both controlled and real-world settings demonstrate
the superiority of our tool learning framework in the real-world application
scenarios compared to both tuning-free (e.g. ChatGPT, Claude) and tuning-based
baselines (e.g. GPT4Tools).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05203">From Artificially Real to Real: Leveraging Pseudo Data from Large Language Models for Low-Resource Molecule Discovery. (arXiv:2309.05203v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuhan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_N/0/1/0/all/0/1">Nuwa Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yanrui Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haochun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jianyu_C/0/1/0/all/0/1">Chen Jianyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sendong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a></p>
<p>Molecule discovery serves as a cornerstone in numerous scientific domains,
fueling the development of new materials and innovative drug designs. Recent
developments of in-silico molecule discovery have highlighted the promising
results of cross-modal techniques, which bridge molecular structures with their
descriptive annotations. However, these cross-modal methods frequently
encounter the issue of data scarcity, hampering their performance and
application. In this paper, we address the low-resource challenge by utilizing
artificially-real data generated by Large Language Models (LLMs). We first
introduce a retrieval-based prompting strategy to construct high-quality pseudo
data, then explore the optimal method to effectively leverage this pseudo data.
Experiments show that using pseudo data for domain adaptation outperforms all
existing methods, while also requiring a smaller model scale, reduced data size
and lower training cost, highlighting its efficiency. Furthermore, our method
shows a sustained improvement as the volume of pseudo data increases, revealing
the great potential of pseudo data in advancing low-resource cross-modal
molecule discovery. Our code and data are available at
https://github.com/SCIR-HI/ArtificiallyR2R.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.08173">FedJudge: Federated Legal Large Language Model. (arXiv:2309.08173v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yue_L/0/1/0/all/0/1">Linan Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yichao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Weibo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Ye Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1">Fangzhou Yao</a></p>
<p>Large Language Models (LLMs) have gained prominence in the field of Legal
Intelligence, offering potential applications in assisting legal professionals
and laymen. However, the centralized training of these Legal LLMs raises data
privacy concerns, as legal data is distributed among various institutions
containing sensitive individual information. This paper addresses this
challenge by exploring the integration of Legal LLMs with Federated Learning
(FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on
devices or clients, and their parameters are aggregated and distributed on a
central server, ensuring data privacy without directly sharing raw data.
However, computation and communication overheads hinder the full fine-tuning of
LLMs under the FL setting. Moreover, the distribution shift of legal data
reduces the effectiveness of FL methods. To this end, in this paper, we propose
the first Federated Legal Large Language Model (FedJudge) framework, which
fine-tunes Legal LLMs efficiently and effectively. Specifically, FedJudge
utilizes parameter-efficient fine-tuning methods to update only a few
additional parameters during the FL training. Besides, we explore the continual
learning methods to preserve the global model's important parameters when
training local clients to mitigate the problem of data shifts. Extensive
experimental results on three real-world datasets clearly validate the
effectiveness of FedJudge. Code is released at
https://github.com/yuelinan/FedJudge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.14859">3M-TRANSFORMER: A Multi-Stage Multi-Stream Multimodal Transformer for Embodied Turn-Taking Prediction. (arXiv:2310.14859v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fatan_M/0/1/0/all/0/1">Mehdi Fatan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mincato_E/0/1/0/all/0/1">Emanuele Mincato</a>, <a href="http://arxiv.org/find/cs/1/au:+Pintzou_D/0/1/0/all/0/1">Dimitra Pintzou</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimiccoli_M/0/1/0/all/0/1">Mariella Dimiccoli</a></p>
<p>Predicting turn-taking in multiparty conversations has many practical
applications in human-computer/robot interaction. However, the complexity of
human communication makes it a challenging task. Recent advances have shown
that synchronous multi-perspective egocentric data can significantly improve
turn-taking prediction compared to asynchronous, single-perspective
transcriptions. Building on this research, we propose a new multimodal
transformer-based architecture for predicting turn-taking in embodied,
synchronized multi-perspective data. Our experimental results on the recently
introduced EgoCom dataset show a substantial performance improvement of up to
14.01% on average compared to existing baselines and alternative
transformer-based approaches. The source code, and the pre-trained models of
our 3M-Transformer will be available upon acceptance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07919">Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models. (arXiv:2311.07919v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chu_Y/0/1/0/all/0/1">Yunfei Chu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xiaohuan Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1">Qian Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Shiliang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Z/0/1/0/all/0/1">Zhijie Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a></p>
<p>Recently, instruction-following audio-language models have received broad
attention for audio interaction with humans. However, the absence of
pre-trained audio models capable of handling diverse audio types and tasks has
hindered progress in this field. Consequently, most existing works have only
been able to support a limited range of interaction capabilities. In this
paper, we develop the Qwen-Audio model and address this limitation by scaling
up audio-language pre-training to cover over 30 tasks and various audio types,
such as human speech, natural sounds, music, and songs, to facilitate universal
audio understanding abilities. However, directly co-training all tasks and
datasets can lead to interference issues, as the textual labels associated with
different datasets exhibit considerable variations due to differences in task
focus, language, granularity of annotation, and text structure. To overcome the
one-to-many interference, we carefully design a multi-task training framework
by conditioning on a sequence of hierarchical tags to the decoder for
encouraging knowledge sharing and avoiding interference through shared and
specified tags respectively. Remarkably, Qwen-Audio achieves impressive
performance across diverse benchmark tasks without requiring any task-specific
fine-tuning, surpassing its counterparts. Building upon the capabilities of
Qwen-Audio, we further develop Qwen-Audio-Chat, which allows for input from
various audios and text inputs, enabling multi-turn dialogues and supporting
various audio-central scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18260">Consensus, dissensus and synergy between clinicians and specialist foundation models in radiology report generation. (arXiv:2311.18260v3 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Tanno_R/0/1/0/all/0/1">Ryutaro Tanno</a>, <a href="http://arxiv.org/find/eess/1/au:+Barrett_D/0/1/0/all/0/1">David G.T. Barrett</a>, <a href="http://arxiv.org/find/eess/1/au:+Sellergren_A/0/1/0/all/0/1">Andrew Sellergren</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghaisas_S/0/1/0/all/0/1">Sumedh Ghaisas</a>, <a href="http://arxiv.org/find/eess/1/au:+Dathathri_S/0/1/0/all/0/1">Sumanth Dathathri</a>, <a href="http://arxiv.org/find/eess/1/au:+See_A/0/1/0/all/0/1">Abigail See</a>, <a href="http://arxiv.org/find/eess/1/au:+Welbl_J/0/1/0/all/0/1">Johannes Welbl</a>, <a href="http://arxiv.org/find/eess/1/au:+Singhal_K/0/1/0/all/0/1">Karan Singhal</a>, <a href="http://arxiv.org/find/eess/1/au:+Azizi_S/0/1/0/all/0/1">Shekoofeh Azizi</a>, <a href="http://arxiv.org/find/eess/1/au:+Tu_T/0/1/0/all/0/1">Tao Tu</a>, <a href="http://arxiv.org/find/eess/1/au:+Schaekermann_M/0/1/0/all/0/1">Mike Schaekermann</a>, <a href="http://arxiv.org/find/eess/1/au:+May_R/0/1/0/all/0/1">Rhys May</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_R/0/1/0/all/0/1">Roy Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Man_S/0/1/0/all/0/1">SiWai Man</a>, <a href="http://arxiv.org/find/eess/1/au:+Ahmed_Z/0/1/0/all/0/1">Zahra Ahmed</a>, <a href="http://arxiv.org/find/eess/1/au:+Mahdavi_S/0/1/0/all/0/1">Sara Mahdavi</a>, <a href="http://arxiv.org/find/eess/1/au:+Matias_Y/0/1/0/all/0/1">Yossi Matias</a>, <a href="http://arxiv.org/find/eess/1/au:+Barral_J/0/1/0/all/0/1">Joelle Barral</a>, <a href="http://arxiv.org/find/eess/1/au:+Eslami_A/0/1/0/all/0/1">Ali Eslami</a>, <a href="http://arxiv.org/find/eess/1/au:+Belgrave_D/0/1/0/all/0/1">Danielle Belgrave</a>, <a href="http://arxiv.org/find/eess/1/au:+Natarajan_V/0/1/0/all/0/1">Vivek Natarajan</a>, <a href="http://arxiv.org/find/eess/1/au:+Shetty_S/0/1/0/all/0/1">Shravya Shetty</a>, <a href="http://arxiv.org/find/eess/1/au:+Kohli_P/0/1/0/all/0/1">Pushmeet Kohli</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1">Po-Sen Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Karthikesalingam_A/0/1/0/all/0/1">Alan Karthikesalingam</a>, <a href="http://arxiv.org/find/eess/1/au:+Ktena_I/0/1/0/all/0/1">Ira Ktena</a></p>
<p>Radiology reports are an instrumental part of modern medicine, informing key
clinical decisions such as diagnosis and treatment. The worldwide shortage of
radiologists, however, restricts access to expert care and imposes heavy
workloads, contributing to avoidable errors and delays in report delivery.
While recent progress in automated report generation with vision-language
models offer clear potential in ameliorating the situation, the path to
real-world adoption has been stymied by the challenge of evaluating the
clinical quality of AI-generated reports. In this study, we build a
state-of-the-art report generation system for chest radiographs,
$\textit{Flamingo-CXR}$, by fine-tuning a well-known vision-language foundation
model on radiology data. To evaluate the quality of the AI-generated reports, a
group of 16 certified radiologists provide detailed evaluations of AI-generated
and human written reports for chest X-rays from an intensive care setting in
the United States and an inpatient setting in India. At least one radiologist
(out of two per case) preferred the AI report to the ground truth report in
over 60$\%$ of cases for both datasets. Amongst the subset of AI-generated
reports that contain errors, the most frequently cited reasons were related to
the location and finding, whereas for human written reports, most mistakes were
related to severity and finding. This disparity suggested potential
complementarity between our AI system and human experts, prompting us to
develop an assistive scenario in which Flamingo-CXR generates a first-draft
report, which is subsequently revised by a clinician. This is the first
demonstration of clinician-AI collaboration for report writing, and the
resultant reports are assessed to be equivalent or preferred by at least one
radiologist to reports written by experts alone in 80$\%$ of in-patient cases
and 60$\%$ of intensive care cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01057">RLHF and IIA: Perverse Incentives. (arXiv:2312.01057v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wanqiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiuyuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_G/0/1/0/all/0/1">Grace Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zheng Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a></p>
<p>Existing algorithms for reinforcement learning from human feedback (RLHF) can
incentivize responses at odds with preferences because they are based on models
that assume independence of irrelevant alternatives (IIA). The perverse
incentives induced by IIA give rise to egregious behavior when innovating on
query formats or learning algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05964">ConSequence: Synthesizing Logically Constrained Sequences for Electronic Health Record Generation. (arXiv:2312.05964v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Theodorou_B/0/1/0/all/0/1">Brandon Theodorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shrusti Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Cao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a></p>
<p>Generative models can produce synthetic patient records for analytical tasks
when real data is unavailable or limited. However, current methods struggle
with adhering to domain-specific knowledge and removing invalid data. We
present ConSequence, an effective approach to integrating domain knowledge into
sequential generative neural network outputs. Our rule-based formulation
includes temporal aggregation and antecedent evaluation modules, ensured by an
efficient matrix multiplication formulation, to satisfy hard and soft logical
constraints across time steps. Existing constraint methods often fail to
guarantee constraint satisfaction, lack the ability to handle temporal
constraints, and hinder the learning and computational efficiency of the model.
In contrast, our approach efficiently handles all types of constraints with
guaranteed logical coherence. We demonstrate ConSequence's effectiveness in
generating electronic health records, outperforming competitors in achieving
complete temporal and spatial constraint satisfaction without compromising
runtime performance or generative quality. Specifically, ConSequence
successfully prevents all rule violations while improving the model quality in
reducing its test perplexity by 5% and incurring less than a 13% slowdown in
generation speed compared to an unconstrained model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07069">Context Matters: Data-Efficient Augmentation of Large Language Models for Scientific Applications. (arXiv:2312.07069v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoran Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Siyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Maravi_A/0/1/0/all/0/1">Anurag Maravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abram_M/0/1/0/all/0/1">Marcin Abram</a></p>
<p>In this paper, we explore the challenges inherent to Large Language Models
(LLMs) like GPT-4, particularly their propensity for hallucinations, logic
mistakes, and incorrect conclusions when tasked with answering complex
questions. The capacity of LLMs to present erroneous answers in a coherent and
semantically rigorous manner further complicates the detection of factual
inaccuracies. This issue is especially pronounced in fields that require
specialized expertise. Our work delves into these challenges, aiming to enhance
the understanding and mitigation of such errors, thereby contributing to the
improvement of LLM accuracy and reliability in scientific and other specialized
domains. Our findings reveal a non-linear relationship between the context's
relevancy and the answers' measured quality. In addition, we demonstrate that
with the correct calibration, it is possible to automate the grading procedure
-- a finding suggesting that, at least to some degree, the LLMs can be used to
self-examine the quality of their own performance. Finally, we describe an
experimental platform that can be seen as a proof-of-concept of the techniques
described in this work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11462">Cascade Speculative Drafting for Even Faster LLM Inference. (arXiv:2312.11462v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Ziyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaocong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jiacheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chenkai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kevin Chen-Chuan Chang</a></p>
<p>Speculative decoding enhances the efficiency of large language models (LLMs)
by leveraging a draft model to draft for a larger target model to review.
However, drafting in speculative decoding involves slow autoregressive
generation and generating tokens of different importance with the same time
allocation. These two inefficiencies lead to its suboptimal performance. To
address this issue, we introduce Cascade Speculative Drafting (CS. Drafting), a
novel approach that employs two types of cascades. The Vertical Cascade
eliminates autoregressive generation from neural models. The Horizontal Cascade
constitutes efficient time allocation in drafting with its optimality supported
by our theoretical analysis. Combining both cascades, our CS. Drafting
algorithm has achieved up to 72 percent additional speedup over speculative
decoding in our experiments while keeping the same output distribution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11562">A Survey of Reasoning with Foundation Models: Concepts, Methodologies, and Outlook. (arXiv:2312.11562v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiankai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chuanyang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_R/0/1/0/all/0/1">Ruihang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiaqi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Mingyu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_M/0/1/0/all/0/1">Mengzhe Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junsong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhangyue Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaozhe Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jie Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Junxian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Wu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xihui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng Ann Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a></p>
<p>Reasoning, a crucial ability for complex problem-solving, plays a pivotal
role in various real-world settings such as negotiation, medical diagnosis, and
criminal investigation. It serves as a fundamental methodology in the field of
Artificial General Intelligence (AGI). With the ongoing development of
foundation models, there is a growing interest in exploring their abilities in
reasoning tasks. In this paper, we introduce seminal foundation models proposed
or adaptable for reasoning, highlighting the latest advancements in various
reasoning tasks, methods, and benchmarks. We then delve into the potential
future directions behind the emergence of reasoning abilities within foundation
models. We also discuss the relevance of multimodal learning, autonomous
agents, and super alignment in the context of reasoning. By discussing these
future research directions, we hope to inspire researchers in their exploration
of this field, stimulate further advancements in reasoning with foundation
models, and contribute to the development of AGI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11779">Are you talking to [&#x27;xem&#x27;] or [&#x27;x&#x27;, &#x27;em&#x27;]? On Tokenization and Addressing Misgendering in LLMs with Pronoun Tokenization Parity. (arXiv:2312.11779v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ovalle_A/0/1/0/all/0/1">Anaelia Ovalle</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrabi_N/0/1/0/all/0/1">Ninareh Mehrabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Palash Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamala_J/0/1/0/all/0/1">Jwala Dhamala</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1">Rahul Gupta</a></p>
<p>A large body of NLP research has documented the ways gender biases manifest
and amplify within large language models (LLMs), though this research has
predominantly operated within a gender binary-centric context. A growing body
of work has identified the harmful limitations of this gender-exclusive
framing; many LLMs cannot correctly and consistently refer to persons outside
the gender binary, especially if they use neopronouns. While data scarcity has
been identified as a possible culprit, the precise mechanisms through which it
influences LLM misgendering remain underexplored. Our work addresses this gap
by studying data scarcity's role in subword tokenization and, consequently, the
formation of LLM word representations. We uncover how the Byte-Pair Encoding
(BPE) tokenizer, a backbone for many popular LLMs, contributes to neopronoun
misgendering through out-of-vocabulary behavior. We introduce pronoun
tokenization parity (PTP), a novel approach to reduce LLM neopronoun
misgendering by preserving a token's functional structure. We evaluate PTP's
efficacy using pronoun consistency-based metrics and a novel syntax-based
metric. Through several controlled experiments, finetuning LLMs with PTP
improves neopronoun consistency from 14.5% to 58.4%, highlighting the
significant role tokenization plays in LLM pronoun consistency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12464">Towards Better Serialization of Tabular Data for Few-shot Classification with Large Language Models. (arXiv:2312.12464v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jaitly_S/0/1/0/all/0/1">Sukriti Jaitly</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_T/0/1/0/all/0/1">Tanay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Shugani_A/0/1/0/all/0/1">Ashish Shugani</a>, <a href="http://arxiv.org/find/cs/1/au:+Grewal_R/0/1/0/all/0/1">Razik Singh Grewal</a></p>
<p>We present a study on the integration of Large Language Models (LLMs) in
tabular data classification, emphasizing an efficient framework. Building upon
existing work done in TabLLM (<a href="/abs/2210.10723">arXiv:2210.10723</a>), we introduce three novel
serialization techniques, including the standout LaTeX serialization method.
This method significantly boosts the performance of LLMs in processing
domain-specific datasets, Our method stands out for its memory efficiency and
ability to fully utilize complex data structures. Through extensive
experimentation, including various serialization approaches like feature
combination and importance, we demonstrate our work's superiority in accuracy
and efficiency over traditional models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12655">Can Transformers Learn Sequential Function Classes In Context?. (arXiv:2312.12655v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Campbell_R/0/1/0/all/0/1">Ryan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1">Emma Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">Evan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vir_R/0/1/0/all/0/1">Reya Vir</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsiao_E/0/1/0/all/0/1">Ethan Hsiao</a></p>
<p>In-context learning (ICL) has revolutionized the capabilities of transformer
models in NLP. In our project, we extend the understanding of the mechanisms
underpinning ICL by exploring whether transformers can learn from sequential,
non-textual function class data distributions. We introduce a novel sliding
window sequential function class and employ toy-sized transformers with a GPT-2
architecture to conduct our experiments. Our analysis indicates that these
models can indeed leverage ICL when trained on non-textual sequential function
classes. Additionally, our experiments with randomized y-label sequences
highlights that transformers retain some ICL capabilities even when the label
associations are obfuscated. We provide evidence that transformers can reason
with and understand sequentiality encoded within function classes, as reflected
by the effective learning of our proposed tasks. Our results also show that the
performance deteriorated with increasing randomness in the labels, though not
to the extent one might expect, implying a potential robustness of learned
sequentiality against label noise. Future research may want to look into how
previous explanations of transformers, such as induction heads and task
vectors, relate to sequentiality in ICL in these toy examples. Our
investigation lays the groundwork for further research into how transformers
process and perceive sequential data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12918">Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors. (arXiv:2312.12918v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi-Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tieniu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a></p>
<p>To combat the potential misuse of Natural Language Generation (NLG)
technology, a variety of algorithms have been developed for the detection of
AI-generated texts. Traditionally, this task is treated as a binary
classification problem. Although supervised learning has demonstrated promising
results, acquiring labeled data for detection purposes poses real-world
challenges and the risk of overfitting. In an effort to address these issues,
we delve into the realm of zero-shot machine-generated text detection. Existing
zero-shot detectors, typically designed for specific tasks or topics, often
assume uniform testing scenarios, limiting their practicality. In our research,
we explore various advanced Large Language Models (LLMs) and their specialized
variants, contributing to this field in several ways. In empirical studies, we
uncover a significant correlation between topics and detection performance.
Secondly, we delve into the influence of topic shifts on zero-shot detectors.
These investigations shed light on the adaptability and robustness of these
detection methods across diverse topics. The code is available at
\url{https://github.com/yfzhang114/robustness-detection}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12999">Machine Mindset: An MBTI Exploration of Large Language Models. (arXiv:2312.12999v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jiaxi Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_L/0/1/0/all/0/1">Liuzhenghao Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Jing Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jing Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">YongHong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Li Yuan</a></p>
<p>We present a novel approach for integrating Myers-Briggs Type Indicator
(MBTI) personality traits into large language models (LLMs), addressing the
challenges of personality consistency in personalized AI. Our method, "Machine
Mindset," involves a two-phase fine-tuning and Direct Preference Optimization
(DPO) to embed MBTI traits into LLMs. This approach ensures that models
internalize these traits, offering a stable and consistent personality profile.
We demonstrate the effectiveness of our models across various domains, showing
alignment between model performance and their respective MBTI traits. The paper
highlights significant contributions in the development of personality datasets
and a new training methodology for personality integration in LLMs, enhancing
the potential for personalized AI applications. We also open-sourced our model
and part of the data at \url{https://github.com/PKU-YuanGroup/Machine-Mindset}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11010">Iterative Shallow Fusion of Backward Language Model for End-to-End Speech Recognition. (arXiv:2310.11010v1 [eess.AS] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ogawa_A/0/1/0/all/0/1">Atsunori Ogawa</a>, <a href="http://arxiv.org/find/eess/1/au:+Moriya_T/0/1/0/all/0/1">Takafumi Moriya</a>, <a href="http://arxiv.org/find/eess/1/au:+Kamo_N/0/1/0/all/0/1">Naoyuki Kamo</a>, <a href="http://arxiv.org/find/eess/1/au:+Tawara_N/0/1/0/all/0/1">Naohiro Tawara</a>, <a href="http://arxiv.org/find/eess/1/au:+Delcroix_M/0/1/0/all/0/1">Marc Delcroix</a></p>
<p>We propose a new shallow fusion (SF) method to exploit an external backward
language model (BLM) for end-to-end automatic speech recognition (ASR). The BLM
has complementary characteristics with a forward language model (FLM), and the
effectiveness of their combination has been confirmed by rescoring ASR
hypotheses as post-processing. In the proposed SF, we iteratively apply the BLM
to partial ASR hypotheses in the backward direction (i.e., from the possible
next token to the start symbol) during decoding, substituting the newly
calculated BLM scores for the scores calculated at the last iteration. To
enhance the effectiveness of this iterative SF (ISF), we train a partial
sentence-aware BLM (PBLM) using reversed text data including partial sentences,
considering the framework of ISF. In experiments using an attention-based
encoder-decoder ASR system, we confirmed that ISF using the PBLM shows
comparable performance with SF using the FLM. By performing ISF, early pruning
of prospective hypotheses can be prevented during decoding, and we can obtain a
performance improvement compared to applying the PBLM as post-processing.
Finally, we confirmed that, by combining SF and ISF, further performance
improvement can be obtained thanks to the complementarity of the FLM and PBLM.
</p>
</p>
</div>

    </div>
    </body>
    