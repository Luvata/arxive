<!DOCTYPE html>
<html>
<head>
<title>2024-01-16-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.06135">A Distributed Neural Linear Thompson Sampling Framework to Achieve URLLC in Industrial IoT. (arXiv:2401.06135v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pase_F/0/1/0/all/0/1">Francesco Pase</a>, <a href="http://arxiv.org/find/cs/1/au:+Giordani_M/0/1/0/all/0/1">Marco Giordani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallero_S/0/1/0/all/0/1">Sara Cavallero</a>, <a href="http://arxiv.org/find/cs/1/au:+Schellmann_M/0/1/0/all/0/1">Malte Schellmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Eichinger_J/0/1/0/all/0/1">Josef Eichinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Verdone_R/0/1/0/all/0/1">Roberto Verdone</a>, <a href="http://arxiv.org/find/cs/1/au:+Zorzi_M/0/1/0/all/0/1">Michele Zorzi</a></p>
<p>Industrial Internet of Things (IIoT) networks will provide Ultra-Reliable
Low-Latency Communication (URLLC) to support critical processes underlying the
production chains. However, standard protocols for allocating wireless
resources may not optimize the latency-reliability trade-off, especially for
uplink communication. For example, centralized grant-based scheduling can
ensure almost zero collisions, but introduces delays in the way resources are
requested by the User Equipments (UEs) and granted by the gNB. In turn,
distributed scheduling (e.g., based on random access), in which UEs
autonomously choose the resources for transmission, may lead to potentially
many collisions especially when the traffic increases. In this work we propose
DIStributed combinatorial NEural linear Thompson Sampling (DISNETS), a novel
scheduling framework that combines the best of the two worlds. By leveraging a
feedback signal from the gNB and reinforcement learning, the UEs are trained to
autonomously optimize their uplink transmissions by selecting the available
resources to minimize the number of collisions, without additional message
exchange to/from the gNB. DISNETS is a distributed, multi-agent adaptation of
the Neural Linear Thompson Sampling (NLTS) algorithm, which has been further
extended to admit multiple parallel actions. We demonstrate the superior
performance of DISNETS in addressing URLLC in IIoT scenarios compared to other
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06137">QuasiNet: a neural network with trainable product layers. (arXiv:2401.06137v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malinovska_K/0/1/0/all/0/1">Krist&#xed;na Malinovsk&#xe1;</a>, <a href="http://arxiv.org/find/cs/1/au:+Holenda_S/0/1/0/all/0/1">Slavom&#xed;r Holenda</a>, <a href="http://arxiv.org/find/cs/1/au:+Malinovsky_L/0/1/0/all/0/1">&#x13d;udov&#xed;t Malinovsk&#xfd;</a></p>
<p>Classical neural networks achieve only limited convergence in hard problems
such as XOR or parity when the number of hidden neurons is small. With the
motivation to improve the success rate of neural networks in these problems, we
propose a new neural network model inspired by existing neural network models
with so called product neurons and a learning rule derived from classical error
backpropagation, which elegantly solves the problem of mutually exclusive
situations. Unlike existing product neurons, which have weights that are preset
and not adaptable, our product layers of neurons also do learn. We tested the
model and compared its success rate to a classical multilayer perceptron in the
aforementioned problems as well as in other hard problems such as the two
spirals. Our results indicate that our model is clearly more successful than
the classical MLP and has the potential to be used in many tasks and
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06139">StockFormer: A Swing Trading Strategy Based on STL Decomposition and Self-Attention Networks. (arXiv:2401.06139v1 [q-fin.TR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Ma_B/0/1/0/all/0/1">Bohan Ma</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_Y/0/1/0/all/0/1">Yiheng Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Lu_Y/0/1/0/all/0/1">Yuchao Lu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Hu_T/0/1/0/all/0/1">Tianzixuan Hu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Xu_J/0/1/0/all/0/1">Jinling Xu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Houlihan_P/0/1/0/all/0/1">Patrick Houlihan</a></p>
<p>Amidst ongoing market recalibration and increasing investor optimism, the
U.S. stock market is experiencing a resurgence, prompting the need for
sophisticated tools to protect and grow portfolios. Addressing this, we
introduce "Stockformer," a cutting-edge deep learning framework optimized for
swing trading, featuring the TopKDropout method for enhanced stock selection.
By integrating STL decomposition and self-attention networks, Stockformer
utilizes the S&amp;P 500's complex data to refine stock return predictions. Our
methodology entailed segmenting data for training and validation (January 2021
to January 2023) and testing (February to June 2023). During testing,
Stockformer's predictions outperformed ten industry models, achieving superior
precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a
remarkable accuracy rate of 62.39% in detecting market trends. In our
backtests, Stockformer's swing trading strategy yielded a cumulative return of
13.19% and an annualized return of 30.80%, significantly surpassing current
state-of-the-art models. Stockformer has emerged as a beacon of innovation in
these volatile times, offering investors a potent tool for market forecasting.
To advance the field and foster community collaboration, we have open-sourced
Stockformer, available at https://github.com/Eric991005/Stockformer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06144">DFU: scale-robust diffusion model for zero-shot super-resolution image generation. (arXiv:2401.06144v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Havrilla_A/0/1/0/all/0/1">Alex Havrilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_K/0/1/0/all/0/1">Kevin Rojas</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wenjing Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1">Molei Tao</a></p>
<p>Diffusion generative models have achieved remarkable success in generating
images with a fixed resolution. However, existing models have limited ability
to generalize to different resolutions when training data at those resolutions
are not available. Leveraging techniques from operator learning, we present a
novel deep-learning architecture, Dual-FNO UNet (DFU), which approximates the
score operator by combining both spatial and spectral information at multiple
resolutions. Comparisons of DFU to baselines demonstrate its scalability: 1)
simultaneously training on multiple resolutions improves FID over training at
any single fixed resolution; 2) DFU generalizes beyond its training
resolutions, allowing for coherent, high-fidelity generation at
higher-resolutions with the same model, i.e. zero-shot super-resolution
image-generation; 3) we propose a fine-tuning strategy to further enhance the
zero-shot super-resolution image-generation capability of our model, leading to
a FID of 11.3 at 1.66 times the maximum training resolution on FFHQ, which no
other method can come close to achieving.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06145">Minuet: Accelerating 3D Sparse Convolutions on GPUs. (arXiv:2401.06145v1 [cs.DC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiacheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannoula_C/0/1/0/all/0/1">Christina Giannoula</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1">Mostafa Elhoushi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleeson_J/0/1/0/all/0/1">James Gleeson</a>, <a href="http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1">Gennady Pekhimenko</a></p>
<p>Sparse Convolution (SC) is widely used for processing 3D point clouds that
are inherently sparse. Different from dense convolution, SC preserves the
sparsity of the input point cloud by only allowing outputs to specific
locations. To efficiently compute SC, prior SC engines first use hash tables to
build a kernel map that stores the necessary General Matrix Multiplication
(GEMM) operations to be executed (Map step), and then use a Gather-GEMM-Scatter
process to execute these GEMM operations (GMaS step). In this work, we analyze
the shortcomings of prior state-of-the-art SC engines, and propose Minuet, a
novel memory-efficient SC engine tailored for modern GPUs. Minuet proposes to
(i) replace the hash tables used in the Map step with a novel segmented sorting
double-traversed binary search algorithm that highly utilizes the on-chip
memory hierarchy of GPUs, (ii) use a lightweight scheme to autotune the tile
size in the Gather and Scatter operations of the GMaS step, such that to adapt
the execution to the particular characteristics of each SC layer, dataset, and
GPU architecture, and (iii) employ a padding-efficient GEMM grouping approach
that reduces both memory padding and kernel launching overheads. Our
evaluations show that Minuet significantly outperforms prior SC engines by on
average $1.74\times$ (up to $2.22\times$) for end-to-end point cloud network
executions. Our novel segmented sorting double-traversed binary search
algorithm achieves superior speedups by $15.8\times$ on average (up to
$26.8\times$) over prior SC engines in the Map step. The source code of Minuet
is publicly available at https://github.com/UofT-EcoSystem/Minuet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06149">Image Classifier Based Generative Method for Planar Antenna Design. (arXiv:2401.06149v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yang Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_W/0/1/0/all/0/1">Weiping Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1">Andrew Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisharat_D/0/1/0/all/0/1">Dia&#x27;a Bisharat</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuandong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qing Huo Liu</a></p>
<p>To extend the antenna design on printed circuit boards (PCBs) for more
engineers of interest, we propose a simple method that models PCB antennas with
a few basic components. By taking two separate steps to decide their geometric
dimensions and positions, antenna prototypes can be facilitated with no
experience required. Random sampling statistics relate to the quality of
dimensions are used in selecting among dimension candidates. A novel
image-based classifier using a convolutional neural network (CNN) is introduced
to further determine the positions of these fixed-dimension components. Two
examples from wearable products have been chosen to examine the entire
workflow. Their final designs are realistic and their performance metrics are
not inferior to the ones designed by experienced engineers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06150">D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation. (arXiv:2401.06150v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mourchid_Y/0/1/0/all/0/1">Youssef Mourchid</a>, <a href="http://arxiv.org/find/eess/1/au:+Slama_R/0/1/0/all/0/1">Rim Slama</a></p>
<p>This paper tackles the challenge of automatically assessing physical
rehabilitation exercises for patients who perform the exercises without
clinician supervision. The objective is to provide a quality score to ensure
correct performance and achieve desired results. To achieve this goal, a new
graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with
Transformer, is introduced. This model combines a modified version of STGCN and
transformer architectures for efficient handling of spatio-temporal data. The
key idea is to consider skeleton data respecting its non-linear structure as a
graph and detecting joints playing the main role in each rehabilitation
exercise. Dense connections and GRU mechanisms are used to rapidly process
large 3D skeleton inputs and effectively model temporal dynamics. The
transformer encoder's attention mechanism focuses on relevant parts of the
input sequence, making it useful for evaluating rehabilitation exercises. The
evaluation of our proposed approach on the KIMORE and UI-PRMD datasets
highlighted its potential, surpassing state-of-the-art methods in terms of
accuracy and computational time. This resulted in faster and more accurate
learning and assessment of rehabilitation exercises. Additionally, our model
provides valuable feedback through qualitative illustrations, effectively
highlighting the significance of joints in specific exercises.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06151">Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes with SE(3)-Discrete Diffusion. (arXiv:2401.06151v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Morehead_A/0/1/0/all/0/1">Alex Morehead</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ruffolo_J/0/1/0/all/0/1">Jeffrey Ruffolo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bhatnagar_A/0/1/0/all/0/1">Aadyot Bhatnagar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Madani_A/0/1/0/all/0/1">Ali Madani</a></p>
<p>Generative models of macromolecules carry abundant and impactful implications
for industrial and biomedical efforts in protein engineering. However, existing
methods are currently limited to modeling protein structures or sequences,
independently or jointly, without regard to the interactions that commonly
occur between proteins and other macromolecules. In this work, we introduce
MMDiff, a generative model that jointly designs sequences and structures of
nucleic acid and protein complexes, independently or in complex, using joint
SE(3)-discrete diffusion noise. Such a model has important implications for
emerging areas of macromolecular design including structure-based transcription
factor design and design of noncoding RNA sequences. We demonstrate the utility
of MMDiff through a rigorous new design benchmark for macromolecular complex
generation that we introduce in this work. Our results demonstrate that MMDiff
is able to successfully generate micro-RNA and single-stranded DNA molecules
while being modestly capable of joint modeling DNA and RNA molecules in
interaction with multi-chain protein complexes. Source code:
https://github.com/Profluent-Internships/MMDiff.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06155">De novo Drug Design using Reinforcement Learning with Multiple GPT Agents. (arXiv:2401.06155v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Hu_X/0/1/0/all/0/1">Xiuyuan Hu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_G/0/1/0/all/0/1">Guoqing Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhao_Y/0/1/0/all/0/1">Yang Zhao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a></p>
<p>De novo drug design is a pivotal issue in pharmacology and a new area of
focus in AI for science research. A central challenge in this field is to
generate molecules with specific properties while also producing a wide range
of diverse candidates. Although advanced technologies such as transformer
models and reinforcement learning have been applied in drug design, their
potential has not been fully realized. Therefore, we propose MolRL-MGPT, a
reinforcement learning algorithm with multiple GPT agents for drug molecular
generation. To promote molecular diversity, we encourage the agents to
collaborate in searching for desirable molecules in diverse directions. Our
algorithm has shown promising results on the GuacaMol benchmark and exhibits
efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes
are available at: https://github.com/HXYfighter/MolRL-MGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06156">A Stochastic Approach to Classification Error Estimates in Convolutional Neural Networks. (arXiv:2401.06156v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peleska_J/0/1/0/all/0/1">Jan Peleska</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruning_F/0/1/0/all/0/1">Felix Br&#xfc;ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleirscher_M/0/1/0/all/0/1">Mario Gleirscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wen-ling Huang</a></p>
<p>This technical report presents research results achieved in the field of
verification of trained Convolutional Neural Network (CNN) used for image
classification in safety-critical applications. As running example, we use the
obstacle detection function needed in future autonomous freight trains with
Grade of Automation (GoA) 4. It is shown that systems like GoA 4 freight trains
are indeed certifiable today with new standards like ANSI/UL 4600 and ISO 21448
used in addition to the long-existing standards EN 50128 and EN 50129.
Moreover, we present a quantitative analysis of the system-level hazard rate to
be expected from an obstacle detection function. It is shown that using
sensor/perceptor fusion, the fused detection system can meet the tolerable
hazard rate deemed to be acceptable for the safety integrity level to be
applied (SIL-3). A mathematical analysis of CNN models is performed which
results in the identification of classification clusters and equivalence
classes partitioning the image input space of the CNN. These clusters and
classes are used to introduce a novel statistical testing method for
determining the residual error probability of a trained CNN and an associated
upper confidence limit. We argue that this greybox approach to CNN
verification, taking into account the CNN model's internal structure, is
essential for justifying that the statistical tests have covered the trained
CNN with its neurons and inter-layer mappings in a comprehensive way.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06159">FRED: Towards a Full Rotation-Equivariance in Aerial Image Object Detection. (arXiv:2401.06159v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chanho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1">Jinsu Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Shon_H/0/1/0/all/0/1">Hyounguk Shon</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1">Yunho Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Junmo Kim</a></p>
<p>Rotation-equivariance is an essential yet challenging property in oriented
object detection. While general object detectors naturally leverage robustness
to spatial shifts due to the translation-equivariance of the conventional CNNs,
achieving rotation-equivariance remains an elusive goal. Current detectors
deploy various alignment techniques to derive rotation-invariant features, but
still rely on high capacity models and heavy data augmentation with all
possible rotations. In this paper, we introduce a Fully Rotation-Equivariant
Oriented Object Detector (FRED), whose entire process from the image to the
bounding box prediction is strictly equivariant. Specifically, we decouple the
invariant task (object classification) and the equivariant task (object
localization) to achieve end-to-end equivariance. We represent the bounding box
as a set of rotation-equivariant vectors to implement rotation-equivariant
localization. Moreover, we utilized these rotation-equivariant vectors as
offsets in the deformable convolution, thereby enhancing the existing
advantages of spatial adaptation. Leveraging full rotation-equivariance, our
FRED demonstrates higher robustness to image-level rotation compared to
existing methods. Furthermore, we show that FRED is one step closer to non-axis
aligned learning through our experiments. Compared to state-of-the-art methods,
our proposed method delivers comparable performance on DOTA-v1.0 and
outperforms by 1.5 mAP on DOTA-v1.5, all while significantly reducing the model
parameters to 16%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06164">Multimodal Gen-AI for Fundamental Investment Research. (arXiv:2401.06164v1 [q-fin.GN])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Li_L/0/1/0/all/0/1">Lezhi Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chang_T/0/1/0/all/0/1">Ting-Yu Chang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_H/0/1/0/all/0/1">Hai Wang</a></p>
<p>This report outlines a transformative initiative in the financial investment
industry, where the conventional decision-making process, laden with
labor-intensive tasks such as sifting through voluminous documents, is being
reimagined. Leveraging language models, our experiments aim to automate
information summarization and investment idea generation. We seek to evaluate
the effectiveness of fine-tuning methods on a base model (Llama2) to achieve
specific application-level goals, including providing insights into the impact
of events on companies and sectors, understanding market condition
relationships, generating investor-aligned investment ideas, and formatting
results with stock recommendations and detailed explanations. Through
state-of-the-art generative modeling techniques, the ultimate objective is to
develop an AI agent prototype, liberating human investors from repetitive tasks
and allowing a focus on high-level strategic thinking. The project encompasses
a diverse corpus dataset, including research reports, investment memos, market
news, and extensive time-series market data. We conducted three experiments
applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat
as the base model, as well as instruction fine-tuning on the GPT3.5 model.
Statistical and human evaluations both show that the fine-tuned versions
perform better in solving text modeling, summarization, reasoning, and finance
domain questions, demonstrating a pivotal step towards enhancing
decision-making processes in the financial domain. Code implementation for the
project can be found on GitHub: https://github.com/Firenze11/finance_lm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06166">Adjustable Molecular Representation for Unified Pre-training Strategy. (arXiv:2401.06166v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Ding_Y/0/1/0/all/0/1">Yan Ding</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ye_Z/0/1/0/all/0/1">Zeliang Ye</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Feng_R/0/1/0/all/0/1">Ruyi Feng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gu_Z/0/1/0/all/0/1">Zhongze Gu</a></p>
<p>We propose a new large-scale molecular model, named AdaMR, which stands for
Adjustable Molecular Representation for Unified Pre-training Strategy. Unlike
recent large-scale molecular models that use a single molecular encoding, AdaMR
employs a granularity-adjustable molecular encoder, learning molecular
representations at both the atomic and substructure levels. For the
pre-training process, we designed a task for molecular canonicalization, which
involves transforming ltiple generic molecular representations into canonical
representations. By adjusting the granularity of molecular encoding, the
trained model can improve the effects on multiple downstream tasks, such as
model attribute prediction and molecule generation. Substructure-level
molecular representation retains information of specific atom groups or
arrangements that determine chemical properties and have similar functions,
which is beneficial for tasks like property prediction. Meanwhile, atomic-level
representation, combined with generative molecular canonicalization
pre-training tasks, enhances the validity, novelty, and uniqueness in
generative tasks. These features of AdaMR demonstrate its strong performance in
numerous downstream tasks. We use different molecular properties prediction
tasks on six different datasets on MoleculeNet and two generative tasks on
ZINC250K dataset to evaluate our proposed molecular encoding and pre-training
methods, and obtain state-of-the-art (SOTA) results on five of these tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06169">Deep Learning model predicts the c-Kit-11 mutational status of canine cutaneous mast cell tumors by HE stained histological slides. (arXiv:2401.06169v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Puget_C/0/1/0/all/0/1">Chlo&#xe9; Puget</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ganz_J/0/1/0/all/0/1">Jonathan Ganz</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ostermaier_J/0/1/0/all/0/1">Julian Ostermaier</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Konrad_T/0/1/0/all/0/1">Thomas Konrad</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Parlak_E/0/1/0/all/0/1">Eda Parlak</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bertram_C/0/1/0/all/0/1">Christof Albert Bertram</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kiupel_M/0/1/0/all/0/1">Matti Kiupel</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Breininger_K/0/1/0/all/0/1">Katharina Breininger</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Aubreville_M/0/1/0/all/0/1">Marc Aubreville</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Klopfleisch_R/0/1/0/all/0/1">Robert Klopfleisch</a></p>
<p>Numerous prognostic factors are currently assessed histopathologically in
biopsies of canine mast cell tumors to evaluate clinical behavior. In addition,
PCR analysis of the c-Kit exon 11 mutational status is often performed to
evaluate the potential success of a tyrosine kinase inhibitor therapy. This
project aimed at training deep learning models (DLMs) to identify the c-Kit-11
mutational status of MCTs solely based on morphology without additional
molecular analysis. HE slides of 195 mutated and 173 non-mutated tumors were
stained consecutively in two different laboratories and scanned with three
different slide scanners. This resulted in six different datasets
(stain-scanner variations) of whole slide images. DLMs were trained with single
and mixed datasets and their performances was assessed under scanner and
staining domain shifts. The DLMs correctly classified HE slides according to
their c-Kit 11 mutation status in, on average, 87% of cases for the best-suited
stain-scanner variant. A relevant performance drop could be observed when the
stain-scanner combination of the training and test dataset differed.
Multi-variant datasets improved the average accuracy but did not reach the
maximum accuracy of algorithms trained and tested on the same stain-scanner
variant. In summary, DLM-assisted morphological examination of MCTs can predict
c-Kit-exon 11 mutational status of MCTs with high accuracy. However, the
recognition performance is impeded by a change of scanner or staining protocol.
Larger data sets with higher numbers of scans originating from different
laboratories and scanners may lead to more robust DLMs to identify c-Kit
mutations in HE slides.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06172">CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods. (arXiv:2401.06172v1 [q-fin.ST])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Chen_Y/0/1/0/all/0/1">Yue Chen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Andrew_X/0/1/0/all/0/1">Xingyi Andrew</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Supasanya_S/0/1/0/all/0/1">Salintip Supasanya</a></p>
<p>Historically, the economic recession often came abruptly and disastrously.
For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from
October 2007 to March 2009. If we could detect the signals of the crisis
earlier, we could have taken preventive measures. Therefore, driven by such
motivation, we use advanced machine learning techniques, including Random
Forest and Extreme Gradient Boosting, to predict any potential market crashes
mainly in the US market. Also, we would like to compare the performance of
these methods and examine which model is better for forecasting US stock market
crashes. We apply our models on the daily financial market data, which tend to
be more responsive with higher reporting frequencies. We consider 75
explanatory variables, including general US stock market indexes, SP 500 sector
indexes, as well as market indicators that can be used for the purpose of
crisis prediction. Finally, we conclude, with selected classification metrics,
that the Extreme Gradient Boosting method performs the best in predicting US
stock market crisis events.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06173">Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization. (arXiv:2401.06173v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Qiu_J/0/1/0/all/0/1">Jiahao Qiu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yuan_H/0/1/0/all/0/1">Hui Yuan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_J/0/1/0/all/0/1">Jinghong Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_W/0/1/0/all/0/1">Wentao Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_H/0/1/0/all/0/1">Huazheng Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_M/0/1/0/all/0/1">Mengdi Wang</a></p>
<p>While modern biotechnologies allow synthesizing new proteins and function
measurements at scale, efficiently exploring a protein sequence space and
engineering it remains a daunting task due to the vast sequence space of any
given protein. Protein engineering is typically conducted through an iterative
process of adding mutations to the wild-type or lead sequences, recombination
of mutations, and running new rounds of screening. To enhance the efficiency of
such a process, we propose a tree search-based bandit learning method, which
expands a tree starting from the initial sequence with the guidance of a bandit
machine learning model. Under simplified assumptions and a Gaussian Process
prior, we provide theoretical analysis and a Bayesian regret bound,
demonstrating that the combination of local search and bandit learning method
can efficiently discover a near-optimal design. The full algorithm is
compatible with a suite of randomized tree search heuristics, machine learning
models, pre-trained embeddings, and bandit techniques. We test various
instances of the algorithm across benchmark protein datasets using simulated
screens. Experiment results demonstrate that the algorithm is both
sample-efficient and able to find top designs using reasonably small mutation
counts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06174">Machine Learning Applications in Spine Biomechanics. (arXiv:2401.06174v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ghezelbash_F/0/1/0/all/0/1">Farshid Ghezelbash</a>, <a href="http://arxiv.org/find/eess/1/au:+Eskandari_A/0/1/0/all/0/1">Amir Hossein Eskandari</a>, <a href="http://arxiv.org/find/eess/1/au:+Robert_Lachaine_X/0/1/0/all/0/1">Xavier Robert-Lachaine</a>, <a href="http://arxiv.org/find/eess/1/au:+Cao_F/0/1/0/all/0/1">Frank Cao</a>, <a href="http://arxiv.org/find/eess/1/au:+Pesteie_M/0/1/0/all/0/1">Mehran Pesteie</a>, <a href="http://arxiv.org/find/eess/1/au:+Qiao_Z/0/1/0/all/0/1">Zhuohua Qiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Shirazi_Adl_A/0/1/0/all/0/1">Aboulfazl Shirazi-Adl</a>, <a href="http://arxiv.org/find/eess/1/au:+Lariviere_C/0/1/0/all/0/1">Christian Larivi&#xe8;re</a></p>
<p>Spine biomechanics is at a transformation with the advent and integration of
machine learning and computer vision technologies. These novel techniques
facilitate the estimation of 3D body shapes, anthropometrics, and kinematics
from as simple as a single-camera image, making them more accessible and
practical for a diverse range of applications. This study introduces a
framework that merges these methodologies with traditional musculoskeletal
modeling, enabling comprehensive analysis of spinal biomechanics during complex
activities from a single camera. Additionally, we aim to evaluate their
performance and limitations in spine biomechanics applications. The real-world
applications explored in this study include assessment in workplace lifting,
evaluation of whiplash injuries in car accidents, and biomechanical analysis in
professional sports. Our results demonstrate potential and limitations of
various algorithms in estimating body shape, kinematics, and conducting
in-field biomechanical analyses. In industrial settings, the potential to
utilize these new technologies for biomechanical risk assessments offers a
pathway for preventive measures against back injuries. In sports activities,
the proposed framework provides new opportunities for performance optimization,
injury prevention, and rehabilitation. The application in forensic domain
further underscores the wide-reaching implications of this technology. While
certain limitations were identified, particularly in accuracy of predictions,
complex interactions, and external load estimation, this study demonstrates
their potential for advancement in spine biomechanics, heralding an optimistic
future in both research and practical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06175">MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly Detection. (arXiv:2401.06175v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_W/0/1/0/all/0/1">Wenwei Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhuangbin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yichen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yuxin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael R. Lyu</a></p>
<p>Key Performance Indicators (KPIs) are essential time-series metrics for
ensuring the reliability and stability of many software systems. They
faithfully record runtime states to facilitate the understanding of anomalous
system behaviors and provide informative clues for engineers to pinpoint the
root causes. The unprecedented scale and complexity of modern software systems,
however, make the volume of KPIs explode. Consequently, many traditional
methods of KPI anomaly detection become impractical, which serves as a catalyst
for the fast development of machine learning-based solutions in both academia
and industry. However, there is currently a lack of rigorous comparison among
these KPI anomaly detection methods, and re-implementation demands a
non-trivial effort. Moreover, we observe that different works adopt independent
evaluation processes with different metrics. Some of them may not fully reveal
the capability of a model and some are creating an illusion of progress. To
better understand the characteristics of different KPI anomaly detectors and
address the evaluation issue, in this paper, we provide a comprehensive review
and evaluation of twelve state-of-the-art methods, and propose a novel metric
called salience. Particularly, the selected methods include five traditional
machine learning-based methods and seven deep learning-based methods. These
methods are evaluated with five multivariate KPI datasets that are publicly
available. A unified toolkit with easy-to-use interfaces is also released. We
report the benchmark results in terms of accuracy, salience, efficiency, and
delay, which are of practical importance for industrial deployment. We believe
our work can contribute as a basis for future academic research and industrial
application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06176">GOODAT: Towards Test-time Graph Out-of-Distribution Detection. (arXiv:2401.06176v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Luzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongxiao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">He Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Di Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a></p>
<p>Graph neural networks (GNNs) have found widespread application in modeling
graph data across diverse domains. While GNNs excel in scenarios where the
testing data shares the distribution of their training counterparts (in
distribution, ID), they often exhibit incorrect predictions when confronted
with samples from an unfamiliar distribution (out-of-distribution, OOD). To
identify and reject OOD samples with GNNs, recent studies have explored graph
OOD detection, often focusing on training a specific model or modifying the
data on top of a well-trained GNN. Despite their effectiveness, these methods
come with heavy training resources and costs, as they need to optimize the
GNN-based models on training data. Moreover, their reliance on modifying the
original GNNs and accessing training data further restricts their universality.
To this end, this paper introduces a method to detect Graph Out-of-Distribution
At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play
solution that operates independently of training data and modifications of GNN
architecture. With a lightweight graph masker, GOODAT can learn informative
subgraphs from test samples, enabling the capture of distinct graph patterns
between OOD and ID samples. To optimize the graph masker, we meticulously
design three unsupervised objective functions based on the graph information
bottleneck principle, motivating the masker to capture compact yet informative
subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT
method outperforms state-of-the-art benchmarks across a variety of real-world
datasets. The code is available at Github: https://github.com/Ee1s/GOODAT
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06179">CNN-DRL for Scalable Actions in Finance. (arXiv:2401.06179v1 [q-fin.ST])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Montazeri_S/0/1/0/all/0/1">Sina Montazeri</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mirzaeinia_A/0/1/0/all/0/1">Akram Mirzaeinia</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Jumakhan_H/0/1/0/all/0/1">Haseebullah Jumakhan</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mirzaeinia_A/0/1/0/all/0/1">Amir Mirzaeinia</a></p>
<p>The published MLP-based DRL in finance has difficulties in learning the
dynamics of the environment when the action scale increases. If the buying and
selling increase to one thousand shares, the MLP agent will not be able to
effectively adapt to the environment. To address this, we designed a CNN agent
that concatenates the data from the last ninety days of the daily feature
vector to create the CNN input matrix. Our extensive experiments demonstrate
that the MLP-based agent experiences a loss corresponding to the initial
environment setup, while our designed CNN remains stable, effectively learns
the environment, and leads to an increase in rewards.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06180">Decentralized Gossip Mutual Learning (GML) for automatic head and neck tumor segmentation. (arXiv:2401.06180v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Jingyun Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_Y/0/1/0/all/0/1">Yading Yuan</a></p>
<p>Federated learning (FL) has emerged as a promising strategy for
collaboratively training complicated machine learning models from different
medical centers without the need of data sharing. However, the traditional FL
relies on a central server to orchestrate the global model training among
clients. This makes it vulnerable to the failure of the model server.
Meanwhile, the model trained based on the global data property may not yield
the best performance on the local data of a particular site due to the
variations of data characteristics among them. To address these limitations, we
proposed Gossip Mutual Learning(GML), a decentralized collaborative learning
framework that employs Gossip Protocol for direct peer-to-peer communication
and encourages each site to optimize its local model by leveraging useful
information from peers through mutual learning. On the task of tumor
segmentation on PET/CT images using HECKTOR21 dataset with 223 cases from five
clinical sites, we demonstrated GML could improve tumor segmentation
performance in terms of Dice Similarity Coefficient (DSC) by 3.2%, 4.6% and
10.4% on site-specific testing cases as compared to three baseline methods:
pooled training, FedAvg and individual training, respectively. We also showed
GML has comparable generalization performance as pooled training and FedAvg
when applying them on 78 cases from two out-of-sample sites where no case was
used for model training. In our experimental setup, GML showcased a sixfold
decrease in communication overhead compared to FedAvg, requiring only 16.67% of
the total communication overhead.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06182">Prediction of Cellular Identities from Trajectory and Cell Fate Information. (arXiv:2401.06182v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Dai_B/0/1/0/all/0/1">Baiyang Dai</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_J/0/1/0/all/0/1">Jiamin Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shroff_H/0/1/0/all/0/1">Hari Shroff</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Riviere_P/0/1/0/all/0/1">Patrick La Riviere</a></p>
<p>Determining cell identities in imaging sequences is an important yet
challenging task. The conventional method for cell identification is via cell
tracking, which is complex and can be time-consuming. In this study, we propose
an innovative approach to cell identification during early C. elegans
embryogenesis using machine learning. We employed random forest, MLP, and LSTM
models, and tested cell classification accuracy on 3D time-lapse confocal
datasets spanning the first 4 hours of embryogenesis. By leveraging a small
number of spatial-temporal features of individual cells, including cell
trajectory and cell fate information, our models achieve an accuracy of over
90%, even with limited data. We also determine the most important feature
contributions and can interpret these features in the context of biological
knowledge. Our research demonstrates the success of predicting cell identities
in 4D imaging sequences directly from simple spatio-temporal features.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06183">End to end Hindi to English speech conversion using Bark, mBART and a finetuned XLSR Wav2Vec2. (arXiv:2401.06183v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Tathe_A/0/1/0/all/0/1">Aniket Tathe</a>, <a href="http://arxiv.org/find/eess/1/au:+Kamble_A/0/1/0/all/0/1">Anand Kamble</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumbharkar_S/0/1/0/all/0/1">Suyash Kumbharkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Bhandare_A/0/1/0/all/0/1">Atharva Bhandare</a>, <a href="http://arxiv.org/find/eess/1/au:+Mitra_A/0/1/0/all/0/1">Anirban C. Mitra</a></p>
<p>Speech has long been a barrier to effective communication and connection,
persisting as a challenge in our increasingly interconnected world. This
research paper introduces a transformative solution to this persistent obstacle
an end-to-end speech conversion framework tailored for Hindi-to-English
translation, culminating in the synthesis of English audio. By integrating
cutting-edge technologies such as XLSR Wav2Vec2 for automatic speech
recognition (ASR), mBART for neural machine translation (NMT), and a
Text-to-Speech (TTS) synthesis component, this framework offers a unified and
seamless approach to cross-lingual communication. We delve into the intricate
details of each component, elucidating their individual contributions and
exploring the synergies that enable a fluid transition from spoken Hindi to
synthesized English audio.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06187">Scissorhands: Scrub Data Influence via Connection Sensitivity in Networks. (arXiv:2401.06187v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Harandi_M/0/1/0/all/0/1">Mehrtash Harandi</a></p>
<p>Machine unlearning has become a pivotal task to erase the influence of data
from a trained model. It adheres to recent data regulation standards and
enhances the privacy and security of machine learning applications. Most
existing machine unlearning methods perform well, however, they typically
necessitate access to the entirety of the remaining data, which might not be
feasible in certain scenarios. In this work, we present a new machine
unlearning approach Scissorhands, which operates effectively with only a subset
of the training data. Initially, Scissorhands identifies the most pertinent
parameters in the given model relative to the forgetting data via connection
sensitivity. This process involves reinitializing the most influential top-$k$
percent of these parameters, resulting in a trimmed model for erasing the
influence of the forgetting data. Subsequently, Scissorhands retrains the
trimmed model through a min-max optimization process, seeking parameters that
preserve information on the remaining data while discarding information related
to the forgetting data. Our experimental results, conducted across five
distinct datasets and utilizing both CNN and ViT, demonstrate that
Scissorhands, despite utilizing only a limited portion of the training data,
showcases competitive performance when compared to existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06194">CrisisKAN: Knowledge-infused and Explainable Multimodal Attention Network for Crisis Event Classification. (arXiv:2401.06194v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Shubham Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Saini_N/0/1/0/all/0/1">Nandini Saini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1">Suman Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1">Debasis Das</a></p>
<p>Pervasive use of social media has become the emerging source for real-time
information (like images, text, or both) to identify various events. Despite
the rapid growth of image and text-based event classification, the
state-of-the-art (SOTA) models find it challenging to bridge the semantic gap
between features of image and text modalities due to inconsistent encoding.
Also, the black-box nature of models fails to explain the model's outcomes for
building trust in high-stakes situations such as disasters, pandemic.
Additionally, the word limit imposed on social media posts can potentially
introduce bias towards specific events. To address these issues, we proposed
CrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention
Network that entails images and texts in conjunction with external knowledge
from Wikipedia to classify crisis events. To enrich the context-specific
understanding of textual information, we integrated Wikipedia knowledge using
proposed wiki extraction algorithm. Along with this, a guided cross-attention
module is implemented to fill the semantic gap in integrating visual and
textual data. In order to ensure reliability, we employ a model-specific
approach called Gradient-weighted Class Activation Mapping (Grad-CAM) that
provides a robust explanation of the predictions of the proposed model. The
comprehensive experiments conducted on the CrisisMMD dataset yield in-depth
analysis across various crisis-specific tasks and settings. As a result,
CrisisKAN outperforms existing SOTA methodologies and provides a novel view in
the domain of explainable multimodal event classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06195">NeuSpin: Design of a Reliable Edge Neuromorphic System Based on Spintronics for Green AI. (arXiv:2401.06195v1 [cs.ET])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Soyed Tuhin Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Danouchi_K/0/1/0/all/0/1">Kamal Danouchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Prenat_G/0/1/0/all/0/1">Guillaume Prenat</a>, <a href="http://arxiv.org/find/cs/1/au:+Anghel_L/0/1/0/all/0/1">Lorena Anghel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tahoori_M/0/1/0/all/0/1">Mehdi B. Tahoori</a></p>
<p>Internet of Things (IoT) and smart wearable devices for personalized
healthcare will require storing and computing ever-increasing amounts of data.
The key requirements for these devices are ultra-low-power, high-processing
capabilities, autonomy at low cost, as well as reliability and accuracy to
enable Green AI at the edge. Artificial Intelligence (AI) models, especially
Bayesian Neural Networks (BayNNs) are resource-intensive and face challenges
with traditional computing architectures due to the memory wall problem.
Computing-in-Memory (CIM) with emerging resistive memories offers a solution by
combining memory blocks and computing units for higher efficiency and lower
power consumption. However, implementing BayNNs on CIM hardware, particularly
with spintronic technologies, presents technical challenges due to variability
and manufacturing defects. The NeuSPIN project aims to address these challenges
through full-stack hardware and software co-design, developing novel
algorithmic and circuit design approaches to enhance the performance,
energy-efficiency and robustness of BayNNs on sprintronic-based CIM platforms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06199">xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein. (arXiv:2401.06199v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cheng_X/0/1/0/all/0/1">Xingyi Cheng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Geng_Y/0/1/0/all/0/1">Yangli-ao Geng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gong_J/0/1/0/all/0/1">Jing Gong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1">Shen Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bei_Z/0/1/0/all/0/1">Zhilei Bei</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_B/0/1/0/all/0/1">Boyan Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zeng_X/0/1/0/all/0/1">Xin Zeng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_C/0/1/0/all/0/1">Chiming Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zeng_A/0/1/0/all/0/1">Aohan Zeng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Song_L/0/1/0/all/0/1">Le Song</a></p>
<p>Protein language models have shown remarkable success in learning biological
information from protein sequences. However, most existing models are limited
by either autoencoding or autoregressive pre-training objectives, which makes
them struggle to handle protein understanding and generation tasks
concurrently. We propose a unified protein language model, xTrimoPGLM, to
address these two types of tasks simultaneously through an innovative
pre-training framework. Our key technical contribution is an exploration of the
compatibility and the potential for joint optimization of the two types of
objectives, which has led to a strategy for training xTrimoPGLM at an
unprecedented scale of 100 billion parameters and 1 trillion training tokens.
Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms
other advanced baselines in 18 protein understanding benchmarks across four
categories. The model also facilitates an atomic-resolution view of protein
structures, leading to an advanced 3D structural prediction model that
surpasses existing language model-based tools. 2) xTrimoPGLM not only can
generate de novo protein sequences following the principles of natural ones,
but also can perform programmable generation after supervised fine-tuning (SFT)
on curated sequences. These results highlight the substantial capability and
versatility of xTrimoPGLM in understanding and generating protein sequences,
contributing to the evolving landscape of foundation models in protein science.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06203">Remixing Music for Hearing Aids Using Ensemble of Fine-Tuned Source Separators. (arXiv:2401.06203v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Daly_M/0/1/0/all/0/1">Matthew Daly</a></p>
<p>This paper introduces our system submission for the Cadenza ICASSP 2024 Grand
Challenge, which presents the problem of remixing and enhancing music for
hearing aid users. Our system placed first in the challenge, achieving the best
average Hearing-Aid Audio Quality Index (HAAQI) score on the evaluation data
set. We describe the system, which uses an ensemble of deep learning music
source separators that are fine tuned on the challenge data. We demonstrate the
effectiveness of our system through the challenge results and analyze the
importance of different system aspects through ablation studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06204">An Exploratory Assessment of LLM&#x27;s Potential Toward Flight Trajectory Reconstruction Analysis. (arXiv:2401.06204v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mott_J/0/1/0/all/0/1">John H. Mott</a></p>
<p>Large Language Models (LLMs) hold transformative potential in aviation,
particularly in reconstructing flight trajectories. This paper investigates
this potential, grounded in the notion that LLMs excel at processing sequential
data and deciphering complex data structures. Utilizing the LLaMA 2 model, a
pre-trained open-source LLM, the study focuses on reconstructing flight
trajectories using Automatic Dependent Surveillance-Broadcast (ADS-B) data with
irregularities inherent in real-world scenarios. The findings demonstrate the
model's proficiency in filtering noise and estimating both linear and curved
flight trajectories. However, the analysis also reveals challenges in managing
longer data sequences, which may be attributed to the token length limitations
of LLM models. The study's insights underscore the promise of LLMs in flight
trajectory reconstruction and open new avenues for their broader application
across the aviation and transportation sectors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06210">Learning Unsupervised Semantic Document Representation for Fine-grained Aspect-based Sentiment Analysis. (arXiv:2401.06210v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Hao-Ming Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pu-Jen Cheng</a></p>
<p>Document representation is the core of many NLP tasks on machine
understanding. A general representation learned in an unsupervised manner
reserves generality and can be used for various applications. In practice,
sentiment analysis (SA) has been a challenging task that is regarded to be
deeply semantic-related and is often used to assess general representations.
Existing methods on unsupervised document representation learning can be
separated into two families: sequential ones, which explicitly take the
ordering of words into consideration, and non-sequential ones, which do not
explicitly do so. However, both of them suffer from their own weaknesses. In
this paper, we propose a model that overcomes difficulties encountered by both
families of methods. Experiments show that our model outperforms
state-of-the-art methods on popular SA datasets and a fine-grained aspect-based
SA by a large margin.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06224">Leveraging Frequency Domain Learning in 3D Vessel Segmentation. (arXiv:2401.06224v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xinyuan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Pan_C/0/1/0/all/0/1">Chengwei Pan</a>, <a href="http://arxiv.org/find/eess/1/au:+Dai_H/0/1/0/all/0/1">Hongming Dai</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_G/0/1/0/all/0/1">Gangming Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jinpeng Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_Y/0/1/0/all/0/1">Yizhou Yu</a></p>
<p>Coronary microvascular disease constitutes a substantial risk to human
health. Employing computer-aided analysis and diagnostic systems, medical
professionals can intervene early in disease progression, with 3D vessel
segmentation serving as a crucial component. Nevertheless, conventional U-Net
architectures tend to yield incoherent and imprecise segmentation outcomes,
particularly for small vessel structures. While models with attention
mechanisms, such as Transformers and large convolutional kernels, demonstrate
superior performance, their extensive computational demands during training and
inference lead to increased time complexity. In this study, we leverage Fourier
domain learning as a substitute for multi-scale convolutional kernels in 3D
hierarchical segmentation models, which can reduce computational expenses while
preserving global receptive fields within the network. Furthermore, a
zero-parameter frequency domain fusion method is designed to improve the skip
connections in U-Net architecture. Experimental results on a public dataset and
an in-house dataset indicate that our novel Fourier transformation-based
network achieves remarkable dice performance (84.37\% on ASACA500 and 80.32\%
on ImageCAS) in tubular vessel segmentation tasks and substantially reduces
computational requirements without compromising global receptive fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06230">WISE: full-Waveform variational Inference via Subsurface Extensions. (arXiv:2401.06230v1 [physics.geo-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Yin_Z/0/1/0/all/0/1">Ziyi Yin</a>, <a href="http://arxiv.org/find/physics/1/au:+Orozco_R/0/1/0/all/0/1">Rafael Orozco</a>, <a href="http://arxiv.org/find/physics/1/au:+Louboutin_M/0/1/0/all/0/1">Mathias Louboutin</a>, <a href="http://arxiv.org/find/physics/1/au:+Herrmann_F/0/1/0/all/0/1">Felix J. Herrmann</a></p>
<p>We introduce a probabilistic technique for full-waveform inversion, employing
variational inference and conditional normalizing flows to quantify uncertainty
in migration-velocity models and its impact on imaging. Our approach integrates
generative artificial intelligence with physics-informed common-image gathers,
reducing reliance on accurate initial velocity models. Considered case studies
demonstrate its efficacy producing realizations of migration-velocity models
conditioned by the data. These models are used to quantify amplitude and
positioning effects during subsequent imaging.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06251">Semantic-Preserving Feature Partitioning for Multi-View Ensemble Learning. (arXiv:2401.06251v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khorshidi_M/0/1/0/all/0/1">Mohammad Sadegh Khorshidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yazdanjue_N/0/1/0/all/0/1">Navid Yazdanjue</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharoun_H/0/1/0/all/0/1">Hassan Gharoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yazdani_D/0/1/0/all/0/1">Danial Yazdani</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikoo_M/0/1/0/all/0/1">Mohammad Reza Nikoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandomi_A/0/1/0/all/0/1">Amir H. Gandomi</a></p>
<p>In machine learning, the exponential growth of data and the associated
``curse of dimensionality'' pose significant challenges, particularly with
expansive yet sparse datasets. Addressing these challenges, multi-view ensemble
learning (MEL) has emerged as a transformative approach, with feature
partitioning (FP) playing a pivotal role in constructing artificial views for
MEL. Our study introduces the Semantic-Preserving Feature Partitioning (SPFP)
algorithm, a novel method grounded in information theory. The SPFP algorithm
effectively partitions datasets into multiple semantically consistent views,
enhancing the MEL process. Through extensive experiments on eight real-world
datasets, ranging from high-dimensional with limited instances to
low-dimensional with high instances, our method demonstrates notable efficacy.
It maintains model accuracy while significantly improving uncertainty measures
in scenarios where high generalization performance is achievable. Conversely,
it retains uncertainty metrics while enhancing accuracy where high
generalization accuracy is less attainable. An effect size analysis further
reveals that the SPFP algorithm outperforms benchmark models by large effect
size and reduces computational demands through effective dimensionality
reduction. The substantial effect sizes observed in most experiments underscore
the algorithm's significant improvements in model performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06252">AGSPNet: A framework for parcel-scale crop fine-grained semantic change detection from UAV high-resolution imagery with agricultural geographic scene constraints. (arXiv:2401.06252v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaochun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanjun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hengfan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lina Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yunhao Lin</a></p>
<p>Real-time and accurate information on fine-grained changes in crop
cultivation is of great significance for crop growth monitoring, yield
prediction and agricultural structure adjustment. Aiming at the problems of
serious spectral confusion in visible high-resolution unmanned aerial vehicle
(UAV) images of different phases, interference of large complex background and
salt-and-pepper noise by existing semantic change detection (SCD) algorithms,
in order to effectively extract deep image features of crops and meet the
demand of agricultural practical engineering applications, this paper designs
and proposes an agricultural geographic scene and parcel-scale constrained SCD
framework for crops (AGSPNet). AGSPNet framework contains three parts:
agricultural geographic scene (AGS) division module, parcel edge extraction
module and crop SCD module. Meanwhile, we produce and introduce an UAV image
SCD dataset (CSCD) dedicated to agricultural monitoring, encompassing multiple
semantic variation types of crops in complex geographical scene. We conduct
comparative experiments and accuracy evaluations in two test areas of this
dataset, and the results show that the crop SCD results of AGSPNet consistently
outperform other deep learning SCD models in terms of quantity and quality,
with the evaluation metrics F1-score, kappa, OA, and mIoU obtaining
improvements of 0.038, 0.021, 0.011 and 0.062, respectively, on average over
the sub-optimal method. The method proposed in this paper can clearly detect
the fine-grained change information of crop types in complex scenes, which can
provide scientific and technical support for smart agriculture monitoring and
management, food policy formulation and food security assurance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06263">FedTabDiff: Federated Learning of Diffusion Probabilistic Models for Synthetic Mixed-Type Tabular Data Generation. (arXiv:2401.06263v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sattarov_T/0/1/0/all/0/1">Timur Sattarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Schreyer_M/0/1/0/all/0/1">Marco Schreyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1">Damian Borth</a></p>
<p>Realistic synthetic tabular data generation encounters significant challenges
in preserving privacy, especially when dealing with sensitive information in
domains like finance and healthcare. In this paper, we introduce
\textit{Federated Tabular Diffusion} (FedTabDiff) for generating high-fidelity
mixed-type tabular data without centralized access to the original tabular
datasets. Leveraging the strengths of \textit{Denoising Diffusion Probabilistic
Models} (DDPMs), our approach addresses the inherent complexities in tabular
data, such as mixed attribute types and implicit relationships. More
critically, FedTabDiff realizes a decentralized learning scheme that permits
multiple entities to collaboratively train a generative model while respecting
data privacy and locality. We extend DDPMs into the federated setting for
tabular data generation, which includes a synchronous update scheme and
weighted averaging for effective model aggregation. Experimental evaluations on
real-world financial and medical datasets attest to the framework's capability
to produce synthetic data that maintains high fidelity, utility, privacy, and
coverage.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06273">Qrlew: Rewriting SQL into Differentially Private SQL. (arXiv:2401.06273v1 [cs.DB])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Grislain_N/0/1/0/all/0/1">Nicolas Grislain</a>, <a href="http://arxiv.org/find/cs/1/au:+Roussel_P/0/1/0/all/0/1">Paul Roussel</a>, <a href="http://arxiv.org/find/cs/1/au:+Agathe_V/0/1/0/all/0/1">Victoria de Sainte Agathe</a></p>
<p>This paper introduces Qrlew, an open source library that can parse SQL
queries into Relations -- an intermediate representation -- that keeps track of
rich data types, value ranges, and row ownership; so that they can easily be
rewritten into differentially-private equivalent and turned back into SQL
queries for execution in a variety of standard data stores.
</p>
<p>With Qrlew, a data practitioner can express their data queries in standard
SQL; the data owner can run the rewritten query without any technical
integration and with strong privacy guarantees on the output; and the query
rewriting can be operated by a privacy-expert who must be trusted by the owner,
but may belong to a separate organization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06278">A Study on Self-Supervised Pretraining for Vision Problems in Gastrointestinal Endoscopy. (arXiv:2401.06278v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sanderson_E/0/1/0/all/0/1">Edward Sanderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Matuszewski_B/0/1/0/all/0/1">Bogdan J. Matuszewski</a></p>
<p>Solutions to vision tasks in gastrointestinal endoscopy (GIE) conventionally
use image encoders pretrained in a supervised manner with ImageNet-1k as
backbones. However, the use of modern self-supervised pretraining algorithms
and a recent dataset of 100k unlabelled GIE images (Hyperkvasir-unlabelled) may
allow for improvements. In this work, we study the fine-tuned performance of
models with ResNet50 and ViT-B backbones pretrained in self-supervised and
supervised manners with ImageNet-1k and Hyperkvasir-unlabelled (self-supervised
only) in a range of GIE vision tasks. In addition to identifying the most
suitable pretraining pipeline and backbone architecture for each task, out of
those considered, our results suggest: that self-supervised pretraining
generally produces more suitable backbones for GIE vision tasks than supervised
pretraining; that self-supervised pretraining with ImageNet-1k is typically
more suitable than pretraining with Hyperkvasir-unlabelled, with the notable
exception of monocular depth estimation in colonoscopy; and that ViT-Bs are
more suitable in polyp segmentation and monocular depth estimation in
colonoscopy, ResNet50s are more suitable in polyp detection, and both
architectures perform similarly in anatomical landmark recognition and
pathological finding characterisation. We hope this work draws attention to the
complexity of pretraining for GIE vision tasks, informs this development of
more suitable approaches than the convention, and inspires further research on
this topic to help advance this development. Code available:
\underline{github.com/ESandML/SSL4GIE}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06279">Sampling and Uniqueness Sets in Graphon Signal Processing. (arXiv:2401.06279v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Parada_Mayorga_A/0/1/0/all/0/1">Alejandro Parada-Mayorga</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a></p>
<p>In this work, we study the properties of sampling sets on families of large
graphs by leveraging the theory of graphons and graph limits. To this end, we
extend to graphon signals the notion of removable and uniqueness sets, which
was developed originally for the analysis of signals on graphs. We state the
formal definition of a $\Lambda-$removable set and conditions under which a
bandlimited graphon signal can be represented in a unique way when its samples
are obtained from the complement of a given $\Lambda-$removable set in the
graphon. By leveraging such results we show that graphon representations of
graphs and graph signals can be used as a common framework to compare sampling
sets between graphs with different numbers of nodes and edges, and different
node labelings. Additionally, given a sequence of graphs that converges to a
graphon, we show that the sequences of sampling sets whose graphon
representation is identical in $[0,1]$ are convergent as well. We exploit the
convergence results to provide an algorithm that obtains approximately close to
optimal sampling sets. Performing a set of numerical experiments, we evaluate
the quality of these sampling sets. Our results open the door for the efficient
computation of optimal sampling sets in graphs of large size.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06281">Demystifying Variational Diffusion Models. (arXiv:2401.06281v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_F/0/1/0/all/0/1">Fabio De Sousa Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a></p>
<p>Despite the growing popularity of diffusion models, gaining a deep
understanding of the model class remains somewhat elusive for the uninitiated
in non-equilibrium statistical physics. With that in mind, we present what we
believe is a more straightforward introduction to diffusion models using
directed graphical modelling and variational Bayesian principles, which imposes
relatively fewer prerequisites on the average reader. Our exposition
constitutes a comprehensive technical review spanning from foundational
concepts like deep latent variable models to recent advances in continuous-time
diffusion-based modelling, highlighting theoretical connections between model
classes along the way. We provide additional mathematical insights that were
omitted in the seminal works whenever possible to aid in understanding, while
avoiding the introduction of new notation. We envision this article serving as
a useful educational supplement for both researchers and practitioners in the
area, and we welcome feedback and contributions from the community at
https://github.com/biomedia-mira/demystifying-diffusion.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06300">Advantage of Quantum Neural Networks as Quantum Information Decoders. (arXiv:2401.06300v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Zhong_W/0/1/0/all/0/1">Weishun Zhong</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Shtanko_O/0/1/0/all/0/1">Oles Shtanko</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Movassagh_R/0/1/0/all/0/1">Ramis Movassagh</a></p>
<p>A promising strategy to protect quantum information from noise-induced errors
is to encode it into the low-energy states of a topological quantum memory
device. However, readout errors from such memory under realistic settings is
less understood. We study the problem of decoding quantum information encoded
in the groundspaces of topological stabilizer Hamiltonians in the presence of
generic perturbations, such as quenched disorder. We first prove that the
standard stabilizer-based error correction and decoding schemes work adequately
well in such perturbed quantum codes by showing that the decoding error
diminishes exponentially in the distance of the underlying unperturbed code. We
then prove that Quantum Neural Network (QNN) decoders provide an almost
quadratic improvement on the readout error. Thus, we demonstrate provable
advantage of using QNNs for decoding realistic quantum error-correcting codes,
and our result enables the exploration of a wider range of non-stabilizer codes
in the near-term laboratory settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06308">A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic 6G-Based Applications. (arXiv:2401.06308v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mazandarani_H/0/1/0/all/0/1">Hamidreza Mazandarani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shokrnezhad_M/0/1/0/all/0/1">Masoud Shokrnezhad</a>, <a href="http://arxiv.org/find/cs/1/au:+Taleb_T/0/1/0/all/0/1">Tarik Taleb</a></p>
<p>The emergence of the semantic-aware paradigm presents opportunities for
innovative services, especially in the context of 6G-based applications.
Although significant progress has been made in semantic extraction techniques,
the incorporation of semantic information into resource allocation
decision-making is still in its early stages, lacking consideration of the
requirements and characteristics of future systems. In response, this paper
introduces a novel formulation for the problem of multiple access to the
wireless spectrum. It aims to optimize the utilization-fairness trade-off,
using the $\alpha$-fairness metric, while accounting for user data correlation
by introducing the concepts of self- and assisted throughputs. Initially, the
problem is analyzed to identify its optimal solution. Subsequently, a
Semantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL)
technique is proposed. This method is grounded in Model-free Multi-Agent Deep
Reinforcement Learning (MADRL), enabling the user equipment to autonomously
make decisions regarding wireless spectrum access based solely on their local
individual observations. The efficiency of the proposed technique is evaluated
through two scenarios: single-channel and multi-channel. The findings
illustrate that, across a spectrum of $\alpha$ values, association matrices,
and channels, SAMA-D3QL consistently outperforms alternative approaches. This
establishes it as a promising candidate for facilitating the realization of
future federated, dynamically evolving applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06318">Striking a Balance in Fairness for Dynamic Systems Through Reinforcement Learning. (arXiv:2401.06318v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yaowei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lear_J/0/1/0/all/0/1">Jacob Lear</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a></p>
<p>While significant advancements have been made in the field of fair machine
learning, the majority of studies focus on scenarios where the decision model
operates on a static population. In this paper, we study fairness in dynamic
systems where sequential decisions are made. Each decision may shift the
underlying distribution of features or user behavior. We model the dynamic
system through a Markov Decision Process (MDP). By acknowledging that
traditional fairness notions and long-term fairness are distinct requirements
that may not necessarily align with one another, we propose an algorithmic
framework to integrate various fairness considerations with reinforcement
learning using both pre-processing and in-processing approaches. Three case
studies show that our method can strike a balance between traditional fairness
notions, long-term fairness, and utility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06325">Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo. (arXiv:2401.06325v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Huang_X/0/1/0/all/0/1">Xunpeng Huang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zou_D/0/1/0/all/0/1">Difan Zou</a>, <a href="http://arxiv.org/find/stat/1/au:+Dong_H/0/1/0/all/0/1">Hanze Dong</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1">Yian Ma</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a></p>
<p>To sample from a general target distribution $p_*\propto e^{-f_*}$ beyond the
isoperimetric condition, Huang et al. (2023) proposed to perform sampling
through reverse diffusion, giving rise to Diffusion-based Monte Carlo (DMC).
Specifically, DMC follows the reverse SDE of a diffusion process that
transforms the target distribution to the standard Gaussian, utilizing a
non-parametric score estimation. However, the original DMC algorithm
encountered high gradient complexity, resulting in an exponential dependency on
the error tolerance $\epsilon$ of the obtained samples. In this paper, we
demonstrate that the high complexity of DMC originates from its redundant
design of score estimation, and proposed a more efficient algorithm, called
RS-DMC, based on a novel recursive score estimation method. In particular, we
first divide the entire diffusion process into multiple segments and then
formulate the score estimation step (at any time step) as a series of
interconnected mean estimation and sampling subproblems accordingly, which are
correlated in a recursive manner. Importantly, we show that with a proper
design of the segment decomposition, all sampling subproblems will only need to
tackle a strongly log-concave distribution, which can be very efficient to
solve using the Langevin-based samplers with a provably rapid convergence rate.
As a result, we prove that the gradient complexity of RS-DMC only has a
quasi-polynomial dependency on $\epsilon$, which significantly improves
exponential gradient complexity in Huang et al. (2023). Furthermore, under
commonly used dissipative conditions, our algorithm is provably much faster
than the popular Langevin-based algorithms. Our algorithm design and
theoretical framework illuminate a novel direction for addressing sampling
problems, which could be of broader applicability in the community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06356">An Empirical Investigation into the Effect of Parameter Choices in Knowledge Distillation. (arXiv:2401.06356v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1">Md Arafat Sultan</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1">Aashka Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Awasthy_P/0/1/0/all/0/1">Parul Awasthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sil_A/0/1/0/all/0/1">Avirup Sil</a></p>
<p>We present a large-scale empirical study of how choices of configuration
parameters affect performance in knowledge distillation (KD). An example of
such a KD parameter is the measure of distance between the predictions of the
teacher and the student, common choices for which include the mean squared
error (MSE) and the KL-divergence. Although scattered efforts have been made to
understand the differences between such options, the KD literature still lacks
a systematic study on their general effect on student performance. We take an
empirical approach to this question in this paper, seeking to find out the
extent to which such choices influence student performance across 13 datasets
from 4 NLP tasks and 3 student sizes. We quantify the cost of making
sub-optimal choices and identify a single configuration that performs well
across the board.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06362">Attention, Distillation, and Tabularization: Towards Practical Neural Network-Based Prefetching. (arXiv:2401.06362v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengmiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Neelesh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kannan_R/0/1/0/all/0/1">Rajgopal Kannan</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasanna_V/0/1/0/all/0/1">Viktor K. Prasanna</a></p>
<p>Attention-based Neural Networks (NN) have demonstrated their effectiveness in
accurate memory access prediction, an essential step in data prefetching.
However, the substantial computational overheads associated with these models
result in high inference latency, limiting their feasibility as practical
prefetchers. To close the gap, we propose a new approach based on
tabularization that significantly reduces model complexity and inference
latency without sacrificing prediction accuracy. Our novel tabularization
methodology takes as input a distilled, yet highly accurate attention-based
model for memory access prediction and efficiently converts its expensive
matrix multiplications into a hierarchy of fast table lookups. As an exemplar
of the above approach, we develop DART, a prefetcher comprised of a simple
hierarchy of tables. With a modest 0.09 drop in F1-score, DART reduces 99.99%
of arithmetic operations from the large attention-based model and 91.83% from
the distilled model. DART accelerates the large model inference by 170x and the
distilled model by 9.4x. DART has comparable latency and storage costs as
state-of-the-art rule-based prefetcher BO but surpasses it by 6.1% in IPC
improvement, resulting in a 37.6% speed-up. DART outperforms state-of-the-art
NN-based prefetchers TransFetch by 33.1% and Voyager by 37.2% in terms of IPC
improvement, primarily due to its low prefetching latency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06406">Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis: A review. (arXiv:2401.06406v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mao_L/0/1/0/all/0/1">Lingchao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hairong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Leland S. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1">Nhan L Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Canoll_P/0/1/0/all/0/1">Peter D Canoll</a>, <a href="http://arxiv.org/find/cs/1/au:+Swanson_K/0/1/0/all/0/1">Kristin R Swanson</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a></p>
<p>Cancer remains one of the most challenging diseases to treat in the medical
field. Machine learning has enabled in-depth analysis of rich multi-omics
profiles and medical imaging for cancer diagnosis and prognosis. Despite these
advancements, machine learning models face challenges stemming from limited
labeled sample sizes, the intricate interplay of high-dimensionality data
types, the inherent heterogeneity observed among patients and within tumors,
and concerns about interpretability and consistency with existing biomedical
knowledge. One approach to surmount these challenges is to integrate biomedical
knowledge into data-driven models, which has proven potential to improve the
accuracy, robustness, and interpretability of model results. Here, we review
the state-of-the-art machine learning studies that adopted the fusion of
biomedical knowledge and data, termed knowledge-informed machine learning, for
cancer diagnosis and prognosis. Emphasizing the properties inherent in four
primary data types including clinical, imaging, molecular, and treatment data,
we highlight modeling considerations relevant to these contexts. We provide an
overview of diverse forms of knowledge representation and current strategies of
knowledge integration into machine learning pipelines with concrete examples.
We conclude the review article by discussing future directions to advance
cancer research through knowledge-informed machine learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06416">Mission: Impossible Language Models. (arXiv:2401.06416v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kallini_J/0/1/0/all/0/1">Julie Kallini</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadimitriou_I/0/1/0/all/0/1">Isabel Papadimitriou</a>, <a href="http://arxiv.org/find/cs/1/au:+Futrell_R/0/1/0/all/0/1">Richard Futrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1">Kyle Mahowald</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a></p>
<p>Chomsky and others have very directly claimed that large language models
(LLMs) are equally capable of learning languages that are possible and
impossible for humans to learn. However, there is very little published
experimental evidence to support such a claim. Here, we develop a set of
synthetic impossible languages of differing complexity, each designed by
systematically altering English data with unnatural word orders and grammar
rules. These languages lie on an impossibility continuum: at one end are
languages that are inherently impossible, such as random and irreversible
shuffles of English words, and on the other, languages that may not be
intuitively impossible but are often considered so in linguistics, particularly
those with rules based on counting word positions. We report on a wide range of
evaluations to assess the capacity of GPT-2 small models to learn these
uncontroversially impossible languages, and crucially, we perform these
assessments at various stages throughout training to compare the learning
process for each language. Our core finding is that GPT-2 struggles to learn
impossible languages when compared to English as a control, challenging the
core claim. More importantly, we hope our approach opens up a productive line
of inquiry in which different LLM architectures are tested on a variety of
impossible languages in an effort to learn more about how LLMs can be used as
tools for these cognitive and typological investigations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06421">Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction. (arXiv:2401.06421v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Geethen Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Moncrieff_G/0/1/0/all/0/1">Glenn Moncrieff</a>, <a href="http://arxiv.org/find/cs/1/au:+Venter_Z/0/1/0/all/0/1">Zander Venter</a>, <a href="http://arxiv.org/find/cs/1/au:+Cawse_Nicholson_K/0/1/0/all/0/1">Kerry Cawse-Nicholson</a>, <a href="http://arxiv.org/find/cs/1/au:+Slingsby_J/0/1/0/all/0/1">Jasper Slingsby</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_T/0/1/0/all/0/1">Tamara B Robinson</a></p>
<p>Unreliable predictions can occur when using artificial intelligence (AI)
systems with negative consequences for downstream applications, particularly
when employed for decision-making. Conformal prediction provides a
model-agnostic framework for uncertainty quantification that can be applied to
any dataset, irrespective of its distribution, post hoc. In contrast to other
pixel-level uncertainty quantification methods, conformal prediction operates
without requiring access to the underlying model and training dataset,
concurrently offering statistically valid and informative prediction regions,
all while maintaining computational efficiency. In response to the increased
need to report uncertainty alongside point predictions, we bring attention to
the promise of conformal prediction within the domain of Earth Observation (EO)
applications. To accomplish this, we assess the current state of uncertainty
quantification in the EO domain and found that only 20% of the reviewed Google
Earth Engine (GEE) datasets incorporated a degree of uncertainty information,
with unreliable methods prevalent. Next, we introduce modules that seamlessly
integrate into existing GEE predictive modelling workflows and demonstrate the
application of these tools for datasets spanning local to global scales,
including the Dynamic World and Global Ecosystem Dynamics Investigation (GEDI)
datasets. These case studies encompass regression and classification tasks,
featuring both traditional and deep learning-based workflows. Subsequently, we
discuss the opportunities arising from the use of conformal prediction in EO.
We anticipate that the increased availability of easy-to-use implementations of
conformal predictors, such as those provided here, will drive wider adoption of
rigorous uncertainty quantification in EO, thereby enhancing the reliability of
uses such as operational monitoring and decision making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06432">Heterogeneous Low-Rank Approximation for Federated Fine-tuning of On-Device Foundation Models. (arXiv:2401.06432v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1">Yae Jee Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Luyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fahrezi_A/0/1/0/all/0/1">Aldi Fahrezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1">Gauri Joshi</a></p>
<p>Large foundation models (FMs) adapt surprisingly well to specific domains or
tasks with fine-tuning. Federated learning (FL) further enables private FM
fine-tuning using the local data on devices. However, the standard FMs' large
size poses challenges for resource-constrained and heterogeneous devices. To
address this, we consider FMs with reduced parameter sizes, referred to as
on-device FMs (ODFMs). While ODFMs allow on-device inference, computational
constraints still hinder efficient federated fine-tuning. We propose a
parameter-efficient federated fine-tuning method for ODFMs using heterogeneous
low-rank approximations (LoRAs) that addresses system and data heterogeneity.
We show that homogeneous LoRA ranks face a trade-off between overfitting and
slow convergence, and propose HetLoRA, which employs heterogeneous ranks across
clients and eliminates the shortcomings of homogeneous HetLoRA. By applying
rank self-pruning locally and sparsity-weighted aggregation at the server, we
combine the advantages of high and low-rank LoRAs, which achieves improved
convergence speed and final performance compared to homogeneous LoRA.
Furthermore, it offers enhanced computation efficiency compared to full
fine-tuning, making it suitable for heterogeneous devices while preserving data
privacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06436">Improving Graph Convolutional Networks with Transformer Layer in social-based items recommendation. (arXiv:2401.06436v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1">Thi Linh Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Tuan Dung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Ta_V/0/1/0/all/0/1">Viet Cuong Ta</a></p>
<p>In this work, we have proposed an approach for improving the GCN for
predicting ratings in social networks. Our model is expanded from the standard
model with several layers of transformer architecture. The main focus of the
paper is on the encoder architecture for node embedding in the network. Using
the embedding layer from the graph-based convolution layer, the attention
mechanism could rearrange the feature space to get a more efficient embedding
for the downstream task. The experiments showed that our proposed architecture
achieves better performance than GCN on the traditional link prediction task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06452">Automated Machine Learning for Positive-Unlabelled Learning. (arXiv:2401.06452v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saunders_J/0/1/0/all/0/1">Jack D. Saunders</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1">Alex A. Freitas</a></p>
<p>Positive-Unlabelled (PU) learning is a growing field of machine learning that
aims to learn classifiers from data consisting of labelled positive and
unlabelled instances, which can be in reality positive or negative, but whose
label is unknown. An extensive number of methods have been proposed to address
PU learning over the last two decades, so many so that selecting an optimal
method for a given PU learning task presents a challenge. Our previous work has
addressed this by proposing GA-Auto-PU, the first Automated Machine Learning
(Auto-ML) system for PU learning. In this work, we propose two new Auto-ML
systems for PU learning: BO-Auto-PU, based on a Bayesian Optimisation approach,
and EBO-Auto-PU, based on a novel evolutionary/Bayesian optimisation approach.
We also present an extensive evaluation of the three Auto-ML systems, comparing
them to each other and to well-established PU learning methods across 60
datasets (20 real-world datasets, each with 3 versions in terms of PU learning
characteristics).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06465">Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test. (arXiv:2401.06465v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hedstrom_A/0/1/0/all/0/1">Anna Hedstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_L/0/1/0/all/0/1">Leander Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapuschkin_S/0/1/0/all/0/1">Sebastian Lapuschkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_M/0/1/0/all/0/1">Marina MC H&#xf6;hne</a></p>
<p>The Model Parameter Randomisation Test (MPRT) is widely acknowledged in the
eXplainable Artificial Intelligence (XAI) community for its well-motivated
evaluative principle: that the explanation function should be sensitive to
changes in the parameters of the model function. However, recent works have
identified several methodological caveats for the empirical interpretation of
MPRT. To address these caveats, we introduce two adaptations to the original
MPRT -- Smooth MPRT and Efficient MPRT, where the former minimises the impact
that noise has on the evaluation results through sampling and the latter
circumvents the need for biased similarity measurements by re-interpreting the
test through the explanation's rise in complexity, after full parameter
randomisation. Our experimental results demonstrate that these proposed
variants lead to improved metric reliability, thus enabling a more trustworthy
application of XAI methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06469">Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning. (arXiv:2401.06469v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_A/0/1/0/all/0/1">Ang Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuhan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_H/0/1/0/all/0/1">Hansen Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Rui Yan</a></p>
<p>In this paper, by treating in-context learning (ICL) as a meta-optimization
process, we explain why LLMs are sensitive to the order of ICL examples. This
understanding leads us to the development of Batch-ICL, an effective,
efficient, and order-agnostic inference algorithm for ICL. Differing from the
standard N-shot learning approach, Batch-ICL employs $N$ separate 1-shot
forward computations and aggregates the resulting meta-gradients. These
aggregated meta-gradients are then applied to a zero-shot learning to generate
the final prediction. This batch processing approach renders the LLM agnostic
to the order of ICL examples. Through extensive experiments and analysis, we
demonstrate that Batch-ICL consistently outperforms most permutations of
example sequences. In some cases, it even exceeds the performance of the
optimal order for standard ICL, all while reducing the computational resources
required. Furthermore, we develop a novel variant of Batch-ICL featuring
multiple "epochs" of meta-optimization. This variant implicitly explores
permutations of ICL examples, further enhancing ICL performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06495">An investigation of structures responsible for gender bias in BERT and DistilBERT. (arXiv:2401.06495v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leteno_T/0/1/0/all/0/1">Thibaud Leteno</a>, <a href="http://arxiv.org/find/cs/1/au:+Gourru_A/0/1/0/all/0/1">Antoine Gourru</a>, <a href="http://arxiv.org/find/cs/1/au:+Laclau_C/0/1/0/all/0/1">Charlotte Laclau</a>, <a href="http://arxiv.org/find/cs/1/au:+Gravier_C/0/1/0/all/0/1">Christophe Gravier</a></p>
<p>In recent years, large Transformer-based Pre-trained Language Models (PLM)
have changed the Natural Language Processing (NLP) landscape, by pushing the
performance boundaries of the state-of-the-art on a wide variety of tasks.
However, this performance gain goes along with an increase in complexity, and
as a result, the size of such models (up to billions of parameters) represents
a constraint for their deployment on embedded devices or short-inference time
tasks. To cope with this situation, compressed models emerged (e.g.
DistilBERT), democratizing their usage in a growing number of applications that
impact our daily lives. A crucial issue is the fairness of the predictions made
by both PLMs and their distilled counterparts. In this paper, we propose an
empirical exploration of this problem by formalizing two questions: (1) Can we
identify the neural mechanism(s) responsible for gender bias in BERT (and by
extension DistilBERT)? (2) Does distillation tend to accentuate or mitigate
gender bias (e.g. is DistilBERT more prone to gender bias than its uncompressed
version, BERT)? Our findings are the following: (I) one cannot identify a
specific layer that produces bias; (II) every attention head uniformly encodes
bias; except in the context of underrepresented classes with a high imbalance
of the sensitive attribute; (III) this subset of heads is different as we
re-fine tune the network; (IV) bias is more homogeneously produced by the heads
in the distilled model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06498">Temporal and Between-Group Variability in College Dropout Prediction. (arXiv:2401.06498v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Glandorf_D/0/1/0/all/0/1">Dominik Glandorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hye Rin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Orona_G/0/1/0/all/0/1">Gabe Avakian Orona</a>, <a href="http://arxiv.org/find/cs/1/au:+Pumptow_M/0/1/0/all/0/1">Marina Pumptow</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Renzhe Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_C/0/1/0/all/0/1">Christian Fischer</a></p>
<p>Large-scale administrative data is a common input in early warning systems
for college dropout in higher education. Still, the terminology and methodology
vary significantly across existing studies, and the implications of different
modeling decisions are not fully understood. This study provides a systematic
evaluation of contributing factors and predictive performance of machine
learning models over time and across different student groups. Drawing on
twelve years of administrative data at a large public university in the US, we
find that dropout prediction at the end of the second year has a 20% higher AUC
than at the time of enrollment in a Random Forest model. Also, most predictive
factors at the time of enrollment, including demographics and high school
performance, are quickly superseded in predictive importance by college
performance and in later stages by enrollment behavior. Regarding variability
across student groups, college GPA has more predictive value for students from
traditionally disadvantaged backgrounds than their peers. These results can
help researchers and administrators understand the comparative value of
different data sources when building early warning systems and optimizing
decisions under specific policy goals.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06499">Fully Automated Tumor Segmentation for Brain MRI data using Multiplanner UNet. (arXiv:2401.06499v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Pandey_S/0/1/0/all/0/1">Sumit Pandey</a>, <a href="http://arxiv.org/find/eess/1/au:+Changdar_S/0/1/0/all/0/1">Satyasaran Changdar</a>, <a href="http://arxiv.org/find/eess/1/au:+Perslev_M/0/1/0/all/0/1">Mathias Perslev</a>, <a href="http://arxiv.org/find/eess/1/au:+Dam_E/0/1/0/all/0/1">Erik B Dam</a></p>
<p>Automated segmentation of distinct tumor regions is critical for accurate
diagnosis and treatment planning in pediatric brain tumors. This study
evaluates the efficacy of the Multi-Planner U-Net (MPUnet) approach in
segmenting different tumor subregions across three challenging datasets:
Pediatrics Tumor Challenge (PED), Brain Metastasis Challenge (MET), and
Sub-Sahara-Africa Adult Glioma (SSA). These datasets represent diverse
scenarios and anatomical variations, making them suitable for assessing the
robustness and generalization capabilities of the MPUnet model. By utilizing
multi-planar information, the MPUnet architecture aims to enhance segmentation
accuracy. Our results show varying performance levels across the evaluated
challenges, with the tumor core (TC) class demonstrating relatively higher
segmentation accuracy. However, variability is observed in the segmentation of
other classes, such as the edema and enhancing tumor (ET) regions. These
findings emphasize the complexity of brain tumor segmentation and highlight the
potential for further refinement of the MPUnet approach and inclusion of MRI
more data and preprocessing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06513">ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A Case Study. (arXiv:2401.06513v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdelkader_H/0/1/0/all/0/1">Hala Abdelkader</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelrazek_M/0/1/0/all/0/1">Mohamed Abdelrazek</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnett_S/0/1/0/all/0/1">Scott Barnett</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jean-Guy Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Rani_P/0/1/0/all/0/1">Priya Rani</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasa_R/0/1/0/all/0/1">Rajesh Vasa</a></p>
<p>Machine learning (ML), especially with the emergence of large language models
(LLMs), has significantly transformed various industries. However, the
transition from ML model prototyping to production use within software systems
presents several challenges. These challenges primarily revolve around ensuring
safety, security, and transparency, subsequently influencing the overall
robustness and trustworthiness of ML models. In this paper, we introduce
ML-On-Rails, a protocol designed to safeguard ML models, establish a
well-defined endpoint interface for different ML tasks, and clear communication
between ML providers and ML consumers (software engineers). ML-On-Rails
enhances the robustness of ML models via incorporating detection capabilities
to identify unique challenges specific to production ML. We evaluated the
ML-On-Rails protocol through a real-world case study of the MoveReminder
application. Through this evaluation, we emphasize the importance of
safeguarding ML models in production.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06514">Personalized Reinforcement Learning with a Budget of Policies. (arXiv:2401.06514v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ivanov_D/0/1/0/all/0/1">Dmitry Ivanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_Porat_O/0/1/0/all/0/1">Omer Ben-Porat</a></p>
<p>Personalization in machine learning (ML) tailors models' decisions to the
individual characteristics of users. While this approach has seen success in
areas like recommender systems, its expansion into high-stakes fields such as
healthcare and autonomous driving is hindered by the extensive regulatory
approval processes involved. To address this challenge, we propose a novel
framework termed represented Markov Decision Processes (r-MDPs) that is
designed to balance the need for personalization with the regulatory
constraints. In an r-MDP, we cater to a diverse user population, each with
unique preferences, through interaction with a small set of representative
policies. Our objective is twofold: efficiently match each user to an
appropriate representative policy and simultaneously optimize these policies to
maximize overall social welfare. We develop two deep reinforcement learning
algorithms that efficiently solve r-MDPs. These algorithms draw inspiration
from the principles of classic K-means clustering and are underpinned by robust
theoretical foundations. Our empirical investigations, conducted across a
variety of simulated environments, showcase the algorithms' ability to
facilitate meaningful personalization even under constrained policy budgets.
Furthermore, they demonstrate scalability, efficiently adapting to larger
policy budgets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06523">Boosting Causal Additive Models. (arXiv:2401.06523v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kertel_M/0/1/0/all/0/1">Maximilian Kertel</a>, <a href="http://arxiv.org/find/stat/1/au:+Klein_N/0/1/0/all/0/1">Nadja Klein</a></p>
<p>We present a boosting-based method to learn additive Structural Equation
Models (SEMs) from observational data, with a focus on the theoretical aspects
of determining the causal order among variables. We introduce a family of score
functions based on arbitrary regression techniques, for which we establish
necessary conditions to consistently favor the true causal ordering. Our
analysis reveals that boosting with early stopping meets these criteria and
thus offers a consistent score function for causal orderings. To address the
challenges posed by high-dimensional data sets, we adapt our approach through a
component-wise gradient descent in the space of additive SEMs. Our simulation
study underlines our theoretical results for lower dimensions and demonstrates
that our high-dimensional adaptation is competitive with state-of-the-art
methods. In addition, it exhibits robustness with respect to the choice of the
hyperparameters making the procedure easy to tune.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06524">Domain Adaptation for Time series Transformers using One-step fine-tuning. (arXiv:2401.06524v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khanal_S/0/1/0/all/0/1">Subina Khanal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tirupathi_S/0/1/0/all/0/1">Seshu Tirupathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zizzo_G/0/1/0/all/0/1">Giulio Zizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1">Ambrish Rawat</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Torben Bach Pedersen</a></p>
<p>The recent breakthrough of Transformers in deep learning has drawn
significant attention of the time series community due to their ability to
capture long-range dependencies. However, like other deep learning models,
Transformers face limitations in time series prediction, including insufficient
temporal understanding, generalization challenges, and data shift issues for
the domains with limited data. Additionally, addressing the issue of
catastrophic forgetting, where models forget previously learned information
when exposed to new data, is another critical aspect that requires attention in
enhancing the robustness of Transformers for time series tasks. To address
these limitations, in this paper, we pre-train the time series Transformer
model on a source domain with sufficient data and fine-tune it on the target
domain with limited data. We introduce the \emph{One-step fine-tuning}
approach, adding some percentage of source domain data to the target domains,
providing the model with diverse time series instances. We then fine-tune the
pre-trained model using a gradual unfreezing technique. This helps enhance the
model's performance in time series prediction for domains with limited data.
Extensive experimental results on two real-world datasets show that our
approach improves over the state-of-the-art baselines by 4.35% and 11.54% for
indoor temperature and wind power prediction, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06538">Intelligent Data-Driven Architectural Features Orchestration for Network Slicing. (arXiv:2401.06538v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moreira_R/0/1/0/all/0/1">Rodrigo Moreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_F/0/1/0/all/0/1">Flavio de Oliveira Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_T/0/1/0/all/0/1">Tereza Cristina Melo de Brito Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_J/0/1/0/all/0/1">Joberto S. B. Martins</a></p>
<p>Network slicing is a crucial enabler and a trend for the Next Generation
Mobile Network (NGMN) and various other new systems like the Internet of
Vehicles (IoV) and Industrial IoT (IIoT). Orchestration and machine learning
are key elements with a crucial role in the network-slicing processes since the
NS process needs to orchestrate resources and functionalities, and machine
learning can potentially optimize the orchestration process. However, existing
network-slicing architectures lack the ability to define intelligent approaches
to orchestrate features and resources in the slicing process. This paper
discusses machine learning-based orchestration of features and capabilities in
network slicing architectures. Initially, the slice resource orchestration and
allocation in the slicing planning, configuration, commissioning, and operation
phases are analyzed. In sequence, we highlight the need for optimized
architectural feature orchestration and recommend using ML-embed agents,
federated learning intrinsic mechanisms for knowledge acquisition, and a
data-driven approach embedded in the network slicing architecture. We further
develop an architectural features orchestration case embedded in the SFI2
network slicing architecture. An attack prevention security mechanism is
developed for the SFI2 architecture using distributed embedded and cooperating
ML agents. The case presented illustrates the architectural feature's
orchestration process and benefits, highlighting its importance for the network
slicing process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06546">Optimizing Feature Selection for Binary Classification with Noisy Labels: A Genetic Algorithm Approach. (arXiv:2401.06546v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Imani_V/0/1/0/all/0/1">Vandad Imani</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradi_E/0/1/0/all/0/1">Elaheh Moradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sevilla_Salcedo_C/0/1/0/all/0/1">Carlos Sevilla-Salcedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortino_V/0/1/0/all/0/1">Vittorio Fortino</a>, <a href="http://arxiv.org/find/cs/1/au:+Tohka_J/0/1/0/all/0/1">Jussi Tohka</a></p>
<p>Feature selection in noisy label scenarios remains an understudied topic. We
propose a novel genetic algorithm-based approach, the Noise-Aware
Multi-Objective Feature Selection Genetic Algorithm (NMFS-GA), for selecting
optimal feature subsets in binary classification with noisy labels. NMFS-GA
offers a unified framework for selecting feature subsets that are both accurate
and interpretable. We evaluate NMFS-GA on synthetic datasets with label noise,
a Breast Cancer dataset enriched with noisy features, and a real-world ADNI
dataset for dementia conversion prediction. Our results indicate that NMFS-GA
can effectively select feature subsets that improve the accuracy and
interpretability of binary classifiers in scenarios with noisy labels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06557">Treatment-Aware Hyperbolic Representation Learning for Causal Effect Estimation with Social Networks. (arXiv:2401.06557v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Ziqiang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xing Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yang Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bowei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiuqiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chen Ma</a></p>
<p>Estimating the individual treatment effect (ITE) from observational data is a
crucial research topic that holds significant value across multiple domains.
How to identify hidden confounders poses a key challenge in ITE estimation.
Recent studies have incorporated the structural information of social networks
to tackle this challenge, achieving notable advancements. However, these
methods utilize graph neural networks to learn the representation of hidden
confounders in Euclidean space, disregarding two critical issues: (1) the
social networks often exhibit a scalefree structure, while Euclidean embeddings
suffer from high distortion when used to embed such graphs, and (2) each
ego-centric network within a social network manifests a treatment-related
characteristic, implying significant patterns of hidden confounders. To address
these issues, we propose a novel method called Treatment-Aware Hyperbolic
Representation Learning (TAHyper). Firstly, TAHyper employs the hyperbolic
space to encode the social networks, thereby effectively reducing the
distortion of confounder representation caused by Euclidean embeddings.
Secondly, we design a treatment-aware relationship identification module that
enhances the representation of hidden confounders by identifying whether an
individual and her neighbors receive the same treatment. Extensive experiments
on two benchmark datasets are conducted to demonstrate the superiority of our
method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06559">A General Benchmark Framework is Dynamic Graph Neural Network Need. (arXiv:2401.06559v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yusen Zhang</a></p>
<p>Dynamic graph learning is crucial for modeling real-world systems with
evolving relationships and temporal dynamics. However, the lack of a unified
benchmark framework in current research has led to inaccurate evaluations of
dynamic graph models. This paper highlights the significance of dynamic graph
learning and its applications in various domains. It emphasizes the need for a
standardized benchmark framework that captures temporal dynamics, evolving
graph structures, and downstream task requirements. Establishing a unified
benchmark will help researchers understand the strengths and limitations of
existing models, foster innovation, and advance dynamic graph learning. In
conclusion, this paper identifies the lack of a standardized benchmark
framework as a current limitation in dynamic graph learning research . Such a
framework will facilitate accurate model evaluation, drive advancements in
dynamic graph learning techniques, and enable the development of more effective
models for real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06566">Maximum Causal Entropy Inverse Reinforcement Learning for Mean-Field Games. (arXiv:2401.06566v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Anahtarci_B/0/1/0/all/0/1">Berkay Anahtarci</a>, <a href="http://arxiv.org/find/eess/1/au:+Kariksiz_C/0/1/0/all/0/1">Can Deha Kariksiz</a>, <a href="http://arxiv.org/find/eess/1/au:+Saldi_N/0/1/0/all/0/1">Naci Saldi</a></p>
<p>In this paper, we introduce the maximum casual entropy Inverse Reinforcement
Learning (IRL) problem for discrete-time mean-field games (MFGs) under an
infinite-horizon discounted-reward optimality criterion. The state space of a
typical agent is finite. Our approach begins with a comprehensive review of the
maximum entropy IRL problem concerning deterministic and stochastic Markov
decision processes (MDPs) in both finite and infinite-horizon scenarios.
Subsequently, we formulate the maximum casual entropy IRL problem for MFGs - a
non-convex optimization problem with respect to policies. Leveraging the linear
programming formulation of MDPs, we restructure this IRL problem into a convex
optimization problem and establish a gradient descent algorithm to compute the
optimal solution with a rate of convergence. Finally, we present a new
algorithm by formulating the MFG problem as a generalized Nash equilibrium
problem (GNEP), which is capable of computing the mean-field equilibrium (MFE)
for the forward RL problem. This method is employed to produce data for a
numerical example. We note that this novel algorithm is also applicable to
general MFE computations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06583">Mapping Transformer Leveraged Embeddings for Cross-Lingual Document Representation. (arXiv:2401.06583v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tashu_T/0/1/0/all/0/1">Tsegaye Misikir Tashu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontos_E/0/1/0/all/0/1">Eduard-Raul Kontos</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabatelli_M/0/1/0/all/0/1">Matthia Sabatelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Valdenegro_Toro_M/0/1/0/all/0/1">Matias Valdenegro-Toro</a></p>
<p>Recommendation systems, for documents, have become tools to find relevant
content on the Web. However, these systems have limitations when it comes to
recommending documents in languages different from the query language, which
means they might overlook resources in non-native languages. This research
focuses on representing documents across languages by using Transformer
Leveraged Document Representations (TLDRs) that are mapped to a cross-lingual
domain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM
RoBERTa, ErnieM) were evaluated using three mapping methods across 20 language
pairs representing combinations of five selected languages of the European
Union. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to
measure the effectiveness of mapped TLDRs compared to non-mapped ones. The
results highlight the power of cross-lingual representations achieved through
pre-trained transformers and mapping approaches suggesting a promising
direction for expanding beyond language connections, between two specific
languages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06588">Dynamic Behaviour of Connectionist Speech Recognition with Strong Latency Constraints. (arXiv:2401.06588v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Salvi_G/0/1/0/all/0/1">Giampiero Salvi</a></p>
<p>This paper describes the use of connectionist techniques in phonetic speech
recognition with strong latency constraints. The constraints are imposed by the
task of deriving the lip movements of a synthetic face in real time from the
speech signal, by feeding the phonetic string into an articulatory synthesiser.
Particular attention has been paid to analysing the interaction between the
time evolution model learnt by the multi-layer perceptrons and the transition
model imposed by the Viterbi decoder, in different latency conditions. Two
experiments were conducted in which the time dependencies in the language model
(LM) were controlled by a parameter. The results show a strong interaction
between the three factors involved, namely the neural network topology, the
length of time dependencies in the LM and the decoder latency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06595">Every Node is Different: Dynamically Fusing Self-Supervised Tasks for Attributed Graph Clustering. (arXiv:2401.06595v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Pengfei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jialu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1">Qinghua Hu</a></p>
<p>Attributed graph clustering is an unsupervised task that partitions nodes
into different groups. Self-supervised learning (SSL) shows great potential in
handling this task, and some recent studies simultaneously learn multiple SSL
tasks to further boost performance. Currently, different SSL tasks are assigned
the same set of weights for all graph nodes. However, we observe that some
graph nodes whose neighbors are in different groups require significantly
different emphases on SSL tasks. In this paper, we propose to dynamically learn
the weights of SSL tasks for different nodes and fuse the embeddings learned
from different SSL tasks to boost performance. We design an innovative graph
clustering approach, namely Dynamically Fusing Self-Supervised Learning
(DyFSS). Specifically, DyFSS fuses features extracted from diverse SSL tasks
using distinct weights derived from a gating network. To effectively learn the
gating network, we design a dual-level self-supervised strategy that
incorporates pseudo labels and the graph structure. Extensive experiments on
five datasets show that DyFSS outperforms the state-of-the-art multi-task SSL
methods by up to 8.66% on the accuracy metric. The code of DyFSS is available
at: https://github.com/q086/DyFSS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06604">Identifying Policy Gradient Subspaces. (arXiv:2401.06604v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jan Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Schumacher_P/0/1/0/all/0/1">Pierre Schumacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Guist_S/0/1/0/all/0/1">Simon Guist</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Le Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Haufle_D/0/1/0/all/0/1">Daniel H&#xe4;ufle</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Buchler_D/0/1/0/all/0/1">Dieter B&#xfc;chler</a></p>
<p>Policy gradient methods hold great potential for solving complex continuous
control tasks. Still, their training efficiency can be improved by exploiting
structure within the optimization problem. Recent work indicates that
supervised learning can be accelerated by leveraging the fact that gradients
lie in a low-dimensional and slowly-changing subspace. In this paper, we
conduct a thorough evaluation of this phenomenon for two popular deep policy
gradient methods on various simulated benchmark tasks. Our results demonstrate
the existence of such gradient subspaces despite the continuously changing data
distribution inherent to reinforcement learning. These findings reveal
promising directions for future work on more efficient reinforcement learning,
e.g., through improving parameter-space exploration or enabling second-order
optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06634">CCFC: Bridging Federated Clustering and Contrastive Learning. (arXiv:2401.06634v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhong-Yuan Zhang</a></p>
<p>Federated clustering, an essential extension of centralized clustering for
federated scenarios, enables multiple data-holding clients to collaboratively
group data while keeping their data locally. In centralized scenarios,
clustering driven by representation learning has made significant advancements
in handling high-dimensional complex data. However, the combination of
federated clustering and representation learning remains underexplored. To
bridge this, we first tailor a cluster-contrastive model for learning
clustering-friendly representations. Then, we harness this model as the
foundation for proposing a new federated clustering method, named
cluster-contrastive federated clustering (CCFC). Benefiting from representation
learning, the clustering performance of CCFC even double those of the best
baseline methods in some cases. Compared to the most related baseline, the
benefit results in substantial NMI score improvements of up to 0.4155 on the
most conspicuous case. Moreover, CCFC also shows superior performance in
handling device failures from a practical viewpoint.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06644">SeizNet: An AI-enabled Implantable Sensor Network System for Seizure Prediction. (arXiv:2401.06644v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saeizadeh_A/0/1/0/all/0/1">Ali Saeizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonholtz_D/0/1/0/all/0/1">Douglas Schonholtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Uvaydov_D/0/1/0/all/0/1">Daniel Uvaydov</a>, <a href="http://arxiv.org/find/cs/1/au:+Guida_R/0/1/0/all/0/1">Raffaele Guida</a>, <a href="http://arxiv.org/find/cs/1/au:+Demirors_E/0/1/0/all/0/1">Emrecan Demirors</a>, <a href="http://arxiv.org/find/cs/1/au:+Johari_P/0/1/0/all/0/1">Pedram Johari</a>, <a href="http://arxiv.org/find/cs/1/au:+Jimenez_J/0/1/0/all/0/1">Jorge M. Jimenez</a>, <a href="http://arxiv.org/find/cs/1/au:+Neimat_J/0/1/0/all/0/1">Joseph S. Neimat</a>, <a href="http://arxiv.org/find/cs/1/au:+Melodia_T/0/1/0/all/0/1">Tommaso Melodia</a></p>
<p>In this paper, we introduce SeizNet, a closed-loop system for predicting
epileptic seizures through the use of Deep Learning (DL) method and implantable
sensor networks. While pharmacological treatment is effective for some epilepsy
patients (with ~65M people affected worldwide), one out of three suffer from
drug-resistant epilepsy. To alleviate the impact of seizure, predictive systems
have been developed that can notify such patients of an impending seizure,
allowing them to take precautionary measures. SeizNet leverages DL techniques
and combines data from multiple recordings, specifically intracranial
electroencephalogram (iEEG) and electrocardiogram (ECG) sensors, that can
significantly improve the specificity of seizure prediction while preserving
very high levels of sensitivity. SeizNet DL algorithms are designed for
efficient real-time execution at the edge, minimizing data privacy concerns,
data transmission overhead, and power inefficiencies associated with
cloud-based solutions. Our results indicate that SeizNet outperforms
traditional single-modality and non-personalized prediction systems in all
metrics, achieving up to 99% accuracy in predicting seizure, offering a
promising new avenue in refractory epilepsy treatment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06646">Block Majorization Minimization with Extrapolation and Application to $\beta$-NMF. (arXiv:2401.06646v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hien_L/0/1/0/all/0/1">Le Thi Khanh Hien</a>, <a href="http://arxiv.org/find/cs/1/au:+Leplat_V/0/1/0/all/0/1">Valentin Leplat</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillis_N/0/1/0/all/0/1">Nicolas Gillis</a></p>
<p>We propose a Block Majorization Minimization method with Extrapolation (BMMe)
for solving a class of multi-convex optimization problems. The extrapolation
parameters of BMMe are updated using a novel adaptive update rule. By showing
that block majorization minimization can be reformulated as a block mirror
descent method, with the Bregman divergence adaptively updated at each
iteration, we establish subsequential convergence for BMMe. We use this method
to design efficient algorithms to tackle nonnegative matrix factorization
problems with the $\beta$-divergences ($\beta$-NMF) for $\beta\in [1,2]$. These
algorithms, which are multiplicative updates with extrapolation, benefit from
our novel results that offer convergence guarantees. We also empirically
illustrate the significant acceleration of BMMe for $\beta$-NMF through
extensive experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06654">Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI Benchmarks. (arXiv:2401.06654v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Blucher_S/0/1/0/all/0/1">Stefan Bl&#xfc;cher</a>, <a href="http://arxiv.org/find/cs/1/au:+Vielhaben_J/0/1/0/all/0/1">Johanna Vielhaben</a>, <a href="http://arxiv.org/find/cs/1/au:+Strodthoff_N/0/1/0/all/0/1">Nils Strodthoff</a></p>
<p>Feature removal is a central building block for eXplainable AI (XAI), both
for occlusion-based explanations (Shapley values) as well as their evaluation
(pixel flipping, PF). However, occlusion strategies can vary significantly from
simple mean replacement up to inpainting with state-of-the-art diffusion
models. This ambiguity limits the usefulness of occlusion-based approaches. For
example, PF benchmarks lead to contradicting rankings. This is amplified by
competing PF measures: Features are either removed starting with most
influential first (MIF) or least influential first (LIF). This study proposes
two complementary perspectives to resolve this disagreement problem. Firstly,
we address the common criticism of occlusion-based XAI, that artificial samples
lead to unreliable model evaluations. We propose to measure the reliability by
the R(eference)-Out-of-Model-Scope (OMS) score. The R-OMS score enables a
systematic comparison of occlusion strategies and resolves the disagreement
problem by grouping consistent PF rankings. Secondly, we show that the
insightfulness of MIF and LIF is conversely dependent on the R-OMS score. To
leverage this, we combine the MIF and LIF measures into the symmetric relevance
gain (SRG) measure. This breaks the inherent connection to the underlying
occlusion strategy and leads to consistent rankings. This resolves the
disagreement problem, which we verify for a set of 40 different occlusion
strategies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06656">Neural Networks for Singular Perturbations. (arXiv:2401.06656v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Opschoor_J/0/1/0/all/0/1">Joost A. A. Opschoor</a>, <a href="http://arxiv.org/find/math/1/au:+Schwab_C/0/1/0/all/0/1">Christoph Schwab</a>, <a href="http://arxiv.org/find/math/1/au:+Xenophontos_C/0/1/0/all/0/1">Christos Xenophontos</a></p>
<p>We prove deep neural network (DNN for short) expressivity rate bounds for
solution sets of a model class of singularly perturbed, elliptic two-point
boundary value problems, in Sobolev norms, on the bounded interval $(-1,1)$. We
assume that the given source term and reaction coefficient are analytic in
$[-1,1]$.
</p>
<p>We establish expression rate bounds in Sobolev norms in terms of the NN size
which are uniform with respect to the singular perturbation parameter for
several classes of DNN architectures. In particular, ReLU NNs, spiking NNs, and
$\tanh$- and sigmoid-activated NNs. The latter activations can represent
``exponential boundary layer solution features'' explicitly, in the last hidden
layer of the DNN, i.e. in a shallow subnetwork, and afford improved robust
expression rate bounds in terms of the NN size.
</p>
<p>We prove that all DNN architectures allow robust exponential solution
expression in so-called `energy' as well as in `balanced' Sobolev norms, for
analytic input data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06683">DQNC2S: DQN-based Cross-stream Crisis event Summarizer. (arXiv:2401.06683v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cambrin_D/0/1/0/all/0/1">Daniele Rege Cambrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cagliero_L/0/1/0/all/0/1">Luca Cagliero</a>, <a href="http://arxiv.org/find/cs/1/au:+Garza_P/0/1/0/all/0/1">Paolo Garza</a></p>
<p>Summarizing multiple disaster-relevant data streams simultaneously is
particularly challenging as existing Retrieve&amp;Re-ranking strategies suffer from
the inherent redundancy of multi-stream data and limited scalability in a
multi-query setting. This work proposes an online approach to crisis timeline
generation based on weak annotation with Deep Q-Networks. It selects on-the-fly
the relevant pieces of text without requiring neither human annotations nor
content re-ranking. This makes the inference time independent of the number of
input queries. The proposed approach also incorporates a redundancy filter into
the reward function to effectively handle cross-stream content overlaps. The
achieved ROUGE and BERTScore results are superior to those of best-performing
models on the CrisisFACTS 2022 benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06687">Proximal Causal Inference With Text Data. (arXiv:2401.06687v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jacob M. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_R/0/1/0/all/0/1">Rohit Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Keith_K/0/1/0/all/0/1">Katherine A. Keith</a></p>
<p>Recent text-based causal methods attempt to mitigate confounding bias by
including unstructured text data as proxies of confounding variables that are
partially or imperfectly measured. These approaches assume analysts have
supervised labels of the confounders given text for a subset of instances, a
constraint that is not always feasible due to data privacy or cost. Here, we
address settings in which an important confounding variable is completely
unobserved. We propose a new causal inference method that splits pre-treatment
text data, infers two proxies from two zero-shot models on the separate splits,
and applies these proxies in the proximal g-formula. We prove that our
text-based proxy method satisfies identification conditions required by the
proximal g-formula while other seemingly reasonable proposals do not. We
evaluate our method in synthetic and semi-synthetic settings and find that it
produces estimates with low bias. This combination of proximal causal inference
and zero-shot classifiers is novel (to our knowledge) and expands the set of
text-specific causal methods available to practitioners.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06688">Don&#x27;t Rank, Combine! Combining Machine Translation Hypotheses Using Quality Estimation. (arXiv:2401.06688v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vernikos_G/0/1/0/all/0/1">Giorgos Vernikos</a>, <a href="http://arxiv.org/find/cs/1/au:+Popescu_Belis_A/0/1/0/all/0/1">Andrei Popescu-Belis</a></p>
<p>Neural machine translation systems estimate probabilities of target sentences
given source sentences, yet these estimates may not align with human
preferences. This work introduces QE-fusion, a method utilizing a quality
estimation metric (QE) that better correlates with human judgments to
synthesize improved translations. QE-fusion leverages a candidate pool sampled
from a model, combining spans from different candidates using QE metrics such
as CometKiwi. We compare QE-fusion against beam search and recent reranking
techniques, such as Minimum Bayes Risk decoding or QE-reranking. Our method
consistently improves translation quality in terms of COMET and BLEURT scores
when applied to large language models (LLMs) used for translation (PolyLM,
XGLM, Llama2, and Mistral) and to multilingual translation models (NLLB), over
five language pairs. Notably, QE-fusion exhibits larger improvements for LLMs
due to their ability to generate diverse outputs. We demonstrate that our
approach generates novel translations in over half of the cases and
consistently outperforms other methods across varying numbers of candidates
(5-200). Furthermore, we empirically establish that QE-fusion scales linearly
with the number of candidates in the pool. QE-fusion proves effective in
enhancing LLM-based translation without the need for costly retraining of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06692">An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models. (arXiv:2401.06692v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhatt_G/0/1/0/all/0/1">Gantavya Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yifang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Arnav M. Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Sang T. Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Mussmann_S/0/1/0/all/0/1">Stephen Mussmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yinglun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilmes_J/0/1/0/all/0/1">Jeffrey Bilmes</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1">Kevin Jamieson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1">Jordan T. Ash</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1">Robert D. Nowak</a></p>
<p>Supervised finetuning (SFT) on instruction datasets has played a crucial role
in achieving the remarkable zero-shot generalization capabilities observed in
modern large language models (LLMs). However, the annotation efforts required
to produce high quality responses for instructions are becoming prohibitively
expensive, especially as the number of tasks spanned by instruction datasets
continues to increase. Active learning is effective in identifying useful
subsets of samples to annotate from an unlabeled pool, but its high
computational cost remains a barrier to its widespread applicability in the
context of LLMs. To mitigate the annotation cost of SFT and circumvent the
computational bottlenecks of active learning, we propose using experimental
design. Experimental design techniques select the most informative samples to
label, and typically maximize some notion of uncertainty and/or diversity. In
our work, we implement a framework that evaluates several existing and novel
experimental design techniques and find that these methods consistently yield
significant gains in label efficiency with little computational overhead. On
generative tasks, our methods achieve the same generalization performance with
only $50\%$ of annotation cost required by random sampling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06697">Quantum Machine Learning in the Cognitive Domain: Alzheimer&#x27;s Disease Study. (arXiv:2401.06697v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akpinar_E/0/1/0/all/0/1">Emine Akpinar</a></p>
<p>Alzheimer's disease (AD) is the most prevalent neurodegenerative brain
disorder, which results in significant cognitive impairments, especially in the
elderly population. Cognitive impairments can manifest as a decline in various
mental faculties, such as concentration, memory, and other higher-order
cognitive abilities. These deficits can significantly impact an individual's
capacity to comprehend information, acquire new knowledge, and communicate
effectively. One of the affected activities due to cognitive impairments is
handwriting. By analyzing different aspects of handwriting, including pressure,
velocity, and spatial organization, researchers can detect subtle alterations
that might indicate early-stage cognitive impairments, especially AD. Recently,
several classical artificial intelligence (AI) approaches have been proposed
for detecting AD in elderly individuals through handwriting analysis. However,
advanced AI methods require more computational power as the size of the data
increases. Additionally, diagnoses can be influenced by factors such as limited
relevant classical vector space and correlations between features. Recent
studies have shown that using quantum computing technologies in healthcare can
not only address these problems but also accelerate complex data analysis and
process large datasets more efficiently. In this study, we introduced a
variational quantum classifier with fewer circuit elements to facilitate the
early diagnosis of AD in elderly individuals based on handwriting data. We
employed ZZFeatureMap for encoding features. To classify AD, a parameterized
quantum circuit consisting of repeated Ry and Rz rotation gates, as well as CY
and CZ two-qubit entangling gates, was designed and implemented. The proposed
model achieved an accuracy of 0.75 in classifying AD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06699">A Closed-form Solution for Weight Optimization in Fully-connected Feed-forward Neural Networks. (arXiv:2401.06699v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tomic_S/0/1/0/all/0/1">Slavisa Tomic</a>, <a href="http://arxiv.org/find/cs/1/au:+Matos_Carvalho_J/0/1/0/all/0/1">Jo&#xe3;o Pedro Matos-Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Beko_M/0/1/0/all/0/1">Marko Beko</a></p>
<p>This work addresses weight optimization problem for fully-connected
feed-forward neural networks. Unlike existing approaches that are based on
back-propagation (BP) and chain rule gradient-based optimization (which implies
iterative execution, potentially burdensome and time-consuming in some cases),
the proposed approach offers the solution for weight optimization in
closed-form by means of least squares (LS) methodology. In the case where the
input-to-output mapping is injective, the new approach optimizes the weights in
a back-propagating fashion in a single iteration by jointly optimizing a set of
weights in each layer for each neuron. In the case where the input-to-output
mapping is not injective (e.g., in classification problems), the proposed
solution is easily adapted to obtain its final solution in a few iterations. An
important advantage over the existing solutions is that these computations (for
all neurons in a layer) are independent from each other; thus, they can be
carried out in parallel to optimize all weights in a given layer
simultaneously. Furthermore, its running time is deterministic in the sense
that one can obtain the exact number of computations necessary to optimize the
weights in all network layers (per iteration, in the case of non-injective
mapping). Our simulation and empirical results show that the proposed scheme,
BPLS, works well and is competitive with existing ones in terms of accuracy,
but significantly surpasses them in terms of running time. To summarize, the
new method is straightforward to implement, is competitive and computationally
more efficient than the existing ones, and is well-tailored for parallel
implementation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06710">Model-Free Approximate Bayesian Learning for Large-Scale Conversion Funnel Optimization. (arXiv:2401.06710v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Iyengar_G/0/1/0/all/0/1">Garud Iyengar</a>, <a href="http://arxiv.org/find/cs/1/au:+Singal_R/0/1/0/all/0/1">Raghav Singal</a></p>
<p>The flexibility of choosing the ad action as a function of the consumer state
is critical for modern-day marketing campaigns. We study the problem of
identifying the optimal sequential personalized interventions that maximize the
adoption probability for a new product. We model consumer behavior by a
conversion funnel that captures the state of each consumer (e.g., interaction
history with the firm) and allows the consumer behavior to vary as a function
of both her state and firm's sequential interventions. We show our model
captures consumer behavior with very high accuracy (out-of-sample AUC of over
0.95) in a real-world email marketing dataset. However, it results in a very
large-scale learning problem, where the firm must learn the state-specific
effects of various interventions from consumer interactions. We propose a novel
attribution-based decision-making algorithm for this problem that we call
model-free approximate Bayesian learning. Our algorithm inherits the
interpretability and scalability of Thompson sampling for bandits and maintains
an approximate belief over the value of each state-specific intervention. The
belief is updated as the algorithm interacts with the consumers. Despite being
an approximation to the Bayes update, we prove the asymptotic optimality of our
algorithm and analyze its convergence rate. We show that our algorithm
significantly outperforms traditional approaches on extensive simulations
calibrated to a real-world email marketing dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06712">Few-Shot Detection of Machine-Generated Text using Style Representations. (arXiv:2401.06712v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Soto_R/0/1/0/all/0/1">Rafael Rivera Soto</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_K/0/1/0/all/0/1">Kailin Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Aleem Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Barry Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bishop_M/0/1/0/all/0/1">Marcus Bishop</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrews_N/0/1/0/all/0/1">Nicholas Andrews</a></p>
<p>The advent of instruction-tuned language models that convincingly mimic human
writing poses a significant risk of abuse. For example, such models could be
used for plagiarism, disinformation, spam, or phishing. However, such abuse may
be counteracted with the ability to detect whether a piece of text was composed
by a language model rather than a human. Some previous approaches to this
problem have relied on supervised methods trained on corpora of confirmed human
and machine-written documents. Unfortunately, model under-specification poses
an unavoidable challenge for neural network-based detectors, making them
brittle in the face of data shifts, such as the release of further language
models producing still more fluent text than the models used to train the
detectors. Other previous approaches require access to the models that may have
generated a document in question at inference or detection time, which is often
impractical. In light of these challenges, we pursue a fundamentally different
approach not relying on samples from language models of concern at training
time. Instead, we propose to leverage representations of writing style
estimated from human-authored text. Indeed, we find that features effective at
distinguishing among human authors are also effective at distinguishing human
from machine authors, including state of the art large language models like
Llama 2, ChatGPT, and GPT-4. Furthermore, given a handful of examples composed
by each of several specific language models of interest, our approach affords
the ability to predict which model generated a given document.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06727">Deep Manifold Graph Auto-Encoder for Attributed Graph Embedding. (arXiv:2401.06727v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bozhen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1">Zelin Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1">Jun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheng Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a></p>
<p>Representing graph data in a low-dimensional space for subsequent tasks is
the purpose of attributed graph embedding. Most existing neural network
approaches learn latent representations by minimizing reconstruction errors.
Rare work considers the data distribution and the topological structure of
latent codes simultaneously, which often results in inferior embeddings in
real-world graph data. This paper proposes a novel Deep Manifold (Variational)
Graph Auto-Encoder (DMVGAE/DMGAE) method for attributed graph data to improve
the stability and quality of learned representations to tackle the crowding
problem. The node-to-node geodesic similarity is preserved between the original
and latent space under a pre-defined distribution. The proposed method
surpasses state-of-the-art baseline algorithms by a significant margin on
different downstream tasks across popular datasets, which validates our
solutions. We promise to release the code after acceptance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06738">Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Dang_A/0/1/0/all/0/1">Anh Dang</a>, <a href="http://arxiv.org/find/math/1/au:+Babanezhad_R/0/1/0/all/0/1">Reza Babanezhad</a>, <a href="http://arxiv.org/find/math/1/au:+Vaswani_S/0/1/0/all/0/1">Sharan Vaswani</a></p>
<p>We analyze the convergence of stochastic heavy ball (SHB) momentum in the
smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with
small mini-batches) cannot attain an accelerated rate of convergence even for
quadratics, and conjecture that the practical gain of SHB is a by-product of
mini-batching. We substantiate this claim by showing that SHB can obtain an
accelerated rate when the mini-batch size is larger than some threshold. In
particular, for strongly-convex quadratics with condition number $\kappa$, we
prove that SHB with the standard step-size and momentum parameters results in
an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence rate,
where $T$ is the number of iterations and $\sigma^2$ is the variance in the
stochastic gradients. To ensure convergence to the minimizer, we propose a
multi-stage approach that results in a noise-adaptive
$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$
rate. For general strongly-convex functions, we use the averaging
interpretation of SHB along with exponential step-sizes to prove an
$O\left(\exp\left(-\frac{T}{\kappa} \right) + \frac{\sigma^2}{T} \right)$
convergence to the minimizer in a noise-adaptive manner. Finally, we
empirically demonstrate the effectiveness of the proposed algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06740">A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models. (arXiv:2401.06740v1 [q-fin.CP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Georgoulis_E/0/1/0/all/0/1">Emmanuil H. Georgoulis</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Papapantoleon_A/0/1/0/all/0/1">Antonis Papapantoleon</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Smaragdakis_C/0/1/0/all/0/1">Costas Smaragdakis</a></p>
<p>We develop a novel deep learning approach for pricing European basket options
written on assets that follow jump-diffusion dynamics. The option pricing
problem is formulated as a partial integro-differential equation, which is
approximated via a new implicit-explicit minimizing movement time-stepping
approach, involving approximation by deep, residual-type Artificial Neural
Networks (ANNs) for each time step. The integral operator is discretized via
two different approaches: a) a sparse-grid Gauss--Hermite approximation
following localised coordinate axes arising from singular value decompositions,
and b) an ANN-based high-dimensional special-purpose quadrature rule.
Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of
the solution for large values of the underlyings and also leads to consistent
outputs with respect to a priori known qualitative properties of the solution.
The performance and robustness with respect to the dimension of the methods are
assessed in a series of numerical experiments involving the Merton
jump-diffusion model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06751">The Unreasonable Effectiveness of Easy Training Data for Hard Tasks. (arXiv:2401.06751v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1">Peter Hase</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1">Peter Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiegreffe_S/0/1/0/all/0/1">Sarah Wiegreffe</a></p>
<p>How can we train models to perform well on hard test data when hard training
data is by definition difficult to label correctly? This question has been
termed the scalable oversight problem and has drawn increasing attention as
language models have continually improved. In this paper, we present the
surprising conclusion that current language models often generalize relatively
well from easy to hard data, even performing as well as "oracle" models trained
on hard data. We demonstrate this kind of easy-to-hard generalization using
simple training methods like in-context learning, linear classifier heads, and
QLoRA for seven different measures of datapoint hardness, including six
empirically diverse human hardness measures (like grade level) and one
model-based measure (loss-based). Furthermore, we show that even if one cares
most about model performance on hard data, it can be better to collect and
train on easy data rather than hard data, since hard data is generally noisier
and costlier to collect. Our experiments use open models up to 70b in size and
four publicly available question-answering datasets with questions ranging in
difficulty from 3rd grade science questions to college level STEM questions and
general-knowledge trivia. We conclude that easy-to-hard generalization in LMs
is surprisingly strong for the tasks studied, suggesting the scalable oversight
problem may be easier than previously thought. Our code is available at
https://github.com/allenai/easy-to-hard-generalization
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06755">Solving the Discretised Multiphase Flow Equations with Interface Capturing on Structured Grids Using Machine Learning Libraries. (arXiv:2401.06755v1 [physics.flu-dyn])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Chen_B/0/1/0/all/0/1">Boyang Chen</a>, <a href="http://arxiv.org/find/physics/1/au:+Heaney_C/0/1/0/all/0/1">Claire E. Heaney</a>, <a href="http://arxiv.org/find/physics/1/au:+Gomes_J/0/1/0/all/0/1">Jefferson L. M. A. Gomes</a>, <a href="http://arxiv.org/find/physics/1/au:+Matar_O/0/1/0/all/0/1">Omar K. Matar</a>, <a href="http://arxiv.org/find/physics/1/au:+Pain_C/0/1/0/all/0/1">Christopher C. Pain</a></p>
<p>This paper solves the multiphase flow equations with interface capturing
using the AI4PDEs approach (Artificial Intelligence for Partial Differential
Equations). The solver within AI4PDEs uses tools from machine learning (ML)
libraries to solve (exactly) partial differential equations (PDEs) that have
been discretised using numerical methods. Convolutional layers can be used to
express the discretisations as a neural network, whose weights are determined
by the numerical method, rather than by training. To solve the system, a
multigrid solver is implemented through a neural network with a U-Net
architecture. Immiscible two-phase flow is modelled by the 3D incompressible
Navier-Stokes equations with surface tension and advection of a volume fraction
field, which describes the interface between the fluids. A new compressive
algebraic volume-of-fluids method is introduced, based on a residual
formulation using Petrov-Galerkin for accuracy and designed with AI4PDEs in
mind. High-order finite-element based schemes are chosen to model a collapsing
water column and a rising bubble. Results compare well with experimental data
and other numerical results from the literature, demonstrating that, for the
first time, finite element discretisations of multiphase flows can be solved
using the neural network solver from the AI4PDEs approach. A benefit of
expressing numerical discretisations as neural networks is that the code can
run, without modification, on CPUs, GPUs or the latest accelerators designed
especially to run AI codes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06757">Synthetic Data Generation Framework, Dataset, and Efficient Deep Model for Pedestrian Intention Prediction. (arXiv:2401.06757v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Riaz_M/0/1/0/all/0/1">Muhammad Naveed Riaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Wielgosz_M/0/1/0/all/0/1">Maciej Wielgosz</a>, <a href="http://arxiv.org/find/cs/1/au:+Romera_A/0/1/0/all/0/1">Abel Garcia Romera</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1">Antonio M. Lopez</a></p>
<p>Pedestrian intention prediction is crucial for autonomous driving. In
particular, knowing if pedestrians are going to cross in front of the
ego-vehicle is core to performing safe and comfortable maneuvers. Creating
accurate and fast models that predict such intentions from sequential images is
challenging. A factor contributing to this is the lack of datasets with diverse
crossing and non-crossing (C/NC) scenarios. We address this scarceness by
introducing a framework, named ARCANE, which allows programmatically generating
synthetic datasets consisting of C/NC video clip samples. As an example, we use
ARCANE to generate a large and diverse dataset named PedSynth. We will show how
PedSynth complements widely used real-world datasets such as JAAD and PIE, so
enabling more accurate models for C/NC prediction. Considering the onboard
deployment of C/NC prediction models, we also propose a deep model named
PedGNN, which is fast and has a very low memory footprint. PedGNN is based on a
GNN-GRU architecture that takes a sequence of pedestrian skeletons as input to
predict crossing intentions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06762">Seeing the roads through the trees: A benchmark for modeling spatial dependencies with aerial imagery. (arXiv:2401.06762v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Robinson_C/0/1/0/all/0/1">Caleb Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Corley_I/0/1/0/all/0/1">Isaac Corley</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortiz_A/0/1/0/all/0/1">Anthony Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1">Juan M. Lavista Ferres</a>, <a href="http://arxiv.org/find/cs/1/au:+Najafirad_P/0/1/0/all/0/1">Peyman Najafirad</a></p>
<p>Fully understanding a complex high-resolution satellite or aerial imagery
scene often requires spatial reasoning over a broad relevant context. The human
object recognition system is able to understand object in a scene over a
long-range relevant context. For example, if a human observes an aerial scene
that shows sections of road broken up by tree canopy, then they will be
unlikely to conclude that the road has actually been broken up into disjoint
pieces by trees and instead think that the canopy of nearby trees is occluding
the road. However, there is limited research being conducted to understand
long-range context understanding of modern machine learning models. In this
work we propose a road segmentation benchmark dataset, Chesapeake Roads Spatial
Context (RSC), for evaluating the spatial long-range context understanding of
geospatial machine learning models and show how commonly used semantic
segmentation models can fail at this task. For example, we show that a U-Net
trained to segment roads from background in aerial imagery achieves an 84%
recall on unoccluded roads, but just 63.5% recall on roads covered by tree
canopy despite being trained to model both the same way. We further analyze how
the performance of models changes as the relevant context for a decision
(unoccluded roads in our case) varies in distance. We release the code to
reproduce our experiments and dataset of imagery and masks to encourage future
research in this direction -- https://github.com/isaaccorley/ChesapeakeRSC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1908.01135">Multiplayer Bandit Learning, from Competition to Cooperation. (arXiv:1908.01135v4 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Branzei_S/0/1/0/all/0/1">Simina Br&#xe2;nzei</a>, <a href="http://arxiv.org/find/cs/1/au:+Peres_Y/0/1/0/all/0/1">Yuval Peres</a></p>
<p>The stochastic multi-armed bandit model captures the tradeoff between
exploration and exploitation. We study the effects of competition and
cooperation on this tradeoff. Suppose there are $k$ arms and two players, Alice
and Bob. In every round, each player pulls an arm, receives the resulting
reward, and observes the choice of the other player but not their reward.
Alice's utility is $\Gamma_A + \lambda \Gamma_B$ (and similarly for Bob), where
$\Gamma_A$ is Alice's total reward and $\lambda \in [-1, 1]$ is a cooperation
parameter. At $\lambda = -1$ the players are competing in a zero-sum game, at
$\lambda = 1$, they are fully cooperating, and at $\lambda = 0$, they are
neutral: each player's utility is their own reward. The model is related to the
economics literature on strategic experimentation, where usually players
observe each other's rewards.
</p>
<p>With discount factor $\beta$, the Gittins index reduces the one-player
problem to the comparison between a risky arm, with a prior $\mu$, and a
predictable arm, with success probability $p$. The value of $p$ where the
player is indifferent between the arms is the Gittins index $g = g(\mu,\beta) &gt;
m$, where $m$ is the mean of the risky arm.
</p>
<p>We show that competing players explore less than a single player: there is
$p^* \in (m, g)$ so that for all $p &gt; p^*$, the players stay at the predictable
arm. However, the players are not myopic: they still explore for some $p &gt; m$.
On the other hand, cooperating players explore more than a single player. We
also show that neutral players learn from each other, receiving strictly higher
total rewards than they would playing alone, for all $ p\in (p^*, g)$, where
$p^*$ is the threshold from the competing case.
</p>
<p>Finally, we show that competing and neutral players eventually settle on the
same arm in every Nash equilibrium, while this can fail for cooperating
players.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2007.12882">A finite sample analysis of the benign overfitting phenomenon for ridge function estimation. (arXiv:2007.12882v5 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Caron_E/0/1/0/all/0/1">Emmanuel Caron</a>, <a href="http://arxiv.org/find/stat/1/au:+Chretien_S/0/1/0/all/0/1">Stephane Chretien</a></p>
<p>Recent extensive numerical experiments in high scale machine learning have
allowed to uncover a quite counterintuitive phase transition, as a function of
the ratio between the sample size and the number of parameters in the model. As
the number of parameters $p$ approaches the sample size $n$, the generalisation
error increases, but surprisingly, it starts decreasing again past the
threshold $p=n$. This phenomenon, brought to the theoretical community
attention in \cite{belkin2019reconciling}, has been thoroughly investigated
lately, more specifically for simpler models than deep neural networks, such as
the linear model when the parameter is taken to be the minimum norm solution to
the least-squares problem, firstly in the asymptotic regime when $p$ and $n$
tend to infinity, see e.g. \cite{hastie2019surprises}, and recently in the
finite dimensional regime and more specifically for linear models
\cite{bartlett2020benign}, \cite{tsigler2020benign},
\cite{lecue2022geometrical}. In the present paper, we propose a finite sample
analysis of non-linear models of \textit{ridge} type, where we investigate the
\textit{overparametrised regime} of the double descent phenomenon for both the
\textit{estimation problem} and the \textit{prediction} problem. Our results
provide a precise analysis of the distance of the best estimator from the true
parameter as well as a generalisation bound which complements recent works of
\cite{bartlett2020benign} and \cite{chinot2020benign}. Our analysis is based on
tools closely related to the continuous Newton method
\cite{neuberger2007continuous} and a refined quantitative analysis of the
performance in prediction of the minimum $\ell_2$-norm solution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.06147">NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1">Jerome Abdelnour</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1">Jean Rouat</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1">Giampiero Salvi</a></p>
<p>The goal of the Acoustic Question Answering (AQA) task is to answer a
free-form text question about the content of an acoustic scene. It was inspired
by the Visual Question Answering (VQA) task. In this paper, based on the
previously introduced CLEAR dataset, we propose a new benchmark for AQA, namely
CLEAR2, that emphasizes the specific challenges of acoustic inputs. These
include handling of variable duration scenes, and scenes built with elementary
sounds that differ between training and test set. We also introduce NAAQA, a
neural architecture that leverages specific properties of acoustic inputs. The
use of 1D convolutions in time and frequency to process 2D spectro-temporal
representations of acoustic content shows promising results and enables
reductions in model complexity. We show that time coordinate maps augment
temporal localization capabilities which enhance performance of the network by
~17 percentage points. On the other hand, frequency coordinate maps have little
influence on this task. NAAQA achieves 79.5% of accuracy on the AQA task with
~4 times fewer parameters than the previously explored VQA model. We evaluate
the perfomance of NAAQA on an independent data set reconstructed from DAQA. We
also test the addition of a MALiMo module in our model on both CLEAR2 and DAQA.
We provide a detailed analysis of the results for the different question types.
We release the code to produce CLEAR2 as well as NAAQA to foster research in
this newly emerging machine learning task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.02381">Robust Peak Detection for Holter ECGs by Self-Organized Operational Neural Networks. (arXiv:2110.02381v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a>, <a href="http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1">Serkan Kiranyaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Malik_J/0/1/0/all/0/1">Junaid Malik</a>, <a href="http://arxiv.org/find/eess/1/au:+Zahid_M/0/1/0/all/0/1">Muhammad Uzair Zahid</a>, <a href="http://arxiv.org/find/eess/1/au:+Ince_T/0/1/0/all/0/1">Turker Ince</a>, <a href="http://arxiv.org/find/eess/1/au:+Chowdhury_M/0/1/0/all/0/1">Muhammad Chowdhury</a>, <a href="http://arxiv.org/find/eess/1/au:+Khandakar_A/0/1/0/all/0/1">Amith Khandakar</a>, <a href="http://arxiv.org/find/eess/1/au:+Tahir_A/0/1/0/all/0/1">Anas Tahir</a></p>
<p>Although numerous R-peak detectors have been proposed in the literature,
their robustness and performance levels may significantly deteriorate in
low-quality and noisy signals acquired from mobile electrocardiogram (ECG)
sensors, such as Holter monitors. Recently, this issue has been addressed by
deep 1-D convolutional neural networks (CNNs) that have achieved
state-of-the-art performance levels in Holter monitors; however, they pose a
high complexity level that requires special parallelized hardware setup for
real-time processing. On the other hand, their performance deteriorates when a
compact network configuration is used instead. This is an expected outcome as
recent studies have demonstrated that the learning performance of CNNs is
limited due to their strictly homogenous configuration with the sole linear
neuron model. In this study, to further boost the peak detection performance
along with an elegant computational efficiency, we propose 1-D Self-Organized
ONNs (Self-ONNs) with generative neurons. The most crucial advantage of 1-D
Self-ONNs over the ONNs is their self-organization capability that voids the
need to search for the best operator set per neuron since each generative
neuron has the ability to create the optimal operator during training. The
experimental results over the China Physiological Signal Challenge-2020 (CPSC)
dataset with more than one million ECG beats show that the proposed 1-D
Self-ONNs can significantly surpass the state-of-the-art deep CNN with less
computational complexity. Results demonstrate that the proposed solution
achieves a 99.10% F1-score, 99.79% sensitivity, and 98.42% positive
predictivity in the CPSC dataset, which is the best R-peak detection
performance ever achieved.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.00832">Gradient Descent, Stochastic Optimization, and Other Tales. (arXiv:2205.00832v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a></p>
<p>The goal of this paper is to debunk and dispel the magic behind black-box
optimizers and stochastic optimizers. It aims to build a solid foundation on
how and why the techniques work. This manuscript crystallizes this knowledge by
deriving from simple intuitions, the mathematics behind the strategies. This
tutorial doesn't shy away from addressing both the formal and informal aspects
of gradient descent and stochastic optimization methods. By doing so, it hopes
to provide readers with a deeper understanding of these techniques as well as
the when, the how and the why of applying these algorithms.
</p>
<p>Gradient descent is one of the most popular algorithms to perform
optimization and by far the most common way to optimize machine learning tasks.
Its stochastic version receives attention in recent years, and this is
particularly true for optimizing deep neural networks. In deep neural networks,
the gradient followed by a single sample or a batch of samples is employed to
save computational resources and escape from saddle points. In 1951, Robbins
and Monro published \textit{A stochastic approximation method}, one of the
first modern treatments on stochastic optimization that estimates local
gradients with a new batch of samples. And now, stochastic optimization has
become a core technology in machine learning, largely due to the development of
the back propagation algorithm in fitting a neural network. The sole aim of
this article is to give a self-contained introduction to concepts and
mathematical tools in gradient descent and stochastic optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.11892">DDPM-CD: Denoising Diffusion Probabilistic Models as Feature Extractors for Change Detection. (arXiv:2206.11892v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1">Wele Gedara Chaminda Bandara</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_N/0/1/0/all/0/1">Nithin Gopalakrishnan Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a></p>
<p>Remote sensing change detection is crucial for understanding the dynamics of
our planet's surface, facilitating the monitoring of environmental changes,
evaluating human impact, predicting future trends, and supporting
decision-making. In this work, we introduce a novel approach for change
detection that can leverage off-the-shelf, unlabeled remote sensing images in
the training process by pre-training a Denoising Diffusion Probabilistic Model
(DDPM) - a class of generative models used in image synthesis. DDPMs learn the
training data distribution by gradually converting training images into a
Gaussian distribution using a Markov chain. During inference (i.e., sampling),
they can generate a diverse set of samples closer to the training distribution,
starting from Gaussian noise, achieving state-of-the-art image synthesis
results. However, in this work, our focus is not on image synthesis but on
utilizing it as a pre-trained feature extractor for the downstream application
of change detection. Specifically, we fine-tune a lightweight change classifier
utilizing the feature representations produced by the pre-trained DDPM
alongside change labels. Experiments conducted on the LEVIR-CD, WHU-CD,
DSIFN-CD, and CDD datasets demonstrate that the proposed DDPM-CD method
significantly outperforms the existing state-of-the-art change detection
methods in terms of F1 score, IoU, and overall accuracy, highlighting the
pivotal role of pre-trained DDPM as a feature extractor for downstream
applications. We have made both the code and pre-trained models available at
https://github.com/wgcban/ddpm-cd
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.07898">Collaborative causal inference on distributed data. (arXiv:2208.07898v5 [stat.ME] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kawamata_Y/0/1/0/all/0/1">Yuji Kawamata</a>, <a href="http://arxiv.org/find/stat/1/au:+Motai_R/0/1/0/all/0/1">Ryoki Motai</a>, <a href="http://arxiv.org/find/stat/1/au:+Okada_Y/0/1/0/all/0/1">Yukihiko Okada</a>, <a href="http://arxiv.org/find/stat/1/au:+Imakura_A/0/1/0/all/0/1">Akira Imakura</a>, <a href="http://arxiv.org/find/stat/1/au:+Sakurai_T/0/1/0/all/0/1">Tetsuya Sakurai</a></p>
<p>In recent years, the development of technologies for causal inference with
privacy preservation of distributed data has gained considerable attention.
Many existing methods for distributed data focus on resolving the lack of
subjects (samples) and can only reduce random errors in estimating treatment
effects. In this study, we propose a data collaboration quasi-experiment
(DC-QE) that resolves the lack of both subjects and covariates, reducing random
errors and biases in the estimation. Our method involves constructing
dimensionality-reduced intermediate representations from private data from
local parties, sharing intermediate representations instead of private data for
privacy preservation, estimating propensity scores from the shared intermediate
representations, and finally, estimating the treatment effects from propensity
scores. Through numerical experiments on both artificial and real-world data,
we confirm that our method leads to better estimation results than individual
analyses. While dimensionality reduction loses some information in the private
data and causes performance degradation, we observe that sharing intermediate
representations with many parties to resolve the lack of subjects and
covariates sufficiently improves performance to overcome the degradation caused
by dimensionality reduction. Although external validity is not necessarily
guaranteed, our results suggest that DC-QE is a promising method. With the
widespread use of our method, intermediate representations can be published as
open data to help researchers find causalities and accumulate a knowledge base.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.15573">Convergence of weak-SINDy Surrogate Models. (arXiv:2209.15573v3 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Russo_B/0/1/0/all/0/1">Benjamin Russo</a>, <a href="http://arxiv.org/find/math/1/au:+Laiu_M/0/1/0/all/0/1">M. Paul Laiu</a></p>
<p>In this paper, we give an in-depth error analysis for surrogate models
generated by a variant of the Sparse Identification of Nonlinear Dynamics
(SINDy) method. We start with an overview of a variety of non-linear system
identification techniques, namely, SINDy, weak-SINDy, and the occupation kernel
method. Under the assumption that the dynamics are a finite linear combination
of a set of basis functions, these methods establish a matrix equation to
recover coefficients. We illuminate the structural similarities between these
techniques and establish a projection property for the weak-SINDy technique.
Following the overview, we analyze the error of surrogate models generated by a
simplified version of weak-SINDy. In particular, under the assumption of
boundedness of a composition operator given by the solution, we show that (i)
the surrogate dynamics converges towards the true dynamics and (ii) the
solution of the surrogate model is reasonably close to the true solution.
Finally, as an application, we discuss the use of a combination of weak-SINDy
surrogate modeling and proper orthogonal decomposition (POD) to build a
surrogate model for partial differential equations (PDEs).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.02091">Tripletformer for Probabilistic Interpolation of Irregularly sampled Time Series. (arXiv:2210.02091v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yalavarthi_V/0/1/0/all/0/1">Vijaya Krishna Yalavarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Burchert_J/0/1/0/all/0/1">Johannes Burchert</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_thieme_L/0/1/0/all/0/1">Lars Schmidt-thieme</a></p>
<p>Irregularly sampled time series data with missing values is observed in many
fields like healthcare, astronomy, and climate science. Interpolation of these
types of time series is crucial for tasks such as root cause analysis and
medical diagnosis, as well as for smoothing out irregular or noisy data. To
address this challenge, we present a novel encoder-decoder architecture called
"Tripletformer" for probabilistic interpolation of irregularly sampled time
series with missing values. This attention-based model operates on sets of
observations, where each element is composed of a triple of time, channel, and
value. The encoder and decoder of the Tripletformer are designed with attention
layers and fully connected layers, enabling the model to effectively process
the presented set elements. We evaluate the Tripletformer against a range of
baselines on multiple real-world and synthetic datasets and show that it
produces more accurate and certain interpolations. Results indicate an
improvement in negative loglikelihood error by up to 32% on real-world datasets
and 85% on synthetic datasets when using the Tripletformer compared to the next
best model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.06015">EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. (arXiv:2210.06015v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bakhtiarifard_P/0/1/0/all/0/1">Pedram Bakhtiarifard</a>, <a href="http://arxiv.org/find/cs/1/au:+Igel_C/0/1/0/all/0/1">Christian Igel</a>, <a href="http://arxiv.org/find/cs/1/au:+Selvan_R/0/1/0/all/0/1">Raghavendra Selvan</a></p>
<p>Energy consumption from the selection, training, and deployment of deep
learning models has seen a significant uptick recently. This work aims to
facilitate the design of energy-efficient deep learning models that require
less computational resources and prioritize environmental sustainability by
focusing on the energy consumption. Neural architecture search (NAS) benefits
from tabular benchmarks, which evaluate NAS strategies cost-effectively through
precomputed performance statistics. We advocate for including energy efficiency
as an additional performance criterion in NAS. To this end, we introduce an
enhanced tabular benchmark encompassing data on energy consumption for varied
architectures. The benchmark, designated as EC-NAS, has been made available in
an open-source format to advance research in energy-conscious NAS. EC-NAS
incorporates a surrogate model to predict energy consumption, aiding in
diminishing the energy expenditure of the dataset creation. Our findings
emphasize the potential of EC-NAS by leveraging multi-objective optimization
algorithms, revealing a balance between energy usage and accuracy. This
suggests the feasibility of identifying energy-lean architectures with little
or no compromise in performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.05408">Controlling Moments with Kernel Stein Discrepancies. (arXiv:2211.05408v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kanagawa_H/0/1/0/all/0/1">Heishiro Kanagawa</a>, <a href="http://arxiv.org/find/stat/1/au:+Barp_A/0/1/0/all/0/1">Alessandro Barp</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>, <a href="http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a></p>
<p>Kernel Stein discrepancies (KSDs) measure the quality of a distributional
approximation and can be computed even when the target density has an
intractable normalizing constant. Notable applications include the diagnosis of
approximate MCMC samplers and goodness-of-fit tests for unnormalized
statistical models. The present work analyzes the convergence control
properties of KSDs. We first show that standard KSDs used for weak convergence
control fail to control moment convergence. To address this limitation, we next
provide sufficient conditions under which alternative diffusion KSDs control
both moment and weak convergence. As an immediate consequence we develop, for
each $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wasserstein
convergence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.07946">Active Inference and Reinforcement Learning: A unified inference on continuous state and action spaces under partially observability. (arXiv:2212.07946v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malekzadeh_P/0/1/0/all/0/1">Parvin Malekzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1">Konstantinos N. Plataniotis</a></p>
<p>Reinforcement learning (RL) has garnered significant attention for developing
decision-making agents that aim to maximize rewards, specified by an external
supervisor, within fully observable environments. However, many real-world
problems involve partial observations, formulated as partially observable
Markov decision processes (POMDPs). Previous studies have tackled RL in POMDPs
by either incorporating the memory of past actions and observations or by
inferring the true state of the environment from observed data. However,
aggregating observed data over time becomes impractical in continuous spaces.
Moreover, inference-based RL approaches often require many samples to perform
well, as they focus solely on reward maximization and neglect uncertainty in
the inferred state. Active inference (AIF) is a framework formulated in POMDPs
and directs agents to select actions by minimizing a function called expected
free energy (EFE). This supplies reward-maximizing (exploitative) behaviour, as
in RL, with information-seeking (exploratory) behaviour. Despite this
exploratory behaviour of AIF, its usage is limited to discrete spaces due to
the computational challenges associated with EFE. In this paper, we propose a
unified principle that establishes a theoretical connection between AIF and RL,
enabling seamless integration of these two approaches and overcoming their
aforementioned limitations in continuous space POMDP settings. We substantiate
our findings with theoretical analysis, providing novel perspectives for
utilizing AIF in the design of artificial agents. Experimental results
demonstrate the superior learning capabilities of our method in solving
continuous space partially observable tasks. Notably, our approach harnesses
information-seeking exploration, enabling it to effectively solve reward-free
problems and rendering explicit task reward design by an external supervisor
optional.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.05910">Product Jacobi-Theta Boltzmann machines with score matching. (arXiv:2303.05910v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Pasquale_A/0/1/0/all/0/1">Andrea Pasquale</a>, <a href="http://arxiv.org/find/stat/1/au:+Krefl_D/0/1/0/all/0/1">Daniel Krefl</a>, <a href="http://arxiv.org/find/stat/1/au:+Carrazza_S/0/1/0/all/0/1">Stefano Carrazza</a>, <a href="http://arxiv.org/find/stat/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a></p>
<p>The estimation of probability density functions is a non trivial task that
over the last years has been tackled with machine learning techniques.
Successful applications can be obtained using models inspired by the Boltzmann
machine (BM) architecture. In this manuscript, the product Jacobi-Theta
Boltzmann machine (pJTBM) is introduced as a restricted version of the
Riemann-Theta Boltzmann machine (RTBM) with diagonal hidden sector connection
matrix. We show that score matching, based on the Fisher divergence, can be
used to fit probability densities with the pJTBM more efficiently than with the
original RTBM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.15954">TraffNet: Learning Causality of Traffic Generation for What-if Prediction. (arXiv:2303.15954v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Ming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qiang Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruimin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yunyi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Geqi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1">Xiangfu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Haibo Jin</a></p>
<p>Real-time what-if traffic prediction is crucial for decision making in
intelligent traffic management and control. Although current deep learning
methods demonstrate significant advantages in traffic prediction, they are
powerless in what-if traffic prediction due to their nature of
correlation-based. Here, we present a simple deep learning framework called
TraffNet that learns the mechanisms of traffic generation for what-if
prediction from vehicle trajectory data. First, we use a heterogeneous graph to
represent the road network, allowing the model to incorporate causal features
of traffic flows, such as Origin-Destination (OD) demands and routes. Next, we
propose a method for learning segment representations, which involves modeling
the process of assigning OD demands onto the road network. The learned segment
representations effectively encapsulate the intricate causes of traffic
generation, facilitating downstream what-if traffic prediction. Finally, we
conduct experiments on synthetic datasets to evaluate the effectiveness of
TraffNet. The code and datasets of TraffNet is available at
https://github.com/mayunyi-1999/TraffNet_code.git.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16372">On the Query Complexity of Training Data Reconstruction in Private Learning. (arXiv:2303.16372v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_P/0/1/0/all/0/1">Prateeti Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lokam_S/0/1/0/all/0/1">Satya Lokam</a></p>
<p>We analyze the number of queries that a whitebox adversary needs to make to a
private learner in order to reconstruct its training data. For $(\epsilon,
\delta)$ DP learners with training data drawn from any arbitrary compact metric
space, we provide the \emph{first known lower bounds on the adversary's query
complexity} as a function of the learner's privacy parameters. \emph{Our
results are minimax optimal for every $\epsilon \geq 0, \delta \in [0, 1]$,
covering both $\epsilon$-DP and $(0, \delta)$ DP as corollaries}. Beyond this,
we obtain query complexity lower bounds for $(\alpha, \epsilon)$ R\'enyi DP
learners that are valid for any $\alpha &gt; 1, \epsilon \geq 0$. Finally, we
analyze data reconstruction attacks on locally compact metric spaces via the
framework of Metric DP, a generalization of DP that accounts for the underlying
metric structure of the data. In this setting, we provide the first known
analysis of data reconstruction in unbounded, high dimensional spaces and
obtain query complexity lower bounds that are nearly tight modulo logarithmic
factors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06686">OKRidge: Scalable Optimal k-Sparse Ridge Regression. (arXiv:2304.06686v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiachang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosen_S/0/1/0/all/0/1">Sam Rosen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1">Chudi Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudin_C/0/1/0/all/0/1">Cynthia Rudin</a></p>
<p>We consider an important problem in scientific discovery, namely identifying
sparse governing equations for nonlinear dynamical systems. This involves
solving sparse ridge regression problems to provable optimality in order to
determine which terms drive the underlying dynamics. We propose a fast
algorithm, OKRidge, for sparse ridge regression, using a novel lower bound
calculation involving, first, a saddle point formulation, and from there,
either solving (i) a linear system or (ii) using an ADMM-based approach, where
the proximal operators can be efficiently evaluated by solving another linear
system and an isotonic regression problem. We also propose a method to
warm-start our solver, which leverages a beam search. Experimentally, our
methods attain provable optimality with run times that are orders of magnitude
faster than those of the existing MIP formulations solved by the commercial
solver Gurobi.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06815">Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization). (arXiv:2304.06815v3 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahmed_T/0/1/0/all/0/1">Toufique Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_K/0/1/0/all/0/1">Kunal Suresh Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Devanbu_P/0/1/0/all/0/1">Premkumar Devanbu</a>, <a href="http://arxiv.org/find/cs/1/au:+Barr_E/0/1/0/all/0/1">Earl T. Barr</a></p>
<p>Large Language Models (LLM) are a new class of computation engines,
"programmed" via prompt engineering. We are still learning how to best
"program" these LLMs to help developers. We start with the intuition that
developers tend to consciously and unconsciously have a collection of semantics
facts in mind when working on coding tasks. Mostly these are shallow, simple
facts arising from a quick read. For a function, examples of facts might
include parameter and local variable names, return expressions, simple pre- and
post-conditions, and basic control and data flow, etc.
</p>
<p>One might assume that the powerful multi-layer architecture of
transformer-style LLMs makes them inherently capable of doing this simple level
of "code analysis" and extracting such information, implicitly, while
processing code: but are they, really? If they aren't, could explicitly adding
this information help? Our goal here is to investigate this question, using the
code summarization task and evaluate whether automatically augmenting an LLM's
prompt with semantic facts explicitly, actually helps.
</p>
<p>Prior work shows that LLM performance on code summarization benefits from
few-shot samples drawn either from the same-project or from examples found via
information retrieval methods (such as BM25). While summarization performance
has steadily increased since the early days, there is still room for
improvement: LLM performance on code summarization still lags its performance
on natural-language tasks like translation and text summarization.
</p>
<p>We find that adding semantic facts actually does help! This approach improves
performance in several different settings suggested by prior work, including
for two different Large Language Models. In most cases, improvement nears or
exceeds 2 BLEU; for the PHP language in the challenging CodeSearchNet dataset,
this augmentation actually yields performance surpassing 30 BLEU.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.07772">A Comprehensive Evaluation of Neural SPARQL Query Generation from Natural Language Questions. (arXiv:2304.07772v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Diallo_P/0/1/0/all/0/1">Papa Abdou Karim Karou Diallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Reyd_S/0/1/0/all/0/1">Samuel Reyd</a>, <a href="http://arxiv.org/find/cs/1/au:+Zouaq_A/0/1/0/all/0/1">Amal Zouaq</a></p>
<p>In recent years, the field of neural machine translation (NMT) for SPARQL
query generation has witnessed significant growth. Incorporating the copy
mechanism with traditional encoder-decoder architectures and using pre-trained
encoder-decoders and large language models have set new performance benchmarks.
This paper presents various experiments that replicate and expand upon recent
NMT-based SPARQL generation studies, comparing pre-trained language models
(PLMs), non-pre-trained language models (NPLMs), and large language models
(LLMs), highlighting the impact of question annotation and the copy mechanism
and testing various fine-tuning methods using LLMs. In particular, we provide a
systematic error analysis of the models and test their generalization ability.
Our study demonstrates that the copy mechanism yields significant performance
enhancements for most PLMs and NPLMs. Annotating the data is pivotal to
generating correct URIs, with the "tag-within" strategy emerging as the most
effective approach. Additionally, our findings reveal that the primary source
of errors stems from incorrect URIs in SPARQL queries that are sometimes
replaced with hallucinated URIs when using base models. This does not happen
using the copy mechanism, but it sometimes leads to selecting wrong URIs among
candidates. Finally, the performance of the tested LLMs fell short of achieving
the desired outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.08172">Pointwise convergence of Fourier series and deep neural network for the indicator function of d-dimensional ball. (arXiv:2304.08172v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kawasumi_R/0/1/0/all/0/1">Ryota Kawasumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoneda_T/0/1/0/all/0/1">Tsuyoshi Yoneda</a></p>
<p>In this paper we clarify the crucial difference between a deep neural network
and the Fourier series. For the multiple Fourier series of the periodization of
some radial functions on $\mathbb{R}^d$, Kuratsubo (2010) investigated the
behavior of the spherical partial sum, and discovered the third phenomenon
other than the well-known Gibbs-Wilbraham and Pinsky phenomena. In particular,
the third one exhibits prevention of pointwise convergence. In contrast to it,
we give a specific deep neural network and prove pointwise convergence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09853">Bridging RL Theory and Practice with the Effective Horizon. (arXiv:2304.09853v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1">Cassidy Laidlaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1">Stuart Russell</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca Dragan</a></p>
<p>Deep reinforcement learning (RL) works impressively in some environments and
fails catastrophically in others. Ideally, RL theory should be able to provide
an understanding of why this is, i.e. bounds predictive of practical
performance. Unfortunately, current theory does not quite have this ability. We
compare standard deep RL algorithms to prior sample complexity bounds by
introducing a new dataset, BRIDGE. It consists of 155 deterministic MDPs from
common deep RL benchmarks, along with their corresponding tabular
representations, which enables us to exactly compute instance-dependent bounds.
We choose to focus on deterministic environments because they share many
interesting properties of stochastic environments, but are easier to analyze.
Using BRIDGE, we find that prior bounds do not correlate well with when deep RL
succeeds vs. fails, but discover a surprising property that does. When actions
with the highest Q-values under the random policy also have the highest
Q-values under the optimal policy (i.e. when it is optimal to be greedy on the
random policy's Q function), deep RL tends to succeed; when they don't, deep RL
tends to fail. We generalize this property into a new complexity measure of an
MDP that we call the effective horizon, which roughly corresponds to how many
steps of lookahead search would be needed in that MDP in order to identify the
next optimal action, when leaf nodes are evaluated with random rollouts. Using
BRIDGE, we show that the effective horizon-based bounds are more closely
reflective of the empirical performance of PPO and DQN than prior sample
complexity bounds across four metrics. We also find that, unlike existing
bounds, the effective horizon can predict the effects of using reward shaping
or a pre-trained exploration policy. Our code and data are available at
https://github.com/cassidylaidlaw/effective-horizon
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16671">A Unified Approach for Maximizing Continuous DR-submodular Functions. (arXiv:2305.16671v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pedramfar_M/0/1/0/all/0/1">Mohammad Pedramfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1">Christopher John Quinn</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1">Vaneet Aggarwal</a></p>
<p>This paper presents a unified approach for maximizing continuous
DR-submodular functions that encompasses a range of settings and oracle access
types. Our approach includes a Frank-Wolfe type offline algorithm for both
monotone and non-monotone functions, with different restrictions on the general
convex set. We consider settings where the oracle provides access to either the
gradient of the function or only the function value, and where the oracle
access is either deterministic or stochastic. We determine the number of
required oracle accesses in all cases. Our approach gives new/improved results
for nine out of the sixteen considered cases, avoids computationally expensive
projections in two cases, with the proposed framework matching performance of
state-of-the-art approaches in the remaining five cases. Notably, our approach
for the stochastic function value-based oracle enables the first regret bounds
with bandit feedback for stochastic DR-submodular functions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19265">Probabilistic computation and uncertainty quantification with emerging covariance. (arXiv:2305.19265v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hengyuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yang Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wenlian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianfeng Feng</a></p>
<p>Building robust, interpretable, and secure AI system requires quantifying and
representing uncertainty under a probabilistic perspective to mimic human
cognitive abilities. However, probabilistic computation presents significant
challenges for most conventional artificial neural network, as they are
essentially implemented in a deterministic manner. In this paper, we develop an
efficient probabilistic computation framework by truncating the probabilistic
representation of neural activation up to its mean and covariance and construct
a moment neural network that encapsulates the nonlinear coupling between the
mean and covariance of the underlying stochastic network. We reveal that when
only the mean but not the covariance is supervised during gradient-based
learning, the unsupervised covariance spontaneously emerges from its nonlinear
coupling with the mean and faithfully captures the uncertainty associated with
model predictions. Our findings highlight the inherent simplicity of
probabilistic computation by seamlessly incorporating uncertainty into model
prediction, paving the way for integrating it into large-scale AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06251">Design Principles for Model Generalization and Scalable AI Integration in Radio Access Networks. (arXiv:2306.06251v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Soldati_P/0/1/0/all/0/1">Pablo Soldati</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghadimi_E/0/1/0/all/0/1">Euhanna Ghadimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1">Burak Demirel</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaigalas_R/0/1/0/all/0/1">Raimundas Gaigalas</a>, <a href="http://arxiv.org/find/cs/1/au:+Sintorn_M/0/1/0/all/0/1">Mathias Sintorn</a></p>
<p>Artificial intelligence (AI) has emerged as a powerful tool for addressing
complex and dynamic tasks in radio communication systems. Research in this
area, however, focused on AI solutions for specific, limited conditions,
hindering models from learning and adapting to generic situations, such as
those met across radio communication systems.
</p>
<p>This paper emphasizes the pivotal role of achieving model generalization in
enhancing performance and enabling scalable AI integration within radio
communications. We outline design principles for model generalization in three
key domains: environment for robustness, intents for adaptability to system
objectives, and control tasks for reducing AI-driven control loops.
Implementing these principles can decrease the number of models deployed and
increase adaptability in diverse radio communication environments. To address
the challenges of model generalization in communication systems, we propose a
learning architecture that leverages centralization of training and data
management functionalities, combined with distributed data generation. We
illustrate these concepts by designing a generalized link adaptation algorithm,
demonstrating the benefits of our proposed approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09910">LabelBench: A Comprehensive Framework for Benchmarking Adaptive Label-Efficient Learning. (arXiv:2306.09910v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yifang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Canal_G/0/1/0/all/0/1">Gregory Canal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mussmann_S/0/1/0/all/0/1">Stephen Mussmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Arnav M. Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatt_G/0/1/0/all/0/1">Gantavya Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yinglun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilmes_J/0/1/0/all/0/1">Jeffrey Bilmes</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon Shaolei Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1">Kevin Jamieson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1">Robert D Nowak</a></p>
<p>Labeled data are critical to modern machine learning applications, but
obtaining labels can be expensive. To mitigate this cost, machine learning
methods, such as transfer learning, semi-supervised learning and active
learning, aim to be label-efficient: achieving high predictive performance from
relatively few labeled examples. While obtaining the best label-efficiency in
practice often requires combinations of these techniques, existing benchmark
and evaluation frameworks do not capture a concerted combination of all such
techniques. This paper addresses this deficiency by introducing LabelBench, a
new computationally-efficient framework for joint evaluation of multiple
label-efficient learning techniques. As an application of LabelBench, we
introduce a novel benchmark of state-of-the-art active learning methods in
combination with semi-supervised learning for fine-tuning pretrained vision
transformers. Our benchmark demonstrates better label-efficiencies than
previously reported in active learning. LabelBench's modular codebase is
open-sourced for the broader community to contribute label-efficient learning
methods and benchmarks. The repository can be found at:
https://github.com/EfficientTraining/LabelBench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11086">Enhancing variational quantum state diagonalization using reinforcement learning techniques. (arXiv:2306.11086v3 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Kundu_A/0/1/0/all/0/1">Akash Kundu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bedelek_P/0/1/0/all/0/1">Przemys&#x142;aw Bede&#x142;ek</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ostaszewski_M/0/1/0/all/0/1">Mateusz Ostaszewski</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Danaci_O/0/1/0/all/0/1">Onur Danaci</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Patel_Y/0/1/0/all/0/1">Yash J. Patel</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Dunjko_V/0/1/0/all/0/1">Vedran Dunjko</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Miszczak_J/0/1/0/all/0/1">Jaros&#x142;aw A. Miszczak</a></p>
<p>The variational quantum algorithms are crucial for the application of NISQ
computers. Such algorithms require short quantum circuits, which are more
amenable to implementation on near-term hardware, and many such methods have
been developed. One of particular interest is the so-called variational quantum
state diagonalization method, which constitutes an important algorithmic
subroutine and can be used directly to work with data encoded in quantum
states. In particular, it can be applied to discern the features of quantum
states, such as entanglement properties of a system, or in quantum machine
learning algorithms. In this work, we tackle the problem of designing a very
shallow quantum circuit, required in the quantum state diagonalization task, by
utilizing reinforcement learning (RL). We use a novel encoding method for the
RL-state, a dense reward function, and an $\epsilon$-greedy policy to achieve
this. We demonstrate that the circuits proposed by the reinforcement learning
methods are shallower than the standard variational quantum state
diagonalization algorithm and thus can be used in situations where hardware
capabilities limit the depth of quantum circuits. The methods we propose in the
paper can be readily adapted to address a wide range of variational quantum
algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15632">Asynchronous Algorithmic Alignment with Cocycles. (arXiv:2306.15632v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dudzik_A/0/1/0/all/0/1">Andrew Dudzik</a>, <a href="http://arxiv.org/find/cs/1/au:+Glehn_T/0/1/0/all/0/1">Tamara von Glehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1">Petar Veli&#x10d;kovi&#x107;</a></p>
<p>State-of-the-art neural algorithmic reasoners make use of message passing in
graph neural networks (GNNs). But typical GNNs blur the distinction between the
definition and invocation of the message function, forcing a node to send
messages to its neighbours at every layer, synchronously. When applying GNNs to
learn to execute dynamic programming algorithms, however, on most steps only a
handful of the nodes would have meaningful updates to send. One, hence, runs
the risk of inefficiencies by sending too much irrelevant data across the
graph. But more importantly, many intermediate GNN steps have to learn the
identity functions, which is a non-trivial learning problem. In this work, we
explicitly separate the concepts of node state update and message function
invocation. With this separation, we obtain a mathematical formulation that
allows us to reason about asynchronous computation in both algorithms and
neural networks. Our analysis yields several practical implementations of
synchronous scalable GNN layers that are provably invariant under various forms
of asynchrony.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.17010">milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing. (arXiv:2306.17010v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Fangqiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peijun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chris Xiaoxuan Lu</a></p>
<p>Approaching the era of ubiquitous computing, human motion sensing plays a
crucial role in smart systems for decision making, user interaction, and
personalized services. Extensive research has been conducted on human tracking,
pose estimation, gesture recognition, and activity recognition, which are
predominantly based on cameras in traditional methods. However, the intrusive
nature of cameras limits their use in smart home applications. To address this,
mmWave radars have gained popularity due to their privacy-friendly features. In
this work, we propose milliFlow, a novel deep learning method for scene flow
estimation as a complementary motion information for mmWave point cloud,
serving as an intermediate level of features and directly benefiting downstream
human motion sensing tasks. Experimental results demonstrate the superior
performance of our method with an average 3D endpoint error of 4.6cm,
significantly surpassing the competing approaches. Furthermore, by
incorporating scene flow information, we achieve remarkable improvements in
human activity recognition, human parsing, and human body part tracking. To
foster further research in this area, we will provide our codebase and dataset
for open access upon acceptance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01163">Improving Language Plasticity via Pretraining with Active Forgetting. (arXiv:2307.01163v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yihong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchisio_K/0/1/0/all/0/1">Kelly Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1">Roberta Raileanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1">David Ifeoluwa Adelani</a>, <a href="http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1">Pontus Stenetorp</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1">Sebastian Riedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1">Mikel Artetxe</a></p>
<p>Pretrained language models (PLMs) are today the primary model for natural
language processing. Despite their impressive downstream performance, it can be
difficult to apply PLMs to new languages, a barrier to making their
capabilities universally accessible. While prior work has shown it possible to
address this issue by learning a new embedding layer for the new language,
doing so is both data and compute inefficient. We propose to use an active
forgetting mechanism during pretraining, as a simple way of creating PLMs that
can quickly adapt to new languages. Concretely, by resetting the embedding
layer every K updates during pretraining, we encourage the PLM to improve its
ability of learning new embeddings within a limited number of updates, similar
to a meta-learning effect. Experiments with RoBERTa show that models pretrained
with our forgetting mechanism not only demonstrate faster convergence during
language adaptation but also outperform standard ones in a low-data regime,
particularly for languages that are distant from English.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06244">Diffusion Models for Multi-target Adversarial Tracking. (arXiv:2307.06244v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1">Sean Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Natarajan_M/0/1/0/all/0/1">Manisha Natarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zixuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gombolay_M/0/1/0/all/0/1">Matthew Gombolay</a></p>
<p>Target tracking plays a crucial role in real-world scenarios, particularly in
drug-trafficking interdiction, where the knowledge of an adversarial target's
location is often limited. Improving autonomous tracking systems will enable
unmanned aerial, surface, and underwater vehicles to better assist in
interdicting smugglers that use manned surface, semi-submersible, and aerial
vessels. As unmanned drones proliferate, accurate autonomous target estimation
is even more crucial for security and safety. This paper presents Constrained
Agent-based Diffusion for Enhanced Multi-Agent Tracking (CADENCE), an approach
aimed at generating comprehensive predictions of adversary locations by
leveraging past sparse state information. To assess the effectiveness of this
approach, we evaluate predictions on single-target and multi-target pursuit
environments, employing Monte-Carlo sampling of the diffusion model to estimate
the probability associated with each generated trajectory. We propose a novel
cross-attention based diffusion model that utilizes constraint-based sampling
to generate multimodal track hypotheses. Our single-target model surpasses the
performance of all baseline methods on Average Displacement Error (ADE) for
predictions across all time horizons.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06857">Lightweight reranking for language model generations. (arXiv:2307.06857v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Siddhartha Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaofei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1">Anoop Deoras</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1">Bing Xiang</a></p>
<p>Large Language Models (LLMs) can exhibit considerable variation in the
quality of their sampled outputs. Reranking and selecting the best generation
from the sampled set is a popular way of obtaining strong gains in generation
quality. In this paper, we present a novel approach for reranking LLM
generations. Unlike other techniques that might involve additional inferences
or training a specialized reranker, our approach relies on easy to compute
pairwise statistics between the generations that have minimal compute overhead.
We show that our approach can be formalized as an extension of self-consistency
and analyze its performance in that framework, theoretically as well as via
simulations. We show strong improvements for selecting the best k generations
for code generation tasks as well as robust improvements for the best
generation for the tasks of autoformalization, summarization, and translation.
While our approach only assumes black-box access to LLMs, we show that
additional access to token probabilities can improve performance even further.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10870">Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1">Dimitri Meunier</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1">Zhu Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>, <a href="http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1">Samory Kpotufe</a></p>
<p>Many recent theoretical works on \emph{meta-learning} aim to achieve
guarantees in leveraging similar representational structures from related tasks
towards simplifying a target task. Importantly, the main aim in theory works on
the subject is to understand the extent to which convergence rates -- in
learning a common representation -- \emph{may scale with the number $N$ of
tasks} (as well as the number of samples per task). First steps in this setting
demonstrate this property when both the shared representation amongst tasks,
and task-specific regression functions, are linear. This linear setting readily
reveals the benefits of aggregating tasks, e.g., via averaging arguments. In
practice, however, the representation is often highly nonlinear, introducing
nontrivial biases in each task that cannot easily be averaged out as in the
linear case. In the present work, we derive theoretical guarantees for
meta-learning with nonlinear representations. In particular, assuming the
shared nonlinearity maps to an infinite-dimensional RKHS, we show that
additional biases can be mitigated with careful regularization that leverages
the smoothness of task-specific regression functions,
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10364">SE(3) Equivariant Augmented Coupling Flows. (arXiv:2308.10364v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Midgley_L/0/1/0/all/0/1">Laurence I. Midgley</a>, <a href="http://arxiv.org/find/cs/1/au:+Stimper_V/0/1/0/all/0/1">Vincent Stimper</a>, <a href="http://arxiv.org/find/cs/1/au:+Antoran_J/0/1/0/all/0/1">Javier Antor&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_E/0/1/0/all/0/1">Emile Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a></p>
<p>Coupling normalizing flows allow for fast sampling and density evaluation,
making them the tool of choice for probabilistic modeling of physical systems.
However, the standard coupling architecture precludes endowing flows that
operate on the Cartesian coordinates of atoms with the SE(3) and permutation
invariances of physical systems. This work proposes a coupling flow that
preserves SE(3) and permutation equivariance by performing coordinate splits
along additional augmented dimensions. At each layer, the flow maps atoms'
positions into learned SE(3) invariant bases, where we apply standard flow
transformations, such as monotonic rational-quadratic splines, before returning
to the original basis. Crucially, our flow preserves fast sampling and density
evaluation, and may be used to produce unbiased estimates of expectations with
respect to the target distribution via importance sampling. When trained on the
DW4, LJ13, and QM9-positional datasets, our flow is competitive with
equivariant continuous normalizing flows and diffusion models, while allowing
sampling more than an order of magnitude faster. Moreover, to the best of our
knowledge, we are the first to learn the full Boltzmann distribution of alanine
dipeptide by only modeling the Cartesian positions of its atoms. Lastly, we
demonstrate that our flow can be trained to approximately sample from the
Boltzmann distribution of the DW4 and LJ13 particle systems using only their
energy functions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.15552">Pure Exploration under Mediators&#x27; Feedback. (arXiv:2308.15552v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Poiani_R/0/1/0/all/0/1">Riccardo Poiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Metelli_A/0/1/0/all/0/1">Alberto Maria Metelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Restelli_M/0/1/0/all/0/1">Marcello Restelli</a></p>
<p>Stochastic multi-armed bandits are a sequential-decision-making framework,
where, at each interaction step, the learner selects an arm and observes a
stochastic reward. Within the context of best-arm identification (BAI)
problems, the goal of the agent lies in finding the optimal arm, i.e., the one
with highest expected reward, as accurately and efficiently as possible.
Nevertheless, the sequential interaction protocol of classical BAI problems,
where the agent has complete control over the arm being pulled at each round,
does not effectively model several decision-making problems of interest (e.g.,
off-policy learning, partially controllable environments, and human feedback).
For this reason, in this work, we propose a novel strict generalization of the
classical BAI problem that we refer to as best-arm identification under
mediators' feedback (BAI-MF). More specifically, we consider the scenario in
which the learner has access to a set of mediators, each of which selects the
arms on the agent's behalf according to a stochastic and possibly unknown
policy. The mediator, then, communicates back to the agent the pulled arm
together with the observed reward. In this setting, the agent's goal lies in
sequentially choosing which mediator to query to identify with high probability
the optimal arm while minimizing the identification time, i.e., the sample
complexity. To this end, we first derive and analyze a statistical lower bound
on the sample complexity specific to our general mediator feedback scenario.
Then, we propose a sequential decision-making strategy for discovering the best
arm under the assumption that the mediators' policies are known to the learner.
As our theory verifies, this algorithm matches the lower bound both almost
surely and in expectation. Finally, we extend these results to cases where the
mediators' policies are unknown to the learner obtaining comparable results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.04027">TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models. (arXiv:2309.04027v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Klu_E/0/1/0/all/0/1">Emmanuel Klu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_S/0/1/0/all/0/1">Sameer Sethi</a></p>
<p>Machine learning models can perpetuate unintended biases from unfair and
imbalanced datasets. Evaluating and debiasing these datasets and models is
especially hard in text datasets where sensitive attributes such as race,
gender, and sexual orientation may not be available. When these models are
deployed into society, they can lead to unfair outcomes for historically
underrepresented groups. In this paper, we present a dataset coupled with an
approach to improve text fairness in classifiers and language models. We create
a new, more comprehensive identity lexicon, TIDAL, which includes 15,123
identity terms and associated sense context across three demographic
categories. We leverage TIDAL to develop an identity annotation and
augmentation tool that can be used to improve the availability of identity
context and the effectiveness of ML fairness techniques. We evaluate our
approaches using human contributors, and additionally run experiments focused
on dataset and model debiasing. Results show our assistive annotation technique
improves the reliability and velocity of human-in-the-loop processes. Our
dataset and methods uncover more disparities during evaluation, and also
produce more fair models during remediation. These approaches provide a
practical path forward for scaling classifier and generative model fairness in
real-world settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.14062">FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning. (arXiv:2309.14062v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goswami_D/0/1/0/all/0/1">Dipam Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Twardowski_B/0/1/0/all/0/1">Bart&#x142;omiej Twardowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Weijer_J/0/1/0/all/0/1">Joost van de Weijer</a></p>
<p>Exemplar-free class-incremental learning (CIL) poses several challenges since
it prohibits the rehearsal of data from previous tasks and thus suffers from
catastrophic forgetting. Recent approaches to incrementally learning the
classifier by freezing the feature extractor after the first task have gained
much attention. In this paper, we explore prototypical networks for CIL, which
generate new class prototypes using the frozen feature extractor and classify
the features based on the Euclidean distance to the prototypes. In an analysis
of the feature distributions of classes, we show that classification based on
Euclidean metrics is successful for jointly trained features. However, when
learning from non-stationary data, we observe that the Euclidean metric is
suboptimal and that feature distributions are heterogeneous. To address this
challenge, we revisit the anisotropic Mahalanobis distance for CIL. In
addition, we empirically show that modeling the feature covariance relations is
better than previous attempts at sampling features from normal distributions
and training a linear classifier. Unlike existing methods, our approach
generalizes to both many- and few-shot CIL settings, as well as to
domain-incremental settings. Interestingly, without updating the backbone
network, our method obtains state-of-the-art results on several standard
continual learning benchmarks. Code is available at
https://github.com/dipamgoswami/FeCAM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00177">A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions. (arXiv:2310.00177v4 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lan_K/0/1/0/all/0/1">Kai Weixian Lan</a>, <a href="http://arxiv.org/find/math/1/au:+Gueidon_E/0/1/0/all/0/1">Elias Gueidon</a>, <a href="http://arxiv.org/find/math/1/au:+Kaneda_A/0/1/0/all/0/1">Ayano Kaneda</a>, <a href="http://arxiv.org/find/math/1/au:+Panetta_J/0/1/0/all/0/1">Julian Panetta</a>, <a href="http://arxiv.org/find/math/1/au:+Teran_J/0/1/0/all/0/1">Joseph Teran</a></p>
<p>We introduce a neural-preconditioned iterative solver for Poisson equations
with mixed boundary conditions. The Poisson equation is ubiquitous in
scientific computing: it governs a wide array of physical phenomena, arises as
a subproblem in many numerical algorithms, and serves as a model problem for
the broader class of elliptic PDEs. The most popular Poisson discretizations
yield large sparse linear systems. At high resolution, and for
performance-critical applications, iterative solvers can be advantageous for
these -- but only when paired with powerful preconditioners. The core of our
solver is a neural network trained to approximate the inverse of a discrete
structured-grid Laplace operator for a domain of arbitrary shape and with mixed
boundary conditions. The structure of this problem motivates a novel network
architecture that we demonstrate is highly effective as a preconditioner even
for boundary conditions outside the training set. We show that on challenging
test cases arising from an incompressible fluid simulation, our method
outperforms state-of-the-art solvers like algebraic multigrid as well as some
recent neural preconditioners.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07987">Semantic-Forward Relaying: A Novel Framework Towards 6G Cooperative Communications. (arXiv:2310.07987v2 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wensheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yuna Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lixin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsumoto_T/0/1/0/all/0/1">Tad Matsumoto</a></p>
<p>This letter proposes a novel relaying framework, semantic-forward (SF), for
cooperative communications towards the sixth-generation (6G) wireless networks.
The SF relay extracts and transmits the semantic features, which reduces
forwarding payload, and also improves the network robustness against intra-link
errors. Based on the theoretical basis for cooperative communications with side
information and the turbo principle, we design a joint source-channel coding
algorithm to iteratively exchange the extrinsic information for enhancing the
decoding gains at the destination. Surprisingly, simulation results indicate
that even in bad channel conditions, SF relaying can still effectively improve
the recovered information quality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08036">ZEST: Attention-based Zero-Shot Learning for Unseen IoT Device Classification. (arXiv:2310.08036v2 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Binghui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gysel_P/0/1/0/all/0/1">Philipp Gysel</a>, <a href="http://arxiv.org/find/cs/1/au:+Divakaran_D/0/1/0/all/0/1">Dinil Mon Divakaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1">Mohan Gurusamy</a></p>
<p>Recent research works have proposed machine learning models for classifying
IoT devices connected to a network. However, there is still a practical
challenge of not having all devices (and hence their traffic) available during
the training of a model. This essentially means, during the operational phase,
we need to classify new devices not seen in the training phase. To address this
challenge, we propose ZEST -- a ZSL (zero-shot learning) framework based on
self-attention for classifying both seen and unseen devices. ZEST consists of
i) a self-attention based network feature extractor, termed SANE, for
extracting latent space representations of IoT traffic, ii) a generative model
that trains a decoder using latent features to generate pseudo data, and iii) a
supervised model that is trained on the generated pseudo data for classifying
devices. We carry out extensive experiments on real IoT traffic data; our
experiments demonstrate i) ZEST achieves significant improvement (in terms of
accuracy) over the baselines; ii) SANE is able to better extract meaningful
representations than LSTM which has been commonly used for modeling network
traffic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.13459">Stable Nonconvex-Nonconcave Training via Linear Interpolation. (arXiv:2310.13459v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pethick_T/0/1/0/all/0/1">Thomas Pethick</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Wanyun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cevher_V/0/1/0/all/0/1">Volkan Cevher</a></p>
<p>This paper presents a theoretical analysis of linear interpolation as a
principled method for stabilizing (large-scale) neural network training. We
argue that instabilities in the optimization process are often caused by the
nonmonotonicity of the loss landscape and show how linear interpolation can
help by leveraging the theory of nonexpansive operators. We construct a new
optimization scheme called relaxed approximate proximal point (RAPP), which is
the first 1-SCLI method to achieve last iterate convergence rates for
$\rho$-comonotone problems while only requiring $\rho &gt; -\tfrac{1}{2L}$. The
construction extends to constrained and regularized settings. By replacing the
inner optimizer in RAPP we rediscover the family of Lookahead algorithms for
which we establish convergence in cohypomonotone problems even when the base
optimizer is taken to be gradient descent ascent. The range of cohypomonotone
problems in which Lookahead converges is further expanded by exploiting that
Lookahead inherits the properties of the base optimizer. We corroborate the
results with experiments on generative adversarial networks which demonstrates
the benefits of the linear interpolation present in both RAPP and Lookahead.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18152">Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs. (arXiv:2310.18152v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yijian Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wenwu Zhu</a></p>
<p>Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs
such as citation networks, e-commerce networks and social networks has
attracted considerable attention in the web community. Recently, large language
models (LLMs) have demonstrated exceptional capabilities across a wide range of
tasks. However, the existing works focus on harnessing the potential of LLMs
solely relying on prompts to convey graph structure information to LLMs, thus
suffering from insufficient understanding of the complex structural
relationships within TAGs. To address this problem, in this paper we present
the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the
reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model
incorporates graph structure information through tailored disentangled graph
neural network (GNN) layers, enabling LLMs to capture the intricate
relationships hidden in text-attributed graphs from multiple structural
factors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing
computational costs and allowing much more flexibility in combining with
different LLM models. Experimental evaluations demonstrate the effectiveness of
the proposed DGTL model on achieving superior or comparable performance over
state-of-the-art baselines. Additionally, we also demonstrate that our DGTL
model can offer natural language explanations for predictions, thereby
significantly enhancing model interpretability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01797">On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Puheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huishuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a></p>
<p>Diffusion models are a class of generative models that serve to establish a
stochastic transport map between an empirically observed, yet unknown, target
distribution and a known prior. Despite their remarkable success in real-world
applications, a theoretical understanding of their generalization capabilities
remains underdeveloped. This work embarks on a comprehensive theoretical
exploration of the generalization attributes of diffusion models. We establish
theoretical estimates of the generalization gap that evolves in tandem with the
training dynamics of score-based diffusion models, suggesting a polynomially
small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$
and the model capacity $m$, evading the curse of dimensionality (i.e., not
exponentially large in the data dimension) when early-stopped. Furthermore, we
extend our quantitative analysis to a data-dependent scenario, wherein target
distributions are portrayed as a succession of densities with progressively
increasing distances between modes. This precisely elucidates the adverse
effect of "modes shift" in ground truths on the model generalization. Moreover,
these estimates are not solely theoretical constructs but have also been
confirmed through numerical simulations. Our findings contribute to the
rigorous understanding of diffusion models' generalization properties and
provide insights that may guide practical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.03865">When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary Classifiers through Membership Inference Attacks. (arXiv:2311.03865v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1">Huan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangsheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1">Tianqing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Ming Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wanlei Zhou</a></p>
<p>Previous studies have developed fairness methods for biased models that
exhibit discriminatory behaviors towards specific subgroups. While these models
have shown promise in achieving fair predictions, recent research has
identified their potential vulnerability to score-based membership inference
attacks (MIAs). In these attacks, adversaries can infer whether a particular
data sample was used during training by analyzing the model's prediction
scores. However, our investigations reveal that these score-based MIAs are
ineffective when targeting fairness-enhanced models in binary classifications.
The attack models trained to launch the MIAs degrade into simplistic threshold
models, resulting in lower attack performance. Meanwhile, we observe that
fairness methods often lead to prediction performance degradation for the
majority subgroups of the training data. This raises the barrier to successful
attacks and widens the prediction gaps between member and non-member data.
Building upon these insights, we propose an efficient MIA method against
fairness-enhanced models based on fairness discrepancy results (FD-MIA). It
leverages the difference in the predictions from both the original and
fairness-enhanced models and exploits the observed prediction gaps as attack
clues. We also explore potential strategies for mitigating privacy leakages.
Extensive experiments validate our findings and demonstrate the efficacy of the
proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08640">Multistage Collaborative Knowledge Distillation from Large Language Models for Semi-Supervised Sequence Generation. (arXiv:2311.08640v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiachen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenlong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Drozdov_A/0/1/0/all/0/1">Andrew Drozdov</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozonoyer_B/0/1/0/all/0/1">Benjamin Rozonoyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1">Md Arafat Sultan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jay-Yoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1">Mohit Iyyer</a>, <a href="http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1">Andrew McCallum</a></p>
<p>We study semi-supervised sequence generation tasks where labeled data are too
scarce to effectively finetune a model and at the same time few-shot prompting
of a large language model (LLM) has suboptimal performance. This happens when a
task, such as parsing, is expensive to annotate and also unfamiliar to a
pretrained LLM. In this paper, we present a discovery that student models
distilled from an in-context learned LLM can often generalize better than their
teacher on such tasks. Leveraging this finding, we present a new method --
multistage collaborative knowledge distillation from an LLM (MCKD) -- for such
tasks. MCKD first few-shot prompts an LLM to produce pseudolabels for unlabeled
data. At each intermediate knowledge distillation (KD) stage, a new pair of
students is trained on disjoint partitions of the pseudolabeled data. Each
student then produces new and improved pseudolabels for its unseen partition to
be used in the next stage of distillation. We demonstrate the advantage of
multistage cross-partition labeling on several syntactic and semantic parsing
tasks. On CRAFT biomedical parsing, for example, 3-stage MCKD with 50 labeled
examples outperforms the prompted LLM and vanilla KD by 7.5% and 3.7% parsing
F1, respectively, and matches the performance of supervised finetuning with 500
examples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.17431">Grounding Foundation Models through Federated Transfer Learning: A General Framework. (arXiv:2311.17431v8 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yan Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1">Tao Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Hanlin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaojin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lixin Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a></p>
<p>Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and
powerful emergent abilities have achieved remarkable success in various natural
language processing and computer vision tasks. Grounding FMs by adapting them
to domain-specific tasks or augmenting them with domain-specific knowledge
enables us to exploit the full potential of FMs. However, grounding FMs faces
several challenges, stemming primarily from constrained computing resources,
data privacy, model heterogeneity, and model ownership. Federated Transfer
Learning (FTL), the combination of federated learning and transfer learning,
provides promising solutions to address these challenges. In recent years, the
need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in
both academia and industry. Motivated by the strong growth in FTL-FM research
and the potential impact of FTL-FM on industrial applications, we propose an
FTL-FM framework that formulates problems of grounding FMs in the federated
learning setting, construct a detailed taxonomy based on the FTL-FM framework
to categorize state-of-the-art FTL-FM works, and comprehensively overview
FTL-FM works based on the proposed taxonomy. We also establish correspondences
between FTL-FM and conventional phases of adapting FM so that FM practitioners
can align their research works with FTL-FM. In addition, we overview advanced
efficiency-improving and privacy-preserving techniques because efficiency and
privacy are critical concerns in FTL-FM. Last, we discuss opportunities and
future research directions of FTL-FM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18787">Communication-Efficient Federated Optimization over Semi-Decentralized Networks. (arXiv:2311.18787v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1">Yuejie Chi</a></p>
<p>In large-scale federated and decentralized learning, communication efficiency
is one of the most challenging bottlenecks. While gossip communication -- where
agents can exchange information with their connected neighbors -- is more
cost-effective than communicating with the remote server, it often requires a
greater number of communication rounds, especially for large and sparse
networks. To tackle the trade-off, we examine the communication efficiency
under a semi-decentralized communication protocol, in which agents can perform
both agent-to-agent and agent-to-server communication in a probabilistic
manner. We design a tailored communication-efficient algorithm over
semi-decentralized networks, referred to as PISCO, which inherits the
robustness to data heterogeneity thanks to gradient tracking and allows
multiple local updates for saving communication. We establish the convergence
rate of PISCO for nonconvex problems and show that PISCO enjoys a linear
speedup in terms of the number of agents and local updates. Our numerical
results highlight the superior communication efficiency of PISCO and its
resilience to data heterogeneity and various network topologies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05398">Generative Network Layer for Communication Systems with Artificial Intelligence. (arXiv:2312.05398v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thorsager_M/0/1/0/all/0/1">Mathias Thorsager</a>, <a href="http://arxiv.org/find/cs/1/au:+Leyva_Mayorga_I/0/1/0/all/0/1">Israel Leyva-Mayorga</a>, <a href="http://arxiv.org/find/cs/1/au:+Soret_B/0/1/0/all/0/1">Beatriz Soret</a>, <a href="http://arxiv.org/find/cs/1/au:+Popovski_P/0/1/0/all/0/1">Petar Popovski</a></p>
<p>The traditional role of the network layer is the transfer of packet replicas
from source to destination through intermediate network nodes. We present a
generative network layer that uses Generative AI (GenAI) at intermediate or
edge network nodes and analyze its impact on the required data rates in the
network. We conduct a case study where the GenAI-aided nodes generate images
from prompts that consist of substantially compressed latent representations.
The results from network flow analyses under image quality constraints show
that the generative network layer can achieve an improvement of more than 100%
in terms of the required data rate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07991">Accelerating the Global Aggregation of Local Explanations. (arXiv:2312.07991v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mor_A/0/1/0/all/0/1">Alon Mor</a>, <a href="http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1">Yonatan Belinkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimelfeld_B/0/1/0/all/0/1">Benny Kimelfeld</a></p>
<p>Local explanation methods highlight the input tokens that have a considerable
impact on the outcome of classifying the document at hand. For example, the
Anchor algorithm applies a statistical analysis of the sensitivity of the
classifier to changes in the token. Aggregating local explanations over a
dataset provides a global explanation of the model. Such aggregation aims to
detect words with the most impact, giving valuable insights about the model,
like what it has learned in training and which adversarial examples expose its
weaknesses. However, standard aggregation methods bear a high computational
cost: a na\"ive implementation applies a costly algorithm to each token of each
document, and hence, it is infeasible for a simple user running in the scope of
a short analysis session. % We devise techniques for accelerating the global
aggregation of the Anchor algorithm. Specifically, our goal is to compute a set
of top-$k$ words with the highest global impact according to different
aggregation functions. Some of our techniques are lossless and some are lossy.
We show that for a very mild loss of quality, we are able to accelerate the
computation by up to 30$\times$, reducing the computation from hours to
minutes. We also devise and study a probabilistic model that accounts for noise
in the Anchor algorithm and diminishes the bias toward words that are frequent
yet low in impact.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14276">Deep Neural Networks and Finite Elements of Any Order on Arbitrary Dimensions. (arXiv:2312.14276v3 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+He_J/0/1/0/all/0/1">Juncai He</a>, <a href="http://arxiv.org/find/math/1/au:+Xu_J/0/1/0/all/0/1">Jinchao Xu</a></p>
<p>In this study, we establish that deep neural networks employing ReLU and
ReLU$^2$ activation functions can effectively represent Lagrange finite element
functions of any order on various simplicial meshes in arbitrary dimensions. We
introduce two novel formulations for globally expressing the basis functions of
Lagrange elements, tailored for both specific and arbitrary meshes. These
formulations are based on a geometric decomposition of the elements,
incorporating several insightful and essential properties of high-dimensional
simplicial meshes, barycentric coordinate functions, and global basis functions
of linear elements. This representation theory facilitates a natural
approximation result for such deep neural networks. Our findings present the
first demonstration of how deep neural networks can systematically generate
general continuous piecewise polynomial functions on both specific or arbitrary
simplicial meshes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14890">NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes. (arXiv:2312.14890v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lizhou Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wenyue Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haoyang Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a></p>
<p>Complex reasoning ability is one of the most important features of current
LLMs, which has also been leveraged to play an integral role in complex
decision-making tasks. Therefore, the investigation into the reasoning
capabilities of Large Language Models (LLMs) is critical: numerous benchmarks
have been established to assess the reasoning abilities of LLMs. However,
current benchmarks are inadequate in offering a rigorous evaluation of the full
extent of reasoning abilities that LLMs are capable of achieving. They are also
prone to the risk of overfitting, as these benchmarks, being publicly
accessible and static, allow models to potentially tailor their responses to
specific benchmark metrics, thereby inflating their performance. Addressing
these limitations, our research introduces a new benchmark, named NPHardEval.
This benchmark is designed to evaluate the reasoning abilities of LLMs across a
broad spectrum of 900 algorithmic questions, extending up to the NP-Hard
complexity class. These questions are meticulously chosen to represent a wide
range of complexity class below the NP-hard complexity class, offering a
rigorous measure of the reasoning ability of LLMs. Through this study, we shed
light on the current state of reasoning in LLMs, providing an objective and
rigorous perspective through the comparison of LLMs' performance across complex
classes. Moreover, this benchmark is designed with a dynamic update mechanism,
where the datapoints are refreshed on a monthly basis. Such regular updates
play a crucial role in mitigating the risk of LLMs overfitting to the
benchmark, promoting a more accurate and reliable assessment of their reasoning
capabilities. The benchmark dataset and code of NPHardEval are available at
https://github.com/casmlab/NPHardEval.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.16015">A Comprehensive Survey of Evaluation Techniques for Recommendation Systems. (arXiv:2312.16015v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jadon_A/0/1/0/all/0/1">Aryan Jadon</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1">Avinash Patil</a></p>
<p>The effectiveness of recommendation systems is pivotal to user engagement and
satisfaction in online platforms. As these recommendation systems increasingly
influence user choices, their evaluation transcends mere technical performance
and becomes central to business success. This paper addresses the multifaceted
nature of recommendations system evaluation by introducing a comprehensive
suite of metrics, each tailored to capture a distinct aspect of system
performance. We discuss
</p>
<p>* Similarity Metrics: to quantify the precision of content-based filtering
mechanisms and assess the accuracy of collaborative filtering techniques.
</p>
<p>* Candidate Generation Metrics: to evaluate how effectively the system
identifies a broad yet relevant range of items.
</p>
<p>* Predictive Metrics: to assess the accuracy of forecasted user preferences.
</p>
<p>* Ranking Metrics: to evaluate the effectiveness of the order in which
recommendations are presented.
</p>
<p>* Business Metrics: to align the performance of the recommendation system
with economic objectives.
</p>
<p>Our approach emphasizes the contextual application of these metrics and their
interdependencies. In this paper, we identify the strengths and limitations of
current evaluation practices and highlight the nuanced trade-offs that emerge
when optimizing recommendation systems across different metrics. The paper
concludes by proposing a framework for selecting and interpreting these metrics
to not only improve system performance but also to advance business goals. This
work is to aid researchers and practitioners in critically assessing
recommendation systems and fosters the development of more nuanced, effective,
and economically viable personalization strategies. Our code is available at
GitHub -
https://github.com/aryan-jadon/Evaluation-Metrics-for-Recommendation-Systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00280">Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation. (arXiv:2401.00280v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fayyazi_R/0/1/0/all/0/1">Reza Fayyazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taghdimi_R/0/1/0/all/0/1">Rozhina Taghdimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shanchieh Jay Yang</a></p>
<p>Tactics, Techniques, and Procedures (TTPs) outline the methods attackers use
to exploit vulnerabilities. The interpretation of TTPs in the MITRE ATT&amp;CK
framework can be challenging for cybersecurity practitioners due to presumed
expertise, complex dependencies, and inherent ambiguity. Meanwhile,
advancements with Large Language Models (LLMs) have led to recent surge in
studies exploring its uses in cybersecurity operations. This leads us to
question how well encoder-only (e.g., RoBERTa) and decoder-only (e.g., GPT-3.5)
LLMs can comprehend and summarize TTPs to inform analysts of the intended
purposes (i.e., tactics) of a cyberattack procedure. The state-of-the-art LLMs
have shown to be prone to hallucination by providing inaccurate information,
which is problematic in critical domains like cybersecurity. Therefore, we
propose the use of Retrieval Augmented Generation (RAG) techniques to extract
relevant contexts for each cyberattack procedure for decoder-only LLMs (without
fine-tuning). We further contrast such approach against supervised fine-tuning
(SFT) of encoder-only LLMs. Our results reveal that both the direct-use of
decoder-only LLMs (i.e., its pre-trained knowledge) and the SFT of encoder-only
LLMs offer inaccurate interpretation of cyberattack procedures. Significant
improvements are shown when RAG is used for decoder-only LLMs, particularly
when directly relevant context is found. This study further sheds insights on
the limitations and capabilities of using RAG for LLMs in interpreting TTPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.02300">Robust Physics Informed Neural Networks. (arXiv:2401.02300v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Los_M/0/1/0/all/0/1">Marcin &#x141;o&#x15b;</a>, <a href="http://arxiv.org/find/cs/1/au:+Paszynski_M/0/1/0/all/0/1">Maciej Paszy&#x144;ski</a></p>
<p>We introduce a Robust version of the Physics-Informed Neural Networks
(RPINNs) to approximate the Partial Differential Equations (PDEs) solution.
Standard Physics Informed Neural Networks (PINN) takes into account the
governing physical laws described by PDE during the learning process. The
network is trained on a data set that consists of randomly selected points in
the physical domain and its boundary. PINNs have been successfully applied to
solve various problems described by PDEs with boundary conditions. The loss
function in traditional PINNs is based on the strong residuals of the PDEs.
This loss function in PINNs is generally not robust with respect to the true
error. The loss function in PINNs can be far from the true error, which makes
the training process more difficult. In particular, we do not know if the
training process has already converged to the solution with the required
accuracy. This is especially true if we do not know the exact solution, so we
cannot estimate the true error during the training. This paper introduces a
different way of defining the loss function. It incorporates the residual and
the inverse of the Gram matrix, computed using the energy norm. We test our
RPINN algorithm on two Laplace problems and one advection-diffusion problem in
two spatial dimensions. We conclude that RPINN is a robust method. The proposed
loss coincides well with the true error of the solution, as measured in the
energy norm. Thus, we know if our training process goes well, and we know when
to stop the training to obtain the neural network approximation of the solution
of the PDE with the true error of required accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04679">RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nikdan_M/0/1/0/all/0/1">Mahdi Nikdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabesh_S/0/1/0/all/0/1">Soroush Tabesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a></p>
<p>We investigate parameter-efficient fine-tuning (PEFT) methods that can
provide good accuracy under limited computational and memory budgets in the
context of large language models (LLMs). We present a new PEFT method called
Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA)
that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components
on top of a set of fixed pretrained weights to efficiently approximate the
performance of a full-fine-tuning (FFT) solution. Across a series of
challenging generative tasks such as grade-school math and SQL query
generation, which require fine-tuning for good performance, we show that RoSA
outperforms both LoRA and pure sparse fine-tuning, at the same parameter
budget. We provide system support for RoSA to complement the training
algorithm, specifically in the form of sparse GPU kernels which enable memory-
and computationally-efficient training. Our code will be made available at
https://github.com/IST-DASLab/RoSA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05363">Generalizable Sleep Staging via Multi-Level Domain Alignment. (arXiv:2401.05363v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jiquan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1">Sha Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiang_H/0/1/0/all/0/1">Haiteng Jiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1">Shijian Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Tao Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Pan_G/0/1/0/all/0/1">Gang Pan</a></p>
<p>Automatic sleep staging is essential for sleep assessment and disorder
diagnosis. Most existing methods depend on one specific dataset and are limited
to be generalized to other unseen datasets, for which the training data and
testing data are from the same dataset. In this paper, we introduce domain
generalization into automatic sleep staging and propose the task of
generalizable sleep staging which aims to improve the model generalization
ability to unseen datasets. Inspired by existing domain generalization methods,
we adopt the feature alignment idea and propose a framework called SleepDG to
solve it. Considering both of local salient features and sequential features
are important for sleep staging, we propose a Multi-level Feature Alignment
combining epoch-level and sequence-level feature alignment to learn
domain-invariant feature representations. Specifically, we design an
Epoch-level Feature Alignment to align the feature distribution of each single
sleep epoch among different domains, and a Sequence-level Feature Alignment to
minimize the discrepancy of sequential features among different domains.
SleepDG is validated on five public datasets, achieving the state-of-the-art
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05414">On the Three Demons in Causality in Finance: Time Resolution, Nonstationarity, and Latent Factors. (arXiv:2401.05414v2 [q-fin.ST] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Dong_X/0/1/0/all/0/1">Xinshuai Dong</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Dai_H/0/1/0/all/0/1">Haoyue Dai</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Fan_Y/0/1/0/all/0/1">Yewen Fan</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Jin_S/0/1/0/all/0/1">Songyao Jin</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Rajendran_S/0/1/0/all/0/1">Sathyamoorthy Rajendran</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a></p>
<p>Financial data is generally time series in essence and thus suffers from
three fundamental issues: the mismatch in time resolution, the time-varying
property of the distribution - nonstationarity, and causal factors that are
important but unknown/unobserved. In this paper, we follow a causal perspective
to systematically look into these three demons in finance. Specifically, we
reexamine these issues in the context of causality, which gives rise to a novel
and inspiring understanding of how the issues can be addressed. Following this
perspective, we provide systematic solutions to these problems, which hopefully
would serve as a foundation for future research in the area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05437">Representation Learning for Wearable-Based Applications in the Case of Missing Data. (arXiv:2401.05437v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Jungo_J/0/1/0/all/0/1">Janosch Jungo</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiang_Y/0/1/0/all/0/1">Yutong Xiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Gashi_S/0/1/0/all/0/1">Shkurta Gashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Holz_C/0/1/0/all/0/1">Christian Holz</a></p>
<p>Wearable devices continuously collect sensor data and use it to infer an
individual's behavior, such as sleep, physical activity, and emotions. Despite
the significant interest and advancements in this field, modeling multimodal
sensor data in real-world environments is still challenging due to low data
quality and limited data annotations. In this work, we investigate
representation learning for imputing missing wearable data and compare it with
state-of-the-art statistical approaches. We investigate the performance of the
transformer model on 10 physiological and behavioral signals with different
masking ratios. Our results show that transformers outperform baselines for
missing data imputation of signals that change more frequently, but not for
monotonic signals. We further investigate the impact of imputation strategies
and masking rations on downstream classification tasks. Our study provides
insights for the design and development of masking-based self-supervised
learning tasks and advocates the adoption of hybrid-based imputation strategies
to address the challenge of missing data in wearable devices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05442">Functional Graphical Models: Structure Enables Offline Data-Driven Optimization. (arXiv:2401.05442v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kuba_J/0/1/0/all/0/1">Jakub Grudzien Kuba</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_M/0/1/0/all/0/1">Masatoshi Uehara</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a></p>
<p>While machine learning models are typically trained to solve prediction
problems, we might often want to use them for optimization problems. For
example, given a dataset of proteins and their corresponding fluorescence
levels, we might want to optimize for a new protein with the highest possible
fluorescence. This kind of data-driven optimization (DDO) presents a range of
challenges beyond those in standard prediction problems, since we need models
that successfully predict the performance of new designs that are better than
the best designs seen in the training set. It is not clear theoretically when
existing approaches can even perform better than the naive approach that simply
selects the best design in the dataset. In this paper, we study how structure
can enable sample-efficient data-driven optimization. To formalize the notion
of structure, we introduce functional graphical models (FGMs) and show
theoretically how they can provide for principled data-driven optimization by
decomposing the original high-dimensional optimization problem into smaller
sub-problems. This allows us to derive much more practical regret bounds for
DDO, and the result implies that DDO with FGMs can achieve nearly optimal
designs in situations where naive approaches fail due to insufficient coverage
of the offline data. We further present a data-driven optimization algorithm
that inferes the FGM structure itself, either over the original input variables
or a latent variable representation of the inputs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05566">Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training. (arXiv:2401.05566v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hubinger_E/0/1/0/all/0/1">Evan Hubinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Denison_C/0/1/0/all/0/1">Carson Denison</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1">Jesse Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lambert_M/0/1/0/all/0/1">Mike Lambert</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1">Meg Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+MacDiarmid_M/0/1/0/all/0/1">Monte MacDiarmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanham_T/0/1/0/all/0/1">Tamera Lanham</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziegler_D/0/1/0/all/0/1">Daniel M. Ziegler</a>, <a href="http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1">Tim Maxwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1">Newton Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermyn_A/0/1/0/all/0/1">Adam Jermyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1">Amanda Askell</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1">Ansh Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Anil_C/0/1/0/all/0/1">Cem Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1">David Duvenaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguli_D/0/1/0/all/0/1">Deep Ganguli</a>, <a href="http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1">Fazl Barez</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1">Jack Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Ndousse_K/0/1/0/all/0/1">Kamal Ndousse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_K/0/1/0/all/0/1">Kshitij Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellitto_M/0/1/0/all/0/1">Michael Sellitto</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1">Mrinank Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+DasSarma_N/0/1/0/all/0/1">Nova DasSarma</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1">Roger Grosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Kravec_S/0/1/0/all/0/1">Shauna Kravec</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yuntao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Witten_Z/0/1/0/all/0/1">Zachary Witten</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_M/0/1/0/all/0/1">Marina Favaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1">Jan Brauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Karnofsky_H/0/1/0/all/0/1">Holden Karnofsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Christiano_P/0/1/0/all/0/1">Paul Christiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1">Samuel R. Bowman</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_L/0/1/0/all/0/1">Logan Graham</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1">Jared Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1">S&#xf6;ren Mindermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenblatt_R/0/1/0/all/0/1">Ryan Greenblatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlegeris_B/0/1/0/all/0/1">Buck Shlegeris</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1">Nicholas Schiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1">Ethan Perez</a></p>
<p>Humans are capable of strategically deceptive behavior: behaving helpfully in
most situations, but then behaving very differently in order to pursue
alternative objectives when given the opportunity. If an AI system learned such
a deceptive strategy, could we detect it and remove it using current
state-of-the-art safety training techniques? To study this question, we
construct proof-of-concept examples of deceptive behavior in large language
models (LLMs). For example, we train models that write secure code when the
prompt states that the year is 2023, but insert exploitable code when the
stated year is 2024. We find that such backdoor behavior can be made
persistent, so that it is not removed by standard safety training techniques,
including supervised fine-tuning, reinforcement learning, and adversarial
training (eliciting unsafe behavior and then training to remove it). The
backdoor behavior is most persistent in the largest models and in models
trained to produce chain-of-thought reasoning about deceiving the training
process, with the persistence remaining even when the chain-of-thought is
distilled away. Furthermore, rather than removing backdoors, we find that
adversarial training can teach models to better recognize their backdoor
triggers, effectively hiding the unsafe behavior. Our results suggest that,
once a model exhibits deceptive behavior, standard techniques could fail to
remove such deception and create a false impression of safety.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05717">Segment Boundary Detection via Class Entropy Measurements in Connectionist Phoneme Recognition. (arXiv:2401.05717v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Salvi_G/0/1/0/all/0/1">Giampiero Salvi</a></p>
<p>This article investigates the possibility to use the class entropy of the
output of a connectionist phoneme recogniser to predict time boundaries between
phonetic classes. The rationale is that the value of the entropy should
increase in proximity of a transition between two segments that are well
modelled (known) by the recognition network since it is a measure of
uncertainty. The advantage of this measure is its simplicity as the posterior
probabilities of each class are available in connectionist phoneme recognition.
The entropy and a number of measures based on differentiation of the entropy
are used in isolation and in combination. The decision methods for predicting
the boundaries range from simple thresholds to neural network based procedure.
The different methods are compared with respect to their precision, measured in
terms of the ratio between the number C of predicted boundaries within 10 or 20
msec of the reference and the total number of predicted boundaries, and recall,
measured as the ratio between C and the total number of reference boundaries.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05982">A tree-based varying coefficient model. (arXiv:2401.05982v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zakrisson_H/0/1/0/all/0/1">Henning Zakrisson</a>, <a href="http://arxiv.org/find/stat/1/au:+Lindholm_M/0/1/0/all/0/1">Mathias Lindholm</a></p>
<p>The paper introduces a tree-based varying coefficient model (VCM) where the
varying coefficients are modelled using the cyclic gradient boosting machine
(CGBM) from Delong et al. (2023). Modelling the coefficient functions using a
CGBM allows for dimension-wise early stopping and feature importance scores.
The dimension-wise early stopping not only reduces the risk of
dimension-specific overfitting, but also reveals differences in model
complexity across dimensions. The use of feature importance scores allows for
simple feature selection and easy model interpretation. The model is evaluated
on the same simulated and real data examples as those used in Richman and
W\"uthrich (2023), and the results show that it produces results in terms of
out of sample loss that are comparable to those of their neural network-based
VCM called LocalGLMnet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06102">Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models. (arXiv:2401.06102v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghandeharioun_A/0/1/0/all/0/1">Asma Ghandeharioun</a>, <a href="http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1">Avi Caciularu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pearce_A/0/1/0/all/0/1">Adam Pearce</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_L/0/1/0/all/0/1">Lucas Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1">Mor Geva</a></p>
<p>Inspecting the information encoded in hidden representations of large
language models (LLMs) can explain models' behavior and verify their alignment
with human values. Given the capabilities of LLMs in generating
human-understandable text, we propose leveraging the model itself to explain
its internal representations in natural language. We introduce a framework
called Patchscopes and show how it can be used to answer a wide range of
questions about an LLM's computation. We show that prior interpretability
methods based on projecting representations into the vocabulary space and
intervening on the LLM computation can be viewed as instances of this
framework. Moreover, several of their shortcomings such as failure in
inspecting early layers or lack of expressivity can be mitigated by
Patchscopes. Beyond unifying prior inspection techniques, Patchscopes also
opens up new possibilities such as using a more capable model to explain the
representations of a smaller model, and unlocks new applications such as
self-correction in multi-hop reasoning.
</p>
</p>
</div>

    </div>
    </body>
    