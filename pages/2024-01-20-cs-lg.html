<!DOCTYPE html>
<html>
<head>
<title>2024-01-20-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.09424">Precipitation Prediction Using an Ensemble of Lightweight Learners. (arXiv:2401.09424v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Li_X/0/1/0/all/0/1">Xinzhe Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Rui_S/0/1/0/all/0/1">Sun Rui</a>, <a href="http://arxiv.org/find/physics/1/au:+Niu_Y/0/1/0/all/0/1">Yiming Niu</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1">Yao Liu</a></p>
<p>Precipitation prediction plays a crucial role in modern agriculture and
industry. However, it poses significant challenges due to the diverse patterns
and dynamics in time and space, as well as the scarcity of high precipitation
events.
</p>
<p>To address this challenge, we propose an ensemble learning framework that
leverages multiple learners to capture the diverse patterns of precipitation
distribution. Specifically, the framework consists of a precipitation predictor
with multiple lightweight heads (learners) and a controller that combines the
outputs from these heads. The learners and the controller are separately
optimized with a proposed 3-stage training scheme.
</p>
<p>By utilizing provided satellite images, the proposed approach can effectively
model the intricate rainfall patterns, especially for high precipitation
events. It achieved 1st place on the core test as well as the nowcasting
leaderboards of the Weather4Cast 2023 competition. For detailed implementation,
please refer to our GitHub repository at:
https://github.com/lxz1217/weather4cast-2023-lxz.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09426">Transduce: learning transduction grammars for string transformation. (arXiv:2401.09426v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Frydman_F/0/1/0/all/0/1">Francis Frydman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangion_P/0/1/0/all/0/1">Philippe Mangion</a></p>
<p>The synthesis of string transformation programs from input-output examples
utilizes various techniques, all based on an inductive bias that comprises a
restricted set of basic operators to be combined. A new algorithm, Transduce,
is proposed, which is founded on the construction of abstract transduction
grammars and their generalization. We experimentally demonstrate that Transduce
can learn positional transformations efficiently from one or two positive
examples without inductive bias, achieving a success rate higher than the
current state of the art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09431">A Smoothing Algorithm for l1 Support Vector Machines. (arXiv:2401.09431v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Emirahmetoglu_I/0/1/0/all/0/1">Ibrahim Emirahmetoglu</a>, <a href="http://arxiv.org/find/math/1/au:+Hajewski_J/0/1/0/all/0/1">Jeffrey Hajewski</a>, <a href="http://arxiv.org/find/math/1/au:+Oliveira_S/0/1/0/all/0/1">Suely Oliveira</a>, <a href="http://arxiv.org/find/math/1/au:+Stewart_D/0/1/0/all/0/1">David E. Stewart</a></p>
<p>A smoothing algorithm is presented for solving the soft-margin Support Vector
Machine (SVM) optimization problem with an $\ell^{1}$ penalty. This algorithm
is designed to require a modest number of passes over the data, which is an
important measure of its cost for very large datasets. The algorithm uses
smoothing for the hinge-loss function, and an active set approach for the
$\ell^{1}$ penalty. The smoothing parameter $\alpha$ is initially large, but
typically halved when the smoothed problem is solved to sufficient accuracy.
Convergence theory is presented that shows
$\mathcal{O}(1+\log(1+\log_+(1/\alpha)))$ guarded Newton steps for each value
of $\alpha$ except for asymptotic bands $\alpha=\Theta(1)$ and
$\alpha=\Theta(1/N)$, with only one Newton step provided $\eta\alpha\gg1/N$,
where $N$ is the number of data points and the stopping criterion that the
predicted reduction is less than $\eta\alpha$. The experimental results show
that our algorithm is capable of strong test accuracy without sacrificing
training speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09432">RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language Models. (arXiv:2401.09432v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1">Meiling Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xuechen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Tianyu Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yiting Xie</a></p>
<p>This study presents RoleCraft-GLM, an innovative framework aimed at enhancing
personalized role-playing with Large Language Models (LLMs). RoleCraft-GLM
addresses the key issue of lacking personalized interactions in conversational
AI, and offers a solution with detailed and emotionally nuanced character
portrayals. We contribute a unique conversational dataset that shifts from
conventional celebrity-centric characters to diverse, non-celebrity personas,
thus enhancing the realism and complexity of language modeling interactions.
Additionally, our approach includes meticulous character development, ensuring
dialogues are both realistic and emotionally resonant. The effectiveness of
RoleCraft-GLM is validated through various case studies, highlighting its
versatility and skill in different scenarios. Our framework excels in
generating dialogues that accurately reflect characters' personality traits and
emotions, thereby boosting user engagement. In conclusion, RoleCraft-GLM marks
a significant leap in personalized AI interactions, and paves the way for more
authentic and immersive AI-assisted role-playing experiences by enabling more
nuanced and emotionally rich dialogues
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09441">Voxceleb-ESP: preliminary experiments detecting Spanish celebrities from their voices. (arXiv:2401.09441v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Labrador_B/0/1/0/all/0/1">Beltr&#xe1;n Labrador</a>, <a href="http://arxiv.org/find/cs/1/au:+Otero_Gonzalez_M/0/1/0/all/0/1">Manuel Otero-Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozano_Diez_A/0/1/0/all/0/1">Alicia Lozano-Diez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_D/0/1/0/all/0/1">Daniel Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Toledano_D/0/1/0/all/0/1">Doroteo T. Toledano</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Rodriguez_J/0/1/0/all/0/1">Joaquin Gonzalez-Rodriguez</a></p>
<p>This paper presents VoxCeleb-ESP, a collection of pointers and timestamps to
YouTube videos facilitating the creation of a novel speaker recognition
dataset. VoxCeleb-ESP captures real-world scenarios, incorporating diverse
speaking styles, noises, and channel distortions. It includes 160 Spanish
celebrities spanning various categories, ensuring a representative distribution
across age groups and geographic regions in Spain. We provide two speaker trial
lists for speaker identification tasks, each of them with same-video or
different-video target trials respectively, accompanied by a cross-lingual
evaluation of ResNet pretrained models. Preliminary speaker identification
results suggest that the complexity of the detection task in VoxCeleb-ESP is
equivalent to that of the original and much larger VoxCeleb in English.
VoxCeleb-ESP contributes to the expansion of speaker recognition benchmarks
with a comprehensive and diverse dataset for the Spanish language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09443">CRD: Collaborative Representation Distance for Practical Anomaly Detection. (arXiv:2401.09443v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yudong Yan</a></p>
<p>Visual defect detection plays an important role in intelligent industry.
Patch based methods consider visual images as a collection of image patches
according to positions, which have stronger discriminative ability for small
defects in products, e.g. scratches on pills. However, the nearest neighbor
search for the query image and the stored patches will occupy $O(n)$ complexity
in terms of time and space requirements, posing strict challenges for
deployment in edge environments. In this paper, we propose an alternative
approach to the distance calculation of image patches via collaborative
representation models. Starting from the nearest neighbor distance with $L_0$
constraint, we relax the constraint to $L_2$ constraint and solve the distance
quickly in close-formed without actually accessing the original stored
collection of image patches. Furthermore, we point out that the main
computational burden of this close-formed solution can be pre-computed by
high-performance server before deployment. Consequently, the distance
calculation on edge devices only requires a simple matrix multiplication, which
is extremely lightweight and GPU-friendly. Performance on real industrial
scenarios demonstrates that compared to the existing state-of-the-art methods,
this distance achieves several hundred times improvement in computational
efficiency with slight performance drop, while greatly reducing memory
overhead.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09446">Explainable Multimodal Sentiment Analysis on Bengali Memes. (arXiv:2401.09446v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Elahi_K/0/1/0/all/0/1">Kazi Toufique Elahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1">Tasnuva Binte Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Shakil Shahriar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Samir Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Joy_S/0/1/0/all/0/1">Sajib Kumar Saha Joy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_F/0/1/0/all/0/1">Faisal Muhammad Shah</a></p>
<p>Memes have become a distinctive and effective form of communication in the
digital era, attracting online communities and cutting across cultural
barriers. Even though memes are frequently linked with humor, they have an
amazing capacity to convey a wide range of emotions, including happiness,
sarcasm, frustration, and more. Understanding and interpreting the sentiment
underlying memes has become crucial in the age of information. Previous
research has explored text-based, image-based, and multimodal approaches,
leading to the development of models like CAPSAN and PromptHate for detecting
various meme categories. However, the study of low-resource languages like
Bengali memes remains scarce, with limited availability of publicly accessible
datasets. A recent contribution includes the introduction of the MemoSen
dataset. However, the achieved accuracy is notably low, and the dataset suffers
from imbalanced distribution. In this study, we employed a multimodal approach
using ResNet50 and BanglishBERT and achieved a satisfactory result of 0.71
weighted F1-score, performed comparison with unimodal approaches, and
interpreted behaviors of the models using explainable artificial intelligence
(XAI) techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09451">Diffusion-Driven Generative Framework for Molecular Conformation Prediction. (arXiv:2401.09451v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Yang_B/0/1/0/all/0/1">Bobin Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghan Chen</a></p>
<p>The task of inferring three-dimensional molecular configurations from their
two-dimensional graph representations is of critical significance in the
domains of computational chemistry and the development of pharmaceuticals. It
contributes fundamentally to our grasp of molecular mechanisms and
interactions. The rapid evolution of machine learning, especially in the realm
of deep generative networks, has catalyzed breakthroughs in the precision of
such predictive modeling. Traditional methodologies typically employ a
bifurcated strategy: initially estimating interatomic distances followed by
sculpting the spatial molecular structure via solving a distance geometry
problem. This sequential approach, however, occasionally fails to capture the
intricacies of local atomic arrangements accurately, thus compromising the
integrity of the resultant structural models. Addressing these deficiencies,
this work introduces an avant-garde generative framework: \method{}, which is
predicated on the diffusion principles found in classical non-equilibrium
thermodynamics. \method{} envisages atoms as discrete entities and is adept at
guiding the reversal of diffusion morphing a distribution of stochastic noise
back into coherent molecular forms through a process akin to a Markov chain.
This transformation begins with the initial representation of a molecular graph
in an abstract latent space, progressing to the realization of the
three-dimensional forms via an elaborate bilevel optimization scheme, tailored
to respect the task's specific requirements.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09452">Incorporating Riemannian Geometric Features for Learning Coefficient of Pressure Distributions on Airplane Wings. (arXiv:2401.09452v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Liwei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenyong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yu Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommer_S/0/1/0/all/0/1">Stefan Sommer</a></p>
<p>The aerodynamic coefficients of aircrafts are significantly impacted by its
geometry, especially when the angle of attack (AoA) is large. In the field of
aerodynamics, traditional polynomial-based parameterization uses as few
parameters as possible to describe the geometry of an airfoil. However, because
the 3D geometry of a wing is more complicated than the 2D airfoil,
polynomial-based parameterizations have difficulty in accurately representing
the entire shape of a wing in 3D space. Existing deep learning-based methods
can extract massive latent neural representations for the shape of 2D airfoils
or 2D slices of wings. Recent studies highlight that directly taking geometric
features as inputs to the neural networks can improve the accuracy of predicted
aerodynamic coefficients. Motivated by geometry theory, we propose to
incorporate Riemannian geometric features for learning Coefficient of Pressure
(CP) distributions on wing surfaces. Our method calculates geometric features
(Riemannian metric, connection, and curvature) and further inputs the geometric
features, coordinates and flight conditions into a deep learning model to
predict the CP distribution. Experimental results show that our method,
compared to state-of-the-art Deep Attention Network (DAN), reduces the
predicted mean square error (MSE) of CP by an average of 8.41% for the DLR-F11
aircraft test set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09454">Voila-A: Aligning Vision-Language Models with User&#x27;s Gaze Attention. (arXiv:2401.09454v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Kun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Lei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zeyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuntao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shuai Ma</a></p>
<p>In recent years, the integration of vision and language understanding has led
to significant advancements in artificial intelligence, particularly through
Vision-Language Models (VLMs). However, existing VLMs face challenges in
handling real-world applications with complex scenes and multiple objects, as
well as aligning their focus with the diverse attention patterns of human
users. In this paper, we introduce gaze information, feasibly collected by AR
or VR devices, as a proxy for human attention to guide VLMs and propose a novel
approach, Voila-A, for gaze alignment to enhance the interpretability and
effectiveness of these models in real-world applications. First, we collect
hundreds of minutes of gaze data to demonstrate that we can mimic human gaze
modalities using localized narratives. We then design an automatic data
annotation pipeline utilizing GPT-4 to generate the VOILA-COCO dataset.
Additionally, we innovate the Voila Perceiver modules to integrate gaze
information into VLMs while preserving their pretrained knowledge. We evaluate
Voila-A using a hold-out validation set and a newly collected VOILA-GAZE
Testset, which features real-life scenarios captured with a gaze-tracking
device. Our experimental results demonstrate that Voila-A significantly
outperforms several baseline models. By aligning model attention with human
gaze patterns, Voila-A paves the way for more intuitive, user-centric VLMs and
fosters engaging human-AI interaction across a wide range of applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09455">Dynamic Routing for Integrated Satellite-Terrestrial Networks: A Constrained Multi-Agent Reinforcement Learning Approach. (arXiv:2401.09455v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyu_Y/0/1/0/all/0/1">Yifeng Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Han Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1">Rongfei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_J/0/1/0/all/0/1">Jianping An</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1">Shiwen Mao</a></p>
<p>The integrated satellite-terrestrial network (ISTN) system has experienced
significant growth, offering seamless communication services in remote areas
with limited terrestrial infrastructure. However, designing a routing scheme
for ISTN is exceedingly difficult, primarily due to the heightened complexity
resulting from the inclusion of additional ground stations, along with the
requirement to satisfy various constraints related to satellite service
quality. To address these challenges, we study packet routing with ground
stations and satellites working jointly to transmit packets, while prioritizing
fast communication and meeting energy efficiency and packet loss requirements.
Specifically, we formulate the problem of packet routing with constraints as a
max-min problem using the Lagrange method. Then we propose a novel constrained
Multi-Agent reinforcement learning (MARL) dynamic routing algorithm named
CMADR, which efficiently balances objective improvement and constraint
satisfaction during the updating of policy and Lagrange multipliers. Finally,
we conduct extensive experiments and an ablation study using the OneWeb and
Telesat mega-constellations. Results demonstrate that CMADR reduces the packet
delay by a minimum of 21% and 15%, while meeting stringent energy consumption
and packet loss rate constraints, outperforming several baseline algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09456">Parametric Constraints for Bayesian Knowledge Tracing from First Principles. (arXiv:2401.09456v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shchepakin_D/0/1/0/all/0/1">Denis Shchepakin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankaranarayanan_S/0/1/0/all/0/1">Sreecharan Sankaranarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmaro_D/0/1/0/all/0/1">Dawn Zimmaro</a></p>
<p>Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's
state of mastery corresponding to a knowledge component. It considers the
learner's state of mastery as a "hidden" or latent binary variable and updates
this state based on the observed correctness of the learner's response using
parameters that represent transition probabilities between states. BKT is often
represented as a Hidden Markov Model and the Expectation-Maximization (EM)
algorithm is used to infer these parameters. However, this algorithm can suffer
from several issues including producing multiple viable sets of parameters,
settling into a local minima, producing degenerate parameter values, and a high
computational cost during fitting. This paper takes a "from first principles"
approach to deriving constraints that can be imposed on the BKT parameter
space. Starting from the basic mathematical truths of probability and building
up to the behaviors expected of the BKT parameters in real systems, this paper
presents a mathematical derivation that results in succinct constraints that
can be imposed on the BKT parameter space. Since these constraints are
necessary conditions, they can be applied prior to fitting in order to reduce
computational cost and the likelihood of issues that can emerge from the EM
procedure. In order to see that promise through, the paper further introduces a
novel algorithm for estimating BKT parameters subject to the newly defined
constraints. While the issue of degenerate parameter values has been reported
previously, this paper is the first, to our best knowledge, to derive the
constrains from first principles while also presenting an algorithm that
respects those constraints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09466">Self Supervised Vision for Climate Downscaling. (arXiv:2401.09466v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Singh_K/0/1/0/all/0/1">Karandeep Singh</a>, <a href="http://arxiv.org/find/physics/1/au:+Jeong_C/0/1/0/all/0/1">Chaeyoon Jeong</a>, <a href="http://arxiv.org/find/physics/1/au:+Shidqi_N/0/1/0/all/0/1">Naufal Shidqi</a>, <a href="http://arxiv.org/find/physics/1/au:+Park_S/0/1/0/all/0/1">Sungwon Park</a>, <a href="http://arxiv.org/find/physics/1/au:+Nellikkattil_A/0/1/0/all/0/1">Arjun Nellikkattil</a>, <a href="http://arxiv.org/find/physics/1/au:+Zeller_E/0/1/0/all/0/1">Elke Zeller</a>, <a href="http://arxiv.org/find/physics/1/au:+Cha_M/0/1/0/all/0/1">Meeyoung Cha</a></p>
<p>Climate change is one of the most critical challenges that our planet is
facing today. Rising global temperatures are already bringing noticeable
changes to Earth's weather and climate patterns with an increased frequency of
unpredictable and extreme weather events. Future projections for climate change
research are based on Earth System Models (ESMs), the computer models that
simulate the Earth's climate system. ESMs provide a framework to integrate
various physical systems, but their output is bound by the enormous
computational resources required for running and archiving higher-resolution
simulations. For a given resource budget, the ESMs are generally run on a
coarser grid, followed by a computationally lighter $downscaling$ process to
obtain a finer-resolution output. In this work, we present a deep-learning
model for downscaling ESM simulation data that does not require high-resolution
ground truth data for model optimization. This is realized by leveraging
salient data distribution patterns and the hidden dependencies between weather
variables for an $\textit{individual}$ data point at $\textit{runtime}$.
Extensive evaluation with $2$x, $3$x, and $4$x scaling factors demonstrates
that the proposed model consistently obtains superior performance over that of
various baselines. The improved downscaling performance and no dependence on
high-resolution ground truth data make the proposed method a valuable tool for
climate research and mark it as a promising direction for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09471">Brain Tumor Radiogenomic Classification. (arXiv:2401.09471v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mohamed_A/0/1/0/all/0/1">Amr Mohamed</a>, <a href="http://arxiv.org/find/eess/1/au:+Rabea_M/0/1/0/all/0/1">Mahmoud Rabea</a>, <a href="http://arxiv.org/find/eess/1/au:+Sameh_A/0/1/0/all/0/1">Aya Sameh</a>, <a href="http://arxiv.org/find/eess/1/au:+Kamal_E/0/1/0/all/0/1">Ehab Kamal</a></p>
<p>The RSNA-MICCAI brain tumor radiogenomic classification challenge aimed to
predict MGMT biomarker status in glioblastoma through binary classification on
Multi parameter mpMRI scans: T1w, T1wCE, T2w and FLAIR. The dataset is splitted
into three main cohorts: training set, validation set which were used during
training, and the testing were only used during final evaluation. Images were
either in a DICOM format or in Png format. different architectures were used to
investigate the problem including the 3D version of Vision Transformer (ViT3D),
ResNet50, Xception and EfficientNet-B3. AUC was used as the main evaluation
metric and the results showed an advantage for both the ViT3D and the Xception
models achieving 0.6015 and 0.61745 respectively on the testing set. compared
to other results, our results proved to be valid given the complexity of the
task. further improvements can be made through exploring different strategies,
different architectures and more diverse datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09475">Triamese-ViT: A 3D-Aware Method for Robust Brain Age Estimation from MRIs. (arXiv:2401.09475v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhaonian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1">Richard Jiang</a></p>
<p>The integration of machine learning in medicine has significantly improved
diagnostic precision, particularly in the interpretation of complex structures
like the human brain. Diagnosing challenging conditions such as Alzheimer's
disease has prompted the development of brain age estimation techniques. These
methods often leverage three-dimensional Magnetic Resonance Imaging (MRI)
scans, with recent studies emphasizing the efficacy of 3D convolutional neural
networks (CNNs) like 3D ResNet. However, the untapped potential of Vision
Transformers (ViTs), known for their accuracy and interpretability, persists in
this domain due to limitations in their 3D versions. This paper introduces
Triamese-ViT, an innovative adaptation of the ViT model for brain age
estimation. Our model uniquely combines ViTs from three different orientations
to capture 3D information, significantly enhancing accuracy and
interpretability. Tested on a dataset of 1351 MRI scans, Triamese-ViT achieves
a Mean Absolute Error (MAE) of 3.84, a 0.9 Spearman correlation coefficient
with chronological age, and a -0.29 Spearman correlation coefficient between
the brain age gap (BAG) and chronological age, significantly better than
previous methods for brian age estimation. A key innovation of Triamese-ViT is
its capacity to generate a comprehensive 3D-like attention map, synthesized
from 2D attention maps of each orientation-specific ViT. This feature is
particularly beneficial for in-depth brain age analysis and disease diagnosis,
offering deeper insights into brain health and the mechanisms of age-related
neural changes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09479">Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning. (arXiv:2401.09479v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vishwakarma_R/0/1/0/all/0/1">Rahul Vishwakarma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaei_A/0/1/0/all/0/1">Amin Rezaei</a></p>
<p>The risk of hardware Trojans being inserted at various stages of chip
production has increased in a zero-trust fabless era. To counter this, various
machine learning solutions have been developed for the detection of hardware
Trojans. While most of the focus has been on either a statistical or deep
learning approach, the limited number of Trojan-infected benchmarks affects the
detection accuracy and restricts the possibility of detecting zero-day Trojans.
To close the gap, we first employ generative adversarial networks to amplify
our data in two alternative representation modalities, a graph and a tabular,
ensuring that the dataset is distributed in a representative manner. Further,
we propose a multimodal deep learning approach to detect hardware Trojans and
evaluate the results from both early fusion and late fusion strategies. We also
estimate the uncertainty quantification metrics of each prediction for
risk-aware decision-making. The outcomes not only confirms the efficacy of our
proposed hardware Trojan detection method but also opens a new door for future
studies employing multimodality and uncertainty quantification to address other
hardware security challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09486">LoMA: Lossless Compressed Memory Attention. (arXiv:2401.09486v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yumeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Zhenyang Xiao</a></p>
<p>The ability to handle long texts is one of the most important capabilities of
Large Language Models (LLMs), but as the text length increases, the consumption
of resources also increases dramatically. At present, reducing resource
consumption by compressing the KV cache is a common approach. Although there
are many existing compression methods, they share a common drawback: the
compression is not lossless. That is, information is inevitably lost during the
compression process. If the compression rate is high, the probability of losing
important information increases dramatically. We propose a new method, Lossless
Compressed Memory Attention (LoMA), which allows for lossless compression of
information into special memory token KV pairs according to a set compression
ratio. Our experiments have achieved remarkable results, demonstrating that
LoMA can be efficiently trained and has very effective performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09489">PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies. (arXiv:2401.09489v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Der_A/0/1/0/all/0/1">Audrey Der</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1">Chin-Chia Michael Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junpeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zhongfang Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Keogh_E/0/1/0/all/0/1">Eamonn J. Keogh</a></p>
<p>In recent years there has been significant progress in time series anomaly
detection. However, after detecting an (perhaps tentative) anomaly, can we
explain it? Such explanations would be useful to triage anomalies. For example,
in an oil refinery, should we respond to an anomaly by dispatching a hydraulic
engineer, or an intern to replace the battery on a sensor? There have been some
parallel efforts to explain anomalies, however many proposed techniques produce
explanations that are indirect, and often seem more complex than the anomaly
they seek to explain. Our review of the literature/checklists/user-manuals used
by frontline practitioners in various domains reveals an interesting
near-universal commonality. Most practitioners discuss, explain and report
anomalies in the following format: The anomaly would be like normal data A, if
not for the corruption B. The reader will appreciate that is a type of
counterfactual explanation. In this work we introduce a domain agnostic
counterfactual explanation technique to produce explanations for time series
anomalies. As we will show, our method can produce both visual and text-based
explanations that are objectively correct, intuitive and in many circumstances,
directly actionable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09492">Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian Process Regression. (arXiv:2401.09492v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garcia_Ruiz_R/0/1/0/all/0/1">Rub&#xe9;n Antonio Garc&#xed;a-Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Blanco_Claraco_J/0/1/0/all/0/1">Jos&#xe9; Luis Blanco-Claraco</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Martinez_J/0/1/0/all/0/1">Javier L&#xf3;pez-Mart&#xed;nez</a>, <a href="http://arxiv.org/find/cs/1/au:+Callejon_Ferre_A/0/1/0/all/0/1">&#xc1;ngel Jes&#xfa;s Callej&#xf3;n-Ferre</a></p>
<p>Expensive ultrasonic anemometers are usually required to measure wind speed
accurately. The aim of this work is to overcome the loss of accuracy of a low
cost hot-wire anemometer caused by the changes of air temperature, by means of
a probabilistic calibration using Gaussian Process Regression. Gaussian Process
Regression is a non-parametric, Bayesian, and supervised learning method
designed to make predictions of an unknown target variable as a function of one
or more known input variables. Our approach is validated against real datasets,
obtaining a good performance in inferring the actual wind speed values. By
performing, before its real use in the field, a calibration of the hot-wire
anemometer taking into account air temperature, permits that the wind speed can
be estimated for the typical range of ambient temperatures, including a
grounded uncertainty estimation for each speed measure.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09493">Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification. (arXiv:2401.09493v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Tam_F/0/1/0/all/0/1">Frederick Iat-Hin Tam</a>, <a href="http://arxiv.org/find/physics/1/au:+Beucler_T/0/1/0/all/0/1">Tom Beucler</a>, <a href="http://arxiv.org/find/physics/1/au:+Ruppert_J/0/1/0/all/0/1">James H. Ruppert Jr</a></p>
<p>Cloud radiative feedback impacts early tropical cyclone (TC) intensification,
but limitations in existing diagnostic frameworks make them unsuitable for
studying asymmetric or transient radiative heating. We propose a linear
Variational Encoder-Decoder (VED) to learn the hidden relationship between
radiation and the surface intensification of realistic simulated TCs. Limiting
VED model inputs enables using its uncertainty to identify periods when
radiation has more importance for intensification. A close examination of the
extracted 3D radiative structures suggests that longwave radiative forcing from
inner core deep convection and shallow clouds both contribute to
intensification, with the deep convection having the most impact overall. We
find that deep convection downwind of the shallow clouds is critical to the
intensification of Haiyan. Our work demonstrates that machine learning can
discover thermodynamic-kinematic relationships without relying on axisymmetric
or deterministic assumptions, paving the way towards the objective discovery of
processes leading to TC intensification in realistic conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09494">VeriBug: An Attention-based Framework for Bug-Localization in Hardware Designs. (arXiv:2401.09494v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stracquadanio_G/0/1/0/all/0/1">Giuseppe Stracquadanio</a>, <a href="http://arxiv.org/find/cs/1/au:+Medya_S/0/1/0/all/0/1">Sourav Medya</a>, <a href="http://arxiv.org/find/cs/1/au:+Quer_S/0/1/0/all/0/1">Stefano Quer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_D/0/1/0/all/0/1">Debjit Pal</a></p>
<p>In recent years, there has been an exponential growth in the size and
complexity of System-on-Chip designs targeting different specialized
applications. The cost of an undetected bug in these systems is much higher
than in traditional processor systems as it may imply the loss of property or
life. The problem is further exacerbated by the ever-shrinking time-to-market
and ever-increasing demand to churn out billions of devices. Despite decades of
research in simulation and formal methods for debugging and verification, it is
still one of the most time-consuming and resource intensive processes in
contemporary hardware design cycle. In this work, we propose VeriBug, which
leverages recent advances in deep learning to accelerate debugging at the
Register-Transfer Level and generates explanations of likely root causes.
First, VeriBug uses control-data flow graph of a hardware design and learns to
execute design statements by analyzing the context of operands and their
assignments. Then, it assigns an importance score to each operand in a design
statement and uses that score for generating explanations for failures.
Finally, VeriBug produces a heatmap highlighting potential buggy source code
portions. Our experiments show that VeriBug can achieve an average bug
localization coverage of 82.5% on open-source designs and different types of
injected bugs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09498">Technical Report: On the Convergence of Gossip Learning in the Presence of Node Inaccessibility. (arXiv:2401.09498v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yue Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xueyang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yecheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a></p>
<p>Gossip learning (GL), as a decentralized alternative to federated learning
(FL), is more suitable for resource-constrained wireless networks, such as
FANETs that are formed by unmanned aerial vehicles (UAVs). GL can significantly
enhance the efficiency and extend the battery life of UAV networks. Despite the
advantages, the performance of GL is strongly affected by data distribution,
communication speed, and network connectivity. However, how these factors
influence the GL convergence is still unclear. Existing work studied the
convergence of GL based on a virtual quantity for the sake of convenience,
which fail to reflect the real state of the network when some nodes are
inaccessible. In this paper, we formulate and investigate the impact of
inaccessible nodes to GL under a dynamic network topology. We first decompose
the weight divergence by whether the node is accessible or not. Then, we
investigate the GL convergence under the dynamic of node accessibility and
theoretically provide how the number of inaccessible nodes, data
non-i.i.d.-ness, and duration of inaccessibility affect the convergence.
Extensive experiments are carried out in practical settings to comprehensively
verify the correctness of our theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09499">Functional Autoencoder for Smoothing and Representation Learning. (arXiv:2401.09499v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Sidi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Beaulac_C/0/1/0/all/0/1">C&#xe9;dric Beaulac</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jiguo Cao</a></p>
<p>A common pipeline in functional data analysis is to first convert the
discretely observed data to smooth functions, and then represent the functions
by a finite-dimensional vector of coefficients summarizing the information.
Existing methods for data smoothing and dimensional reduction mainly focus on
learning the linear mappings from the data space to the representation space,
however, learning only the linear representations may not be sufficient. In
this study, we propose to learn the nonlinear representations of functional
data using neural network autoencoders designed to process data in the form it
is usually collected without the need of preprocessing. We design the encoder
to employ a projection layer computing the weighted inner product of the
functional data and functional weights over the observed timestamp, and the
decoder to apply a recovery layer that maps the finite-dimensional vector
extracted from the functional data back to functional space using a set of
predetermined basis functions. The developed architecture can accommodate both
regularly and irregularly spaced data. Our experiments demonstrate that the
proposed method outperforms functional principal component analysis in terms of
prediction and classification, and maintains superior smoothing ability and
better computational efficiency in comparison to the conventional autoencoders
under both linear and nonlinear settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09507">Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising. (arXiv:2401.09507v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhuang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Linhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1">Shuo Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yifan Zeng</a></p>
<p>In the e-commerce advertising scenario, estimating the true probabilities
(known as a calibrated estimate) on CTR and CVR is critical and can directly
affect the benefits of the buyer, seller and platform. Previous research has
introduced numerous solutions for addressing the calibration problem. These
methods typically involve the training of calibrators using a validation set
and subsequently applying these calibrators to correct the original estimated
values during online inference. However, what sets e-commerce advertising
scenarios is the challenge of multi-field calibration. Multi-field calibration
can be subdivided into two distinct sub-problems: value calibration and shape
calibration. Value calibration is defined as no over- or under-estimation for
each value under concerned fields. Shape calibration is defined as no over- or
under-estimation for each subset of the pCTR within the specified range under
condition of concerned fields. In order to achieve shape calibration and value
calibration, it is necessary to have a strong data utilization ability.Because
the quantity of pCTR specified range for single field-value sample is relative
small, which makes the calibrator more difficult to train. However the existing
methods cannot simultaneously fulfill both value calibration and shape
calibration. To solve these problems, we propose a new method named Deep
Ensemble Shape Calibration (DESC). We introduce innovative basis calibration
functions, which enhance both function expression capabilities and data
utilization by combining these basis calibration functions. A significant
advancement lies in the development of an allocator capable of allocating the
most suitable shape calibrators to different estimation error distributions
within diverse fields and values.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09509">Exploration of Activation Fault Reliability in Quantized Systolic Array-Based DNN Accelerators. (arXiv:2401.09509v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Taheri_M/0/1/0/all/0/1">Mahdi Taheri</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherezova_N/0/1/0/all/0/1">Natalia Cherezova</a>, <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mohammad Saeed Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenihhin_M/0/1/0/all/0/1">Maksim Jenihhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahani_A/0/1/0/all/0/1">Ali Mahani</a>, <a href="http://arxiv.org/find/cs/1/au:+Daneshtalab_M/0/1/0/all/0/1">Masoud Daneshtalab</a>, <a href="http://arxiv.org/find/cs/1/au:+Raik_J/0/1/0/all/0/1">Jaan Raik</a></p>
<p>The stringent requirements for the Deep Neural Networks (DNNs) accelerator's
reliability stand along with the need for reducing the computational burden on
the hardware platforms, i.e. reducing the energy consumption and execution time
as well as increasing the efficiency of DNN accelerators. Moreover, the growing
demand for specialized DNN accelerators with tailored requirements,
particularly for safety-critical applications, necessitates a comprehensive
design space exploration to enable the development of efficient and robust
accelerators that meet those requirements. Therefore, the trade-off between
hardware performance, i.e. area and delay, and the reliability of the DNN
accelerator implementation becomes critical and requires tools for analysis.
This paper presents a comprehensive methodology for exploring and enabling a
holistic assessment of the trilateral impact of quantization on model accuracy,
activation fault reliability, and hardware efficiency. A fully automated
framework is introduced that is capable of applying various quantization-aware
techniques, fault injection, and hardware implementation, thus enabling the
measurement of hardware parameters. Moreover, this paper proposes a novel
lightweight protection technique integrated within the framework to ensure the
dependable deployment of the final systolic-array-based FPGA implementation.
The experiments on established benchmarks demonstrate the analysis flow and the
profound implications of quantization on reliability, hardware performance, and
network accuracy, particularly concerning the transient faults in the network's
activations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09510">Community Detection in the Multi-View Stochastic Block Model. (arXiv:2401.09510v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yexin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhongtian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiaosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuelong Li</a></p>
<p>This paper considers the problem of community detection on multiple
potentially correlated graphs from an information-theoretical perspective. We
first put forth a random graph model, called the multi-view stochastic block
model (MVSBM), designed to generate correlated graphs on the same set of nodes
(with cardinality $n$). The $n$ nodes are partitioned into two disjoint
communities of equal size. The presence or absence of edges in the graphs for
each pair of nodes depends on whether the two nodes belong to the same
community or not. The objective for the learner is to recover the hidden
communities with observed graphs. Our technical contributions are two-fold: (i)
We establish an information-theoretic upper bound (Theorem~1) showing that
exact recovery of community is achievable when the model parameters of MVSBM
exceed a certain threshold. (ii) Conversely, we derive an information-theoretic
lower bound (Theorem~2) showing that when the model parameters of MVSBM fall
below the aforementioned threshold, then for any estimator, the expected number
of misclassified nodes will always be greater than one. Our results for the
MVSBM recover several prior results for community detection in the standard SBM
as well as in multiple independent SBMs as special cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09515">Enhancing Surveillance Camera FOV Quality via Semantic Line Detection and Classification with Deep Hough Transform. (arXiv:2401.09515v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Freeman_A/0/1/0/all/0/1">Andrew C. Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Wenjing Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_B/0/1/0/all/0/1">Bin Hwang</a></p>
<p>The quality of recorded videos and images is significantly influenced by the
camera's field of view (FOV). In critical applications like surveillance
systems and self-driving cars, an inadequate FOV can give rise to severe safety
and security concerns, including car accidents and thefts due to the failure to
detect individuals and objects. The conventional methods for establishing the
correct FOV heavily rely on human judgment and lack automated mechanisms to
assess video and image quality based on FOV. In this paper, we introduce an
innovative approach that harnesses semantic line detection and classification
alongside deep Hough transform to identify semantic lines, thus ensuring a
suitable FOV by understanding 3D view through parallel lines. Our approach
yields an effective F1 score of 0.729 on the public EgoCart dataset, coupled
with a notably high median score in the line placement metric. We illustrate
that our method offers a straightforward means of assessing the quality of the
camera's field of view, achieving a classification accuracy of 83.8\%. This
metric can serve as a proxy for evaluating the potential performance of video
and image quality applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09516">Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling. (arXiv:2401.09516v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhongkai Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_Z/0/1/0/all/0/1">Zijie Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a></p>
<p>Learning neural operators for solving partial differential equations (PDEs)
has attracted great attention due to its high inference efficiency. However,
training such operators requires generating a substantial amount of labeled
data, i.e., PDE problems together with their solutions. The data generation
process is exceptionally time-consuming, as it involves solving numerous
systems of linear equations to obtain numerical solutions to the PDEs. Many
existing methods solve these systems independently without considering their
inherent similarities, resulting in extremely redundant computations. To tackle
this problem, we propose a novel method, namely Sorting Krylov Recycling (SKR),
to boost the efficiency of solving these systems, thus significantly
accelerating data generation for neural operators training. To the best of our
knowledge, SKR is the first attempt to address the time-consuming nature of
data generation for learning neural operators. The working horse of SKR is
Krylov subspace recycling, a powerful technique for solving a series of
interrelated systems by leveraging their inherent similarities. Specifically,
SKR employs a sorting algorithm to arrange these systems in a sequence, where
adjacent systems exhibit high similarities. Then it equips a solver with Krylov
subspace recycling to solve the systems sequentially instead of independently,
thus effectively enhancing the solving efficiency. Both theoretical analysis
and extensive experiments demonstrate that SKR can significantly accelerate
neural operator data generation, achieving a remarkable speedup of up to 13.9
times.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09517">Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning. (arXiv:2401.09517v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Junhao Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Antoniades_M/0/1/0/all/0/1">Mathilde Antoniades</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhijian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_G/0/1/0/all/0/1">Gyujoon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Skampardoni_I/0/1/0/all/0/1">Ioanna Skampardoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rongguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Davatzikos_C/0/1/0/all/0/1">Christos Davatzikos</a></p>
<p>Machine learning has been increasingly used to obtain individualized
neuroimaging signatures for disease diagnosis, prognosis, and response to
treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it
has contributed to a better understanding of disease heterogeneity by
identifying disease subtypes that present significant differences in various
brain phenotypic measures. In this review, we first present a systematic
literature overview of studies using machine learning and multimodal MRI to
unravel disease heterogeneity in various neuropsychiatric and neurodegenerative
disorders, including Alzheimer disease, schizophrenia, major depressive
disorder, autism spectrum disorder, multiple sclerosis, as well as their
potential in transdiagnostic settings. Subsequently, we summarize relevant
machine learning methodologies and discuss an emerging paradigm which we call
dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological
heterogeneity of neuropsychiatric and neurodegenerative disorders into a low
dimensional yet informative, quantitative brain phenotypic representation,
serving as a robust intermediate phenotype (i.e., endophenotype) largely
reflecting underlying genetics and etiology. Finally, we discuss the potential
clinical implications of the current findings and envision future research
avenues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09555">Improving Classification Performance With Human Feedback: Label a few, we label the rest. (arXiv:2401.09555v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vidra_N/0/1/0/all/0/1">Natan Vidra</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifford_T/0/1/0/all/0/1">Thomas Clifford</a>, <a href="http://arxiv.org/find/cs/1/au:+Jijo_K/0/1/0/all/0/1">Katherine Jijo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_E/0/1/0/all/0/1">Eden Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a></p>
<p>In the realm of artificial intelligence, where a vast majority of data is
unstructured, obtaining substantial amounts of labeled data to train supervised
machine learning models poses a significant challenge. To address this, we
delve into few-shot and active learning, where are goal is to improve AI models
with human feedback on a few labeled examples. This paper focuses on
understanding how a continuous feedback loop can refine models, thereby
enhancing their accuracy, recall, and precision through incremental human
input. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and
SetFit, we aim to analyze the efficacy of using a limited number of labeled
examples to substantially improve model accuracy. We benchmark this approach on
the Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to
prove that with just a few labeled examples, we are able to surpass the
accuracy of zero shot large language models to provide enhanced text
classification performance. We demonstrate that rather than needing to manually
label millions of rows of data, we just need to label a few and the model can
effectively predict the rest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09556">Deep learning enhanced mixed integer optimization: Learning to reduce model dimensionality. (arXiv:2401.09556v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Triantafyllou_N/0/1/0/all/0/1">Niki Triantafyllou</a>, <a href="http://arxiv.org/find/math/1/au:+Papathanasiou_M/0/1/0/all/0/1">Maria M. Papathanasiou</a></p>
<p>This work introduces a framework to address the computational complexity
inherent in Mixed-Integer Programming (MIP) models by harnessing the potential
of deep learning. We compare the effectiveness of (a) feed-forward neural
networks (ANN) and (b) convolutional neural networks (CNN) in approximating the
active dimensions within MIP problems. We utilize multi-label classification to
account for more than one active dimension. To enhance the framework's
performance, we employ Bayesian optimization for hyperparameter tuning, aiming
to maximize sample-level accuracy. The primary objective is to train the neural
networks to predict all active dimensions accurately, thereby maximizing the
occurrence of global optimum solutions. We apply this framework to a flow-based
facility location allocation Mixed-Integer Linear Programming (MILP)
formulation that describes long-term investment planning and medium-term
tactical planning in a personalized medicine supply chain for cell therapy
manufacturing and distribution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09561">Sharing Knowledge in Multi-Task Deep Reinforcement Learning. (arXiv:2401.09561v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DEramo_C/0/1/0/all/0/1">Carlo D&#x27;Eramo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tateo_D/0/1/0/all/0/1">Davide Tateo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonarini_A/0/1/0/all/0/1">Andrea Bonarini</a>, <a href="http://arxiv.org/find/cs/1/au:+Restelli_M/0/1/0/all/0/1">Marcello Restelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a></p>
<p>We study the benefit of sharing representations among tasks to enable the
effective use of deep neural networks in Multi-Task Reinforcement Learning. We
leverage the assumption that learning from different tasks, sharing common
properties, is helpful to generalize the knowledge of them resulting in a more
effective feature extraction compared to learning a single task. Intuitively,
the resulting set of features offers performance benefits when used by
Reinforcement Learning algorithms. We prove this by providing theoretical
guarantees that highlight the conditions for which is convenient to share
representations among tasks, extending the well-known finite-time bounds of
Approximate Value-Iteration to the multi-task setting. In addition, we
complement our analysis by proposing multi-task extensions of three
Reinforcement Learning algorithms that we empirically evaluate on widely used
Reinforcement Learning benchmarks showing significant improvements over the
single-task counterparts in terms of sample efficiency and performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09574">Towards Scalable and Robust Model Versioning. (arXiv:2401.09574v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenxin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhagoji_A/0/1/0/all/0/1">Arjun Nitin Bhagoji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Ben Y. Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haitao Zheng</a></p>
<p>As the deployment of deep learning models continues to expand across
industries, the threat of malicious incursions aimed at gaining access to these
deployed models is on the rise. Should an attacker gain access to a deployed
model, whether through server breaches, insider attacks, or model inversion
techniques, they can then construct white-box adversarial attacks to manipulate
the model's classification outcomes, thereby posing significant risks to
organizations that rely on these models for critical tasks. Model owners need
mechanisms to protect themselves against such losses without the necessity of
acquiring fresh training data - a process that typically demands substantial
investments in time and capital.
</p>
<p>In this paper, we explore the feasibility of generating multiple versions of
a model that possess different attack properties, without acquiring new
training data or changing model architecture. The model owner can deploy one
version at a time and replace a leaked version immediately with a new version.
The newly deployed model version can resist adversarial attacks generated
leveraging white-box access to one or all previously leaked versions. We show
theoretically that this can be accomplished by incorporating parameterized
hidden distributions into the model training data, forcing the model to learn
task-irrelevant features uniquely defined by the chosen data. Additionally,
optimal choices of hidden distributions can produce a sequence of model
versions capable of resisting compound transferability attacks over time.
Leveraging our analytical insights, we design and implement a practical model
versioning method for DNN classifiers, which leads to significant robustness
improvements over existing methods. We believe our work presents a promising
direction for safeguarding DNN services beyond their initial deployment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09579">Fully-blind Neural Network Based Equalization for Severe Nonlinear Distortions in 112 Gbit/s Passive Optical Networks. (arXiv:2401.09579v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Lauinger_V/0/1/0/all/0/1">Vincent Lauinger</a>, <a href="http://arxiv.org/find/eess/1/au:+Matalla_P/0/1/0/all/0/1">Patrick Matalla</a>, <a href="http://arxiv.org/find/eess/1/au:+Ney_J/0/1/0/all/0/1">Jonas Ney</a>, <a href="http://arxiv.org/find/eess/1/au:+Wehn_N/0/1/0/all/0/1">Norbert Wehn</a>, <a href="http://arxiv.org/find/eess/1/au:+Randel_S/0/1/0/all/0/1">Sebastian Randel</a>, <a href="http://arxiv.org/find/eess/1/au:+Schmalen_L/0/1/0/all/0/1">Laurent Schmalen</a></p>
<p>We demonstrate and evaluate a fully-blind digital signal processing (DSP)
chain for 100G passive optical networks (PONs), and analyze different equalizer
topologies based on neural networks with low hardware complexity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09582">eipy: An Open-Source Python Package for Multi-modal Data Integration using Heterogeneous Ensembles. (arXiv:2401.09582v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bennett_J/0/1/0/all/0/1">Jamie J. R. Bennett</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yan Chak Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_G/0/1/0/all/0/1">Gaurav Pandey</a></p>
<p>In this paper, we introduce eipy--an open-source Python package for
developing effective, multi-modal heterogeneous ensembles for classification.
eipy simultaneously provides both a rigorous, and user-friendly framework for
comparing and selecting the best-performing multi-modal data integration and
predictive modeling methods by systematically evaluating their performance
using nested cross-validation. The package is designed to leverage
scikit-learn-like estimators as components to build multi-modal predictive
models. An up-to-date user guide, including API reference and tutorials, for
eipy is maintained at https://eipy.readthedocs.io . The main repository for
this project can be found on GitHub at https://github.com/GauravPandeyLab/eipy .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09587">Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis. (arXiv:2401.09587v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jie Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1">Xiaochuan Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingrui Liu</a></p>
<p>Bilevel optimization is an important formulation for many machine learning
problems. Current bilevel optimization algorithms assume that the gradient of
the upper-level function is Lipschitz. However, recent studies reveal that
certain neural networks such as recurrent neural networks (RNNs) and
long-short-term memory networks (LSTMs) exhibit potential unbounded smoothness,
rendering conventional bilevel optimization algorithms unsuitable. In this
paper, we design a new bilevel optimization algorithm, namely BO-REP, to
address this challenge. This algorithm updates the upper-level variable using
normalized momentum and incorporates two novel techniques for updating the
lower-level variable: \textit{initialization refinement} and \textit{periodic
updates}. Specifically, once the upper-level variable is initialized, a
subroutine is invoked to obtain a refined estimate of the corresponding optimal
lower-level variable, and the lower-level variable is updated only after every
specific period instead of each iteration. When the upper-level problem is
nonconvex and unbounded smooth, and the lower-level problem is strongly convex,
we prove that our algorithm requires $\widetilde{\mathcal{O}}(1/\epsilon^4)$
iterations to find an $\epsilon$-stationary point in the stochastic setting,
where each iteration involves calling a stochastic gradient or Hessian-vector
product oracle. Notably, this result matches the state-of-the-art complexity
results under the bounded smoothness setting and without mean-squared
smoothness of the stochastic gradient, up to logarithmic factors. Our proof
relies on novel technical lemmas for the periodically updated lower-level
variable, which are of independent interest. Our experiments on
hyper-representation learning, hyperparameter optimization, and data
hyper-cleaning for text classification tasks demonstrate the effectiveness of
our proposed algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09596">Efficient generative adversarial networks using linear additive-attention Transformers. (arXiv:2401.09596v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Morales_Juarez_E/0/1/0/all/0/1">Emilio Morales-Juarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuentes_Pineda_G/0/1/0/all/0/1">Gibran Fuentes-Pineda</a></p>
<p>Although the capacity of deep generative models for image generation, such as
Diffusion Models (DMs) and Generative Adversarial Networks (GANs), has
dramatically improved in recent years, much of their success can be attributed
to computationally expensive architectures. This has limited their adoption and
use to research laboratories and companies with large resources, while
significantly raising the carbon footprint for training, fine-tuning, and
inference. In this work, we present LadaGAN, an efficient generative
adversarial network that is built upon a novel Transformer block named
Ladaformer. The main component of this block is a linear additive-attention
mechanism that computes a single attention vector per head instead of the
quadratic dot-product attention. We employ Ladaformer in both the generator and
discriminator, which reduces the computational complexity and overcomes the
training instabilities often associated with Transformer GANs. LadaGAN
consistently outperforms existing convolutional and Transformer GANs on
benchmark datasets at different resolutions while being significantly more
efficient. Moreover, LadaGAN shows competitive performance compared to
state-of-the-art multi-step generative models (e.g. DMs) using orders of
magnitude less computational resources.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09604">MedBlindTuner: Towards Privacy-preserving Fine-tuning on Biomedical Images with Transformers and Fully Homomorphic Encryption. (arXiv:2401.09604v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Panzade_P/0/1/0/all/0/1">Prajwal Panzade</a>, <a href="http://arxiv.org/find/cs/1/au:+Takabi_D/0/1/0/all/0/1">Daniel Takabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhipeng Cai</a></p>
<p>Advancements in machine learning (ML) have significantly revolutionized
medical image analysis, prompting hospitals to rely on external ML services.
However, the exchange of sensitive patient data, such as chest X-rays, poses
inherent privacy risks when shared with third parties. Addressing this concern,
we propose MedBlindTuner, a privacy-preserving framework leveraging fully
homomorphic encryption (FHE) and a data-efficient image transformer (DEiT).
MedBlindTuner enables the training of ML models exclusively on FHE-encrypted
medical images. Our experimental evaluation demonstrates that MedBlindTuner
achieves comparable accuracy to models trained on non-encrypted images,
offering a secure solution for outsourcing ML computations while preserving
patient data privacy. To the best of our knowledge, this is the first work that
uses data-efficient image transformers and fully homomorphic encryption in this
domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09606">Robustness Evaluation of Machine Learning Models for Robot Arm Action Recognition in Noisy Environments. (arXiv:2401.09606v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Motamedi_E/0/1/0/all/0/1">Elaheh Motamedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Behzad_K/0/1/0/all/0/1">Kian Behzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Zandi_R/0/1/0/all/0/1">Rojin Zandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salehinejad_H/0/1/0/all/0/1">Hojjat Salehinejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Siami_M/0/1/0/all/0/1">Milad Siami</a></p>
<p>In the realm of robot action recognition, identifying distinct but spatially
proximate arm movements using vision systems in noisy environments poses a
significant challenge. This paper studies robot arm action recognition in noisy
environments using machine learning techniques. Specifically, a vision system
is used to track the robot's movements followed by a deep learning model to
extract the arm's key points. Through a comparative analysis of machine
learning methods, the effectiveness and robustness of this model are assessed
in noisy environments. A case study was conducted using the Tic-Tac-Toe game in
a 3-by-3 grid environment, where the focus is to accurately identify the
actions of the arms in selecting specific locations within this constrained
environment. Experimental results show that our approach can achieve precise
key point detection and action classification despite the addition of noise and
uncertainties to the dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09607">Land Cover Image Classification. (arXiv:2401.09607v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rangel_A/0/1/0/all/0/1">Antonio Rangel</a>, <a href="http://arxiv.org/find/cs/1/au:+Terven_J/0/1/0/all/0/1">Juan Terven</a>, <a href="http://arxiv.org/find/cs/1/au:+Cordova_Esparza_D/0/1/0/all/0/1">Diana M. Cordova-Esparza</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavez_Urbiola_E/0/1/0/all/0/1">E.A. Chavez-Urbiola</a></p>
<p>Land Cover (LC) image classification has become increasingly significant in
understanding environmental changes, urban planning, and disaster management.
However, traditional LC methods are often labor-intensive and prone to human
error. This paper explores state-of-the-art deep learning models for enhanced
accuracy and efficiency in LC analysis. We compare convolutional neural
networks (CNN) against transformer-based methods, showcasing their applications
and advantages in LC studies. We used EuroSAT, a patch-based LC classification
data set based on Sentinel-2 satellite images and achieved state-of-the-art
results using current transformer models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09622">SMOOTHIE: A Theory of Hyper-parameter Optimization for Software Analytics. (arXiv:2401.09622v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yedida_R/0/1/0/all/0/1">Rahul Yedida</a>, <a href="http://arxiv.org/find/cs/1/au:+Menzies_T/0/1/0/all/0/1">Tim Menzies</a></p>
<p>Hyper-parameter optimization is the black art of tuning a learner's control
parameters. In software analytics, a repeated result is that such tuning can
result in dramatic performance improvements. Despite this, hyper-parameter
optimization is often applied rarely or poorly in software analytics--perhaps
due to the CPU cost of exploring all those parameter options can be
prohibitive.
</p>
<p>We theorize that learners generalize better when the loss landscape is
``smooth''. This theory is useful since the influence on ``smoothness'' of
different hyper-parameter choices can be tested very quickly (e.g. for a deep
learner, after just one epoch).
</p>
<p>To test this theory, this paper implements and tests SMOOTHIE, a novel
hyper-parameter optimizer that guides its optimizations via considerations of
``smothness''. The experiments of this paper test SMOOTHIE on numerous SE tasks
including (a) GitHub issue lifetime prediction; (b) detecting false alarms in
static code warnings; (c) defect prediction, and (d) a set of standard ML
datasets. In all these experiments, SMOOTHIE out-performed state-of-the-art
optimizers. Better yet, SMOOTHIE ran 300% faster than the prior state-of-the
art. We hence conclude that this theory (that hyper-parameter optimization is
best viewed as a ``smoothing'' function for the decision landscape), is both
theoretically interesting and practically very useful.
</p>
<p>To support open science and other researchers working in this area, all our
scripts and datasets are available on-line at
https://github.com/yrahul3910/smoothness-hpo/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09624">MITS-GAN: Safeguarding Medical Imaging from Tampering with Generative Adversarial Networks. (arXiv:2401.09624v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Pasqualino_G/0/1/0/all/0/1">Giovanni Pasqualino</a>, <a href="http://arxiv.org/find/eess/1/au:+Guarnera_L/0/1/0/all/0/1">Luca Guarnera</a>, <a href="http://arxiv.org/find/eess/1/au:+Ortis_A/0/1/0/all/0/1">Alessandro Ortis</a>, <a href="http://arxiv.org/find/eess/1/au:+Battiato_S/0/1/0/all/0/1">Sebastiano Battiato</a></p>
<p>The progress in generative models, particularly Generative Adversarial
Networks (GANs), opened new possibilities for image generation but raised
concerns about potential malicious uses, especially in sensitive areas like
medical imaging. This study introduces MITS-GAN, a novel approach to prevent
tampering in medical images, with a specific focus on CT scans. The approach
disrupts the output of the attacker's CT-GAN architecture by introducing
imperceptible but yet precise perturbations. Specifically, the proposed
approach involves the introduction of appropriate Gaussian noise to the input
as a protective measure against various attacks. Our method aims to enhance
tamper resistance, comparing favorably to existing techniques. Experimental
results on a CT scan dataset demonstrate MITS-GAN's superior performance,
emphasizing its ability to generate tamper-resistant images with negligible
artifacts. As image tampering in medical domains poses life-threatening risks,
our proactive approach contributes to the responsible and ethical use of
generative models. This work provides a foundation for future research in
countering cyber threats in medical imaging. Models and codes are publicly
available at the following link
\url{https://iplab.dmi.unict.it/MITS-GAN-2024/}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09627">SymTC: A Symbiotic Transformer-CNN Net for Instance Segmentation of Lumbar Spine MRI. (arXiv:2401.09627v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Jiasong Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Qian_L/0/1/0/all/0/1">Linchen Qian</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_L/0/1/0/all/0/1">Linhai Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Urakov_T/0/1/0/all/0/1">Timur Urakov</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_W/0/1/0/all/0/1">Weiyong Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Liang_L/0/1/0/all/0/1">Liang Liang</a></p>
<p>Intervertebral disc disease, a prevalent ailment, frequently leads to
intermittent or persistent low back pain, and diagnosing and assessing of this
disease rely on accurate measurement of vertebral bone and intervertebral disc
geometries from lumbar MR images. Deep neural network (DNN) models may assist
clinicians with more efficient image segmentation of individual instances
(disks and vertebrae) of the lumbar spine in an automated way, which is termed
as instance image segmentation. In this work, we proposed SymTC, an innovative
lumbar spine MR image segmentation model that combines the strengths of
Transformer and Convolutional Neural Network (CNN). Specifically, we designed a
parallel dual-path architecture to merge CNN layers and Transformer layers, and
we integrated a novel position embedding into the self-attention module of
Transformer, enhancing the utilization of positional information for more
accurate segmentation. To further improves model performance, we introduced a
new data augmentation technique to create synthetic yet realistic MR image
dataset, named SSMSpine, which is made publicly available. We evaluated our
SymTC and the other 15 existing image segmentation models on our private
in-house dataset and the public SSMSpine dataset, using two metrics, Dice
Similarity Coefficient and 95% Hausdorff Distance. The results show that our
SymTC has the best performance for segmenting vertebral bones and
intervertebral discs in lumbar spine MR images. The SymTC code and SSMSpine
dataset are available at https://github.com/jiasongchen/SymTC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09629">Multiple Locally Linear Kernel Machines. (arXiv:2401.09629v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Picard_D/0/1/0/all/0/1">David Picard</a></p>
<p>In this paper we propose a new non-linear classifier based on a combination
of locally linear classifiers. A well known optimization formulation is given
as we cast the problem in a $\ell_1$ Multiple Kernel Learning (MKL) problem
using many locally linear kernels. Since the number of such kernels is huge, we
provide a scalable generic MKL training algorithm handling streaming kernels.
With respect to the inference time, the resulting classifier fits the gap
between high accuracy but slow non-linear classifiers (such as classical MKL)
and fast but low accuracy linear classifiers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09631">Physics-Informed Calibration of Aeromagnetic Compensation in Magnetic Navigation Systems using Liquid Time-Constant Networks. (arXiv:2401.09631v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nerrise_F/0/1/0/all/0/1">Favour Nerrise</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Sosanya_A/0/1/0/all/0/1">Andrew Sosa Sosanya</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Neary_P/0/1/0/all/0/1">Patrick Neary</a> (2) ((1) Department of Electrical Engineering, Stanford University, CA, USA, (2) SandboxAQ, Palo Alto, CA, USA)</p>
<p>Magnetic navigation (MagNav) is a rising alternative to the Global
Positioning System (GPS) and has proven useful for aircraft navigation.
Traditional aircraft navigation systems, while effective, face limitations in
precision and reliability in certain environments and against attacks. Airborne
MagNav leverages the Earth's magnetic field to provide accurate positional
information. However, external magnetic fields induced by aircraft electronics
and Earth's large-scale magnetic fields disrupt the weaker signal of interest.
We introduce a physics-informed approach using Tolles-Lawson coefficients for
compensation and Liquid Time-Constant Networks (LTCs) to remove complex, noisy
signals derived from the aircraft's magnetic sources. Using real flight data
with magnetometer measurements and aircraft measurements, we observe up to a
64% reduction in aeromagnetic compensation error (RMSE nT), outperforming
conventional models. This significant improvement underscores the potential of
a physics-informed, machine learning approach for extracting clean, reliable,
and accurate magnetic signals for MagNav positional estimation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09638">Automatic 3D Multi-modal Ultrasound Segmentation of Human Placenta using Fusion Strategies and Deep Learning. (arXiv:2401.09638v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Singh_S/0/1/0/all/0/1">Sonit Singh</a>, <a href="http://arxiv.org/find/eess/1/au:+Stevenson_G/0/1/0/all/0/1">Gordon Stevenson</a>, <a href="http://arxiv.org/find/eess/1/au:+Mein_B/0/1/0/all/0/1">Brendan Mein</a>, <a href="http://arxiv.org/find/eess/1/au:+Welsh_A/0/1/0/all/0/1">Alec Welsh</a>, <a href="http://arxiv.org/find/eess/1/au:+Sowmya_A/0/1/0/all/0/1">Arcot Sowmya</a></p>
<p>Purpose: Ultrasound is the most commonly used medical imaging modality for
diagnosis and screening in clinical practice. Due to its safety profile,
noninvasive nature and portability, ultrasound is the primary imaging modality
for fetal assessment in pregnancy. Current ultrasound processing methods are
either manual or semi-automatic and are therefore laborious, time-consuming and
prone to errors, and automation would go a long way in addressing these
challenges. Automated identification of placental changes at earlier gestation
could facilitate potential therapies for conditions such as fetal growth
restriction and pre-eclampsia that are currently detected only at late
gestational age, potentially preventing perinatal morbidity and mortality.
</p>
<p>Methods: We propose an automatic three-dimensional multi-modal (B-mode and
power Doppler) ultrasound segmentation of the human placenta using deep
learning combined with different fusion strategies.We collected data containing
Bmode and power Doppler ultrasound scans for 400 studies.
</p>
<p>Results: We evaluated different fusion strategies and state-of-the-art image
segmentation networks for placenta segmentation based on standard overlap- and
boundary-based metrics. We found that multimodal information in the form of
B-mode and power Doppler scans outperform any single modality. Furthermore, we
found that B-mode and power Doppler input scans fused at the data level provide
the best results with a mean Dice Similarity Coefficient (DSC) of 0.849.
</p>
<p>Conclusion: We conclude that the multi-modal approach of combining B-mode and
power Doppler scans is effective in segmenting the placenta from 3D ultrasound
scans in a fully automated manner and is robust to quality variation of the
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09641">Functional Linear Non-Gaussian Acyclic Model for Causal Discovery. (arXiv:2401.09641v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tian-Le Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kuang-Yao Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_J/0/1/0/all/0/1">Joe Suzuki</a></p>
<p>In causal discovery, non-Gaussianity has been used to characterize the
complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM),
encompassing both the causal ordering of variables and their respective
connection strengths. However, LiNGAM can only deal with the finite-dimensional
case. To expand this concept, we extend the notion of variables to encompass
vectors and even functions, leading to the Functional Linear Non-Gaussian
Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify
causal relationships in brain-effective connectivity tasks involving, for
example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to
handle these inherently infinite-dimensional datasets and explain the
availability of functional data analysis from both empirical and theoretical
perspectives. {We establish theoretical guarantees of the identifiability of
the causal relationship among non-Gaussian random vectors and even random
functions in infinite-dimensional Hilbert spaces.} To address the issue of
sparsity in discrete time points within intrinsic infinite-dimensional
functional data, we propose optimizing the coordinates of the vectors using
functional principal component analysis. Experimental results on synthetic data
verify the ability of the proposed framework to identify causal relationships
among multivariate functions using the observed samples. For real data, we
focus on analyzing the brain connectivity patterns derived from fMRI data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09646">ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on Climate Change. (arXiv:2401.09646v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thulke_D/0/1/0/all/0/1">David Thulke</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yingbo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelser_P/0/1/0/all/0/1">Petrus Pelser</a>, <a href="http://arxiv.org/find/cs/1/au:+Brune_R/0/1/0/all/0/1">Rein Brune</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalota_R/0/1/0/all/0/1">Rricha Jalota</a>, <a href="http://arxiv.org/find/cs/1/au:+Fok_F/0/1/0/all/0/1">Floris Fok</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_M/0/1/0/all/0/1">Michael Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyk_I/0/1/0/all/0/1">Ian van Wyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasir_A/0/1/0/all/0/1">Abdallah Nasir</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_H/0/1/0/all/0/1">Hayden Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Tragemann_T/0/1/0/all/0/1">Taylor Tragemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Katie Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowler_A/0/1/0/all/0/1">Ariana Fowler</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanco_A/0/1/0/all/0/1">Andrew Stanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabriel_J/0/1/0/all/0/1">Jon Gabriel</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_J/0/1/0/all/0/1">Jordan Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Moro_D/0/1/0/all/0/1">Dean Moro</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsymbalov_E/0/1/0/all/0/1">Evgenii Tsymbalov</a>, <a href="http://arxiv.org/find/cs/1/au:+Waal_J/0/1/0/all/0/1">Juliette de Waal</a>, <a href="http://arxiv.org/find/cs/1/au:+Matusov_E/0/1/0/all/0/1">Evgeny Matusov</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaghi_M/0/1/0/all/0/1">Mudar Yaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shihadah_M/0/1/0/all/0/1">Mohammad Shihadah</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>, <a href="http://arxiv.org/find/cs/1/au:+Dugast_C/0/1/0/all/0/1">Christian Dugast</a>, <a href="http://arxiv.org/find/cs/1/au:+Dotan_J/0/1/0/all/0/1">Jonathan Dotan</a>, <a href="http://arxiv.org/find/cs/1/au:+Erasmus_D/0/1/0/all/0/1">Daniel Erasmus</a></p>
<p>This paper introduces ClimateGPT, a model family of domain-specific large
language models that synthesize interdisciplinary research on climate change.
We trained two 7B models from scratch on a science-oriented dataset of 300B
tokens. For the first model, the 4.2B domain-specific tokens were included
during pre-training and the second was adapted to the climate domain after
pre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously
pre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each
model is instruction fine-tuned on a high-quality and human-generated
domain-specific dataset that has been created in close cooperation with climate
scientists. To reduce the number of hallucinations, we optimize the model for
retrieval augmentation and propose a hierarchical retrieval strategy. To
increase the accessibility of our model to non-English speakers, we propose to
make use of cascaded machine translation and show that this approach can
perform comparably to natively multilingual models while being easier to scale
to a large number of languages. Further, to address the intrinsic
interdisciplinary aspect of climate change we consider different research
perspectives. Therefore, the model can produce in-depth answers focusing on
different perspectives in addition to an overall answer. We propose a suite of
automatic climate-specific benchmarks to evaluate LLMs. On these benchmarks,
ClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model
while not degrading results on general domain benchmarks. Our human evaluation
confirms the trends we saw in our benchmarks. All models were trained and
evaluated using renewable energy and are released publicly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09651">Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning. (arXiv:2401.09651v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dickens_C/0/1/0/all/0/1">Charles Dickens</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Changyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1">Connor Pryor</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_S/0/1/0/all/0/1">Stephen Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1">Lise Getoor</a></p>
<p>We address a key challenge for neuro-symbolic (NeSy) systems by leveraging
convex and bilevel optimization techniques to develop a general gradient-based
framework for end-to-end neural and symbolic parameter learning. The
applicability of our framework is demonstrated with NeuPSL, a state-of-the-art
NeSy architecture. To achieve this, we propose a smooth primal and dual
formulation of NeuPSL inference and show learning gradients are functions of
the optimal dual variables. Additionally, we develop a dual block coordinate
descent algorithm for the new formulation that naturally exploits warm-starts.
This leads to over 100x learning runtime improvements over the current best
NeuPSL inference method. Finally, we provide extensive empirical evaluations
across $8$ datasets covering a range of tasks and demonstrate our learning
framework achieves up to a 16% point prediction performance improvement over
alternative learning methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09656">Mobility Accelerates Learning: Convergence Analysis on Hierarchical Federated Learning in Vehicular Networks. (arXiv:2401.09656v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jintao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz G&#xfc;nd&#xfc;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhisheng Niu</a></p>
<p>Hierarchical federated learning (HFL) enables distributed training of models
across multiple devices with the help of several edge servers and a cloud edge
server in a privacy-preserving manner. In this paper, we consider HFL with
highly mobile devices, mainly targeting at vehicular networks. Through
convergence analysis, we show that mobility influences the convergence speed by
both fusing the edge data and shuffling the edge models. While mobility is
usually considered as a challenge from the perspective of communication, we
prove that it increases the convergence speed of HFL with edge-level
heterogeneous data, since more diverse data can be incorporated. Furthermore,
we demonstrate that a higher speed leads to faster convergence, since it
accelerates the fusion of data. Simulation results show that mobility increases
the model accuracy of HFL by up to 15.1% when training a convolutional neural
network on the CIFAR-10 dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09665">Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks. (arXiv:2401.09665v1 [math.PR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>, <a href="http://arxiv.org/find/math/1/au:+Doshi_V/0/1/0/all/0/1">Vishwaraj Doshi</a>, <a href="http://arxiv.org/find/math/1/au:+Eun_D/0/1/0/all/0/1">Do Young Eun</a></p>
<p>We study a family of distributed stochastic optimization algorithms where
gradients are sampled by a token traversing a network of agents in random-walk
fashion. Typically, these random-walks are chosen to be Markov chains that
asymptotically sample from a desired target distribution, and play a critical
role in the convergence of the optimization iterates. In this paper, we take a
novel approach by replacing the standard linear Markovian token by one which
follows a nonlinear Markov chain - namely the Self-Repellent Radom Walk (SRRW).
Defined for any given 'base' Markov chain, the SRRW, parameterized by a
positive scalar {\alpha}, is less likely to transition to states that were
highly visited in the past, thus the name. In the context of MCMC sampling on a
graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW
achieves O(1/{\alpha}) decrease in the asymptotic variance for sampling. We
propose the use of a 'generalized' version of the SRRW to drive token
algorithms for distributed stochastic optimization in the form of stochastic
approximation, termed SA-SRRW. We prove that the optimization iterate errors of
the resulting SA-SRRW converge to zero almost surely and prove a central limit
theorem, deriving the explicit form of the resulting asymptotic covariance
matrix corresponding to iterate errors. This asymptotic covariance is always
smaller than that of an algorithm driven by the base Markov chain and decreases
at rate O(1/{\alpha}^2) - the performance benefit of using SRRW thereby
amplified in the stochastic optimization context. Empirical results support our
theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09671">Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach. (arXiv:2401.09671v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shrestha_S/0/1/0/all/0/1">Sagar Shrestha</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiao Fu</a></p>
<p>Unsupervised domain translation (UDT) aims to find functions that convert
samples from one domain (e.g., sketches) to another domain (e.g., photos)
without changing the high-level semantic meaning (also referred to as
``content''). The translation functions are often sought by probability
distribution matching of the transformed source domain and target domain.
CycleGAN stands as arguably the most representative approach among this line of
work. However, it was noticed in the literature that CycleGAN and variants
could fail to identify the desired translation functions and produce
content-misaligned translations. This limitation arises due to the presence of
multiple translation functions -- referred to as ``measure-preserving
automorphism" (MPA) -- in the solution space of the learning criteria. Despite
awareness of such identifiability issues, solutions have remained elusive. This
study delves into the core identifiability inquiry and introduces an MPA
elimination theory. Our analysis shows that MPA is unlikely to exist, if
multiple pairs of diverse cross-domain conditional distributions are matched by
the learning function. Our theory leads to a UDT learner using distribution
matching over auxiliary variable-induced subsets of the domains -- other than
over the entire data domains as in the classical approaches. The proposed
framework is the first to rigorously establish translation identifiability
under reasonable UDT settings, to our best knowledge. Experiments corroborate
with our theoretical claims.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09673">Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack. (arXiv:2401.09673v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhongliang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weiye Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yifei Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1">Ognjen Arandjelovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Lei Fang</a></p>
<p>Neural style transfer (NST) is widely adopted in computer vision to generate
new images with arbitrary styles. This process leverages neural networks to
merge aesthetic elements of a style image with the structural aspects of a
content image into a harmoniously integrated visual result. However,
unauthorized NST can exploit artwork. Such misuse raises socio-technical
concerns regarding artists' rights and motivates the development of technical
approaches for the proactive protection of original creations. Adversarial
attack is a concept primarily explored in machine learning security. Our work
introduces this technique to protect artists' intellectual property. In this
paper Locally Adaptive Adversarial Color Attack (LAACA), a method for altering
images in a manner imperceptible to the human eyes but disruptive to NST.
Specifically, we design perturbations targeting image areas rich in
high-frequency content, generated by disrupting intermediate features. Our
experiments and user study confirm that by attacking NST using the proposed
method results in visually worse neural style transfer, thus making it an
effective solution for visual artwork protection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09681">Harnessing Density Ratios for Online Reinforcement Learning. (arXiv:2401.09681v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amortila_P/0/1/0/all/0/1">Philip Amortila</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">Dylan J. Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekhari_A/0/1/0/all/0/1">Ayush Sekhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tengyang Xie</a></p>
<p>The theories of offline and online reinforcement learning, despite having
evolved in parallel, have begun to show signs of the possibility for a
unification, with algorithms and analysis techniques for one setting often
having natural counterparts in the other. However, the notion of density ratio
modeling, an emerging paradigm in offline RL, has been largely absent from
online RL, perhaps for good reason: the very existence and boundedness of
density ratios relies on access to an exploratory dataset with good coverage,
but the core challenge in online RL is to collect such a dataset without having
one to start. In this work we show -- perhaps surprisingly -- that density
ratio-based algorithms have online counterparts. Assuming only the existence of
an exploratory distribution with good coverage, a structural condition known as
coverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses
density ratio realizability and value function realizability to perform
sample-efficient online exploration. GLOW addresses unbounded density ratios
via careful use of truncation, and combines this with optimism to guide
exploration. GLOW is computationally inefficient; we complement it with a more
efficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2022)
wherein online RL is augmented with additional offline data. HyGLOW is derived
as a special case of a more general meta-algorithm that provides a provable
black-box reduction from hybrid RL to offline RL, which may be of independent
interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09682">Comparative Study on the Performance of Categorical Variable Encoders in Classification and Regression Tasks. (arXiv:2401.09682v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wenbin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Runwen Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Ying Fu</a></p>
<p>Categorical variables often appear in datasets for classification and
regression tasks, and they need to be encoded into numerical values before
training. Since many encoders have been developed and can significantly impact
performance, choosing the appropriate encoder for a task becomes a
time-consuming yet important practical issue. This study broadly classifies
machine learning models into three categories: 1) ATI models that implicitly
perform affine transformations on inputs, such as multi-layer perceptron neural
network; 2) Tree-based models that are based on decision trees, such as random
forest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot
encoder is the best choice for ATI models in the sense that it can mimic any
other encoders by learning suitable weights from the data. We also explain why
the target encoder and its variants are the most suitable encoders for
tree-based models. This study conducted comprehensive computational experiments
to evaluate 14 encoders, including one-hot and target encoders, along with
eight common machine-learning models on 28 datasets. The computational results
agree with our theoretical analysis. The findings in this study shed light on
how to select the suitable encoder for data scientists in fields such as fraud
detection, disease diagnosis, etc.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09691">Imitation Learning Inputting Image Feature to Each Layer of Neural Network. (arXiv:2401.09691v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yamane_K/0/1/0/all/0/1">Koki Yamane</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakaino_S/0/1/0/all/0/1">Sho Sakaino</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsuji_T/0/1/0/all/0/1">Toshiaki Tsuji</a></p>
<p>Imitation learning enables robots to learn and replicate human behavior from
training data. Recent advances in machine learning enable end-to-end learning
approaches that directly process high-dimensional observation data, such as
images. However, these approaches face a critical challenge when processing
data from multiple modalities, inadvertently ignoring data with a lower
correlation to the desired output, especially when using short sampling
periods. This paper presents a useful method to address this challenge, which
amplifies the influence of data with a relatively low correlation to the output
by inputting the data into each neural network layer. The proposed approach
effectively incorporates diverse data sources into the learning process.
Through experiments using a simple pick-and-place operation with raw images and
joint information as input, significant improvements in success rates are
demonstrated even when dealing with data from short sampling periods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09693">EfficientRec an unlimited user-item scale recommendation system based on clustering and users interaction embedding profile. (arXiv:2401.09693v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Quan_V/0/1/0/all/0/1">Vu Hong Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngan_L/0/1/0/all/0/1">Le Hoang Ngan</a>, <a href="http://arxiv.org/find/cs/1/au:+Duc_L/0/1/0/all/0/1">Le Minh Duc</a>, <a href="http://arxiv.org/find/cs/1/au:+Linh_N/0/1/0/all/0/1">Nguyen Tran Ngoc Linh</a>, <a href="http://arxiv.org/find/cs/1/au:+Quynh_Le_H/0/1/0/all/0/1">Hoang Quynh-Le</a></p>
<p>Recommendation systems are highly interested in technology companies
nowadays. The businesses are constantly growing users and products, causing the
number of users and items to continuously increase over time, to very large
numbers. Traditional recommendation algorithms with complexity dependent on the
number of users and items make them difficult to adapt to the industrial
environment. In this paper, we introduce a new method applying graph neural
networks with a contrastive learning framework in extracting user preferences.
We incorporate a soft clustering architecture that significantly reduces the
computational cost of the inference process. Experiments show that the model is
able to learn user preferences with low computational cost in both training and
prediction phases. At the same time, the model gives a very good accuracy. We
call this architecture EfficientRec with the implication of model compactness
and the ability to scale to unlimited users and products.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09728">Offline Imitation Learning by Controlling the Effective Planning Horizon. (arXiv:2401.09728v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahn_H/0/1/0/all/0/1">Hee-Jun Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shim_S/0/1/0/all/0/1">Seong-Woong Shim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Byung-Jun Lee</a></p>
<p>In offline imitation learning (IL), we generally assume only a handful of
expert trajectories and a supplementary offline dataset from suboptimal
behaviors to learn the expert policy. While it is now common to minimize the
divergence between state-action visitation distributions so that the agent also
considers the future consequences of an action, a sampling error in an offline
dataset may lead to erroneous estimates of state-action visitations in the
offline case. In this paper, we investigate the effect of controlling the
effective planning horizon (i.e., reducing the discount factor) as opposed to
imposing an explicit regularizer, as previously studied. Unfortunately, it
turns out that the existing algorithms suffer from magnified approximation
errors when the effective planning horizon is shortened, which results in a
significant degradation in performance. We analyze the main cause of the
problem and provide the right remedies to correct the algorithm. We show that
the corrected algorithm improves on popular imitation learning benchmarks by
controlling the effective planning horizon rather than an explicit
regularization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09748">Bootstrapping OTS-Funcimg Pre-training Model (Botfip) -- A Comprehensive Symbolic Regression Framework. (arXiv:2401.09748v1 [cs.SC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Pengbo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haibiao Zheng</a></p>
<p>In the field of scientific computing, many problem-solving approaches tend to
focus only on the process and final outcome, even in AI for science, there is a
lack of deep multimodal information mining behind the data, missing a
multimodal framework akin to that in the image-text domain. In this paper, we
take Symbolic Regression(SR) as our focal point and, drawing inspiration from
the BLIP model in the image-text domain, propose a scientific computing
multimodal framework based on Function Images (Funcimg) and Operation Tree
Sequence (OTS), named Bootstrapping OTS-Funcimg Pre-training Model (Botfip). In
SR experiments, we validate the advantages of Botfip in low-complexity SR
problems, showcasing its potential. As a MED framework, Botfip holds promise
for future applications in a broader range of scientific computing problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09750">Exploration and Anti-Exploration with Distributional Random Network Distillation. (arXiv:2401.09750v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1">Jian Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_J/0/1/0/all/0/1">Jiafei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a></p>
<p>Exploration remains a critical issue in deep reinforcement learning for an
agent to attain high returns in unknown environments. Although the prevailing
exploration Random Network Distillation (RND) algorithm has been demonstrated
to be effective in numerous environments, it often needs more discriminative
power in bonus allocation. This paper highlights the ``bonus inconsistency''
issue within RND, pinpointing its primary limitation. To address this issue, we
introduce the Distributional RND (DRND), a derivative of the RND. DRND enhances
the exploration process by distilling a distribution of random networks and
implicitly incorporating pseudo counts to improve the precision of bonus
allocation. This refinement encourages agents to engage in more extensive
exploration. Our method effectively mitigates the inconsistency issue without
introducing significant computational overhead. Both theoretical analysis and
experimental results demonstrate the superiority of our approach over the
original RND algorithm. Our method excels in challenging online exploration
scenarios and effectively serves as an anti-exploration mechanism in D4RL
offline tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09752">Improving Speaker-independent Speech Emotion Recognition Using Dynamic Joint Distribution Adaptation. (arXiv:2401.09752v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_Y/0/1/0/all/0/1">Yuan Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_H/0/1/0/all/0/1">Hailun Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn Schuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wenming Zheng</a></p>
<p>In speaker-independent speech emotion recognition, the training and testing
samples are collected from diverse speakers, leading to a multi-domain shift
challenge across the feature distributions of data from different speakers.
Consequently, when the trained model is confronted with data from new speakers,
its performance tends to degrade. To address the issue, we propose a Dynamic
Joint Distribution Adaptation (DJDA) method under the framework of multi-source
domain adaptation. DJDA firstly utilizes joint distribution adaptation (JDA),
involving marginal distribution adaptation (MDA) and conditional distribution
adaptation (CDA), to more precisely measure the multi-domain distribution
shifts caused by different speakers. This helps eliminate speaker bias in
emotion features, allowing for learning discriminative and speaker-invariant
speech emotion features from coarse-level to fine-level. Furthermore, we
quantify the adaptation contributions of MDA and CDA within JDA by using a
dynamic balance factor based on $\mathcal{A}$-Distance, promoting to
effectively handle the unknown distributions encountered in data from new
speakers. Experimental results demonstrate the superior performance of our DJDA
as compared to other state-of-the-art (SOTA) methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09753">Applications of Machine Learning to Optimizing Polyolefin Manufacturing. (arXiv:2401.09753v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1">Niket Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Y.A. Liu</a></p>
<p>This chapter is a preprint from our book by , focusing on leveraging machine
learning (ML) in chemical and polyolefin manufacturing optimization. It's
crafted for both novices and seasoned professionals keen on the latest ML
applications in chemical processes. We trace the evolution of AI and ML in
chemical industries, delineate core ML components, and provide resources for ML
beginners. A detailed discussion on various ML methods is presented, covering
regression, classification, and unsupervised learning techniques, with
performance metrics and examples. Ensemble methods, deep learning networks,
including MLP, DNNs, RNNs, CNNs, and transformers, are explored for their
growing role in chemical applications. Practical workshops guide readers
through predictive modeling using advanced ML algorithms. The chapter
culminates with insights into science-guided ML, advocating for a hybrid
approach that enhances model accuracy. The extensive bibliography offers
resources for further research and practical implementation. This chapter aims
to be a thorough primer on ML's practical application in chemical engineering,
particularly for polyolefin production, and sets the stage for continued
learning in subsequent chapters. Please cite the original work [169,170] when
referencing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09754">Universally Robust Graph Neural Networks by Preserving Neighbor Similarity. (arXiv:2401.09754v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yulin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yuni Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_X/0/1/0/all/0/1">Xing Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a></p>
<p>Despite the tremendous success of graph neural networks in learning
relational data, it has been widely investigated that graph neural networks are
vulnerable to structural attacks on homophilic graphs. Motivated by this, a
surge of robust models is crafted to enhance the adversarial robustness of
graph neural networks on homophilic graphs. However, the vulnerability based on
heterophilic graphs remains a mystery to us. To bridge this gap, in this paper,
we start to explore the vulnerability of graph neural networks on heterophilic
graphs and theoretically prove that the update of the negative classification
loss is negatively correlated with the pairwise similarities based on the
powered aggregated neighbor features. This theoretical proof explains the
empirical observations that the graph attacker tends to connect dissimilar node
pairs based on the similarities of neighbor features instead of ego features
both on homophilic and heterophilic graphs. In this way, we novelly introduce a
novel robust model termed NSPGNN which incorporates a dual-kNN graphs pipeline
to supervise the neighbor similarity-guided propagation. This propagation
utilizes the low-pass filter to smooth the features of node pairs along the
positive kNN graphs and the high-pass filter to discriminate the features of
node pairs along the negative kNN graphs. Extensive experiments on both
homophilic and heterophilic graphs validate the universal robustness of NSPGNN
compared to the state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09756">Explaining Drift using Shapley Values. (arXiv:2401.09756v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Edakunni_N/0/1/0/all/0/1">Narayanan U. Edakunni</a>, <a href="http://arxiv.org/find/cs/1/au:+Tekriwal_U/0/1/0/all/0/1">Utkarsh Tekriwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Anukriti Jain</a></p>
<p>Machine learning models often deteriorate in their performance when they are
used to predict the outcomes over data on which they were not trained. These
scenarios can often arise in real world when the distribution of data changes
gradually or abruptly due to major events like a pandemic. There have been many
attempts in machine learning research to come up with techniques that are
resilient to such Concept drifts. However, there is no principled framework to
identify the drivers behind the drift in model performance. In this paper, we
propose a novel framework - DBShap that uses Shapley values to identify the
main contributors of the drift and quantify their respective contributions. The
proposed framework not only quantifies the importance of individual features in
driving the drift but also includes the change in the underlying relation
between the input and output as a possible driver. The explanation provided by
DBShap can be used to understand the root cause behind the drift and use it to
make the model resilient to the drift.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09769">Towards Learning from Graphs with Heterophily: Progress and Future. (arXiv:2401.09769v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1">Chenghua Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_C/0/1/0/all/0/1">Caihua Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Siqiang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chuan Shi</a></p>
<p>Graphs are structured data that models complex relations between real-world
entities. Heterophilous graphs, where linked nodes are prone to be with
different labels or dissimilar features, have recently attracted significant
attention and found many applications. Meanwhile, increasing efforts have been
made to advance learning from heterophilous graphs. Although there exist
surveys on the relevant topic, they focus on heterophilous GNNs, which are only
sub-topics of heterophilous graph learning. In this survey, we comprehensively
overview existing works on learning from graphs with heterophily.First, we
collect over 180 publications and introduce the development of this field.
Then, we systematically categorize existing methods based on a hierarchical
taxonomy including learning strategies, model architectures and practical
applications. Finally, we discuss the primary challenges of existing studies
and highlight promising avenues for future research.More publication details
and corresponding open-source codes can be accessed and will be continuously
updated at our
repositories:https://github.com/gongchenghua/Awesome-Survey-Graphs-with-Heterophily.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09787">Querying Easily Flip-flopped Samples for Deep Active Learning. (arXiv:2401.09787v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Seong Jin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gwangsu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junghyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1">Chang D. Yoo</a></p>
<p>Active learning is a machine learning paradigm that aims to improve the
performance of a model by strategically selecting and querying unlabeled data.
One effective selection strategy is to base it on the model's predictive
uncertainty, which can be interpreted as a measure of how informative a sample
is. The sample's distance to the decision boundary is a natural measure of
predictive uncertainty, but it is often intractable to compute, especially for
complex decision boundaries formed in multiclass classification tasks. To
address this issue, this paper proposes the {\it least disagree metric} (LDM),
defined as the smallest probability of disagreement of the predicted label, and
an estimator for LDM proven to be asymptotically consistent under mild
assumptions. The estimator is computationally efficient and can be easily
implemented for deep learning models using parameter perturbation. The
LDM-based active learning is performed by querying unlabeled data with the
smallest LDM. Experimental results show that our LDM-based active learning
algorithm obtains state-of-the-art overall performance on all considered
datasets and deep architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09791">BreastRegNet: A Deep Learning Framework for Registration of Breast Faxitron and Histopathology Images. (arXiv:2401.09791v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Golestani_N/0/1/0/all/0/1">Negar Golestani</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_A/0/1/0/all/0/1">Aihui Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Bean_G/0/1/0/all/0/1">Gregory R Bean</a>, <a href="http://arxiv.org/find/eess/1/au:+Rusu_M/0/1/0/all/0/1">Mirabela Rusu</a></p>
<p>A standard treatment protocol for breast cancer entails administering
neoadjuvant therapy followed by surgical removal of the tumor and surrounding
tissue. Pathologists typically rely on cabinet X-ray radiographs, known as
Faxitron, to examine the excised breast tissue and diagnose the extent of
residual disease. However, accurately determining the location, size, and
focality of residual cancer can be challenging, and incorrect assessments can
lead to clinical consequences. The utilization of automated methods can improve
the histopathology process, allowing pathologists to choose regions for
sampling more effectively and precisely. Despite the recognized necessity,
there are currently no such methods available. Training such automated
detection models require accurate ground truth labels on ex-vivo radiology
images, which can be acquired through registering Faxitron and histopathology
images and mapping the extent of cancer from histopathology to x-ray images.
This study introduces a deep learning-based image registration approach trained
on mono-modal synthetic image pairs. The models were trained using data from 50
women who received neoadjuvant chemotherapy and underwent surgery. The results
demonstrate that our method is faster and yields significantly lower average
landmark error ($2.1\pm1.96$ mm) over the state-of-the-art iterative
($4.43\pm4.1$ mm) and deep learning ($4.02\pm3.15$ mm) approaches. Improved
performance of our approach in integrating radiology and pathology information
facilitates generating large datasets, which allows training models for more
accurate breast cancer detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09793">PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection. (arXiv:2401.09793v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhijie Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiwen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weizheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaixiang Yang</a></p>
<p>Anomaly detection stands as a crucial aspect of time series analysis, aiming
to identify abnormal events in time series samples. The central challenge of
this task lies in effectively learning the representations of normal and
abnormal patterns in a label-lacking scenario. Previous research mostly relied
on reconstruction-based approaches, restricting the representational abilities
of the models. In addition, most of the current deep learning-based methods are
not lightweight enough, which prompts us to design a more efficient framework
for anomaly detection. In this study, we introduce PatchAD, a novel multi-scale
patch-based MLP-Mixer architecture that leverages contrastive learning for
representational extraction and anomaly detection. Specifically, PatchAD is
composed of four distinct MLP Mixers, exclusively utilizing the MLP
architecture for high efficiency and lightweight architecture. Additionally, we
also innovatively crafted a dual project constraint module to mitigate
potential model degradation. Comprehensive experiments demonstrate that PatchAD
achieves state-of-the-art results across multiple real-world multivariate time
series datasets. Our code is publicly
available.\footnote{\url{https://github.com/EmorZz1G/PatchAD}}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09796">A Fast, Performant, Secure Distributed Training Framework For Large Language Model. (arXiv:2401.09796v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yinggui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_A/0/1/0/all/0/1">Anda Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1">Aihui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Chaofan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a></p>
<p>The distributed (federated) LLM is an important method for co-training the
domain-specific LLM using siloed data. However, maliciously stealing model
parameters and data from the server or client side has become an urgent problem
to be solved. In this paper, we propose a secure distributed LLM based on model
slicing. In this case, we deploy the Trusted Execution Environment (TEE) on
both the client and server side, and put the fine-tuned structure (LoRA or
embedding of P-tuning v2) into the TEE. Then, secure communication is executed
in the TEE and general environments through lightweight encryption. In order to
further reduce the equipment cost as well as increase the model performance and
accuracy, we propose a split fine-tuning scheme. In particular, we split the
LLM by layers and place the latter layers in a server-side TEE (the client does
not need a TEE). We then combine the proposed Sparsification Parameter
Fine-tuning (SPF) with the LoRA part to improve the accuracy of the downstream
task. Numerous experiments have shown that our method guarantees accuracy while
maintaining security.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09804">Clickbait vs. Quality: How Engagement-Based Optimization Shapes the Content Landscape in Online Platforms. (arXiv:2401.09804v1 [cs.GT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Immorlica_N/0/1/0/all/0/1">Nicole Immorlica</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagadeesan_M/0/1/0/all/0/1">Meena Jagadeesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucier_B/0/1/0/all/0/1">Brendan Lucier</a></p>
<p>Online content platforms commonly use engagement-based optimization when
making recommendations. This encourages content creators to invest in quality,
but also rewards gaming tricks such as clickbait. To understand the total
impact on the content landscape, we study a game between content creators
competing on the basis of engagement metrics and analyze the equilibrium
decisions about investment in quality and gaming. First, we show the content
created at equilibrium exhibits a positive correlation between quality and
gaming, and we empirically validate this finding on a Twitter dataset. Using
the equilibrium structure of the content landscape, we then examine the
downstream performance of engagement-based optimization along several axes.
Perhaps counterintuitively, the average quality of content consumed by users
can decrease at equilibrium as gaming tricks become more costly for content
creators to employ. Moreover, engagement-based optimization can perform worse
in terms of user utility than a baseline with random recommendations, and
engagement-based optimization is also suboptimal in terms of realized
engagement relative to quality-based optimization. Altogether, our results
highlight the need to consider content creator incentives when evaluating a
platform's choice of optimization metric.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09819">PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path Planning. (arXiv:2401.09819v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Qinglong Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1">Chongkun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xueqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_S/0/1/0/all/0/1">Songping Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1">Bin Liang</a></p>
<p>The classical path planners, such as sampling-based path planners, have the
limitations of sensitivity to the initial solution and slow convergence to the
optimal solution. However, finding a near-optimal solution in a short period is
challenging in many applications such as the autonomous vehicle with limited
power/fuel. To achieve an end-to-end near-optimal path planner, we first divide
the path planning problem into two subproblems, which are path's space
segmentation and waypoints generation in the given path's space. We further
propose a two-level cascade neural network named Path Planning Network (PPNet)
to solve the path planning problem by solving the abovementioned subproblems.
Moreover, we propose a novel efficient data generation method for path planning
named EDaGe-PP. The results show the total computation time is less than 1/33
and the success rate of PPNet trained by the dataset that is generated by
EDaGe-PP is about $2 \times$ compared to other methods. We validate PPNet
against state-of-the-art path planning methods. The results show PPNet can find
a near-optimal solution in 15.3ms, which is much shorter than the
state-of-the-art path planners.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09840">FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction. (arXiv:2401.09840v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Telepov_A/0/1/0/all/0/1">Alexander Telepov</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tsypin_A/0/1/0/all/0/1">Artem Tsypin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khrabrov_K/0/1/0/all/0/1">Kuzma Khrabrov</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yakukhnov_S/0/1/0/all/0/1">Sergey Yakukhnov</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Strashnov_P/0/1/0/all/0/1">Pavel Strashnov</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhilyaev_P/0/1/0/all/0/1">Petr Zhilyaev</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Rumiantsev_E/0/1/0/all/0/1">Egor Rumiantsev</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ezhov_D/0/1/0/all/0/1">Daniel Ezhov</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Avetisian_M/0/1/0/all/0/1">Manvel Avetisian</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Popova_O/0/1/0/all/0/1">Olga Popova</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kadurin_A/0/1/0/all/0/1">Artur Kadurin</a></p>
<p>A rational design of new therapeutic drugs aims to find a molecular structure
with desired biological functionality, e.g., an ability to activate or suppress
a specific protein via binding to it. Molecular docking is a common technique
for evaluating protein-molecule interactions. Recently, Reinforcement Learning
(RL) has emerged as a promising approach to generating molecules with the
docking score (DS) as a reward. In this work, we reproduce, scrutinize and
improve the recent RL model for molecule generation called FREED
(<a href="/abs/2110.01219">arXiv:2110.01219</a>). Extensive evaluation of the proposed method reveals several
limitations and challenges despite the outstanding results reported for three
target proteins. Our contributions include fixing numerous implementation bugs
and simplifying the model while increasing its quality, significantly extending
experiments, and conducting an accurate comparison with current
state-of-the-art methods for protein-conditioned molecule generation. We show
that the resulting fixed model is capable of producing molecules with superior
docking scores compared to alternative approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09862">Evolutionary Multi-Objective Optimization of Large Language Model Prompts for Balancing Sentiments. (arXiv:2401.09862v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Baumann_J/0/1/0/all/0/1">Jill Baumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kramer_O/0/1/0/all/0/1">Oliver Kramer</a></p>
<p>The advent of large language models (LLMs) such as ChatGPT has attracted
considerable attention in various domains due to their remarkable performance
and versatility. As the use of these models continues to grow, the importance
of effective prompt engineering has come to the fore. Prompt optimization
emerges as a crucial challenge, as it has a direct impact on model performance
and the extraction of relevant information. Recently, evolutionary algorithms
(EAs) have shown promise in addressing this issue, paving the way for novel
optimization strategies. In this work, we propose a evolutionary
multi-objective (EMO) approach specifically tailored for prompt optimization
called EMO-Prompts, using sentiment analysis as a case study. We use sentiment
analysis capabilities as our experimental targets. Our results demonstrate that
EMO-Prompts effectively generates prompts capable of guiding the LLM to produce
texts embodying two conflicting emotions simultaneously.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09865">Improving fine-grained understanding in image-text pre-training. (arXiv:2401.09865v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bica_I/0/1/0/all/0/1">Ioana Bica</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilic_A/0/1/0/all/0/1">Anastasija Ili&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1">Matthias Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogan_G/0/1/0/all/0/1">Goker Erdogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosnjak_M/0/1/0/all/0/1">Matko Bo&#x161;njak</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplanis_C/0/1/0/all/0/1">Christos Kaplanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1">Alexey A. Gritsenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1">Matthias Minderer</a>, <a href="http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1">Charles Blundell</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitrovic_J/0/1/0/all/0/1">Jovana Mitrovi&#x107;</a></p>
<p>We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple
method for pretraining more fine-grained multimodal representations from
image-text pairs. Given that multiple image patches often correspond to single
words, we propose to learn a grouping of image patches for every token in the
caption. To achieve this, we use a sparse similarity metric between image
patches and language tokens and compute for each token a language-grouped
vision embedding as the weighted average of patches. The token and
language-grouped vision embeddings are then contrasted through a fine-grained
sequence-wise loss that only depends on individual samples and does not require
other batch samples as negatives. This enables more detailed information to be
learned in a computationally inexpensive manner. SPARC combines this
fine-grained loss with a contrastive loss between global image and text
embeddings to learn representations that simultaneously encode global and local
information. We thoroughly evaluate our proposed method and show improved
performance over competing approaches both on image-level tasks relying on
coarse-grained information, e.g. classification, as well as region-level tasks
relying on fine-grained information, e.g. retrieval, object detection, and
segmentation. Moreover, SPARC improves model faithfulness and captioning in
foundational vision-language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09870">Reconciling Spatial and Temporal Abstractions for Goal Representation. (arXiv:2401.09870v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zadem_M/0/1/0/all/0/1">Mehdi Zadem</a>, <a href="http://arxiv.org/find/cs/1/au:+Mover_S/0/1/0/all/0/1">Sergio Mover</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1">Sao Mai Nguyen</a></p>
<p>Goal representation affects the performance of Hierarchical Reinforcement
Learning (HRL) algorithms by decomposing the complex learning problem into
easier subtasks. Recent studies show that representations that preserve
temporally abstract environment dynamics are successful in solving difficult
problems and provide theoretical guarantees for optimality. These methods
however cannot scale to tasks where environment dynamics increase in complexity
i.e. the temporally abstract transition relations depend on larger number of
variables. On the other hand, other efforts have tried to use spatial
abstraction to mitigate the previous issues. Their limitations include
scalability to high dimensional environments and dependency on prior knowledge.
</p>
<p>In this paper, we propose a novel three-layer HRL algorithm that introduces,
at different levels of the hierarchy, both a spatial and a temporal goal
abstraction. We provide a theoretical study of the regret bounds of the learned
policies. We evaluate the approach on complex continuous control tasks,
demonstrating the effectiveness of spatial and temporal abstractions learned by
this approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09880">Attention-Based Recurrent Neural Network For Automatic Behavior Laying Hen Recognition. (arXiv:2401.09880v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Laleye_F/0/1/0/all/0/1">Fr&#xe9;jus A. A. Laleye</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousse_M/0/1/0/all/0/1">Mika&#xeb;l A. Mousse</a></p>
<p>One of the interests of modern poultry farming is the vocalization of laying
hens which contain very useful information on health behavior. This information
is used as health and well-being indicators that help breeders better monitor
laying hens, which involves early detection of problems for rapid and more
effective intervention. In this work, we focus on the sound analysis for the
recognition of the types of calls of the laying hens in order to propose a
robust system of characterization of their behavior for a better monitoring. To
do this, we first collected and annotated laying hen call signals, then
designed an optimal acoustic characterization based on the combination of time
and frequency domain features. We then used these features to build the
multi-label classification models based on recurrent neural network to assign a
semantic class to the vocalization that characterize the laying hen behavior.
The results show an overall performance with our model based on the combination
of time and frequency domain features that obtained the highest F1-score
(F1=92.75) with a gain of 17% on the models using the frequency domain features
and of 8% on the compared approaches from the litterature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09881">GA-SmaAt-GNet: Generative Adversarial Small Attention GNet for Extreme Precipitation Nowcasting. (arXiv:2401.09881v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Reulen_E/0/1/0/all/0/1">Eloy Reulen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrkanoon_S/0/1/0/all/0/1">Siamak Mehrkanoon</a></p>
<p>In recent years, data-driven modeling approaches have gained considerable
traction in various meteorological applications, particularly in the realm of
weather forecasting. However, these approaches often encounter challenges when
dealing with extreme weather conditions. In light of this, we propose
GA-SmaAt-GNet, a novel generative adversarial architecture that makes use of
two methodologies aimed at enhancing the performance of deep learning models
for extreme precipitation nowcasting. Firstly, it uses a novel SmaAt-GNet built
upon the successful SmaAt-UNet architecture as generator. This network
incorporates precipitation masks (binarized precipitation maps) as an
additional data source, leveraging valuable information for improved
predictions. Additionally, GA-SmaAt-GNet utilizes an attention-augmented
discriminator inspired by the well-established Pix2Pix architecture.
Furthermore, we assess the performance of GA-SmaAt-GNet using real-life
precipitation dataset from the Netherlands. Our experimental results reveal a
notable improvement in both overall performance and for extreme precipitation
events. Furthermore, we conduct uncertainty analysis on the proposed
GA-SmaAt-GNet model as well as on the precipitation dataset, providing
additional insights into the predictive capabilities of the model. Finally, we
offer further insights into the predictions of our proposed model using
Grad-CAM. This visual explanation technique generates activation heatmaps,
illustrating areas of the input that are more activated for various parts of
the network.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09886">Cooperative Edge Caching Based on Elastic Federated and Multi-Agent Deep Reinforcement Learning in Next-Generation Network. (arXiv:2401.09886v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_P/0/1/0/all/0/1">Pingyi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1">Qiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Huiling Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Letaief_K/0/1/0/all/0/1">Khaled B. Letaief</a></p>
<p>Edge caching is a promising solution for next-generation networks by
empowering caching units in small-cell base stations (SBSs), which allows user
equipments (UEs) to fetch users' requested contents that have been pre-cached
in SBSs. It is crucial for SBSs to predict accurate popular contents through
learning while protecting users' personal information. Traditional federated
learning (FL) can protect users' privacy but the data discrepancies among UEs
can lead to a degradation in model quality. Therefore, it is necessary to train
personalized local models for each UE to predict popular contents accurately.
In addition, the cached contents can be shared among adjacent SBSs in
next-generation networks, thus caching predicted popular contents in different
SBSs may affect the cost to fetch contents. Hence, it is critical to determine
where the popular contents are cached cooperatively. To address these issues,
we propose a cooperative edge caching scheme based on elastic federated and
multi-agent deep reinforcement learning (CEFMR) to optimize the cost in the
network. We first propose an elastic FL algorithm to train the personalized
model for each UE, where adversarial autoencoder (AAE) model is adopted for
training to improve the prediction accuracy, then {a popular} content
prediction algorithm is proposed to predict the popular contents for each SBS
based on the trained AAE model. Finally, we propose a multi-agent deep
reinforcement learning (MADRL) based algorithm to decide where the predicted
popular contents are collaboratively cached among SBSs. Our experimental
results demonstrate the superiority of our proposed scheme to existing baseline
caching schemes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09890">A Survey on Hardware Accelerators for Large Language Models. (arXiv:2401.09890v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kachris_C/0/1/0/all/0/1">Christoforos Kachris</a></p>
<p>Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. As the demand for more sophisticated
LLMs continues to grow, there is a pressing need to address the computational
challenges associated with their scale and complexity. This paper presents a
comprehensive survey on hardware accelerators designed to enhance the
performance and energy efficiency of Large Language Models. By examining a
diverse range of accelerators, including GPUs, FPGAs, and custom-designed
architectures, we explore the landscape of hardware solutions tailored to meet
the unique computational demands of LLMs. The survey encompasses an in-depth
analysis of architecture, performance metrics, and energy efficiency
considerations, providing valuable insights for researchers, engineers, and
decision-makers aiming to optimize the deployment of LLMs in real-world
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09902">Interplay between depth and width for interpolation in neural ODEs. (arXiv:2401.09902v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Alvarez_Lopez_A/0/1/0/all/0/1">Antonio &#xc1;lvarez-L&#xf3;pez</a>, <a href="http://arxiv.org/find/math/1/au:+Slimane_A/0/1/0/all/0/1">Arselane Hadj Slimane</a>, <a href="http://arxiv.org/find/math/1/au:+Iriondo_E/0/1/0/all/0/1">Enrique Zuazua Iriondo</a></p>
<p>Neural ordinary differential equations (neural ODEs) have emerged as a
natural tool for supervised learning from a control perspective, yet a complete
understanding of their optimal architecture remains elusive. In this work, we
examine the interplay between their width $p$ and number of layer transitions
$L$ (effectively the depth $L+1$). Specifically, we assess the model
expressivity in terms of its capacity to interpolate either a finite dataset
$D$ comprising $N$ pairs of points or two probability measures in
$\mathbb{R}^d$ within a Wasserstein error margin $\varepsilon&gt;0$. Our findings
reveal a balancing trade-off between $p$ and $L$, with $L$ scaling as
$O(1+N/p)$ for dataset interpolation, and
$L=O\left(1+(p\varepsilon^d)^{-1}\right)$ for measure interpolation.
</p>
<p>In the autonomous case, where $L=0$, a separate study is required, which we
undertake focusing on dataset interpolation. We address the relaxed problem of
$\varepsilon$-approximate controllability and establish an error decay of
$\varepsilon\sim O(\log(p)p^{-1/d})$. This decay rate is a consequence of
applying a universal approximation theorem to a custom-built Lipschitz vector
field that interpolates $D$. In the high-dimensional setting, we further
demonstrate that $p=O(N)$ neurons are likely sufficient to achieve exact
control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09915">Qadence: a differentiable interface for digital-analog programs. (arXiv:2401.09915v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Seitz_D/0/1/0/all/0/1">Dominik Seitz</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Heim_N/0/1/0/all/0/1">Niklas Heim</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Moutinho_J/0/1/0/all/0/1">Jo&#xe3;o P. Moutinho</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Guichard_R/0/1/0/all/0/1">Roland Guichard</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Abramavicius_V/0/1/0/all/0/1">Vytautas Abramavicius</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wennersteen_A/0/1/0/all/0/1">Aleksander Wennersteen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Both_G/0/1/0/all/0/1">Gert-Jan Both</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Quelle_A/0/1/0/all/0/1">Anton Quelle</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Groot_C/0/1/0/all/0/1">Caroline de Groot</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Velikova_G/0/1/0/all/0/1">Gergana V. Velikova</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Elfving_V/0/1/0/all/0/1">Vincent E. Elfving</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Dagrada_M/0/1/0/all/0/1">Mario Dagrada</a></p>
<p>Digital-analog quantum computing (DAQC) is an alternative paradigm for
universal quantum computation combining digital single-qubit gates with global
analog operations acting on a register of interacting qubits. Currently, no
available open-source software is tailored to express, differentiate, and
execute programs within the DAQC paradigm. In this work, we address this
shortfall by presenting Qadence, a high-level programming interface for
building complex digital-analog quantum programs developed at Pasqal. Thanks to
its flexible interface, native differentiability, and focus on real-device
execution, Qadence aims at advancing research on variational quantum algorithms
built for native DAQC platforms such as Rydberg atom arrays.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09916">Enabling On-device Continual Learning with Binary Neural Networks. (arXiv:2401.09916v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vorabbi_L/0/1/0/all/0/1">Lorenzo Vorabbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maltoni_D/0/1/0/all/0/1">Davide Maltoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Borghi_G/0/1/0/all/0/1">Guido Borghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Santi_S/0/1/0/all/0/1">Stefano Santi</a></p>
<p>On-device learning remains a formidable challenge, especially when dealing
with resource-constrained devices that have limited computational capabilities.
This challenge is primarily rooted in two key issues: first, the memory
available on embedded devices is typically insufficient to accommodate the
memory-intensive back-propagation algorithm, which often relies on
floating-point precision. Second, the development of learning algorithms on
models with extreme quantization levels, such as Binary Neural Networks (BNNs),
is critical due to the drastic reduction in bit representation. In this study,
we propose a solution that combines recent advancements in the field of
Continual Learning (CL) and Binary Neural Networks to enable on-device training
while maintaining competitive performance. Specifically, our approach leverages
binary latent replay (LR) activations and a novel quantization scheme that
significantly reduces the number of bits required for gradient computation. The
experimental validation demonstrates a significant accuracy improvement in
combination with a noticeable reduction in memory requirement, confirming the
suitability of our approach in expanding the practical applications of deep
learning in real-world scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09918">Probabilistic Truly Unordered Rule Sets. (arXiv:2401.09918v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lincen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeuwen_M/0/1/0/all/0/1">Matthijs van Leeuwen</a></p>
<p>Rule set learning has recently been frequently revisited because of its
interpretability. Existing methods have several shortcomings though. First,
most existing methods impose orders among rules, either explicitly or
implicitly, which makes the models less comprehensible. Second, due to the
difficulty of handling conflicts caused by overlaps (i.e., instances covered by
multiple rules), existing methods often do not consider probabilistic rules.
Third, learning classification rules for multi-class target is understudied, as
most existing methods focus on binary classification or multi-class
classification via the ``one-versus-rest" approach.
</p>
<p>To address these shortcomings, we propose TURS, for Truly Unordered Rule
Sets. To resolve conflicts caused by overlapping rules, we propose a novel
model that exploits the probabilistic properties of our rule sets, with the
intuition of only allowing rules to overlap if they have similar probabilistic
outputs. We next formalize the problem of learning a TURS model based on the
MDL principle and develop a carefully designed heuristic algorithm. We
benchmark against a wide range of rule-based methods and demonstrate that our
method learns rule sets that have lower model complexity and highly competitive
predictive performance. In addition, we empirically show that rules in our
model are empirically ``independent" and hence truly unordered.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09940">Biases in Expected Goals Models Confound Finishing Ability. (arXiv:2401.09940v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jesse Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Robberechts_P/0/1/0/all/0/1">Pieter Robberechts</a></p>
<p>Expected Goals (xG) has emerged as a popular tool for evaluating finishing
skill in soccer analytics. It involves comparing a player's cumulative xG with
their actual goal output, where consistent overperformance indicates strong
finishing ability. However, the assessment of finishing skill in soccer using
xG remains contentious due to players' difficulty in consistently outperforming
their cumulative xG. In this paper, we aim to address the limitations and
nuances surrounding the evaluation of finishing skill using xG statistics.
Specifically, we explore three hypotheses: (1) the deviation between actual and
expected goals is an inadequate metric due to the high variance of shot
outcomes and limited sample sizes, (2) the inclusion of all shots in cumulative
xG calculation may be inappropriate, and (3) xG models contain biases arising
from interdependencies in the data that affect skill measurement. We found that
sustained overperformance of cumulative xG requires both high shot volumes and
exceptional finishing, including all shot types can obscure the finishing
ability of proficient strikers, and that there is a persistent bias that makes
the actual and expected goals closer for excellent finishers than it really is.
Overall, our analysis indicates that we need more nuanced quantitative
approaches for investigating a player's finishing ability, which we achieved
using a technique from AI fairness to learn an xG model that is calibrated for
multiple subgroups of players. As a concrete use case, we show that (1) the
standard biased xG model underestimates Messi's GAX by 17% and (2) Messi's GAX
is 27% higher than the typical elite high-shot-volume attacker, indicating that
Messi is even a more exceptional finisher than people commonly believed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09943">Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance Sparse Information Aggregation. (arXiv:2401.09943v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruizhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xinke Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuchen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiayuan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yongxin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yichen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xu Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Junfeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yasha Zhao</a></p>
<p>Graph Neural Networks (GNNs) have shown considerable effectiveness in a
variety of graph learning tasks, particularly those based on the
message-passing approach in recent years. However, their performance is often
constrained by a limited receptive field, a challenge that becomes more acute
in the presence of sparse graphs. In light of the power series, which possesses
infinite expansion capabilities, we propose a novel \underline{G}raph
\underline{P}ower \underline{F}ilter \underline{N}eural Network (GPFN) that
enhances node classification by employing a power series graph filter to
augment the receptive field. Concretely, our GPFN designs a new way to build a
graph filter with an infinite receptive field based on the convergence power
series, which can be analyzed in the spectral and spatial domains. Besides, we
theoretically prove that our GPFN is a general framework that can integrate any
power series and capture long-range dependencies. Finally, experimental results
on three datasets demonstrate the superiority of our GPFN over state-of-the-art
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09944">WindSeer: Real-time volumetric wind prediction over complex terrain aboard a small UAV. (arXiv:2401.09944v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Achermann_F/0/1/0/all/0/1">Florian Achermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Stastny_T/0/1/0/all/0/1">Thomas Stastny</a>, <a href="http://arxiv.org/find/cs/1/au:+Danciu_B/0/1/0/all/0/1">Bogdan Danciu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1">Andrey Kolobov</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jen Jen Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Siegwart_R/0/1/0/all/0/1">Roland Siegwart</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawrance_N/0/1/0/all/0/1">Nicholas Lawrance</a></p>
<p>Real-time high-resolution wind predictions are beneficial for various
applications including safe manned and unmanned aviation. Current weather
models require too much compute and lack the necessary predictive capabilities
as they are valid only at the scale of multiple kilometers and hours - much
lower spatial and temporal resolutions than these applications require. Our
work, for the first time, demonstrates the ability to predict low-altitude wind
in real-time on limited-compute devices, from only sparse measurement data. We
train a neural network, WindSeer, using only synthetic data from computational
fluid dynamics simulations and show that it can successfully predict real wind
fields over terrain with known topography from just a few noisy and spatially
clustered wind measurements. WindSeer can generate accurate predictions at
different resolutions and domain sizes on previously unseen topography without
retraining. We demonstrate that the model successfully predicts historical wind
data collected by weather stations and wind measured onboard drones.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09945">HGAttack: Transferable Heterogeneous Graph Adversarial Attack. (arXiv:2401.09945v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">He Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhiwei Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1">Deheng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a></p>
<p>Heterogeneous Graph Neural Networks (HGNNs) are increasingly recognized for
their performance in areas like the web and e-commerce, where resilience
against adversarial attacks is crucial. However, existing adversarial attack
methods, which are primarily designed for homogeneous graphs, fall short when
applied to HGNNs due to their limited ability to address the structural and
semantic complexity of HGNNs. This paper introduces HGAttack, the first
dedicated gray box evasion attack method for heterogeneous graphs. We design a
novel surrogate model to closely resemble the behaviors of the target HGNN and
utilize gradient-based methods for perturbation generation. Specifically, the
proposed surrogate model effectively leverages heterogeneous information by
extracting meta-path induced subgraphs and applying GNNs to learn node
embeddings with distinct semantics from each subgraph. This approach improves
the transferability of generated attacks on the target HGNN and significantly
reduces memory costs. For perturbation generation, we introduce a
semantics-aware mechanism that leverages subgraph gradient information to
autonomously identify vulnerable edges across a wide range of relations within
a constrained perturbation budget. We validate HGAttack's efficacy with
comprehensive experiments on three datasets, providing empirical analyses of
its generated perturbations. Outperforming baseline methods, HGAttack
demonstrated significant efficacy in diminishing the performance of target HGNN
models, affirming the effectiveness of our approach in evaluating the
robustness of HGNNs against adversarial attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09949">SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning. (arXiv:2401.09949v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsoi_H/0/1/0/all/0/1">Ho Fung Tsoi</a>, <a href="http://arxiv.org/find/cs/1/au:+Loncar_V/0/1/0/all/0/1">Vladimir Loncar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasu_S/0/1/0/all/0/1">Sridhara Dasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_P/0/1/0/all/0/1">Philip Harris</a></p>
<p>Contrary to the use of genetic programming, the neural network approach to
symbolic regression can scale well with high input dimension and leverage
gradient methods for faster equation searching. Common ways of constraining
expression complexity have relied on multistage pruning methods with
fine-tuning, but these often lead to significant performance loss. In this
work, we propose SymbolNet, a neural network approach to symbolic regression in
a novel framework that enables dynamic pruning of model weights, input
features, and mathematical operators in a single training, where both training
loss and expression complexity are optimized simultaneously. We introduce a
sparsity regularization term per pruning type, which can adaptively adjust its
own strength and lead to convergence to a target sparsity level. In contrast to
most existing symbolic regression methods that cannot efficiently handle
datasets with more than $O$(10) inputs, we demonstrate the effectiveness of our
model on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN
(3072 inputs).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09953">Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification. (arXiv:2401.09953v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yutong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Runpeng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yuxuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bresson_X/0/1/0/all/0/1">Xavier Bresson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinchao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1">Roger Zimmermann</a></p>
<p>Graph Neural Networks (GNNs) have become the preferred tool to process graph
data, with their efficacy being boosted through graph data augmentation
techniques. Despite the evolution of augmentation methods, issues like graph
property distortions and restricted structural changes persist. This leads to
the question: Is it possible to develop more property-conserving and
structure-sensitive augmentation methods? Through a spectral lens, we
investigate the interplay between graph properties, their augmentation, and
their spectral behavior, and found that keeping the low-frequency eigenvalues
unchanged can preserve the critical properties at a large scale when generating
augmented graphs. These observations inform our introduction of the Dual-Prism
(DP) augmentation method, comprising DP-Noise and DP-Mask, which adeptly
retains essential graph properties while diversifying augmented graphs.
Extensive experiments validate the efficiency of our approach, providing a new
and promising direction for graph data augmentation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09979">False Discovery Rate Control for Gaussian Graphical Models via Neighborhood Screening. (arXiv:2401.09979v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Koka_T/0/1/0/all/0/1">Taulant Koka</a>, <a href="http://arxiv.org/find/stat/1/au:+Machkour_J/0/1/0/all/0/1">Jasin Machkour</a>, <a href="http://arxiv.org/find/stat/1/au:+Muma_M/0/1/0/all/0/1">Michael Muma</a></p>
<p>Gaussian graphical models emerge in a wide range of fields. They model the
statistical relationships between variables as a graph, where an edge between
two variables indicates conditional dependence. Unfortunately, well-established
estimators, such as the graphical lasso or neighborhood selection, are known to
be susceptible to a high prevalence of false edge detections. False detections
may encourage inaccurate or even incorrect scientific interpretations, with
major implications in applications, such as biomedicine or healthcare. In this
paper, we introduce a nodewise variable selection approach to graph learning
and provably control the false discovery rate of the selected edge set at a
self-estimated level. A novel fusion method of the individual neighborhoods
outputs an undirected graph estimate. The proposed method is parameter-free and
does not require tuning by the user. Benchmarks against competing false
discovery rate controlling methods in numerical experiments considering
different graph topologies show a significant gain in performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09980">Ventricular Segmentation: A Brief Comparison of U-Net Derivatives. (arXiv:2401.09980v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Saichandran_K/0/1/0/all/0/1">Ketan Suhaas Saichandran</a></p>
<p>Medical imaging refers to the technologies and methods utilized to view the
human body and its inside, in order to diagnose, monitor, or even treat medical
disorders. This paper aims to explore the application of deep learning
techniques in the semantic segmentation of Cardiac short-axis MRI (Magnetic
Resonance Imaging) images, aiming to enhance the diagnosis, monitoring, and
treatment of medical disorders related to the heart. The focus centers on
implementing various architectures that are derivatives of U-Net, to
effectively isolate specific parts of the heart for comprehensive anatomical
and functional analysis. Through a combination of images, graphs, and
quantitative metrics, the efficacy of the models and their predictions are
showcased. Additionally, this paper addresses encountered challenges and
outline strategies for future improvements. This abstract provides a concise
overview of the efforts in utilizing deep learning for cardiac image
segmentation, emphasizing both the accomplishments and areas for further
refinement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09986">FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling. (arXiv:2401.09986v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kichang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Songkuk Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">JeongGil Ko</a></p>
<p>Federated learning are inherently hampered by data heterogeneity: non-iid
distributed training data over local clients. We propose a novel model training
approach for federated learning, FLex&amp;Chill, which exploits the Logit Chilling
method. Through extensive evaluations, we demonstrate that, in the presence of
non-iid data characteristics inherent in federated learning systems, this
approach can expedite model convergence and improve inference accuracy.
Quantitatively, from our experiments, we observe up to 6X improvement in the
global federated learning model convergence time, and up to 3.37% improvement
in inference accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09988">Developing an AI-based Integrated System for Bee Health Evaluation. (arXiv:2401.09988v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_A/0/1/0/all/0/1">Andrew Liang</a></p>
<p>Honey bees pollinate about one-third of the world's food supply, but bee
colonies have alarmingly declined by nearly 40% over the past decade due to
several factors, including pesticides and pests. Traditional methods for
monitoring beehives, such as human inspection, are subjective, disruptive, and
time-consuming. To overcome these limitations, artificial intelligence has been
used to assess beehive health. However, previous studies have lacked an
end-to-end solution and primarily relied on data from a single source, either
bee images or sounds. This study introduces a comprehensive system consisting
of bee object detection and health evaluation. Additionally, it utilized a
combination of visual and audio signals to analyze bee behaviors. An
Attention-based Multimodal Neural Network (AMNN) was developed to adaptively
focus on key features from each type of signal for accurate bee health
assessment. The AMNN achieved an overall accuracy of 92.61%, surpassing eight
existing single-signal Convolutional Neural Networks and Recurrent Neural
Networks. It outperformed the best image-based model by 32.51% and the top
sound-based model by 13.98% while maintaining efficient processing times.
Furthermore, it improved prediction robustness, attaining an F1-score higher
than 90% across all four evaluated health conditions. The study also shows that
audio signals are more reliable than images for assessing bee health. By
seamlessly integrating AMNN with image and sound data in a comprehensive bee
health monitoring system, this approach provides a more efficient and
non-invasive solution for the early detection of bee diseases and the
preservation of bee colonies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10014">Optimizing Medication Decisions for Patients with Atrial Fibrillation through Path Development Network. (arXiv:2401.10014v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tian Xie</a></p>
<p>Atrial fibrillation (AF) is a common cardiac arrhythmia characterized by
rapid and irregular contractions of the atria. It significantly elevates the
risk of strokes due to slowed blood flow in the atria, especially in the left
atrial appendage, which is prone to blood clot formation. Such clots can
migrate into cerebral arteries, leading to ischemic stroke. To assess whether
AF patients should be prescribed anticoagulants, doctors often use the
CHA2DS2-VASc scoring system. However, anticoagulant use must be approached with
caution as it can impact clotting functions. This study introduces a machine
learning algorithm that predicts whether patients with AF should be recommended
anticoagulant therapy using 12-lead ECG data. In this model, we use STOME to
enhance time-series data and then process it through a Convolutional Neural
Network (CNN). By incorporating a path development layer, the model achieves a
specificity of 30.6% under the condition of an NPV of 1. In contrast, LSTM
algorithms without path development yield a specificity of only 2.7% under the
same NPV condition.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10095">Learning shallow quantum circuits. (arXiv:2401.10095v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1">Hsin-Yuan Huang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1">Yunchao Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Broughton_M/0/1/0/all/0/1">Michael Broughton</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kim_I/0/1/0/all/0/1">Isaac Kim</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Anshu_A/0/1/0/all/0/1">Anurag Anshu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Landau_Z/0/1/0/all/0/1">Zeph Landau</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+McClean_J/0/1/0/all/0/1">Jarrod R. McClean</a></p>
<p>Despite fundamental interests in learning quantum circuits, the existence of
a computationally efficient algorithm for learning shallow quantum circuits
remains an open question. Because shallow quantum circuits can generate
distributions that are classically hard to sample from, existing learning
algorithms do not apply. In this work, we present a polynomial-time classical
algorithm for learning the description of any unknown $n$-qubit shallow quantum
circuit $U$ (with arbitrary unknown architecture) within a small diamond
distance using single-qubit measurement data on the output states of $U$. We
also provide a polynomial-time classical algorithm for learning the description
of any unknown $n$-qubit state $\lvert \psi \rangle = U \lvert 0^n \rangle$
prepared by a shallow quantum circuit $U$ (on a 2D lattice) within a small
trace distance using single-qubit measurements on copies of $\lvert \psi
\rangle$. Our approach uses a quantum circuit representation based on local
inversions and a technique to combine these inversions. This circuit
representation yields an optimization landscape that can be efficiently
navigated and enables efficient learning of quantum circuits that are
classically hard to simulate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10107">Comparison analysis between standard polysomnographic data and in-ear-EEG signals: A preliminary study. (arXiv:2401.10107v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Palo_G/0/1/0/all/0/1">Gianpaolo Palo</a>, <a href="http://arxiv.org/find/eess/1/au:+Fiorillo_L/0/1/0/all/0/1">Luigi Fiorillo</a>, <a href="http://arxiv.org/find/eess/1/au:+Monachino_G/0/1/0/all/0/1">Giuliana Monachino</a>, <a href="http://arxiv.org/find/eess/1/au:+Bechny_M/0/1/0/all/0/1">Michal Bechny</a>, <a href="http://arxiv.org/find/eess/1/au:+Melnykowycz_M/0/1/0/all/0/1">Mark Melnykowycz</a>, <a href="http://arxiv.org/find/eess/1/au:+Tzovara_A/0/1/0/all/0/1">Athina Tzovara</a>, <a href="http://arxiv.org/find/eess/1/au:+Agostini_V/0/1/0/all/0/1">Valentina Agostini</a>, <a href="http://arxiv.org/find/eess/1/au:+Faraci_F/0/1/0/all/0/1">Francesca Dalia Faraci</a></p>
<p>Study Objectives: Polysomnography (PSG) currently serves as the benchmark for
evaluating sleep disorders. Its discomfort, impracticality for home-use, and
introduction of bias in sleep quality assessment necessitate the exploration of
less invasive, cost-effective, and portable alternatives. One promising
contender is the in-ear-EEG sensor, which offers advantages in terms of
comfort, fixed electrode positions, resistance to electromagnetic interference,
and user-friendliness. This study aims to establish a methodology to assess the
similarity between the in-ear-EEG signal and standard PSG.
</p>
<p>Methods: We assess the agreement between the PSG and in-ear-EEG derived
hypnograms. We extract features in the time- and frequency- domain from PSG and
in-ear-EEG 30-second epochs. We only consider the epochs where the PSG-scorers
and the in-ear-EEG-scorers were in agreement. We introduce a methodology to
quantify the similarity between PSG derivations and the single-channel
in-ear-EEG. The approach relies on a comparison of distributions of selected
features -- extracted for each sleep stage and subject on both PSG and the
in-ear-EEG signals -- via a Jensen-Shannon Divergence Feature-based Similarity
Index (JSD-FSI).
</p>
<p>Results: We found a high intra-scorer variability, mainly due to the
uncertainty the scorers had in evaluating the in-ear-EEG signals. We show that
the similarity between PSG and in-ear-EEG signals is high (JSD-FSI: 0.61 +/-
0.06 in awake, 0.60 +/- 0.07 in NREM and 0.51 +/- 0.08 in REM), and in line
with the similarity values computed independently on standard
PSG-channel-combinations.
</p>
<p>Conclusions: In-ear-EEG is a valuable solution for home-based sleep
monitoring, however further studies with a larger and more heterogeneous
dataset are needed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10119">Towards Principled Graph Transformers. (arXiv:2401.10119v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Muller_L/0/1/0/all/0/1">Luis M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1">Christopher Morris</a></p>
<p>Graph learning architectures based on the k-dimensional Weisfeiler-Leman
(k-WL) hierarchy offer a theoretically well-understood expressive power.
However, such architectures often fail to deliver solid predictive performance
on real-world tasks, limiting their practical impact. In contrast, global
attention-based models such as graph transformers demonstrate strong
performance in practice, but comparing their expressive power with the k-WL
hierarchy remains challenging, particularly since these architectures rely on
positional or structural encodings for their expressivity and predictive
performance. To address this, we show that the recently proposed Edge
Transformer, a global attention model operating on node pairs instead of nodes,
has at least 3-WL expressive power. Empirically, we demonstrate that the Edge
Transformer surpasses other theoretically aligned architectures regarding
predictive performance while not relying on positional or structural encodings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10134">Spatial-Temporal Large Language Model for Traffic Prediction. (arXiv:2401.10134v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chenxi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qianxiong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhishuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1">Cheng Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziyue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Rui Zhao</a></p>
<p>Traffic prediction, a critical component for intelligent transportation
systems, endeavors to foresee future traffic at specific locations using
historical data. Although existing traffic prediction models often emphasize
developing complex neural network structures, their accuracy has not seen
improvements accordingly. Recently, Large Language Models (LLMs) have shown
outstanding capabilities in time series analysis. Differing from existing
models, LLMs progress mainly through parameter expansion and extensive
pre-training while maintaining their fundamental structures. In this paper, we
propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic
prediction. Specifically, ST-LLM redefines the timesteps at each location as
tokens and incorporates a spatial-temporal embedding module to learn the
spatial location and global temporal representations of tokens. Then these
representations are fused to provide each token with unified spatial and
temporal information. Furthermore, we propose a novel partially frozen
attention strategy of the LLM, which is designed to capture spatial-temporal
dependencies for traffic prediction. Comprehensive experiments on real traffic
datasets offer evidence that ST-LLM outperforms state-of-the-art models.
Notably, the ST-LLM also exhibits robust performance in both few-shot and
zero-shot prediction scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10144">Exploiting Hierarchical Interactions for Protein Surface Learning. (arXiv:2401.10144v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1">Yiqun Lin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pan_L/0/1/0/all/0/1">Liang Pan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_X/0/1/0/all/0/1">Xiaomeng Li</a></p>
<p>Predicting interactions between proteins is one of the most important yet
challenging problems in structural bioinformatics. Intrinsically, potential
function sites in protein surfaces are determined by both geometric and
chemical features. However, existing works only consider handcrafted or
individually learned chemical features from the atom type and extract geometric
features independently. Here, we identify two key properties of effective
protein surface learning: 1) relationship among atoms: atoms are linked with
each other by covalent bonds to form biomolecules instead of appearing alone,
leading to the significance of modeling the relationship among atoms in
chemical feature learning. 2) hierarchical feature interaction: the neighboring
residue effect validates the significance of hierarchical feature interaction
among atoms and between surface points and atoms (or residues). In this paper,
we present a principled framework based on deep learning techniques, namely
Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for
protein surface analysis by bridging chemical and geometric features with
hierarchical interactions. Extensive experiments demonstrate that our method
outperforms the prior state-of-the-art method by 2.3% in site prediction task
and 3.2% in interaction matching task, respectively. Our code is available at
https://github.com/xmed-lab/HCGNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10148">Explicitly Disentangled Representations in Object-Centric Learning. (arXiv:2401.10148v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Majellaro_R/0/1/0/all/0/1">Riccardo Majellaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Collu_J/0/1/0/all/0/1">Jonathan Collu</a>, <a href="http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1">Aske Plaat</a>, <a href="http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1">Thomas M. Moerland</a></p>
<p>Extracting structured representations from raw visual data is an important
and long-standing challenge in machine learning. Recently, techniques for
unsupervised learning of object-centric representations have raised growing
interest. In this context, enhancing the robustness of the latent features can
improve the efficiency and effectiveness of the training of downstream tasks. A
promising step in this direction is to disentangle the factors that cause
variation in the data. Previously, Invariant Slot Attention disentangled
position, scale, and orientation from the remaining features. Extending this
approach, we focus on separating the shape and texture components. In
particular, we propose a novel architecture that biases object-centric models
toward disentangling shape and texture components into two non-overlapping
subsets of the latent space dimensions. These subsets are known a priori, hence
before the training process. Experiments on a range of object-centric
benchmarks reveal that our approach achieves the desired disentanglement while
also numerically improving baseline performance in most cases. In addition, we
show that our method can generate novel textures for a specific object or
transfer textures between objects with distinct shapes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10149">Multi-Agent Reinforcement Learning for Maritime Operational Technology Cyber Security. (arXiv:2401.10149v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1">Alec Wilson</a>, <a href="http://arxiv.org/find/cs/1/au:+Menzies_R/0/1/0/all/0/1">Ryan Menzies</a>, <a href="http://arxiv.org/find/cs/1/au:+Morarji_N/0/1/0/all/0/1">Neela Morarji</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">David Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Mont_M/0/1/0/all/0/1">Marco Casassa Mont</a>, <a href="http://arxiv.org/find/cs/1/au:+Turkbeyler_E/0/1/0/all/0/1">Esin Turkbeyler</a>, <a href="http://arxiv.org/find/cs/1/au:+Gralewski_L/0/1/0/all/0/1">Lisa Gralewski</a></p>
<p>This paper demonstrates the potential for autonomous cyber defence to be
applied on industrial control systems and provides a baseline environment to
further explore Multi-Agent Reinforcement Learning's (MARL) application to this
problem domain. It introduces a simulation environment, IPMSRL, of a generic
Integrated Platform Management System (IPMS) and explores the use of MARL for
autonomous cyber defence decision-making on generic maritime based IPMS
Operational Technology (OT). OT cyber defensive actions are less mature than
they are for Enterprise IT. This is due to the relatively brittle nature of OT
infrastructure originating from the use of legacy systems, design-time
engineering assumptions, and lack of full-scale modern security controls. There
are many obstacles to be tackled across the cyber landscape due to continually
increasing cyber-attack sophistication and the limitations of traditional
IT-centric cyber defence solutions. Traditional IT controls are rarely deployed
on OT infrastructure, and where they are, some threats aren't fully addressed.
In our experiments, a shared critic implementation of Multi Agent Proximal
Policy Optimisation (MAPPO) outperformed Independent Proximal Policy
Optimisation (IPPO). MAPPO reached an optimal policy (episode outcome mean of
1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome
mean of 0.966 after one million timesteps. Hyperparameter tuning greatly
improved training performance. Across one million timesteps the tuned
hyperparameters reached an optimal policy whereas the default hyperparameters
only managed to win sporadically, with most simulations resulting in a draw. We
tested a real-world constraint, attack detection alert success, and found that
when alert success probability is reduced to 0.75 or 0.9, the MARL defenders
were still able to win in over 97.5% or 99.5% of episodes, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10155">A novel hybrid time-varying graph neural network for traffic flow forecasting. (arXiv:2401.10155v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Ben Ao Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_B/0/1/0/all/0/1">Bao-Lin Ye</a></p>
<p>Real-time and accurate traffic flow prediction is the foundation for ensuring
the efficient operation of intelligent transportation systems.In existing
traffic flow prediction methods based on graph neural networks (GNNs),
pre-defined graphs were usually used to describe the spatial correlations of
different traffic nodes in urban road networks. However, the ability of
pre-defined graphs used to describe spatial correlation was limited by prior
knowledge and graph generation methods. Although time-varying graphs based on
data-driven learning can partially overcome the drawbacks of pre-defined
graphs, the learning ability of existing adaptive graphs was limited. For
example, time-varying graphs cannot adequately capture the inherent spatial
correlations in traffic flow data.In order to solve these problems, we have
proposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow
prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10158">DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks. (arXiv:2401.10158v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koursioumpas_N/0/1/0/all/0/1">Nikolaos Koursioumpas</a>, <a href="http://arxiv.org/find/cs/1/au:+Magoula_L/0/1/0/all/0/1">Lina Magoula</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavrakakis_I/0/1/0/all/0/1">Ioannis Stavrakakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonistioti_N/0/1/0/all/0/1">Nancy Alonistioti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_Estevez_M/0/1/0/all/0/1">M. A. Gutierrez-Estevez</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalili_R/0/1/0/all/0/1">Ramin Khalili</a></p>
<p>Beyond 5G and 6G networks are expected to support new and challenging use
cases and applications that depend on a certain level of Quality of Service
(QoS) to operate smoothly. Predicting the QoS in a timely manner is of high
importance, especially for safety-critical applications as in the case of
vehicular communications. Although until recent years the QoS prediction has
been carried out by centralized Artificial Intelligence (AI) solutions, a
number of privacy, computational, and operational concerns have emerged.
Alternative solutions have been surfaced (e.g. Split Learning, Federated
Learning), distributing AI tasks of reduced complexity across nodes, while
preserving the privacy of the data. However, new challenges rise when it comes
to scalable distributed learning approaches, taking into account the
heterogeneous nature of future wireless networks. The current work proposes
DISTINQT, a privacy-aware distributed learning framework for QoS prediction.
Our framework supports multiple heterogeneous nodes, in terms of data types and
model architectures, by sharing computations across them. This, enables the
incorporation of diverse knowledge into a sole learning process that will
enhance the robustness and generalization capabilities of the final QoS
prediction model. DISTINQT also contributes to data privacy preservation by
encoding any raw input data into a non-linear latent representation before any
transmission. Evaluation results showcase that our framework achieves a
statistically identical performance compared to its centralized version and an
average performance improvement of up to 65% against six state-of-the-art
centralized baseline solutions in the Tele-Operated Driving use case.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10176">Comprehensive OOD Detection Improvements. (arXiv:2401.10176v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lakkapragada_A/0/1/0/all/0/1">Anish Lakkapragada</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanna_A/0/1/0/all/0/1">Amol Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1">Edward Raff</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1">Nathan Inkawhich</a></p>
<p>As machine learning becomes increasingly prevalent in impactful decisions,
recognizing when inference data is outside the model's expected input
distribution is paramount for giving context to predictions.
Out-of-distribution (OOD) detection methods have been created for this task.
Such methods can be split into representation-based or logit-based methods from
whether they respectively utilize the model's embeddings or predictions for OOD
detection. In contrast to most papers which solely focus on one such group, we
address both. We employ dimensionality reduction on feature embeddings in
representation-based methods for both time speedups and improved performance.
Additionally, we propose DICE-COL, a modification of the popular logit-based
method Directed Sparsification (DICE) that resolves an unnoticed flaw. We
demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark
framework, where they significantly improve performance and set
state-of-the-art results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10185">Transfer Learning in Human Activity Recognition: A Survey. (arXiv:2401.10185v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dhekane_S/0/1/0/all/0/1">Sourish Gunesh Dhekane</a>, <a href="http://arxiv.org/find/cs/1/au:+Ploetz_T/0/1/0/all/0/1">Thomas Ploetz</a></p>
<p>Sensor-based human activity recognition (HAR) has been an active research
area, owing to its applications in smart environments, assisted living,
fitness, healthcare, etc. Recently, deep learning based end-to-end training has
resulted in state-of-the-art performance in domains such as computer vision and
natural language, where large amounts of annotated data are available. However,
large quantities of annotated data are not available for sensor-based HAR.
Moreover, the real-world settings on which the HAR is performed differ in terms
of sensor modalities, classification tasks, and target users. To address this
problem, transfer learning has been employed extensively. In this survey, we
focus on these transfer learning methods in the application domains of smart
home and wearables-based HAR. In particular, we provide a problem-solution
perspective by categorizing and presenting the works in terms of their
contributions and the challenges they address. We also present an updated view
of the state-of-the-art for both application domains. Based on our analysis of
205 papers, we highlight the gaps in the literature and provide a roadmap for
addressing them. This survey provides a reference to the HAR community, by
summarizing the existing works and providing a promising research agenda.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10189">Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongxiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Huimin Zhao</a></p>
<p>Fine-grained few-shot entity extraction in the chemical domain faces two
unique challenges. First, compared with entity extraction tasks in the general
domain, sentences from chemical papers usually contain more entities. Moreover,
entity extraction models usually have difficulty extracting entities of
long-tailed types. In this paper, we propose Chem-FINESE, a novel
sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to
address these two challenges. Our Chem-FINESE has two components: a seq2seq
entity extractor to extract named entities from the input sentence and a
seq2seq self-validation module to reconstruct the original input sentence from
extracted entities. Inspired by the fact that a good entity extraction system
needs to extract entities faithfully, our new self-validation module leverages
entity extraction results to reconstruct the original input sentence. Besides,
we design a new contrastive loss to reduce excessive copying during the
extraction process. Finally, we release ChemNER+, a new fine-grained chemical
entity extraction dataset that is annotated by domain experts with the ChemNER
schema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets
show that our newly proposed framework has contributed up to 8.26% and 6.84%
absolute F1-score gains respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10190">A Kaczmarz-inspired approach to accelerate the optimization of neural network wavefunctions. (arXiv:2401.10190v1 [physics.comp-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Goldshlager_G/0/1/0/all/0/1">Gil Goldshlager</a>, <a href="http://arxiv.org/find/physics/1/au:+Abrahamsen_N/0/1/0/all/0/1">Nilin Abrahamsen</a>, <a href="http://arxiv.org/find/physics/1/au:+Lin_L/0/1/0/all/0/1">Lin Lin</a></p>
<p>Neural network wavefunctions optimized using the variational Monte Carlo
method have been shown to produce highly accurate results for the electronic
structure of atoms and small molecules, but the high cost of optimizing such
wavefunctions prevents their application to larger systems. We propose the
Subsampled Projected-Increment Natural Gradient Descent (SPRING) optimizer to
reduce this bottleneck. SPRING combines ideas from the recently introduced
minimum-step stochastic reconfiguration optimizer (MinSR) and the classical
randomized Kaczmarz method for solving linear least-squares problems. We
demonstrate that SPRING outperforms both MinSR and the popular
Kronecker-Factored Approximate Curvature method (KFAC) across a number of small
atoms and molecules, given that the learning rates of all methods are optimally
tuned. For example, on the oxygen atom, SPRING attains chemical accuracy after
forty thousand training iterations, whereas both MinSR and KFAC fail to do so
even after one hundred thousand iterations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10191">Divide and not forget: Ensemble of selectively trained experts in Continual Learning. (arXiv:2401.10191v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rypesc_G/0/1/0/all/0/1">Grzegorz Rype&#x15b;&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1">Sebastian Cygert</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_V/0/1/0/all/0/1">Valeriya Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_B/0/1/0/all/0/1">Bartosz Zieli&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Twardowski_B/0/1/0/all/0/1">Bart&#x142;omiej Twardowski</a></p>
<p>Class-incremental learning is becoming more popular as it helps models widen
their applicability while not forgetting what they already know. A trend in
this area is to use a mixture-of-expert technique, where different models work
together to solve the task. However, the experts are usually trained all at
once using whole task data, which makes them all prone to forgetting and
increasing computational burden. To address this limitation, we introduce a
novel approach named SEED. SEED selects only one, the most optimal expert for a
considered task, and uses data from this task to fine-tune only this expert.
For this purpose, each expert represents each class with a Gaussian
distribution, and the optimal expert is selected based on the similarity of
those distributions. Consequently, SEED increases diversity and heterogeneity
within the experts while maintaining the high stability of this ensemble
method. The extensive experiments demonstrate that SEED achieves
state-of-the-art performance in exemplar-free settings across various
scenarios, showing the potential of expert diversification through data in
continual learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10207">Eclectic Rule Extraction for Explainability of Deep Neural Network based Intrusion Detection Systems. (arXiv:2401.10207v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ables_J/0/1/0/all/0/1">Jesse Ables</a>, <a href="http://arxiv.org/find/cs/1/au:+Childers_N/0/1/0/all/0/1">Nathaniel Childers</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_W/0/1/0/all/0/1">William Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1">Sudip Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahimi_S/0/1/0/all/0/1">Shahram Rahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banicescu_I/0/1/0/all/0/1">Ioana Banicescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Seale_M/0/1/0/all/0/1">Maria Seale</a></p>
<p>This paper addresses trust issues created from the ubiquity of black box
algorithms and surrogate explainers in Explainable Intrusion Detection Systems
(X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance
transparency, black box surrogate explainers, such as Local Interpretable
Model-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are
difficult to trust. The black box nature of these surrogate explainers makes
the process behind explanation generation opaque and difficult to understand.
To avoid this problem, one can use transparent white box algorithms such as
Rule Extraction (RE). There are three types of RE algorithms: pedagogical,
decompositional, and eclectic. Pedagogical methods offer fast but untrustworthy
white-box explanations, while decompositional RE provides trustworthy
explanations with poor scalability. This work explores eclectic rule
extraction, which strikes a balance between scalability and trustworthiness. By
combining techniques from pedagogical and decompositional approaches, eclectic
rule extraction leverages the advantages of both, while mitigating some of
their drawbacks. The proposed Hybrid X-IDS architecture features eclectic RE as
a white box surrogate explainer for black box Deep Neural Networks (DNN). The
presented eclectic RE algorithm extracts human-readable rules from hidden
layers, facilitating explainable and trustworthy rulesets. Evaluations on
UNSW-NB15 and CIC-IDS-2017 datasets demonstrate the algorithm's ability to
generate rulesets with 99.9% accuracy, mimicking DNN outputs. The contributions
of this work include the hybrid X-IDS architecture, the eclectic rule
extraction algorithm applicable to intrusion detection datasets, and a thorough
analysis of performance and explainability, demonstrating the trade-offs
involved in rule extraction speed and accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10210">Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction. (arXiv:2401.10210v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shakya_A/0/1/0/all/0/1">Anup Shakya</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_V/0/1/0/all/0/1">Vasile Rus</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopal_D/0/1/0/all/0/1">Deepak Venugopal</a></p>
<p>Predicting the strategy (sequence of concepts) that a student is likely to
use in problem-solving helps Adaptive Instructional Systems (AISs) better adapt
themselves to different types of learners based on their learning abilities.
This can lead to a more dynamic, engaging, and personalized experience for
students. To scale up training a prediction model (such as LSTMs) over
large-scale education datasets, we develop a non-parametric approach to cluster
symmetric instances in the data. Specifically, we learn a representation based
on Node2Vec that encodes symmetries over mastery or skill level since, to solve
a problem, it is natural that a student's strategy is likely to involve
concepts in which they have gained mastery. Using this representation, we use
DP-Means to group symmetric instances through a coarse-to-fine refinement of
the clusters. We apply our model to learn strategies for Math learning from
large-scale datasets from MATHia, a leading AIS for middle-school math
learning. Our results illustrate that our approach can consistently achieve
high accuracy using a small sample that is representative of the full dataset.
Further, we show that this approach helps us learn strategies with high
accuracy for students at different skill levels, i.e., leveraging symmetries
improves fairness in the prediction model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10211">Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation. (arXiv:2401.10211v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Li_Z/0/1/0/all/0/1">Zhengyi Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_M/0/1/0/all/0/1">Menglu Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_L/0/1/0/all/0/1">Lida Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a></p>
<p>Protein post-translational modification (PTM) site prediction is a
fundamental task in bioinformatics. Several computational methods have been
developed to predict PTM sites. However, existing methods ignore the structure
information and merely utilize protein sequences. Furthermore, designing a more
fine-grained structure representation learning method is urgently needed as PTM
is a biological event that occurs at the atom granularity. In this paper, we
propose a PTM site prediction method by Coupling of Multi-Granularity structure
and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically,
multigranularity structure-aware representation learning is designed to learn
neighborhood structure representations at the amino acid, atom, and whole
protein granularity from AlphaFold predicted structures, followed by utilizing
contrastive learning to optimize the structure representations.Additionally,
multi-scale sequence representation learning is used to extract context
sequence information, and motif generated by aligning all context sequences of
PTM sites assists the prediction. Extensive experiments on three datasets show
that PTM-CMGMS outperforms the state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10213">Improving automatic detection of driver fatigue and distraction using machine learning. (arXiv:2401.10213v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongjiang Wu</a></p>
<p>Changes and advances in information technology have played an important role
in the development of intelligent vehicle systems in recent years. Driver
fatigue and distracted driving are important factors in traffic accidents.
Thus, onboard monitoring of driving behavior has become a crucial component of
advanced driver assistance systems for intelligent vehicles. In this article,
we present techniques for simultaneously detecting fatigue and distracted
driving behaviors using vision-based and machine learning-based approaches. In
driving fatigue detection, we use facial alignment networks to identify facial
feature points in the images, and calculate the distance of the facial feature
points to detect the opening and closing of the eyes and mouth. Furthermore, we
use a convolutional neural network (CNN) based on the MobileNet architecture to
identify various distracted driving behaviors. Experiments are performed on a
PC based setup with a webcam and results are demonstrated using public datasets
as well as custom datasets created for training and testing. Compared to
previous approaches, we build our own datasets and provide better results in
terms of accuracy and computation time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10216">Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products. (arXiv:2401.10216v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shengjie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnapriyan_A/0/1/0/all/0/1">Aditi S. Krishnapriyan</a></p>
<p>Developing equivariant neural networks for the E(3) group plays an important
role in modeling 3D data across real-world applications. Enforcing this
equivariance primarily involves the tensor products of irreducible
representations (irreps). However, the computational complexity of such
operations increases significantly as higher-order tensors are used. In this
work, we propose a systematic approach to substantially accelerate the
computation of the tensor products of irreps. We mathematically connect the
commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are
integrals of products of three spherical harmonics. Through Gaunt coefficients,
the tensor product of irreps becomes equivalent to the multiplication between
spherical functions represented by spherical harmonics. This perspective
further allows us to change the basis for the equivariant operations from
spherical harmonics to a 2D Fourier basis. Consequently, the multiplication
between spherical functions represented by a 2D Fourier basis can be
efficiently computed via the convolution theorem and Fast Fourier Transforms.
This transformation reduces the complexity of full tensor products of irreps
from $\mathcal{O}(L^6)$ to $\mathcal{O}(L^3)$, where $L$ is the max degree of
irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which
serves as a new method to construct efficient equivariant operations across
different model architectures. Our experiments on the Open Catalyst Project and
3BPA datasets demonstrate both the increased efficiency and improved
performance of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10220">AutoFT: Robust Fine-Tuning by Optimizing Hyperparameters on OOD Data. (arXiv:2401.10220v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1">Caroline Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yoonho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Annie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1">Allan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Aditi Raghunathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a></p>
<p>Foundation models encode rich representations that can be adapted to a
desired task by fine-tuning on task-specific data. However, fine-tuning a model
on one particular data distribution often compromises the model's original
performance on other distributions. Current methods for robust fine-tuning
utilize hand-crafted regularization techniques to constrain the fine-tuning
process towards the base foundation model. Yet, it is hard to precisely specify
what characteristics of the foundation model to retain during fine-tuning, as
this depends on how the pre-training, fine-tuning, and evaluation data
distributions relate to each other. We propose AutoFT, a data-driven approach
for guiding foundation model fine-tuning. AutoFT optimizes fine-tuning
hyperparameters to maximize performance on a small out-of-distribution (OOD)
validation set. To guide fine-tuning in a granular way, AutoFT searches a
highly expressive hyperparameter space that includes weight coefficients for
many different losses, in addition to learning rate and weight decay values. We
evaluate AutoFT on nine natural distribution shifts which include domain shifts
and subpopulation shifts. Our experiments show that AutoFT significantly
improves generalization to new OOD data, outperforming existing robust
fine-tuning methods. Notably, AutoFT achieves new state-of-the-art performance
on the WILDS-iWildCam and WILDS-FMoW benchmarks, outperforming the previous
best methods by $6.0\%$ and $1.5\%$, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10225">ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1">Rajarshi Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a></p>
<p>In this work, we introduce ChatQA, a family of conversational question
answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we
propose a two-stage instruction tuning method that can significantly improve
the zero-shot conversational QA results from large language models (LLMs). To
handle retrieval in conversational QA, we fine-tune a dense retriever on a
multi-turn QA dataset, which provides comparable results to using the
state-of-the-art query rewriting model while largely reducing deployment cost.
Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10
conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic
data from OpenAI GPT models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10227">A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask Inpainting. (arXiv:2401.10227v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1">Wouter Van Gansbeke</a>, <a href="http://arxiv.org/find/cs/1/au:+Brabandere_B/0/1/0/all/0/1">Bert De Brabandere</a></p>
<p>Panoptic and instance segmentation networks are often trained with
specialized object detection modules, complex loss functions, and ad-hoc
post-processing steps to handle the permutation-invariance of the instance
masks. This work builds upon Stable Diffusion and proposes a latent diffusion
approach for panoptic segmentation, resulting in a simple architecture which
omits these complexities. Our training process consists of two steps: (1)
training a shallow autoencoder to project the segmentation masks to latent
space; (2) training a diffusion model to allow image-conditioned sampling in
latent space. The use of a generative model unlocks the exploration of mask
completion or inpainting, which has applications in interactive segmentation.
The experimental validation yields promising results for both panoptic
segmentation and mask inpainting. While not setting a new state-of-the-art, our
model's simplicity, generality, and mask completion capability are desirable
properties.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2011.14238">Approximate Cross-validated Mean Estimates for Bayesian Hierarchical Regression Models. (arXiv:2011.14238v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zhang_A/0/1/0/all/0/1">Amy X. Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Bao_L/0/1/0/all/0/1">Le Bao</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1">Changcheng Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Daniels_M/0/1/0/all/0/1">Michael J. Daniels</a></p>
<p>We introduce a novel procedure for obtaining cross-validated predictive
estimates for Bayesian hierarchical regression models (BHRMs). Bayesian
hierarchical models are popular for their ability to model complex dependence
structures and provide probabilistic uncertainty estimates, but can be
computationally expensive to run. Cross-validation (CV) is therefore not a
common practice to evaluate the predictive performance of BHRMs. Our method
circumvents the need to re-run computationally costly estimation methods for
each cross-validation fold and makes CV more feasible for large BHRMs. By
conditioning on the variance-covariance parameters, we shift the CV problem
from probability-based sampling to a simple and familiar optimization problem.
In many cases, this produces estimates which are equivalent to full CV. We
provide theoretical results and demonstrate its efficacy on publicly available
data and in simulations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.08440">Climate-Invariant Machine Learning. (arXiv:2112.08440v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Beucler_T/0/1/0/all/0/1">Tom Beucler</a>, <a href="http://arxiv.org/find/cs/1/au:+Gentine_P/0/1/0/all/0/1">Pierre Gentine</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuval_J/0/1/0/all/0/1">Janni Yuval</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ankitesh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1">Liran Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jerry Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sungduk Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasp_S/0/1/0/all/0/1">Stephan Rasp</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1">Fiaz Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+OGorman_P/0/1/0/all/0/1">Paul A. O&#x27;Gorman</a>, <a href="http://arxiv.org/find/cs/1/au:+Neelin_J/0/1/0/all/0/1">J. David Neelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutsko_N/0/1/0/all/0/1">Nicholas J. Lutsko</a>, <a href="http://arxiv.org/find/cs/1/au:+Pritchard_M/0/1/0/all/0/1">Michael Pritchard</a></p>
<p>Projecting climate change is a generalization problem: we extrapolate the
recent past using physical models across past, present, and future climates.
Current climate models require representations of processes that occur at
scales smaller than model grid size, which have been the main source of model
projection uncertainty. Recent machine learning (ML) algorithms hold promise to
improve such process representations, but tend to extrapolate poorly to climate
regimes they were not trained on. To get the best of the physical and
statistical worlds, we propose a new framework - termed "climate-invariant" ML
- incorporating knowledge of climate processes into ML algorithms, and show
that it can maintain high offline accuracy across a wide range of climate
conditions and configurations in three distinct atmospheric models. Our results
suggest that explicitly incorporating physical knowledge into data-driven
models of Earth system processes can improve their consistency, data
efficiency, and generalizability across climate regimes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.13125">Normality-Guided Distributional Reinforcement Learning for Continuous Control. (arXiv:2208.13125v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Byun_J/0/1/0/all/0/1">Ju-Seung Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrault_A/0/1/0/all/0/1">Andrew Perrault</a></p>
<p>Learning a predictive model of the mean return, or value function, plays a
critical role in many reinforcement learning algorithms. Distributional
reinforcement learning (DRL) has been shown to improve performance by modeling
the value distribution, not just the mean. We study the value distribution in
several continuous control tasks and find that the learned value distribution
is empirical quite close to normal. We design a method that exploits this
property, employ variances predicted from a variance network, along with
returns, to analytically compute target quantile bars representing a normal for
our distributional value function. In addition, we propose a policy update
strategy based on the correctness as measured by structural characteristics of
the value distribution not present in the standard value function. The approach
we outline is compatible with many DRL structures. We use two representative
on-policy algorithms, PPO and TRPO, as testbeds. Our method yields
statistically significant improvements in 10 out of 16 continuous task
settings, while utilizing a reduced number of weights and achieving faster
training time compared to an ensemble-based method for quantifying value
distribution uncertainty.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.15629">Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks. (arXiv:2210.15629v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1">Edwin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yujie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Amy Zhang</a></p>
<p>Training generalist agents is difficult across several axes, requiring us to
deal with high-dimensional inputs (space), long horizons (time), and
generalization to novel tasks. Recent advances with architectures have allowed
for improved scaling along one or two of these axes, but are still
computationally prohibitive to use. In this paper, we propose to address all
three axes by leveraging \textbf{L}anguage to \textbf{C}ontrol
\textbf{D}iffusion models as a hierarchical planner conditioned on language
(LCD). We effectively and efficiently scale diffusion models for planning in
extended temporal, state, and task dimensions to tackle long horizon control
problems conditioned on natural language instructions, as a step towards
generalist agents. Comparing LCD with other state-of-the-art models on the
CALVIN language robotics benchmark finds that LCD outperforms other SOTA
methods in multi-task success rates, whilst improving inference speed over
other comparable diffusion models by 3.3x~15x. We show that LCD can
successfully leverage the unique strength of diffusion models to produce
coherent long range plans while addressing their weakness in generating
low-level details and control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.11086">An Embarrassingly Simple Baseline for Imbalanced Semi-Supervised Learning. (arXiv:2211.11086v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yue Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiele_B/0/1/0/all/0/1">Bernt Schiele</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Savvides_M/0/1/0/all/0/1">Marios Savvides</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1">Bhiksha Raj</a></p>
<p>Semi-supervised learning (SSL) has shown great promise in leveraging
unlabeled data to improve model performance. While standard SSL assumes uniform
data distribution, we consider a more realistic and challenging setting called
imbalanced SSL, where imbalanced class distributions occur in both labeled and
unlabeled data. Although there are existing endeavors to tackle this challenge,
their performance degenerates when facing severe imbalance since they can not
reduce the class imbalance sufficiently and effectively. In this paper, we
study a simple yet overlooked baseline -- SimiS -- which tackles data imbalance
by simply supplementing labeled data with pseudo-labels, according to the
difference in class distribution from the most frequent class. Such a simple
baseline turns out to be highly effective in reducing class imbalance. It
outperforms existing methods by a significant margin, e.g., 12.8%, 13.6%, and
16.7% over previous SOTA on CIFAR100-LT, FOOD101-LT, and ImageNet127
respectively. The reduced imbalance results in faster convergence and better
pseudo-label accuracy of SimiS. The simplicity of our method also makes it
possible to be combined with other re-balancing techniques to improve the
performance further. Moreover, our method shows great robustness to a wide
range of data distributions, which holds enormous potential in practice. Code
will be publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.14630">Detecting Change Intervals with Isolation Distributional Kernel. (arXiv:2212.14630v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Ye Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_K/0/1/0/all/0/1">Kai Ming Ting</a>, <a href="http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1">Flora D. Salim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hong Xian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Luxing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gang Li</a></p>
<p>Detecting abrupt changes in data distribution is one of the most significant
tasks in streaming data analysis. Although many unsupervised Change-Point
Detection (CPD) methods have been proposed recently to identify those changes,
they still suffer from missing subtle changes, poor scalability, or/and
sensitivity to outliers. To meet these challenges, we are the first to
generalise the CPD problem as a special case of the Change-Interval Detection
(CID) problem. Then we propose a CID method, named iCID, based on a recent
Isolation Distributional Kernel (IDK). iCID identifies the change interval if
there is a high dissimilarity score between two non-homogeneous temporal
adjacent intervals. The data-dependent property and finite feature map of IDK
enabled iCID to efficiently identify various types of change-points in data
streams with the tolerance of outliers. Moreover, the proposed online and
offline versions of iCID have the ability to optimise key parameter settings.
The effectiveness and efficiency of iCID have been systematically verified on
both synthetic and real-world datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.00924">Increasing biases can be more efficient than increasing weights. (arXiv:2301.00924v3 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Metta_C/0/1/0/all/0/1">Carlo Metta</a>, <a href="http://arxiv.org/find/cs/1/au:+Fantozzi_M/0/1/0/all/0/1">Marco Fantozzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papini_A/0/1/0/all/0/1">Andrea Papini</a>, <a href="http://arxiv.org/find/cs/1/au:+Amato_G/0/1/0/all/0/1">Gianluca Amato</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergamaschi_M/0/1/0/all/0/1">Matteo Bergamaschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Galfre_S/0/1/0/all/0/1">Silvia Giulia Galfr&#xe8;</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchetti_A/0/1/0/all/0/1">Alessandro Marchetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Veglio_M/0/1/0/all/0/1">Michelangelo Vegli&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Parton_M/0/1/0/all/0/1">Maurizio Parton</a>, <a href="http://arxiv.org/find/cs/1/au:+Morandin_F/0/1/0/all/0/1">Francesco Morandin</a></p>
<p>We introduce a novel computational unit for neural networks that features
multiple biases, challenging the traditional perceptron structure. This unit
emphasizes the importance of preserving uncorrupted information as it is passed
from one unit to the next, applying activation functions later in the process
with specialized biases for each unit. Through both empirical and theoretical
analyses, we show that by focusing on increasing biases rather than weights,
there is potential for significant enhancement in a neural network model's
performance. This approach offers an alternative perspective on optimizing
information flow within neural networks. See source code at
https://github.com/CuriosAI/dac-dev.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00695">Versatile Energy-Based Probabilistic Models for High Energy Physics. (arXiv:2302.00695v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_T/0/1/0/all/0/1">Taoli Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a></p>
<p>As a classical generative modeling approach, energy-based models have the
natural advantage of flexibility in the form of the energy function. Recently,
energy-based models have achieved great success in modeling high-dimensional
data in computer vision and natural language processing. In line with these
advancements, we build a multi-purpose energy-based probabilistic model for
High Energy Physics events at the Large Hadron Collider. This framework builds
on a powerful generative model and describes higher-order inter-particle
interactions. It suits different encoding architectures and builds on implicit
generation. As for applicative aspects, it can serve as a powerful
parameterized event generator for physics simulation, a generic anomalous
signal detector free from spurious correlations, and an augmented event
classifier for particle identification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.02070">Semantic-Guided Generative Image Augmentation Method with Diffusion Models for Image Classification. (arXiv:2302.02070v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinghao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yutai Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yunlong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Feng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuanliang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qingfu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1">Wanxiang Che</a></p>
<p>Existing image augmentation methods consist of two categories:
perturbation-based methods and generative methods. Perturbation-based methods
apply pre-defined perturbations to augment an original image, but only locally
vary the image, thus lacking image diversity. In contrast, generative methods
bring more image diversity in the augmented images but may not preserve
semantic consistency, thus incorrectly changing the essential semantics of the
original image. To balance image diversity and semantic consistency in
augmented images, we propose SGID, a Semantic-guided Generative Image
augmentation method with Diffusion models for image classification.
Specifically, SGID employs diffusion models to generate augmented images with
good image diversity. More importantly, SGID takes image labels and captions as
guidance to maintain semantic consistency between the augmented and original
images. Experimental results show that SGID outperforms the best augmentation
baseline by 1.72% on ResNet-50 (from scratch), 0.33% on ViT (ImageNet-21k), and
0.14% on CLIP-ViT (LAION-2B). Moreover, SGID can be combined with other image
augmentation baselines and further improves the overall performance. We
demonstrate the semantic consistency and image diversity of SGID through
quantitative human and automated evaluations, as well as qualitative case
studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.07580">Unboxing Tree Ensembles for interpretability: a hierarchical visualization tool and a multivariate optimal re-built tree. (arXiv:2302.07580v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Teodoro_G/0/1/0/all/0/1">Giulia Di Teodoro</a>, <a href="http://arxiv.org/find/math/1/au:+Monaci_M/0/1/0/all/0/1">Marta Monaci</a>, <a href="http://arxiv.org/find/math/1/au:+Palagi_L/0/1/0/all/0/1">Laura Palagi</a></p>
<p>The interpretability of models has become a crucial issue in Machine Learning
because of algorithmic decisions' growing impact on real-world applications.
Tree ensemble methods, such as Random Forests or XgBoost, are powerful learning
tools for classification tasks. However, while combining multiple trees may
provide higher prediction quality than a single one, it sacrifices the
interpretability property resulting in "black-box" models. In light of this, we
aim to develop an interpretable representation of a tree-ensemble model that
can provide valuable insights into its behavior. First, given a target
tree-ensemble model, we develop a hierarchical visualization tool based on a
heatmap representation of the forest's feature use, considering the frequency
of a feature and the level at which it is selected as an indicator of
importance. Next, we propose a mixed-integer linear programming (MILP)
formulation for constructing a single optimal multivariate tree that accurately
mimics the target model predictions. The goal is to provide an interpretable
surrogate model based on oblique hyperplane splits, which uses only the most
relevant features according to the defined forest's importance indicators. The
MILP model includes a penalty on feature selection based on their frequency in
the forest to further induce sparsity of the splits. The natural formulation
has been strengthened to improve the computational performance of
{mixed-integer} software. Computational experience is carried out on benchmark
datasets from the UCI repository using a state-of-the-art off-the-shelf solver.
Results show that the proposed model is effective in yielding a shallow
interpretable tree approximating the tree-ensemble decision function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02472">ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure. (arXiv:2303.02472v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoon_H/0/1/0/all/0/1">Hee Suk Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Tee_J/0/1/0/all/0/1">Joshua Tian Jin Tee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_E/0/1/0/all/0/1">Eunseop Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sunjae Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gwangsu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingzhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1">Chang D. Yoo</a></p>
<p>Studies have shown that modern neural networks tend to be poorly calibrated
due to over-confident predictions. Traditionally, post-processing methods have
been used to calibrate the model after training. In recent years, various
trainable calibration measures have been proposed to incorporate them directly
into the training process. However, these methods all incorporate internal
hyperparameters, and the performance of these calibration objectives relies on
tuning these hyperparameters, incurring more computational costs as the size of
neural networks and datasets become larger. As such, we present Expected
Squared Difference (ESD), a tuning-free (i.e., hyperparameter-free) trainable
calibration objective loss, where we view the calibration error from the
perspective of the squared difference between the two expectations. With
extensive experiments on several architectures (CNNs, Transformers) and
datasets, we demonstrate that (1) incorporating ESD into the training improves
model calibration in various batch size settings without the need for internal
hyperparameter tuning, (2) ESD yields the best-calibrated results compared with
previous approaches, and (3) ESD drastically improves the computational costs
required for calibration during training due to the absence of internal
hyperparameter. The code is publicly accessible at
https://github.com/hee-suk-yoon/ESD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.09906">Discovering mesoscopic descriptions of collective movement with neural stochastic modelling. (arXiv:2303.09906v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pratiush_U/0/1/0/all/0/1">Utkarsh Pratiush</a>, <a href="http://arxiv.org/find/cs/1/au:+Nabeel_A/0/1/0/all/0/1">Arshed Nabeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttal_V/0/1/0/all/0/1">Vishwesha Guttal</a>, <a href="http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1">Prathosh AP</a></p>
<p>Collective motion is an ubiquitous phenomenon in nature, inspiring engineers,
physicists and mathematicians to develop mathematical models and bio-inspired
designs. Collective motion at small to medium group sizes ($\sim$10-1000
individuals, also called the `mesoscale'), can show nontrivial features due to
stochasticity. Therefore, characterizing both the deterministic and stochastic
aspects of the dynamics is crucial in the study of mesoscale collective
phenomena. Here, we use a physics-inspired, neural-network based approach to
characterize the stochastic group dynamics of interacting individuals, through
a stochastic differential equation (SDE) that governs the collective dynamics
of the group. We apply this technique on both synthetic and real-world
datasets, and identify the deterministic and stochastic aspects of the dynamics
using drift and diffusion fields, enabling us to make novel inferences about
the nature of order in these systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.15579">Adjusted Wasserstein Distributionally Robust Estimator in Statistical Learning. (arXiv:2303.15579v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1">Yiling Xie</a>, <a href="http://arxiv.org/find/stat/1/au:+Huo_X/0/1/0/all/0/1">Xiaoming Huo</a></p>
<p>We propose an adjusted Wasserstein distributionally robust estimator -- based
on a nonlinear transformation of the Wasserstein distributionally robust (WDRO)
estimator in statistical learning. The classic WDRO estimator is asymptotically
biased, while our adjusted WDRO estimator is asymptotically unbiased, resulting
in a smaller asymptotic mean squared error. Meanwhile, the proposed adjusted
WDRO has an out-of-sample performance guarantee. Further, under certain
conditions, our proposed adjustment technique provides a general principle to
de-bias asymptotically biased estimators. Specifically, we will investigate how
the adjusted WDRO estimator is developed in the generalized linear model,
including logistic regression, linear regression, and Poisson regression.
Numerical experiments demonstrate the favorable practical performance of the
adjusted estimator over the classic one.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17045">Training Neural Networks is NP-Hard in Fixed Dimension. (arXiv:2303.17045v2 [cs.CC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Froese_V/0/1/0/all/0/1">Vincent Froese</a>, <a href="http://arxiv.org/find/cs/1/au:+Hertrich_C/0/1/0/all/0/1">Christoph Hertrich</a></p>
<p>We study the parameterized complexity of training two-layer neural networks
with respect to the dimension of the input data and the number of hidden
neurons, considering ReLU and linear threshold activation functions. Albeit the
computational complexity of these problems has been studied numerous times in
recent years, several questions are still open. We answer questions by Arora et
al. [ICLR '18] and Khalife and Basu [IPCO '22] showing that both problems are
NP-hard for two dimensions, which excludes any polynomial-time algorithm for
constant dimension. We also answer a question by Froese et al. [JAIR '22]
proving W[1]-hardness for four ReLUs (or two linear threshold neurons) with
zero training error. Finally, in the ReLU case, we show fixed-parameter
tractability for the combined parameter number of dimensions and number of
ReLUs if the network is assumed to compute a convex map. Our results settle the
complexity status regarding these parameters almost completely.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.01300">On Mitigating the Utility-Loss in Differentially Private Learning: A new Perspective by a Geometrically Inspired Kernel Approach. (arXiv:2304.01300v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">Mohit Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Moser_B/0/1/0/all/0/1">Bernhard A. Moser</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_L/0/1/0/all/0/1">Lukas Fischer</a></p>
<p>Privacy-utility tradeoff remains as one of the fundamental issues of
differentially private machine learning. This paper introduces a geometrically
inspired kernel-based approach to mitigate the accuracy-loss issue in
classification. In this approach, a representation of the affine hull of given
data points is learned in Reproducing Kernel Hilbert Spaces (RKHS). This leads
to a novel distance measure that hides privacy-sensitive information about
individual data points and improves the privacy-utility tradeoff via
significantly reducing the risk of membership inference attacks. The
effectiveness of the approach is demonstrated through experiments on MNIST
dataset, Freiburg groceries dataset, and a real biomedical dataset. It is
verified that the approach remains computationally practical. The application
of the approach to federated learning is considered and it is observed that the
accuracy-loss due to data being distributed is either marginal or not
significantly high.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.05527">Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box. (arXiv:2304.05527v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Giordano_R/0/1/0/all/0/1">Ryan Giordano</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingram_M/0/1/0/all/0/1">Martin Ingram</a>, <a href="http://arxiv.org/find/cs/1/au:+Broderick_T/0/1/0/all/0/1">Tamara Broderick</a></p>
<p>Automatic differentiation variational inference (ADVI) offers fast and
easy-to-use posterior approximation in multiple modern probabilistic
programming languages. However, its stochastic optimizer lacks clear
convergence criteria and requires tuning parameters. Moreover, ADVI inherits
the poor posterior uncertainty estimates of mean-field variational Bayes
(MFVB). We introduce "deterministic ADVI" (DADVI) to address these issues.
DADVI replaces the intractable MFVB objective with a fixed Monte Carlo
approximation, a technique known in the stochastic optimization literature as
the "sample average approximation" (SAA). By optimizing an approximate but
deterministic objective, DADVI can use off-the-shelf second-order optimization,
and, unlike standard mean-field ADVI, is amenable to more accurate posterior
covariances via linear response (LR). In contrast to existing worst-case
theory, we show that, on certain classes of common statistical problems, DADVI
and the SAA can perform well with relatively few samples even in very high
dimensions, though we also show that such favorable results cannot extend to
variational approximations that are too expressive relative to mean-field ADVI.
We show on a variety of real-world problems that DADVI reliably finds good
solutions with default settings (unlike ADVI) and, together with LR
covariances, is typically faster and more accurate than standard ADVI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09048">CodeKGC: Code Language Model for Generative Knowledge Graph Construction. (arXiv:2304.09048v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1">Zhen Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yinuo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_F/0/1/0/all/0/1">Feiyu Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Wei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a></p>
<p>Current generative knowledge graph construction approaches usually fail to
capture structural knowledge by simply flattening natural language into
serialized texts or a specification language. However, large generative
language model trained on structured data such as code has demonstrated
impressive capability in understanding natural language for structural
prediction and reasoning tasks. Intuitively, we address the task of generative
knowledge graph construction with code language model: given a code-format
natural language input, the target is to generate triples which can be
represented as code completion tasks. Specifically, we develop schema-aware
prompts that effectively utilize the semantic structure within the knowledge
graph. As code inherently possesses structure, such as class and function
definitions, it serves as a useful model for prior semantic structural
knowledge. Furthermore, we employ a rationale-enhanced generation method to
boost the performance. Rationales provide intermediate steps, thereby improving
knowledge extraction abilities. Experimental results indicate that the proposed
approach can obtain better performance on benchmark datasets compared with
baselines. Code and datasets are available in
https://github.com/zjunlp/DeepKE/tree/main/example/llm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09172">Hyperbolic Image-Text Representations. (arXiv:2304.09172v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Desai_K/0/1/0/all/0/1">Karan Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Nickel_M/0/1/0/all/0/1">Maximilian Nickel</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurohit_T/0/1/0/all/0/1">Tanmay Rajpurohit</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_J/0/1/0/all/0/1">Justin Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedantam_R/0/1/0/all/0/1">Ramakrishna Vedantam</a></p>
<p>Visual and linguistic concepts naturally organize themselves in a hierarchy,
where a textual concept "dog" entails all images that contain dogs. Despite
being intuitive, current large-scale vision and language models such as CLIP do
not explicitly capture such hierarchy. We propose MERU, a contrastive model
that yields hyperbolic representations of images and text. Hyperbolic spaces
have suitable geometric properties to embed tree-like data, so MERU can better
capture the underlying hierarchy in image-text datasets. Our results show that
MERU learns a highly interpretable and structured representation space while
being competitive with CLIP's performance on standard multi-modal tasks like
image classification and image-text retrieval. Our code and models are
available at https://www.github.com/facebookresearch/meru
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02650">A Constrained BA Algorithm for Rate-Distortion and Distortion-Rate Functions. (arXiv:2305.02650v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lingyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shitong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1">Wenhao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huihui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1">Bo Bai</a></p>
<p>The Blahut-Arimoto (BA) algorithm has played a fundamental role in the
numerical computation of rate-distortion (RD) functions. This algorithm
possesses a desirable monotonic convergence property by alternatively
minimizing its Lagrangian with a fixed multiplier. In this paper, we propose a
novel modification of the BA algorithm, wherein the multiplier is updated
through a one-dimensional root-finding step using a monotonic univariate
function, efficiently implemented by Newton's method in each iteration.
Consequently, the modified algorithm directly computes the RD function for a
given target distortion, without exploring the entire RD curve as in the
original BA algorithm. Moreover, this modification presents a versatile
framework, applicable to a wide range of problems, including the computation of
distortion-rate (DR) functions. Theoretical analysis shows that the outputs of
the modified algorithms still converge to the solutions of the RD and DR
functions with rate $O(1/n)$, where $n$ is the number of iterations.
Additionally, these algorithms provide $\varepsilon$-approximation solutions
with $O\left(\frac{MN\log N}{\varepsilon}(1+\log |\log \varepsilon|)\right)$
arithmetic operations, where $M,N$ are the sizes of source and reproduced
alphabets respectively. Numerical experiments demonstrate that the modified
algorithms exhibit significant acceleration compared with the original BA
algorithms and showcase commendable performance across classical source
distributions such as discretized Gaussian, Laplacian and uniform sources.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02749">Explainable Reinforcement Learning via a Causal World Model. (arXiv:2305.02749v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhongwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_J/0/1/0/all/0/1">Jingqing Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_D/0/1/0/all/0/1">Dengpeng Xing</a></p>
<p>Generating explanations for reinforcement learning (RL) is challenging as
actions may produce long-term effects on the future. In this paper, we develop
a novel framework for explainable RL by learning a causal world model without
prior knowledge of the causal structure of the environment. The model captures
the influence of actions, allowing us to interpret the long-term effects of
actions through causal chains, which present how actions influence
environmental variables and finally lead to rewards. Different from most
explanatory models which suffer from low accuracy, our model remains accurate
while improving explainability, making it applicable in model-based learning.
As a result, we demonstrate that our causal model can serve as the bridge
between explainability and learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.04099">Symbolic Regression on FPGAs for Fast Machine Learning Inference. (arXiv:2305.04099v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsoi_H/0/1/0/all/0/1">Ho Fung Tsoi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pol_A/0/1/0/all/0/1">Adrian Alan Pol</a>, <a href="http://arxiv.org/find/cs/1/au:+Loncar_V/0/1/0/all/0/1">Vladimir Loncar</a>, <a href="http://arxiv.org/find/cs/1/au:+Govorkova_E/0/1/0/all/0/1">Ekaterina Govorkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Cranmer_M/0/1/0/all/0/1">Miles Cranmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasu_S/0/1/0/all/0/1">Sridhara Dasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmer_P/0/1/0/all/0/1">Peter Elmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_P/0/1/0/all/0/1">Philip Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Ojalvo_I/0/1/0/all/0/1">Isobel Ojalvo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pierini_M/0/1/0/all/0/1">Maurizio Pierini</a></p>
<p>The high-energy physics community is investigating the potential of deploying
machine-learning-based solutions on Field-Programmable Gate Arrays (FPGAs) to
enhance physics sensitivity while still meeting data processing time
constraints. In this contribution, we introduce a novel end-to-end procedure
that utilizes a machine learning technique called symbolic regression (SR). It
searches the equation space to discover algebraic relations approximating a
dataset. We use PySR (a software to uncover these expressions based on an
evolutionary algorithm) and extend the functionality of hls4ml (a package for
machine learning inference in FPGAs) to support PySR-generated expressions for
resource-constrained production environments. Deep learning models often
optimize the top metric by pinning the network size because the vast
hyperparameter space prevents an extensive search for neural architecture.
Conversely, SR selects a set of models on the Pareto front, which allows for
optimizing the performance-resource trade-off directly. By embedding symbolic
forms, our implementation can dramatically reduce the computational resources
needed to perform critical tasks. We validate our method on a physics
benchmark: the multiclass classification of jets produced in simulated
proton-proton collisions at the CERN Large Hadron Collider. We show that our
approach can approximate a 3-layer neural network using an inference model that
achieves up to a 13-fold decrease in execution time, down to 5 ns, while still
preserving more than 90% approximation accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.07376">DAISM: Digital Approximate In-SRAM Multiplier-based Accelerator for DNN Training and Inference. (arXiv:2305.07376v2 [cs.AR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sonnino_L/0/1/0/all/0/1">Lorenzo Sonnino</a>, <a href="http://arxiv.org/find/cs/1/au:+Shresthamali_S/0/1/0/all/0/1">Shaswot Shresthamali</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondo_M/0/1/0/all/0/1">Masaaki Kondo</a></p>
<p>DNNs are widely used but face significant computational costs due to matrix
multiplications, especially from data movement between the memory and
processing units. One promising approach is therefore Processing-in-Memory as
it greatly reduces this overhead. However, most PIM solutions rely either on
novel memory technologies that have yet to mature or bit-serial computations
that have significant performance overhead and scalability issues. Our work
proposes an in-SRAM digital multiplier, that uses a conventional memory to
perform bit-parallel computations, leveraging multiple wordlines activation. We
then introduce DAISM, an architecture leveraging this multiplier, which
achieves up to two orders of magnitude higher area efficiency compared to the
SOTA counterparts, with competitive energy efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.09820">Machine-Made Media: Monitoring the Mobilization of Machine-Generated Articles on Misinformation and Mainstream News Websites. (arXiv:2305.09820v4 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hanley_H/0/1/0/all/0/1">Hans W. A. Hanley</a>, <a href="http://arxiv.org/find/cs/1/au:+Durumeric_Z/0/1/0/all/0/1">Zakir Durumeric</a></p>
<p>As large language models (LLMs) like ChatGPT have gained traction, an
increasing number of news websites have begun utilizing them to generate
articles. However, not only can these language models produce factually
inaccurate articles on reputable websites but disreputable news sites can
utilize LLMs to mass produce misinformation. To begin to understand this
phenomenon, we present one of the first large-scale studies of the prevalence
of synthetic articles within online news media. To do this, we train a
DeBERTa-based synthetic news detector and classify over 15.90 million articles
from 3,074 misinformation and mainstream news websites. We find that between
January 1, 2022, and May 1, 2023, the relative number of synthetic news
articles increased by 55.4% on mainstream websites while increasing by 457% on
misinformation sites. We find that this increase is largely driven by smaller
less popular websites. Analyzing the impact of the release of ChatGPT using an
interrupted-time-series, we show that while its release resulted in a marked
increase in synthetic articles on small sites as well as misinformation news
websites, there was not a corresponding increase on large mainstream news
websites.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12788">GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs. (arXiv:2305.12788v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Pengcheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Cao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cross_A/0/1/0/all/0/1">Adam Cross</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a></p>
<p>Clinical predictive models often rely on patients' electronic health records
(EHR), but integrating medical knowledge to enhance predictions and
decision-making is challenging. This is because personalized predictions
require personalized knowledge graphs (KGs), which are difficult to generate
from patient EHR data. To address this, we propose \textsc{GraphCare}, an
open-world framework that uses external KGs to improve EHR-based predictions.
Our method extracts knowledge from large language models (LLMs) and external
biomedical KGs to build patient-specific KGs, which are then used to train our
proposed Bi-attention AugmenTed (BAT) graph neural network (GNN) for healthcare
predictions. On two public datasets, MIMIC-III and MIMIC-IV, \textsc{GraphCare}
surpasses baselines in four vital healthcare prediction tasks: mortality,
readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it
boosts AUROC by 17.6\% and 6.6\% for mortality and readmission, and F1-score by
7.9\% and 10.8\% for LOS and drug recommendation, respectively. Notably,
\textsc{GraphCare} demonstrates a substantial edge in scenarios with limited
data availability. Our findings highlight the potential of using external KGs
in healthcare prediction tasks and demonstrate the promise of
\textsc{GraphCare} in generating personalized KGs for promoting personalized
medicine.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13971">Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning. (arXiv:2305.13971v6 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1">Saibo Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1">Martin Josifoski</a>, <a href="http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1">Maxime Peyrard</a>, <a href="http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1">Robert West</a></p>
<p>Despite their impressive performance, large language models (LMs) still
struggle with reliably generating complex output structures when not finetuned
to follow the required output format exactly. To address this issue,
grammar-constrained decoding (GCD) can be used to control the generation of
LMs, guaranteeing that the output follows a given structure. Most existing GCD
methods are, however, limited to specific tasks, such as parsing or code
generation. In this work, we demonstrate that formal grammars can describe the
output space for a much wider range of tasks and argue that GCD can serve as a
unified framework for structured NLP tasks in general. For increased
flexibility, we introduce input-dependent grammars, which allow the grammar to
depend on the input and thus enable the generation of different output
structures for different inputs. We then empirically demonstrate the power and
flexibility of GCD-enhanced LMs on (1) information extraction, (2) entity
disambiguation, and (3) constituency parsing. Our results indicate that
grammar-constrained LMs substantially outperform unconstrained LMs or even beat
task-specific finetuned models. Grammar constraints thus hold great promise for
harnessing off-the-shelf LMs for a wide range of structured NLP tasks,
especially where training data is scarce or finetuning is expensive. Code and
data: https://github.com/epfl-dlab/GCD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.17198">A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning Coordination Problem. (arXiv:2305.17198v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barde_P/0/1/0/all/0/1">Paul Barde</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowrouzezahrai_D/0/1/0/all/0/1">Derek Nowrouzezahrai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Amy Zhang</a></p>
<p>Training multiple agents to coordinate is an essential problem with
applications in robotics, game theory, economics, and social sciences. However,
most existing Multi-Agent Reinforcement Learning (MARL) methods are online and
thus impractical for real-world applications in which collecting new
interactions is costly or dangerous. While these algorithms should leverage
offline data when available, doing so gives rise to what we call the offline
coordination problem. Specifically, we identify and formalize the strategy
agreement (SA) and the strategy fine-tuning (SFT) coordination challenges, two
issues at which current offline MARL algorithms fail. Concretely, we reveal
that the prevalent model-free methods are severely deficient and cannot handle
coordination-intensive offline multi-agent tasks in either toy or MuJoCo
domains. To address this setback, we emphasize the importance of inter-agent
interactions and propose the very first model-based offline MARL method. Our
resulting algorithm, Model-based Offline Multi-Agent Proximal Policy
Optimization (MOMA-PPO) generates synthetic interaction data and enables agents
to converge on a strategy while fine-tuning their policies accordingly. This
simple model-based solution solves the coordination-intensive offline tasks,
significantly outperforming the prevalent model-free methods even under severe
partial observability and with learned world models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18417">Determinantal Point Process Attention Over Grid Cell Code Supports Out of Distribution Generalization. (arXiv:2305.18417v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1">Shanka Subhra Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Frankland_S/0/1/0/all/0/1">Steven Frankland</a>, <a href="http://arxiv.org/find/cs/1/au:+Webb_T/0/1/0/all/0/1">Taylor Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1">Jonathan D. Cohen</a></p>
<p>Deep neural networks have made tremendous gains in emulating human-like
intelligence, and have been used increasingly as ways of understanding how the
brain may solve the complex computational problems on which this relies.
However, these still fall short of, and therefore fail to provide insight into
how the brain supports strong forms of generalization of which humans are
capable. One such case is out-of-distribution (OOD) generalization-successful
performance on test examples that lie outside the distribution of the training
set. Here, we identify properties of processing in the brain that may
contribute to this ability. We describe a two-part algorithm that draws on
specific features of neural computation to achieve OOD generalization, and
provide a proof of concept by evaluating performance on two challenging
cognitive tasks. First we draw on the fact that the mammalian brain represents
metric spaces using grid cell code (e.g., in entorhinal cortex): abstract
representations of relational structure, organized in recurring motifs that
cover the representational space. Second, we propose an attentional mechanism
that operates over the grid cell code using Determinantal Point Process (DPP),
that we call DPP attention (DPP-A) -- a transformation that ensures maximum
sparseness in the coverage of that space. We show that a loss function that
combines standard task-optimized error with DPP-A can exploit the recurring
motifs in the grid cell code, and can be integrated with common architectures
to achieve strong OOD generalization performance on analogy and arithmetic
tasks. This provides both an interpretation of how the grid cell code in the
mammalian brain may contribute to generalization performance, and at the same
time a potential means for improving such capabilities in artificial neural
networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19838">Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization. (arXiv:2305.19838v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bardou_A/0/1/0/all/0/1">Anthony Bardou</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiran_P/0/1/0/all/0/1">Patrick Thiran</a>, <a href="http://arxiv.org/find/cs/1/au:+Begin_T/0/1/0/all/0/1">Thomas Begin</a></p>
<p>Bayesian Optimization (BO) is typically used to optimize an unknown function
$f$ that is noisy and costly to evaluate, by exploiting an acquisition function
that must be maximized at each optimization step. Even if provably
asymptotically optimal BO algorithms are efficient at optimizing
low-dimensional functions, scaling them to high-dimensional spaces remains an
open problem, often tackled by assuming an additive structure for $f$. By doing
so, BO algorithms typically introduce additional restrictive assumptions on the
additive structure that reduce their applicability domain. This paper contains
two main contributions: (i) we relax the restrictive assumptions on the
additive structure of $f$ without weakening the maximization guarantees of the
acquisition function, and (ii) we address the over-exploration problem for
decentralized BO algorithms. To these ends, we propose DuMBO, an asymptotically
optimal decentralized BO algorithm that achieves very competitive performance
against state-of-the-art BO algorithms, especially when the additive structure
of $f$ comprises high-dimensional factors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00323">Thought Cloning: Learning to Think while Acting by Imitating Human Thinking. (arXiv:2306.00323v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengran Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1">Jeff Clune</a></p>
<p>Language is often considered a key aspect of human thinking, providing us
with exceptional abilities to generalize, explore, plan, replan, and adapt to
new situations. However, Reinforcement Learning (RL) agents are far from
human-level performance in any of these abilities. We hypothesize one reason
for such cognitive deficiencies is that they lack the benefits of thinking in
language and that we can improve AI agents by training them to think like
humans do. We introduce a novel Imitation Learning framework, Thought Cloning,
where the idea is to not just clone the behaviors of human demonstrators, but
also the thoughts humans have as they perform these behaviors. While we expect
Thought Cloning to truly shine at scale on internet-sized datasets of humans
thinking out loud while acting (e.g. online videos with transcripts), here we
conduct experiments in a domain where the thinking and action data are
synthetically generated. Results reveal that Thought Cloning learns much faster
than Behavioral Cloning and its performance advantage grows the further out of
distribution test tasks are, highlighting its ability to better handle novel
situations. Thought Cloning also provides important benefits for AI Safety and
Interpretability, and makes it easier to debug and improve AI. Because we can
observe the agent's thoughts, we can (1) more easily diagnose why things are
going wrong, making it easier to fix the problem, (2) steer the agent by
correcting its thinking, or (3) prevent it from doing unsafe things it plans to
do. Overall, by training agents how to think as well as behave, Thought Cloning
creates safer, more powerful agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00788">Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression. (arXiv:2306.00788v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhai_R/0/1/0/all/0/1">Runtian Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bingbin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_Z/0/1/0/all/0/1">Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a></p>
<p>Data augmentation is critical to the empirical success of modern
self-supervised representation learning, such as contrastive learning and
masked language modeling. However, a theoretical understanding of the exact
role of augmentation remains limited. Recent work has built the connection
between self-supervised learning and the approximation of the top eigenspace of
a graph Laplacian operator, suggesting that learning a linear probe atop such
representation can be connected to RKHS regression. Building on this insight,
this work delves into a statistical analysis of augmentation-based pretraining.
Starting from the isometry property, a geometric characterization of the target
function given by the augmentation, we disentangle the effects of the model and
the augmentation, and prove two generalization bounds that are free of model
complexity. Our first bound works for an arbitrary encoder, where the
prediction error is decomposed as the sum of an estimation error incurred by
fitting a linear probe with RKHS regression, and an approximation error
entailed by RKHS approximation. Our second bound specifically addresses the
case where the encoder is near-optimal, that is it approximates the top-d
eigenspace of the RKHS induced by the augmentation. A key ingredient in our
analysis is the augmentation complexity, which we use to quantitatively compare
different augmentations and analyze their impact on downstream performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04961">Recovering Simultaneously Structured Data via Non-Convex Iteratively Reweighted Least Squares. (arXiv:2306.04961v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kummerle_C/0/1/0/all/0/1">Christian K&#xfc;mmerle</a>, <a href="http://arxiv.org/find/cs/1/au:+Maly_J/0/1/0/all/0/1">Johannes Maly</a></p>
<p>We propose a new algorithm for the problem of recovering data that adheres to
multiple, heterogeneous low-dimensional structures from linear observations.
Focusing on data matrices that are simultaneously row-sparse and low-rank, we
propose and analyze an iteratively reweighted least squares (IRLS) algorithm
that is able to leverage both structures. In particular, it optimizes a
combination of non-convex surrogates for row-sparsity and rank, a balancing of
which is built into the algorithm. We prove locally quadratic convergence of
the iterates to a simultaneously structured data matrix in a regime of minimal
sample complexity (up to constants and a logarithmic factor), which is known to
be impossible for a combination of convex surrogates. In experiments, we show
that the IRLS method exhibits favorable empirical convergence, identifying
simultaneously row-sparse and low-rank matrices from fewer measurements than
state-of-the-art methods. Code is available at
https://github.com/ckuemmerle/simirls.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05109">Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML. (arXiv:2306.05109v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Water_R/0/1/0/all/0/1">Robin van de Water</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_H/0/1/0/all/0/1">Hendrik Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Elbers_P/0/1/0/all/0/1">Paul Elbers</a>, <a href="http://arxiv.org/find/cs/1/au:+Thoral_P/0/1/0/all/0/1">Patrick Thoral</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnrich_B/0/1/0/all/0/1">Bert Arnrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Rockenschaub_P/0/1/0/all/0/1">Patrick Rockenschaub</a></p>
<p>Medical applications of machine learning (ML) have experienced a surge in
popularity in recent years. The intensive care unit (ICU) is a natural habitat
for ML given the abundance of available data from electronic health records.
Models have been proposed to address numerous ICU prediction tasks like the
early detection of complications. While authors frequently report
state-of-the-art performance, it is challenging to verify claims of
superiority. Datasets and code are not always published, and cohort
definitions, preprocessing pipelines, and training setups are difficult to
reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular
framework that allows researchers to define reproducible and comparable
clinical ML experiments; we offer an end-to-end solution from cohort definition
to model evaluation. The framework natively supports most open-access ICU
datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future
ICU datasets. Combined with a transparent preprocessing pipeline and extensible
training code for multiple ML and deep learning models, YAIB enables unified
model development. Our benchmark comes with five predefined established
prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and
length of stay) developed in collaboration with clinicians. Adding further
tasks is straightforward by design. Using YAIB, we demonstrate that the choice
of dataset, cohort definition, and preprocessing have a major impact on the
prediction performance - often more so than model class - indicating an urgent
need for YAIB as a holistic benchmarking tool. We provide our work to the
clinical ML community to accelerate method development and enable real-world
clinical implementations. Software Repository:
https://github.com/rvandewater/YAIB.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05535">Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data. (arXiv:2306.05535v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ivanov_P/0/1/0/all/0/1">Petar Ivanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1">Ivan Koychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Hardalov_M/0/1/0/all/0/1">Momchil Hardalov</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1">Preslav Nakov</a></p>
<p>Developing tools to automatically detect check-worthy claims in political
debates and speeches can greatly help moderators of debates, journalists, and
fact-checkers. While previous work on this problem has focused exclusively on
the text modality, here we explore the utility of the audio modality as an
additional input. We create a new multimodal dataset (text and audio in
English) containing 48 hours of speech from past political debates in the USA.
We then experimentally demonstrate that, in the case of multiple speakers,
adding the audio modality yields sizable improvements over using the text
modality alone; moreover, an audio-only model could outperform a text-only one
for a single speaker. With the aim to enable future research, we make all our
data and code publicly available at
https://github.com/petar-iv/audio-checkworthiness-detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02140">Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives. (arXiv:2307.02140v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duan_M/0/1/0/all/0/1">Moming Duan</a></p>
<p>Traditional Federated Learning (FL) follows a server-domincated cooperation
paradigm which narrows the application scenarios of FL and decreases the
enthusiasm of data holders to participate. To fully unleash the potential of
FL, we advocate rethinking the design of current FL frameworks and extending it
to a more generalized concept: Open Federated Learning Platforms. We propose
two reciprocal cooperation frameworks for FL to achieve this: query-based FL
and contract-based FL. In this survey, we conduct a comprehensive review of the
feasibility of constructing an open FL platform from both technical and legal
perspectives. We begin by reviewing the definition of FL and summarizing its
inherent limitations, including server-client coupling, low model reusability,
and non-public. In the query-based FL platform, which is an open model sharing
and reusing platform empowered by the community for model mining, we explore a
wide range of valuable topics, including the availability of up-to-date model
repositories for model querying, legal compliance analysis between different
model licenses, and copyright issues and intellectual property protection in
model reusing. In particular, we introduce a novel taxonomy to streamline the
analysis of model license compatibility in FL studies that involve batch model
reusing methods, including combination, amalgamation, distillation, and
generation. This taxonomy provides a systematic framework for identifying the
corresponding clauses of licenses and facilitates the identification of
potential legal implications and restrictions when reusing models. Through this
survey, we uncover the the current dilemmas faced by FL and advocate for the
development of sustainable open FL platforms. We aim to provide guidance for
establishing such platforms in the future, while identifying potential problems
and challenges that need to be addressed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13275">CTAGE: Curvature-Based Topology-Aware Graph Embedding for Learning Molecular Representations. (arXiv:2307.13275v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1">Zheng Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xian Wei</a></p>
<p>AI-driven drug design relies significantly on predicting molecular
properties, which is a complex task. In current approaches, the most commonly
used feature representations for training deep neural network models are based
on SMILES and molecular graphs. While these methods are concise and efficient,
they have limitations in capturing complex spatial information. Recently,
researchers have recognized the importance of incorporating three-dimensional
information of molecular structures into models. However, capturing spatial
information requires the introduction of additional units in the generator,
bringing additional design and computational costs. Therefore, it is necessary
to develop a method for predicting molecular properties that effectively
combines spatial structural information while maintaining the simplicity and
efficiency of graph neural networks. In this work, we propose an embedding
approach CTAGE, utilizing $k$-hop discrete Ricci curvature to extract
structural insights from molecular graph data. This effectively integrates
spatial structural information while preserving the training complexity of the
network. Experimental results indicate that introducing node curvature
significantly improves the performance of current graph neural network
frameworks, validating that the information from k-hop node curvature
effectively reflects the relationship between molecular structure and function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03686">Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization. (arXiv:2308.03686v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Benton_J/0/1/0/all/0/1">Joe Benton</a>, <a href="http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1">Valentin De Bortoli</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>, <a href="http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1">George Deligiannidis</a></p>
<p>Denoising diffusions are a powerful method to generate approximate samples
from high-dimensional data distributions. Recent results provide polynomial
bounds on their convergence rate, assuming $L^2$-accurate scores. Until now,
the tightest bounds were either superlinear in the data dimension or required
strong smoothness assumptions. We provide the first convergence bounds which
are linear in the data dimension (up to logarithmic factors) assuming only
finite second moments of the data distribution. We show that diffusion models
require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to
approximate an arbitrary distribution on $\mathbb{R}^d$ corrupted with Gaussian
noise of variance $\delta$ to within $\varepsilon^2$ in KL divergence. Our
proof extends the Girsanov-based methods of previous works. We introduce a
refined treatment of the error from discretizing the reverse SDE inspired by
stochastic localization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05021">On Error Propagation of Diffusion Models. (arXiv:2308.05021v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yangming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a></p>
<p>Although diffusion models (DMs) have shown promising performances in a number
of tasks (e.g., speech synthesis and image generation), they might suffer from
error propagation because of their sequential structure. However, this is not
certain because some sequential models, such as Conditional Random Field (CRF),
are free from this problem. To address this issue, we develop a theoretical
framework to mathematically formulate error propagation in the architecture of
DMs, The framework contains three elements, including modular error, cumulative
error, and propagation equation. The modular and cumulative errors are related
by the equation, which interprets that DMs are indeed affected by error
propagation. Our theoretical study also suggests that the cumulative error is
closely related to the generation quality of DMs. Based on this finding, we
apply the cumulative error as a regularization term to reduce error
propagation. Because the term is computationally intractable, we derive its
upper bound and design a bootstrap algorithm to efficiently estimate the bound
for optimization. We have conducted extensive experiments on multiple image
datasets, showing that our proposed regularization reduces error propagation,
significantly improves vanilla DMs, and outperforms previous baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.08469">LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters. (arXiv:2308.08469v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Ching Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei-Yao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wen-Chih Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tien-Fu Chen</a></p>
<p>Multivariate time-series forecasting is vital in various domains, e.g.,
economic planning and weather prediction. Deep train-from-scratch models have
exhibited effective performance yet require large amounts of data, which limits
real-world applicability. Recently, researchers have leveraged the
representation learning transferability of pre-trained Large Language Models
(LLMs) to handle limited non-linguistic datasets effectively. However,
incorporating LLMs with time-series data presents challenges of limited
adaptation due to different compositions between time-series and linguistic
data, and the inability to process multi-scale temporal information. To tackle
these challenges, we propose LLM4TS, a framework for time-series forecasting
with pre-trained LLMs. LLM4TS consists of a two-stage fine-tuning strategy: the
\textit{time-series alignment} stage to align LLMs with the nuances of
time-series data, and the \textit{forecasting fine-tuning} stage for downstream
time-series forecasting tasks. Furthermore, our framework features a novel
two-level aggregation method that integrates multi-scale temporal data within
pre-trained LLMs, enhancing their ability to interpret time-specific
information. In experiments across 7 time-series forecasting datasets, LLM4TS
is superior to existing state-of-the-art methods compared with
trained-from-scratch models in full-shot scenarios, and also achieves an
average improvement of 6.84% in MSE in few-shot scenarios. In addition,
evaluations compared with different self-supervised learning approaches
highlight LLM4TS's effectiveness with representation learning in forecasting
tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10462">Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models. (arXiv:2308.10462v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weyssow_M/0/1/0/all/0/1">Martin Weyssow</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kisub Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1">David Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahraoui_H/0/1/0/all/0/1">Houari Sahraoui</a></p>
<p>Large Language Models (LLMs) demonstrate impressive capabilities to generate
accurate code snippets given natural language intents in zero-shot, i.e.,
without the need for specific fine-tuning. While prior studies have highlighted
the advantages of fine-tuning LLMs, this process incurs high computational
costs, making it impractical in resource-scarce environments, particularly for
models with billions of parameters. To address these challenges, previous
research explored In-Context Learning (ICL) as a strategy to guide the LLM
generative process with task-specific prompt examples. However, ICL introduces
inconveniences, such as the need for designing contextually relevant prompts
and the absence of learning task-specific parameters, thereby limiting
downstream task performance. In this context, we foresee Parameter-Efficient
Fine-Tuning (PEFT) techniques as a promising approach to efficiently specialize
LLMs to task-specific data while maintaining reasonable resource consumption.
In this paper, we deliver a comprehensive study of PEFT techniques for LLMs
under the automated code generation scenario. Our comprehensive investigation
of PEFT techniques for LLMs reveals their superiority and potential over ICL
across a diverse set of LLMs. Additionally, we demonstrate the extended
capabilities of PEFT, showcasing its ability to learn from two distinct
datasets jointly without compromising performance. Furthermore, our study
highlights the potential for tuning larger LLMs and significant reductions in
memory usage by combining PEFT with quantization. Therefore, this study opens
opportunities for broader applications of PEFT in software engineering
scenarios. Our code is available at
https://github.com/martin-wey/peft-llm-code/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12952">BridgeData V2: A Dataset for Robot Learning at Scale. (arXiv:2308.12952v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Walke_H/0/1/0/all/0/1">Homer Walke</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_K/0/1/0/all/0/1">Kevin Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1">Abraham Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Moo Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Max Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chongyi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tony Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_Estruch_P/0/1/0/all/0/1">Philippe Hansen-Estruch</a>, <a href="http://arxiv.org/find/cs/1/au:+Vuong_Q/0/1/0/all/0/1">Quan Vuong</a>, <a href="http://arxiv.org/find/cs/1/au:+He_A/0/1/0/all/0/1">Andre He</a>, <a href="http://arxiv.org/find/cs/1/au:+Myers_V/0/1/0/all/0/1">Vivek Myers</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_K/0/1/0/all/0/1">Kuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a></p>
<p>We introduce BridgeData V2, a large and diverse dataset of robotic
manipulation behaviors designed to facilitate research on scalable robot
learning. BridgeData V2 contains 60,096 trajectories collected across 24
environments on a publicly available low-cost robot. BridgeData V2 provides
extensive task and environment variability, leading to skills that can
generalize across environments, domains, and institutions, making the dataset a
useful resource for a broad range of researchers. Additionally, the dataset is
compatible with a wide variety of open-vocabulary, multi-task learning methods
conditioned on goal images or natural language instructions. In our
experiments, we train 6 state-of-the-art imitation learning and offline
reinforcement learning methods on our dataset, and find that they succeed on a
suite of tasks requiring varying amounts of generalization. We also demonstrate
that the performance of these methods improves with more data and higher
capacity models, and that training on a greater variety of skills leads to
improved generalization. By publicly sharing BridgeData V2 and our pre-trained
models, we aim to accelerate research in scalable robot learning methods.
Project page at https://rail-berkeley.github.io/bridgedata
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03708">Chat Failures and Troubles: Reasons and Solutions. (arXiv:2309.03708v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Helal_M/0/1/0/all/0/1">Manal Helal</a>, <a href="http://arxiv.org/find/cs/1/au:+Holthaus_P/0/1/0/all/0/1">Patrick Holthaus</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakatos_G/0/1/0/all/0/1">Gabriella Lakatos</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirabdollahian_F/0/1/0/all/0/1">Farshid Amirabdollahian</a></p>
<p>This paper examines some common problems in Human-Robot Interaction (HRI)
causing failures and troubles in Chat. A given use case's design decisions
start with the suitable robot, the suitable chatting model, identifying common
problems that cause failures, identifying potential solutions, and planning
continuous improvement. In conclusion, it is recommended to use a closed-loop
control algorithm that guides the use of trained Artificial Intelligence (AI)
pre-trained models and provides vocabulary filtering, re-train batched models
on new datasets, learn online from data streams, and/or use reinforcement
learning models to self-update the trained models and reduce errors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07778">Virchow: A Million-Slide Digital Pathology Foundation Model. (arXiv:2309.07778v5 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/eess/1/au:+Bozkurt_A/0/1/0/all/0/1">Alican Bozkurt</a>, <a href="http://arxiv.org/find/eess/1/au:+Casson_A/0/1/0/all/0/1">Adam Casson</a>, <a href="http://arxiv.org/find/eess/1/au:+Shaikovski_G/0/1/0/all/0/1">George Shaikovski</a>, <a href="http://arxiv.org/find/eess/1/au:+Zelechowski_M/0/1/0/all/0/1">Michal Zelechowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1">Siqi Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Severson_K/0/1/0/all/0/1">Kristen Severson</a>, <a href="http://arxiv.org/find/eess/1/au:+Zimmermann_E/0/1/0/all/0/1">Eric Zimmermann</a>, <a href="http://arxiv.org/find/eess/1/au:+Hall_J/0/1/0/all/0/1">James Hall</a>, <a href="http://arxiv.org/find/eess/1/au:+Tenenholtz_N/0/1/0/all/0/1">Neil Tenenholtz</a>, <a href="http://arxiv.org/find/eess/1/au:+Fusi_N/0/1/0/all/0/1">Nicolo Fusi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mathieu_P/0/1/0/all/0/1">Philippe Mathieu</a>, <a href="http://arxiv.org/find/eess/1/au:+Eck_A/0/1/0/all/0/1">Alexander van Eck</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1">Donghun Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Viret_J/0/1/0/all/0/1">Julian Viret</a>, <a href="http://arxiv.org/find/eess/1/au:+Robert_E/0/1/0/all/0/1">Eric Robert</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yi Kan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Kunz_J/0/1/0/all/0/1">Jeremy D. Kunz</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_M/0/1/0/all/0/1">Matthew C. H. Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Bernhard_J/0/1/0/all/0/1">Jan Bernhard</a>, <a href="http://arxiv.org/find/eess/1/au:+Godrich_R/0/1/0/all/0/1">Ran A. Godrich</a>, <a href="http://arxiv.org/find/eess/1/au:+Oakley_G/0/1/0/all/0/1">Gerard Oakley</a>, <a href="http://arxiv.org/find/eess/1/au:+Millar_E/0/1/0/all/0/1">Ewan Millar</a>, <a href="http://arxiv.org/find/eess/1/au:+Hanna_M/0/1/0/all/0/1">Matthew Hanna</a>, <a href="http://arxiv.org/find/eess/1/au:+Retamero_J/0/1/0/all/0/1">Juan Retamero</a>, <a href="http://arxiv.org/find/eess/1/au:+Moye_W/0/1/0/all/0/1">William A. Moye</a>, <a href="http://arxiv.org/find/eess/1/au:+Yousfi_R/0/1/0/all/0/1">Razik Yousfi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kanan_C/0/1/0/all/0/1">Christopher Kanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Klimstra_D/0/1/0/all/0/1">David Klimstra</a>, <a href="http://arxiv.org/find/eess/1/au:+Rothrock_B/0/1/0/all/0/1">Brandon Rothrock</a>, <a href="http://arxiv.org/find/eess/1/au:+Fuchs_T/0/1/0/all/0/1">Thomas J. Fuchs</a></p>
<p>The use of artificial intelligence to enable precision medicine and decision
support systems through the analysis of pathology images has the potential to
revolutionize the diagnosis and treatment of cancer. Such applications will
depend on models' abilities to capture the diverse patterns observed in
pathology images. To address this challenge, we present Virchow, a foundation
model for computational pathology. Using self-supervised learning empowered by
the DINOv2 algorithm, Virchow is a vision transformer model with 632 million
parameters trained on 1.5 million hematoxylin and eosin stained whole slide
images from diverse tissue and specimen types, which is orders of magnitude
more data than previous works. The Virchow model enables the development of a
pan-cancer detection system with 0.949 overall specimen-level AUC across 17
different cancer types, while also achieving 0.937 AUC on 7 rare cancer types.
The Virchow model sets the state-of-the-art on the internal and external image
tile level benchmarks and slide level biomarker prediction tasks. The gains in
performance highlight the importance of training on massive pathology image
datasets, suggesting scaling up the data and network architecture can improve
the accuracy for many high-impact computational pathology applications where
limited amounts of training data are available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12971">Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes. (arXiv:2309.12971v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yujie Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Linyuan L&#xfc;</a></p>
<p>Despite the recent successes of vanilla Graph Neural Networks (GNNs) on
various tasks, their foundation on pairwise networks inherently limits their
capacity to discern latent higher-order interactions in complex systems. To
bridge this capability gap, we propose a novel approach exploiting the rich
mathematical theory of simplicial complexes (SCs) - a robust tool for modeling
higher-order interactions. Current SC-based GNNs are burdened by high
complexity and rigidity, and quantifying higher-order interaction strengths
remains challenging. Innovatively, we present a higher-order Flower-Petals (FP)
model, incorporating FP Laplacians into SCs. Further, we introduce a
Higher-order Graph Convolutional Network (HiGCN) grounded in FP Laplacians,
capable of discerning intrinsic features across varying topological scales. By
employing learnable graph filters, a parameter group within each FP Laplacian
domain, we can identify diverse patterns where the filters' weights serve as a
quantifiable measure of higher-order interaction strengths. The theoretical
underpinnings of HiGCN's advanced expressiveness are rigorously demonstrated.
Additionally, our empirical investigations reveal that the proposed model
accomplishes state-of-the-art performance on a range of graph tasks and
provides a scalable and flexible solution to explore higher-order interactions
in graphs. Codes and datasets are available at
https://github.com/Yiminghh/HiGCN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.14068">Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models. (arXiv:2309.14068v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yangming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Breugel_B/0/1/0/all/0/1">Boris van Breugel</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a></p>
<p>Because diffusion models have shown impressive performances in a number of
tasks, such as image synthesis, there is a trend in recent works to prove (with
certain assumptions) that these models have strong approximation capabilities.
In this paper, we show that current diffusion models actually have an
expressive bottleneck in backward denoising and some assumption made by
existing theoretical guarantees is too strong. Based on this finding, we prove
that diffusion models have unbounded errors in both local and global denoising.
In light of our theoretical studies, we introduce soft mixture denoising (SMD),
an expressive and efficient model for backward denoising. SMD not only permits
diffusion models to well approximate any Gaussian mixture distributions in
theory, but also is simple and efficient for implementation. Our experiments on
multiple image datasets show that SMD significantly improves different types of
diffusion models (e.g., DDPM), espeically in the situation of few backward
iterations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.15188">ICML 2023 Topological Deep Learning Challenge : Design and Results. (arXiv:2309.15188v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Papillon_M/0/1/0/all/0/1">Mathilde Papillon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1">Mustafa Hajij</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenne_H/0/1/0/all/0/1">Helen Jenne</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathe_J/0/1/0/all/0/1">Johan Mathe</a>, <a href="http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1">Audun Myers</a>, <a href="http://arxiv.org/find/cs/1/au:+Papamarkou_T/0/1/0/all/0/1">Theodore Papamarkou</a>, <a href="http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1">Tolga Birdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1">Tamal Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Doster_T/0/1/0/all/0/1">Tim Doster</a>, <a href="http://arxiv.org/find/cs/1/au:+Emerson_T/0/1/0/all/0/1">Tegan Emerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalakrishnan_G/0/1/0/all/0/1">Gurusankar Gopalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Govil_D/0/1/0/all/0/1">Devendra Govil</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzman_Saenz_A/0/1/0/all/0/1">Aldo Guzm&#xe1;n-S&#xe1;enz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1">Henry Kvinge</a>, <a href="http://arxiv.org/find/cs/1/au:+Livesay_N/0/1/0/all/0/1">Neal Livesay</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Soham Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaga_S/0/1/0/all/0/1">Shreyas N. Samaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramamurthy_K/0/1/0/all/0/1">Karthikeyan Natesan Ramamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Karri_M/0/1/0/all/0/1">Maneel Reddy Karri</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosen_P/0/1/0/all/0/1">Paul Rosen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanborn_S/0/1/0/all/0/1">Sophia Sanborn</a>, <a href="http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1">Robin Walters</a>, <a href="http://arxiv.org/find/cs/1/au:+Agerberg_J/0/1/0/all/0/1">Jens Agerberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Barikbin_S/0/1/0/all/0/1">Sadrodin Barikbin</a>, <a href="http://arxiv.org/find/cs/1/au:+Battiloro_C/0/1/0/all/0/1">Claudio Battiloro</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazhenov_G/0/1/0/all/0/1">Gleb Bazhenov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernardez_G/0/1/0/all/0/1">Guillermo Bernardez</a>, <a href="http://arxiv.org/find/cs/1/au:+Brent_A/0/1/0/all/0/1">Aiden Brent</a>, <a href="http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1">Sergio Escalera</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiorellino_S/0/1/0/all/0/1">Simone Fiorellino</a>, <a href="http://arxiv.org/find/cs/1/au:+Gavrilev_D/0/1/0/all/0/1">Dmitrii Gavrilev</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassanin_M/0/1/0/all/0/1">Mohammed Hassanin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hausner_P/0/1/0/all/0/1">Paul H&#xe4;usner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardaa_O/0/1/0/all/0/1">Odin Hoff Gardaa</a>, <a href="http://arxiv.org/find/cs/1/au:+Khamis_A/0/1/0/all/0/1">Abdelwahed Khamis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lecha_M/0/1/0/all/0/1">Manuel Lecha</a>, <a href="http://arxiv.org/find/cs/1/au:+Magai_G/0/1/0/all/0/1">German Magai</a>, <a href="http://arxiv.org/find/cs/1/au:+Malygina_T/0/1/0/all/0/1">Tatiana Malygina</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballester_R/0/1/0/all/0/1">Rub&#xe9;n Ballester</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadimpalli_K/0/1/0/all/0/1">Kalyan Nadimpalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikitin_A/0/1/0/all/0/1">Alexander Nikitin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabinowitz_A/0/1/0/all/0/1">Abraham Rabinowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Salatiello_A/0/1/0/all/0/1">Alessandro Salatiello</a>, <a href="http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1">Simone Scardapane</a>, <a href="http://arxiv.org/find/cs/1/au:+Scofano_L/0/1/0/all/0/1">Luca Scofano</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Suraj Singh</a>, et al. (10 additional authors not shown)</p>
<p>This paper presents the computational challenge on topological deep learning
that was hosted within the ICML 2023 Workshop on Topology and Geometry in
Machine Learning. The competition asked participants to provide open-source
implementations of topological neural networks from the literature by
contributing to the python packages TopoNetX (data processing) and TopoModelX
(deep learning). The challenge attracted twenty-eight qualifying submissions in
its two-month duration. This paper describes the design of the challenge and
summarizes its main findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.16316">Astroconformer: The Prospects of Analyzing Stellar Light Curves with Transformer-Based Deep Learning Models. (arXiv:2309.16316v2 [astro-ph.SR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Pan_J/0/1/0/all/0/1">Jia-Shu Pan</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1">Yuan-Sen Ting</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Yu_J/0/1/0/all/0/1">Jie Yu</a></p>
<p>Stellar light curves contain valuable information about oscillations and
granulation, offering insights into stars' internal structures and evolutionary
states. Traditional asteroseismic techniques, primarily focused on power
spectral analysis, often overlook the crucial phase information in these light
curves. Addressing this gap, recent machine learning applications, particularly
those using Convolutional Neural Networks (CNNs), have made strides in
inferring stellar properties from light curves. However, CNNs are limited by
their localized feature extraction capabilities. In response, we introduce
$\textit{Astroconformer}$, a Transformer-based deep learning framework,
specifically designed to capture long-range dependencies in stellar light
curves. Our empirical analysis centers on estimating surface gravity ($\log
g$), using a dataset derived from single-quarter Kepler light curves with $\log
g$ values ranging from 0.2 to 4.4. $\textit{Astroconformer}$ demonstrates
superior performance, achieving a root-mean-square-error (RMSE) of 0.017 dex at
$\log g\approx3$ in data-rich regimes and up to 0.1 dex in sparser areas. This
performance surpasses both K-nearest neighbor models and advanced CNNs.
Ablation studies highlight the influence of receptive field size on model
effectiveness, with larger fields correlating to improved results.
$\textit{Astroconformer}$ also excels in extracting $\nu_{\max}$ with high
precision. It achieves less than 2% relative median absolute error for 90-day
red giant light curves. Notably, the error remains under 3% for 30-day light
curves, whose oscillations are undetectable by a conventional pipeline in 30%
cases. Furthermore, the attention mechanisms in $\textit{Astroconformer}$ align
closely with the characteristics of stellar oscillations and granulation
observed in light curves.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.16467">Compositional Program Generation for Few-Shot Systematic Generalization. (arXiv:2309.16467v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Klinger_T/0/1/0/all/0/1">Tim Klinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Luke Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1">Soham Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1">Maxwell Crouse</a>, <a href="http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1">Parikshit Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1">Alexander Gray</a></p>
<p>Compositional generalization is a key ability of humans that enables us to
learn new concepts from only a handful examples. Neural machine learning
models, including the now ubiquitous Transformers, struggle to generalize in
this way, and typically require thousands of examples of a concept during
training in order to generalize meaningfully. This difference in ability
between humans and artificial neural architectures, motivates this study on a
neuro-symbolic architecture called the Compositional Program Generator (CPG).
CPG has three key features: \textit{modularity}, \textit{composition}, and
\textit{abstraction}, in the form of grammar rules, that enable it to
generalize both systematically to new concepts in a few-shot manner, as well as
productively by length on various sequence-to-sequence language tasks. For each
input, CPG uses a grammar of the input language and a parser to generate a
parse in which each grammar rule is assigned its own unique semantic module, a
probabilistic copy or substitution program. Instances with the same parse are
always processed with the same composed modules, while those with different
parses may be processed with different modules. CPG learns parameters for the
modules and is able to learn the semantics for new rules and types
incrementally, without forgetting or retraining on rules it's already seen. It
achieves perfect generalization on both the SCAN and COGS benchmarks using just
14 examples for SCAN and 22 examples for COGS -- state-of-the-art accuracy with
a 1000x improvement in sample efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.17366">3D-Mol: A Novel Contrastive Learning Framework for Molecular Property Prediction with 3D Information. (arXiv:2309.17366v2 [q-bio.BM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Kuang_T/0/1/0/all/0/1">Taojie Kuang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1">Yiming Ren</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ren_Z/0/1/0/all/0/1">Zhixiang Ren</a></p>
<p>Molecular property prediction, crucial for early drug candidate screening and
optimization, has seen advancements with deep learning-based methods. While
deep learning-based methods have advanced considerably, they often fall short
in fully leveraging 3D spatial information. Specifically, current molecular
encoding techniques tend to inadequately extract spatial information, leading
to ambiguous representations where a single one might represent multiple
distinct molecules. Moreover, existing molecular modeling methods focus
predominantly on the most stable 3D conformations, neglecting other viable
conformations present in reality. To address these issues, we propose 3D-Mol, a
novel approach designed for more accurate spatial structure representation. It
deconstructs molecules into three hierarchical graphs to better extract
geometric information. Additionally, 3D-Mol leverages contrastive learning for
pretraining on 20 million unlabeled data, treating their conformations with
identical topological structures as weighted positive pairs and contrasting
ones as negatives, based on the similarity of their 3D conformation descriptors
and fingerprints. We compare 3D-Mol with various state-of-the-art baselines on
7 benchmarks and demonstrate our outstanding performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08744">Circuit Component Reuse Across Tasks in Transformer Language Models. (arXiv:2310.08744v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Merullo_J/0/1/0/all/0/1">Jack Merullo</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1">Ellie Pavlick</a></p>
<p>Recent work in mechanistic interpretability has shown that behaviors in
language models can be successfully reverse-engineered through circuit
analysis. A common criticism, however, is that each circuit is task-specific,
and thus such analysis cannot contribute to understanding the models at a
higher level. In this work, we present evidence that insights (both low-level
findings about specific heads and higher-level findings about general
algorithms) can indeed generalize across tasks. Specifically, we study the
circuit discovered in Wang et al. (2022) for the Indirect Object Identification
(IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that
it is mostly reused to solve a seemingly different task: Colored Objects
(Ippolito &amp; Callison-Burch, 2023). We provide evidence that the process
underlying both tasks is functionally very similar, and contains about a 78%
overlap in in-circuit attention heads. We further present a proof-of-concept
intervention experiment, in which we adjust four attention heads in middle
layers in order to 'repair' the Colored Objects circuit and make it behave like
the IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the
Colored Objects task and explain most sources of error. The intervention
affects downstream attention heads in specific ways predicted by their
interactions in the IOI circuit, indicating that this subcircuit behavior is
invariant to the different task inputs. Overall, our results provide evidence
that it may yet be possible to explain large language models' behavior in terms
of a relatively small number of interpretable task-general algorithmic building
blocks and computational components.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12086">FactCHD: Benchmarking Fact-Conflicting Hallucination Detection. (arXiv:2310.12086v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Duanzheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_H/0/1/0/all/0/1">Honghao Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenxi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yong_J/0/1/0/all/0/1">Jiang Yong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1">Chengfei Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a></p>
<p>Despite their impressive generative capabilities, LLMs are hindered by
fact-conflicting hallucinations in real-world applications. The accurate
identification of hallucinations in texts generated by LLMs, especially in
complex inferential scenarios, is a relatively unexplored area. To address this
gap, we present FactCHD, a dedicated benchmark designed for the detection of
fact-conflicting hallucinations from LLMs. FactCHD features a diverse dataset
that spans various factuality patterns, including vanilla, multi-hop,
comparison, and set operation. A distinctive element of FactCHD is its
integration of fact-based evidence chains, significantly enhancing the depth of
evaluating the detectors' explanations. Experiments on different LLMs expose
the shortcomings of current approaches in detecting factual errors accurately.
Furthermore, we introduce Truth-Triangulator that synthesizes reflective
considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming
to yield more credible detection through the amalgamation of predictive results
and evidence. The benchmark dataset is available at
https://github.com/zjunlp/FactCHD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.13897">Masked Hard-Attention Transformers and Boolean RASP Recognize Exactly the Star-Free Languages. (arXiv:2310.13897v2 [cs.FL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Angluin_D/0/1/0/all/0/1">Dana Angluin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1">David Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Andy Yang</a></p>
<p>We consider transformer encoders with hard attention (in which all attention
is focused on exactly one position) and strict future masking (in which each
position only attends to positions strictly to its left), and prove that the
class of languages recognized by these networks is exactly the star-free
languages. Adding position embeddings increases the class of recognized
languages to other well-studied classes. A key technique in these proofs is
Boolean RASP, a variant of RASP that is restricted to Boolean values. Via the
star-free languages, we relate transformers to first-order logic, temporal
logic, and algebraic automata theory.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15141">SpecTr: Fast Speculative Decoding via Optimal Transport. (arXiv:2310.15141v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Ziteng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1">Ananda Theertha Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ro_J/0/1/0/all/0/1">Jae Hun Ro</a>, <a href="http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1">Ahmad Beirami</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_H/0/1/0/all/0/1">Himanshu Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Felix Yu</a></p>
<p>Autoregressive sampling from large language models has led to
state-of-the-art results in several natural language tasks. However,
autoregressive sampling generates tokens one at a time making it slow, and even
prohibitive in certain tasks. One way to speed up sampling is
$\textit{speculative decoding}$: use a small model to sample a $\textit{draft}$
(block or sequence of tokens), and then score all tokens in the draft by the
large language model in parallel. A subset of the tokens in the draft are
accepted (and the rest rejected) based on a statistical method to guarantee
that the final output follows the distribution of the large model. In this
work, we provide a principled understanding of speculative decoding through the
lens of optimal transport (OT) with $\textit{membership cost}$. This framework
can be viewed as an extension of the well-known $\textit{maximal-coupling}$
problem. This new formulation enables us to generalize the speculative decoding
method to allow for a set of $k$ candidates at the token-level, which leads to
an improved optimal membership cost. We show that the optimal draft selection
algorithm (transport plan) can be computed via linear programming, whose
best-known runtime is exponential in $k$. We then propose a valid draft
selection algorithm whose acceptance probability is $(1-1/e)$-optimal
multiplicatively. Moreover, it can be computed in time almost linear with size
of domain of a single token. Using this $new draft selection$ algorithm, we
develop a new autoregressive sampling algorithm called $\textit{SpecTr}$, which
provides speedup in decoding while ensuring that there is no quality
degradation in the decoded output. We experimentally demonstrate that for
state-of-the-art large language models, the proposed approach achieves a wall
clock speedup of 2.13X, a further 1.37X speedup over speculative decoding on
standard benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19776">Learn to Categorize or Categorize to Learn? Self-Coding for Generalized Category Discovery. (arXiv:2310.19776v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rastegar_S/0/1/0/all/0/1">Sarah Rastegar</a>, <a href="http://arxiv.org/find/cs/1/au:+Doughty_H/0/1/0/all/0/1">Hazel Doughty</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G. M. Snoek</a></p>
<p>In the quest for unveiling novel categories at test time, we confront the
inherent limitations of traditional supervised recognition models that are
restricted by a predefined category set. While strides have been made in the
realms of self-supervised and open-world learning towards test-time category
discovery, a crucial yet often overlooked question persists: what exactly
delineates a category? In this paper, we conceptualize a category through the
lens of optimization, viewing it as an optimal solution to a well-defined
problem. Harnessing this unique conceptualization, we propose a novel,
efficient and self-supervised method capable of discovering previously unknown
categories at test time. A salient feature of our approach is the assignment of
minimum length category codes to individual data instances, which encapsulates
the implicit category hierarchy prevalent in real-world datasets. This
mechanism affords us enhanced control over category granularity, thereby
equipping our model to handle fine-grained categories adeptly. Experimental
evaluations, bolstered by state-of-the-art benchmark comparisons, testify to
the efficacy of our solution in managing unknown categories at test time.
Furthermore, we fortify our proposition with a theoretical foundation,
providing proof of its optimality. Our code is available at
https://github.com/SarahRastegar/InfoSieve.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.20496">BasisFormer: Attention-based Time Series Forecasting with Learnable and Interpretable Basis. (arXiv:2310.20496v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1">Zelin Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shizhan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Weiyao Lin</a></p>
<p>Bases have become an integral part of modern deep learning-based models for
time series forecasting due to their ability to act as feature extractors or
future references. To be effective, a basis must be tailored to the specific
set of time series data and exhibit distinct correlation with each time series
within the set. However, current state-of-the-art methods are limited in their
ability to satisfy both of these requirements simultaneously. To address this
challenge, we propose BasisFormer, an end-to-end time series forecasting
architecture that leverages learnable and interpretable bases. This
architecture comprises three components: First, we acquire bases through
adaptive self-supervised learning, which treats the historical and future
sections of the time series as two distinct views and employs contrastive
learning. Next, we design a Coef module that calculates the similarity
coefficients between the time series and bases in the historical view via
bidirectional cross-attention. Finally, we present a Forecast module that
selects and consolidates the bases in the future view based on the similarity
coefficients, resulting in accurate future predictions. Through extensive
experiments on six datasets, we demonstrate that BasisFormer outperforms
previous state-of-the-art methods by 11.04\% and 15.78\% respectively for
univariate and multivariate forecasting tasks. Code is available at:
\url{https://github.com/nzl5116190/Basisformer}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.20708">Unexpected Improvements to Expected Improvement for Bayesian Optimization. (arXiv:2310.20708v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ament_S/0/1/0/all/0/1">Sebastian Ament</a>, <a href="http://arxiv.org/find/cs/1/au:+Daulton_S/0/1/0/all/0/1">Samuel Daulton</a>, <a href="http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1">David Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Balandat_M/0/1/0/all/0/1">Maximilian Balandat</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakshy_E/0/1/0/all/0/1">Eytan Bakshy</a></p>
<p>Expected Improvement (EI) is arguably the most popular acquisition function
in Bayesian optimization and has found countless successful applications, but
its performance is often exceeded by that of more recent methods. Notably, EI
and its variants, including for the parallel and multi-objective settings, are
challenging to optimize because their acquisition values vanish numerically in
many regions. This difficulty generally increases as the number of
observations, dimensionality of the search space, or the number of constraints
grow, resulting in performance that is inconsistent across the literature and
most often sub-optimal. Herein, we propose LogEI, a new family of acquisition
functions whose members either have identical or approximately equal optima as
their canonical counterparts, but are substantially easier to optimize
numerically. We demonstrate that numerical pathologies manifest themselves in
"classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well as
their constrained, noisy, and parallel variants, and propose corresponding
reformulations that remedy these pathologies. Our empirical results show that
members of the LogEI family of acquisition functions substantially improve on
the optimization performance of their canonical counterparts and surprisingly,
are on par with or exceed the performance of recent state-of-the-art
acquisition functions, highlighting the understated role of numerical
optimization in the literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00964">On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications. (arXiv:2311.00964v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1">Chengyao Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yin Lou</a></p>
<p>Rules are widely used in Fintech institutions to make fraud prevention
decisions, since rules are highly interpretable thanks to their intuitive
if-then structure. In practice, a two-stage framework of fraud prevention
decision rule set mining is usually employed in large Fintech institutions.
This paper is concerned with finding high-quality rule subsets in a
bi-objective space (such as precision and recall) from an initial pool of
rules. To this end, we adopt the concept of Pareto optimality and aim to find a
set of non-dominated rule subsets, which constitutes a Pareto front. We propose
a heuristic-based framework called PORS and we identify that the core of PORS
is the problem of solution selection on the front (SSF). We provide a
systematic categorization of the SSF problem and a thorough empirical
evaluation of various SSF methods on both public and proprietary datasets. We
also introduce a novel variant of sequential covering algorithm called
SpectralRules to encourage the diversity of the initial rule set and we
empirically find that SpectralRules further improves the quality of the found
Pareto front. On two real application scenarios within Alipay, we demonstrate
the advantages of our proposed methodology compared to existing work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01356">Upper and lower bounds for the Lipschitz constant of random neural networks. (arXiv:2311.01356v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Geuchen_P/0/1/0/all/0/1">Paul Geuchen</a>, <a href="http://arxiv.org/find/stat/1/au:+Heindl_T/0/1/0/all/0/1">Thomas Heindl</a>, <a href="http://arxiv.org/find/stat/1/au:+Stoger_D/0/1/0/all/0/1">Dominik St&#xf6;ger</a>, <a href="http://arxiv.org/find/stat/1/au:+Voigtlaender_F/0/1/0/all/0/1">Felix Voigtlaender</a></p>
<p>Empirical studies have widely demonstrated that neural networks are highly
sensitive to small, adversarial perturbations of the input. The worst-case
robustness against these so-called adversarial examples can be quantified by
the Lipschitz constant of the neural network. In this paper, we study upper and
lower bounds for the Lipschitz constant of random ReLU neural networks.
Specifically, we assume that the weights and biases follow a generalization of
the He initialization, where general symmetric distributions for the biases are
permitted. For shallow neural networks, we characterize the Lipschitz constant
up to an absolute numerical constant. For deep networks with fixed depth and
sufficiently large width, our established upper bound is larger than the lower
bound by a factor that is logarithmic in the width.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.04938">Improved DDIM Sampling with Moment Matching Gaussian Mixtures. (arXiv:2311.04938v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gabbur_P/0/1/0/all/0/1">Prasad Gabbur</a></p>
<p>We propose using a Gaussian Mixture Model (GMM) as reverse transition
operator (kernel) within the Denoising Diffusion Implicit Models (DDIM)
framework, which is one of the most widely used approaches for accelerated
sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).
Specifically we match the first and second order central moments of the DDPM
forward marginals by constraining the parameters of the GMM. We see that moment
matching is sufficient to obtain samples with equal or better quality than the
original DDIM with Gaussian kernels. We provide experimental results with
unconditional models trained on CelebAHQ and FFHQ and class-conditional models
trained on ImageNet datasets respectively. Our results suggest that using the
GMM kernel leads to significant improvements in the quality of the generated
samples when the number of sampling steps is small, as measured by FID and IS
metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a
FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73
respectively with a Gaussian kernel.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05081">Generalized test utilities for long-tail performance in extreme multi-label classification. (arXiv:2311.05081v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schultheis_E/0/1/0/all/0/1">Erik Schultheis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wydmuch_M/0/1/0/all/0/1">Marek Wydmuch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotlowski_W/0/1/0/all/0/1">Wojciech Kot&#x142;owski</a>, <a href="http://arxiv.org/find/cs/1/au:+Babbar_R/0/1/0/all/0/1">Rohit Babbar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dembczynski_K/0/1/0/all/0/1">Krzysztof Dembczy&#x144;ski</a></p>
<p>Extreme multi-label classification (XMLC) is the task of selecting a small
subset of relevant labels from a very large set of possible labels. As such, it
is characterized by long-tail labels, i.e., most labels have very few positive
instances. With standard performance measures such as precision@k, a classifier
can ignore tail labels and still report good performance. However, it is often
argued that correct predictions in the tail are more "interesting" or
"rewarding," but the community has not yet settled on a metric capturing this
intuitive concept. The existing propensity-scored metrics fall short on this
goal by confounding the problems of long-tail and missing labels. In this
paper, we analyze generalized metrics budgeted "at k" as an alternative
solution. To tackle the challenging problem of optimizing these metrics, we
formulate it in the expected test utility (ETU) framework, which aims to
optimize the expected performance on a fixed test set. We derive optimal
prediction rules and construct computationally efficient approximations with
provable regret guarantees and robustness against model misspecification. Our
algorithm, based on block coordinate ascent, scales effortlessly to XMLC
problems and obtains promising results in terms of long-tail performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07202">Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control. (arXiv:2311.07202v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zihao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhe Wu</a></p>
<p>Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive
Control (MPC) successfully attains globally optimal solutions by upholding
convexity within the MPC framework. However, current ICNN architectures
encounter the issue of vanishing/exploding gradients, which limits their
ability to serve as deep neural networks for complex tasks. Additionally, the
current neural network-based MPC, including conventional neural network-based
MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC
based on first-principles models. In this study, we leverage the principles of
ICNNs to propose a novel Input Convex LSTM for Lyapunov-based MPC, with the
specific goal of reducing convergence time and mitigating the
vanishing/exploding gradient problem while ensuring closed-loop stability. From
a simulation study of a nonlinear chemical reactor, we observed a mitigation of
vanishing/exploding gradient problem and a reduction in convergence time, with
a percentage decrease of 46.7%, 31.3%, and 20.2% compared to baseline plain
RNN, plain LSTM, and Input Convex Recurrent Neural Network, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10359">FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel Identification. (arXiv:2311.10359v4 [cs.DC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenqing Wu</a></p>
<p>Highly parallelized workloads like machine learning training, inferences and
general HPC tasks are greatly accelerated using GPU devices. In a cloud
computing cluster, serving a GPU's computation power through multi-tasks
sharing is highly demanded since there are always more task requests than the
number of GPU available. Existing GPU sharing solutions focus on reducing
task-level waiting time or task-level switching costs when multiple jobs
competing for a single GPU. Non-stopped computation requests come with
different priorities, having non-symmetric impact on QoS for sharing a GPU
device. Existing work missed the kernel-level optimization opportunity brought
by this setting. To address this problem, we present a novel kernel-level
scheduling strategy called FIKIT: Filling Inter-kernel Idle Time. FIKIT
incorporates task-level priority information, fine-grained kernel
identification, and kernel measurement, allowing low priorities task's
execution during high priority task's inter-kernel idle time. Thereby, filling
the GPU's device runtime fully, and reduce overall GPU sharing impact to cloud
services. Across a set of ML models, the FIKIT based inference system
accelerated high priority tasks by 1.33 to 14.87 times compared to the JCT in
GPU sharing mode, and more than half of the cases are accelerated by more than
3.5 times. Alternatively, under preemptive sharing, the low-priority tasks have
a comparable to default GPU sharing mode JCT, with a 0.84 to 1 times ratio. We
further limit the kernel measurement and runtime fine-grained kernel scheduling
overhead to less than 5%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13184">Large Language Model-Enhanced Algorithm Selection: Towards Comprehensive Algorithm Representation. (arXiv:2311.13184v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xingyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jibin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bingbing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1">Kay Chen Tan</a></p>
<p>Algorithm selection aims to identify the most suitable algorithm for solving
a specific problem before execution, which has become a critical process of the
AutoML. Current mainstream algorithm selection techniques rely heavily on
feature representations of various problems and employ the performance of each
algorithm as supervised information. However, there is a significant research
gap concerning the consideration of algorithm features. This gap is primarily
attributed to the inherent complexity of algorithms, making it particularly
challenging to find a universally effective feature extraction method that is
applicable across a diverse range of algorithms. Unfortunately, neglecting this
aspect undoubtedly impacts the accuracy of algorithm selection and indirectly
necessitates an increased volume of problem data for training purposes. This
paper takes a significant stride towards addressing this gap by proposing an
approach that integrates algorithm representation into the algorithm selection
process. Specifically, our proposed model employs distinct modules to extract
representations of both problems and algorithms, where the algorithm
representation leverages the capabilities of pre-trained LLMs in the realm of
code comprehension. Following the extraction of embedding vectors for both
algorithms and problems, the most suitable algorithm is determined through
calculations of matching degrees. Our experiments not only validate the
effectiveness of the proposed model but also showcase the performance of
different embedded pre-trained LLMs, which suggests that the proposed algorithm
selection framework holds the potential to serve as a baseline task for
evaluating the code representation capabilities of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13594">Labeling Neural Representations with Inverse Recognition. (arXiv:2311.13594v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bykov_K/0/1/0/all/0/1">Kirill Bykov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopf_L/0/1/0/all/0/1">Laura Kopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1">Shinichi Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Kloft_M/0/1/0/all/0/1">Marius Kloft</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_M/0/1/0/all/0/1">Marina M.-C. H&#xf6;hne</a></p>
<p>Deep Neural Networks (DNNs) demonstrate remarkable capabilities in learning
complex hierarchical data representations, but the nature of these
representations remains largely unknown. Existing global explainability
methods, such as Network Dissection, face limitations such as reliance on
segmentation masks, lack of statistical significance testing, and high
computational demands. We propose Inverse Recognition (INVERT), a scalable
approach for connecting learned representations with human-understandable
concepts by leveraging their capacity to discriminate between these concepts.
In contrast to prior work, INVERT is capable of handling diverse types of
neurons, exhibits less computational complexity, and does not rely on the
availability of segmentation masks. Moreover, INVERT provides an interpretable
metric assessing the alignment between the representation and its corresponding
explanation and delivering a measure of statistical significance. We
demonstrate the applicability of INVERT in various scenarios, including the
identification of representations affected by spurious correlations, and the
interpretation of the hierarchical structure of decision-making within the
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18243">DKiS: Decay weight invertible image steganography with private key. (arXiv:2311.18243v2 [cs.MM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yitian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuhua Liu</a></p>
<p>Image steganography, defined as the practice of concealing information within
another image, traditionally encounters security challenges when its methods
become publicly known or are under attack. To address this, a novel private
key-based image steganography technique has been introduced. This approach
ensures the security of the hidden information, as access requires a
corresponding private key, regardless of the public knowledge of the
steganography method. Experimental evidence has been presented, demonstrating
the effectiveness of our method and showcasing its real-world applicability.
Furthermore, a critical challenge in the invertible image steganography process
has been identified by us: the transfer of non-essential, or `garbage',
information from the secret to the host pipeline. To tackle this issue, the
decay weight has been introduced to control the information transfer,
effectively filtering out irrelevant data and enhancing the performance of
image steganography. The code for this technique is publicly accessible at
https://github.com/yanghangAI/DKiS, and a practical demonstration can be found
at <a href="http://yanghang.site/hidekey.">this http URL</a>
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04273">Invariant Random Forest: Tree-Based Model Solution for OOD Generalization. (arXiv:2312.04273v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yufan Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xing Yan</a></p>
<p>Out-Of-Distribution (OOD) generalization is an essential topic in machine
learning. However, recent research is only focusing on the corresponding
methods for neural networks. This paper introduces a novel and effective
solution for OOD generalization of decision tree models, named Invariant
Decision Tree (IDT). IDT enforces a penalty term with regard to the
unstable/varying behavior of a split across different environments during the
growth of the tree. Its ensemble version, the Invariant Random Forest (IRF), is
constructed. Our proposed method is motivated by a theoretical result under
mild conditions, and validated by numerical tests with both synthetic and real
datasets. The superior performance compared to non-OOD tree models implies that
considering OOD generalization for tree models is absolutely necessary and
should be given more attention.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06305">A Meta-Level Learning Algorithm for Sequential Hyper-Parameter Space Reduction in AutoML. (arXiv:2312.06305v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Borboudakis_G/0/1/0/all/0/1">Giorgos Borboudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Charonyktakis_P/0/1/0/all/0/1">Paulos Charonyktakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Paraschakis_K/0/1/0/all/0/1">Konstantinos Paraschakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsamardinos_I/0/1/0/all/0/1">Ioannis Tsamardinos</a></p>
<p>AutoML platforms have numerous options for the algorithms to try for each
step of the analysis, i.e., different possible algorithms for imputation,
transformations, feature selection, and modelling. Finding the optimal
combination of algorithms and hyper-parameter values is computationally
expensive, as the number of combinations to explore leads to an exponential
explosion of the space. In this paper, we present the Sequential
Hyper-parameter Space Reduction (SHSR) algorithm that reduces the space for an
AutoML tool with negligible drop in its predictive performance. SHSR is a
meta-level learning algorithm that analyzes past runs of an AutoML tool on
several datasets and learns which hyper-parameter values to filter out from
consideration on a new dataset to analyze. SHSR is evaluated on 284
classification and 375 regression problems, showing an approximate 30%
reduction in execution time with a performance drop of less than 0.1%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11034">Partial Label Learning with a Partner. (arXiv:2312.11034v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1">Chongjie Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zekun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuehui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a></p>
<p>In partial label learning (PLL), each instance is associated with a set of
candidate labels among which only one is ground-truth. The majority of the
existing works focuses on constructing robust classifiers to estimate the
labeling confidence of candidate labels in order to identify the correct one.
However, these methods usually struggle to rectify mislabeled samples. To help
existing PLL methods identify and rectify mislabeled samples, in this paper, we
introduce a novel partner classifier and propose a novel ``mutual supervision''
paradigm. Specifically, we instantiate the partner classifier predicated on the
implicit fact that non-candidate labels of a sample should not be assigned to
it, which is inherently accurate and has not been fully investigated in PLL.
Furthermore, a novel collaborative term is formulated to link the base
classifier and the partner one. During each stage of mutual supervision, both
classifiers will blur each other's predictions through a blurring mechanism to
prevent overconfidence in a specific label. Extensive experiments demonstrate
that the performance and disambiguation ability of several well-established
stand-alone and deep-learning based PLL approaches can be significantly
improved by coupling with this learning paradigm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12469">Distilling Autoregressive Models to Obtain High-Performance Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference Speed. (arXiv:2312.12469v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yubin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingzhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Changliang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">You Zhou</a></p>
<p>Neural construction models have shown promising performance for Vehicle
Routing Problems (VRPs) by adopting either the Autoregressive (AR) or
Non-Autoregressive (NAR) learning approach. While AR models produce
high-quality solutions, they generally have a high inference latency due to
their sequential generation nature. Conversely, NAR models generate solutions
in parallel with a low inference latency but generally exhibit inferior
performance. In this paper, we propose a generic Guided Non-Autoregressive
Knowledge Distillation (GNARKD) method to obtain high-performance NAR models
having a low inference latency. GNARKD removes the constraint of sequential
generation in AR models while preserving the learned pivotal components in the
network architecture to obtain the corresponding NAR models through knowledge
distillation. We evaluate GNARKD by applying it to three widely adopted AR
models to obtain NAR VRP solvers for both synthesized and real-world instances.
The experimental results demonstrate that GNARKD significantly reduces the
inference time (4-5 times faster) with acceptable performance drop (2-3\%). To
the best of our knowledge, this study is first-of-its-kind to obtain NAR VRP
solvers from AR ones through knowledge distillation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12838">FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image Segmentation against Heterogeneous Annotation Noise. (arXiv:2312.12838v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1">Nannan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhaobin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zengqiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Li Yu</a></p>
<p>Federated learning (FL) has emerged as a promising paradigm for training
segmentation models on decentralized medical data, owing to its
privacy-preserving property. However, existing research overlooks the prevalent
annotation noise encountered in real-world medical datasets, which limits the
performance ceilings of FL. In this paper, we, for the first time, identify and
tackle this problem. For problem formulation, we propose a contour evolution
for modeling non-independent and identically distributed (Non-IID) noise across
pixels within each client and then extend it to the case of multi-source data
to form a heterogeneous noise model (i.e., Non-IID annotation noise across
clients). For robust learning from annotations with such two-level Non-IID
noise, we emphasize the importance of data quality in model aggregation,
allowing high-quality clients to have a greater impact on FL. To achieve this,
we propose Federated learning with Annotation quAlity-aware AggregatIon, named
FedA3I, by introducing a quality factor based on client-wise noise estimation.
Specifically, noise estimation at each client is accomplished through the
Gaussian mixture model and then incorporated into model aggregation in a
layer-wise manner to up-weight high-quality clients. Extensive experiments on
two real-world medical image segmentation datasets demonstrate the superior
performance of FedA$^3$I against the state-of-the-art approaches in dealing
with cross-client annotation noise. The code is available at
https://github.com/wnn2000/FedAAAI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12849">Divergences induced by dual subtractive and divisive normalizations of exponential families and their convex deformations. (arXiv:2312.12849v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a></p>
<p>Exponential families are statistical models which are the workhorses in
statistics, information theory, and machine learning among others. An
exponential family can either be normalized subtractively by its cumulant or
free energy function or equivalently normalized divisively by its partition
function. Both subtractive and divisive normalizers are strictly convex and
smooth functions inducing pairs of Bregman and Jensen divergences. It is
well-known that skewed Bhattacharryya distances between probability densities
of an exponential family amounts to skewed Jensen divergences induced by the
cumulant function between their corresponding natural parameters, and in limit
cases that the sided Kullback-Leibler divergences amount to reverse-sided
Bregman divergences. In this paper, we first show that the $\alpha$-divergences
between unnormalized densities of an exponential family amounts to scaled
$\alpha$-skewed Jensen divergences induced by the partition function. We then
show how comparative convexity with respect to a pair of quasi-arithmetic means
allows to deform both convex functions and their arguments, and thereby define
dually flat spaces with corresponding divergences when ordinary convexity is
preserved.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.17670">TopCoW: Benchmarking Topology-Aware Anatomical Segmentation of the Circle of Willis (CoW) for CTA and MRA. (arXiv:2312.17670v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Musio_F/0/1/0/all/0/1">Fabio Musio</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yihui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Juchler_N/0/1/0/all/0/1">Norman Juchler</a>, <a href="http://arxiv.org/find/cs/1/au:+Paetzold_J/0/1/0/all/0/1">Johannes C. Paetzold</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Maskari_R/0/1/0/all/0/1">Rami Al-Maskari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoher_L/0/1/0/all/0/1">Luciano H&#xf6;her</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongwei Bran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamamci_I/0/1/0/all/0/1">Ibrahim Ethem Hamamci</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekuboyina_A/0/1/0/all/0/1">Anjany Sekuboyina</a>, <a href="http://arxiv.org/find/cs/1/au:+Shit_S/0/1/0/all/0/1">Suprosanna Shit</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Houjing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Waldmannstetter_D/0/1/0/all/0/1">Diana Waldmannstetter</a>, <a href="http://arxiv.org/find/cs/1/au:+Kofler_F/0/1/0/all/0/1">Florian Kofler</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarro_F/0/1/0/all/0/1">Fernando Navarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Menten_M/0/1/0/all/0/1">Martin Menten</a>, <a href="http://arxiv.org/find/cs/1/au:+Ezhov_I/0/1/0/all/0/1">Ivan Ezhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Vos_I/0/1/0/all/0/1">Iris Vos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruigrok_Y/0/1/0/all/0/1">Ynte Ruigrok</a>, <a href="http://arxiv.org/find/cs/1/au:+Velthuis_B/0/1/0/all/0/1">Birgitta Velthuis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuijf_H/0/1/0/all/0/1">Hugo Kuijf</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammerli_J/0/1/0/all/0/1">Julien H&#xe4;mmerli</a>, <a href="http://arxiv.org/find/cs/1/au:+Wurster_C/0/1/0/all/0/1">Catherine Wurster</a>, <a href="http://arxiv.org/find/cs/1/au:+Bijlenga_P/0/1/0/all/0/1">Philippe Bijlenga</a>, <a href="http://arxiv.org/find/cs/1/au:+Westphal_L/0/1/0/all/0/1">Laura Westphal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisschop_J/0/1/0/all/0/1">Jeroen Bisschop</a>, <a href="http://arxiv.org/find/cs/1/au:+Colombo_E/0/1/0/all/0/1">Elisa Colombo</a>, <a href="http://arxiv.org/find/cs/1/au:+Baazaoui_H/0/1/0/all/0/1">Hakim Baazaoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Makmur_A/0/1/0/all/0/1">Andrew Makmur</a>, <a href="http://arxiv.org/find/cs/1/au:+Hallinan_J/0/1/0/all/0/1">James Hallinan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiestler_B/0/1/0/all/0/1">Bene Wiestler</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirschke_J/0/1/0/all/0/1">Jan S. Kirschke</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiest_R/0/1/0/all/0/1">Roland Wiest</a>, <a href="http://arxiv.org/find/cs/1/au:+Montagnon_E/0/1/0/all/0/1">Emmanuel Montagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Letourneau_Guillon_L/0/1/0/all/0/1">Laurent Letourneau-Guillon</a>, <a href="http://arxiv.org/find/cs/1/au:+Galdran_A/0/1/0/all/0/1">Adrian Galdran</a>, <a href="http://arxiv.org/find/cs/1/au:+Galati_F/0/1/0/all/0/1">Francesco Galati</a>, <a href="http://arxiv.org/find/cs/1/au:+Falcetta_D/0/1/0/all/0/1">Daniele Falcetta</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuluaga_M/0/1/0/all/0/1">Maria A. Zuluaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chaolong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoran Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zehan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ra_S/0/1/0/all/0/1">Sinyoung Ra</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jongyun Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyunjin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junqiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wodzinski_M/0/1/0/all/0/1">Marek Wodzinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_H/0/1/0/all/0/1">Henning M&#xfc;ller</a>, et al. (33 additional authors not shown)</p>
<p>The Circle of Willis (CoW) is an important network of arteries connecting
major circulations of the brain. Its vascular architecture is believed to
affect the risk, severity, and clinical outcome of serious neuro-vascular
diseases. However, characterizing the highly variable CoW anatomy is still a
manual and time-consuming expert task. The CoW is usually imaged by two
angiographic imaging modalities, magnetic resonance angiography (MRA) and
computed tomography angiography (CTA), but there exist limited public datasets
with annotations on CoW anatomy, especially for CTA. Therefore we organized the
TopCoW Challenge in 2023 with the release of an annotated CoW dataset. The
TopCoW dataset was the first public dataset with voxel-level annotations for
thirteen possible CoW vessel components, enabled by virtual-reality (VR)
technology. It was also the first large dataset with paired MRA and CTA from
the same patients. TopCoW challenge formalized the CoW characterization problem
as a multiclass anatomical segmentation task with an emphasis on topological
metrics. We invited submissions worldwide for the CoW segmentation task, which
attracted over 140 registered participants from four continents. The top
performing teams managed to segment many CoW components to Dice scores around
90%, but with lower scores for communicating arteries and rare variants. There
were also topological mistakes for predictions with high Dice scores.
Additional topological analysis revealed further areas for improvement in
detecting certain CoW components and matching CoW variant topology accurately.
TopCoW represented a first attempt at benchmarking the CoW anatomical
segmentation task for MRA and CTA, both morphologically and topologically.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.02860">Framework for Variable-lag Motif Following Relation Inference In Time Series using Matrix Profile analysis. (arXiv:2401.02860v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chinpattanakarn_N/0/1/0/all/0/1">Naaek Chinpattanakarn</a>, <a href="http://arxiv.org/find/cs/1/au:+Amornbunchornvej_C/0/1/0/all/0/1">Chainarong Amornbunchornvej</a></p>
<p>Knowing who follows whom and what patterns they are following are crucial
steps to understand collective behaviors (e.g. a group of human, a school of
fish, or a stock market). Time series is one of resources that can be used to
get insight regarding following relations. However, the concept of following
patterns or motifs and the solution to find them in time series are not
obvious. In this work, we formalize a concept of following motifs between two
time series and present a framework to infer following patterns between two
time series. The framework utilizes one of efficient and scalable methods to
retrieve motifs from time series called the Matrix Profile Method. We compare
our proposed framework with several baselines. The framework performs better
than baselines in the simulation datasets. In the dataset of sound recording,
the framework is able to retrieve the following motifs within a pair of time
series that two singers sing following each other. In the cryptocurrency
dataset, the framework is capable of capturing the following motifs within a
pair of time series from two digital currencies, which implies that the values
of one currency follow the values of another currency patterns. Our framework
can be utilized in any field of time series to get insight regarding following
patterns between time series.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04855">LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control. (arXiv:2401.04855v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Saurav Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Muthukrishnan_R/0/1/0/all/0/1">Ramya Muthukrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gosrich_W/0/1/0/all/0/1">Walker Gosrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vijay Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a></p>
<p>Coverage control is the problem of navigating a robot swarm to
collaboratively monitor features or a phenomenon of interest not known a
priori. The problem is challenging in decentralized settings with robots that
have limited communication and sensing capabilities. We propose a learnable
Perception-Action-Communication (LPAC) architecture for the problem, wherein a
convolution neural network (CNN) processes localized perception; a graph neural
network (GNN) facilitates robot communications; finally, a shallow multi-layer
perceptron (MLP) computes robot actions. The GNN enables collaboration in the
robot swarm by computing what information to communicate with nearby robots and
how to incorporate received information. Evaluations show that the LPAC models
-- trained using imitation learning -- outperform standard decentralized and
centralized coverage control algorithms. The learned policy generalizes to
environments different from the training dataset, transfers to larger
environments with more robots, and is robust to noisy position estimates. The
results indicate the suitability of LPAC architectures for decentralized
navigation in robot swarms to achieve collaborative behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05566">Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training. (arXiv:2401.05566v3 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hubinger_E/0/1/0/all/0/1">Evan Hubinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Denison_C/0/1/0/all/0/1">Carson Denison</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1">Jesse Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lambert_M/0/1/0/all/0/1">Mike Lambert</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1">Meg Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+MacDiarmid_M/0/1/0/all/0/1">Monte MacDiarmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanham_T/0/1/0/all/0/1">Tamera Lanham</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziegler_D/0/1/0/all/0/1">Daniel M. Ziegler</a>, <a href="http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1">Tim Maxwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1">Newton Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermyn_A/0/1/0/all/0/1">Adam Jermyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1">Amanda Askell</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1">Ansh Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Anil_C/0/1/0/all/0/1">Cem Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1">David Duvenaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguli_D/0/1/0/all/0/1">Deep Ganguli</a>, <a href="http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1">Fazl Barez</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1">Jack Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Ndousse_K/0/1/0/all/0/1">Kamal Ndousse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_K/0/1/0/all/0/1">Kshitij Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellitto_M/0/1/0/all/0/1">Michael Sellitto</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1">Mrinank Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+DasSarma_N/0/1/0/all/0/1">Nova DasSarma</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1">Roger Grosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Kravec_S/0/1/0/all/0/1">Shauna Kravec</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yuntao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Witten_Z/0/1/0/all/0/1">Zachary Witten</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_M/0/1/0/all/0/1">Marina Favaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1">Jan Brauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Karnofsky_H/0/1/0/all/0/1">Holden Karnofsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Christiano_P/0/1/0/all/0/1">Paul Christiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1">Samuel R. Bowman</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_L/0/1/0/all/0/1">Logan Graham</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1">Jared Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1">S&#xf6;ren Mindermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenblatt_R/0/1/0/all/0/1">Ryan Greenblatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlegeris_B/0/1/0/all/0/1">Buck Shlegeris</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1">Nicholas Schiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1">Ethan Perez</a></p>
<p>Humans are capable of strategically deceptive behavior: behaving helpfully in
most situations, but then behaving very differently in order to pursue
alternative objectives when given the opportunity. If an AI system learned such
a deceptive strategy, could we detect it and remove it using current
state-of-the-art safety training techniques? To study this question, we
construct proof-of-concept examples of deceptive behavior in large language
models (LLMs). For example, we train models that write secure code when the
prompt states that the year is 2023, but insert exploitable code when the
stated year is 2024. We find that such backdoor behavior can be made
persistent, so that it is not removed by standard safety training techniques,
including supervised fine-tuning, reinforcement learning, and adversarial
training (eliciting unsafe behavior and then training to remove it). The
backdoor behavior is most persistent in the largest models and in models
trained to produce chain-of-thought reasoning about deceiving the training
process, with the persistence remaining even when the chain-of-thought is
distilled away. Furthermore, rather than removing backdoors, we find that
adversarial training can teach models to better recognize their backdoor
triggers, effectively hiding the unsafe behavior. Our results suggest that,
once a model exhibits deceptive behavior, standard techniques could fail to
remove such deception and create a false impression of safety.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07231">Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data. (arXiv:2401.07231v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maeda_T/0/1/0/all/0/1">Takashi Nicholas Maeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1">Shohei Shimizu</a></p>
<p>This paper proposes two methods for causal additive models with unobserved
variables (CAM-UV). CAM-UV assumes that the causal functions take the form of
generalized additive models and that latent confounders are present. First, we
propose a method that leverages prior knowledge for efficient causal discovery.
Then, we propose an extension of this method for inferring causality in time
series data. The original CAM-UV algorithm differs from other existing causal
function models in that it does not seek the causal order between observed
variables, but rather aims to identify the causes for each observed variable.
Therefore, the first proposed method in this paper utilizes prior knowledge,
such as understanding that certain variables cannot be causes of specific
others. Moreover, by incorporating the prior knowledge that causes precedes
their effects in time, we extend the first algorithm to the second method for
causal discovery in time series data. We validate the first proposed method by
using simulated data to demonstrate that the accuracy of causal discovery
increases as more prior knowledge is accumulated. Additionally, we test the
second proposed method by comparing it with existing time series causal
discovery methods, using both simulated data and real-world data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07927">Are self-explanations from Large Language Models faithful?. (arXiv:2401.07927v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1">Andreas Madsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a></p>
<p>Instruction-tuned large language models (LLMs) excel at many tasks, and will
even provide explanations for their behavior. Since these models are directly
accessible to the public, there is a risk that convincing and wrong
explanations can lead to unsupported confidence in LLMs. Therefore,
interpretability-faithfulness of self-explanations is an important
consideration for AI Safety. Assessing the interpretability-faithfulness of
these explanations, termed self-explanations, is challenging as the models are
too complex for humans to annotate what is a correct explanation. To address
this, we propose employing self-consistency checks as a measure of
faithfulness. For example, if an LLM says a set of words is important for
making a prediction, then it should not be able to make the same prediction
without these words. While self-consistency checks are a common approach to
faithfulness, they have not previously been applied to LLM's self-explanations.
We apply self-consistency checks to three types of self-explanations:
counterfactuals, importance measures, and redactions. Our work demonstrate that
faithfulness is both task and model dependent, e.g., for sentiment
classification, counterfactual explanations are more faithful for Llama2,
importance measures for Mistral, and redaction for Falcon 40B. Finally, our
findings are robust to prompt-variations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08224">Differentially Private Estimation of CATE in Adaptive Experiment. (arXiv:2401.08224v2 [stat.ME] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Li_J/0/1/0/all/0/1">Jiachun Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Shi_K/0/1/0/all/0/1">Kaining Shi</a>, <a href="http://arxiv.org/find/stat/1/au:+Simchi_Levi_D/0/1/0/all/0/1">David Simchi-Levi</a></p>
<p>Adaptive experiment is widely adopted to estimate conditional average
treatment effect (CATE) in clinical trials and many other scenarios. While the
primary goal in experiment is to maximize estimation accuracy, due to the
imperative of social welfare, it's also crucial to provide treatment with
superior outcomes to patients, which is measured by regret in contextual bandit
framework. These two objectives often lead to contrast optimal allocation
mechanism. Furthermore, privacy concerns arise in clinical scenarios containing
sensitive data like patients health records. Therefore, it's essential for the
treatment allocation mechanism to incorporate robust privacy protection
measures. In this paper, we investigate the tradeoff between loss of social
welfare and statistical power in contextual bandit experiment. We propose a
matched upper and lower bound for the multi-objective optimization problem, and
then adopt the concept of Pareto optimality to mathematically characterize the
optimality condition. Furthermore, we propose differentially private algorithms
which still matches the lower bound, showing that privacy is "almost free".
Additionally, we derive the asymptotic normality of the estimator, which is
essential in statistical inference and hypothesis testing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08406">RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture. (arXiv:2401.08406v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Balaguer_A/0/1/0/all/0/1">Angels Balaguer</a>, <a href="http://arxiv.org/find/cs/1/au:+Benara_V/0/1/0/all/0/1">Vinamra Benara</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunha_R/0/1/0/all/0/1">Renato Luiz de Freitas Cunha</a>, <a href="http://arxiv.org/find/cs/1/au:+Filho_R/0/1/0/all/0/1">Roberto de M. Estev&#xe3;o Filho</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendry_T/0/1/0/all/0/1">Todd Hendry</a>, <a href="http://arxiv.org/find/cs/1/au:+Holstein_D/0/1/0/all/0/1">Daniel Holstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Marsman_J/0/1/0/all/0/1">Jennifer Marsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mecklenburg_N/0/1/0/all/0/1">Nick Mecklenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Malvar_S/0/1/0/all/0/1">Sara Malvar</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunes_L/0/1/0/all/0/1">Leonardo O. Nunes</a>, <a href="http://arxiv.org/find/cs/1/au:+Padilha_R/0/1/0/all/0/1">Rafael Padilha</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharp_M/0/1/0/all/0/1">Morris Sharp</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1">Bruno Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Swati Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Aski_V/0/1/0/all/0/1">Vijay Aski</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Ranveer Chandra</a></p>
<p>There are two common ways in which developers are incorporating proprietary
and domain-specific data when building applications of Large Language Models
(LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the
prompt with the external data, while fine-Tuning incorporates the additional
knowledge into the model itself. However, the pros and cons of both approaches
are not well understood. In this paper, we propose a pipeline for fine-tuning
and RAG, and present the tradeoffs of both for multiple popular LLMs, including
Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages,
including extracting information from PDFs, generating questions and answers,
using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We
propose metrics to assess the performance of different stages of the RAG and
fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset.
Agriculture as an industry has not seen much penetration of AI, and we study a
potentially disruptive application - what if we could provide location-specific
insights to a farmer? Our results show the effectiveness of our dataset
generation pipeline in capturing geographic-specific knowledge, and the
quantitative and qualitative benefits of RAG and fine-tuning. We see an
accuracy increase of over 6 p.p. when fine-tuning the model and this is
cumulative with RAG, which increases accuracy by 5 p.p. further. In one
particular experiment, we also demonstrate that the fine-tuned model leverages
information from across geographies to answer specific questions, increasing
answer similarity from 47% to 72%. Overall, the results point to how systems
built using LLMs can be adapted to respond and incorporate knowledge across a
dimension that is critical for a specific industry, paving the way for further
applications of LLMs in other industrial domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08689">NODI: Out-Of-Distribution Detection with Noise from Diffusion. (arXiv:2401.08689v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingqiu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1">Aojun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a></p>
<p>Out-of-distribution (OOD) detection is a crucial part of deploying machine
learning models safely. It has been extensively studied with a plethora of
methods developed in the literature. This problem is tackled with an OOD score
computation, however, previous methods compute the OOD scores with limited
usage of the in-distribution dataset. For instance, the OOD scores are computed
with information from a small portion of the in-distribution data. Furthermore,
these methods encode images with a neural image encoder. The robustness of
these methods is rarely checked with respect to image encoders of different
training methods and architectures. In this work, we introduce the diffusion
process into the OOD task. The diffusion model integrates information on the
whole training set into the predicted noise vectors. What's more, we deduce a
closed-form solution for the noise vector (stable point). Then the noise vector
is converted into our OOD score, we test both the deep model predicted noise
vector and the closed-form noise vector on the OOD benchmarks \cite{openood}.
Our method outperforms previous OOD methods across all types of image encoders
(Table. \ref{main}). A $3.5\%$ performance gain is achieved with the MAE-based
image encoder. Moreover, we studied the robustness of OOD methods by applying
different types of image encoders. Some OOD methods failed to generalize well
when switching image encoders from ResNet to Vision Transformers, our method
performs exhibits good robustness with all the image encoders.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08727">MA2GCN: Multi Adjacency relationship Attention Graph Convolutional Networks for Traffic Prediction using Trajectory data. (arXiv:2401.08727v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhengke Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yuliang Ma</a></p>
<p>The problem of traffic congestion not only causes a large amount of economic
losses, but also seriously endangers the urban environment. Predicting traffic
congestion has important practical significance. So far, most studies have been
based on historical data from sensors placed on different roads to predict
future traffic flow and speed, to analyze the traffic congestion conditions of
a certain road segment. However, due to the fixed position of sensors, it is
difficult to mine new information. On the other hand, vehicle trajectory data
is more flexible and can extract traffic information as needed. Therefore, we
proposed a new traffic congestion prediction model - Multi Adjacency
relationship Attention Graph Convolutional Networks(MA2GCN). This model
transformed vehicle trajectory data into graph structured data in grid form,
and proposed a vehicle entry and exit matrix based on the mobility between
different grids. At the same time, in order to improve the performance of the
model, this paper also built a new adaptive adjacency matrix generation method
and adjacency matrix attention module. This model mainly used gated temporal
convolution and graph convolution to extract temporal and spatial information,
respectively. Compared with multiple baselines, our model achieved the best
performance on Shanghai taxi GPS trajectory dataset. The code is available at
https://github.com/zachysun/Taxi_Traffic_Benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09180">Unsupervised Multiple Domain Translation through Controlled Disentanglement in Variational Autoencoder. (arXiv:2401.09180v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Almudevar_A/0/1/0/all/0/1">Antonio Almud&#xe9;var</a>, <a href="http://arxiv.org/find/cs/1/au:+Mariotte_T/0/1/0/all/0/1">Th&#xe9;o Mariotte</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_A/0/1/0/all/0/1">Alfonso Ortega</a>, <a href="http://arxiv.org/find/cs/1/au:+Tahon_M/0/1/0/all/0/1">Marie Tahon</a></p>
<p>Unsupervised Multiple Domain Translation is the task of transforming data
from one domain to other domains without having paired data to train the
systems. Typically, methods based on Generative Adversarial Networks (GANs) are
used to address this task. However, our proposal exclusively relies on a
modified version of a Variational Autoencoder. This modification consists of
the use of two latent variables disentangled in a controlled way by design. One
of this latent variables is imposed to depend exclusively on the domain, while
the other one must depend on the rest of the variability factors of the data.
Additionally, the conditions imposed over the domain latent variable allow for
better control and understanding of the latent space. We empirically
demonstrate that our approach works on different vision datasets improving the
performance of other well known methods. Finally, we prove that, indeed, one of
the latent variables stores all the information related to the domain and the
other one hardly contains any domain information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09192">Preparing Lessons for Progressive Training on Language Models. (arXiv:2401.09192v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yu Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Ye Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yichun Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiaxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1">Lifeng Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a></p>
<p>The rapid progress of Transformers in artificial intelligence has come at the
cost of increased resource consumption and greenhouse gas emissions due to
growing model sizes. Prior work suggests using pretrained small models to
improve training efficiency, but this approach may not be suitable for new
model structures. On the other hand, training from scratch can be slow, and
progressively stacking layers often fails to achieve significant acceleration.
To address these challenges, we propose a novel method called Apollo, which
prep\textbf{a}res lessons for ex\textbf{p}anding \textbf{o}perations by
\textbf{l}earning high-\textbf{l}ayer functi\textbf{o}nality during training of
low layers. Our approach involves low-value-prioritized sampling (LVPS) to
train different depths and weight sharing to facilitate efficient expansion. We
also introduce an interpolation method for stable model depth extension.
Experiments demonstrate that Apollo achieves state-of-the-art acceleration
ratios, even rivaling methods using pretrained models, making it a universal
and efficient solution for training deep models while reducing time, financial,
and environmental costs.
</p>
</p>
</div>

    </div>
    </body>
    