<!DOCTYPE html>
<html>
<head>
<title>2023-07-14-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.06337">Incomplete Utterance Rewriting as Sequential Greedy Tagging. (arXiv:2307.06337v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunshan Chen</a></p>
<p>The task of incomplete utterance rewriting has recently gotten much
attention. Previous models struggled to extract information from the dialogue
context, as evidenced by the low restoration scores. To address this issue, we
propose a novel sequence tagging-based model, which is more adept at extracting
information from context. Meanwhile, we introduce speaker-aware embedding to
model speaker variation. Experiments on multiple public datasets show that our
model achieves optimal results on all nine restoration scores while having
other metric scores comparable to previous state-of-the-art models.
Furthermore, benefitting from the model's simplicity, our approach outperforms
most previous models on inference speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06341">Assessment of the suitability of degradation models for the planning of CCTV inspections of sewer pipes. (arXiv:2307.06341v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Morer_F/0/1/0/all/0/1">Fidae El Morer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wittek_S/0/1/0/all/0/1">Stefan Wittek</a>, <a href="http://arxiv.org/find/cs/1/au:+Rausch_A/0/1/0/all/0/1">Andreas Rausch</a></p>
<p>The degradation of sewer pipes poses significant economical, environmental
and health concerns. The maintenance of such assets requires structured plans
to perform inspections, which are more efficient when structural and
environmental features are considered along with the results of previous
inspection reports. The development of such plans requires degradation models
that can be based on statistical and machine learning methods. This work
proposes a methodology to assess their suitability to plan inspections
considering three dimensions: accuracy metrics, ability to produce long-term
degradation curves and explainability. Results suggest that although ensemble
models yield the highest accuracy, they are unable to infer the long-term
degradation of the pipes, whereas the Logistic Regression offers a slightly
less accurate model that is able to produce consistent degradation curves with
a high explainability. A use case is presented to demonstrate this methodology
and the efficiency of model-based planning compared to the current inspection
plan.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06343">Sequential Experimental Design for X-Ray CT Using Deep Reinforcement Learning. (arXiv:2307.06343v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1">Tianyuan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lucka_F/0/1/0/all/0/1">Felix Lucka</a>, <a href="http://arxiv.org/find/eess/1/au:+Leeuwen_T/0/1/0/all/0/1">Tristan van Leeuwen</a></p>
<p>In X-ray Computed Tomography (CT), projections from many angles are acquired
and used for 3D reconstruction. To make CT suitable for in-line quality
control, reducing the number of angles while maintaining reconstruction quality
is necessary. Sparse-angle tomography is a popular approach for obtaining 3D
reconstructions from limited data. To optimize its performance, one can adapt
scan angles sequentially to select the most informative angles for each scanned
object. Mathematically, this corresponds to solving and optimal experimental
design (OED) problem. OED problems are high-dimensional, non-convex, bi-level
optimization problems that cannot be solved online, i.e., during the scan. To
address these challenges, we pose the OED problem as a partially observable
Markov decision process in a Bayesian framework, and solve it through deep
reinforcement learning. The approach learns efficient non-greedy policies to
solve a given class of OED problems through extensive offline training rather
than solving a given OED problem directly via numerical optimization. As such,
the trained policy can successfully find the most informative scan angles
online. We use a policy training method based on the Actor-Critic approach and
evaluate its performance on 2D tomography with synthetic data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06362">Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1">Inbar Seroussi</a>, <a href="http://arxiv.org/find/stat/1/au:+Miron_A/0/1/0/all/0/1">Asaf Miron</a>, <a href="http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1">Zohar Ringel</a></p>
<p>Physically informed neural networks (PINNs) are a promising emerging method
for solving differential equations. As in many other deep learning approaches,
the choice of PINN design and training protocol requires careful craftsmanship.
Here, we suggest a comprehensive theoretical framework that sheds light on this
important problem. Leveraging an equivalence between infinitely
over-parameterized neural networks and Gaussian process regression (GPR), we
derive an integro-differential equation that governs PINN prediction in the
large data-set limit -- the Neurally-Informed Equation (NIE). This equation
augments the original one by a kernel term reflecting architecture choices and
allows quantifying implicit bias induced by the network via a spectral
decomposition of the source term in the original differential equation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06380">Personalized Anomaly Detection in PPG Data using Representation Learning and Biometric Identification. (arXiv:2307.06380v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghorbani_R/0/1/0/all/0/1">Ramin Ghorbani</a>, <a href="http://arxiv.org/find/cs/1/au:+Reinders_M/0/1/0/all/0/1">Marcel J.T. Reinders</a>, <a href="http://arxiv.org/find/cs/1/au:+Tax_D/0/1/0/all/0/1">David M.J. Tax</a></p>
<p>Photoplethysmography (PPG) signals, typically acquired from wearable devices,
hold significant potential for continuous fitness-health monitoring. In
particular, heart conditions that manifest in rare and subtle deviating heart
patterns may be interesting. However, robust and reliable anomaly detection
within these data remains a challenge due to the scarcity of labeled data and
high inter-subject variability. This paper introduces a two-stage framework
leveraging representation learning and personalization to improve anomaly
detection performance in PPG data. The proposed framework first employs
representation learning to transform the original PPG signals into a more
discriminative and compact representation. We then apply three different
unsupervised anomaly detection methods for movement detection and biometric
identification. We validate our approach using two different datasets in both
generalized and personalized scenarios. The results show that representation
learning significantly improves anomaly detection performance while reducing
the high inter-subject variability. Personalized models further enhance anomaly
detection performance, underscoring the role of personalization in PPG-based
fitness-health monitoring systems. The results from biometric identification
show that it's easier to distinguish a new user from one intended authorized
user than from a group of users. Overall, this study provides evidence of the
effectiveness of representation learning and personalization for anomaly
detection in PPG data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06385">Temporal Label-Refinement for Weakly-Supervised Audio-Visual Event Localization. (arXiv:2307.06385v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_K/0/1/0/all/0/1">Kalyan Ramakrishnan</a></p>
<p>Audio-Visual Event Localization (AVEL) is the task of temporally localizing
and classifying \emph{audio-visual events}, i.e., events simultaneously visible
and audible in a video. In this paper, we solve AVEL in a weakly-supervised
setting, where only video-level event labels (their presence/absence, but not
their locations in time) are available as supervision for training. Our idea is
to use a base model to estimate labels on the training data at a finer temporal
resolution than at the video level and re-train the model with these labels.
I.e., we determine the subset of labels for each \emph{slice} of frames in a
training video by (i) replacing the frames outside the slice with those from a
second video having no overlap in video-level labels, and (ii) feeding this
synthetic video into the base model to extract labels for just the slice in
question. To handle the out-of-distribution nature of our synthetic videos, we
propose an auxiliary objective for the base model that induces more reliable
predictions of the localized event labels as desired. Our three-stage pipeline
outperforms several existing AVEL methods with no architectural changes and
improves performance on a related weakly-supervised task as well.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06398">Trainability, Expressivity and Interpretability in Gated Neural ODEs. (arXiv:2307.06398v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Timothy Doyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Can_T/0/1/0/all/0/1">Tankut Can</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_K/0/1/0/all/0/1">Kamesh Krishnamurthy</a></p>
<p>Understanding how the dynamics in biological and artificial neural networks
implement the computations required for a task is a salient open question in
machine learning and neuroscience. In particular, computations requiring
complex memory storage and retrieval pose a significant challenge for these
networks to implement or learn. Recently, a family of models described by
neural ordinary differential equations (nODEs) has emerged as powerful
dynamical neural network models capable of capturing complex dynamics. Here, we
extend nODEs by endowing them with adaptive timescales using gating
interactions. We refer to these as gated neural ODEs (gnODEs). Using a task
that requires memory of continuous quantities, we demonstrate the inductive
bias of the gnODEs to learn (approximate) continuous attractors. We further
show how reduced-dimensional gnODEs retain their modeling power while greatly
improving interpretability, even allowing explicit visualization of the
structure of learned attractors. We introduce a novel measure of expressivity
which probes the capacity of a neural network to generate complex trajectories.
Using this measure, we explore how the phase-space dimension of the nODEs and
the complexity of the function modeling the flow field contribute to
expressivity. We see that a more complex function for modeling the flow field
allows a lower-dimensional nODE to capture a given target dynamics. Finally, we
demonstrate the benefit of gating in nODEs on several real-world tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06406">Testing Sparsity Assumptions in Bayesian Networks. (arXiv:2307.06406v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Duttweiler_L/0/1/0/all/0/1">Luke Duttweiler</a>, <a href="http://arxiv.org/find/stat/1/au:+Thurston_S/0/1/0/all/0/1">Sally W. Thurston</a>, <a href="http://arxiv.org/find/stat/1/au:+Almudevar_A/0/1/0/all/0/1">Anthony Almudevar</a></p>
<p>Bayesian network (BN) structure discovery algorithms typically either make
assumptions about the sparsity of the true underlying network, or are limited
by computational constraints to networks with a small number of variables.
While these sparsity assumptions can take various forms, frequently the
assumptions focus on an upper bound for the maximum in-degree of the underlying
graph $\nabla_G$. Theorem 2 in Duttweiler et. al. (2023) demonstrates that the
largest eigenvalue of the normalized inverse covariance matrix ($\Omega$) of a
linear BN is a lower bound for $\nabla_G$. Building on this result, this paper
provides the asymptotic properties of, and a debiasing procedure for, the
sample eigenvalues of $\Omega$, leading to a hypothesis test that may be used
to determine if the BN has max in-degree greater than 1. A linear BN structure
discovery workflow is suggested in which the investigator uses this hypothesis
test to aid in selecting an appropriate structure discovery algorithm. The
hypothesis test performance is evaluated through simulations and the workflow
is demonstrated on data from a human psoriasis study.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06422">Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection. (arXiv:2307.06422v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1">Eli Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei-Ning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1">Chao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1">Ayfer &#xd6;zg&#xfc;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1">Olgica Milenkovic</a></p>
<p>Graph learning methods, such as Graph Neural Networks (GNNs) based on graph
convolutions, are highly successful in solving real-world learning problems
involving graph-structured data. However, graph learning methods expose
sensitive user information and interactions not only through their model
parameters but also through their model predictions. Consequently, standard
Differential Privacy (DP) techniques that merely offer model weight privacy are
inadequate. This is especially the case for node predictions that leverage
neighboring node attributes directly via graph convolutions that create
additional risks of privacy leakage. To address this problem, we introduce
Graph Differential Privacy (GDP), a new formal DP framework tailored to graph
learning settings that ensures both provably private model parameters and
predictions. Furthermore, since there may be different privacy requirements for
the node attributes and graph structure, we introduce a novel notion of relaxed
node-level data adjacency. This relaxation can be used for establishing
guarantees for different degrees of graph topology privacy while maintaining
node attribute privacy. Importantly, this relaxation reveals a useful trade-off
between utility and topology privacy for graph learning methods. In addition,
our analysis of GDP reveals that existing DP-GNNs fail to exploit this
trade-off due to the complex interplay between graph topology and attribute
data in standard graph convolution designs. To mitigate this problem, we
introduce the Differentially Private Decoupled Graph Convolution (DPDGC) model,
which benefits from decoupled graph convolution while providing GDP guarantees.
Extensive experiments on seven node classification benchmarking datasets
demonstrate the superior privacy-utility trade-off of DPDGC over existing
DP-GNNs based on standard graph convolution design.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06431">Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. (arXiv:2307.06431v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Schroder_T/0/1/0/all/0/1">Tobias Schr&#xf6;der</a>, <a href="http://arxiv.org/find/stat/1/au:+Ou_Z/0/1/0/all/0/1">Zijing Ou</a>, <a href="http://arxiv.org/find/stat/1/au:+Lim_J/0/1/0/all/0/1">Jen Ning Lim</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1">Yingzhen Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Vollmer_S/0/1/0/all/0/1">Sebastian J. Vollmer</a>, <a href="http://arxiv.org/find/stat/1/au:+Duncan_A/0/1/0/all/0/1">Andrew B. Duncan</a></p>
<p>Energy-based models are a simple yet powerful class of probabilistic models,
but their widespread adoption has been limited by the computational burden of
training them. We propose a novel loss function called Energy Discrepancy (ED)
which does not rely on the computation of scores or expensive Markov chain
Monte Carlo. We show that ED approaches the explicit score matching and
negative log-likelihood loss under different limits, effectively interpolating
between both. Consequently, minimum ED estimation overcomes the problem of
nearsightedness encountered in score-based estimation methods, while also
enjoying theoretical guarantees. Through numerical experiments, we demonstrate
that ED learns low-dimensional data distributions faster and more accurately
than explicit score matching or contrastive divergence. For high-dimensional
image data, we describe how the manifold hypothesis puts limitations on our
approach and demonstrate the effectiveness of energy discrepancy by training
the energy-based model as a prior of a variational decoder model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06434">Improved selective background Monte Carlo simulation at Belle II with graph attention networks and weighted events. (arXiv:2307.06434v1 [hep-ex])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ex/1/au:+Yu_B/0/1/0/all/0/1">Boyang Yu</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Hartmann_N/0/1/0/all/0/1">Nikolai Hartmann</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Schinnerl_L/0/1/0/all/0/1">Luca Schinnerl</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Kuhr_T/0/1/0/all/0/1">Thomas Kuhr</a></p>
<p>When measuring rare processes at Belle II, a huge luminosity is required,
which means a large number of simulations are necessary to determine signal
efficiencies and background contributions. However, this process demands high
computation costs while most of the simulated data, in particular in case of
background, are discarded by the event selection. Thus, filters using graph
neural networks are introduced at an early stage to save the resources for the
detector simulation and reconstruction of events discarded at analysis level.
In our work, we improved the performance of the filters using graph attention
and investigated statistical methods including sampling and reweighting to deal
with the biases introduced by the filtering.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06440">No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1">Jean Kaddour</a>, <a href="http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1">Oscar Key</a>, <a href="http://arxiv.org/find/cs/1/au:+Nawrot_P/0/1/0/all/0/1">Piotr Nawrot</a>, <a href="http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1">Pasquale Minervini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a></p>
<p>The computation necessary for training Transformer-based language models has
skyrocketed in recent years. This trend has motivated research on efficient
training algorithms designed to improve training, validation, and downstream
performance faster than standard training. In this work, we revisit three
categories of such algorithms: dynamic architectures (layer stacking, layer
dropping), batch selection (selective backprop, RHO loss), and efficient
optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed
computation budget using such methods, we find that their training, validation,
and downstream gains vanish compared to a baseline with a fully-decayed
learning rate. We define an evaluation protocol that enables computation to be
done on arbitrary machines by mapping all computation time to a reference
machine which we call reference system time. We discuss the limitations of our
proposed protocol and release our code to encourage rigorous research in
efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06442">On Collaboration in Distributed Parameter Estimation with Resource Constraints. (arXiv:2307.06442v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu-Zhen Janice Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Menasche_D/0/1/0/all/0/1">Daniel S. Menasch&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1">Don Towsley</a></p>
<p>We study sensor/agent data collection and collaboration policies for
parameter estimation, accounting for resource constraints and correlation
between observations collected by distinct sensors/agents. Specifically, we
consider a group of sensors/agents each samples from different variables of a
multivariate Gaussian distribution and has different estimation objectives, and
we formulate a sensor/agent's data collection and collaboration policy design
problem as a Fisher information maximization (or Cramer-Rao bound minimization)
problem. When the knowledge of correlation between variables is available, we
analytically identify two particular scenarios: (1) where the knowledge of the
correlation between samples cannot be leveraged for collaborative estimation
purposes and (2) where the optimal data collection policy involves investing
scarce resources to collaboratively sample and transfer information that is not
of immediate interest and whose statistics are already known, with the sole
goal of increasing the confidence on the estimate of the parameter of interest.
When the knowledge of certain correlation is unavailable but collaboration may
still be worthwhile, we propose novel ways to apply multi-armed bandit
algorithms to learn the optimal data collection and collaboration policy in our
distributed parameter estimation problem and demonstrate that the proposed
algorithms, DOUBLE-F, DOUBLE-Z, UCB-F, UCB-Z, are effective through
simulations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06450">Stochastic Delay Differential Games: Financial Modeling and Machine Learning Algorithms. (arXiv:2307.06450v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Balkin_R/0/1/0/all/0/1">Robert Balkin</a>, <a href="http://arxiv.org/find/math/1/au:+Ceniceros_H/0/1/0/all/0/1">Hector D. Ceniceros</a>, <a href="http://arxiv.org/find/math/1/au:+Hu_R/0/1/0/all/0/1">Ruimeng Hu</a></p>
<p>In this paper, we propose a numerical methodology for finding the closed-loop
Nash equilibrium of stochastic delay differential games through deep learning.
These games are prevalent in finance and economics where multi-agent
interaction and delayed effects are often desired features in a model, but are
introduced at the expense of increased dimensionality of the problem. This
increased dimensionality is especially significant as that arising from the
number of players is coupled with the potential infinite dimensionality caused
by the delay. Our approach involves parameterizing the controls of each player
using distinct recurrent neural networks. These recurrent neural network-based
controls are then trained using a modified version of Brown's fictitious play,
incorporating deep learning techniques. To evaluate the effectiveness of our
methodology, we test it on finance-related problems with known solutions.
Furthermore, we also develop new problems and derive their analytical Nash
equilibrium solutions, which serve as additional benchmarks for assessing the
performance of our proposed deep learning approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06457">Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1">Max Simchowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a></p>
<p>Obtaining rigorous statistical guarantees for generalization under
distribution shift remains an open and active research area. We study a setting
we call combinatorial distribution shift, where (a) under the test- and
training-distributions, the labels $z$ are determined by pairs of features
$(x,y)$, (b) the training distribution has coverage of certain marginal
distributions over $x$ and $y$ separately, but (c) the test distribution
involves examples from a product distribution over $(x,y)$ that is {not}
covered by the training distribution. Focusing on the special case where the
labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z
\mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to
extrapolate to a test distribution domain that is $not$ covered in training,
i.e., achieving bilinear combinatorial extrapolation.
</p>
<p>Our setting generalizes a special case of matrix completion from
missing-not-at-random data, for which all existing results require the
ground-truth matrices to be either exactly low-rank, or to exhibit very sharp
spectral cutoffs. In this work, we develop a series of theoretical results that
enable bilinear combinatorial extrapolation under gradual spectral decay as
observed in typical high-dimensional data, including novel algorithms,
generalization guarantees, and linear-algebraic results. A key tool is a novel
perturbation bound for the rank-$k$ singular value decomposition approximations
between two matrices that depends on the relative spectral gap rather than the
absolute spectral gap, a result that may be of broader independent interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06483">Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+TeBlunthuis_N/0/1/0/all/0/1">Nathan TeBlunthuis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hase_V/0/1/0/all/0/1">Valerie Hase</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1">Chung-Hong Chan</a></p>
<p>Automated classifiers (ACs), often built via supervised machine learning
(SML), can categorize large, statistically powerful samples of data ranging
from text to images and video, and have become widely popular measurement
devices in communication science and related fields. Despite this popularity,
even highly accurate classifiers make errors that cause misclassification bias
and misleading results in downstream analyses-unless such analyses account for
these errors. As we show in a systematic literature review of SML applications,
communication scholars largely ignore misclassification bias. In principle,
existing statistical methods can use "gold standard" validation data, such as
that created by human annotators, to correct misclassification bias and produce
consistent estimates. We introduce and test such methods, including a new
method we design and implement in the R package misclassificationmodels, via
Monte Carlo simulations designed to reveal each method's limitations, which we
also release. Based on our results, we recommend our new error correction
method as it is versatile and efficient. In sum, automated classifiers, even
those below common accuracy standards or making systematic misclassifications,
can be useful for measurement with careful study design and appropriate error
correction methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06496">Microbial Genetic Algorithm-based Black-box Attack against Interpretable Deep Learning Systems. (arXiv:2307.06496v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdukhamidov_E/0/1/0/all/0/1">Eldor Abdukhamidov</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuhamad_M/0/1/0/all/0/1">Mohammed Abuhamad</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_Tin_E/0/1/0/all/0/1">Eric Chan-Tin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuhmed_T/0/1/0/all/0/1">Tamer Abuhmed</a></p>
<p>Deep learning models are susceptible to adversarial samples in white and
black-box environments. Although previous studies have shown high attack
success rates, coupling DNN models with interpretation models could offer a
sense of security when a human expert is involved, who can identify whether a
given sample is benign or malicious. However, in white-box environments,
interpretable deep learning systems (IDLSes) have been shown to be vulnerable
to malicious manipulations. In black-box settings, as access to the components
of IDLSes is limited, it becomes more challenging for the adversary to fool the
system. In this work, we propose a Query-efficient Score-based black-box attack
against IDLSes, QuScore, which requires no knowledge of the target model and
its coupled interpretation model. QuScore is based on transfer-based and
score-based methods by employing an effective microbial genetic algorithm. Our
method is designed to reduce the number of queries necessary to carry out
successful attacks, resulting in a more efficient process. By continuously
refining the adversarial samples created based on feedback scores from the
IDLS, our approach effectively navigates the search space to identify
perturbations that can fool the system. We evaluate the attack's effectiveness
on four CNN models (Inception, ResNet, VGG, DenseNet) and two interpretation
models (CAM, Grad), using both ImageNet and CIFAR datasets. Our results show
that the proposed approach is query-efficient with a high attack success rate
that can reach between 95% and 100% and transferability with an average success
rate of 69% in the ImageNet and CIFAR datasets. Our attack method generates
adversarial examples with attribution maps that resemble benign samples. We
have also demonstrated that our attack is resilient against various
preprocessing defense techniques and can easily be transferred to different DNN
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06501">Hybrid Control Policy for Artificial Pancreas via Ensemble Deep Reinforcement Learning. (arXiv:2307.06501v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1">Wenzhou Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tianyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Luolin Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1">Feng Qi</a></p>
<p>Objective: The artificial pancreas (AP) has shown promising potential in
achieving closed-loop glucose control for individuals with type 1 diabetes
mellitus (T1DM). However, designing an effective control policy for the AP
remains challenging due to the complex physiological processes, delayed insulin
response, and inaccurate glucose measurements. While model predictive control
(MPC) offers safety and stability through the dynamic model and safety
constraints, it lacks individualization and is adversely affected by
unannounced meals. Conversely, deep reinforcement learning (DRL) provides
personalized and adaptive strategies but faces challenges with distribution
shifts and substantial data requirements. Methods: We propose a hybrid control
policy for the artificial pancreas (HyCPAP) to address the above challenges.
HyCPAP combines an MPC policy with an ensemble DRL policy, leveraging the
strengths of both policies while compensating for their respective limitations.
To facilitate faster deployment of AP systems in real-world settings, we
further incorporate meta-learning techniques into HyCPAP, leveraging previous
experience and patient-shared knowledge to enable fast adaptation to new
patients with limited available data. Results: We conduct extensive experiments
using the FDA-accepted UVA/Padova T1DM simulator across three scenarios. Our
approaches achieve the highest percentage of time spent in the desired
euglycemic range and the lowest occurrences of hypoglycemia. Conclusion: The
results clearly demonstrate the superiority of our methods for closed-loop
glucose management in individuals with T1DM. Significance: The study presents
novel control policies for AP systems, affirming the great potential of
proposed methods for efficient closed-loop glucose control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06513">Leveraging Contextual Counterfactuals Toward Belief Calibration. (arXiv:2307.06513v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiuyi/0/1/0/all/0/1">Qiuyi</a> (Richard) <a href="http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1">Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Michael S. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sherol Chen</a></p>
<p>Beliefs and values are increasingly being incorporated into our AI systems
through alignment processes, such as carefully curating data collection
principles or regularizing the loss function used for training. However, the
meta-alignment problem is that these human beliefs are diverse and not aligned
across populations; furthermore, the implicit strength of each belief may not
be well calibrated even among humans, especially when trying to generalize
across contexts. Specifically, in high regret situations, we observe that
contextual counterfactuals and recourse costs are particularly important in
updating a decision maker's beliefs and the strengths to which such beliefs are
held. Therefore, we argue that including counterfactuals is key to an accurate
calibration of beliefs during alignment. To do this, we first segment belief
diversity into two categories: subjectivity (across individuals within a
population) and epistemic uncertainty (within an individual across different
contexts). By leveraging our notion of epistemic uncertainty, we introduce `the
belief calibration cycle' framework to more holistically calibrate this
diversity of beliefs with context-driven counterfactual reasoning by using a
multi-objective optimization. We empirically apply our framework for finding a
Pareto frontier of clustered optimal belief strengths that generalize across
different contexts, demonstrating its efficacy on a toy dataset for credit
decisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06518">Machine Learning practices and infrastructures. (arXiv:2307.06518v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Berman_G/0/1/0/all/0/1">Glen Berman</a></p>
<p>Machine Learning (ML) systems, particularly when deployed in high-stakes
domains, are deeply consequential. They can exacerbate existing inequities,
create new modes of discrimination, and reify outdated social constructs.
Accordingly, the social context (i.e. organisations, teams, cultures) in which
ML systems are developed is a site of active research for the field of AI
ethics, and intervention for policymakers. This paper focuses on one aspect of
social context that is often overlooked: interactions between practitioners and
the tools they rely on, and the role these interactions play in shaping ML
practices and the development of ML systems. In particular, through an
empirical study of questions asked on the Stack Exchange forums, the use of
interactive computing platforms (e.g. Jupyter Notebook and Google Colab) in ML
practices is explored. I find that interactive computing platforms are used in
a host of learning and coordination practices, which constitutes an
infrastructural relationship between interactive computing platforms and ML
practitioners. I describe how ML practices are co-evolving alongside the
development of interactive computing platforms, and highlight how this risks
making invisible aspects of the ML life cycle that AI ethics researchers' have
demonstrated to be particularly salient for the societal impact of deployed ML
systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06521">Artificial Intelligence for Drug Discovery: Are We There Yet?. (arXiv:2307.06521v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasselgren_C/0/1/0/all/0/1">Catrin Hasselgren</a>, <a href="http://arxiv.org/find/cs/1/au:+Oprea_T/0/1/0/all/0/1">Tudor I. Oprea</a></p>
<p>Drug discovery is adapting to novel technologies such as data science,
informatics, and artificial intelligence (AI) to accelerate effective treatment
development while reducing costs and animal experiments. AI is transforming
drug discovery, as indicated by increasing interest from investors, industrial
and academic scientists, and legislators. Successful drug discovery requires
optimizing properties related to pharmacodynamics, pharmacokinetics, and
clinical outcomes. This review discusses the use of AI in the three pillars of
drug discovery: diseases, targets, and therapeutic modalities, with a focus on
small molecule drugs. AI technologies, such as generative chemistry, machine
learning, and multi-property optimization, have enabled several compounds to
enter clinical trials. The scientific community must carefully vet known
information to address the reproducibility crisis. The full potential of AI in
drug discovery can only be realized with sufficient ground truth and
appropriate human intervention at later pipeline stages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06534">DSV: An Alignment Validation Loss for Self-supervised Outlier Model Selection. (arXiv:2307.06534v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1">Jaemin Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yue Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Lingxiao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1">Leman Akoglu</a></p>
<p>Self-supervised learning (SSL) has proven effective in solving various
problems by generating internal supervisory signals. Unsupervised anomaly
detection, which faces the high cost of obtaining true labels, is an area that
can greatly benefit from SSL. However, recent literature suggests that tuning
the hyperparameters (HP) of data augmentation functions is crucial to the
success of SSL-based anomaly detection (SSAD), yet a systematic method for
doing so remains unknown. In this work, we propose DSV (Discordance and
Separability Validation), an unsupervised validation loss to select
high-performing detection models with effective augmentation HPs. DSV captures
the alignment between an augmentation function and the anomaly-generating
mechanism with surrogate losses, which approximate the discordance and
separability of test data, respectively. As a result, the evaluation via DSV
leads to selecting an effective SSAD model exhibiting better alignment, which
results in high detection accuracy. We theoretically derive the degree of
approximation conducted by the surrogate losses and empirically show that DSV
outperforms a wide range of baselines on 21 real-world tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06538">Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems. (arXiv:2307.06538v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1">Ainesh Bakshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Allen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1">Morris Yau</a></p>
<p>Recently Chen and Poor initiated the study of learning mixtures of linear
dynamical systems. While linear dynamical systems already have wide-ranging
applications in modeling time-series data, using mixture models can lead to a
better fit or even a richer understanding of underlying subpopulations
represented in the data. In this work we give a new approach to learning
mixtures of linear dynamical systems that is based on tensor decompositions. As
a result, our algorithm succeeds without strong separation conditions on the
components, and can be used to compete with the Bayes optimal clustering of the
trajectories. Moreover our algorithm works in the challenging
partially-observed setting. Our starting point is the simple but powerful
observation that the classic Ho-Kalman algorithm is a close relative of modern
tensor decomposition methods for learning latent variable models. This gives us
a playbook for how to extend it to work with more complicated generative
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06540">Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A Natural Language Processing Approach. (arXiv:2307.06540v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yufei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Raga_R/0/1/0/all/0/1">Rodolfo C. Raga Jr</a></p>
<p>This study addressed the complex task of sentiment analysis on a dataset of
119,988 original tweets from Weibo using a Convolutional Neural Network (CNN),
offering a new approach to Natural Language Processing (NLP). The data, sourced
from Baidu's PaddlePaddle AI platform, were meticulously preprocessed,
tokenized, and categorized based on sentiment labels. A CNN-based model was
utilized, leveraging word embeddings for feature extraction, and trained to
perform sentiment classification. The model achieved a macro-average F1-score
of approximately 0.73 on the test set, showing balanced performance across
positive, neutral, and negative sentiments. The findings underscore the
effectiveness of CNNs for sentiment analysis tasks, with implications for
practical applications in social media analysis, market research, and policy
studies. The complete experimental content and code have been made publicly
available on the Kaggle data platform for further research and development.
Future work may involve exploring different architectures, such as Recurrent
Neural Networks (RNN) or transformers, or using more complex pre-trained models
like BERT, to further improve the model's ability to understand linguistic
nuances and context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06541">On the Effective Horizon of Inverse Reinforcement Learning. (arXiv:2307.06541v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yiqing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1">Finale Doshi-Velez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1">David Hsu</a></p>
<p>Inverse reinforcement learning (IRL) algorithms often rely on (forward)
reinforcement learning or planning over a given time horizon to compute an
approximately optimal policy for a hypothesized reward function and then match
this policy with expert demonstrations. The time horizon plays a critical role
in determining both the accuracy of reward estimate and the computational
efficiency of IRL algorithms. Interestingly, an effective time horizon shorter
than the ground-truth value often produces better results faster. This work
formally analyzes this phenomenon and provides an explanation: the time horizon
controls the complexity of an induced policy class and mitigates overfitting
with limited data. This analysis leads to a principled choice of the effective
horizon for IRL. It also prompts us to reexamine the classic IRL formulation:
it is more natural to learn jointly the reward and the effective horizon
together rather than the reward alone with a given horizon. Our experimental
results confirm the theoretical analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06547">Full-resolution Lung Nodule Segmentation from Chest X-ray Images using Residual Encoder-Decoder Networks. (arXiv:2307.06547v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Horry_M/0/1/0/all/0/1">Michael James Horry</a>, <a href="http://arxiv.org/find/eess/1/au:+Chakraborty_S/0/1/0/all/0/1">Subrata Chakraborty</a>, <a href="http://arxiv.org/find/eess/1/au:+Pradhan_B/0/1/0/all/0/1">Biswajeet Pradhan</a>, <a href="http://arxiv.org/find/eess/1/au:+Paul_M/0/1/0/all/0/1">Manoranjan Paul</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_J/0/1/0/all/0/1">Jing Zhu</a>, <a href="http://arxiv.org/find/eess/1/au:+Barua_P/0/1/0/all/0/1">Prabal Datta Barua</a>, <a href="http://arxiv.org/find/eess/1/au:+Acharya_U/0/1/0/all/0/1">U. Rajendra Acharya</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1">Fang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_J/0/1/0/all/0/1">Jianlong Zhou</a></p>
<p>Lung cancer is the leading cause of cancer death and early diagnosis is
associated with a positive prognosis. Chest X-ray (CXR) provides an inexpensive
imaging mode for lung cancer diagnosis. Suspicious nodules are difficult to
distinguish from vascular and bone structures using CXR. Computer vision has
previously been proposed to assist human radiologists in this task, however,
leading studies use down-sampled images and computationally expensive methods
with unproven generalization. Instead, this study localizes lung nodules using
efficient encoder-decoder neural networks that process full resolution images
to avoid any signal loss resulting from down-sampling. Encoder-decoder networks
are trained and tested using the JSRT lung nodule dataset. The networks are
used to localize lung nodules from an independent external CXR dataset.
Sensitivity and false positive rates are measured using an automated framework
to eliminate any observer subjectivity. These experiments allow for the
determination of the optimal network depth, image resolution and pre-processing
pipeline for generalized lung nodule localization. We find that nodule
localization is influenced by subtlety, with more subtle nodules being detected
in earlier training epochs. Therefore, we propose a novel self-ensemble model
from three consecutive epochs centered on the validation optimum. This ensemble
achieved a sensitivity of 85% in 10-fold internal testing with false positives
of 8 per image. A sensitivity of 81% is achieved at a false positive rate of 6
following morphological false positive reduction. This result is comparable to
more computationally complex systems based on linear and spatial filtering, but
with a sub-second inference time that is faster than other methods. The
proposed algorithm achieved excellent generalization results against an
external dataset with sensitivity of 77% at a false positive rate of 7.6.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06555">Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianfeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hongkai Zhao</a></p>
<p>This paper explores the expressive power of deep neural networks for a
diverse range of activation functions. An activation function set $\mathscr{A}$
is defined to encompass the majority of commonly used activation functions,
such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$,
$\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$,
$\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$,
$\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and
$\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in
\mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be
approximated to arbitrary precision by a $\varrho$-activated network of width
$6N$ and depth $2L$ on any bounded set. This finding enables the extension of
most approximation results achieved with $\mathtt{ReLU}$ networks to a wide
variety of other activation functions, at the cost of slightly larger
constants.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06556">Metal Oxide-based Gas Sensor Array for the VOCs Analysis in Complex Mixtures using Machine Learning. (arXiv:2307.06556v1 [physics.app-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Singh_S/0/1/0/all/0/1">Shivam Singh</a>, <a href="http://arxiv.org/find/physics/1/au:+S_S/0/1/0/all/0/1">Sajana S</a>, <a href="http://arxiv.org/find/physics/1/au:+Poornima/0/1/0/all/0/1">Poornima</a>, <a href="http://arxiv.org/find/physics/1/au:+Sreelekha_G/0/1/0/all/0/1">Gajje Sreelekha</a>, <a href="http://arxiv.org/find/physics/1/au:+Adak_C/0/1/0/all/0/1">Chandranath Adak</a>, <a href="http://arxiv.org/find/physics/1/au:+Shukla_R/0/1/0/all/0/1">Rajendra P. Shukla</a>, <a href="http://arxiv.org/find/physics/1/au:+Kamble_V/0/1/0/all/0/1">Vinayak Kamble</a></p>
<p>Detection of Volatile Organic Compounds (VOCs) from the breath is becoming a
viable route for the early detection of diseases non-invasively. This paper
presents a sensor array with three metal oxide electrodes that can use machine
learning methods to identify four distinct VOCs in a mixture. The metal oxide
sensor array was subjected to various VOC concentrations, including ethanol,
acetone, toluene and chloroform. The dataset obtained from individual gases and
their mixtures were analyzed using multiple machine learning algorithms, such
as Random Forest (RF), K-Nearest Neighbor (KNN), Decision Tree, Linear
Regression, Logistic Regression, Naive Bayes, Linear Discriminant Analysis,
Artificial Neural Network, and Support Vector Machine. KNN and RF have shown
more than 99% accuracy in classifying different varying chemicals in the gas
mixtures. In regression analysis, KNN has delivered the best results with R2
value of more than 0.99 and LOD of 0.012, 0.015, 0.014 and 0.025 PPM for
predicting the concentrations of varying chemicals Acetone, Toluene, Ethanol,
and Chloroform, respectively in complex mixtures. Therefore, it is demonstrated
that the array utilizing the provided algorithms can classify and predict the
concentrations of the four gases simultaneously for disease diagnosis and
treatment monitoring.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06564">Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach. (arXiv:2307.06564v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shoush_M/0/1/0/all/0/1">Mahmoud Shoush</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1">Marlon Dumas</a></p>
<p>Prescriptive process monitoring methods seek to optimize the performance of
business processes by triggering interventions at runtime, thereby increasing
the probability of positive case outcomes. These interventions are triggered
according to an intervention policy. Reinforcement learning has been put
forward as an approach to learning intervention policies through trial and
error. Existing approaches in this space assume that the number of resources
available to perform interventions in a process is unlimited, an unrealistic
assumption in practice. This paper argues that, in the presence of resource
constraints, a key dilemma in the field of prescriptive process monitoring is
to trigger interventions based not only on predictions of their necessity,
timeliness, or effect but also on the uncertainty of these predictions and the
level of resource utilization. Indeed, committing scarce resources to an
intervention when the necessity or effects of this intervention are highly
uncertain may intuitively lead to suboptimal intervention effects. Accordingly,
the paper proposes a reinforcement learning approach for prescriptive process
monitoring that leverages conformal prediction techniques to consider the
uncertainty of the predictions upon which an intervention decision is based. An
evaluation using real-life datasets demonstrates that explicitly modeling
uncertainty using conformal predictions helps reinforcement learning agents
converge towards policies with higher net intervention gain
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06565">Efficient SGD Neural Network Training via Sublinear Activated Neuron Identification. (arXiv:2307.06565v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1">Lianke Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuanyuan Yang</a></p>
<p>Deep learning has been widely used in many fields, but the model training
process usually consumes massive computational resources and time. Therefore,
designing an efficient neural network training method with a provable
convergence guarantee is a fundamental and important research question. In this
paper, we present a static half-space report data structure that consists of a
fully connected two-layer neural network for shifted ReLU activation to enable
activated neuron identification in sublinear time via geometric search. We also
prove that our algorithm can converge in $O(M^2/\epsilon^2)$ time with network
size quadratic in the coefficient norm upper bound $M$ and error term
$\epsilon$.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06581">Deep Neural Networks for Semiparametric Frailty Models via H-likelihood. (arXiv:2307.06581v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1">Hangbin Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+HA_I/0/1/0/all/0/1">IL DO HA</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1">Youngjo Lee</a></p>
<p>For prediction of clustered time-to-event data, we propose a new deep neural
network based gamma frailty model (DNN-FM). An advantage of the proposed model
is that the joint maximization of the new h-likelihood provides maximum
likelihood estimators for fixed parameters and best unbiased predictors for
random frailties. Thus, the proposed DNN-FM is trained by using a negative
profiled h-likelihood as a loss function, constructed by profiling out the
non-parametric baseline hazard. Experimental studies show that the proposed
method enhances the prediction performance of the existing methods. A real data
analysis shows that the inclusion of subject-specific frailties helps to
improve prediction of the DNN based Cox model (DNN-Cox).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06608">Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks. (arXiv:2307.06608v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1">Jitao Sang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1">Qi Yi</a></p>
<p>Recently, the no-box adversarial attack, in which the attacker lacks access
to the model's architecture, weights, and training data, become the most
practical and challenging attack setup. However, there is an unawareness of the
potential and flexibility inherent in the surrogate model selection process on
no-box setting. Inspired by the burgeoning interest in utilizing foundational
models to address downstream tasks, this paper adopts an innovative idea that
1) recasting adversarial attack as a downstream task. Specifically, image noise
generation to meet the emerging trend and 2) introducing foundational models as
surrogate models. Harnessing the concept of non-robust features, we elaborate
on two guiding principles for surrogate model selection to explain why the
foundational model is an optimal choice for this role. However, paradoxically,
we observe that these foundational models underperform. Analyzing this
unexpected behavior within the feature space, we attribute the lackluster
performance of foundational models (e.g., CLIP) to their significant
representational capacity and, conversely, their lack of discriminative
prowess. To mitigate this issue, we propose the use of a margin-based loss
strategy for the fine-tuning of foundational models on target images. The
experimental results verify that our approach, which employs the basic Fast
Gradient Sign Method (FGSM) attack algorithm, outstrips the performance of
other, more convoluted algorithms. We conclude by advocating for the research
community to consider surrogate models as crucial determinants in the
effectiveness of adversarial attacks in no-box settings. The implications of
our work bear relevance for improving the efficacy of such adversarial attacks
and the overall robustness of AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06618">Learning IMM Filter Parameters from Measurements using Gradient Descent. (arXiv:2307.06618v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brandenburger_A/0/1/0/all/0/1">Andr&#xe9; Brandenburger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_F/0/1/0/all/0/1">Folker Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Charlish_A/0/1/0/all/0/1">Alexander Charlish</a></p>
<p>The performance of data fusion and tracking algorithms often depends on
parameters that not only describe the sensor system, but can also be
task-specific. While for the sensor system tuning these variables is
time-consuming and mostly requires expert knowledge, intrinsic parameters of
targets under track can even be completely unobservable until the system is
deployed. With state-of-the-art sensor systems growing more and more complex,
the number of parameters naturally increases, necessitating the automatic
optimization of the model variables. In this paper, the parameters of an
interacting multiple model (IMM) filter are optimized solely using
measurements, thus without necessity for any ground-truth data. The resulting
method is evaluated through an ablation study on simulated data, where the
trained model manages to match the performance of a filter parametrized with
ground-truth values.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06620">Online Distributed Learning with Quantized Finite-Time Coordination. (arXiv:2307.06620v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bastianello_N/0/1/0/all/0/1">Nicola Bastianello</a>, <a href="http://arxiv.org/find/cs/1/au:+Rikos_A/0/1/0/all/0/1">Apostolos I. Rikos</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1">Karl H. Johansson</a></p>
<p>In this paper we consider online distributed learning problems. Online
distributed learning refers to the process of training learning models on
distributed data sources. In our setting a set of agents need to cooperatively
train a learning model from streaming data. Differently from federated
learning, the proposed approach does not rely on a central server but only on
peer-to-peer communications among the agents. This approach is often used in
scenarios where data cannot be moved to a centralized location due to privacy,
security, or cost reasons. In order to overcome the absence of a central
server, we propose a distributed algorithm that relies on a quantized,
finite-time coordination protocol to aggregate the locally trained models.
Furthermore, our algorithm allows for the use of stochastic gradients during
local training. Stochastic gradients are computed using a randomly sampled
subset of the local training data, which makes the proposed algorithm more
efficient and scalable than traditional gradient descent. In our paper, we
analyze the performance of the proposed algorithm in terms of the mean distance
from the online solution. Finally, we present numerical results for a logistic
regression task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06622">Quantum Autoencoders for Learning Quantum Channel Codes. (arXiv:2307.06622v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Rathi_L/0/1/0/all/0/1">Lakshika Rathi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+DiAdamo_S/0/1/0/all/0/1">Stephen DiAdamo</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Shabani_A/0/1/0/all/0/1">Alireza Shabani</a></p>
<p>This work investigates the application of quantum machine learning techniques
for classical and quantum communication across different qubit channel models.
By employing parameterized quantum circuits and a flexible channel noise model,
we develop a machine learning framework to generate quantum channel codes and
evaluate their effectiveness. We explore classical, entanglement-assisted, and
quantum communication scenarios within our framework. Applying it to various
quantum channel models as proof of concept, we demonstrate strong performance
in each case. Our results highlight the potential of quantum machine learning
in advancing research on quantum communication systems, enabling a better
understanding of capacity bounds under modulation constraints, various
communication settings, and diverse channel models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06631">Frameless Graph Knowledge Distillation. (arXiv:2307.06631v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiqi Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a></p>
<p>Knowledge distillation (KD) has shown great potential for transferring
knowledge from a complex teacher model to a simple student model in which the
heavy learning task can be accomplished efficiently and without losing too much
prediction accuracy. Recently, many attempts have been made by applying the KD
mechanism to the graph representation learning models such as graph neural
networks (GNNs) to accelerate the model's inference speed via student models.
However, many existing KD-based GNNs utilize MLP as a universal approximator in
the student model to imitate the teacher model's process without considering
the graph knowledge from the teacher model. In this work, we provide a KD-based
framework on multi-scaled GNNs, known as graph framelet, and prove that by
adequately utilizing the graph knowledge in a multi-scaled manner provided by
graph framelet decomposition, the student model is capable of adapting both
homophilic and heterophilic graphs and has the potential of alleviating the
over-squashing issue with a simple yet effectively graph surgery. Furthermore,
we show how the graph knowledge supplied by the teacher is learned and digested
by the student model via both algebra and geometry. Comprehensive experiments
show that our proposed model can generate learning accuracy identical to or
even surpass the teacher model while maintaining the high speed of inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06640">Discovering How Agents Learn Using Few Data. (arXiv:2307.06640v1 [cs.GT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sakos_I/0/1/0/all/0/1">Iosif Sakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Varvitsiotis_A/0/1/0/all/0/1">Antonios Varvitsiotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1">Georgios Piliouras</a></p>
<p>Decentralized learning algorithms are an essential tool for designing
multi-agent systems, as they enable agents to autonomously learn from their
experience and past interactions. In this work, we propose a theoretical and
algorithmic framework for real-time identification of the learning dynamics
that govern agent behavior using a short burst of a single system trajectory.
Our method identifies agent dynamics through polynomial regression, where we
compensate for limited data by incorporating side-information constraints that
capture fundamental assumptions or expectations about agent behavior. These
constraints are enforced computationally using sum-of-squares optimization,
leading to a hierarchy of increasingly better approximations of the true agent
dynamics. Extensive experiments demonstrated that our approach, using only 5
samples from a short run of a single trajectory, accurately recovers the true
dynamics across various benchmarks, including equilibrium selection and
prediction of chaotic systems up to 10 Lyapunov times. These findings suggest
that our approach has significant potential to support effective policy and
decision-making in strategic multi-agent systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06644">An Improved Uniform Convergence Bound with Fat-Shattering Dimension. (arXiv:2307.06644v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Colomboni_R/0/1/0/all/0/1">Roberto Colomboni</a>, <a href="http://arxiv.org/find/cs/1/au:+Esposito_E/0/1/0/all/0/1">Emmanuel Esposito</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1">Andrea Paudice</a></p>
<p>The fat-shattering dimension characterizes the uniform convergence property
of real-valued functions. The state-of-the-art upper bounds feature a
multiplicative squared logarithmic factor on the sample complexity, leaving an
open gap with the existing lower bound. We provide an improved uniform
convergence bound that closes this gap.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06645">Multivariate Time Series characterization and forecasting of VoIP traffic in real mobile networks. (arXiv:2307.06645v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mauro_M/0/1/0/all/0/1">Mario Di Mauro</a>, <a href="http://arxiv.org/find/cs/1/au:+Galatro_G/0/1/0/all/0/1">Giovanni Galatro</a>, <a href="http://arxiv.org/find/cs/1/au:+Postiglione_F/0/1/0/all/0/1">Fabio Postiglione</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Wei Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liotta_A/0/1/0/all/0/1">Antonio Liotta</a></p>
<p>Predicting the behavior of real-time traffic (e.g., VoIP) in mobility
scenarios could help the operators to better plan their network infrastructures
and to optimize the allocation of resources. Accordingly, in this work the
authors propose a forecasting analysis of crucial QoS/QoE descriptors (some of
which neglected in the technical literature) of VoIP traffic in a real mobile
environment. The problem is formulated in terms of a multivariate time series
analysis. Such a formalization allows to discover and model the temporal
relationships among various descriptors and to forecast their behaviors for
future periods. Techniques such as Vector Autoregressive models and machine
learning (deep-based and tree-based) approaches are employed and compared in
terms of performance and time complexity, by reframing the multivariate time
series problem into a supervised learning one. Moreover, a series of auxiliary
analyses (stationarity, orthogonal impulse responses, etc.) are performed to
discover the analytical structure of the time series and to provide deep
insights about their relationships. The whole theoretical analysis has an
experimental counterpart since a set of trials across a real-world LTE-Advanced
environment has been performed to collect, post-process and analyze about
600,000 voice packets, organized per flow and differentiated per codec.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06688">Aeolus Ocean -- A simulation environment for the autonomous COLREG-compliant navigation of Unmanned Surface Vehicles using Deep Reinforcement Learning and Maritime Object Detection. (arXiv:2307.06688v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vekinis_A/0/1/0/all/0/1">Andrew Alexander Vekinis</a>, <a href="http://arxiv.org/find/cs/1/au:+Perantonis_S/0/1/0/all/0/1">Stavros Perantonis</a></p>
<p>Heading towards navigational autonomy in unmanned surface vehicles (USVs) in
the maritime sector can fundamentally lead towards safer waters as well as
reduced operating costs, while also providing a range of exciting new
capabilities for oceanic research, exploration and monitoring. However,
achieving such a goal is challenging. USV control systems must, safely and
reliably, be able to adhere to the international regulations for preventing
collisions at sea (COLREGs) in encounters with other vessels as they navigate
to a given waypoint while being affected by realistic weather conditions,
either during the day or at night. To deal with the multitude of possible
scenarios, it is critical to have a virtual environment that is able to
replicate the realistic operating conditions USVs will encounter, before they
can be implemented in the real world. Such "digital twins" form the foundations
upon which Deep Reinforcement Learning (DRL) and Computer Vision (CV)
algorithms can be used to develop and guide USV control systems. In this paper
we describe the novel development of a COLREG-compliant DRL-based collision
avoidant navigational system with CV-based awareness in a realistic ocean
simulation environment. The performance of the trained autonomous Agents
resulting from this approach is evaluated in several successful navigations to
set waypoints in both open sea and coastal encounters with other vessels. A
binary executable version of the simulator with trained agents is available at
https://github.com/aavek/Aeolus-Ocean
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06693">Ageing Analysis of Embedded SRAM on a Large-Scale Testbed Using Machine Learning. (arXiv:2307.06693v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lanzieri_L/0/1/0/all/0/1">Leandro Lanzieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kietzmann_P/0/1/0/all/0/1">Peter Kietzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fey_G/0/1/0/all/0/1">Goerschwin Fey</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlarb_H/0/1/0/all/0/1">Holger Schlarb</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_T/0/1/0/all/0/1">Thomas C. Schmidt</a></p>
<p>Ageing detection and failure prediction are essential in many Internet of
Things (IoT) deployments, which operate huge quantities of embedded devices
unattended in the field for years. In this paper, we present a large-scale
empirical analysis of natural SRAM wear-out using 154 boards from a
general-purpose testbed. Starting from SRAM initialization bias, which each
node can easily collect at startup, we apply various metrics for feature
extraction and experiment with common machine learning methods to predict the
age of operation for this node. Our findings indicate that even though ageing
impacts are subtle, our indicators can well estimate usage times with an $R^2$
score of 0.77 and a mean error of 24% using regressors, and with an F1 score
above 0.6 for classifiers applying a six-months resolution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06698">IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation. (arXiv:2307.06698v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thanapalasingam_T/0/1/0/all/0/1">Thiviyan Thanapalasingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Krieken_E/0/1/0/all/0/1">Emile van Krieken</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloem_P/0/1/0/all/0/1">Peter Bloem</a>, <a href="http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1">Paul Groth</a></p>
<p>Knowledge Graph Embedding (KGE) models are used to learn continuous
representations of entities and relations. A key task in the literature is
predicting missing links between entities. However, Knowledge Graphs are not
just sets of links but also have semantics underlying their structure.
Semantics is crucial in several downstream tasks, such as query answering or
reasoning. We introduce the subgraph inference task, where a model has to
generate likely and semantically valid subgraphs. We propose IntelliGraphs, a
set of five new Knowledge Graph datasets. The IntelliGraphs datasets contain
subgraphs with semantics expressed in logical rules for evaluating subgraph
inference. We also present the dataset generator that produced the synthetic
datasets. We designed four novel baseline models, which include three models
based on traditional KGEs. We evaluate their expressiveness and show that these
models cannot capture the semantics. We believe this benchmark will encourage
the development of machine learning models that emphasize semantic
understanding.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06701">S-HR-VQVAE: Sequential Hierarchical Residual Learning Vector Quantized Variational Autoencoder for Video Prediction. (arXiv:2307.06701v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Adiban_M/0/1/0/all/0/1">Mohammad Adiban</a>, <a href="http://arxiv.org/find/cs/1/au:+Stefanov_K/0/1/0/all/0/1">Kalin Stefanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1">Giampiero Salvi</a></p>
<p>We address the video prediction task by putting forth a novel model that
combines (i) our recently proposed hierarchical residual vector quantized
variational autoencoder (HR-VQVAE), and (ii) a novel spatiotemporal PixelCNN
(ST-PixelCNN). We refer to this approach as a sequential hierarchical residual
learning vector quantized variational autoencoder (S-HR-VQVAE). By leveraging
the intrinsic capabilities of HR-VQVAE at modeling still images with a
parsimonious representation, combined with the ST-PixelCNN's ability at
handling spatiotemporal information, S-HR-VQVAE can better deal with chief
challenges in video prediction. These include learning spatiotemporal
information, handling high dimensional data, combating blurry prediction, and
implicit modeling of physical characteristics. Extensive experimental results
on the KTH Human Action and Moving-MNIST tasks demonstrate that our model
compares favorably against top video prediction techniques both in quantitative
and qualitative evaluations despite a much smaller model size. Finally, we
boost S-HR-VQVAE by proposing a novel training method to jointly estimate the
HR-VQVAE and ST-PixelCNN parameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06709">GRAN is superior to GraphRNN: node orderings, kernel- and graph embeddings-based metrics for graph generators. (arXiv:2307.06709v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Touat_O/0/1/0/all/0/1">Ousmane Touat</a>, <a href="http://arxiv.org/find/cs/1/au:+Stier_J/0/1/0/all/0/1">Julian Stier</a>, <a href="http://arxiv.org/find/cs/1/au:+Portier_P/0/1/0/all/0/1">Pierre-Edouard Portier</a>, <a href="http://arxiv.org/find/cs/1/au:+Granitzer_M/0/1/0/all/0/1">Michael Granitzer</a></p>
<p>A wide variety of generative models for graphs have been proposed. They are
used in drug discovery, road networks, neural architecture search, and program
synthesis. Generating graphs has theoretical challenges, such as isomorphic
representations -- evaluating how well a generative model performs is
difficult. Which model to choose depending on the application domain?
</p>
<p>We extensively study kernel-based metrics on distributions of graph
invariants and manifold-based and kernel-based metrics in graph embedding
space. Manifold-based metrics outperform kernel-based metrics in embedding
space. We use these metrics to compare GraphRNN and GRAN, two well-known
generative models for graphs, and unveil the influence of node orderings. It
shows the superiority of GRAN over GraphRNN - further, our proposed adaptation
of GraphRNN with a depth-first search ordering is effective for small-sized
graphs.
</p>
<p>A guideline on good practices regarding dataset selection and node feature
initialization is provided. Our work is accompanied by open-source code and
reproducible experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06713">Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Estienne_L/0/1/0/all/0/1">Lautaro Estienne</a></p>
<p>A wide variety of natural language tasks are currently being addressed with
large-scale language models (LLMs). These models are usually trained with a
very large amount of unsupervised text data and adapted to perform a downstream
natural language task using methods like fine-tuning, calibration or in-context
learning. In this work, we propose an approach to adapt the prior class
distribution to perform text classification tasks without the need for labelled
samples and only few in-domain sample queries. The proposed approach treats the
LLM as a black box, adding a stage where the model posteriors are calibrated to
the task. Results show that these methods outperform the un-adapted model for
different number of training shots in the prompt and a previous approach were
calibration is performed without using any adaptation data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06721">Why Guided Dialog Policy Learning performs well? Understanding the role of adversarial learning and its alternative. (arXiv:2307.06721v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shimoyama_S/0/1/0/all/0/1">Sho Shimoyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Morimura_T/0/1/0/all/0/1">Tetsuro Morimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_K/0/1/0/all/0/1">Kenshi Abe</a>, <a href="http://arxiv.org/find/cs/1/au:+Takamichi_T/0/1/0/all/0/1">Toda Takamichi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomomatsu_Y/0/1/0/all/0/1">Yuta Tomomatsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masakazu Sugiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Hentona_A/0/1/0/all/0/1">Asahi Hentona</a>, <a href="http://arxiv.org/find/cs/1/au:+Azuma_Y/0/1/0/all/0/1">Yuuki Azuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ninomiya_H/0/1/0/all/0/1">Hirotaka Ninomiya</a></p>
<p>Dialog policies, which determine a system's action based on the current state
at each dialog turn, are crucial to the success of the dialog. In recent years,
reinforcement learning (RL) has emerged as a promising option for dialog policy
learning (DPL). In RL-based DPL, dialog policies are updated according to
rewards. The manual construction of fine-grained rewards, such as
state-action-based ones, to effectively guide the dialog policy is challenging
in multi-domain task-oriented dialog scenarios with numerous state-action pair
combinations. One way to estimate rewards from collected data is to train the
reward estimator and dialog policy simultaneously using adversarial learning
(AL). Although this method has demonstrated superior performance
experimentally, it is fraught with the inherent problems of AL, such as mode
collapse. This paper first identifies the role of AL in DPL through detailed
analyses of the objective functions of dialog policy and reward estimator.
Next, based on these analyses, we propose a method that eliminates AL from
reward estimation and DPL while retaining its advantages. We evaluate our
method using MultiWOZ, a multi-domain task-oriented dialog corpus.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06723">Breaking 3-Factor Approximation for Correlation Clustering in Polylogarithmic Rounds. (arXiv:2307.06723v1 [cs.DS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1">Nairen Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shang-En Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hsin-Hao Su</a></p>
<p>In this paper, we study parallel algorithms for the correlation clustering
problem, where every pair of two different entities is labeled with similar or
dissimilar. The goal is to partition the entities into clusters to minimize the
number of disagreements with the labels. Currently, all efficient parallel
algorithms have an approximation ratio of at least 3. In comparison with the
$1.994+\epsilon$ ratio achieved by polynomial-time sequential algorithms
[CLN22], a significant gap exists.
</p>
<p>We propose the first poly-logarithmic depth parallel algorithm that achieves
a better approximation ratio than 3. Specifically, our algorithm computes a
$(2.4+\epsilon)$-approximate solution and uses $\tilde{O}(m^{1.5})$ work.
Additionally, it can be translated into a $\tilde{O}(m^{1.5})$-time sequential
algorithm and a poly-logarithmic rounds sublinear-memory MPC algorithm with
$\tilde{O}(m^{1.5})$ total memory.
</p>
<p>Our approach is inspired by Awerbuch, Khandekar, and Rao's [AKR12]
length-constrained multi-commodity flow algorithm, where we develop an
efficient parallel algorithm to solve a truncated correlation clustering linear
program of Charikar, Guruswami, and Wirth [CGW05]. Then we show the solution of
the truncated linear program can be rounded with a factor of at most 2.4 loss
by using the framework of [CMSY15]. Such a rounding framework can then be
implemented using parallel pivot-based approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06736">MPR-Net:Multi-Scale Pattern Reproduction Guided Universality Time Series Interpretable Forecasting. (arXiv:2307.06736v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tianlong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuemei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Caiming Zhang</a></p>
<p>Time series forecasting has received wide interest from existing research due
to its broad applications and inherent challenging. The research challenge lies
in identifying effective patterns in historical series and applying them to
future forecasting. Advanced models based on point-wise connected MLP and
Transformer architectures have strong fitting power, but their secondary
computational complexity limits practicality. Additionally, those structures
inherently disrupt the temporal order, reducing the information utilization and
making the forecasting process uninterpretable. To solve these problems, this
paper proposes a forecasting model, MPR-Net. It first adaptively decomposes
multi-scale historical series patterns using convolution operation, then
constructs a pattern extension forecasting method based on the prior knowledge
of pattern reproduction, and finally reconstructs future patterns into future
series using deconvolution operation. By leveraging the temporal dependencies
present in the time series, MPR-Net not only achieves linear time complexity,
but also makes the forecasting process interpretable. By carrying out
sufficient experiments on more than ten real data sets of both short and long
term forecasting tasks, MPR-Net achieves the state of the art forecasting
performance, as well as good generalization and robustness performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06742">Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling Services: A Multi-Agent Hierarchical Reinforcement Learning Approach. (arXiv:2307.06742v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1">Jinhua Si</a>, <a href="http://arxiv.org/find/eess/1/au:+He_F/0/1/0/all/0/1">Fang He</a>, <a href="http://arxiv.org/find/eess/1/au:+Lin_X/0/1/0/all/0/1">Xi Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_X/0/1/0/all/0/1">Xindi Tang</a></p>
<p>The integrated development of city clusters has given rise to an increasing
demand for intercity travel. Intercity ride-pooling service exhibits
considerable potential in upgrading traditional intercity bus services by
implementing demand-responsive enhancements. Nevertheless, its online
operations suffer the inherent complexities due to the coupling of vehicle
resource allocation among cities and pooled-ride vehicle routing. To tackle
these challenges, this study proposes a two-level framework designed to
facilitate online fleet management. Specifically, a novel multi-agent feudal
reinforcement learning model is proposed at the upper level of the framework to
cooperatively assign idle vehicles to different intercity lines, while the
lower level updates the routes of vehicles using an adaptive large neighborhood
search heuristic. Numerical studies based on the realistic dataset of Xiamen
and its surrounding cities in China show that the proposed framework
effectively mitigates the supply and demand imbalances, and achieves
significant improvement in both the average daily system profit and order
fulfillment ratio.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06753">Cramer Type Distances for Learning Gaussian Mixture Models by Gradient Descent. (arXiv:2307.06753v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruichong Zhang</a></p>
<p>The learning of Gaussian Mixture Models (also referred to simply as GMMs)
plays an important role in machine learning. Known for their expressiveness and
interpretability, Gaussian mixture models have a wide range of applications,
from statistics, computer vision to distributional reinforcement learning.
However, as of today, few known algorithms can fit or learn these models, some
of which include Expectation-Maximization algorithms and Sliced Wasserstein
Distance. Even fewer algorithms are compatible with gradient descent, the
common learning process for neural networks.
</p>
<p>In this paper, we derive a closed formula of two GMMs in the univariate,
one-dimensional case, then propose a distance function called Sliced Cram\'er
2-distance for learning general multivariate GMMs. Our approach has several
advantages over many previous methods. First, it has a closed-form expression
for the univariate case and is easy to compute and implement using common
machine learning libraries (e.g., PyTorch and TensorFlow). Second, it is
compatible with gradient descent, which enables us to integrate GMMs with
neural networks seamlessly. Third, it can fit a GMM not only to a set of data
points, but also to another GMM directly, without sampling from the target
model. And fourth, it has some theoretical guarantees like global gradient
boundedness and unbiased sampling gradient. These features are especially
useful for distributional reinforcement learning and Deep Q Networks, where the
goal is to learn a distribution over future rewards. We will also construct a
Gaussian Mixture Distributional Deep Q Network as a toy example to demonstrate
its effectiveness. Compared with previous models, this model is parameter
efficient in terms of representing a distribution and possesses better
interpretability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06760">Privacy-Utility Trade-offs in Neural Networks for Medical Population Graphs: Insights from Differential Privacy and Graph Structure. (arXiv:2307.06760v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mueller_T/0/1/0/all/0/1">Tamara T. Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Chevli_M/0/1/0/all/0/1">Maulik Chevli</a>, <a href="http://arxiv.org/find/cs/1/au:+Daigavane_A/0/1/0/all/0/1">Ameya Daigavane</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a></p>
<p>We initiate an empirical investigation into differentially private graph
neural networks on population graphs from the medical domain by examining
privacy-utility trade-offs at different privacy levels on both real-world and
synthetic datasets and performing auditing through membership inference
attacks. Our findings highlight the potential and the challenges of this
specific DP application area. Moreover, we find evidence that the underlying
graph structure constitutes a potential factor for larger performance gaps by
showing a correlation between the degree of graph homophily and the accuracy of
the trained model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06771">Generalizing Supervised Deep Learning MRI Reconstruction to Multiple and Unseen Contrasts using Meta-Learning Hypernetworks. (arXiv:2307.06771v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ramanarayanan_S/0/1/0/all/0/1">Sriprabha Ramanarayanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Palla_A/0/1/0/all/0/1">Arun Palla</a>, <a href="http://arxiv.org/find/eess/1/au:+Ram_K/0/1/0/all/0/1">Keerthi Ram</a>, <a href="http://arxiv.org/find/eess/1/au:+Sivaprakasam_M/0/1/0/all/0/1">Mohanasankar Sivaprakasam</a></p>
<p>Meta-learning has recently been an emerging data-efficient learning technique
for various medical imaging operations and has helped advance contemporary deep
learning models. Furthermore, meta-learning enhances the knowledge
generalization of the imaging tasks by learning both shared and discriminative
weights for various configurations of imaging tasks. However, existing
meta-learning models attempt to learn a single set of weight initializations of
a neural network that might be restrictive for multimodal data. This work aims
to develop a multimodal meta-learning model for image reconstruction, which
augments meta-learning with evolutionary capabilities to encompass diverse
acquisition settings of multimodal data. Our proposed model called KM-MAML
(Kernel Modulation-based Multimodal Meta-Learning), has hypernetworks that
evolve to generate mode-specific weights. These weights provide the
mode-specific inductive bias for multiple modes by re-calibrating each kernel
of the base network for image reconstruction via a low-rank kernel modulation
operation. We incorporate gradient-based meta-learning (GBML) in the contextual
space to update the weights of the hypernetworks for different modes. The
hypernetworks and the reconstruction network in the GBML setting provide
discriminative mode-specific features and low-level image features,
respectively. Experiments on multi-contrast MRI reconstruction show that our
model, (i) exhibits superior reconstruction performance over joint training,
other meta-learning methods, and context-specific MRI reconstruction methods,
and (ii) better adaptation capabilities with improvement margins of 0.5 dB in
PSNR and 0.01 in SSIM. Besides, a representation analysis with U-Net shows that
kernel modulation infuses 80% of mode-specific representation changes in the
high-resolution layers. Our source code is available at
https://github.com/sriprabhar/KM-MAML/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06775">A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feldman_J/0/1/0/all/0/1">Jonathan Feldman</a></p>
<p>Over the last decade, there has been a vast increase in eating disorder
diagnoses and eating disorder-attributed deaths, reaching their zenith during
the Covid-19 pandemic. This immense growth derived in part from the stressors
of the pandemic but also from increased exposure to social media, which is rife
with content that promotes eating disorders. Such content can induce eating
disorders in viewers. This study aimed to create a multimodal deep learning
model capable of determining whether a given social media post promotes eating
disorders based on a combination of visual and textual data. A labeled dataset
of Tweets was collected from Twitter, upon which twelve deep learning models
were trained and tested. Based on model performance, the most effective deep
learning model was the multimodal fusion of the RoBERTa natural language
processing model and the MaxViT image classification model, attaining accuracy
and F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion
model, deployed to classify an unlabeled dataset of posts from the social media
sites Tumblr and Reddit, generated similar classifications as previous research
studies that did not employ artificial intelligence, showing that artificial
intelligence can develop insights congruent to those of researchers.
Additionally, the model was used to conduct a time-series analysis of yet
unseen Tweets from eight Twitter hashtags, uncovering that the relative
abundance of pro-eating disorder content has decreased drastically. However,
since approximately 2018, pro-eating disorder content has either stopped its
decline or risen once more in ampleness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06784">Robotic surface exploration with vision and tactile sensing for cracks detection and characterisation. (arXiv:2307.06784v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Palermo_F/0/1/0/all/0/1">Francesca Palermo</a>, <a href="http://arxiv.org/find/cs/1/au:+Omarali_B/0/1/0/all/0/1">Bukeikhan Omarali</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_C/0/1/0/all/0/1">Changae Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Althoefer_K/0/1/0/all/0/1">Kaspar Althoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Farkhatdinov_I/0/1/0/all/0/1">Ildar Farkhatdinov</a></p>
<p>This paper presents a novel algorithm for crack localisation and detection
based on visual and tactile analysis via fibre-optics. A finger-shaped sensor
based on fibre-optics is employed for the data acquisition to collect data for
the analysis and the experiments. To detect the possible locations of cracks a
camera is used to scan an environment while running an object detection
algorithm. Once the crack is detected, a fully-connected graph is created from
a skeletonised version of the crack. A minimum spanning tree is then employed
for calculating the shortest path to explore the crack which is then used to
develop the motion planner for the robotic manipulator. The motion planner
divides the crack into multiple nodes which are then explored individually.
Then, the manipulator starts the exploration and performs the tactile data
classification to confirm if there is indeed a crack in that location or just a
false positive from the vision algorithm. If a crack is detected, also the
length, width, orientation and number of branches are calculated. This is
repeated until all the nodes of the crack are explored.
</p>
<p>In order to validate the complete algorithm, various experiments are
performed: comparison of exploration of cracks through full scan and motion
planning algorithm, implementation of frequency-based features for crack
classification and geometry analysis using a combination of vision and tactile
data. From the results of the experiments, it is shown that the proposed
algorithm is able to detect cracks and improve the results obtained from vision
to correctly classify cracks and their geometry with minimal cost thanks to the
motion planning algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06797">Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics. (arXiv:2307.06797v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Carbone_A/0/1/0/all/0/1">Alessandra Carbone</a>, <a href="http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1">Aur&#xe9;lien Decelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosset_L/0/1/0/all/0/1">Lorenzo Rosset</a>, <a href="http://arxiv.org/find/cs/1/au:+Seoane_B/0/1/0/all/0/1">Beatriz Seoane</a></p>
<p>In this study, we address the challenge of using energy-based models to
produce high-quality, label-specific data in complex structured datasets, such
as population genetics, RNA or protein sequences data. Traditional training
methods encounter difficulties due to inefficient Markov chain Monte Carlo
mixing, which affects the diversity of synthetic data and increases generation
times. To address these issues, we use a novel training algorithm that exploits
non-equilibrium effects. This approach, applied on the Restricted Boltzmann
Machine, improves the model's ability to correctly classify samples and
generate high-quality synthetic data in only a few sampling steps. The
effectiveness of this method is demonstrated by its successful application to
four different types of data: handwritten digits, mutations of human genomes
classified by continental origin, functionally characterized sequences of an
enzyme protein family, and homologous RNA sequences from specific taxonomies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06816">Data-driven Nonlinear Parametric Model Order Reduction Framework using Deep Hierarchical Variational Autoencoder. (arXiv:2307.06816v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">SiHun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangmin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_K/0/1/0/all/0/1">Kijoo Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Haeseong Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">SangJoon Shin</a></p>
<p>A data-driven parametric model order reduction (MOR) method using a deep
artificial neural network is proposed. The present network, which is the
least-squares hierarchical variational autoencoder (LSH-VAE), is capable of
performing nonlinear MOR for the parametric interpolation of a nonlinear
dynamic system with a significant number of degrees of freedom. LSH-VAE
exploits two major changes to the existing networks: a hierarchical deep
structure and a hybrid weighted, probabilistic loss function. The enhancements
result in a significantly improved accuracy and stability compared against the
conventional nonlinear MOR methods, autoencoder, and variational autoencoder.
Upon LSH-VAE, a parametric MOR framework is presented based on the spherically
linear interpolation of the latent manifold. The present framework is validated
and evaluated on three nonlinear and multiphysics dynamic systems. First, the
present framework is evaluated on the fluid-structure interaction benchmark
problem to assess its efficiency and accuracy. Then, a highly nonlinear
aeroelastic phenomenon, limit cycle oscillation, is analyzed. Finally, the
present framework is applied to a three-dimensional fluid flow to demonstrate
its capability of efficiently analyzing a significantly large number of degrees
of freedom. The performance of LSH-VAE is emphasized by comparing its results
against that of the widely used nonlinear MOR methods, convolutional
autoencoder, and $\beta$-VAE. The present framework exhibits a significantly
enhanced accuracy to the conventional methods while still exhibiting a large
speed-up factor.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06821">Equalization in Dispersion-Managed Systems Using Learned Digital Back-Propagation. (arXiv:2307.06821v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abu_Romoh_M/0/1/0/all/0/1">Mohannad Abu-Romoh</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Costa_N/0/1/0/all/0/1">Nelson Costa</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Jaouen_Y/0/1/0/all/0/1">Yves Jaou&#xeb;n</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Napoli_A/0/1/0/all/0/1">Antonio Napoli</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Pedro_J/0/1/0/all/0/1">Jo&#xe3;o Pedro</a> (2,4), <a href="http://arxiv.org/find/cs/1/au:+Spinnler_B/0/1/0/all/0/1">Bernhard Spinnler</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Yousefi_M/0/1/0/all/0/1">Mansoor Yousefi</a> (1) ((1) Institut Polytechnique de Paris, T&#xe9;l&#xe9;com Paris, Palaiseau, France, (2) Infinera Unipessoal Lda, Carnaxide, Portugal, (3) Infinera, Munich, Germany, (4) Instituto de Telecomunica&#xe7;&#xf5;es, Instituto Superior T&#xe9;cnico, Lisboa, Portugal)</p>
<p>In this paper, we investigate the use of the learned digital back-propagation
(LDBP) for equalizing dual-polarization fiber-optic transmission in
dispersion-managed (DM) links. LDBP is a deep neural network that optimizes the
parameters of DBP using the stochastic gradient descent. We evaluate DBP and
LDBP in a simulated WDM dual-polarization fiber transmission system operating
at the bitrate of 256 Gbit/s per channel, with a dispersion map designed for a
2016 km link with 15% residual dispersion. Our results show that in
single-channel transmission, LDBP achieves an effective signal-to-noise ratio
improvement of 6.3 dB and 2.5 dB, respectively, over linear equalization and
DBP. In WDM transmission, the corresponding $Q$-factor gains are 1.1 dB and 0.4
dB, respectively. Additionally, we conduct a complexity analysis, which reveals
that a frequency-domain implementation of LDBP and DBP is more favorable in
terms of complexity than the time-domain implementation. These findings
demonstrate the effectiveness of LDBP in mitigating the nonlinear effects in DM
fiber-optic transmission systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06822">TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Haoyu Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Anicic_D/0/1/0/all/0/1">Darko Anicic</a>, <a href="http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1">Thomas A. Runkler</a></p>
<p>The field of Tiny Machine Learning (TinyML) has made substantial advancements
in democratizing machine learning on low-footprint devices, such as
microcontrollers. The prevalence of these miniature devices raises the question
of whether aggregating their knowledge can benefit TinyML applications.
Federated meta-learning is a promising answer to this question, as it addresses
the scarcity of labeled data and heterogeneous data distribution across devices
in the real world. However, deploying TinyML hardware faces unique resource
constraints, making existing methods impractical due to energy, privacy, and
communication limitations. We introduce TinyMetaFed, a model-agnostic
meta-learning framework suitable for TinyML. TinyMetaFed facilitates
collaborative training of a neural network initialization that can be quickly
fine-tuned on new devices. It offers communication savings and privacy
protection through partial local reconstruction and Top-P% selective
communication, computational efficiency via online learning, and robustness to
client heterogeneity through few-shot learning. The evaluations on three TinyML
use cases demonstrate that TinyMetaFed can significantly reduce energy
consumption and communication overhead, accelerate convergence, and stabilize
the training process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06824">CLAIMED -- the open source framework for building coarse-grained operators for accelerated discovery in science. (arXiv:2307.06824v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kienzler_R/0/1/0/all/0/1">Romeo Kienzler</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1">Rafflesia Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nilmeier_J/0/1/0/all/0/1">Jerome Nilmeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Nesic_I/0/1/0/all/0/1">Ivan Nesic</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddad_I/0/1/0/all/0/1">Ibrahim Haddad</a></p>
<p>In modern data-driven science, reproducibility and reusability are key
challenges. Scientists are well skilled in the process from data to
publication. Although some publication channels require source code and data to
be made accessible, rerunning and verifying experiments is usually hard due to
a lack of standards. Therefore, reusing existing scientific data processing
code from state-of-the-art research is hard as well. This is why we introduce
CLAIMED, which has a proven track record in scientific research for addressing
the repeatability and reusability issues in modern data-driven science. CLAIMED
is a framework to build reusable operators and scalable scientific workflows by
supporting the scientist to draw from previous work by re-composing workflows
from existing libraries of coarse-grained scientific operators. Although
various implementations exist, CLAIMED is programming language, scientific
library, and execution environment agnostic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06825">A Causal Framework to Unify Common Domain Generalization Approaches. (arXiv:2307.06825v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Nevin L. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kaican Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Han Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weiyan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Luning Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongxiang Huang</a></p>
<p>Domain generalization (DG) is about learning models that generalize well to
new domains that are related to, but different from, the training domain(s). It
is a fundamental problem in machine learning and has attracted much attention
in recent years. A large number of approaches have been proposed. Different
approaches are motivated from different perspectives, making it difficult to
gain an overall understanding of the area. In this paper, we propose a causal
framework for domain generalization and present an understanding of common DG
approaches in the framework. Our work sheds new lights on the following
questions: (1) What are the key ideas behind each DG method? (2) Why is it
expected to improve generalization to new domains theoretically? (3) How are
different DG methods related to each other and what are relative advantages and
limitations? By providing a unified perspective on DG, we hope to help
researchers better understand the underlying principles and develop more
effective approaches for this critical problem in machine learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06831">A Novel Bayes&#x27; Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Caprio_M/0/1/0/all/0/1">Michele Caprio</a>, <a href="http://arxiv.org/find/stat/1/au:+Sale_Y/0/1/0/all/0/1">Yusuf Sale</a>, <a href="http://arxiv.org/find/stat/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a></p>
<p>In their seminal 1990 paper, Wasserman and Kadane establish an upper bound
for the Bayes' posterior probability of a measurable set $A$, when the prior
lies in a class of probability measures $\mathcal{P}$ and the likelihood is
precise. They also give a sufficient condition for such upper bound to hold
with equality. In this paper, we introduce a generalization of their result by
additionally addressing uncertainty related to the likelihood. We give an upper
bound for the posterior probability when both the prior and the likelihood
belong to a set of probabilities. Furthermore, we give a sufficient condition
for this upper bound to become an equality. This result is interesting on its
own, and has the potential of being applied to various fields of engineering
(e.g. model predictive control), machine learning, and artificial intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06834">Enhancing Reliability in Federated mmWave Networks: A Practical and Scalable Solution using Radar-Aided Dynamic Blockage Recognition. (arXiv:2307.06834v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Al_Quraan_M/0/1/0/all/0/1">Mohammad Al-Quraan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoha_A/0/1/0/all/0/1">Ahmed Zoha</a>, <a href="http://arxiv.org/find/cs/1/au:+Centeno_A/0/1/0/all/0/1">Anthony Centeno</a>, <a href="http://arxiv.org/find/cs/1/au:+Salameh_H/0/1/0/all/0/1">Haythem Bany Salameh</a>, <a href="http://arxiv.org/find/cs/1/au:+Muhaidat_S/0/1/0/all/0/1">Sami Muhaidat</a>, <a href="http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1">Muhammad Ali Imran</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohjazi_L/0/1/0/all/0/1">Lina Mohjazi</a></p>
<p>This article introduces a new method to improve the dependability of
millimeter-wave (mmWave) and terahertz (THz) network services in dynamic
outdoor environments. In these settings, line-of-sight (LoS) connections are
easily interrupted by moving obstacles like humans and vehicles. The proposed
approach, coined as Radar-aided Dynamic blockage Recognition (RaDaR), leverages
radar measurements and federated learning (FL) to train a dual-output neural
network (NN) model capable of simultaneously predicting blockage status and
time. This enables determining the optimal point for proactive handover (PHO)
or beam switching, thereby reducing the latency introduced by 5G new radio
procedures and ensuring high quality of experience (QoE). The framework employs
radar sensors to monitor and track objects movement, generating range-angle and
range-velocity maps that are useful for scene analysis and predictions.
Moreover, FL provides additional benefits such as privacy protection,
scalability, and knowledge sharing. The framework is assessed using an
extensive real-world dataset comprising mmWave channel information and radar
data. The evaluation results show that RaDaR substantially enhances network
reliability, achieving an average success rate of 94% for PHO compared to
existing reactive HO procedures that lack proactive blockage prediction.
Additionally, RaDaR maintains a superior QoE by ensuring sustained high
throughput levels and minimising PHO latency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06836">PC-Droid: Faster diffusion and improved quality for particle cloud generation. (arXiv:2307.06836v1 [hep-ex])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ex/1/au:+Leigh_M/0/1/0/all/0/1">Matthew Leigh</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Sengupta_D/0/1/0/all/0/1">Debajyoti Sengupta</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Raine_J/0/1/0/all/0/1">John Andrew Raine</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Quetant_G/0/1/0/all/0/1">Guillaume Qu&#xe9;tant</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Golling_T/0/1/0/all/0/1">Tobias Golling</a></p>
<p>Building on the success of PC-JeDi we introduce PC-Droid, a substantially
improved diffusion model for the generation of jet particle clouds. By
leveraging a new diffusion formulation, studying more recent integration
solvers, and training on all jet types simultaneously, we are able to achieve
state-of-the-art performance for all types of jets across all evaluation
metrics. We study the trade-off between generation speed and quality by
comparing two attention based architectures, as well as the potential of
consistency distillation to reduce the number of diffusion steps. Both the
faster architecture and consistency models demonstrate performance surpassing
many competing models, with generation time up to two orders of magnitude
faster than PC-JeDi.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06840">Ensemble learning for blending gridded satellite and gauge-measured precipitation data. (arXiv:2307.06840v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Papacharalampous_G/0/1/0/all/0/1">Georgia Papacharalampous</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyralis_H/0/1/0/all/0/1">Hristos Tyralis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1">Nikolaos Doulamis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1">Anastasios Doulamis</a></p>
<p>Regression algorithms are regularly used for improving the accuracy of
satellite precipitation products. In this context, ground-based measurements
are the dependent variable and the satellite data are the predictor variables,
together with topography factors. Alongside this, it is increasingly recognised
in many fields that combinations of algorithms through ensemble learning can
lead to substantial predictive performance improvements. Still, a sufficient
number of ensemble learners for improving the accuracy of satellite
precipitation products and their large-scale comparison are currently missing
from the literature. In this work, we fill this specific gap by proposing 11
new ensemble learners in the field and by extensively comparing them for the
entire contiguous United States and for a 15-year period. We use monthly data
from the PERSIANN (Precipitation Estimation from Remotely Sensed Information
using Artificial Neural Networks) and IMERG (Integrated Multi-satellitE
Retrievals for GPM) gridded datasets. We also use gauge-measured precipitation
data from the Global Historical Climatology Network monthly database, version 2
(GHCNm). The ensemble learners combine the predictions by six regression
algorithms (base learners), namely the multivariate adaptive regression splines
(MARS), multivariate adaptive polynomial splines (poly-MARS), random forests
(RF), gradient boosting machines (GBM), extreme gradient boosting (XGBoost) and
Bayesian regularized neural networks (BRNN), and each of them is based on a
different combiner. The combiners include the equal-weight combiner, the median
combiner, two best learners and seven variants of a sophisticated stacking
method. The latter stacks a regression algorithm on the top of the base
learners to combine their independent predictions...
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06842">Federated Multi-Agent Deep Reinforcement Learning for Dynamic and Flexible 3D Operation of 5G Multi-MAP Networks. (arXiv:2307.06842v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Catte_E/0/1/0/all/0/1">Esteban Catt&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Sana_M/0/1/0/all/0/1">Mohamed Sana</a>, <a href="http://arxiv.org/find/cs/1/au:+Maman_M/0/1/0/all/0/1">Mickael Maman</a></p>
<p>This paper addresses the efficient management of Mobile Access Points (MAPs),
which are Unmanned Aerial Vehicles (UAV), in 5G networks. We propose a
two-level hierarchical architecture, which dynamically reconfigures the network
while considering Integrated Access-Backhaul (IAB) constraints. The high-layer
decision process determines the number of MAPs through consensus, and we
develop a joint optimization process to account for co-dependence in network
self-management. In the low-layer, MAPs manage their placement using a
double-attention based Deep Reinforcement Learning (DRL) model that encourages
cooperation without retraining. To improve generalization and reduce
complexity, we propose a federated mechanism for training and sharing one
placement model for every MAP in the low-layer. Additionally, we jointly
optimize the placement and backhaul connectivity of MAPs using a
multi-objective reward function, considering the impact of varying MAP
placement on wireless backhaul connectivity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06848">Tensor Completion via Leverage Sampling and Tensor QR Decomposition for Network Latency Estimation. (arXiv:2307.06848v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jun Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Ji-Qian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing-Qi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1">An-Bao Xu</a></p>
<p>In this paper, we consider the network latency estimation, which has been an
important metric for network performance. However, a large scale of network
latency estimation requires a lot of computing time. Therefore, we propose a
new method that is much faster and maintains high accuracy. The data structure
of network nodes can form a matrix, and the tensor model can be formed by
introducing the time dimension. Thus, the entire problem can be be summarized
as a tensor completion problem. The main idea of our method is improving the
tensor leverage sampling strategy and introduce tensor QR decomposition into
tensor completion. To achieve faster tensor leverage sampling, we replace
tensor singular decomposition (t-SVD) with tensor CSVD-QR to appoximate t-SVD.
To achieve faster completion for incomplete tensor, we use the tensor
$L_{2,1}$-norm rather than traditional tensor nuclear norm. Furthermore, we
introduce tensor QR decomposition into alternating direction method of
multipliers (ADMM) framework. Numerical experiments witness that our method is
faster than state-of-art algorithms with satisfactory accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06855">Data Augmentation in Training CNNs: Injecting Noise to Images. (arXiv:2307.06855v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akbiyik_M/0/1/0/all/0/1">M. Eren Akbiyik</a></p>
<p>Noise injection is a fundamental tool for data augmentation, and yet there is
no widely accepted procedure to incorporate it with learning frameworks. This
study analyzes the effects of adding or applying different noise models of
varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise
models that are distributed with different density functions are given common
magnitude levels via Structural Similarity (SSIM) metric in order to create an
appropriate ground for comparison. The basic results are conforming with the
most of the common notions in machine learning, and also introduce some novel
heuristics and recommendations on noise injection. The new approaches will
provide better understanding on optimal learning procedures for image
classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06857">Self-consistency for open-ended generations. (arXiv:2307.06857v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Siddhartha Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaofei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1">Anoop Deoras</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1">Bing Xiang</a></p>
<p>In this paper, we present a novel approach for improving the quality and
consistency of generated outputs from large-scale pre-trained language models
(LLMs). Self-consistency has emerged as an effective approach for prompts with
fixed answers, selecting the answer with the highest number of votes. In this
paper, we introduce a generalized framework for self-consistency that extends
its applicability beyond problems that have fixed-answer answers. Through
extensive simulations, we demonstrate that our approach consistently recovers
the optimal or near-optimal generation from a set of candidates. We also
propose lightweight parameter-free similarity functions that show significant
and consistent improvements across code generation, autoformalization, and
summarization tasks, even without access to token log probabilities. Our method
incurs minimal computational overhead, requiring no auxiliary reranker models
or modifications to the existing model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06860">AnuraSet: A dataset for benchmarking Neotropical anuran calls identification in passive acoustic monitoring. (arXiv:2307.06860v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Canas_J/0/1/0/all/0/1">Juan Sebasti&#xe1;n Ca&#xf1;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Toro_Gomez_M/0/1/0/all/0/1">Maria Paula Toro-G&#xf3;mez</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugai_L/0/1/0/all/0/1">Larissa Sayuri Moreira Sugai</a>, <a href="http://arxiv.org/find/cs/1/au:+Restrepo_H/0/1/0/all/0/1">Hern&#xe1;n Dar&#xed;o Ben&#xed;tez Restrepo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudas_J/0/1/0/all/0/1">Jorge Rudas</a>, <a href="http://arxiv.org/find/cs/1/au:+Bautista_B/0/1/0/all/0/1">Breyner Posso Bautista</a>, <a href="http://arxiv.org/find/cs/1/au:+Toledo_L/0/1/0/all/0/1">Lu&#xed;s Felipe Toledo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dena_S/0/1/0/all/0/1">Simone Dena</a>, <a href="http://arxiv.org/find/cs/1/au:+Domingos_A/0/1/0/all/0/1">Ad&#xe3;o Henrique Rosa Domingos</a>, <a href="http://arxiv.org/find/cs/1/au:+Souza_F/0/1/0/all/0/1">Franco Leandro de Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Neckel_Oliveira_S/0/1/0/all/0/1">Selvino Neckel-Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosa_A/0/1/0/all/0/1">Anderson da Rosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_Rocha_V/0/1/0/all/0/1">V&#xed;tor Carvalho-Rocha</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernardy_J/0/1/0/all/0/1">Jos&#xe9; Vin&#xed;cius Bernardy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugai_J/0/1/0/all/0/1">Jos&#xe9; Luiz Massao Moreira Sugai</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_C/0/1/0/all/0/1">Carolina Em&#xed;lia dos Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastos_R/0/1/0/all/0/1">Rog&#xe9;rio Pereira Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Llusia_D/0/1/0/all/0/1">Diego Llusia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulloa_J/0/1/0/all/0/1">Juan Sebasti&#xe1;n Ulloa</a></p>
<p>Global change is predicted to induce shifts in anuran acoustic behavior,
which can be studied through passive acoustic monitoring (PAM). Understanding
changes in calling behavior requires the identification of anuran species,
which is challenging due to the particular characteristics of neotropical
soundscapes. In this paper, we introduce a large-scale multi-species dataset of
anuran amphibians calls recorded by PAM, that comprises 27 hours of expert
annotations for 42 different species from two Brazilian biomes. We provide open
access to the dataset, including the raw recordings, experimental setup code,
and a benchmark with a baseline model of the fine-grained categorization
problem. Additionally, we highlight the challenges of the dataset to encourage
machine learning researchers to solve the problem of anuran call identification
towards conservation policy. All our experiments and resources can be found on
our GitHub repository https://github.com/soundclim/anuraset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06870">Embodied Lifelong Learning for Task and Motion Planning. (arXiv:2307.06870v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mendez_J/0/1/0/all/0/1">Jorge A. Mendez</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1">Leslie Pack Kaelbling</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1">Tom&#xe1;s Lozano-P&#xe9;rez</a></p>
<p>A robot deployed in a home over long stretches of time faces a true lifelong
learning problem. As it seeks to provide assistance to its users, the robot
should leverage any accumulated experience to improve its own knowledge to
become a more proficient assistant. We formalize this setting with a novel
lifelong learning problem formulation in the context of learning for task and
motion planning (TAMP). Exploiting the modularity of TAMP systems, we develop a
generative mixture model that produces candidate continuous parameters for a
planner. Whereas most existing lifelong learning approaches determine a priori
how data is shared across task models, our approach learns shared and
non-shared models and determines which to use online during planning based on
auxiliary tasks that serve as a proxy for each model's understanding of a
state. Our method exhibits substantial improvements in planning success on
simulated 2D domains and on several problems from the BEHAVIOR benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06871">Identifying Early Help Referrals For Local Authorities With Machine Learning And Bias Analysis. (arXiv:2307.06871v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Neto_E/0/1/0/all/0/1">Eufr&#xe1;sio de A. Lima Neto</a>, <a href="http://arxiv.org/find/cs/1/au:+Bailiss_J/0/1/0/all/0/1">Jonathan Bailiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Finke_A/0/1/0/all/0/1">Axel Finke</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1">Jo Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Cosma_G/0/1/0/all/0/1">Georgina Cosma</a></p>
<p>Local authorities in England, such as Leicestershire County Council (LCC),
provide Early Help services that can be offered at any point in a young
person's life when they experience difficulties that cannot be supported by
universal services alone, such as schools. This paper investigates the
utilisation of machine learning (ML) to assist experts in identifying families
that may need to be referred for Early Help assessment and support. LCC
provided an anonymised dataset comprising 14360 records of young people under
the age of 18. The dataset was pre-processed, machine learning models were
build, and experiments were conducted to validate and test the performance of
the models. Bias mitigation techniques were applied to improve the fairness of
these models. During testing, while the models demonstrated the capability to
identify young people requiring intervention or early help, they also produced
a significant number of false positives, especially when constructed with
imbalanced data, incorrectly identifying individuals who most likely did not
need an Early Help referral. This paper empirically explores the suitability of
data-driven ML models for identifying young people who may require Early Help
services and discusses their appropriateness and limitations for this task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06877">The complexity of non-stationary reinforcement learning. (arXiv:2307.06877v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Papadimitriou_C/0/1/0/all/0/1">Christos Papadimitriou</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Binghui Peng</a></p>
<p>The problem of continual learning in the domain of reinforcement learning,
often called non-stationary reinforcement learning, has been identified as an
important challenge to the application of reinforcement learning. We prove a
worst-case complexity result, which we believe captures this challenge:
Modifying the probabilities or the reward of a single state-action pair in a
reinforcement learning problem requires an amount of time almost as large as
the number of states in order to keep the value function up to date, unless the
strong exponential time hypothesis (SETH) is false; SETH is a widely accepted
strengthening of the P $\neq$ NP conjecture. Recall that the number of states
in current applications of reinforcement learning is typically astronomical. In
contrast, we show that just $\textit{adding}$ a new state-action pair is
considerably easier to implement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06886">Min-Max Optimization under Delays. (arXiv:2307.06886v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Adibi_A/0/1/0/all/0/1">Arman Adibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1">Aritra Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1">Hamed Hassani</a></p>
<p>Delays and asynchrony are inevitable in large-scale machine-learning problems
where communication plays a key role. As such, several works have extensively
analyzed stochastic optimization with delayed gradients. However, as far as we
are aware, no analogous theory is available for min-max optimization, a topic
that has gained recent popularity due to applications in adversarial
robustness, game theory, and reinforcement learning. Motivated by this gap, we
examine the performance of standard min-max optimization algorithms with
delayed gradient updates. First, we show (empirically) that even small delays
can cause prominent algorithms like Extra-gradient (\texttt{EG}) to diverge on
simple instances for which \texttt{EG} guarantees convergence in the absence of
delays. Our empirical study thus suggests the need for a careful analysis of
delayed versions of min-max optimization algorithms. Accordingly, under
suitable technical assumptions, we prove that Gradient Descent-Ascent
(\texttt{GDA}) and \texttt{EG} with delayed updates continue to guarantee
convergence to saddle points for convex-concave and strongly convex-strongly
concave settings. Our complexity bounds reveal, in a transparent manner, the
slow-down in convergence caused by delays.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06887">Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks. (arXiv:2307.06887v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Collins_L/0/1/0/all/0/1">Liam Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1">Hamed Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1">Mahdi Soltanolkotabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mokhtari_A/0/1/0/all/0/1">Aryan Mokhtari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a></p>
<p>Feature learning, i.e. extracting meaningful representations of data, is
quintessential to the practical success of neural networks trained with
gradient descent, yet it is notoriously difficult to explain how and why it
occurs. Recent theoretical studies have shown that shallow neural networks
optimized on a single task with gradient-based methods can learn meaningful
features, extending our understanding beyond the neural tangent kernel or
random feature regime in which negligible feature learning occurs. But in
practice, neural networks are increasingly often trained on {\em many} tasks
simultaneously with differing loss functions, and these prior analyses do not
generalize to such settings. In the multi-task learning setting, a variety of
studies have shown effective feature learning by simple linear models. However,
multi-task learning via {\em nonlinear} models, arguably the most common
learning paradigm in practice, remains largely mysterious. In this work, we
present the first results proving feature learning occurs in a multi-task
setting with a nonlinear model. We show that when the tasks are binary
classification problems with labels depending on only $r$ directions within the
ambient $d\gg r$-dimensional input space, executing a simple gradient-based
multitask learning algorithm on a two-layer ReLU neural network learns the
ground-truth $r$ directions. In particular, any downstream task on the $r$
ground-truth coordinates can be solved by learning a linear classifier with
sample and neuron complexity independent of the ambient dimension $d$, while a
random feature model requires exponential complexity in $d$ for such a
guarantee.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06913">Uncovering Unique Concept Vectors through Latent Space Decomposition. (arXiv:2307.06913v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Graziani_M/0/1/0/all/0/1">Mara Graziani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahony_L/0/1/0/all/0/1">Laura O&#x27; Mahony</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">An-Phi Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_H/0/1/0/all/0/1">Henning M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrearczyk_V/0/1/0/all/0/1">Vincent Andrearczyk</a></p>
<p>Interpreting the inner workings of deep learning models is crucial for
establishing trust and ensuring model safety. Concept-based explanations have
emerged as a superior approach that is more interpretable than feature
attribution estimates such as pixel saliency. However, defining the concepts
for the interpretability analysis biases the explanations by the user's
expectations on the concepts. To address this, we propose a novel post-hoc
unsupervised method that automatically uncovers the concepts learned by deep
models during training. By decomposing the latent space of a layer in singular
vectors and refining them by unsupervised clustering, we uncover concept
vectors aligned with directions of high variance that are relevant to the model
prediction, and that point to semantically distinct concepts. Our extensive
experiments reveal that the majority of our concepts are readily understandable
to humans, exhibit coherency, and bear relevance to the task at hand. Moreover,
we showcase the practical utility of our method in dataset exploration, where
our concept vectors successfully identify outlier training samples affected by
various confounding factors. This novel exploration technique has remarkable
versatility to data types and model architectures and it will facilitate the
identification of biases and the discovery of sources of error within training
data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06915">Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality. (arXiv:2307.06915v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wei_Z/0/1/0/all/0/1">Ziyang Wei</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_W/0/1/0/all/0/1">Wanrong Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_W/0/1/0/all/0/1">Wei Biao Wu</a></p>
<p>Stochastic Gradient Descent (SGD) is one of the simplest and most popular
algorithms in modern statistical and machine learning due to its computational
and memory efficiency. Various averaging schemes have been proposed to
accelerate the convergence of SGD in different settings. In this paper, we
explore a general averaging scheme for SGD. Specifically, we establish the
asymptotic normality of a broad range of weighted averaged SGD solutions and
provide asymptotically valid online inference approaches. Furthermore, we
propose an adaptive averaging scheme that exhibits both optimal statistical
rate and favorable non-asymptotic convergence, drawing insights from the
optimal weight for the linear model in terms of non-asymptotic mean squared
error (MSE).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06924">DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding. (arXiv:2307.06924v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuijing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Aamir Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1">Kaiwen Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1">Peixin Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mizrachi_Z/0/1/0/all/0/1">Zachary Mizrachi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Justin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+McPherson_D/0/1/0/all/0/1">D. Livingston McPherson</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_W/0/1/0/all/0/1">Wendy A. Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1">Katherine Driggs-Campbell</a></p>
<p>Persons with visual impairments (PwVI) have difficulties understanding and
navigating spaces around them. Current wayfinding technologies either focus
solely on navigation or provide limited communication about the environment.
Motivated by recent advances in visual-language grounding and semantic
navigation, we propose DRAGON, a guiding robot powered by a dialogue system and
the ability to associate the environment with natural language. By
understanding the commands from the user, DRAGON is able to guide the user to
the desired landmarks on the map, describe the environment, and answer
questions from visual observations. Through effective utilization of dialogue,
the robot can ground the user's free-form descriptions to landmarks in the
environment, and give the user semantic information through spoken language. We
conduct a user study with blindfolded participants in an everyday indoor
environment. Our results demonstrate that DRAGON is able to communicate with
the user smoothly, provide a good guiding experience, and connect users with
their surrounding environment in an intuitive manner.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06925">Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models. (arXiv:2307.06925v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arar_M/0/1/0/all/0/1">Moab Arar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_R/0/1/0/all/0/1">Rinon Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Atzmon_Y/0/1/0/all/0/1">Yuval Atzmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_A/0/1/0/all/0/1">Ariel Shamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1">Amit H. Bermano</a></p>
<p>Text-to-image (T2I) personalization allows users to guide the creative image
generation process by combining their own visual concepts in natural language
prompts. Recently, encoder-based techniques have emerged as a new effective
approach for T2I personalization, reducing the need for multiple images and
long training times. However, most existing encoders are limited to a
single-class domain, which hinders their ability to handle diverse concepts. In
this work, we propose a domain-agnostic method that does not require any
specialized dataset or prior information about the personalized concepts. We
introduce a novel contrastive-based regularization technique to maintain high
fidelity to the target concept characteristics while keeping the predicted
embeddings close to editable regions of the latent space, by pushing the
predicted tokens toward their nearest existing CLIP tokens. Our experimental
results demonstrate the effectiveness of our approach and show how the learned
tokens are more semantic than tokens predicted by unregularized models. This
leads to a better representation that achieves state-of-the-art performance
while being more flexible than previous methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06933">FDAPT: Federated Domain-adaptive Pre-training for Language Models. (arXiv:2307.06933v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lekang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Svoboda_F/0/1/0/all/0/1">Filip Svoboda</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas D. Lane</a></p>
<p>Combining Domain-adaptive Pre-training (DAPT) with Federated Learning (FL)
can enhance model adaptation by leveraging more sensitive and distributed data
while preserving data privacy. However, few studies have focused on this
method. Therefore, we conduct the first comprehensive empirical study to
evaluate the performance of Federated Domain-adaptive Pre-training (FDAPT). We
demonstrate that FDAPT can maintain competitive downstream task performance to
the centralized baseline in both IID and non-IID situations. Furthermore, we
propose a novel algorithm, Frozen Federated Domain-adaptive Pre-training
(FFDAPT). FFDAPT improves the computational efficiency by 12.1% on average and
exhibits similar downstream task performance to standard FDAPT, with general
performance fluctuations remaining less than 1%. Finally, through a critical
evaluation of our work, we identify promising future research directions for
this new research area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06941">On the Connection between Game-Theoretic Feature Attributions and Counterfactual Explanations. (arXiv:2307.06941v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Albini_E/0/1/0/all/0/1">Emanuele Albini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Shubham Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Saumitra Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1">Danial Dervovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1">Daniele Magazzeni</a></p>
<p>Explainable Artificial Intelligence (XAI) has received widespread interest in
recent years, and two of the most popular types of explanations are feature
attributions, and counterfactual explanations. These classes of approaches have
been largely studied independently and the few attempts at reconciling them
have been primarily empirical. This work establishes a clear theoretical
connection between game-theoretic feature attributions, focusing on but not
limited to SHAP, and counterfactuals explanations. After motivating operative
changes to Shapley values based feature attributions and counterfactual
explanations, we prove that, under conditions, they are in fact equivalent. We
then extend the equivalency result to game-theoretic solution concepts beyond
Shapley values. Moreover, through the analysis of the conditions of such
equivalence, we shed light on the limitations of naively using counterfactual
explanations to provide feature importances. Experiments on three datasets
quantitatively show the difference in explanations at every stage of the
connection between the two approaches and corroborate the theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06945">In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1">Tao Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Si-Qing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a></p>
<p>We propose the In-context Autoencoder (ICAE) for context compression in a
large language model (LLM). The ICAE has two modules: a learnable encoder
adapted with LoRA from an LLM for compressing a long context into a limited
number of memory slots, and a fixed decoder which is the target LLM that can
condition on the memory slots for various purposes. We first pretrain the ICAE
using both autoencoding and language modeling objectives on massive text data,
enabling it to generate memory slots that accurately and comprehensively
represent the original context. Then, we fine-tune the pretrained ICAE on a
small amount of instruct data to enhance its interaction with various prompts
for producing desirable responses. Our experimental results demonstrate that
the ICAE learned with our proposed pretraining and fine-tuning paradigm can
effectively produce memory slots with $4\times$ context compression, which can
be well conditioned on by the target LLM to respond to various prompts. The
promising results demonstrate significant implications of the ICAE for its
novel approach to the long context problem and its potential to reduce
computation and memory overheads for LLM inference in practice, suggesting
further research effort in context management for an LLM. Our code and data
will be released shortly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06949">HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models. (arXiv:2307.06949v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1">Nataniel Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1">Varun Jampani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1">Tingbo Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1">Yael Pritch</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadhwa_N/0/1/0/all/0/1">Neal Wadhwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_M/0/1/0/all/0/1">Michael Rubinstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1">Kfir Aberman</a></p>
<p>Personalization has emerged as a prominent aspect within the field of
generative AI, enabling the synthesis of individuals in diverse contexts and
styles, while retaining high-fidelity to their identities. However, the process
of personalization presents inherent challenges in terms of time and memory
requirements. Fine-tuning each personalized model needs considerable GPU time
investment, and storing a personalized model per subject can be demanding in
terms of storage capacity. To overcome these challenges, we propose
HyperDreamBooth-a hypernetwork capable of efficiently generating a small set of
personalized weights from a single image of a person. By composing these
weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth
can generate a person's face in various contexts and styles, with high subject
details while also preserving the model's crucial knowledge of diverse styles
and semantic modifications. Our method achieves personalization on faces in
roughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual
Inversion, using as few as one reference image, with the same quality and style
diversity as DreamBooth. Also our method yields a model that is 10000x smaller
than a normal DreamBooth model. Project page: https://hyperdreambooth.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1901.07186">Towards Learning to Imitate from a Single Video Demonstration. (arXiv:1901.07186v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1">Glen Berseth</a>, <a href="http://arxiv.org/find/cs/1/au:+Golemo_F/0/1/0/all/0/1">Florian Golemo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a></p>
<p>Agents that can learn to imitate given video observation -- \emph{without
direct access to state or action information} are more applicable to learning
in the natural world. However, formulating a reinforcement learning (RL) agent
that facilitates this goal remains a significant challenge. We approach this
challenge using contrastive training to learn a reward function comparing an
agent's behaviour with a single demonstration. We use a Siamese recurrent
neural network architecture to learn rewards in space and time between motion
clips while training an RL policy to minimize this distance. Through
experimentation, we also find that the inclusion of multi-task data and
additional image encoding losses improve the temporal consistency of the
learned rewards and, as a result, significantly improves policy learning. We
demonstrate our approach on simulated humanoid, dog, and raptor agents in 2D
and a quadruped and a humanoid in 3D. We show that our method outperforms
current state-of-the-art techniques in these environments and can learn to
imitate from a single video demonstration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1912.13122">Declarative Mechanism Design. (arXiv:1912.13122v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garcia_Camino_A/0/1/0/all/0/1">Andr&#xe9;s Garc&#xed;a-Camino</a></p>
<p>Regulation of Multi-Agent Systems (MAS) and Declarative Electronic
Institutions (DEIs) was a multidisciplinary research topic of the past decade
involving (Physical and Software) Agents and Law since the beginning, but
recently evolved towards News-claimed Robot Lawyer since 2016. One of these
first proposals of restricting the behaviour of Software Agentswas Electronic
Institutions.However, with the recent reformulation of Artificial Neural
Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal
issues regarding the use of DL has raised concerns in the Artificial
Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly
addressed, we propose the Regulation of Artificial Neural Networks as
Agent-based Training of a special type of regulated Artificial Neural Network
that we call Institutional Neural Network (INN).The main purpose of this paper
is to bring attention to Artificial Teaching (AT) and to give a tentative
answer showing a proof-of-concept implementation of Regulated Deep Learning
(RDL). This paper introduces the former concept and provide sI, a language
previously used to model declaratively and extend Electronic Institutions, as a
means to regulate the execution of Artificial Neural Networks and their
interactions with Artificial Teachers (ATs)
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2102.06984">Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v5 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1">Hanbaek Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kureh_Y/0/1/0/all/0/1">Yacoub H. Kureh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vendrow_J/0/1/0/all/0/1">Joshua Vendrow</a>, <a href="http://arxiv.org/find/cs/1/au:+Porter_M/0/1/0/all/0/1">Mason A. Porter</a></p>
<p>It is common to use networks to encode the architecture of interactions
between entities in complex systems in the physical, biological, social, and
information sciences. To study the large-scale behavior of complex systems, it
is useful to examine mesoscale structures in networks as building blocks that
influence such behavior. We present a new approach for describing low-rank
mesoscale structures in networks, and we illustrate our approach using several
synthetic network models and empirical friendship, collaboration, and
protein--protein interaction (PPI) networks. We find that these networks
possess a relatively small number of `latent motifs' that together can
successfully approximate most subgraphs of a network at a fixed mesoscale. We
use an algorithm for `network dictionary learning' (NDL), which combines a
network-sampling method and nonnegative matrix factorization, to learn the
latent motifs of a given network. The ability to encode a network using a set
of latent motifs has a wide variety of applications to network-analysis tasks,
such as comparison, denoising, and edge inference. Additionally, using a new
network denoising and reconstruction (NDR) algorithm, we demonstrate how to
denoise a corrupted network by using only the latent motifs that one learns
directly from the corrupted network.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.06613">A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Treutlein_J/0/1/0/all/0/1">Johannes Treutlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1">Michael Dennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1">Caspar Oesterheld</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a></p>
<p>In many coordination problems, independently reasoning humans are able to
discover mutually compatible policies. In contrast, independently trained
self-play policies are often mutually incompatible. Zero-shot coordination
(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement
learning to address this fundamental issue. Prior work approaches the ZSC
problem by assuming players can agree on a shared learning algorithm but not on
labels for actions and observations, and proposes other-play as an optimal
solution. However, until now, this "label-free" problem has only been
informally defined. We formalize this setting as the label-free coordination
(LFC) problem by defining the label-free coordination game. We show that
other-play is not an optimal solution to the LFC problem as it fails to
consistently break ties between incompatible maximizers of the other-play
objective. We introduce an extension of the algorithm, other-play with
tie-breaking, and prove that it is optimal in the LFC problem and an
equilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the
ZSC setting aims to prevent, we conclude that the LFC problem does not reflect
the aims of ZSC. To address this, we introduce an alternative informal
operationalization of ZSC as a starting point for future work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.07501">Balanced Coarsening for Multilevel Hypergraph Partitioning via Wasserstein Discrepancy. (arXiv:2106.07501v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhicheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiaxuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a></p>
<p>We propose a balanced coarsening scheme for multilevel hypergraph
partitioning. In addition, an initial partitioning algorithm is designed to
improve the quality of k-way hypergraph partitioning. By assigning vertex
weights through the LPT algorithm, we generate a prior hypergraph under a
relaxed balance constraint. With the prior hypergraph, we have defined the
Wasserstein discrepancy to coordinate the optimal transport of coarsening
process. And the optimal transport matrix is solved by Sinkhorn algorithm. Our
coarsening scheme fully takes into account the minimization of connectivity
metric (objective function). For the initial partitioning stage, we define a
normalized cut function induced by Fiedler vector, which is theoretically
proved to be a concave function. Thereby, a three-point algorithm is designed
to find the best cut under the balance constraint.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2109.13445">Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations. (arXiv:2109.13445v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1">Avi Cooper</a>, <a href="http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1">Xavier Boix</a>, <a href="http://arxiv.org/find/cs/1/au:+Harari_D/0/1/0/all/0/1">Daniel Harari</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1">Spandan Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1">Hanspeter Pfister</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1">Tomotake Sasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_P/0/1/0/all/0/1">Pawan Sinha</a></p>
<p>The capability of Deep Neural Networks (DNNs) to recognize objects in
orientations outside the distribution of the training data is not well
understood. We present evidence that DNNs are capable of generalizing to
objects in novel orientations by disseminating orientation-invariance obtained
from familiar objects seen from many viewpoints. This capability strengthens
when training the DNN with an increasing number of familiar objects, but only
in orientations that involve 2D rotations of familiar orientations. We show
that this dissemination is achieved via neurons tuned to common features
between familiar and unfamiliar objects. These results implicate brain-like
neural mechanisms for generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.08440">Climate-Invariant Machine Learning. (arXiv:2112.08440v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Beucler_T/0/1/0/all/0/1">Tom Beucler</a>, <a href="http://arxiv.org/find/cs/1/au:+Gentine_P/0/1/0/all/0/1">Pierre Gentine</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuval_J/0/1/0/all/0/1">Janni Yuval</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ankitesh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1">Liran Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jerry Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sungduk Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasp_S/0/1/0/all/0/1">Stephan Rasp</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1">Fiaz Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+OGorman_P/0/1/0/all/0/1">Paul A. O&#x27;Gorman</a>, <a href="http://arxiv.org/find/cs/1/au:+Neelin_J/0/1/0/all/0/1">J. David Neelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutsko_N/0/1/0/all/0/1">Nicholas J. Lutsko</a>, <a href="http://arxiv.org/find/cs/1/au:+Pritchard_M/0/1/0/all/0/1">Michael Pritchard</a></p>
<p>Projecting climate change is a generalization problem: we extrapolate the
recent past using physical models across past, present, and future climates.
Current climate models require representations of processes that occur at
scales smaller than model grid size, which have been the main source of model
projection uncertainty. Recent machine learning (ML) algorithms hold promise to
improve such process representations, but tend to extrapolate poorly to climate
regimes they were not trained on. To get the best of the physical and
statistical worlds, we propose a new framework -- termed "climate-invariant" ML
-- incorporating knowledge of climate processes into ML algorithms, and show
that it can maintain high accuracy across a wide range of climate and
geographic conditions in three distinct atmospheric models. Our results suggest
that explicitly incorporating physical knowledge into data-driven models of
Earth system processes can improve their consistency, data efficiency, and
generalizability across climate regimes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.07306">Bregman Deviations of Generic Exponential Families. (arXiv:2201.07306v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Sayak Ray Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Saux_P/0/1/0/all/0/1">Patrick Saux</a>, <a href="http://arxiv.org/find/cs/1/au:+Maillard_O/0/1/0/all/0/1">Odalric-Ambrym Maillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalan_A/0/1/0/all/0/1">Aditya Gopalan</a></p>
<p>We revisit the method of mixture technique, also known as the Laplace method,
to study the concentration phenomenon in generic exponential families.
Combining the properties of Bregman divergence associated with log-partition
function of the family with the method of mixtures for super-martingales, we
establish a generic bound controlling the Bregman divergence between the
parameter of the family and a finite sample estimate of the parameter. Our
bound is time-uniform and makes appear a quantity extending the classical
information gain to exponential families, which we call the Bregman information
gain. For the practitioner, we instantiate this novel bound to several
classical families, e.g., Gaussian, Bernoulli, Exponential, Weibull, Pareto,
Poisson and Chi-square yielding explicit forms of the confidence sets and the
Bregman information gain. We further numerically compare the resulting
confidence bounds to state-of-the-art alternatives for time-uniform
concentration and show that this novel method yields competitive results.
Finally, we highlight the benefit of our concentration bounds on some
illustrative applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.07372">Prospective Learning: Principled Extrapolation to the Future. (arXiv:2201.07372v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1">Ashwin De Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_R/0/1/0/all/0/1">Rahul Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1">Lyle Ungar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shuler_M/0/1/0/all/0/1">Marshall Hussain Shuler</a>, <a href="http://arxiv.org/find/cs/1/au:+Cowan_N/0/1/0/all/0/1">Noah J. Cowan</a>, <a href="http://arxiv.org/find/cs/1/au:+Platt_M/0/1/0/all/0/1">Michael Platt</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Isik_L/0/1/0/all/0/1">Leyla Isik</a>, <a href="http://arxiv.org/find/cs/1/au:+Roh_S/0/1/0/all/0/1">Seung-Eon Roh</a>, <a href="http://arxiv.org/find/cs/1/au:+Charles_A/0/1/0/all/0/1">Adam Charles</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_A/0/1/0/all/0/1">Archana Venkataraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Caffo_B/0/1/0/all/0/1">Brian Caffo</a>, <a href="http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1">Javier J. How</a>, <a href="http://arxiv.org/find/cs/1/au:+Kebschull_J/0/1/0/all/0/1">Justus M Kebschull</a>, <a href="http://arxiv.org/find/cs/1/au:+Krakauer_J/0/1/0/all/0/1">John W. Krakauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bichuch_M/0/1/0/all/0/1">Maxim Bichuch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kinfu_K/0/1/0/all/0/1">Kaleab Alemayehu Kinfu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yezerets_E/0/1/0/all/0/1">Eva Yezerets</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1">Dinesh Jayaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jong M. Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Villar_S/0/1/0/all/0/1">Soledad Villar</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_I/0/1/0/all/0/1">Ian Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1">Carey E. Priebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartung_T/0/1/0/all/0/1">Thomas Hartung</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1">Michael I. Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1">Jayanta Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Ningyuan/0/1/0/all/0/1">Ningyuan</a> (Teresa) <a href="http://arxiv.org/find/cs/1/au:+Huang/0/1/0/all/0/1">Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1">Eric Eaton</a>, <a href="http://arxiv.org/find/cs/1/au:+Etienne_Cummings_R/0/1/0/all/0/1">Ralph Etienne-Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogburn_E/0/1/0/all/0/1">Elizabeth L. Ogburn</a>, <a href="http://arxiv.org/find/cs/1/au:+Burns_R/0/1/0/all/0/1">Randal Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Osuagwu_O/0/1/0/all/0/1">Onyema Osuagwu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mensh_B/0/1/0/all/0/1">Brett Mensh</a>, <a href="http://arxiv.org/find/cs/1/au:+Muotri_A/0/1/0/all/0/1">Alysson R. Muotri</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1">Julia Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1">Chris White</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Weiwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rusu_A/0/1/0/all/0/1">Andrei A. Rusu</a>, <a href="http://arxiv.org/find/cs/1/au:+Verstynen_T/0/1/0/all/0/1">Timothy Verstynen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kording_K/0/1/0/all/0/1">Konrad P. Kording</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1">Pratik Chaudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a></p>
<p>Learning is a process which can update decision rules, based on past
experience, such that future performance improves. Traditionally, machine
learning is often evaluated under the assumption that the future will be
identical to the past in distribution or change adversarially. But these
assumptions can be either too optimistic or pessimistic for many problems in
the real world. Real world scenarios evolve over multiple spatiotemporal scales
with partially predictable dynamics. Here we reformulate the learning problem
to one that centers around this idea of dynamic futures that are partially
learnable. We conjecture that certain sequences of tasks are not
retrospectively learnable (in which the data distribution is fixed), but are
prospectively learnable (in which distributions may be dynamic), suggesting
that prospective learning is more difficult in kind than retrospective
learning. We argue that prospective learning more accurately characterizes many
real world problems that (1) currently stymie existing artificial intelligence
solutions and/or (2) lack adequate explanations for how natural intelligences
solve them. Thus, studying prospective learning will lead to deeper insights
and solutions to currently vexing challenges in both natural and artificial
intelligences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.04428">Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dorfman_R/0/1/0/all/0/1">Ron Dorfman</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1">Kfir Y. Levy</a></p>
<p>We consider stochastic optimization problems where data is drawn from a
Markov chain. Existing methods for this setting crucially rely on knowing the
mixing time of the chain, which in real-world applications is usually unknown.
We propose the first optimization method that does not require the knowledge of
the mixing time, yet obtains the optimal asymptotic convergence rate when
applied to convex problems. We further show that our approach can be extended
to: (i) finding stationary points in non-convex optimization with Markovian
data, and (ii) obtaining better dependence on the mixing time in temporal
difference (TD) learning; in both cases, our method is completely oblivious to
the mixing time. Our method relies on a novel combination of multi-level Monte
Carlo (MLMC) gradient estimation together with an adaptive learning method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2204.07729">Efficient Bayesian Policy Reuse with a Scalable Observation Model in Deep Reinforcement Learning. (arXiv:2204.07729v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinmei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chunlin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1">Daoyi Dong</a></p>
<p>Bayesian policy reuse (BPR) is a general policy transfer framework for
selecting a source policy from an offline library by inferring the task belief
based on some observation signals and a trained observation model. In this
paper, we propose an improved BPR method to achieve more efficient policy
transfer in deep reinforcement learning (DRL). First, most BPR algorithms use
the episodic return as the observation signal that contains limited information
and cannot be obtained until the end of an episode. Instead, we employ the
state transition sample, which is informative and instantaneous, as the
observation signal for faster and more accurate task inference. Second, BPR
algorithms usually require numerous samples to estimate the probability
distribution of the tabular-based observation model, which may be expensive and
even infeasible to learn and maintain, especially when using the state
transition sample as the signal. Hence, we propose a scalable observation model
based on fitting state transition functions of source tasks from only a small
number of samples, which can generalize to any signals observed in the target
task. Moreover, we extend the offline-mode BPR to the continual learning
setting by expanding the scalable observation model in a plug-and-play fashion,
which can avoid negative transfer when faced with new unknown tasks.
Experimental results show that our method can consistently facilitate faster
and more efficient policy transfer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.10369">Energy-efficient Deployment of Deep Learning Applications on Cortex-M based Microcontrollers using Deep Compression. (arXiv:2205.10369v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deutel_M/0/1/0/all/0/1">Mark Deutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Woller_P/0/1/0/all/0/1">Philipp Woller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1">Christopher Mutschler</a>, <a href="http://arxiv.org/find/cs/1/au:+Teich_J/0/1/0/all/0/1">J&#xfc;rgen Teich</a></p>
<p>Large Deep Neural Networks (DNNs) are the backbone of today's artificial
intelligence due to their ability to make accurate predictions when being
trained on huge datasets. With advancing technologies, such as the Internet of
Things, interpreting large quantities of data generated by sensors is becoming
an increasingly important task. However, in many applications not only the
predictive performance but also the energy consumption of deep learning models
is of major interest. This paper investigates the efficient deployment of deep
learning models on resource-constrained microcontroller architectures via
network compression. We present a methodology for the systematic exploration of
different DNN pruning, quantization, and deployment strategies, targeting
different ARM Cortex-M based low-power systems. The exploration allows to
analyze trade-offs between key metrics such as accuracy, memory consumption,
execution time, and power consumption. We discuss experimental results on three
different DNN architectures and show that we can compress them to below 10\% of
their original parameter count before their predictive quality decreases. This
also allows us to deploy and evaluate them on Cortex-M based microcontrollers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.09522">Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Magesh_A/0/1/0/all/0/1">Akshayaa Magesh</a>, <a href="http://arxiv.org/find/stat/1/au:+Veeravalli_V/0/1/0/all/0/1">Venugopal V. Veeravalli</a>, <a href="http://arxiv.org/find/stat/1/au:+Roy_A/0/1/0/all/0/1">Anirban Roy</a>, <a href="http://arxiv.org/find/stat/1/au:+Jha_S/0/1/0/all/0/1">Susmit Jha</a></p>
<p>We study the problem of Out-of-Distribution (OOD) detection, that is,
detecting whether a learning algorithm's output can be trusted at inference
time. While a number of tests for OOD detection have been proposed in prior
work, a formal framework for studying this problem is lacking. We propose a
definition for the notion of OOD that includes both the input distribution and
the learning algorithm, which provides insights for the construction of
powerful tests for OOD detection. We propose a multiple hypothesis testing
inspired procedure to systematically combine any number of different statistics
from the learning algorithm using conformal p-values. We further provide strong
guarantees on the probability of incorrectly classifying an in-distribution
sample as OOD. In our experiments, we find that threshold-based tests proposed
in prior work perform well in specific settings, but not uniformly well across
different types of OOD instances. In contrast, our proposed method that
combines multiple statistics performs uniformly well across different datasets
and neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.04827">Classification and Generation of real-world data with an Associative Memory Model. (arXiv:2207.04827v4 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Simas_R/0/1/0/all/0/1">Rodrigo Simas</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_Couto_L/0/1/0/all/0/1">Luis Sa-Couto</a>, <a href="http://arxiv.org/find/cs/1/au:+Wichert_A/0/1/0/all/0/1">Andreas Wichert</a></p>
<p>Drawing from memory the face of a friend you have not seen in years is a
difficult task. However, if you happen to cross paths, you would easily
recognize each other. The biological memory is equipped with an impressive
compression algorithm that can store the essential, and then infer the details
to match perception. The Willshaw Memory is a simple abstract model for
cortical computations which implements mechanisms of biological memories. Using
our recently proposed sparse coding prescription for visual patterns, this
model can store and retrieve an impressive amount of real-world data in a
fault-tolerant manner. In this paper, we extend the capabilities of the basic
Associative Memory Model by using a Multiple-Modality framework. In this
setting, the memory stores several modalities (e.g., visual, or textual) of
each pattern simultaneously. After training, the memory can be used to infer
missing modalities when just a subset is perceived. Using a simple
encoder-memory-decoder architecture, and a newly proposed iterative retrieval
algorithm for the Willshaw Model, we perform experiments on the MNIST dataset.
By storing both the images and labels as modalities, a single Memory can be
used not only to retrieve and complete patterns but also to classify and
generate new ones. We further discuss how this model could be used for other
learning tasks, thus serving as a biologically-inspired framework for learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.11290">TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring. (arXiv:2207.11290v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhaskhar_N/0/1/0/all/0/1">Nandita Bhaskhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel L. Rubin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Messer_C/0/1/0/all/0/1">Christopher Lee-Messer</a></p>
<p>Continuous monitoring of trained ML models to determine when their
predictions should and should not be trusted is essential for their safe
deployment. Such a framework ought to be high-performing, explainable, post-hoc
and actionable. We propose TRUST-LAPSE, a "mistrust" scoring framework for
continuous model monitoring. We assess the trustworthiness of each input
sample's model prediction using a sequence of latent-space embeddings.
Specifically, (a) our latent-space mistrust score estimates mistrust using
distance metrics (Mahalanobis distance) and similarity metrics (cosine
similarity) in the latent-space and (b) our sequential mistrust score
determines deviations in correlations over the sequence of past input
representations in a non-parametric, sliding-window based algorithm for
actionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream
tasks: (1) distributionally shifted input detection, and (2) data drift
detection. We evaluate across diverse domains - audio and vision using public
datasets and further benchmark our approach on challenging, real-world
electroencephalograms (EEG) datasets for seizure detection. Our latent-space
mistrust scores achieve state-of-the-art results with AUROCs of 84.1 (vision),
73.9 (audio), and 77.1 (clinical EEGs), outperforming baselines by over 10
points. We expose critical failures in popular baselines that remain
insensitive to input semantic content, rendering them unfit for real-world
model monitoring. We show that our sequential mistrust scores achieve high
drift detection rates; over 90% of the streams show &lt; 20% error for all
domains. Through extensive qualitative and quantitative evaluations, we show
that our mistrust scores are more robust and provide explainability for easy
adoption into practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.07734">Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success. (arXiv:2208.07734v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1">Jaemin Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tiancheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1">Leman Akoglu</a></p>
<p>Self-supervised learning (SSL) has emerged as a promising alternative to
create supervisory signals to real-world problems, avoiding the extensive cost
of manual labeling. SSL is particularly attractive for unsupervised tasks such
as anomaly detection (AD), where labeled anomalies are rare or often
nonexistent. A large catalog of augmentation functions has been used for
SSL-based AD (SSAD) on image data, and recent works have reported that the type
of augmentation has a significant impact on accuracy. Motivated by those, this
work sets out to put image-based SSAD under a larger lens and investigate the
role of data augmentation in SSAD. Through extensive experiments on 3 different
detector models and across 420 AD tasks, we provide comprehensive numerical and
visual evidences that the alignment between data augmentation and
anomaly-generating mechanism is the key to the success of SSAD, and in the lack
thereof, SSL may even impair accuracy. To the best of our knowledge, this is
the first meta-analysis on the role of data augmentation in SSAD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.11986">Local Intrinsic Dimensionality Measures for Graphs, with Applications to Graph Embeddings. (arXiv:2208.11986v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Savic_M/0/1/0/all/0/1">Milo&#x161; Savi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurbalija_V/0/1/0/all/0/1">Vladimir Kurbalija</a>, <a href="http://arxiv.org/find/cs/1/au:+Radovanovic_M/0/1/0/all/0/1">Milo&#x161; Radovanovi&#x107;</a></p>
<p>The notion of local intrinsic dimensionality (LID) is an important
advancement in data dimensionality analysis, with applications in data mining,
machine learning and similarity search problems. Existing distance-based LID
estimators were designed for tabular datasets encompassing data points
represented as vectors in a Euclidean space. After discussing their limitations
for graph-structured data considering graph embeddings and graph distances, we
propose NC-LID, a novel LID-related measure for quantifying the discriminatory
power of the shortest-path distance with respect to natural communities of
nodes as their intrinsic localities. It is shown how this measure can be used
to design LID-aware graph embedding algorithms by formulating two LID-elastic
variants of node2vec with personalized hyperparameters that are adjusted
according to NC-LID values. Our empirical analysis of NC-LID on a large number
of real-world graphs shows that this measure is able to point to nodes with
high link reconstruction errors in node2vec embeddings better than node
centrality metrics. The experimental evaluation also shows that the proposed
LID-elastic node2vec extensions improve node2vec by better preserving graph
structure in generated embeddings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.06392">Joint User and Data Detection in Grant-Free NOMA with Attention-based BiLSTM Network. (arXiv:2209.06392v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Khan_S/0/1/0/all/0/1">Saud Khan</a>, <a href="http://arxiv.org/find/eess/1/au:+Durrani_S/0/1/0/all/0/1">Salman Durrani</a>, <a href="http://arxiv.org/find/eess/1/au:+Shahab_M/0/1/0/all/0/1">Muhammad Basit Shahab</a>, <a href="http://arxiv.org/find/eess/1/au:+Johnson_S/0/1/0/all/0/1">Sarah J. Johnson</a>, <a href="http://arxiv.org/find/eess/1/au:+Camtepe_S/0/1/0/all/0/1">Seyit Camtepe</a></p>
<p>We consider the multi-user detection (MUD) problem in uplink grant-free
non-orthogonal multiple access (NOMA), where the access point has to identify
the total number and correct identity of the active Internet of Things (IoT)
devices and decode their transmitted data. We assume that IoT devices use
complex spreading sequences and transmit information in a random-access manner
following the burst-sparsity model, where some IoT devices transmit their data
in multiple adjacent time slots with a high probability, while others transmit
only once during a frame. Exploiting the temporal correlation, we propose an
attention-based bidirectional long short-term memory (BiLSTM) network to solve
the MUD problem. The BiLSTM network creates a pattern of the device activation
history using forward and reverse pass LSTMs, whereas the attention mechanism
provides essential context to the device activation points. By doing so, a
hierarchical pathway is followed for detecting active devices in a grant-free
scenario. Then, by utilising the complex spreading sequences, blind data
detection for the estimated active devices is performed. The proposed framework
does not require prior knowledge of device sparsity levels and channels for
performing MUD. The results show that the proposed network achieves better
performance compared to existing benchmark schemes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.10081">Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Haibin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zichuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junyou Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Qiang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1">Deheng Ye</a></p>
<p>We study the adaption of soft actor-critic (SAC) from continuous action space
to discrete action space. We revisit vanilla SAC and provide an in-depth
understanding of its Q value underestimation and performance instability issues
when applied to discrete settings. We thereby propose entropy-penalty and
double average Q-learning with Q-clip to address these issues. Extensive
experiments on typical benchmarks with discrete action space, including Atari
games and a large-scale MOBA game, show the efficacy of our proposed method.
Our code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.10741">A kernel Stein test of goodness of fit for sequential models. (arXiv:2210.10741v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Baum_J/0/1/0/all/0/1">Jerome Baum</a>, <a href="http://arxiv.org/find/stat/1/au:+Kanagawa_H/0/1/0/all/0/1">Heishiro Kanagawa</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a></p>
<p>We propose a goodness-of-fit measure for probability densities modeling
observations with varying dimensionality, such as text documents of differing
lengths or variable-length sequences. The proposed measure is an instance of
the kernel Stein discrepancy (KSD), which has been used to construct
goodness-of-fit tests for unnormalized densities. The KSD is defined by its
Stein operator: current operators used in testing apply to fixed-dimensional
spaces. As our main contribution, we extend the KSD to the variable-dimension
setting by identifying appropriate Stein operators, and propose a novel KSD
goodness-of-fit test. As with the previous variants, the proposed KSD does not
require the density to be normalized, allowing the evaluation of a large class
of models. Our test is shown to perform well in practice on discrete sequential
data benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.14905">RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding. (arXiv:2210.14905v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaojuan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Song-Chun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yitao Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Muhan Zhang</a></p>
<p>Knowledge graph (KG) reasoning is an important problem for knowledge graphs.
In this paper, we propose a novel and principled framework called \textbf{RulE}
(stands for {Rul}e {E}mbedding) to effectively leverage logical rules to
enhance KG reasoning. Unlike knowledge graph embedding (KGE) methods, RulE
learns rule embeddings from existing triplets and first-order {rules} by
jointly representing \textbf{entities}, \textbf{relations} and \textbf{logical
rules} in a unified embedding space. Based on the learned rule embeddings, a
confidence score can be calculated for each rule, reflecting its consistency
with the observed triplets. This allows us to perform logical rule inference in
a soft way, thus alleviating the brittleness of logic. On the other hand, RulE
injects prior logical rule information into the embedding space, enriching and
regularizing the entity/relation embeddings. This makes KGE alone perform
better too. RulE is conceptually simple and empirically effective. We conduct
extensive experiments to verify each component of RulE. Results on multiple
benchmarks reveal that our model outperforms the majority of existing
embedding-based and rule-based approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.15092">Generalized Laplacian Regularized Framelet Graph Neural Networks. (arXiv:2210.15092v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiqi Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_A/0/1/0/all/0/1">Andi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasnev_A/0/1/0/all/0/1">Andrey Vasnev</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a></p>
<p>This paper introduces a novel Framelet Graph approach based on p-Laplacian
GNN. The proposed two models, named p-Laplacian undecimated framelet graph
convolution (pL-UFG) and generalized p-Laplacian undecimated framelet graph
convolution (pL-fUFG) inherit the nature of p-Laplacian with the expressive
power of multi-resolution decomposition of graph signals. The empirical study
highlights the excellent performance of the pL-UFG and pL-fUFG in different
graph learning tasks including node classification and signal denoising.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.00241">Adversarial Policies Beat Superhuman Go AIs. (arXiv:2211.00241v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tony T. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleave_A/0/1/0/all/0/1">Adam Gleave</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_T/0/1/0/all/0/1">Tom Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelrine_K/0/1/0/all/0/1">Kellin Pelrine</a>, <a href="http://arxiv.org/find/cs/1/au:+Belrose_N/0/1/0/all/0/1">Nora Belrose</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1">Joseph Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1">Michael D. Dennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yawen Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pogrebniak_V/0/1/0/all/0/1">Viktor Pogrebniak</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1">Stuart Russell</a></p>
<p>We attack the state-of-the-art Go-playing AI system KataGo by training
adversarial policies against it, achieving a &gt;97% win rate against KataGo
running at superhuman settings. Our adversaries do not win by playing Go well.
Instead, they trick KataGo into making serious blunders. Our attack transfers
zero-shot to other superhuman Go-playing AIs, and is comprehensible to the
extent that human experts can implement it without algorithmic assistance to
consistently beat superhuman AIs. The core vulnerability uncovered by our
attack persists even in KataGo agents adversarially trained to defend against
our attack. Our results demonstrate that even superhuman AI systems may harbor
surprising failure modes. Example games are available https://goattack.far.ai/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.01856">Human Biophysics as Network Weights: Conditional Generative Models for Dynamic Simulation. (arXiv:2211.01856v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shihan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Clarke_A/0/1/0/all/0/1">Alexander Kenneth Clarke</a>, <a href="http://arxiv.org/find/cs/1/au:+Maksymenko_K/0/1/0/all/0/1">Kostiantyn Maksymenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Deslauriers_Gauthier_S/0/1/0/all/0/1">Samuel Deslauriers-Gauthier</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1">Xinjun Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiangyang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Farina_D/0/1/0/all/0/1">Dario Farina</a></p>
<p>Simulations of biophysical systems are fundamental for studying physiological
mechanisms and developing human machine interfaces. Whilst advanced numerical
methods, such as finite element models, can excel in this task, they are
extremely computationally expensive to use when generating a large number of
simulations or simulating dynamic events with continuously changing structural
parameters. We propose an architecture that uses a conditional generative model
to interpolate between the numerical model states, dramatically lowering the
modeling time while maintaining a high generation accuracy. As a demonstration
of this concept, we present BioMime, a hybrid-structured generative model that
enables an accurate, ultra-fast, and arbitrarily high temporal-resolution
simulation of a specific biophysical system during dynamic changes. This
methodology has wide applications in physiological and clinical research as
well as in supporting data augmentation strategies for signal analysis,
representing a computationally efficient and highly accurate model for
biophysical simulations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.06407">Control Transformer: Robot Navigation in Unknown Environments through PRM-Guided Return-Conditioned Sequence Modeling. (arXiv:2211.06407v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lawson_D/0/1/0/all/0/1">Daniel Lawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Qureshi_A/0/1/0/all/0/1">Ahmed H. Qureshi</a></p>
<p>Learning long-horizon tasks such as navigation has presented difficult
challenges for successfully applying reinforcement learning to robotics. From
another perspective, under known environments, sampling-based planning can
robustly find collision-free paths in environments without learning. In this
work, we propose Control Transformer that models return-conditioned sequences
from low-level policies guided by a sampling-based Probabilistic Roadmap (PRM)
planner. We demonstrate that our framework can solve long-horizon navigation
tasks using only local information. We evaluate our approach on
partially-observed maze navigation with MuJoCo robots, including Ant, Point,
and Humanoid. We show that Control Transformer can successfully navigate
through mazes and transfer to unknown environments. Additionally, we apply our
method to a differential drive robot (Turtlebot3) and show zero-shot sim2real
transfer under noisy observations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.15944">The Effectiveness of World Models for Continual Reinforcement Learning. (arXiv:2211.15944v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kessler_S/0/1/0/all/0/1">Samuel Kessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostaszewski_M/0/1/0/all/0/1">Mateusz Ostaszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Bortkiewicz_M/0/1/0/all/0/1">Micha&#x142; Bortkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarski_M/0/1/0/all/0/1">Mateusz &#x17b;arski</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1">Maciej Wo&#x142;czyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1">Stephen J. Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Milos_P/0/1/0/all/0/1">Piotr Mi&#x142;o&#x15b;</a></p>
<p>World models power some of the most efficient reinforcement learning
algorithms. In this work, we showcase that they can be harnessed for continual
learning - a situation when the agent faces changing environments. World models
typically employ a replay buffer for training, which can be naturally extended
to continual learning. We systematically study how different selective
experience replay methods affect performance, forgetting, and transfer. We also
provide recommendations regarding various modeling options for using world
models. The best set of choices is called Continual-Dreamer, it is
task-agnostic and utilizes the world model for continual exploration.
Continual-Dreamer is sample efficient and outperforms state-of-the-art
task-agnostic continual reinforcement learning methods on Minigrid and Minihack
benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.03044">A Survey on Transformers in Reinforcement Learning. (arXiv:2301.03044v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Hao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zichuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zongqing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1">Deheng Ye</a></p>
<p>Transformer has been considered the dominating neural architecture in NLP and
CV, mostly under supervised settings. Recently, a similar surge of using
Transformers has appeared in the domain of reinforcement learning (RL), but it
is faced with unique design choices and challenges brought by the nature of RL.
However, the evolution of Transformers in RL has not yet been well unraveled.
In this paper, we seek to systematically review motivations and progress on
using Transformers in RL, provide a taxonomy on existing works, discuss each
sub-field, and summarize future prospects.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.08128">EPiC-GAN: Equivariant Point Cloud Generation for Particle Jets. (arXiv:2301.08128v3 [hep-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ph/1/au:+Buhmann_E/0/1/0/all/0/1">Erik Buhmann</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Kasieczka_G/0/1/0/all/0/1">Gregor Kasieczka</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Thaler_J/0/1/0/all/0/1">Jesse Thaler</a></p>
<p>With the vast data-collecting capabilities of current and future high-energy
collider experiments, there is an increasing demand for computationally
efficient simulations. Generative machine learning models enable fast event
generation, yet so far these approaches are largely constrained to fixed data
structures and rigid detector geometries. In this paper, we introduce EPiC-GAN
- equivariant point cloud generative adversarial network - which can produce
point clouds of variable multiplicity. This flexible framework is based on deep
sets and is well suited for simulating sprays of particles called jets. The
generator and discriminator utilize multiple EPiC layers with an interpretable
global latent vector. Crucially, the EPiC layers do not rely on pairwise
information sharing between particles, which leads to a significant speed-up
over graph- and transformer-based approaches with more complex relation
diagrams. We demonstrate that EPiC-GAN scales well to large particle
multiplicities and achieves high generation fidelity on benchmark jet
generation tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.11873">A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Elsemuller_L/0/1/0/all/0/1">Lasse Elsem&#xfc;ller</a>, <a href="http://arxiv.org/find/stat/1/au:+Schnuerch_M/0/1/0/all/0/1">Martin Schnuerch</a>, <a href="http://arxiv.org/find/stat/1/au:+Burkner_P/0/1/0/all/0/1">Paul-Christian B&#xfc;rkner</a>, <a href="http://arxiv.org/find/stat/1/au:+Radev_S/0/1/0/all/0/1">Stefan T. Radev</a></p>
<p>Bayesian model comparison (BMC) offers a principled approach for assessing
the relative merits of competing computational models and propagating
uncertainty into model selection decisions. However, BMC is often intractable
for the popular class of hierarchical models due to their high-dimensional
nested parameter structure. To address this intractability, we propose a deep
learning method for performing BMC on any set of hierarchical models which can
be instantiated as probabilistic programs. Since our method enables amortized
inference, it allows efficient re-estimation of posterior model probabilities
and fast performance validation prior to any real-data application. In a series
of extensive validation studies, we benchmark the performance of our method
against the state-of-the-art bridge sampling method and demonstrate excellent
amortized inference across all BMC settings. We then showcase our method by
comparing four hierarchical evidence accumulation models that have previously
been deemed intractable for BMC due to partly implicit likelihoods. In this
application, we corroborate evidence for the recently proposed L\'evy flight
model of decision-making and show how transfer learning can be leveraged to
enhance training efficiency. We provide reproducible code for all analyses and
an open-source implementation of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.12811">SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer. (arXiv:2301.12811v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Takida_Y/0/1/0/all/0/1">Yuhta Takida</a>, <a href="http://arxiv.org/find/cs/1/au:+Imaizumi_M/0/1/0/all/0/1">Masaaki Imaizumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shibuya_T/0/1/0/all/0/1">Takashi Shibuya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chieh-Hsin Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Uesaka_T/0/1/0/all/0/1">Toshimitsu Uesaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Murata_N/0/1/0/all/0/1">Naoki Murata</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1">Yuki Mitsufuji</a></p>
<p>Generative adversarial networks (GANs) learn a target probability
distribution by optimizing a generator and a discriminator with minimax
objectives. This paper addresses the question of whether such optimization
actually provides the generator with gradients that make its distribution close
to the target distribution. We derive metrizable conditions, sufficient
conditions for the discriminator to serve as the distance between the
distributions by connecting the GAN formulation with the concept of sliced
optimal transport. Furthermore, by leveraging these theoretical results, we
propose a novel GAN training scheme, called slicing adversarial network (SAN).
With only simple modifications, a broad class of existing GANs can be converted
to SANs. Experiments on synthetic and image datasets support our theoretical
results and the SAN's effectiveness as compared to usual GANs. Furthermore, we
also apply SAN to StyleGAN-XL, which leads to state-of-the-art FID score
amongst GANs for class conditional generation on ImageNet 256$\times$256.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00422">Robust online active learning. (arXiv:2302.00422v5 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Cacciarelli_D/0/1/0/all/0/1">Davide Cacciarelli</a>, <a href="http://arxiv.org/find/stat/1/au:+Kulahci_M/0/1/0/all/0/1">Murat Kulahci</a>, <a href="http://arxiv.org/find/stat/1/au:+Tyssedal_J/0/1/0/all/0/1">John S&#xf8;lve Tyssedal</a></p>
<p>In many industrial applications, obtaining labeled observations is not
straightforward as it often requires the intervention of human experts or the
use of expensive testing equipment. In these circumstances, active learning can
be highly beneficial in suggesting the most informative data points to be used
when fitting a model. Reducing the number of observations needed for model
development alleviates both the computational burden required for training and
the operational expenses related to labeling. Online active learning, in
particular, is useful in high-volume production processes where the decision
about the acquisition of the label for a data point needs to be taken within an
extremely short time frame. However, despite the recent efforts to develop
online active learning strategies, the behavior of these methods in the
presence of outliers has not been thoroughly examined. In this work, we
investigate the performance of online active linear regression in contaminated
data streams. Our study shows that the currently available query strategies are
prone to sample outliers, whose inclusion in the training set eventually
degrades the predictive performance of the models. To address this issue, we
propose a solution that bounds the search area of a conditional D-optimal
algorithm and uses a robust estimator. Our approach strikes a balance between
exploring unseen regions of the input space and protecting against outliers.
Through numerical simulations, we show that the proposed method is effective in
improving the performance of online active learning in the presence of
outliers, thus expanding the potential applications of this powerful tool.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00482">Improving and generalizing flow-based generative models with minibatch optimal transport. (arXiv:2302.00482v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tong_A/0/1/0/all/0/1">Alexander Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Malkin_N/0/1/0/all/0/1">Nikolay Malkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huguet_G/0/1/0/all/0/1">Guillaume Huguet</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanlei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rector_Brooks_J/0/1/0/all/0/1">Jarrid Rector-Brooks</a>, <a href="http://arxiv.org/find/cs/1/au:+Fatras_K/0/1/0/all/0/1">Kilian Fatras</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1">Guy Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a></p>
<p>Continuous normalizing flows (CNFs) are an attractive generative modeling
technique, but they have been held back by limitations in their
simulation-based maximum likelihood training. We introduce the generalized
conditional flow matching (CFM) technique, a family of simulation-free training
objectives for CNFs. CFM features a stable regression objective like that used
to train the stochastic flow in diffusion models but enjoys the efficient
inference of deterministic flow models. In contrast to both diffusion models
and prior CNF training algorithms, CFM does not require the source distribution
to be Gaussian or require evaluation of its density. A variant of our objective
is optimal transport CFM (OT-CFM), which creates simpler flows that are more
stable to train and lead to faster inference, as evaluated in our experiments.
Furthermore, OT-CFM is the first method to compute dynamic OT in a
simulation-free way. Training CNFs with CFM improves results on a variety of
conditional and unconditional generation tasks, such as inferring single cell
dynamics, unsupervised image translation, and Schr\"odinger bridge inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06887">Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Guneyi_E/0/1/0/all/0/1">Eylem Tugce Guneyi</a>, <a href="http://arxiv.org/find/stat/1/au:+Yaldiz_B/0/1/0/all/0/1">Berkay Yaldiz</a>, <a href="http://arxiv.org/find/stat/1/au:+Canbolat_A/0/1/0/all/0/1">Abdullah Canbolat</a>, <a href="http://arxiv.org/find/stat/1/au:+Vural_E/0/1/0/all/0/1">Elif Vural</a></p>
<p>The modeling of time-varying graph signals as stationary time-vertex
stochastic processes permits the inference of missing signal values by
efficiently employing the correlation patterns of the process across different
graph nodes and time instants. In this study, we propose an algorithm for
computing graph autoregressive moving average (graph ARMA) processes based on
learning the joint time-vertex power spectral density of the process from its
incomplete realizations for the task of signal interpolation. Our solution
relies on first roughly estimating the joint spectrum of the process from
partially observed realizations and then refining this estimate by projecting
it onto the spectrum manifold of the graph ARMA process through convex
relaxations. The initially missing signal values are then estimated based on
the learnt model. Experimental results show that the proposed approach achieves
high accuracy in time-vertex signal estimation problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.08715">EfficientNet Algorithm for Classification of Different Types of Cancer. (arXiv:2304.08715v3 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Samir_R/0/1/0/all/0/1">Romario Sameh Samir</a></p>
<p>Accurate and efficient classification of different types of cancer is
critical for early detection and effective treatment. In this paper, we present
the results of our experiments using the EfficientNet algorithm for
classification of brain tumor, breast cancer mammography, chest cancer, and
skin cancer. We used publicly available datasets and preprocessed the images to
ensure consistency and comparability. Our experiments show that the
EfficientNet algorithm achieved high accuracy, precision, recall, and F1 scores
on each of the cancer datasets, outperforming other state-of-the-art algorithms
in the literature. We also discuss the strengths and weaknesses of the
EfficientNet algorithm and its potential applications in clinical practice. Our
results suggest that the EfficientNet algorithm is well-suited for
classification of different types of cancer and can be used to improve the
accuracy and efficiency of cancer diagnosis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.11140">Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Cordonnier_M/0/1/0/all/0/1">Matthieu Cordonnier</a>, <a href="http://arxiv.org/find/stat/1/au:+Keriven_N/0/1/0/all/0/1">Nicolas Keriven</a>, <a href="http://arxiv.org/find/stat/1/au:+Tremblay_N/0/1/0/all/0/1">Nicolas Tremblay</a>, <a href="http://arxiv.org/find/stat/1/au:+Vaiter_S/0/1/0/all/0/1">Samuel Vaiter</a></p>
<p>We study the convergence of message passing graph neural networks on random
graph models to their continuous counterpart as the number of nodes tends to
infinity. Until now, this convergence was only known for architectures with
aggregation functions in the form of normalized means, or, equivalently, of an
application of classical operators like the adjacency matrix or the graph
Laplacian. We extend such results to a large class of aggregation functions,
that encompasses all classically used message passing graph neural networks,
such as attention-based message passing, max convolutional message passing or
(degree-normalized) convolutional message passing. Under mild assumptions, we
give non-asymptotic bounds with high probability to quantify this convergence.
Our main result is based on the McDiarmid inequality. Interestingly, this
result does not apply to the case where the aggregation is a coordinate-wise
maximum. We treat this case separately and obtain a different convergence rate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.11336">Differentially Private Synthetic Data Generation via Lipschitz-Regularised Variational Autoencoders. (arXiv:2304.11336v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gross_B/0/1/0/all/0/1">Benedikt Gro&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Wunder_G/0/1/0/all/0/1">Gerhard Wunder</a></p>
<p>Synthetic data has been hailed as the silver bullet for privacy preserving
data analysis. If a record is not real, then how could it violate a person's
privacy? In addition, deep-learning based generative models are employed
successfully to approximate complex high-dimensional distributions from data
and draw realistic samples from this learned distribution. It is often
overlooked though that generative models are prone to memorising many details
of individual training records and often generate synthetic data that too
closely resembles the underlying sensitive training data, hence violating
strong privacy regulations as, e.g., encountered in health care. Differential
privacy is the well-known state-of-the-art framework for guaranteeing
protection of sensitive individuals' data, allowing aggregate statistics and
even machine learning models to be released publicly without compromising
privacy. The training mechanisms however often add too much noise during the
training process, and thus severely compromise the utility of these private
models. Even worse, the tight privacy budgets do not allow for many training
epochs so that model quality cannot be properly controlled in practice. In this
paper we explore an alternative approach for privately generating data that
makes direct use of the inherent stochasticity in generative models, e.g.,
variational autoencoders. The main idea is to appropriately constrain the
continuity modulus of the deep models instead of adding another noise mechanism
on top. For this approach, we derive mathematically rigorous privacy guarantees
and illustrate its effectiveness with practical experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.12330">Parallel bootstrap-based on-policy deep reinforcement learning for continuous flow control applications. (arXiv:2304.12330v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Viquerat_J/0/1/0/all/0/1">J. Viquerat</a>, <a href="http://arxiv.org/find/cs/1/au:+Hachem_E/0/1/0/all/0/1">E. Hachem</a></p>
<p>The coupling of deep reinforcement learning to numerical flow control
problems has recently received a considerable attention, leading to
groundbreaking results and opening new perspectives for the domain. Due to the
usually high computational cost of fluid dynamics solvers, the use of parallel
environments during the learning process represents an essential ingredient to
attain efficient control in a reasonable time. Yet, most of the deep
reinforcement learning literature for flow control relies on on-policy
algorithms, for which the massively parallel transition collection may break
theoretical assumptions and lead to suboptimal control models. To overcome this
issue, we propose a parallelism pattern relying on partial-trajectory buffers
terminated by a return bootstrapping step, allowing a flexible use of parallel
environments while preserving the on-policiness of the updates. This approach
is illustrated on a CPU-intensive continuous flow control problem from the
literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.07804">Improving Small Language Models on PubMedQA via Generative Data Augmentation. (arXiv:2305.07804v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shangdi Yu</a></p>
<p>Large Language Models (LLMs) have made remarkable advancements in the field
of natural language processing. However, their increasing size poses challenges
in terms of computational cost. On the other hand, Small Language Models (SLMs)
are known for their efficiency, but they often struggle with limited capacity
and training data, especially in specific domains. In this paper, we introduce
a novel method aimed at improving SLMs in the medical domain using LLM-based
generative data augmentation. The objective of our approach is to develop more
efficient and capable models that are specifically tailored for specialized
applications. Through experiments conducted on the PubMedQA dataset, we
demonstrate the effectiveness of LLMs in refining and diversifying existing
question-answer pairs. This refinement process leads to improved performance in
a significantly smaller model after fine-tuning. Notably, our best SLM, with
under 1.6 billion parameters, outperforms the few-shot GPT-4 on the PubMedQA
dataset. Our code and generated data are publicly available to facilitate
further explorations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15639">Revisiting Generalized p-Laplacian Regularized Framelet GCNs: Convergence, Energy Dynamic and Training with Non-Linear Diffusion. (arXiv:2305.15639v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiqi Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qibin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a></p>
<p>This paper presents a comprehensive theoretical analysis of the graph
p-Laplacian regularized framelet network (pL-UFG) to establish a solid
understanding of its properties. We conduct a convergence analysis on pL-UFG,
addressing the gap in the understanding of its asymptotic behaviors. Further by
investigating the generalized Dirichlet energy of pL-UFG, we demonstrate that
the Dirichlet energy remains non-zero throughout convergence, ensuring the
avoidance of over-smoothing issues. Additionally, we elucidate the energy
dynamic perspective, highlighting the synergistic relationship between the
implicit layer in pL-UFG and graph framelets. This synergy enhances the model's
adaptability to both homophilic and heterophilic data. Notably, we reveal that
pL-UFG can be interpreted as a generalized non-linear diffusion process,
thereby bridging the gap between pL-UFG and differential equations on the
graph. Importantly, these multifaceted analyses lead to unified conclusions
that offer novel insights for understanding and implementing pL-UFG, as well as
other graph neural network (GNN) models. Finally, based on our dynamic
analysis, we propose two novel pL-UFG models with manually controlled energy
dynamics. We demonstrate empirically and theoretically that our proposed models
not only inherit the advantages of pL-UFG but also significantly reduce
computational costs for training on large-scale graph datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03570">Personalization Disentanglement for Federated Learning: An explainable perspective. (arXiv:2306.03570v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1">Peng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1">Guodong Long</a></p>
<p>Personalized federated learning (PFL) jointly trains a variety of local
models through balancing between knowledge sharing across clients and model
personalization per client. This paper addresses PFL via explicit disentangling
latent representations into two parts to capture the shared knowledge and
client-specific personalization, which leads to more reliable and effective
PFL. The disentanglement is achieved by a novel Federated Dual Variational
Autoencoder (FedDVA), which employs two encoders to infer the two types of
representations. FedDVA can produce a better understanding of the trade-off
between global knowledge sharing and local personalization in PFL. Moreover, it
can be integrated with existing FL methods and turn them into personalized
models for heterogeneous downstream tasks. Extensive experiments validate the
advantages caused by disentanglement and show that models trained with
disentangled representations substantially outperform those vanilla methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06283">14 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon. (arXiv:2306.06283v3 [cond-mat.mtrl-sci] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Jablonka_K/0/1/0/all/0/1">Kevin Maik Jablonka</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ai_Q/0/1/0/all/0/1">Qianxiang Ai</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Al_Feghali_A/0/1/0/all/0/1">Alexander Al-Feghali</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Badhwar_S/0/1/0/all/0/1">Shruti Badhwar</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Bocarsly_J/0/1/0/all/0/1">Joshua D. Bocarsly</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Bran_A/0/1/0/all/0/1">Andres M Bran</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Bringuier_S/0/1/0/all/0/1">Stefan Bringuier</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Brinson_L/0/1/0/all/0/1">L. Catherine Brinson</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Choudhary_K/0/1/0/all/0/1">Kamal Choudhary</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Circi_D/0/1/0/all/0/1">Defne Circi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Cox_S/0/1/0/all/0/1">Sam Cox</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Jong_W/0/1/0/all/0/1">Wibe A. de Jong</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Evans_M/0/1/0/all/0/1">Matthew L. Evans</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Gastellu_N/0/1/0/all/0/1">Nicolas Gastellu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Genzling_J/0/1/0/all/0/1">Jerome Genzling</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Gil_M/0/1/0/all/0/1">Mar&#xed;a Victoria Gil</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Gupta_A/0/1/0/all/0/1">Ankur K. Gupta</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Hong_Z/0/1/0/all/0/1">Zhi Hong</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Imran_A/0/1/0/all/0/1">Alishba Imran</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kruschwitz_S/0/1/0/all/0/1">Sabine Kruschwitz</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Labarre_A/0/1/0/all/0/1">Anne Labarre</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lala_J/0/1/0/all/0/1">Jakub L&#xe1;la</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Liu_T/0/1/0/all/0/1">Tao Liu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ma_S/0/1/0/all/0/1">Steven Ma</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Majumdar_S/0/1/0/all/0/1">Sauradeep Majumdar</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Merz_G/0/1/0/all/0/1">Garrett W. Merz</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Moitessier_N/0/1/0/all/0/1">Nicolas Moitessier</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Moubarak_E/0/1/0/all/0/1">Elias Moubarak</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Mourino_B/0/1/0/all/0/1">Beatriz Mouri&#xf1;o</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Pelkie_B/0/1/0/all/0/1">Brenden Pelkie</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Pieler_M/0/1/0/all/0/1">Michael Pieler</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ramos_M/0/1/0/all/0/1">Mayk Caldas Ramos</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Rankovic_B/0/1/0/all/0/1">Bojana Rankovi&#x107;</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Rodriques_S/0/1/0/all/0/1">Samuel G. Rodriques</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Sanders_J/0/1/0/all/0/1">Jacob N. Sanders</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Schwaller_P/0/1/0/all/0/1">Philippe Schwaller</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Schwarting_M/0/1/0/all/0/1">Marcus Schwarting</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Shi_J/0/1/0/all/0/1">Jiale Shi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Smit_B/0/1/0/all/0/1">Berend Smit</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Smith_B/0/1/0/all/0/1">Ben E. Smith</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Herck_J/0/1/0/all/0/1">Joren Van Herck</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Volker_C/0/1/0/all/0/1">Christoph V&#xf6;lker</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ward_L/0/1/0/all/0/1">Logan Ward</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Warren_S/0/1/0/all/0/1">Sean Warren</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Weiser_B/0/1/0/all/0/1">Benjamin Weiser</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zhang_S/0/1/0/all/0/1">Sylvester Zhang</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoqi Zhang</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zia_G/0/1/0/all/0/1">Ghezal Ahmad Zia</a>, et al. (5 additional authors not shown)</p>
<p>Large-language models (LLMs) such as GPT-4 caught the interest of many
scientists. Recent studies suggested that these models could be useful in
chemistry and materials science. To explore these possibilities, we organized a
hackathon.
</p>
<p>This article chronicles the projects built as part of this hackathon.
Participants employed LLMs for various applications, including predicting
properties of molecules and materials, designing novel interfaces for tools,
extracting knowledge from unstructured data, and developing new educational
applications.
</p>
<p>The diverse topics and the fact that working prototypes could be generated in
less than two days highlight that LLMs will profoundly impact the future of our
fields. The rich collection of ideas and projects also indicates that the
applications of LLMs are not limited to materials science and chemistry but
offer potential benefits to a wide range of scientific disciplines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10045">Efficient Approximations of Complete Interatomic Potentials for Crystal Property Prediction. (arXiv:2306.10045v5 [physics.chem-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Lin_Y/0/1/0/all/0/1">Yuchao Lin</a>, <a href="http://arxiv.org/find/physics/1/au:+Yan_K/0/1/0/all/0/1">Keqiang Yan</a>, <a href="http://arxiv.org/find/physics/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Qian_X/0/1/0/all/0/1">Xiaoning Qian</a>, <a href="http://arxiv.org/find/physics/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a></p>
<p>We study property prediction for crystal materials. A crystal structure
consists of a minimal unit cell that is repeated infinitely in 3D space. How to
accurately represent such repetitive structures in machine learning models
remains unresolved. Current methods construct graphs by establishing edges only
between nearby nodes, thereby failing to faithfully capture infinite repeating
patterns and distant interatomic interactions. In this work, we propose several
innovations to overcome these limitations. First, we propose to model
physics-principled interatomic potentials directly instead of only using
distances as in many existing methods. These potentials include the Coulomb
potential, London dispersion potential, and Pauli repulsion potential. Second,
we model the complete set of potentials among all atoms, instead of only
between nearby atoms as in existing methods. This is enabled by our
approximations of infinite potential summations with provable error bounds. We
further develop efficient algorithms to compute the approximations. Finally, we
propose to incorporate our computations of complete interatomic potentials into
message passing neural networks for representation learning. We perform
experiments on the JARVIS and Materials Project benchmarks for evaluation.
Results show that the use of interatomic potentials and complete interatomic
potentials leads to consistent performance improvements with reasonable
computational costs. Our code is publicly available as part of the AIRS library
(https://github.com/divelab/AIRS/tree/main/OpenMat/PotNet).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11740">A survey on deep learning approaches for data integration in autonomous driving system. (arXiv:2306.11740v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Likang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Caifa Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiya Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yue Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a></p>
<p>The perception module of self-driving vehicles relies on a multi-sensor
system to understand its environment. Recent advancements in deep learning have
led to the rapid development of approaches that integrate multi-sensory
measurements to enhance perception capabilities. This paper surveys the latest
deep learning integration techniques applied to the perception module in
autonomous driving systems, categorizing integration approaches based on "what,
how, and when to integrate". A new taxonomy of integration is proposed, based
on three dimensions: multi-view, multi-modality, and multi-frame. The
integration operations and their pros and cons are summarized, providing new
insights into the properties of an "ideal" data integration approach that can
alleviate the limitations of existing methods. After reviewing hundreds of
relevant papers, this survey concludes with a discussion of the key features of
an optimal data integration approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.13339">TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support. (arXiv:2306.13339v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zheng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_J/0/1/0/all/0/1">Jiahe Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertino_E/0/1/0/all/0/1">Elisa Bertino</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a></p>
<p>Trust evaluation assesses trust relationships between entities and
facilitates decision-making. Machine Learning (ML) shows great potential for
trust evaluation owing to its learning capabilities. In recent years, Graph
Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in
dealing with graph data. This has motivated researchers to explore their use in
trust evaluation, as trust relationships among entities can be modeled as a
graph. However, current trust evaluation methods that employ GNNs fail to fully
satisfy the dynamic nature of trust, overlook the adverse effects of attacks on
trust evaluation, and cannot provide convincing explanations on evaluation
results. To address these problems, we propose TrustGuard, a GNN-based accurate
trust evaluation model that supports trust dynamicity, is robust against
typical attacks, and provides explanations through visualization. Specifically,
TrustGuard is designed with a layered architecture that contains a snapshot
input layer, a spatial aggregation layer, a temporal aggregation layer, and a
prediction layer. Among them, the spatial aggregation layer adopts a defense
mechanism to robustly aggregate local trust, and the temporal aggregation layer
applies an attention mechanism for effective learning of temporal patterns.
Extensive experiments on two real-world datasets show that TrustGuard
outperforms state-of-the-art GNN-based trust evaluation models with respect to
trust prediction across single-timeslot and multi-timeslot, even in the
presence of attacks. In addition, TrustGuard can explain its evaluation results
by visualizing both spatial and temporal views.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00268">Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning. (arXiv:2307.00268v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md Tamjid Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1">Hung La</a></p>
<p>Lately, differential privacy (DP) has been introduced in cooperative
multiagent reinforcement learning (CMARL) to safeguard the agents' privacy
against adversarial inference during knowledge sharing. Nevertheless, we argue
that the noise introduced by DP mechanisms may inadvertently give rise to a
novel poisoning threat, specifically in the context of private knowledge
sharing during CMARL, which remains unexplored in the literature. To address
this shortcoming, we present an adaptive, privacy-exploiting, and
evasion-resilient localized poisoning attack (PeLPA) that capitalizes on the
inherent DP-noise to circumvent anomaly detection systems and hinder the
optimal convergence of the CMARL model. We rigorously evaluate our proposed
PeLPA attack in diverse environments, encompassing both non-adversarial and
multiple-adversarial contexts. Our findings reveal that, in a medium-scale
environment, the PeLPA attack with attacker ratios of 20% and 40% can lead to
an increase in average steps to goal by 50.69% and 64.41%, respectively.
Furthermore, under similar conditions, PeLPA can result in a 1.4x and 1.6x
computational time increase in optimal reward attainment and a 1.18x and 1.38x
slower convergence for attacker ratios of 20% and 40%, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00858">Beyond the Snapshot: Brain Tokenized Graph Transformer for Longitudinal Brain Functional Connectome Embedding. (arXiv:2307.00858v2 [q-bio.NC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Dong_Z/0/1/0/all/0/1">Zijian Dong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_Y/0/1/0/all/0/1">Yilei Wu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xiao_Y/0/1/0/all/0/1">Yu Xiao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chong_J/0/1/0/all/0/1">Joanna Su Xian Chong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jin_Y/0/1/0/all/0/1">Yueming Jin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhou_J/0/1/0/all/0/1">Juan Helen Zhou</a></p>
<p>Under the framework of network-based neurodegeneration, brain functional
connectome (FC)-based Graph Neural Networks (GNN) have emerged as a valuable
tool for the diagnosis and prognosis of neurodegenerative diseases such as
Alzheimer's disease (AD). However, these models are tailored for brain FC at a
single time point instead of characterizing FC trajectory. Discerning how FC
evolves with disease progression, particularly at the predementia stages such
as cognitively normal individuals with amyloid deposition or individuals with
mild cognitive impairment (MCI), is crucial for delineating disease spreading
patterns and developing effective strategies to slow down or even halt disease
advancement. In this work, we proposed the first interpretable framework for
brain FC trajectory embedding with application to neurodegenerative disease
diagnosis and prognosis, namely Brain Tokenized Graph Transformer (Brain
TokenGT). It consists of two modules: 1) Graph Invariant and Variant Embedding
(GIVE) for generation of node and spatio-temporal edge embeddings, which were
tokenized for downstream processing; 2) Brain Informed Graph Transformer
Readout (BIGTR) which augments previous tokens with trainable type identifiers
and non-trainable node identifiers and feeds them into a standard transformer
encoder to readout. We conducted extensive experiments on two public
longitudinal fMRI datasets of the AD continuum for three tasks, including
differentiating MCI from controls, predicting dementia conversion in MCI, and
classification of amyloid positive or negative cognitively normal individuals.
Based on brain FC trajectory, the proposed Brain TokenGT approach outperformed
all the other benchmark models and at the same time provided excellent
interpretability. The code is available at
https://github.com/ZijianD/Brain-TokenGT.git
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01316">Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach. (arXiv:2307.01316v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharifi_I/0/1/0/all/0/1">Iman Sharifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yildirim_M/0/1/0/all/0/1">Mustafa Yildirim</a>, <a href="http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1">Saber Fallah</a></p>
<p>The dynamic nature of driving environments and the presence of diverse road
users pose significant challenges for decision-making in autonomous driving.
Deep reinforcement learning (DRL) has emerged as a popular approach to tackle
this problem. However, the application of existing DRL solutions is mainly
confined to simulated environments due to safety concerns, impeding their
deployment in real-world. To overcome this limitation, this paper introduces a
novel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics
(DRLSL) that combines the strengths of DRL (learning from experience) and
symbolic first-order logics (knowledge-driven reasoning) to enable safe
learning in real-time interactions of autonomous driving within real
environments. This innovative approach provides a means to learn autonomous
driving policies by actively engaging with the physical environment while
ensuring safety. We have implemented the DRLSL framework in autonomous driving
using the highD dataset and demonstrated that our method successfully avoids
unsafe actions during both the training and testing phases. Furthermore, our
results indicate that DRLSL achieves faster convergence during training and
exhibits better generalizability to new driving scenarios compared to
traditional DRL methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01497">Accelerated stochastic approximation with state-dependent noise. (arXiv:2307.01497v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Ilandarideva_S/0/1/0/all/0/1">Sasila Ilandarideva</a>, <a href="http://arxiv.org/find/math/1/au:+Juditsky_A/0/1/0/all/0/1">Anatoli Juditsky</a>, <a href="http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1">Guanghui Lan</a>, <a href="http://arxiv.org/find/math/1/au:+Li_T/0/1/0/all/0/1">Tianjiao Li</a></p>
<p>We consider a class of stochastic smooth convex optimization problems under
rather general assumptions on the noise in the stochastic gradient observation.
As opposed to the classical problem setting in which the variance of noise is
assumed to be uniformly bounded, herein we assume that the variance of
stochastic gradients is related to the "sub-optimality" of the approximate
solutions delivered by the algorithm. Such problems naturally arise in a
variety of applications, in particular, in the well-known generalized linear
regression problem in statistics. However, to the best of our knowledge, none
of the existing stochastic approximation algorithms for solving this class of
problems attain optimality in terms of the dependence on accuracy, problem
parameters, and mini-batch size.
</p>
<p>We discuss two non-Euclidean accelerated stochastic approximation
routines--stochastic accelerated gradient descent (SAGD) and stochastic
gradient extrapolation (SGE)--which carry a particular duality relationship. We
show that both SAGD and SGE, under appropriate conditions, achieve the optimal
convergence rate, attaining the optimal iteration and sample complexities
simultaneously. However, corresponding assumptions for the SGE algorithm are
more general; they allow, for instance, for efficient application of the SGE to
statistical estimation problems under heavy tail noises and discontinuous score
functions. We also discuss the application of the SGE to problems satisfying
quadratic growth conditions, and show how it can be used to recover sparse
solutions. Finally, we report on some simulation experiments to illustrate
numerical performance of our proposed algorithms in high-dimensional settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02719">Understanding Uncertainty Sampling. (arXiv:2307.02719v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaocheng Li</a></p>
<p>Uncertainty sampling is a prevalent active learning algorithm that queries
sequentially the annotations of data samples which the current prediction model
is uncertain about. However, the usage of uncertainty sampling has been largely
heuristic: (i) There is no consensus on the proper definition of "uncertainty"
for a specific task under a specific loss; (ii) There is no theoretical
guarantee that prescribes a standard protocol to implement the algorithm, for
example, how to handle the sequentially arrived annotated data under the
framework of optimization algorithms such as stochastic gradient descent. In
this work, we systematically examine uncertainty sampling algorithms under both
stream-based and pool-based active learning. We propose a notion of equivalent
loss which depends on the used uncertainty measure and the original loss
function and establish that an uncertainty sampling algorithm essentially
optimizes against such an equivalent loss. The perspective verifies the
properness of existing uncertainty measures from two aspects: surrogate
property and loss convexity. Furthermore, we propose a new notion for designing
uncertainty measures called \textit{loss as uncertainty}. The idea is to use
the conditional expected loss given the features as the uncertainty measure.
Such an uncertainty measure has nice analytical properties and generality to
cover both classification and regression problems, which enable us to provide
the first generalization bound for uncertainty sampling algorithms under both
stream-based and pool-based settings, in the full generality of the underlying
model and problem. Lastly, we establish connections between certain variants of
the uncertainty sampling algorithms with risk-sensitive objectives and
distributional robustness, which can partly explain the advantage of
uncertainty sampling algorithms when the sample size is small.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03854">inTformer: A Time-Embedded Attention-Based Transformer for Crash Likelihood Prediction at Intersections Using Connected Vehicle Data. (arXiv:2307.03854v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anik_B/0/1/0/all/0/1">B.M. Tazbiul Hassan Anik</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_Z/0/1/0/all/0/1">Zubayer Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdel_Aty_M/0/1/0/all/0/1">Mohamed Abdel-Aty</a></p>
<p>The real-time crash likelihood prediction model is an essential component of
the proactive traffic safety management system. Over the years, numerous
studies have attempted to construct a crash likelihood prediction model in
order to enhance traffic safety, but mostly on freeways. In the majority of the
existing studies, researchers have primarily employed a deep learning-based
framework to identify crash potential. Lately, Transformer has emerged as a
potential deep neural network that fundamentally operates through
attention-based mechanisms. Transformer has several functional benefits over
extant deep learning models such as Long Short-Term Memory (LSTM), Convolution
Neural Network (CNN), etc. Firstly, Transformer can readily handle long-term
dependencies in a data sequence. Secondly, Transformers can parallelly process
all elements in a data sequence during training. Finally, a Transformer does
not have the vanishing gradient issue. Realizing the immense possibility of
Transformers, this paper proposes inTersection-Transformer (inTformer), a
time-embedded attention-based Transformer model that can effectively predict
intersection crash likelihood in real-time. The proposed model was evaluated
using connected vehicle data extracted from INRIX and Center for Advanced
Transportation Technology (CATT) Lab's Signal Analytics Platform. The data was
parallelly formatted and stacked at different timesteps to develop nine
inTformer models. The best inTformer model achieved a sensitivity of 73%. This
model was also compared to earlier studies on crash likelihood prediction at
intersections and with several established deep learning models trained on the
same connected vehicle dataset. In every scenario, this inTformer outperformed
the benchmark models confirming the viability of the proposed inTformer
architecture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03875">Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mellou_K/0/1/0/all/0/1">Konstantina Mellou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathuri_J/0/1/0/all/0/1">Jeevan Pathuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Menache_I/0/1/0/all/0/1">Ishai Menache</a></p>
<p>Supply chain operations traditionally involve a variety of complex decision
making problems. Over the last few decades, supply chains greatly benefited
from advances in computation, which allowed the transition from manual
processing to automation and cost-effective optimization. Nonetheless, business
operators still need to spend substantial efforts in explaining and
interpreting the optimization outcomes to stakeholders. Motivated by the recent
advances in Large Language Models (LLMs), we study how this disruptive
technology can help bridge the gap between supply chain automation and human
comprehension and trust thereof. We design OptiGuide -- a framework that
accepts as input queries in plain text, and outputs insights about the
underlying optimization outcomes. Our framework does not forgo the
state-of-the-art combinatorial optimization technology, but rather leverages it
to quantitatively answer what-if scenarios (e.g., how would the cost change if
we used supplier B instead of supplier A for a given demand?). Importantly, our
design does not require sending proprietary data over to LLMs, which can be a
privacy concern in some circumstances. We demonstrate the effectiveness of our
framework on a real server placement scenario within Microsoft's cloud supply
chain. Along the way, we develop a general evaluation benchmark, which can be
used to evaluate the accuracy of the LLM output in other scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05845">PIGEON: Predicting Image Geolocations. (arXiv:2307.05845v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Haas_L/0/1/0/all/0/1">Lukas Haas</a>, <a href="http://arxiv.org/find/cs/1/au:+Skreta_M/0/1/0/all/0/1">Michal Skreta</a>, <a href="http://arxiv.org/find/cs/1/au:+Alberti_S/0/1/0/all/0/1">Silas Alberti</a></p>
<p>We introduce PIGEON, a multi-task end-to-end system for planet-scale image
geolocalization that achieves state-of-the-art performance on both external
benchmarks and in human evaluation. Our work incorporates semantic geocell
creation with label smoothing, conducts pretraining of a vision transformer on
images with geographic information, and refines location predictions with
ProtoNets across a candidate set of geocells. The contributions of PIGEON are
three-fold: first, we design a semantic geocells creation and splitting
algorithm based on open-source data which can be adapted to any geospatial
dataset. Second, we show the effectiveness of intra-geocell refinement and the
applicability of unsupervised clustering and ProtNets to the task. Finally, we
make our pre-trained CLIP transformer model, StreetCLIP, publicly available for
use in adjacent domains with applications to fighting climate change and urban
and rural scene understanding.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05888">Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud Computing Environment. (arXiv:2307.05888v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuling Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1">Guangzhi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1">Pan Hui</a></p>
<p>In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to
empower various areas as a bridge between physical objects and the digital
world. Through virtualization and simulation techniques, multiple functions can
be achieved by leveraging computing resources. In this process, Mobile Cloud
Computing (MCC) and Mobile Edge Computing (MEC) have become two of the key
factors to achieve real-time feedback. However, current works only considered
edge servers or cloud servers in the DT system models. Besides, The models
ignore the DT with not only one data resource. In this paper, we propose a new
DT system model considering a heterogeneous MEC/MCC environment. Each DT in the
model is maintained in one of the servers via multiple data collection devices.
The offloading decision-making problem is also considered and a new offloading
scheme is proposed based on Distributed Deep Learning (DDL). Simulation results
demonstrate that our proposed algorithm can effectively and efficiently
decrease the system's average latency and energy consumption. Significant
improvement is achieved compared with the baselines under the dynamic
environment of DTs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05926">Filling time-series gaps using image techniques: Multidimensional context autoencoder approach for building energy data imputation. (arXiv:2307.05926v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chun Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Quintana_M/0/1/0/all/0/1">Matias Quintana</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_Z/0/1/0/all/0/1">Zoltan Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_C/0/1/0/all/0/1">Clayton Miller</a></p>
<p>Building energy prediction and management has become increasingly important
in recent decades, driven by the growth of Internet of Things (IoT) devices and
the availability of more energy data. However, energy data is often collected
from multiple sources and can be incomplete or inconsistent, which can hinder
accurate predictions and management of energy systems and limit the usefulness
of the data for decision-making and research. To address this issue, past
studies have focused on imputing missing gaps in energy data, including random
and continuous gaps. One of the main challenges in this area is the lack of
validation on a benchmark dataset with various building and meter types, making
it difficult to accurately evaluate the performance of different imputation
methods. Another challenge is the lack of application of state-of-the-art
imputation methods for missing gaps in energy data. Contemporary
image-inpainting methods, such as Partial Convolution (PConv), have been widely
used in the computer vision domain and have demonstrated their effectiveness in
dealing with complex missing patterns. To study whether energy data imputation
can benefit from the image-based deep learning method, this study compared
PConv, Convolutional neural networks (CNNs), and weekly persistence method
using one of the biggest publicly available whole building energy datasets,
consisting of 1479 power meters worldwide, as the benchmark. The results show
that, compared to the CNN with the raw time series (1D-CNN) and the weekly
persistence method, neural network models with reshaped energy data with two
dimensions reduced the Mean Squared Error (MSE) by 10% to 30%. The advanced
deep learning method, Partial convolution (PConv), has further reduced the MSE
by 20-30% than 2D-CNN and stands out among all models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06324">Provably Faster Gradient Descent via Long Steps. (arXiv:2307.06324v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Grimmer_B/0/1/0/all/0/1">Benjamin Grimmer</a></p>
<p>This work establishes provably faster convergence rates for gradient descent
via a computer-assisted analysis technique. Our theory allows nonconstant
stepsize policies with frequent long steps potentially violating descent by
analyzing the overall effect of many iterations at once rather than the typical
one-iteration inductions used in most first-order method analyses. We show that
long steps, which may increase the objective value in the short term, lead to
provably faster convergence in the long term. A conjecture towards proving a
faster $O(1/T\log T)$ rate for gradient descent is also motivated along with
simple numerical validation.
</p>
</p>
</div>

    </div>
    </body>
    