<!DOCTYPE html>
<html>
<head>
<title>2023-07-08-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.02491">TablEye: Seeing small Tables through the Lens of Images. (arXiv:2307.02491v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seung-eon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sang-Chul Lee</a></p>
<p>The exploration of few-shot tabular learning becomes imperative. Tabular data
is a versatile representation that captures diverse information, yet it is not
exempt from limitations, property of data and model size. Labeling extensive
tabular data can be challenging, and it may not be feasible to capture every
important feature. Few-shot tabular learning, however, remains relatively
unexplored, primarily due to scarcity of shared information among independent
datasets and the inherent ambiguity in defining boundaries within tabular data.
To the best of our knowledge, no meaningful and unrestricted few-shot tabular
learning techniques have been developed without imposing constraints on the
dataset. In this paper, we propose an innovative framework called TablEye,
which aims to overcome the limit of forming prior knowledge for tabular data by
adopting domain transformation. It facilitates domain transformation by
generating tabular images, which effectively conserve the intrinsic semantics
of the original tabular data. This approach harnesses rigorously tested
few-shot learning algorithms and embedding functions to acquire and apply prior
knowledge. Leveraging shared data domains allows us to utilize this prior
knowledge, originally learned from the image domain. Specifically, TablEye
demonstrated a superior performance by outstripping the TabLLM in a 4-shot task
with a maximum 0.11 AUC and a STUNT in a 1- shot setting, where it led on
average by 3.17% accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02493">FREEDOM: Target Label &amp; Source Data &amp; Domain Information-Free Multi-Source Domain Adaptation for Unsupervised Personalization. (arXiv:2307.02493v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunju Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_G/0/1/0/all/0/1">Gyusang Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Youn_C/0/1/0/all/0/1">Chan-Hyun Youn</a></p>
<p>From a service perspective, Multi-Source Domain Adaptation (MSDA) is a
promising scenario to adapt a deployed model to a client's dataset. It can
provide adaptation without a target label and support the case where a source
dataset is constructed from multiple domains. However, it is impractical,
wherein its training heavily relies on prior domain information of the
multi-source dataset -- how many domains exist and the domain label of each
data sample. Moreover, MSDA requires both source and target datasets
simultaneously (physically), causing storage limitations on the client device
or data privacy issues by transferring client data to a server. For a more
practical scenario of model adaptation from a service provider's point of view,
we relax these constraints and present a novel problem scenario of Three-Free
Domain Adaptation, namely TFDA, where 1) target labels, 2) source dataset, and
mostly 3) source domain information (domain labels + the number of domains) are
unavailable. Under the problem scenario, we propose a practical adaptation
framework called FREEDOM. It leverages the power of the generative model,
disentangling data into class and style aspects, where the style is defined as
the class-independent information from the source data and designed with a
nonparametric Bayesian approach. In the adaptation stage, FREEDOM aims to match
the source class distribution with the target's under the philosophy that class
distribution is consistent even if the style is different; after then, only
part of the classification model is deployed as a personalized network. As a
result, FREEDOM achieves state-of-the-art or comparable performance even
without domain information, with reduced final model size on the target side,
independent of the number of source domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02496">Learning to reconstruct the bubble distribution with conductivity maps using Invertible Neural Networks and Error Diffusion. (arXiv:2307.02496v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Kumar_N/0/1/0/all/0/1">Nishant Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Krause_L/0/1/0/all/0/1">Lukas Krause</a>, <a href="http://arxiv.org/find/eess/1/au:+Wondrak_T/0/1/0/all/0/1">Thomas Wondrak</a>, <a href="http://arxiv.org/find/eess/1/au:+Eckert_S/0/1/0/all/0/1">Sven Eckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Eckert_K/0/1/0/all/0/1">Kerstin Eckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Gumhold_S/0/1/0/all/0/1">Stefan Gumhold</a></p>
<p>Electrolysis is crucial for eco-friendly hydrogen production, but gas bubbles
generated during the process hinder reactions, reduce cell efficiency, and
increase energy consumption. Additionally, these gas bubbles cause changes in
the conductivity inside the cell, resulting in corresponding variations in the
induced magnetic field around the cell. Therefore, measuring these gas
bubble-induced magnetic field fluctuations using external magnetic sensors and
solving the inverse problem of Biot-Savart Law allows for estimating the
conductivity in the cell and, thus, bubble size and location. However,
determining high-resolution conductivity maps from only a few induced magnetic
field measurements is an ill-posed inverse problem. To overcome this, we
exploit Invertible Neural Networks (INNs) to reconstruct the conductivity
field. Our qualitative results and quantitative evaluation using random error
diffusion show that INN achieves far superior performance compared to Tikhonov
regularization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02497">Multi-gauge Hydrological Variational Data Assimilation: Regionalization Learning with Spatial Gradients using Multilayer Perceptron and Bayesian-Guided Multivariate Regression. (arXiv:2307.02497v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1">Ngo Nghi Truyen Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Garambois_P/0/1/0/all/0/1">Pierre-Andr&#xe9; Garambois</a>, <a href="http://arxiv.org/find/cs/1/au:+Colleoni_F/0/1/0/all/0/1">Fran&#xe7;ois Colleoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Renard_B/0/1/0/all/0/1">Benjamin Renard</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_H/0/1/0/all/0/1">H&#xe9;l&#xe8;ne Roux</a> (IMFT)</p>
<p>Tackling the difficult problem of estimating spatially distributed
hydrological parameters, especially for floods on ungauged watercourses, this
contribution presents a novel seamless regionalization technique for learning
complex regional transfer functions designed for high-resolution hydrological
models. The transfer functions rely on: (i) a multilayer perceptron enabling a
seamless flow of gradient computation to employ machine learning optimization
algorithms, or (ii) a multivariate regression mapping optimized by variational
data assimilation algorithms and guided by Bayesian estimation, addressing the
equifinality issue of feasible solutions. The approach involves incorporating
the inferable regionalization mappings into a differentiable hydrological model
and optimizing a cost function computed on multi-gauge data with accurate
adjoint-based spatially distributed gradients.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02501">Generalization Guarantees via Algorithm-dependent Rademacher Complexity. (arXiv:2307.02501v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Sachs_S/0/1/0/all/0/1">Sarah Sachs</a>, <a href="http://arxiv.org/find/stat/1/au:+Erven_T/0/1/0/all/0/1">Tim van Erven</a>, <a href="http://arxiv.org/find/stat/1/au:+Hodgkinson_L/0/1/0/all/0/1">Liam Hodgkinson</a>, <a href="http://arxiv.org/find/stat/1/au:+Khanna_R/0/1/0/all/0/1">Rajiv Khanna</a>, <a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1">Umut Simsekli</a></p>
<p>Algorithm- and data-dependent generalization bounds are required to explain
the generalization behavior of modern machine learning algorithms. In this
context, there exists information theoretic generalization bounds that involve
(various forms of) mutual information, as well as bounds based on hypothesis
set stability. We propose a conceptually related, but technically distinct
complexity measure to control generalization error, which is the empirical
Rademacher complexity of an algorithm- and data-dependent hypothesis class.
Combining standard properties of Rademacher complexity with the convenient
structure of this class, we are able to (i) obtain novel bounds based on the
finite fractal dimension, which (a) extend previous fractal dimension-type
bounds from continuous to finite hypothesis classes, and (b) avoid a mutual
information term that was required in prior work; (ii) we greatly simplify the
proof of a recent dimension-independent generalization bound for stochastic
gradient descent; and (iii) we easily recover results for VC classes and
compression schemes, similar to approaches based on conditional mutual
information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02507">STS-CCL: Spatial-Temporal Synchronous Contextual Contrastive Learning for Urban Traffic Forecasting. (arXiv:2307.02507v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lincan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaixiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Fengji Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1">Jichao Bi</a></p>
<p>Efficiently capturing the complex spatiotemporal representations from
large-scale unlabeled traffic data remains to be a challenging task. In
considering of the dilemma, this work employs the advanced contrastive learning
and proposes a novel Spatial-Temporal Synchronous Contextual Contrastive
Learning (STS-CCL) model. First, we elaborate the basic and strong augmentation
methods for spatiotemporal graph data, which not only perturb the data in terms
of graph structure and temporal characteristics, but also employ a
learning-based dynamic graph view generator for adaptive augmentation. Second,
we introduce a Spatial-Temporal Synchronous Contrastive Module (STS-CM) to
simultaneously capture the decent spatial-temporal dependencies and realize
graph-level contrasting. To further discriminate node individuals in negative
filtering, a Semantic Contextual Contrastive method is designed based on
semantic features and spatial heterogeneity, achieving node-level contrastive
learning along with negative filtering. Finally, we present a hard mutual-view
contrastive training scheme and extend the classic contrastive loss to an
integrated objective function, yielding better performance. Extensive
experiments and evaluations demonstrate that building a predictor upon STS-CCL
contrastive learning model gains superior performance than existing traffic
forecasting benchmarks. The proposed STS-CCL is highly suitable for large
datasets with only a few labeled data and other spatiotemporal tasks with data
scarcity issue.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02509">Wasserstein Auto-Encoders of Merge Trees (and Persistence Diagrams). (arXiv:2307.02509v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pont_M/0/1/0/all/0/1">Mahieu Pont</a>, <a href="http://arxiv.org/find/cs/1/au:+Tierny_J/0/1/0/all/0/1">Julien Tierny</a></p>
<p>This paper presents a computational framework for the Wasserstein
auto-encoding of merge trees (MT-WAE), a novel extension of the classical
auto-encoder neural network architecture to the Wasserstein metric space of
merge trees. In contrast to traditional auto-encoders which operate on
vectorized data, our formulation explicitly manipulates merge trees on their
associated metric space at each layer of the network, resulting in superior
accuracy and interpretability. Our novel neural network approach can be
interpreted as a non-linear generalization of previous linear attempts [65] at
merge tree encoding. It also trivially extends to persistence diagrams.
Extensive experiments on public ensembles demonstrate the efficiency of our
algorithms, with MT-WAE computations in the orders of minutes on average. We
show the utility of our contributions in two applications adapted from previous
work on merge tree encoding [65]. First, we apply MT-WAE to data reduction and
reliably compress merge trees by concisely representing them with their
coordinates in the final layer of our auto-encoder. Second, we document an
application to dimensionality reduction, by exploiting the latent space of our
auto-encoder, for the visual analysis of ensemble data. We illustrate the
versatility of our framework by introducing two penalty terms, to help preserve
in the latent space both the Wasserstein distances between merge trees, as well
as their clusters. In both applications, quantitative experiments assess the
relevance of our framework. Finally, we provide a C++ implementation that can
be used for reproducibility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02511">Diffusion Models for Computational Design at the Example of Floor Plans. (arXiv:2307.02511v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ploennigs_J/0/1/0/all/0/1">Joern Ploennigs</a>, <a href="http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1">Markus Berger</a></p>
<p>AI Image generators based on diffusion models are widely discussed recently
for their capability to create images from simple text prompts. But, for
practical use in civil engineering they need to be able to create specific
construction plans for given constraints. Within this paper we explore the
capabilities of those diffusion-based AI generators for computational design at
the example of floor plans and identify their current limitation. We explain
how the diffusion-models work and propose new diffusion models with improved
semantic encoding. In several experiments we show that we can improve validity
of generated floor plans from 6% to 90% and query performance for different
examples. We identify short comings and derive future research challenges of
those models and discuss the need to combine diffusion models with building
information modelling. With this we provide key insights into the current state
and future directions for diffusion models in civil engineering.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02516">Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency. (arXiv:2307.02516v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wald_T/0/1/0/all/0/1">Tassilo Wald</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulrich_C/0/1/0/all/0/1">Constantin Ulrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmerer_D/0/1/0/all/0/1">David Zimmerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehler_G/0/1/0/all/0/1">Gregor Koehler</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_M/0/1/0/all/0/1">Michael Baumgartner</a>, <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1">Klaus H. Maier-Hein</a></p>
<p>Independently trained machine learning models tend to learn similar features.
Given an ensemble of independently trained models, this results in correlated
predictions and common failure modes. Previous attempts focusing on
decorrelation of output predictions or logits yielded mixed results,
particularly due to their reduction in model accuracy caused by conflicting
optimization objectives. In this paper, we propose the novel idea of utilizing
methods of the representational similarity field to promote dissimilarity
during training instead of measuring similarity of trained models. To this end,
we promote intermediate representations to be dissimilar at different depths
between architectures, with the goal of learning robust ensembles with disjoint
failure modes. We show that highly dissimilar intermediate representations
result in less correlated output predictions and slightly lower error
consistency, resulting in higher ensemble accuracy. With this, we shine first
light on the connection between intermediate representations and their impact
on the output predictions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02520">Conditional independence testing under model misspecification. (arXiv:2307.02520v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Polo_F/0/1/0/all/0/1">Felipe Maia Polo</a>, <a href="http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1">Yuekai Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Banerjee_M/0/1/0/all/0/1">Moulinath Banerjee</a></p>
<p>Conditional independence (CI) testing is fundamental and challenging in
modern statistics and machine learning. Many modern methods for CI testing rely
on powerful supervised learning methods to learn regression functions or Bayes
predictors as an intermediate step. Although the methods are guaranteed to
control Type-I error when the supervised learning methods accurately estimate
the regression functions or Bayes predictors, their behavior is less understood
when they fail due to model misspecification. In a broader sense, model
misspecification can arise even when universal approximators (e.g., deep neural
nets) are employed. Then, we study the performance of regression-based CI tests
under model misspecification. Namely, we propose new approximations or upper
bounds for the testing errors of three regression-based tests that depend on
misspecification errors. Moreover, we introduce the Rao-Blackwellized Predictor
Test (RBPT), a novel regression-based CI test robust against model
misspecification. Finally, we conduct experiments with artificial and real
data, showcasing the usefulness of our theory and methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02572">Conditional Korhunen-Lo\&#x27;{e}ve regression model with Basis Adaptation for high-dimensional problems: uncertainty quantification and inverse modeling. (arXiv:2307.02572v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yeung_Y/0/1/0/all/0/1">Yu-Hong Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Tipireddy_R/0/1/0/all/0/1">Ramakrishna Tipireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Barajas_Solano_D/0/1/0/all/0/1">David A. Barajas-Solano</a>, <a href="http://arxiv.org/find/cs/1/au:+Tartakovsky_A/0/1/0/all/0/1">Alexandre M. Tartakovsky</a></p>
<p>We propose a methodology for improving the accuracy of surrogate models of
the observable response of physical systems as a function of the systems'
spatially heterogeneous parameter fields with applications to uncertainty
quantification and parameter estimation in high-dimensional problems.
Practitioners often formulate finite-dimensional representations of spatially
heterogeneous parameter fields using truncated unconditional Karhunen-Lo\'{e}ve
expansions (KLEs) for a certain choice of unconditional covariance kernel and
construct surrogate models of the observable response with respect to the
random variables in the KLE. When direct measurements of the parameter fields
are available, we propose improving the accuracy of these surrogate models by
representing the parameter fields via conditional Karhunen-Lo\'{e}ve expansions
(CKLEs). CKLEs are constructed by conditioning the covariance kernel of the
unconditional expansion on the direct measurements via Gaussian process
regression and then truncating the corresponding KLE. We apply the proposed
methodology to constructing surrogate models via the Basis Adaptation (BA)
method of the stationary hydraulic head response, measured at spatially
discrete observation locations, of a groundwater flow model of the Hanford
Site, as a function of the 1,000-dimensional representation of the model's
log-transmissivity field. We find that BA surrogate models of the hydraulic
head based on CKLEs are more accurate than BA surrogate models based on
unconditional expansions for forward uncertainty quantification tasks.
Furthermore, we find that inverse estimates of the hydraulic transmissivity
field computed using CKLE-based BA surrogate models are more accurate than
those computed using unconditional BA surrogate models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02574">Semi-supervised Learning from Street-View Images and OpenStreetMap for Automatic Building Height Estimation. (arXiv:2307.02574v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhendong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dax_G/0/1/0/all/0/1">Gabriel Dax</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_G/0/1/0/all/0/1">Gefei Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Hongchao Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zipf_A/0/1/0/all/0/1">Alexander Zipf</a>, <a href="http://arxiv.org/find/cs/1/au:+Werner_M/0/1/0/all/0/1">Martin Werner</a></p>
<p>Accurate building height estimation is key to the automatic derivation of 3D
city models from emerging big geospatial data, including Volunteered
Geographical Information (VGI). However, an automatic solution for large-scale
building height estimation based on low-cost VGI data is currently missing. The
fast development of VGI data platforms, especially OpenStreetMap (OSM) and
crowdsourced street-view images (SVI), offers a stimulating opportunity to fill
this research gap. In this work, we propose a semi-supervised learning (SSL)
method of automatically estimating building height from Mapillary SVI and OSM
data to generate low-cost and open-source 3D city modeling in LoD1. The
proposed method consists of three parts: first, we propose an SSL schema with
the option of setting a different ratio of "pseudo label" during the supervised
regression; second, we extract multi-level morphometric features from OSM data
(i.e., buildings and streets) for the purposed of inferring building height;
last, we design a building floor estimation workflow with a pre-trained facade
object detection network to generate "pseudo label" from SVI and assign it to
the corresponding OSM building footprint. In a case study, we validate the
proposed SSL method in the city of Heidelberg, Germany and evaluate the model
performance against the reference data of building heights. Based on three
different regression models, namely Random Forest (RF), Support Vector Machine
(SVM), and Convolutional Neural Network (CNN), the SSL method leads to a clear
performance boosting in estimating building heights with a Mean Absolute Error
(MAE) around 2.1 meters, which is competitive to state-of-the-art approaches.
The preliminary result is promising and motivates our future work in scaling up
the proposed method based on low-cost VGI data, with possibilities in even
regions and areas with diverse data quality and availability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02575">How accurate are existing land cover maps for agriculture in Sub-Saharan Africa?. (arXiv:2307.02575v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kerner_H/0/1/0/all/0/1">Hannah Kerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakalembe_C/0/1/0/all/0/1">Catherine Nakalembe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Adam Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zvonkov_I/0/1/0/all/0/1">Ivan Zvonkov</a>, <a href="http://arxiv.org/find/cs/1/au:+McWeeny_R/0/1/0/all/0/1">Ryan McWeeny</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_G/0/1/0/all/0/1">Gabriel Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Becker_Reshef_I/0/1/0/all/0/1">Inbal Becker-Reshef</a></p>
<p>Satellite Earth observations (EO) can provide affordable and timely
information for assessing crop conditions and food production. Such monitoring
systems are essential in Africa, where there is high food insecurity and sparse
agricultural statistics. EO-based monitoring systems require accurate cropland
maps to provide information about croplands, but there is a lack of data to
determine which of the many available land cover maps most accurately identify
cropland in African countries. This study provides a quantitative evaluation
and intercomparison of 11 publicly available land cover maps to assess their
suitability for cropland classification and EO-based agriculture monitoring in
Africa using statistically rigorous reference datasets from 8 countries. We
hope the results of this study will help users determine the most suitable map
for their needs and encourage future work to focus on resolving inconsistencies
between maps and improving accuracy in low-accuracy regions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02578">Multimodal Temporal Fusion Transformers Are Good Product Demand Forecasters. (arXiv:2307.02578v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sukel_M/0/1/0/all/0/1">Maarten Sukel</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudinac_S/0/1/0/all/0/1">Stevan Rudinac</a>, <a href="http://arxiv.org/find/cs/1/au:+Worring_M/0/1/0/all/0/1">Marcel Worring</a></p>
<p>Multimodal demand forecasting aims at predicting product demand utilizing
visual, textual, and contextual information. This paper proposes a method for
multimodal product demand forecasting using convolutional, graph-based, and
transformer-based architectures. Traditional approaches to demand forecasting
rely on historical demand, product categories, and additional contextual
information such as seasonality and events. However, these approaches have
several shortcomings, such as the cold start problem making it difficult to
predict product demand until sufficient historical data is available for a
particular product, and their inability to properly deal with category
dynamics. By incorporating multimodal information, such as product images and
textual descriptions, our architecture aims to address the shortcomings of
traditional approaches and outperform them. The experiments conducted on a
large real-world dataset show that the proposed approach effectively predicts
demand for a wide range of products. The multimodal pipeline presented in this
work enhances the accuracy and reliability of the predictions, demonstrating
the potential of leveraging multimodal information in product demand
forecasting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02588">TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers. (arXiv:2307.02588v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Varghese_A/0/1/0/all/0/1">Alan John Varghese</a>, <a href="http://arxiv.org/find/cs/1/au:+Bora_A/0/1/0/all/0/1">Aniruddha Bora</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengjia Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1">George Em Karniadakis</a></p>
<p>Dynamic graph embedding has emerged as a very effective technique for
addressing diverse temporal graph analytic tasks (i.e., link prediction, node
classification, recommender systems, anomaly detection, and graph generation)
in various applications. Such temporal graphs exhibit heterogeneous transient
dynamics, varying time intervals, and highly evolving node features throughout
their evolution. Hence, incorporating long-range dependencies from the
historical graph context plays a crucial role in accurately learning their
temporal dynamics. In this paper, we develop a graph embedding model with
uncertainty quantification, TransformerG2G, by exploiting the advanced
transformer encoder to first learn intermediate node representations from its
current state ($t$) and previous context (over timestamps [$t-1, t-l$], $l$ is
the length of context). Moreover, we employ two projection layers to generate
lower-dimensional multivariate Gaussian distributions as each node's latent
embedding at timestamp $t$. We consider diverse benchmarks with varying levels
of ``novelty" as measured by the TEA plots. Our experiments demonstrate that
the proposed TransformerG2G model outperforms conventional multi-step methods
and our prior work (DynG2G) in terms of both link prediction accuracy and
computational efficiency, especially for high degree of novelty. Furthermore,
the learned time-dependent attention weights across multiple graph snapshots
reveal the development of an automatic adaptive time stepping enabled by the
transformer. Importantly, by examining the attention weights, we can uncover
temporal dependencies, identify influential elements, and gain insights into
the complex interactions within the graph structure. For example, we identified
a strong correlation between attention weights and node degree at the various
stages of the graph topology evolution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02598">Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation. (arXiv:2307.02598v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lachapelle_S/0/1/0/all/0/1">S&#xe9;bastien Lachapelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1">Divyat Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1">Ioannis Mitliagkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a></p>
<p>We tackle the problems of latent variables identification and
"out-of-support" image generation in representation learning. We show that both
are possible for a class of decoders that we call additive, which are
reminiscent of decoders used for object-centric representation learning (OCRL)
and well suited for images that can be decomposed as a sum of object-specific
images. We provide conditions under which exactly solving the reconstruction
problem using an additive decoder is guaranteed to identify the blocks of
latent variables up to permutation and block-wise invertible transformations.
This guarantee relies only on very weak assumptions about the distribution of
the latent factors, which might present statistical dependencies and have an
almost arbitrarily shaped support. Our result provides a new setting where
nonlinear independent component analysis (ICA) is possible and adds to our
theoretical understanding of OCRL methods. We also show theoretically that
additive decoders can generate novel images by recombining observed factors of
variations in novel ways, an ability we refer to as Cartesian-product
extrapolation. We show empirically that additivity is crucial for both
identifiability and extrapolation on simulated data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02615">Human Inspired Progressive Alignment and Comparative Learning for Grounded Word Acquisition. (arXiv:2307.02615v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1">Yuwei Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattimer_B/0/1/0/all/0/1">Barrett Martin Lattimer</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1">Joyce Chai</a></p>
<p>Human language acquisition is an efficient, supervised, and continual
process. In this work, we took inspiration from how human babies acquire their
first language, and developed a computational process for word acquisition
through comparative learning. Motivated by cognitive findings, we generated a
small dataset that enables the computation models to compare the similarities
and differences of various attributes, learn to filter out and extract the
common information for each shared linguistic label. We frame the acquisition
of words as not only the information filtration process, but also as
representation-symbol mapping. This procedure does not involve a fixed
vocabulary size, nor a discriminative objective, and allows the models to
continually learn more concepts efficiently. Our results in controlled
experiments have shown the potential of this approach for efficient continual
learning of grounded words.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02620">Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning. (arXiv:2307.02620v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bellinger_C/0/1/0/all/0/1">Colin Bellinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1">Isaac Tamblyn</a></p>
<p>Reinforcement learning (RL) has been shown to learn sophisticated control
policies for complex tasks including games, robotics, heating and cooling
systems and text generation. The action-perception cycle in RL, however,
generally assumes that a measurement of the state of the environment is
available at each time step without a cost. In applications such as deep-sea
and planetary robot exploration, materials design and medicine, however, there
can be a high cost associated with measuring, or even approximating, the state
of the environment. In this paper, we survey the recently growing literature
that adopts the perspective that an RL agent might not need, or even want, a
costly measurement at each time step. Within this context, we propose the Deep
Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the
literature and empirically evaluate it on OpenAI gym and Atari Pong
environments. Our results, show that DMSOA learns a better policy with fewer
decision steps and measurements than the considered alternative from the
literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02623">FLuID: Mitigating Stragglers in Federated Learning using Invariant Dropout. (arXiv:2307.02623v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_I/0/1/0/all/0/1">Irene Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_P/0/1/0/all/0/1">Prashant J. Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1">Divya Mahajan</a></p>
<p>Federated Learning (FL) allows machine learning models to train locally on
individual mobile devices, synchronizing model updates via a shared server.
This approach safeguards user privacy; however, it also generates a
heterogeneous training environment due to the varying performance capabilities
across devices. As a result, straggler devices with lower performance often
dictate the overall training time in FL. In this work, we aim to alleviate this
performance bottleneck due to stragglers by dynamically balancing the training
load across the system. We introduce Invariant Dropout, a method that extracts
a sub-model based on the weight update threshold, thereby minimizing potential
impacts on accuracy. Building on this dropout technique, we develop an adaptive
training framework, Federated Learning using Invariant Dropout (FLuID). FLuID
offers a lightweight sub-model extraction to regulate computational intensity,
thereby reducing the load on straggler devices without affecting model quality.
Our method leverages neuron updates from non-straggler devices to construct a
tailored sub-model for each straggler based on client performance profiling.
Furthermore, FLuID can dynamically adapt to changes in stragglers as runtime
conditions shift. We evaluate FLuID using five real-world mobile clients. The
evaluations show that Invariant Dropout maintains baseline model efficiency
while alleviating the performance bottleneck of stragglers through a dynamic,
runtime approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02631">An explainable model to support the decision about the therapy protocol for AML. (arXiv:2307.02631v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Almeida_J/0/1/0/all/0/1">Jade M. Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_G/0/1/0/all/0/1">Giovanna A. Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_Neto_J/0/1/0/all/0/1">Jo&#xe3;o A. Machado-Neto</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_T/0/1/0/all/0/1">Tiago A. Almeida</a></p>
<p>Acute Myeloid Leukemia (AML) is one of the most aggressive types of
hematological neoplasm. To support the specialists' decision about the
appropriate therapy, patients with AML receive a prognostic of outcomes
according to their cytogenetic and molecular characteristics, often divided
into three risk categories: favorable, intermediate, and adverse. However, the
current risk classification has known problems, such as the heterogeneity
between patients of the same risk group and no clear definition of the
intermediate risk category. Moreover, as most patients with AML receive an
intermediate-risk classification, specialists often demand other tests and
analyses, leading to delayed treatment and worsening of the patient's clinical
condition. This paper presents the data analysis and an explainable
machine-learning model to support the decision about the most appropriate
therapy protocol according to the patient's survival prediction. In addition to
the prediction model being explainable, the results obtained are promising and
indicate that it is possible to use it to support the specialists' decisions
safely. Most importantly, the findings offered in this study have the potential
to open new avenues of research toward better treatments and prognostic
markers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02632">Stability of Q-Learning Through Design and Optimism. (arXiv:2307.02632v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meyn_S/0/1/0/all/0/1">Sean Meyn</a></p>
<p>Q-learning has become an important part of the reinforcement learning toolkit
since its introduction in the dissertation of Chris Watkins in the 1980s. The
purpose of this paper is in part a tutorial on stochastic approximation and
Q-learning, providing details regarding the INFORMS APS inaugural Applied
Probability Trust Plenary Lecture, presented in Nancy France, June 2023.
</p>
<p>The paper also presents new approaches to ensure stability and potentially
accelerated convergence for these algorithms, and stochastic approximation in
other settings. Two contributions are entirely new:
</p>
<p>1. Stability of Q-learning with linear function approximation has been an
open topic for research for over three decades. It is shown that with
appropriate optimistic training in the form of a modified Gibbs policy, there
exists a solution to the projected Bellman equation, and the algorithm is
stable (in terms of bounded parameter estimates). Convergence remains one of
many open topics for research.
</p>
<p>2. The new Zap Zero algorithm is designed to approximate the Newton-Raphson
flow without matrix inversion. It is stable and convergent under mild
assumptions on the mean flow vector field for the algorithm, and compatible
statistical assumption on an underlying Markov chain. The algorithm is a
general approach to stochastic approximation which in particular applies to
Q-learning with "oblivious" training even with non-linear function
approximation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02633">Hybrid Ground-State Quantum Algorithms based on Neural Schr\&quot;odinger Forging. (arXiv:2307.02633v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Schoulepnikoff_P/0/1/0/all/0/1">Paulin de Schoulepnikoff</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kiss_O/0/1/0/all/0/1">Oriel Kiss</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Vallecorsa_S/0/1/0/all/0/1">Sofia Vallecorsa</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Carleo_G/0/1/0/all/0/1">Giuseppe Carleo</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Grossi_M/0/1/0/all/0/1">Michele Grossi</a></p>
<p>Entanglement forging based variational algorithms leverage the bi-partition
of quantum systems for addressing ground state problems. The primary limitation
of these approaches lies in the exponential summation required over the
numerous potential basis states, or bitstrings, when performing the Schmidt
decomposition of the whole system. To overcome this challenge, we propose a new
method for entanglement forging employing generative neural networks to
identify the most pertinent bitstrings, eliminating the need for the
exponential sum. Through empirical demonstrations on systems of increasing
complexity, we show that the proposed algorithm achieves comparable or superior
performance compared to the existing standard implementation of entanglement
forging. Moreover, by controlling the amount of required resources, this scheme
can be applied to larger, as well as non permutation invariant systems, where
the latter constraint is associated with the Heisenberg forging procedure. We
substantiate our findings through numerical simulations conducted on spins
models exhibiting one-dimensional ring, two-dimensional triangular lattice
topologies, and nuclear shell model configurations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02641">Active Class Selection for Few-Shot Class-Incremental Learning. (arXiv:2307.02641v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McClurg_C/0/1/0/all/0/1">Christopher McClurg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayub_A/0/1/0/all/0/1">Ali Ayub</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyagi_H/0/1/0/all/0/1">Harsh Tyagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajtmajer_S/0/1/0/all/0/1">Sarah M. Rajtmajer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1">Alan R. Wagner</a></p>
<p>For real-world applications, robots will need to continually learn in their
environments through limited interactions with their users. Toward this,
previous works in few-shot class incremental learning (FSCIL) and active class
selection (ACS) have achieved promising results but were tested in constrained
setups. Therefore, in this paper, we combine ideas from FSCIL and ACS to
develop a novel framework that can allow an autonomous agent to continually
learn new objects by asking its users to label only a few of the most
informative objects in the environment. To this end, we build on a
state-of-the-art (SOTA) FSCIL model and extend it with techniques from ACS
literature. We term this model Few-shot Incremental Active class SeleCtiOn
(FIASco). We further integrate a potential field-based navigation technique
with our model to develop a complete framework that can allow an agent to
process and reason on its sensory data through the FIASco model, navigate
towards the most informative object in the environment, gather data about the
object through its sensors and incrementally update the FIASco model.
Experimental results on a simulated agent and a real robot show the
significance of our approach for long-term real-world robotics applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02672">GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations. (arXiv:2307.02672v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lust_J/0/1/0/all/0/1">Julia Lust</a>, <a href="http://arxiv.org/find/cs/1/au:+Condurache_A/0/1/0/all/0/1">Alexandru P. Condurache</a></p>
<p>Deep neural networks tend to make overconfident predictions and often require
additional detectors for misclassifications, particularly for safety-critical
applications. Existing detection methods usually only focus on adversarial
attacks or out-of-distribution samples as reasons for false predictions.
However, generalization errors occur due to diverse reasons often related to
poorly learning relevant invariances. We therefore propose GIT, a holistic
approach for the detection of generalization errors that combines the usage of
gradient information and invariance transformations. The invariance
transformations are designed to shift misclassified samples back into the
generalization area of the neural network, while the gradient information
measures the contradiction between the initial prediction and the corresponding
inherent computations of the neural network using the transformed sample. Our
experiments demonstrate the superior performance of GIT compared to the
state-of-the-art on a variety of network architectures, problem setups and
perturbation types.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02690">Scaling In-Context Demonstrations with Structured Attention. (arXiv:2307.02690v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaixuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengdi Wang</a></p>
<p>The recent surge of large language models (LLMs) highlights their ability to
perform in-context learning, i.e., "learning" to perform a task from a few
demonstrations in the context without any parameter updates. However, their
capabilities of in-context learning are limited by the model architecture: 1)
the use of demonstrations is constrained by a maximum sentence length due to
positional embeddings; 2) the quadratic complexity of attention hinders users
from using more demonstrations efficiently; 3) LLMs are shown to be sensitive
to the order of the demonstrations. In this work, we tackle these challenges by
proposing a better architectural design for in-context learning. We propose
SAICL (Structured Attention for In-Context Learning), which replaces the
full-attention by a structured attention mechanism designed for in-context
learning, and removes unnecessary dependencies between individual
demonstrations, while making the model invariant to the permutation of
demonstrations. We evaluate SAICL in a meta-training framework and show that
SAICL achieves comparable or better performance than full attention while
obtaining up to 3.4x inference speed-up. SAICL also consistently outperforms a
strong Fusion-in-Decoder (FiD) baseline which processes each demonstration
independently. Finally, thanks to its linear nature, we demonstrate that SAICL
can easily scale to hundreds of demonstrations with continuous performance
gains with scaling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02693">Kernels, Data &amp; Physics. (arXiv:2307.02693v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cagnetta_F/0/1/0/all/0/1">Francesco Cagnetta</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1">Deborah Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabanayagam_M/0/1/0/all/0/1">Mahalakshmi Sabanayagam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsilivis_N/0/1/0/all/0/1">Nikolaos Tsilivis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kempe_J/0/1/0/all/0/1">Julia Kempe</a></p>
<p>Lecture notes from the course given by Professor Julia Kempe at the summer
school "Statistical physics of Machine Learning" in Les Houches. The notes
discuss the so-called NTK approach to problems in machine learning, which
consists of gaining an understanding of generally unsolvable problems by
finding a tractable kernel formulation. The notes are mainly focused on
practical applications such as data distillation and adversarial robustness,
examples of inductive bias are also discussed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02694">Loss Functions and Metrics in Deep Learning. A Review. (arXiv:2307.02694v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Terven_J/0/1/0/all/0/1">Juan Terven</a>, <a href="http://arxiv.org/find/cs/1/au:+Cordova_Esparza_D/0/1/0/all/0/1">Diana M. Cordova-Esparza</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_Pedraza_A/0/1/0/all/0/1">Alfonzo Ramirez-Pedraza</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavez_Urbiola_E/0/1/0/all/0/1">Edgar A. Chavez-Urbiola</a></p>
<p>One of the essential components of deep learning is the choice of the loss
function and performance metrics used to train and evaluate models. This paper
reviews the most prevalent loss functions and performance measurements in deep
learning. We examine the benefits and limits of each technique and illustrate
their application to various deep-learning problems. Our review aims to give a
comprehensive picture of the different loss functions and performance
indicators used in the most common deep learning tasks and help practitioners
choose the best method for their specific task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02707">Towards Symmetry-Aware Generation of Periodic Materials. (arXiv:2307.02707v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chengkai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a></p>
<p>We consider the problem of generating periodic materials with deep models.
While symmetry-aware molecule generation has been studied extensively, periodic
materials possess different symmetries, which have not been completely captured
by existing methods. In this work, we propose SyMat, a novel material
generation approach that can capture physical symmetries of periodic material
structures. SyMat generates atom types and lattices of materials through
generating atom type sets, lattice lengths and lattice angles with a
variational auto-encoder model. In addition, SyMat employs a score-based
diffusion model to generate atom coordinates of materials, in which a novel
symmetry-aware probabilistic model is used in the coordinate diffusion process.
We show that SyMat is theoretically invariant to all symmetry transformations
on materials and demonstrate that SyMat achieves promising performance on
random generation and property optimization tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02712">Multi-Similarity Contrastive Learning. (arXiv:2307.02712v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mu_E/0/1/0/all/0/1">Emily Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttag_J/0/1/0/all/0/1">John Guttag</a>, <a href="http://arxiv.org/find/cs/1/au:+Makar_M/0/1/0/all/0/1">Maggie Makar</a></p>
<p>Given a similarity metric, contrastive methods learn a representation in
which examples that are similar are pushed together and examples that are
dissimilar are pulled apart. Contrastive learning techniques have been utilized
extensively to learn representations for tasks ranging from image
classification to caption generation. However, existing contrastive learning
approaches can fail to generalize because they do not take into account the
possibility of different similarity relations. In this paper, we propose a
novel multi-similarity contrastive loss (MSCon), that learns generalizable
embeddings by jointly utilizing supervision from multiple metrics of
similarity. Our method automatically learns contrastive similarity weightings
based on the uncertainty in the corresponding similarity, down-weighting
uncertain tasks and leading to better out-of-domain generalization to new
tasks. We show empirically that networks trained with MSCon outperform
state-of-the-art baselines on in-domain and out-of-domain settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02719">Understanding Uncertainty Sampling. (arXiv:2307.02719v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaocheng Li</a></p>
<p>Uncertainty sampling is a prevalent active learning algorithm that queries
sequentially the annotations of data samples which the current prediction model
is uncertain about. However, the usage of uncertainty sampling has been largely
heuristic: (i) There is no consensus on the proper definition of "uncertainty"
for a specific task under a specific loss; (ii) There is no theoretical
guarantee that prescribes a standard protocol to implement the algorithm, for
example, how to handle the sequentially arrived annotated data under the
framework of optimization algorithms such as stochastic gradient descent. In
this work, we systematically examine uncertainty sampling algorithms under both
stream-based and pool-based active learning. We propose a notion of equivalent
loss which depends on the used uncertainty measure and the original loss
function and establish that an uncertainty sampling algorithm essentially
optimizes against such an equivalent loss. The perspective verifies the
properness of existing uncertainty measures from two aspects: surrogate
property and loss convexity. Furthermore, we propose a new notion for designing
uncertainty measures called \textit{loss as uncertainty}. The idea is to use
the conditional expected loss given the features as the uncertainty measure.
Such an uncertainty measure has nice analytical properties and generality to
cover both classification and regression problems, which enable us to provide
the first generalization bound for uncertainty sampling algorithms under both
stream-based and pool-based settings, in the full generality of the underlying
model and problem. Lastly, we establish connections between certain variants of
the uncertainty sampling algorithms with risk-sensitive objectives and
distributional robustness, which can partly explain the advantage of
uncertainty sampling algorithms when the sample size is small.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02726">Through the Fairness Lens: Experimental Analysis and Evaluation of Entity Matching. (arXiv:2307.02726v1 [cs.DB])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shahbazi_N/0/1/0/all/0/1">Nima Shahbazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Danevski_N/0/1/0/all/0/1">Nikola Danevski</a>, <a href="http://arxiv.org/find/cs/1/au:+Nargesian_F/0/1/0/all/0/1">Fatemeh Nargesian</a>, <a href="http://arxiv.org/find/cs/1/au:+Asudeh_A/0/1/0/all/0/1">Abolfazl Asudeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_D/0/1/0/all/0/1">Divesh Srivastava</a></p>
<p>Entity matching (EM) is a challenging problem studied by different
communities for over half a century. Algorithmic fairness has also become a
timely topic to address machine bias and its societal impacts. Despite
extensive research on these two topics, little attention has been paid to the
fairness of entity matching.
</p>
<p>Towards addressing this gap, we perform an extensive experimental evaluation
of a variety of EM techniques in this paper. We generated two social datasets
from publicly available datasets for the purpose of auditing EM through the
lens of fairness. Our findings underscore potential unfairness under two common
conditions in real-world societies: (i) when some demographic groups are
overrepresented, and (ii) when names are more similar in some groups compared
to others. Among our many findings, it is noteworthy to mention that while
various fairness definitions are valuable for different settings, due to EM's
class imbalance nature, measures such as positive predictive value parity and
true positive rate parity are, in general, more capable of revealing EM
unfairness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02728">Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning. (arXiv:2307.02728v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Levy_A/0/1/0/all/0/1">Andrew Levy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rammohan_S/0/1/0/all/0/1">Sreehari Rammohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Allievi_A/0/1/0/all/0/1">Alessandro Allievi</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>, <a href="http://arxiv.org/find/cs/1/au:+Konidaris_G/0/1/0/all/0/1">George Konidaris</a></p>
<p>General purpose agents will require large repertoires of skills. Empowerment
-- the maximum mutual information between skills and the states -- provides a
pathway for learning large collections of distinct skills, but mutual
information is difficult to optimize. We introduce a new framework,
Hierarchical Empowerment, that makes computing empowerment more tractable by
integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning.
Our framework makes two specific contributions. First, we introduce a new
variational lower bound on mutual information that can be used to compute
empowerment over short horizons. Second, we introduce a hierarchical
architecture for computing empowerment over exponentially longer time scales.
We verify the contributions of the framework in a series of simulated robotics
tasks. In a popular ant navigation domain, our four level agents are able to
learn skills that cover a surface area over two orders of magnitude larger than
prior work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02732">Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?. (arXiv:2307.02732v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shimabucoro_L/0/1/0/all/0/1">Lu&#xed;sa Shimabucoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1">Timothy Hospedales</a>, <a href="http://arxiv.org/find/cs/1/au:+Gouk_H/0/1/0/all/0/1">Henry Gouk</a></p>
<p>Numerous benchmarks for Few-Shot Learning have been proposed in the last
decade. However all of these benchmarks focus on performance averaged over many
tasks, and the question of how to reliably evaluate and tune models trained for
individual tasks in this regime has not been addressed. This paper presents the
first investigation into task-level evaluation -- a fundamental step when
deploying a model. We measure the accuracy of performance estimators in the
few-shot setting, consider strategies for model selection, and examine the
reasons for the failure of evaluators usually thought of as being robust. We
conclude that cross-validation with a low number of folds is the best choice
for directly estimating the performance of a model, whereas using bootstrapping
or cross validation with a large number of folds is better for model selection
purposes. Overall, we find that existing benchmarks for few-shot learning are
not designed in such a way that one can get a reliable picture of how
effectively methods can be used on individual tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02752">Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2307.02752v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Li Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sijie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jielin Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haoran Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1">Wai Kin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhao Ding</a></p>
<p>The prevalent use of benchmarks in current offline reinforcement learning
(RL) research has led to a neglect of the imbalance of real-world dataset
distributions in the development of models. The real-world offline RL dataset
is often imbalanced over the state space due to the challenge of exploration or
safety considerations. In this paper, we specify properties of imbalanced
datasets in offline RL, where the state coverage follows a power law
distribution characterized by skewed policies. Theoretically and empirically,
we show that typically offline RL methods based on distributional constraints,
such as conservative Q-learning (CQL), are ineffective in extracting policies
under the imbalanced dataset. Inspired by natural intelligence, we propose a
novel offline RL method that utilizes the augmentation of CQL with a retrieval
process to recall past related experiences, effectively alleviating the
challenges posed by imbalanced datasets. We evaluate our method on several
tasks in the context of imbalanced datasets with varying levels of imbalance,
utilizing the variant of D4RL. Empirical results demonstrate the superiority of
our method over other baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02764">When Does Confidence-Based Cascade Deferral Suffice?. (arXiv:2307.02764v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jitkrittum_W/0/1/0/all/0/1">Wittawat Jitkrittum</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Neha Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Krishna Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_H/0/1/0/all/0/1">Harikrishna Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1">Ankit Singh Rawat</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a></p>
<p>Cascades are a classical strategy to enable inference cost to vary adaptively
across samples, wherein a sequence of classifiers are invoked in turn. A
deferral rule determines whether to invoke the next classifier in the sequence,
or to terminate prediction. One simple deferral rule employs the confidence of
the current classifier, e.g., based on the maximum predicted softmax
probability. Despite being oblivious to the structure of the cascade -- e.g.,
not modelling the errors of downstream models -- such confidence-based deferral
often works remarkably well in practice. In this paper, we seek to better
understand the conditions under which confidence-based deferral may fail, and
when alternate deferral strategies can perform better. We first present a
theoretical characterisation of the optimal deferral rule, which precisely
characterises settings under which confidence-based deferral may suffer. We
then study post-hoc deferral mechanisms, and demonstrate they can significantly
improve upon confidence-based deferral in settings where (i) downstream models
are specialists that only work well on a subset of inputs, (ii) samples are
subject to label noise, and (iii) there is distribution shift between the train
and test set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02766">Temporal Difference Learning for High-Dimensional PIDEs with Jumps. (arXiv:2307.02766v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lu_L/0/1/0/all/0/1">Liwei Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Guo_H/0/1/0/all/0/1">Hailong Guo</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_X/0/1/0/all/0/1">Xu Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a></p>
<p>In this paper, we propose a deep learning framework for solving
high-dimensional partial integro-differential equations (PIDEs) based on the
temporal difference learning. We introduce a set of Levy processes and
construct a corresponding reinforcement learning model. To simulate the entire
process, we use deep neural networks to represent the solutions and non-local
terms of the equations. Subsequently, we train the networks using the temporal
difference error, termination condition, and properties of the non-local terms
as the loss function. The relative error of the method reaches O(10^{-3}) in
100-dimensional experiments and O(10^{-4}) in one-dimensional pure jump
problems. Additionally, our method demonstrates the advantages of low
computational cost and robustness, making it well-suited for addressing
problems with different forms and intensities of jumps.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02779">Large Language Models Empowered Autonomous Edge AI for Connected Intelligence. (arXiv:2307.02779v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yifei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jiawei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zehong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Hao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Letaief_K/0/1/0/all/0/1">Khaled B. Letaief</a></p>
<p>The evolution of wireless networks gravitates towards connected intelligence,
a concept that envisions seamless interconnectivity among humans, objects, and
intelligence in a hyper-connected cyber-physical world. Edge AI emerges as a
promising solution to achieve connected intelligence by delivering
high-quality, low-latency, and privacy-preserving AI services at the network
edge. In this article, we introduce an autonomous edge AI system that
automatically organizes, adapts, and optimizes itself to meet users' diverse
requirements. The system employs a cloud-edge-client hierarchical architecture,
where the large language model, i.e., Generative Pretrained Transformer (GPT),
resides in the cloud, and other AI models are co-deployed on devices and edge
servers. By leveraging the powerful abilities of GPT in language understanding,
planning, and code generation, we present a versatile framework that
efficiently coordinates edge AI models to cater to users' personal demands
while automatically generating code to train new models via edge federated
learning. Experimental results demonstrate the system's remarkable ability to
accurately comprehend user demands, efficiently execute AI models with minimal
cost, and effectively create high-performance AI models through federated
learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02791">The Role of Subgroup Separability in Group-Fair Medical Image Classification. (arXiv:2307.02791v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1">Charles Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Roschewitz_M/0/1/0/all/0/1">M&#xe9;lanie Roschewitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a></p>
<p>We investigate performance disparities in deep classifiers. We find that the
ability of classifiers to separate individuals into subgroups varies
substantially across medical imaging modalities and protected characteristics;
crucially, we show that this property is predictive of algorithmic bias.
Through theoretical analysis and extensive empirical evaluation, we find a
relationship between subgroup separability, subgroup disparities, and
performance degradation when models are trained on data with systematic bias
such as underdiagnosis. Our findings shed new light on the question of how
models become biased, providing important insights for the development of fair
medical imaging AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02796">VerifAI: Verified Generative AI. (arXiv:2307.02796v1 [cs.DB])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_N/0/1/0/all/0/1">Nan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Ju Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Lei Cao</a></p>
<p>Generative AI has made significant strides, yet concerns about the accuracy
and reliability of its outputs continue to grow. Such inaccuracies can have
serious consequences such as inaccurate decision-making, the spread of false
information, privacy violations, legal liabilities, and more. Although efforts
to address these risks are underway, including explainable AI and responsible
AI practices such as transparency, privacy protection, bias mitigation, and
social and environmental responsibility, misinformation caused by generative AI
will remain a significant challenge. We propose that verifying the outputs of
generative AI from a data management perspective is an emerging issue for
generative AI. This involves analyzing the underlying data from multi-modal
data lakes, including text files, tables, and knowledge graphs, and assessing
its quality and consistency. By doing so, we can establish a stronger
foundation for evaluating the outputs of generative AI models. Such an approach
can ensure the correctness of generative AI, promote transparency, and enable
decision-making with greater confidence. Our vision is to promote the
development of verifiable generative AI and contribute to a more trustworthy
and responsible use of AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02799">Few-Shot Personalized Saliency Prediction Using Tensor Regression for Preserving Structural Global Information. (arXiv:2307.02799v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Moroto_Y/0/1/0/all/0/1">Yuya Moroto</a>, <a href="http://arxiv.org/find/eess/1/au:+Maeda_K/0/1/0/all/0/1">Keisuke Maeda</a>, <a href="http://arxiv.org/find/eess/1/au:+Ogawa_T/0/1/0/all/0/1">Takahiro Ogawa</a>, <a href="http://arxiv.org/find/eess/1/au:+Haseyama_M/0/1/0/all/0/1">Miki Haseyama</a></p>
<p>This paper presents a few-shot personalized saliency prediction using
tensor-to-matrix regression for preserving the structural global information of
personalized saliency maps (PSMs). In contrast to a general saliency map, a PSM
has been great potential since its map indicates the person-specific visual
attention that is useful for obtaining individual visual preferences from
heterogeneity of gazed areas. The PSM prediction is needed for acquiring the
PSM for the unseen image, but its prediction is still a challenging task due to
the complexity of individual gaze patterns. For recognizing individual gaze
patterns from the limited amount of eye-tracking data, the previous methods
adopt the similarity of gaze tendency between persons. However, in the previous
methods, the PSMs are vectorized for the prediction model. In this way, the
structural global information of the PSMs corresponding to the image is
ignored. For automatically revealing the relationship between PSMs, we focus on
the tensor-based regression model that can preserve the structural information
of PSMs, and realize the improvement of the prediction accuracy. In the
experimental results, we confirm the proposed method including the tensor-based
regression outperforms the comparative methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02804">OLR-WA Online Regression with Weighted Average. (arXiv:2307.02804v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abu_Shaira_M/0/1/0/all/0/1">Mohammad Abu-Shaira</a>, <a href="http://arxiv.org/find/cs/1/au:+Speegle_G/0/1/0/all/0/1">Greg Speegle</a></p>
<p>Machine Learning requires a large amount of training data in order to build
accurate models. Sometimes the data arrives over time, requiring significant
storage space and recalculating the model to account for the new data. On-line
learning addresses these issues by incrementally modifying the model as data is
encountered, and then discarding the data. In this study we introduce a new
online linear regression approach. Our approach combines newly arriving data
with a previously existing model to create a new model. The introduced model,
named OLR-WA (OnLine Regression with Weighted Average) uses user-defined
weights to provide flexibility in the face of changing data to bias the results
in favor of old or new data. We have conducted 2-D and 3-D experiments
comparing OLR-WA to a static model using the entire data set. The results show
that for consistent data, OLR-WA and the static batch model perform similarly
and for varying data, the user can set the OLR-WA to adapt more quickly or to
resist change.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02813">CPDG: A Contrastive Pre-Training Method for Dynamic Graph Neural Networks. (arXiv:2307.02813v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bei_Y/0/1/0/all/0/1">Yuanchen Bei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1">Huixuan Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengdi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1">Jiajun Bu</a></p>
<p>Dynamic graph data mining has gained popularity in recent years due to the
rich information contained in dynamic graphs and their widespread use in the
real world. Despite the advances in dynamic graph neural networks (DGNNs), the
rich information and diverse downstream tasks have posed significant
difficulties for the practical application of DGNNs in industrial scenarios. To
this end, in this paper, we propose to address them by pre-training and present
the Contrastive Pre-Training Method for Dynamic Graph Neural Networks (CPDG).
CPDG tackles the challenges of pre-training for DGNNs, including generalization
and long-short term modeling capability, through a flexible structural-temporal
subgraph sampler along with structural-temporal contrastive pre-training
schemes. Extensive experiments conducted on both large-scale research and
industrial dynamic graph datasets show that CPDG outperforms existing methods
in dynamic graph pre-training for various downstream tasks under three transfer
settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02819">Trends in Machine Learning and Electroencephalogram (EEG): A Review for Undergraduate Researchers. (arXiv:2307.02819v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Murungi_N/0/1/0/all/0/1">Nathan Koome Murungi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1">Michael Vinh Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xufeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaodong Qu</a></p>
<p>This paper presents a systematic literature review on Brain-Computer
Interfaces (BCIs) in the context of Machine Learning. Our focus is on
Electroencephalography (EEG) research, highlighting the latest trends as of
2023. The objective is to provide undergraduate researchers with an accessible
overview of the BCI field, covering tasks, algorithms, and datasets. By
synthesizing recent findings, our aim is to offer a fundamental understanding
of BCI research, identifying promising avenues for future investigations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02828">Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks. (arXiv:2307.02828v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anmin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_C/0/1/0/all/0/1">Chenxuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yanbo Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a></p>
<p>Deep neural networks are known to be vulnerable to adversarial examples
crafted by adding human-imperceptible perturbations to the benign input. After
achieving nearly 100% attack success rates in white-box setting, more focus is
shifted to black-box attacks, of which the transferability of adversarial
examples has gained significant attention. In either case, the common
gradient-based methods generally use the sign function to generate
perturbations on the gradient update, that offers a roughly correct direction
and has gained great success. But little work pays attention to its possible
limitation. In this work, we observe that the deviation between the original
gradient and the generated noise may lead to inaccurate gradient update
estimation and suboptimal solutions for adversarial transferability. To this
end, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM).
Specifically, we use data rescaling to substitute the sign function without
extra computational cost. We further propose a Depth First Sampling method to
eliminate the fluctuation of rescaling and stabilize the gradient update. Our
method could be used in any gradient-based attacks and is extensible to be
integrated with various input transformation or ensemble methods to further
improve the adversarial transferability. Extensive experiments on the standard
ImageNet dataset show that our method could significantly boost the
transferability of gradient-based attacks and outperform the state-of-the-art
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02829">Policy Contrastive Imitation Learning. (arXiv:2307.02829v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jialei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhaoheng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yingdong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a></p>
<p>Adversarial imitation learning (AIL) is a popular method that has recently
achieved much success. However, the performance of AIL is still unsatisfactory
on the more challenging tasks. We find that one of the major reasons is due to
the low quality of AIL discriminator representation. Since the AIL
discriminator is trained via binary classification that does not necessarily
discriminate the policy from the expert in a meaningful way, the resulting
reward might not be meaningful either. We propose a new method called Policy
Contrastive Imitation Learning (PCIL) to resolve this issue. PCIL learns a
contrastive representation space by anchoring on different policies and
generates a smooth cosine-similarity-based reward. Our proposed representation
learning objective can be viewed as a stronger version of the AIL objective and
provide a more meaningful comparison between the agent and the policy. From a
theoretical perspective, we show the validity of our method using the
apprenticeship learning framework. Furthermore, our empirical evaluation on the
DeepMind Control suite demonstrates that PCIL can achieve state-of-the-art
performance. Finally, qualitative results suggest that PCIL builds a smoother
and more meaningful representation space for imitation learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02842">Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation. (arXiv:2307.02842v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yihan Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Pihe Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Siwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Desheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longbo Huang</a></p>
<p>Risk-sensitive reinforcement learning (RL) aims to optimize policies that
balance the expected reward and risk. In this paper, we investigate a novel
risk-sensitive RL formulation with an Iterated Conditional Value-at-Risk (CVaR)
objective under linear and general function approximations. This new
formulation, named ICVaR-RL with function approximation, provides a principled
way to guarantee safety at each decision step. For ICVaR-RL with linear
function approximation, we propose a computationally efficient algorithm
ICVaR-L, which achieves an
$\widetilde{O}(\sqrt{\alpha^{-(H+1)}(d^2H^4+dH^6)K})$ regret, where $\alpha$ is
the risk level, $d$ is the dimension of state-action features, $H$ is the
length of each episode, and $K$ is the number of episodes. We also establish a
matching lower bound $\Omega(\sqrt{\alpha^{-(H-1)}d^2K})$ to validate the
optimality of ICVaR-L with respect to $d$ and $K$. For ICVaR-RL with general
function approximation, we propose algorithm ICVaR-G, which achieves an
$\widetilde{O}(\sqrt{\alpha^{-(H+1)}DH^4K})$ regret, where $D$ is a dimensional
parameter that depends on the eluder dimension and covering number.
Furthermore, our analysis provides several novel techniques for risk-sensitive
RL, including an efficient approximation of the CVaR operator, a new ridge
regression with CVaR-adapted features, and a refined elliptical potential
lemma.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02865">PLIERS: a Popularity-Based Recommender System for Content Dissemination in Online Social Networks. (arXiv:2307.02865v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arnaboldi_V/0/1/0/all/0/1">Valerio Arnaboldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Campana_M/0/1/0/all/0/1">Mattia Giovanni Campana</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmastro_F/0/1/0/all/0/1">Franca Delmastro</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagani_E/0/1/0/all/0/1">Elena Pagani</a></p>
<p>In this paper, we propose a novel tag-based recommender system called PLIERS,
which relies on the assumption that users are mainly interested in items and
tags with similar popularity to those they already own. PLIERS is aimed at
reaching a good tradeoff between algorithmic complexity and the level of
personalization of recommended items. To evaluate PLIERS, we performed a set of
experiments on real OSN datasets, demonstrating that it outperforms
state-of-the-art solutions in terms of personalization, relevance, and novelty
of recommendations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02867">Towards a safe MLOps Process for the Continuous Development and Safety Assurance of ML-based Systems in the Railway Domain. (arXiv:2307.02867v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeller_M/0/1/0/all/0/1">Marc Zeller</a>, <a href="http://arxiv.org/find/cs/1/au:+Waschulzik_T/0/1/0/all/0/1">Thomas Waschulzik</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_R/0/1/0/all/0/1">Reiner Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahlmann_C/0/1/0/all/0/1">Claus Bahlmann</a></p>
<p>Traditional automation technologies alone are not sufficient to enable
driverless operation of trains (called Grade of Automation (GoA) 4) on
non-restricted infrastructure. The required perception tasks are nowadays
realized using Machine Learning (ML) and thus need to be developed and deployed
reliably and efficiently. One important aspect to achieve this is to use an
MLOps process for tackling improved reproducibility, traceability,
collaboration, and continuous adaptation of a driverless operation to changing
conditions. MLOps mixes ML application development and operation (Ops) and
enables high frequency software releases and continuous innovation based on the
feedback from operations. In this paper, we outline a safe MLOps process for
the continuous development and safety assurance of ML-based systems in the
railway domain. It integrates system engineering, safety assurance, and the ML
life-cycle in a comprehensive workflow. We present the individual stages of the
process and their interactions. Moreover, we describe relevant challenges to
automate the different stages of the safe MLOps process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02884">Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight. (arXiv:2307.02884v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiacheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minshuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengdi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yu Bai</a></p>
<p>This paper studies the sample-efficiency of learning in Partially Observable
Markov Decision Processes (POMDPs), a challenging problem in reinforcement
learning that is known to be exponentially hard in the worst-case. Motivated by
real-world settings such as loading in game playing, we propose an enhanced
feedback model called ``multiple observations in hindsight'', where after each
episode of interaction with the POMDP, the learner may collect multiple
additional observations emitted from the encountered latent states, but may not
observe the latent states themselves. We show that sample-efficient learning
under this feedback model is possible for two new subclasses of POMDPs:
\emph{multi-observation revealing POMDPs} and \emph{distinguishable POMDPs}.
Both subclasses generalize and substantially relax \emph{revealing POMDPs} -- a
widely studied subclass for which sample-efficient learning is possible under
standard trajectory feedback. Notably, distinguishable POMDPs only require the
emission distributions from different latent states to be \emph{different}
instead of \emph{linearly independent} as required in revealing POMDPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02889">Learning to Solve Tasks with Exploring Prior Behaviours. (arXiv:2307.02889v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Ruiqi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1">Tianhong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Celiktutan_O/0/1/0/all/0/1">Oya Celiktutan</a></p>
<p>Demonstrations are widely used in Deep Reinforcement Learning (DRL) for
facilitating solving tasks with sparse rewards. However, the tasks in
real-world scenarios can often have varied initial conditions from the
demonstration, which would require additional prior behaviours. For example,
consider we are given the demonstration for the task of \emph{picking up an
object from an open drawer}, but the drawer is closed in the training. Without
acquiring the prior behaviours of opening the drawer, the robot is unlikely to
solve the task. To address this, in this paper we propose an Intrinsic Rewards
Driven Example-based Control \textbf{(IRDEC)}. Our method can endow agents with
the ability to explore and acquire the required prior behaviours and then
connect to the task-specific behaviours in the demonstration to solve
sparse-reward tasks without requiring additional demonstration of the prior
behaviours. The performance of our method outperforms other baselines on three
navigation tasks and one robotic manipulation task with sparse rewards. Codes
are available at https://github.com/Ricky-Zhu/IRDEC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02891">BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables. (arXiv:2307.02891v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Binkyte_R/0/1/0/all/0/1">Ruta Binkyte</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1">Daniele Gorla</a>, <a href="http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1">Catuscia Palamidessi</a></p>
<p>We consider the problem of unfair discrimination between two groups and
propose a pre-processing method to achieve fairness. Corrective methods like
statistical parity usually lead to bad accuracy and do not really achieve
fairness in situations where there is a correlation between the sensitive
attribute S and the legitimate attribute E (explanatory variable) that should
determine the decision. To overcome these drawbacks, other notions of fairness
have been proposed, in particular, conditional statistical parity and equal
opportunity. However, E is often not directly observable in the data, i.e., it
is a latent variable. We may observe some other variable Z representing E, but
the problem is that Z may also be affected by S, hence Z itself can be biased.
To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an
approach based on a combination of Bayes inference and the
Expectation-Maximization method, to estimate the most likely value of E for a
given Z for each group. The decision can then be based directly on the
estimated E. We show, by experiments on synthetic and real data sets, that our
approach provides a good level of fairness as well as high accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02894">Free Bits: Latency Optimization of Mixed-Precision Quantized Neural Networks on the Edge. (arXiv:2307.02894v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rutishauser_G/0/1/0/all/0/1">Georg Rutishauser</a>, <a href="http://arxiv.org/find/cs/1/au:+Conti_F/0/1/0/all/0/1">Francesco Conti</a>, <a href="http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1">Luca Benini</a></p>
<p>Mixed-precision quantization, where a deep neural network's layers are
quantized to different precisions, offers the opportunity to optimize the
trade-offs between model size, latency, and statistical accuracy beyond what
can be achieved with homogeneous-bit-width quantization. To navigate the
intractable search space of mixed-precision configurations for a given network,
this paper proposes a hybrid search methodology. It consists of a
hardware-agnostic differentiable search algorithm followed by a hardware-aware
heuristic optimization to find mixed-precision configurations latency-optimized
for a specific hardware target. We evaluate our algorithm on MobileNetV1 and
MobileNetV2 and deploy the resulting networks on a family of multi-core RISC-V
microcontroller platforms with different hardware characteristics. We achieve
up to 28.6% reduction of end-to-end latency compared to an 8-bit model at a
negligible accuracy drop from a full-precision baseline on the 1000-class
ImageNet dataset. We demonstrate speedups relative to an 8-bit baseline, even
on systems with no hardware support for sub-byte arithmetic at negligible
accuracy drop. Furthermore, we show the superiority of our approach with
respect to differentiable search targeting reduced binary operation counts as a
proxy for latency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02903">PUFFIN: A Path-Unifying Feed-Forward Interfaced Network for Vapor Pressure Prediction. (arXiv:2307.02903v1 [physics.chem-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Santana_V/0/1/0/all/0/1">Vinicius Viena Santana</a>, <a href="http://arxiv.org/find/physics/1/au:+Rebello_C/0/1/0/all/0/1">Carine Menezes Rebello</a>, <a href="http://arxiv.org/find/physics/1/au:+Queiroz_L/0/1/0/all/0/1">Luana P. Queiroz</a>, <a href="http://arxiv.org/find/physics/1/au:+Ribeiro_A/0/1/0/all/0/1">Ana Mafalda Ribeiro</a>, <a href="http://arxiv.org/find/physics/1/au:+Shardta_N/0/1/0/all/0/1">Nadia Shardta</a>, <a href="http://arxiv.org/find/physics/1/au:+Nogueira_I/0/1/0/all/0/1">Idelfonso B. R. Nogueira</a></p>
<p>Accurately predicting vapor pressure is vital for various industrial and
environmental applications. However, obtaining accurate measurements for all
compounds of interest is not possible due to the resource and labor intensity
of experiments. The demand for resources and labor further multiplies when a
temperature-dependent relationship for predicting vapor pressure is desired. In
this paper, we propose PUFFIN (Path-Unifying Feed-Forward Interfaced Network),
a machine learning framework that combines transfer learning with a new
inductive bias node inspired by domain knowledge (the Antoine equation) to
improve vapor pressure prediction. By leveraging inductive bias and transfer
learning using graph embeddings, PUFFIN outperforms alternative strategies that
do not use inductive bias or that use generic descriptors of compounds. The
framework's incorporation of domain-specific knowledge to overcome the
limitation of poor data availability shows its potential for broader
applications in chemical compound analysis, including the prediction of other
physicochemical properties. Importantly, our proposed machine learning
framework is partially interpretable, because the inductive Antoine node yields
network-derived Antoine equation coefficients. It would then be possible to
directly incorporate the obtained analytical expression in process design
software for better prediction and control of processes occurring in industry
and the environment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02906">A Real-time Human Pose Estimation Approach for Optimal Sensor Placement in Sensor-based Human Activity Recognition. (arXiv:2307.02906v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Konak_O/0/1/0/all/0/1">Orhan Konak</a>, <a href="http://arxiv.org/find/cs/1/au:+Wischmann_A/0/1/0/all/0/1">Alexander Wischmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Water_R/0/1/0/all/0/1">Robin van de Water</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnrich_B/0/1/0/all/0/1">Bert Arnrich</a></p>
<p>Sensor-based Human Activity Recognition facilitates unobtrusive monitoring of
human movements. However, determining the most effective sensor placement for
optimal classification performance remains challenging. This paper introduces a
novel methodology to resolve this issue, using real-time 2D pose estimations
derived from video recordings of target activities. The derived skeleton data
provides a unique strategy for identifying the optimal sensor location. We
validate our approach through a feasibility study, applying inertial sensors to
monitor 13 different activities across ten subjects. Our findings indicate that
the vision-based method for sensor placement offers comparable results to the
conventional deep learning approach, demonstrating its efficacy. This research
significantly advances the field of Human Activity Recognition by providing a
lightweight, on-device solution for determining the optimal sensor placement,
thereby enhancing data anonymization and supporting a multimodal classification
approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02932">When No-Rejection Learning is Optimal for Regression with Rejection. (arXiv:2307.02932v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaocheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chunlin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hanzhao Wang</a></p>
<p>Learning with rejection is a prototypical model for studying the interaction
between humans and AI on prediction tasks. The model has two components, a
predictor and a rejector. Upon the arrival of a sample, the rejector first
decides whether to accept it; if accepted, the predictor fulfills the
prediction task, and if rejected, the prediction will be deferred to humans.
The learning problem requires learning a predictor and a rejector
simultaneously. This changes the structure of the conventional loss function
and often results in non-convexity and inconsistency issues. For the
classification with rejection problem, several works develop surrogate losses
for the jointly learning with provable consistency guarantees; in parallel,
there has been less work for the regression counterpart. We study the
regression with rejection (RwR) problem and investigate the no-rejection
learning strategy which treats the RwR problem as a standard regression task to
learn the predictor. We establish that the suboptimality of the no-rejection
learning strategy observed in the literature can be mitigated by enlarging the
function class of the predictor. Then we introduce the truncated loss to single
out the learning for the predictor and we show that a consistent surrogate
property can be established for the predictor individually in an easier way
than for the predictor and the rejector jointly. Our findings advocate for a
two-step learning procedure that first uses all the data to learn the predictor
and then calibrates the prediction loss for the rejector. It is better aligned
with the common intuition that more data samples will lead to a better
predictor and it calls for more efforts on a better design of calibration
algorithms for learning the rejector. While our discussions mainly focus on the
regression problem, the theoretical results and insights generalize to the
classification problem as well.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02953">SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks. (arXiv:2307.02953v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Cheng_J/0/1/0/all/0/1">Junlong Cheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_C/0/1/0/all/0/1">Chengrui Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_F/0/1/0/all/0/1">Fengjie Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_M/0/1/0/all/0/1">Min Zhu</a></p>
<p>Recently, U-shaped networks have dominated the field of medical image
segmentation due to their simple and easily tuned structure. However, existing
U-shaped segmentation networks: 1) mostly focus on designing complex
self-attention modules to compensate for the lack of long-term dependence based
on convolution operation, which increases the overall number of parameters and
computational complexity of the network; 2) simply fuse the features of encoder
and decoder, ignoring the connection between their spatial locations. In this
paper, we rethink the above problem and build a lightweight medical image
segmentation network, called SegNetr. Specifically, we introduce a novel
SegNetr block that can perform local-global interactions dynamically at any
stage and with only linear complexity. At the same time, we design a general
information retention skip connection (IRSC) to preserve the spatial location
information of encoder features and achieve accurate fusion with the decoder
features. We validate the effectiveness of SegNetr on four mainstream medical
image segmentation datasets, with 59\% and 76\% fewer parameters and GFLOPs
than vanilla U-Net, while achieving segmentation performance comparable to
state-of-the-art methods. Notably, the components proposed in this paper can be
applied to other U-shaped networks to improve their segmentation performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02969">DPM: Clustering Sensitive Data through Separation. (arXiv:2307.02969v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schutt_Y/0/1/0/all/0/1">Yara Sch&#xfc;tt</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebenow_J/0/1/0/all/0/1">Johannes Liebenow</a>, <a href="http://arxiv.org/find/cs/1/au:+Braun_T/0/1/0/all/0/1">Tanya Braun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrke_M/0/1/0/all/0/1">Marcel Gehrke</a>, <a href="http://arxiv.org/find/cs/1/au:+Thaeter_F/0/1/0/all/0/1">Florian Thaeter</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1">Esfandiar Mohammadi</a></p>
<p>Privacy-preserving clustering groups data points in an unsupervised manner
whilst ensuring that sensitive information remains protected. Previous
privacy-preserving clustering focused on identifying concentration of point
clouds. In this paper, we take another path and focus on identifying
appropriate separators that split a data set. We introduce the novel
differentially private clustering algorithm DPM that searches for accurate data
point separators in a differentially private manner. DPM addresses two key
challenges for finding accurate separators: identifying separators that are
large gaps between clusters instead of small gaps within a cluster and, to
efficiently spend the privacy budget, prioritising separators that split the
data into large subparts. Using the differentially private Exponential
Mechanism, DPM randomly chooses cluster separators with provably high utility:
For a data set $D$, if there is a wide low-density separator in the central
$60\%$ quantile, DPM finds that separator with probability $1 -
\exp(-\sqrt{|D|})$. Our experimental evaluation demonstrates that DPM achieves
significant improvements in terms of the clustering metric inertia. With the
inertia results of the non-private KMeans++ as a baseline, for $\varepsilon =
1$ and $\delta=10^{-5}$ DPM improves upon the difference to the baseline by up
to $50\%$ for a synthetic data set and by up to $62\%$ for a real-world data
set compared to a state-of-the-art clustering algorithm by Chang and Kamath.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02973">Pruning vs Quantization: Which is Better?. (arXiv:2307.02973v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kuzmin_A/0/1/0/all/0/1">Andrey Kuzmin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagel_M/0/1/0/all/0/1">Markus Nagel</a>, <a href="http://arxiv.org/find/cs/1/au:+Baalen_M/0/1/0/all/0/1">Mart van Baalen</a>, <a href="http://arxiv.org/find/cs/1/au:+Behboodi_A/0/1/0/all/0/1">Arash Behboodi</a>, <a href="http://arxiv.org/find/cs/1/au:+Blankevoort_T/0/1/0/all/0/1">Tijmen Blankevoort</a></p>
<p>Neural network pruning and quantization techniques are almost as old as
neural networks themselves. However, to date only ad-hoc comparisons between
the two have been published. In this paper, we set out to answer the question
on which is better: neural network quantization or pruning? By answering this
question, we hope to inform design decisions made on neural network hardware
going forward. We provide an extensive comparison between the two techniques
for compressing deep neural networks. First, we give an analytical comparison
of expected quantization and pruning error for general data distributions.
Then, we provide lower bounds for the per-layer pruning and quantization error
in trained networks, and compare these to empirical error after optimization.
Finally, we provide an extensive experimental comparison for training 8
large-scale models on 3 tasks. Our results show that in most cases quantization
outperforms pruning. Only in some scenarios with very high compression ratio,
pruning might be beneficial from an accuracy standpoint.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02975">Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data. (arXiv:2307.02975v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Campana_M/0/1/0/all/0/1">Mattia Giovanni Campana</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmastro_F/0/1/0/all/0/1">Franca Delmastro</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagani_E/0/1/0/all/0/1">Elena Pagani</a></p>
<p>Disease detection from smartphone data represents an open research challenge
in mobile health (m-health) systems. COVID-19 and its respiratory symptoms are
an important case study in this area and their early detection is a potential
real instrument to counteract the pandemic situation. The efficacy of this
solution mainly depends on the performances of AI algorithms applied to the
collected data and their possible implementation directly on the users' mobile
devices. Considering these issues, and the limited amount of available data, in
this paper we present the experimental evaluation of 3 different deep learning
models, compared also with hand-crafted features, and of two main approaches of
transfer learning in the considered scenario: both feature extraction and
fine-tuning. Specifically, we considered VGGish, YAMNET, and
L\textsuperscript{3}-Net (including 12 different configurations) evaluated
through user-independent experiments on 4 different datasets (13,447 samples in
total). Results clearly show the advantages of L\textsuperscript{3}-Net in all
the experimental settings as it overcomes the other solutions by 12.3\% in
terms of Precision-Recall AUC as features extractor, and by 10\% when the model
is fine-tuned. Moreover, we note that to fine-tune only the fully-connected
layers of the pre-trained models generally leads to worse performances, with an
average drop of 6.6\% with respect to feature extraction. %highlighting the
need for further investigations. Finally, we evaluate the memory footprints of
the different models for their possible applications on commercial mobile
devices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02984">A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications. (arXiv:2307.02984v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pennisi_M/0/1/0/all/0/1">Matteo Pennisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salanitri_F/0/1/0/all/0/1">Federica Proietto Salanitri</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellitto_G/0/1/0/all/0/1">Giovanni Bellitto</a>, <a href="http://arxiv.org/find/cs/1/au:+Palazzo_S/0/1/0/all/0/1">Simone Palazzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagci_U/0/1/0/all/0/1">Ulas Bagci</a>, <a href="http://arxiv.org/find/cs/1/au:+Spampinato_C/0/1/0/all/0/1">Concetto Spampinato</a></p>
<p>Generative Adversarial Networks (GANs) have demonstrated their ability to
generate synthetic samples that match a target distribution. However, from a
privacy perspective, using GANs as a proxy for data sharing is not a safe
solution, as they tend to embed near-duplicates of real samples in the latent
space. Recent works, inspired by k-anonymity principles, address this issue
through sample aggregation in the latent space, with the drawback of reducing
the dataset by a factor of k. Our work aims to mitigate this problem by
proposing a latent space navigation strategy able to generate diverse synthetic
samples that may support effective training of deep models, while addressing
privacy concerns in a principled way. Our approach leverages an auxiliary
identity classifier as a guide to non-linearly walk between points in the
latent space, minimizing the risk of collision with near-duplicates of real
samples. We empirically demonstrate that, given any random pair of points in
the latent space, our walking strategy is safer than linear interpolation. We
then test our path-finding strategy combined to k-same methods and demonstrate,
on two benchmarks for tuberculosis and diabetic retinopathy classification,
that training a model using samples generated by our approach mitigate drops in
performance, while keeping privacy preservation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02991">ContainerGym: A Real-World Reinforcement Learning Benchmark for Resource Allocation. (arXiv:2307.02991v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pendyala_A/0/1/0/all/0/1">Abhijeet Pendyala</a>, <a href="http://arxiv.org/find/cs/1/au:+Dettmer_J/0/1/0/all/0/1">Justin Dettmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Glasmachers_T/0/1/0/all/0/1">Tobias Glasmachers</a>, <a href="http://arxiv.org/find/cs/1/au:+Atamna_A/0/1/0/all/0/1">Asma Atamna</a></p>
<p>We present ContainerGym, a benchmark for reinforcement learning inspired by a
real-world industrial resource allocation task. The proposed benchmark encodes
a range of challenges commonly encountered in real-world sequential decision
making problems, such as uncertainty. It can be configured to instantiate
problems of varying degrees of difficulty, e.g., in terms of variable
dimensionality. Our benchmark differs from other reinforcement learning
benchmarks, including the ones aiming to encode real-world difficulties, in
that it is directly derived from a real-world industrial problem, which
underwent minimal simplification and streamlining. It is sufficiently versatile
to evaluate reinforcement learning algorithms on any real-world problem that
fits our resource allocation framework. We provide results of standard baseline
methods. Going beyond the usual training reward curves, our results and the
statistical tools used to interpret them allow to highlight interesting
limitations of well-known deep reinforcement learning algorithms, namely PPO,
TRPO and DQN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03003">Improving the Efficiency of Human-in-the-Loop Systems: Adding Artificial to Human Experts. (arXiv:2307.03003v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jakubik_J/0/1/0/all/0/1">Johannes Jakubik</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_D/0/1/0/all/0/1">Daniel Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemmer_P/0/1/0/all/0/1">Patrick Hemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vossing_M/0/1/0/all/0/1">Michael V&#xf6;ssing</a>, <a href="http://arxiv.org/find/cs/1/au:+Satzger_G/0/1/0/all/0/1">Gerhard Satzger</a></p>
<p>Information systems increasingly leverage artificial intelligence (AI) and
machine learning (ML) to generate value from vast amounts of data. However, ML
models are imperfect and can generate incorrect classifications. Hence,
human-in-the-loop (HITL) extensions to ML models add a human review for
instances that are difficult to classify. This study argues that continuously
relying on human experts to handle difficult model classifications leads to a
strong increase in human effort, which strains limited resources. To address
this issue, we propose a hybrid system that creates artificial experts that
learn to classify data instances from unknown classes previously reviewed by
human experts. Our hybrid system assesses which artificial expert is suitable
for classifying an instance from an unknown class and automatically assigns it.
Over time, this reduces human effort and increases the efficiency of the
system. Our experiments demonstrate that our approach outperforms traditional
HITL systems for several benchmarks on image classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03027">Improving Retrieval-Augmented Large Language Models via Data Importance Learning. (arXiv:2307.03027v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xiaozhong Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Grafberger_S/0/1/0/all/0/1">Stefan Grafberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Biegel_S/0/1/0/all/0/1">Samantha Biegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Shaopeng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Meng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Schelter_S/0/1/0/all/0/1">Sebastian Schelter</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a></p>
<p>Retrieval augmentation enables large language models to take advantage of
external knowledge, for example on tasks like question answering and data
imputation. However, the performance of such retrieval-augmented models is
limited by the data quality of their underlying retrieval corpus. In this
paper, we propose an algorithm based on multilinear extension for evaluating
the data importance of retrieved data points. There are exponentially many
terms in the multilinear extension, and one key contribution of this paper is a
polynomial time algorithm that computes exactly, given a retrieval-augmented
model with an additive utility function and a validation set, the data
importance of data points in the retrieval corpus using the multilinear
extension of the model's utility function. We further proposed an even more
efficient ({\epsilon}, {\delta})-approximation algorithm. Our experimental
results illustrate that we can enhance the performance of large language models
by only pruning or reweighting the retrieval corpus, without requiring further
training. For some tasks, this even allows a small model (e.g., GPT-JT),
augmented with a search engine API, to outperform GPT-3.5 (without retrieval
augmentation). Moreover, we show that weights based on multilinear extension
can be computed efficiently in practice (e.g., in less than ten minutes for a
corpus with 100 million elements).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03034">PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models. (arXiv:2307.03034v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Liu_K/0/1/0/all/0/1">Keqin Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_C/0/1/0/all/0/1">Chengzhong Zhang</a></p>
<p>In this paper, we consider a general observation model for restless
multi-armed bandit problems. The operation of the player needs to be based on
certain feedback mechanism that is error-prone due to resource constraints or
environmental or intrinsic noises. By establishing a general probabilistic
model for dynamics of feedback/observation, we formulate the problem as a
restless bandit with a countable belief state space starting from an arbitrary
initial belief (a priori information). We apply the achievable region method
with partial conservation law (PCL) to the infinite-state problem and analyze
its indexability and priority index (Whittle index). Finally, we propose an
approximation process to transform the problem into which the AG algorithm of
Ni\~no-Mora and Bertsimas for finite-state problems can be applied to.
Numerical experiments show that our algorithm has an excellent performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03042">Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain. (arXiv:2307.03042v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gema_A/0/1/0/all/0/1">Aryo Gema</a>, <a href="http://arxiv.org/find/cs/1/au:+Daines_L/0/1/0/all/0/1">Luke Daines</a>, <a href="http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1">Pasquale Minervini</a>, <a href="http://arxiv.org/find/cs/1/au:+Alex_B/0/1/0/all/0/1">Beatrice Alex</a></p>
<p>Adapting pretrained language models to novel domains, such as clinical
applications, traditionally involves retraining their entire set of parameters.
However, this approach is increasingly proven to be impractical owing to the
substantial computational requirements associated with training such large
language models. To address this issue, Parameter-Efficient Fine-Tuning (PEFT)
techniques offer a viable solution by selectively fine-tuning a small subset of
additional parameters, significantly reducing the computational requirements
for domain adaptation. In this study, we propose Clinical LLaMA-LoRA, a PEFT
adapter layer built upon the open-sourced LLaMA model. Clinical LLaMA-LoRA is
trained using clinical notes obtained from the MIMIC-IV database, thereby
creating a specialised adapter designed for the clinical domain. Additionally,
we propose a two-step PEFT framework which fuses Clinical LLaMA-LoRA with
Downstream LLaMA-LoRA, another PEFT adapter specialised for downstream tasks.
We evaluate this framework on multiple clinical outcome prediction datasets,
comparing it to clinically trained language models. Our proposed framework
achieves a state-of-the-art AUROC score averaged across all clinical downstream
tasks. We observe substantial improvements of 6-9% AUROC score in the
large-scale multilabel classification tasks, such as diagnoses and procedures
classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03043">A Near-Linear Time Algorithm for the Chamfer Distance. (arXiv:2307.03043v1 [cs.DS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1">Ainesh Bakshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1">Piotr Indyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaram_R/0/1/0/all/0/1">Rajesh Jayaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Waingarten_E/0/1/0/all/0/1">Erik Waingarten</a></p>
<p>For any two point sets $A,B \subset \mathbb{R}^d$ of size up to $n$, the
Chamfer distance from $A$ to $B$ is defined as $\text{CH}(A,B)=\sum_{a \in A}
\min_{b \in B} d_X(a,b)$, where $d_X$ is the underlying distance measure (e.g.,
the Euclidean or Manhattan distance). The Chamfer distance is a popular measure
of dissimilarity between point clouds, used in many machine learning, computer
vision, and graphics applications, and admits a straightforward $O(d n^2)$-time
brute force algorithm. Further, the Chamfer distance is often used as a proxy
for the more computationally demanding Earth-Mover (Optimal Transport)
Distance. However, the \emph{quadratic} dependence on $n$ in the running time
makes the naive approach intractable for large datasets.
</p>
<p>We overcome this bottleneck and present the first $(1+\epsilon)$-approximate
algorithm for estimating the Chamfer distance with a near-linear running time.
Specifically, our algorithm runs in time $O(nd \log (n)/\varepsilon^2)$ and is
implementable. Our experiments demonstrate that it is both accurate and fast on
large high-dimensional datasets. We believe that our algorithm will open new
avenues for analyzing large high-dimensional point clouds. We also give
evidence that if the goal is to \emph{report} a $(1+\varepsilon)$-approximate
mapping from $A$ to $B$ (as opposed to just its value), then any sub-quadratic
time algorithm is unlikely to exist.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03045">Track Mix Generation on Music Streaming Services using Transformers. (arXiv:2307.03045v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bendada_W/0/1/0/all/0/1">Walid Bendada</a>, <a href="http://arxiv.org/find/cs/1/au:+Bontempelli_T/0/1/0/all/0/1">Th&#xe9;o Bontempelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Morlon_M/0/1/0/all/0/1">Mathieu Morlon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapus_B/0/1/0/all/0/1">Benjamin Chapus</a>, <a href="http://arxiv.org/find/cs/1/au:+Cador_T/0/1/0/all/0/1">Thibault Cador</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouabca_T/0/1/0/all/0/1">Thomas Bouab&#xe7;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1">Guillaume Salha-Galvan</a></p>
<p>This paper introduces Track Mix, a personalized playlist generation system
released in 2022 on the music streaming service Deezer. Track Mix automatically
generates "mix" playlists inspired by initial music tracks, allowing users to
discover music similar to their favorite content. To generate these mixes, we
consider a Transformer model trained on millions of track sequences from user
playlists. In light of the growing popularity of Transformers in recent years,
we analyze the advantages, drawbacks, and technical challenges of using such a
model for mix generation on the service, compared to a more traditional
collaborative filtering approach. Since its release, Track Mix has been
generating playlists for millions of users daily, enhancing their music
discovery experience on Deezer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03048">Origin-Destination Travel Time Oracle for Map-based Services. (arXiv:2307.03048v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1">Huaiyu Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jilin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shengnan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jensen_C/0/1/0/all/0/1">Christian S. Jensen</a></p>
<p>Given an origin (O), a destination (D), and a departure time (T), an
Origin-Destination (OD) travel time oracle~(ODT-Oracle) returns an estimate of
the time it takes to travel from O to D when departing at T. ODT-Oracles serve
important purposes in map-based services. To enable the construction of such
oracles, we provide a travel-time estimation (TTE) solution that leverages
historical trajectories to estimate time-varying travel times for OD pairs.
</p>
<p>The problem is complicated by the fact that multiple historical trajectories
with different travel times may connect an OD pair, while trajectories may vary
from one another. To solve the problem, it is crucial to remove outlier
trajectories when doing travel time estimation for future queries.
</p>
<p>We propose a novel, two-stage framework called Diffusion-based
Origin-destination Travel Time Estimation (DOT), that solves the problem.
First, DOT employs a conditioned Pixelated Trajectories (PiT) denoiser that
enables building a diffusion-based PiT inference process by learning
correlations between OD pairs and historical trajectories. Specifically, given
an OD pair and a departure time, we aim to infer a PiT. Next, DOT encompasses a
Masked Vision Transformer~(MViT) that effectively and efficiently estimates a
travel time based on the inferred PiT. We report on extensive experiments on
two real-world datasets that offer evidence that DOT is capable of
outperforming baseline methods in terms of accuracy, scalability, and
explainability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03056">Generalizing Backpropagation for Gradient-Based Interpretability. (arXiv:2307.03056v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Du_K/0/1/0/all/0/1">Kevin Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennigen_L/0/1/0/all/0/1">Lucas Torroba Hennigen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoehr_N/0/1/0/all/0/1">Niklas Stoehr</a>, <a href="http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1">Alexander Warstadt</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a></p>
<p>Many popular feature-attribution methods for interpreting deep neural
networks rely on computing the gradients of a model's output with respect to
its inputs. While these methods can indicate which input features may be
important for the model's prediction, they reveal little about the inner
workings of the model itself. In this paper, we observe that the gradient
computation of a model is a special case of a more general formulation using
semirings. This observation allows us to generalize the backpropagation
algorithm to efficiently compute other interpretable statistics about the
gradient graph of a neural network, such as the highest-weighted path and
entropy. We implement this generalized algorithm, evaluate it on synthetic
datasets to better understand the statistics it computes, and apply it to study
BERT's behavior on the subject-verb number agreement task (SVA). With this
method, we (a) validate that the amount of gradient flow through a component of
a model reflects its importance to a prediction and (b) for SVA, identify which
pathways of the self-attention mechanism are most important.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03067">DeepOnto: A Python Package for Ontology Engineering with Deep Learning. (arXiv:2307.03067v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaoyan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1">Ian Horrocks</a>, <a href="http://arxiv.org/find/cs/1/au:+Allocca_C/0/1/0/all/0/1">Carlo Allocca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taehun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapkota_B/0/1/0/all/0/1">Brahmananda Sapkota</a></p>
<p>Applying deep learning techniques, particularly language models (LMs), in
ontology engineering has raised widespread attention. However, deep learning
frameworks like PyTorch and Tensorflow are predominantly developed for Python
programming, while widely-used ontology APIs, such as the OWL API and Jena, are
primarily Java-based. To facilitate seamless integration of these frameworks
and APIs, we present Deeponto, a Python package designed for ontology
engineering. The package encompasses a core ontology processing module founded
on the widely-recognised and reliable OWL API, encapsulating its fundamental
features in a more "Pythonic" manner and extending its capabilities to include
other essential components including reasoning, verbalisation, normalisation,
projection, and more. Building on this module, Deeponto offers a suite of
tools, resources, and algorithms that support various ontology engineering
tasks, such as ontology alignment and completion, by harnessing deep learning
methodologies, primarily pre-trained LMs. In this paper, we also demonstrate
the practical utility of Deeponto through two use-cases: the Digital Health
Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment
Evaluation Initiative (OAEI).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03068">A Hybrid End-to-End Spatio-Temporal Attention Neural Network with Graph-Smooth Signals for EEG Emotion Recognition. (arXiv:2307.03068v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sartipi_S/0/1/0/all/0/1">Shadi Sartipi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torkamani_Azar_M/0/1/0/all/0/1">Mastaneh Torkamani-Azar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cetin_M/0/1/0/all/0/1">Mujdat Cetin</a></p>
<p>Recently, physiological data such as electroencephalography (EEG) signals
have attracted significant attention in affective computing. In this context,
the main goal is to design an automated model that can assess emotional states.
Lately, deep neural networks have shown promising performance in emotion
recognition tasks. However, designing a deep architecture that can extract
practical information from raw data is still a challenge. Here, we introduce a
deep neural network that acquires interpretable physiological representations
by a hybrid structure of spatio-temporal encoding and recurrent attention
network blocks. Furthermore, a preprocessing step is applied to the raw data
using graph signal processing tools to perform graph smoothing in the spatial
domain. We demonstrate that our proposed architecture exceeds state-of-the-art
results for emotion classification on the publicly available DEAP dataset. To
explore the generality of the learned model, we also evaluate the performance
of our architecture towards transfer learning (TL) by transferring the model
parameters from a specific source to other target domains. Using DEAP as the
source dataset, we demonstrate the effectiveness of our model in performing
cross-modality TL and improving emotion classification accuracy on DREAMER and
the Emotional English Word (EEWD) datasets, which involve EEG-based emotion
classification tasks with different stimuli.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03077">Learning Disentangled Representations in Signed Directed Graphs without Social Assumptions. (arXiv:2307.03077v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ko_G/0/1/0/all/0/1">Geonwoo Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1">Jinhong Jung</a></p>
<p>Signed graphs are complex systems that represent trust relationships or
preferences in various domains. Learning node representations in such graphs is
crucial for many mining tasks. Although real-world signed relationships can be
influenced by multiple latent factors, most existing methods often oversimplify
the modeling of signed relationships by relying on social theories and treating
them as simplistic factors. This limits their expressiveness and their ability
to capture the diverse factors that shape these relationships. In this paper,
we propose DINES, a novel method for learning disentangled node representations
in signed directed graphs without social assumptions. We adopt a disentangled
framework that separates each embedding into distinct factors, allowing for
capturing multiple latent factors. We also explore lightweight graph
convolutions that focus solely on sign and direction, without depending on
social theories. Additionally, we propose a decoder that effectively classifies
an edge's sign by considering correlations between the factors. To further
enhance disentanglement, we jointly train a self-supervised factor
discriminator with our encoder and decoder. Throughout extensive experiments on
real-world signed directed graphs, we show that DINES effectively learns
disentangled node representations, and significantly outperforms its
competitors in the sign prediction task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03084">OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models. (arXiv:2307.03084v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengding Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Weilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xingtai Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a></p>
<p>The scale of large pre-trained models (PTMs) poses significant challenges in
adapting to downstream tasks due to the high optimization overhead and storage
costs associated with full-parameter fine-tuning. To address this, many studies
explore parameter-efficient tuning methods, also framed as "delta tuning",
which updates only a small subset of parameters, known as "delta modules",
while keeping the backbone model's parameters fixed. However, the practicality
and flexibility of delta tuning have been limited due to existing
implementations that directly modify the code of the backbone PTMs and
hard-code specific delta tuning methods for each PTM. In this paper, we present
OpenDelta, an open-source library that overcomes these limitations by providing
a plug-and-play implementation of various delta tuning methods. Our novel
techniques eliminate the need to modify the backbone PTMs' code, making
OpenDelta compatible with different, even novel PTMs. OpenDelta is designed to
be simple, modular, and extensible, providing a comprehensive platform for
researchers and practitioners to adapt large PTMs efficiently.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03093">Beyond Intuition, a Framework for Applying GPs to Real-World Data. (arXiv:2307.03093v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tazi_K/0/1/0/all/0/1">Kenza Tazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jihao Andreas Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Viljoen_R/0/1/0/all/0/1">Ross Viljoen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_A/0/1/0/all/0/1">Alex Gardner</a>, <a href="http://arxiv.org/find/cs/1/au:+John_T/0/1/0/all/0/1">Ti John</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1">Hong Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1">Richard E. Turner</a></p>
<p>Gaussian Processes (GPs) offer an attractive method for regression over
small, structured and correlated datasets. However, their deployment is
hindered by computational costs and limited guidelines on how to apply GPs
beyond simple low-dimensional datasets. We propose a framework to identify the
suitability of GPs to a given problem and how to set up a robust and
well-specified GP model. The guidelines formalise the decisions of experienced
GP practitioners, with an emphasis on kernel design and options for
computational scalability. The framework is then applied to a case study of
glacier elevation change yielding more accurate results at test time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03108">How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models. (arXiv:2307.03108v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhenting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1">Lingjuan Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris Metaxas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shiqing Ma</a></p>
<p>Recent text-to-image diffusion models have shown surprising performance in
generating high-quality images. However, concerns have arisen regarding the
unauthorized usage of data during the training process. One example is when a
model trainer collects a set of images created by a particular artist and
attempts to train a model capable of generating similar images without
obtaining permission from the artist. To address this issue, it becomes crucial
to detect unauthorized data usage. In this paper, we propose a method for
detecting such unauthorized data usage by planting injected memorization into
the text-to-image diffusion models trained on the protected dataset.
Specifically, we modify the protected image dataset by adding unique contents
on the images such as stealthy image wrapping functions that are imperceptible
to human vision but can be captured and memorized by diffusion models. By
analyzing whether the model has memorization for the injected content (i.e.,
whether the generated images are processed by the chosen post-processing
function), we can detect models that had illegally utilized the unauthorized
data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate
the effectiveness of the proposed method in detecting unauthorized data usages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03118">Quantum Solutions to the Privacy vs. Utility Tradeoff. (arXiv:2307.03118v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Chatterjee_S/0/1/0/all/0/1">Sagnik Chatterjee</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kungurtsev_V/0/1/0/all/0/1">Vyacheslav Kungurtsev</a></p>
<p>In this work, we propose a novel architecture (and several variants thereof)
based on quantum cryptographic primitives with provable privacy and security
guarantees regarding membership inference attacks on generative models. Our
architecture can be used on top of any existing classical or quantum generative
models. We argue that the use of quantum gates associated with unitary
operators provides inherent advantages compared to standard Differential
Privacy based techniques for establishing guaranteed security from all
polynomial-time adversaries.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03119">Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance. (arXiv:2307.03119v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuchen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhenggang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1">Kan Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Li Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a></p>
<p>Order execution is a fundamental task in quantitative finance, aiming at
finishing acquisition or liquidation for a number of trading orders of the
specific assets. Recent advance in model-free reinforcement learning (RL)
provides a data-driven solution to the order execution problem. However, the
existing works always optimize execution for an individual order, overlooking
the practice that multiple orders are specified to execute simultaneously,
resulting in suboptimality and bias. In this paper, we first present a
multi-agent RL (MARL) method for multi-order execution considering practical
constraints. Specifically, we treat every agent as an individual operator to
trade one specific order, while keeping communicating with each other and
collaborating for maximizing the overall profits. Nevertheless, the existing
MARL algorithms often incorporate communication among agents by exchanging only
the information of their partial observations, which is inefficient in
complicated financial market. To improve collaboration, we then propose a
learnable multi-round communication protocol, for the agents communicating the
intended actions with each other and refining accordingly. It is optimized
through a novel action value attribution method which is provably consistent
with the original learning objective yet more efficient. The experiments on the
data from two real-world markets have illustrated superior performance with
significantly better collaboration effectiveness achieved by our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03126">Context-Aware Configuration and Management of WiFi Direct Groups for Real Opportunistic Networks. (arXiv:2307.03126v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arnaboldi_V/0/1/0/all/0/1">Valerio Arnaboldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Campana_M/0/1/0/all/0/1">Mattia Giovanni Campana</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmastro_F/0/1/0/all/0/1">Franca Delmastro</a></p>
<p>Wi-Fi Direct is a promising technology for the support of device-to-device
communications (D2D) on commercial mobile devices. However, the standard
as-it-is is not sufficient to support the real deployment of networking
solutions entirely based on D2D such as opportunistic networks. In fact, WiFi
Direct presents some characteristics that could limit the autonomous creation
of D2D connections among users' personal devices. Specifically, the standard
explicitly requires the user's authorization to establish a connection between
two or more devices, and it provides a limited support for inter-group
communication. In some cases, this might lead to the creation of isolated
groups of nodes which cannot communicate among each other. In this paper, we
propose a novel middleware-layer protocol for the efficient configuration and
management of WiFi Direct groups (WiFi Direct Group Manager, WFD-GM) to enable
autonomous connections and inter-group communication. This enables
opportunistic networks in real conditions (e.g., variable mobility and network
size). WFD-GM defines a context function that takes into account heterogeneous
parameters for the creation of the best group configuration in a specific time
window, including an index of nodes' stability and power levels. We evaluate
the protocol performances by simulating three reference scenarios including
different mobility models, geographical areas and number of nodes. Simulations
are also supported by experimental results related to the evaluation in a real
testbed of the involved context parameters. We compare WFD-GM with the
state-of-the-art solutions and we show that it performs significantly better
than a Baseline approach in scenarios with medium/low mobility, and it is
comparable with it in case of high mobility, without introducing additional
overhead.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03128">Principal subbundles for dimension reduction. (arXiv:2307.03128v1 [stat.ME])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Akhoj_M/0/1/0/all/0/1">Morten Akh&#xf8;j</a>, <a href="http://arxiv.org/find/stat/1/au:+Benn_J/0/1/0/all/0/1">James Benn</a>, <a href="http://arxiv.org/find/stat/1/au:+Grong_E/0/1/0/all/0/1">Erlend Grong</a>, <a href="http://arxiv.org/find/stat/1/au:+Sommer_S/0/1/0/all/0/1">Stefan Sommer</a>, <a href="http://arxiv.org/find/stat/1/au:+Pennec_X/0/1/0/all/0/1">Xavier Pennec</a></p>
<p>In this paper we demonstrate how sub-Riemannian geometry can be used for
manifold learning and surface reconstruction by combining local linear
approximations of a point cloud to obtain lower dimensional bundles. Local
approximations obtained by local PCAs are collected into a rank $k$ tangent
subbundle on $\mathbb{R}^d$, $k&lt;d$, which we call a principal subbundle. This
determines a sub-Riemannian metric on $\mathbb{R}^d$. We show that
sub-Riemannian geodesics with respect to this metric can successfully be
applied to a number of important problems, such as: explicit construction of an
approximating submanifold $M$, construction of a representation of the
point-cloud in $\mathbb{R}^k$, and computation of distances between
observations, taking the learned geometry into account. The reconstruction is
guaranteed to equal the true submanifold in the limit case where tangent spaces
are estimated exactly. Via simulations, we show that the framework is robust
when applied to noisy data. Furthermore, the framework generalizes to
observations on an a priori known Riemannian manifold.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03132">T-MARS: Improving Visual Representations by Circumventing Text Feature Learning. (arXiv:2307.03132v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maini_P/0/1/0/all/0/1">Pratyush Maini</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1">Sachin Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Aditi Raghunathan</a></p>
<p>Large web-sourced multimodal datasets have powered a slew of new methods for
learning general-purpose visual representations, advancing the state of the art
in computer vision and revolutionizing zero- and few-shot recognition. One
crucial decision facing practitioners is how, if at all, to curate these
ever-larger datasets. For example, the creators of the LAION-5B dataset chose
to retain only image-caption pairs whose CLIP similarity score exceeded a
designated threshold. In this paper, we propose a new state-of-the-art data
filtering approach motivated by our observation that nearly 40% of LAION's
images contain text that overlaps significantly with the caption. Intuitively,
such data could be wasteful as it incentivizes models to perform optical
character recognition rather than learning visual features. However, naively
removing all such data could also be wasteful, as it throws away images that
contain visual features (in addition to overlapping text). Our simple and
scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those
pairs where the text dominates the remaining visual features -- by first
masking out the text and then filtering out those with a low CLIP similarity
score of the masked image. Experimentally, T-MARS outperforms the top-ranked
method on the "medium scale" of DataComp (a data filtering benchmark) by a
margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic
evaluation on various data pool sizes from 2M to 64M shows that the accuracy
gains enjoyed by T-MARS linearly increase as data and compute are scaled
exponentially. Code is available at https://github.com/locuslab/T-MARS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03133">Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification. (arXiv:2307.03133v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yongcan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_L/0/1/0/all/0/1">Lijun Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Ran He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a></p>
<p>Test-time adaptation (TTA) is a technique aimed at enhancing the
generalization performance of models by leveraging unlabeled samples solely
during prediction. Given the need for robustness in neural network systems when
faced with distribution shifts, numerous TTA methods have recently been
proposed. However, evaluating these methods is often done under different
settings, such as varying distribution shifts, backbones, and designing
scenarios, leading to a lack of consistent and fair benchmarks to validate
their effectiveness. To address this issue, we present a benchmark that
systematically evaluates 13 prominent TTA methods and their variants on five
widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C,
DomainNet, and Office-Home. These methods encompass a wide range of adaptation
scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation
v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the
compatibility of different TTA methods with diverse network backbones. To
implement this benchmark, we have developed a unified framework in PyTorch,
which allows for consistent evaluation and comparison of the TTA methods across
the different datasets and network architectures. By establishing this
benchmark, we aim to provide researchers and practitioners with a reliable
means of assessing and comparing the effectiveness of TTA methods in improving
model robustness and generalization performance. Our code is available at
https://github.com/yuyongcan/Benchmark-TTA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03135">Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yunhao Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minghua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a></p>
<p>Large vision-language models have achieved outstanding performance, but their
size and computational requirements make their deployment on
resource-constrained devices and time-sensitive tasks impractical. Model
distillation, the process of creating smaller, faster models that maintain the
performance of larger models, is a promising direction towards the solution.
This paper investigates the distillation of visual representations in large
teacher vision-language models into lightweight student models using a small-
or mid-scale dataset. Notably, this study focuses on open-vocabulary
out-of-distribution (OOD) generalization, a challenging problem that has been
overlooked in previous model distillation literature. We propose two principles
from vision and language modality perspectives to enhance student's OOD
generalization: (1) by better imitating teacher's visual representation space,
and carefully promoting better coherence in vision-language alignment with the
teacher; (2) by enriching the teacher's language representations with
informative and finegrained semantic attributes to effectively distinguish
between different labels. We propose several metrics and conduct extensive
experiments to investigate their techniques. The results demonstrate
significant improvements in zero-shot and few-shot student performance on
open-vocabulary out-of-distribution classification, highlighting the
effectiveness of our proposed approaches. Our code will be released at
https://github.com/xuanlinli17/large_vlm_distillation_ood
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03136">Multiplicative Updates for Online Convex Optimization over Symmetric Cones. (arXiv:2307.03136v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Canyakmaz_I/0/1/0/all/0/1">Ilayda Canyakmaz</a>, <a href="http://arxiv.org/find/math/1/au:+Lin_W/0/1/0/all/0/1">Wayne Lin</a>, <a href="http://arxiv.org/find/math/1/au:+Piliouras_G/0/1/0/all/0/1">Georgios Piliouras</a>, <a href="http://arxiv.org/find/math/1/au:+Varvitsiotis_A/0/1/0/all/0/1">Antonios Varvitsiotis</a></p>
<p>We study online convex optimization where the possible actions are trace-one
elements in a symmetric cone, generalizing the extensively-studied experts
setup and its quantum counterpart. Symmetric cones provide a unifying framework
for some of the most important optimization models, including linear,
second-order cone, and semidefinite optimization. Using tools from the field of
Euclidean Jordan Algebras, we introduce the Symmetric-Cone Multiplicative
Weights Update (SCMWU), a projection-free algorithm for online optimization
over the trace-one slice of an arbitrary symmetric cone. We show that SCMWU is
equivalent to Follow-the-Regularized-Leader and Online Mirror Descent with
symmetric-cone negative entropy as regularizer. Using this structural result we
show that SCMWU is a no-regret algorithm, and verify our theoretical results
with extensive experiments. Our results unify and generalize the analysis for
the Multiplicative Weights Update method over the probability simplex and the
Matrix Multiplicative Weights Update method over the set of density matrices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03137">Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images. (arXiv:2307.03137v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ozcelik_S/0/1/0/all/0/1">Seher Ozcelik</a>, <a href="http://arxiv.org/find/eess/1/au:+Unver_S/0/1/0/all/0/1">Sinan Unver</a>, <a href="http://arxiv.org/find/eess/1/au:+Gurses_I/0/1/0/all/0/1">Ilke Ali Gurses</a>, <a href="http://arxiv.org/find/eess/1/au:+Turkay_R/0/1/0/all/0/1">Rustu Turkay</a>, <a href="http://arxiv.org/find/eess/1/au:+Gunduz_Demir_C/0/1/0/all/0/1">Cigdem Gunduz-Demir</a></p>
<p>Segmentation networks are not explicitly imposed to learn global invariants
of an image, such as the shape of an object and the geometry between multiple
objects, when they are trained with a standard loss function. On the other
hand, incorporating such invariants into network training may help improve
performance for various segmentation tasks when they are the intrinsic
characteristics of the objects to be segmented. One example is segmentation of
aorta and great vessels in computed tomography (CT) images where vessels are
found in a particular geometry in the body due to the human anatomy and they
mostly seem as round objects on a 2D CT image. This paper addresses this issue
by introducing a new topology-aware loss function that penalizes topology
dissimilarities between the ground truth and prediction through persistent
homology. Different from the previously suggested segmentation network designs,
which apply the threshold filtration on a likelihood function of the prediction
map and the Betti numbers of the ground truth, this paper proposes to apply the
Vietoris-Rips filtration to obtain persistence diagrams of both ground truth
and prediction maps and calculate the dissimilarity with the Wasserstein
distance between the corresponding persistence diagrams. The use of this
filtration has advantage of modeling shape and geometry at the same time, which
may not happen when the threshold filtration is applied. Our experiments on
4327 CT images of 24 subjects reveal that the proposed topology-aware loss
function leads to better results than its counterparts, indicating the
effectiveness of this use.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03157">Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?. (arXiv:2307.03157v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Janet Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunbei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhengming Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamm_J/0/1/0/all/0/1">Jihun Hamm</a></p>
<p>Deep learning-based diagnostic system has demonstrated potential in
classifying skin cancer conditions when labeled training example are abundant.
However, skin lesion analysis often suffers from a scarcity of labeled data,
hindering the development of an accurate and reliable diagnostic system. In
this work, we leverage multiple skin lesion datasets and investigate the
feasibility of various unsupervised domain adaptation (UDA) methods in binary
and multi-class skin lesion classification. In particular, we assess three UDA
training schemes: single-, combined-, and multi-source. Our experiment results
show that UDA is effective in binary classification, with further improvement
being observed when imbalance is mitigated. In multi-class task, its
performance is less prominent, and imbalance problem again needs to be
addressed to achieve above-baseline accuracy. Through our quantitative
analysis, we find that the test error of multi-class tasks is strongly
correlated with label shift, and feature-level UDA methods have limitations
when handling imbalanced datasets. Finally, our study reveals that UDA can
effectively reduce bias against minority groups and promote fairness, even
without the explicit use of fairness-focused techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03170">Focused Transformer: Contrastive Training for Context Scaling. (arXiv:2307.03170v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tworkowski_S/0/1/0/all/0/1">Szymon Tworkowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Staniszewski_K/0/1/0/all/0/1">Konrad Staniszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacek_M/0/1/0/all/0/1">Miko&#x142;aj Pacek</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuhuai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1">Henryk Michalewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Milos_P/0/1/0/all/0/1">Piotr Mi&#x142;o&#x15b;</a></p>
<p>Large language models have an exceptional capability to incorporate new
information in a contextual manner. However, the full potential of such an
approach is often restrained due to a limitation in the effective context
length. One solution to this issue is to endow an attention layer with access
to an external memory, which comprises of (key, value) pairs. Yet, as the
number of documents increases, the proportion of relevant keys to irrelevant
ones decreases, leading the model to focus more on the irrelevant keys. We
identify a significant challenge, dubbed the distraction issue, where keys
linked to different semantic values might overlap, making them hard to
distinguish. To tackle this problem, we introduce the Focused Transformer
(FoT), a technique that employs a training process inspired by contrastive
learning. This novel approach enhances the structure of the (key, value) space,
enabling an extension of the context length. Our method allows for fine-tuning
pre-existing, large-scale models to lengthen their effective context. This is
demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The
resulting models, which we name LongLLaMA, exhibit advancements in tasks
requiring a long context. We further illustrate that our LongLLaMA models
adeptly manage a $256 k$ context length for passkey retrieval.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03175">Push Past Green: Learning to Look Behind Plant Foliage by Moving It. (arXiv:2307.03175v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Saurabh Gupta</a></p>
<p>Autonomous agriculture applications (e.g., inspection, phenotyping, plucking
fruits) require manipulating the plant foliage to look behind the leaves and
the branches. Partial visibility, extreme clutter, thin structures, and unknown
geometry and dynamics for plants make such manipulation challenging. We tackle
these challenges through data-driven methods. We use self-supervision to train
SRPNet, a neural network that predicts what space is revealed on execution of a
candidate action on a given plant. We use SRPNet with the cross-entropy method
to predict actions that are effective at revealing space beneath plant foliage.
Furthermore, as SRPNet does not just predict how much space is revealed but
also where it is revealed, we can execute a sequence of actions that
incrementally reveal more and more space beneath the plant foliage. We
experiment with a synthetic (vines) and a real plant (Dracaena) on a physical
test-bed across 5 settings including 2 settings that test generalization to
novel plant configurations. Our experiments reveal the effectiveness of our
overall method, PPG, over a competitive hand-crafted exploration method, and
the effectiveness of SRPNet over a hand-crafted dynamics model and relevant
ablations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03176">Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles. (arXiv:2307.03176v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ruben_B/0/1/0/all/0/1">Benjamin S. Ruben</a>, <a href="http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1">Cengiz Pehlevan</a></p>
<p>Feature bagging is a well-established ensembling method which aims to reduce
prediction variance by training estimators in an ensemble on random subsamples
or projections of features. Typically, ensembles are chosen to be homogeneous,
in the sense the the number of feature dimensions available to an estimator is
uniform across the ensemble. Here, we introduce heterogeneous feature
ensembling, with estimators built on varying number of feature dimensions, and
consider its performance in a linear regression setting. We study an ensemble
of linear predictors, each fit using ridge regression on a subset of the
available features. We allow the number of features included in these subsets
to vary. Using the replica trick from statistical physics, we derive learning
curves for ridge ensembles with deterministic linear masks. We obtain explicit
expressions for the learning curves in the case of equicorrelated data with an
isotropic feature noise. Using the derived expressions, we investigate the
effect of subsampling and ensembling, finding sharp transitions in the optimal
ensembling strategy in the parameter space of noise level, data correlations,
and data-task alignment. Finally, we suggest variable-dimension feature bagging
as a strategy to mitigate double descent for robust machine learning in
practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03186">TGRL: An Algorithm for Teacher Guided Reinforcement Learning. (arXiv:2307.03186v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shenfeld_I/0/1/0/all/0/1">Idan Shenfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1">Zhang-Wei Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1">Aviv Tamar</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a></p>
<p>Learning from rewards (i.e., reinforcement learning or RL) and learning to
imitate a teacher (i.e., teacher-student learning) are two established
approaches for solving sequential decision-making problems. To combine the
benefits of these different forms of learning, it is common to train a policy
to maximize a combination of reinforcement and teacher-student learning
objectives. However, without a principled method to balance these objectives,
prior work used heuristics and problem-specific hyperparameter searches to
balance the two objectives. We present a $\textit{principled}$ approach, along
with an approximate implementation for $\textit{dynamically}$ and
$\textit{automatically}$ balancing when to follow the teacher and when to use
rewards. The main idea is to adjust the importance of teacher supervision by
comparing the agent's performance to the counterfactual scenario of the agent
learning without teacher supervision and only from rewards. If using teacher
supervision improves performance, the importance of teacher supervision is
increased and otherwise it is decreased. Our method, $\textit{Teacher Guided
Reinforcement Learning}$ (TGRL), outperforms strong baselines across diverse
domains without hyper-parameter tuning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03190">Synthesizing Artistic Cinemagraphs from Text. (arXiv:2307.03190v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mahapatra_A/0/1/0/all/0/1">Aniruddha Mahapatra</a>, <a href="http://arxiv.org/find/cs/1/au:+Siarohin_A/0/1/0/all/0/1">Aliaksandr Siarohin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1">Sergey Tulyakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a></p>
<p>We introduce Artistic Cinemagraph, a fully automated method for creating
cinemagraphs from text descriptions - an especially challenging task when
prompts feature imaginary elements and artistic styles, given the complexity of
interpreting the semantics and motions of these images. Existing single-image
animation methods fall short on artistic inputs, and recent text-based video
methods frequently introduce temporal inconsistencies, struggling to keep
certain regions static. To address these challenges, we propose an idea of
synthesizing image twins from a single text prompt - a pair of an artistic
image and its pixel-aligned corresponding natural-looking twin. While the
artistic image depicts the style and appearance detailed in our text prompt,
the realistic counterpart greatly simplifies layout and motion analysis.
Leveraging existing natural image and video datasets, we can accurately segment
the realistic image and predict plausible motion given the semantic
information. The predicted motion can then be transferred to the artistic image
to create the final cinemagraph. Our method outperforms existing approaches in
creating cinemagraphs for natural landscapes as well as artistic and
other-worldly scenes, as validated by automated metrics and user studies.
Finally, we demonstrate two extensions: animating existing paintings and
controlling motion directions using text.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2011.05905">ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks. (arXiv:2011.05905v4 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhichuang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Ruimin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Changming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Amrita Roy Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Long Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1">Somesh Jha</a></p>
<p>With the increased usage of AI accelerators on mobile and edge devices,
on-device machine learning (ML) is gaining popularity. Thousands of proprietary
ML models are being deployed today on billions of untrusted devices. This
raises serious security concerns about model privacy. However, protecting model
privacy without losing access to the untrusted AI accelerators is a challenging
problem. In this paper, we present a novel on-device model inference system,
ShadowNet. ShadowNet protects the model privacy with Trusted Execution
Environment (TEE) while securely outsourcing the heavy linear layers of the
model to the untrusted hardware accelerators. ShadowNet achieves this by
transforming the weights of the linear layers before outsourcing them and
restoring the results inside the TEE. The non-linear layers are also kept
secure inside the TEE. ShadowNet's design ensures efficient transformation of
the weights and the subsequent restoration of the results. We build a ShadowNet
prototype based on TensorFlow Lite and evaluate it on five popular CNNs,
namely, MobileNet, ResNet-44, MiniVGG, ResNet-404, and YOLOv4-tiny. Our
evaluation shows that ShadowNet achieves strong security guarantees with
reasonable performance, offering a practical solution for secure on-device
model inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2101.04757">Airfoil GAN: Encoding and Synthesizing Airfoils for Aerodynamic Shape Optimization. (arXiv:2101.04757v2 [cs.CE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimada_K/0/1/0/all/0/1">Kenji Shimada</a>, <a href="http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1">Amir Barati Farimani</a></p>
<p>The current design of aerodynamic shapes, like airfoils, involves
computationally intensive simulations to explore the possible design space.
Usually, such design relies on the prior definition of design parameters and
places restrictions on synthesizing novel shapes. In this work, we propose a
data-driven shape encoding and generating method, which automatically learns
representations from existing airfoils and uses the learned representations to
generate new airfoils. The representations are then used in the optimization of
synthesized airfoil shapes based on their aerodynamic performance. Our model is
built upon VAEGAN, a neural network that combines Variational Autoencoder with
Generative Adversarial Network and is trained by the gradient-based technique.
Our model can (1) encode the existing airfoil into a latent vector and
reconstruct the airfoil from that, (2) generate novel airfoils by randomly
sampling the latent vectors and mapping the vectors to the airfoil coordinate
domain, and (3) synthesize airfoils with desired aerodynamic properties by
optimizing learned features via a genetic algorithm. Our experiments show that
the learned features encode shape information thoroughly and comprehensively
without predefined design parameters. By interpolating/extrapolating feature
vectors or sampling from Gaussian noises, the model can automatically
synthesize novel airfoil shapes, some of which possess competitive or even
better aerodynamic properties comparing to airfoils used for model training
purposes. By optimizing shapes on the learned latent domain via a genetic
algorithm, synthesized airfoils can evolve to target aerodynamic properties.
This demonstrates an efficient learning-based airfoil design framework, which
encodes and optimizes the airfoil on the latent domain and synthesizes
promising airfoil candidates for required aerodynamic performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2108.09923">Convolutional Filtering and Neural Networks with Non Commutative Algebras. (arXiv:2108.09923v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Parada_Mayorga_A/0/1/0/all/0/1">Alejandro Parada-Mayorga</a>, <a href="http://arxiv.org/find/cs/1/au:+Butler_L/0/1/0/all/0/1">Landon Butler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a></p>
<p>In this paper we introduce and study the algebraic generalization of non
commutative convolutional neural networks. We leverage the theory of algebraic
signal processing to model convolutional non commutative architectures, and we
derive concrete stability bounds that extend those obtained in the literature
for commutative convolutional neural networks. We show that non commutative
convolutional architectures can be stable to deformations on the space of
operators. We develop the spectral representation of non commutative signal
models to show that non commutative filters process Fourier components
independently of each other. In particular we prove that although the spectral
decompositions of signals in non commutative models are associated to
eigenspaces of dimension larger than one, there exists a trade-off between
stability and selectivity, which is controlled by matrix polynomial functions
in spaces of matrices of low dimension. This tradeoff shows how when the
filters in the algebra are restricted to be stable, there is a loss in
discriminability that is compensated in the network by the pointwise
nonlinearities. The results derived in this paper have direct applications and
implications in non commutative convolutional architectures such as group
neural networks, multigraph neural networks, and quaternion neural networks,
for which we provide a set of numerical experiments showing their behavior when
perturbations are present.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.05192">Convex-Concave Min-Max Stackelberg Games. (arXiv:2110.05192v8 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goktas_D/0/1/0/all/0/1">Denizalp Goktas</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenwald_A/0/1/0/all/0/1">Amy Greenwald</a></p>
<p>Min-max optimization problems (i.e., min-max games) have been attracting a
great deal of attention because of their applicability to a wide range of
machine learning problems. Although significant progress has been made
recently, the literature to date has focused on games with independent strategy
sets; little is known about solving games with dependent strategy sets, which
can be characterized as min-max Stackelberg games. We introduce two first-order
methods that solve a large class of convex-concave min-max Stackelberg games,
and show that our methods converge in polynomial time. Min-max Stackelberg
games were first studied by Wald, under the posthumous name of Wald's maximin
model, a variant of which is the main paradigm used in robust optimization,
which means that our methods can likewise solve many convex robust optimization
problems. We observe that the computation of competitive equilibria in Fisher
markets also comprises a min-max Stackelberg game. Further, we demonstrate the
efficacy and efficiency of our algorithms in practice by computing competitive
equilibria in Fisher markets with varying utility structures. Our experiments
suggest potential ways to extend our theoretical results, by demonstrating how
different smoothness properties can affect the convergence rate of our
algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2111.15365">Expert Aggregation for Financial Forecasting. (arXiv:2111.15365v4 [q-fin.ST] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Remlinger_C/0/1/0/all/0/1">Carl Remlinger</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Marie_B/0/1/0/all/0/1">Bri&#xe8;re Marie</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Clemence_A/0/1/0/all/0/1">Alasseur Cl&#xe9;mence</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mikael_J/0/1/0/all/0/1">Joseph Mikael</a></p>
<p>Machine learning algorithms dedicated to financial time series forecasting
have gained a lot of interest. But choosing between several algorithms can be
challenging, as their estimation accuracy may be unstable over time. Online
aggregation of experts combine the forecasts of a finite set of models in a
single approach without making any assumption about the models. In this paper,
a Bernstein Online Aggregation (BOA) procedure is applied to the construction
of long-short strategies built from individual stock return forecasts coming
from different machine learning models. The online mixture of experts leads to
attractive portfolio performances even in environments characterised by
non-stationarity. The aggregation outperforms individual algorithms, offering a
higher portfolio Sharpe Ratio, lower shortfall, with a similar turnover.
Extensions to expert and aggregation specialisations are also proposed to
improve the overall mixture on a family of portfolio evaluation metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.07856">Potential sources of dataset bias complicate investigation of underdiagnosis by machine learning algorithms. (arXiv:2201.07856v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bernhardt_M/0/1/0/all/0/1">M&#xe9;lanie Bernhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1">Charles Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a></p>
<p>An increasing number of reports raise concerns about the risk that machine
learning algorithms could amplify health disparities due to biases embedded in
the training data. Seyyed-Kalantari et al. find that models trained on three
chest X-ray datasets yield disparities in false-positive rates (FPR) across
subgroups on the 'no-finding' label (indicating the absence of disease). The
models consistently yield higher FPR on subgroups known to be historically
underserved, and the study concludes that the models exhibit and potentially
even amplify systematic underdiagnosis. We argue that the experimental setup in
the study is insufficient to study algorithmic underdiagnosis. In the absence
of specific knowledge (or assumptions) about the extent and nature of the
dataset bias, it is difficult to investigate model bias. Importantly, their use
of test data exhibiting the same bias as the training data (due to random
splitting) severely complicates the interpretation of the reported disparities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.00126">Learning Low-Dimensional Nonlinear Structures from High-Dimensional Noisy Data: An Integral Operator Approach. (arXiv:2203.00126v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ding_X/0/1/0/all/0/1">Xiucai Ding</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_R/0/1/0/all/0/1">Rong Ma</a></p>
<p>We propose a kernel-spectral embedding algorithm for learning low-dimensional
nonlinear structures from high-dimensional and noisy observations, where the
datasets are assumed to be sampled from an intrinsically low-dimensional
manifold and corrupted by high-dimensional noise. The algorithm employs an
adaptive bandwidth selection procedure which does not rely on prior knowledge
of the underlying manifold. The obtained low-dimensional embeddings can be
further utilized for downstream purposes such as data visualization, clustering
and prediction. Our method is theoretically justified and practically
interpretable. Specifically, we establish the convergence of the final
embeddings to their noiseless counterparts when the dimension and size of the
samples are comparably large, and characterize the effect of the
signal-to-noise ratio on the rate of convergence and phase transition. We also
prove convergence of the embeddings to the eigenfunctions of an integral
operator defined by the kernel map of some reproducing kernel Hilbert space
capturing the underlying nonlinear structures. Numerical simulations and
analysis of three real datasets show the superior empirical performance of the
proposed method, compared to many existing methods, on learning various
manifolds in diverse applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2204.09269">A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond. (arXiv:2204.09269v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yisheng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lijun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Junliang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juntao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-yan Liu</a></p>
<p>Non-autoregressive (NAR) generation, which is first proposed in neural
machine translation (NMT) to speed up inference, has attracted much attention
in both machine learning and natural language processing communities. While NAR
generation can significantly accelerate inference speed for machine
translation, the speedup comes at the cost of sacrificed translation accuracy
compared to its counterpart, autoregressive (AR) generation. In recent years,
many new models and algorithms have been designed/proposed to bridge the
accuracy gap between NAR generation and AR generation. In this paper, we
conduct a systematic survey with comparisons and discussions of various
non-autoregressive translation (NAT) models from different aspects.
Specifically, we categorize the efforts of NAT into several groups, including
data manipulation, modeling methods, training criterion, decoding algorithms,
and the benefit from pre-trained models. Furthermore, we briefly review other
applications of NAR models beyond machine translation, such as grammatical
error correction, text summarization, text style transfer, dialogue, semantic
parsing, automatic speech recognition, and so on. In addition, we also discuss
potential directions for future exploration, including releasing the dependency
of KD, reasonable training objectives, pre-training for NAR, and wider
applications, etc. We hope this survey can help researchers capture the latest
progress in NAR generation, inspire the design of advanced NAR models and
algorithms, and enable industry practitioners to choose appropriate solutions
for their applications. The web page of this survey is at
\url{https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.03447">Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v7 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaoyan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jimenez_Ruiz_E/0/1/0/all/0/1">Ernesto Jim&#xe9;nez-Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadian_A/0/1/0/all/0/1">Ali Hadian</a>, <a href="http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1">Ian Horrocks</a></p>
<p>Ontology Matching (OM) plays an important role in many domains such as
bioinformatics and the Semantic Web, and its research is becoming increasingly
popular, especially with the application of machine learning (ML) techniques.
Although the Ontology Alignment Evaluation Initiative (OAEI) represents an
impressive effort for the systematic evaluation of OM systems, it still suffers
from several limitations including limited evaluation of subsumption mappings,
suboptimal reference mappings, and limited support for the evaluation of
ML-based systems. To tackle these limitations, we introduce five new biomedical
OM tasks involving ontologies extracted from Mondo and UMLS. Each task includes
both equivalence and subsumption matching; the quality of reference mappings is
ensured by human curation, ontology pruning, etc.; and a comprehensive
evaluation framework is proposed to measure OM performance from various
perspectives for both ML-based and non-ML-based OM systems. We report
evaluation results for OM systems of different types to demonstrate the usage
of these resources, all of which are publicly available as part of the new
BioML track at OAEI 2022.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.13104">Trainable Weight Averaging: A General Approach for Subspace Training. (arXiv:2205.13104v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhehao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Q/0/1/0/all/0/1">Qinghua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yingwen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolin Huang</a></p>
<p>Training deep neural networks (DNNs) in low-dimensional subspaces is a
promising direction for achieving efficient training and better generalization
performance. Previous works extract the subspaces by using random projection or
performing dimensionality reduction method on the training trajectory, but
these methods can be inefficient or unstable in terms of dimensionality and
numerical operations. In this paper, we connect subspace training to weight
averaging and propose Trainable Weight Averaging (TWA), a general approach for
subspace training that generalizes the previous efforts. TWA is efficient in
terms of dimensionality and also easy to use, making it a promising new method
for subspace training. We further design an efficient scheme for subspace
training to cope with large-scale problems, which allows parallel training
across multiple nodes and evenly distributing the memory and computation burden
to each node. We apply TWA to efficient neural network training and improving
fine-tuning performance tasks to demonstrate the great efficiency and
effectiveness of our approach. We conduct extensive experiments that cover
various benchmark computer vision and neural language processing tasks with
various architectures. The code of implementation is available at
https://github.com/nblt/TWA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.04779">Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations. (arXiv:2206.04779v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ball_P/0/1/0/all/0/1">Philip J. Ball</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudner_T/0/1/0/all/0/1">Tim G. J. Rudner</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1">Michael A. Osborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a></p>
<p>Offline reinforcement learning has shown great promise in leveraging large
pre-collected datasets for policy learning, allowing agents to forgo
often-expensive online data collection. However, offline reinforcement learning
from visual observations with continuous action spaces remains under-explored,
with a limited understanding of the key challenges in this complex domain. In
this paper, we establish simple baselines for continuous control in the visual
domain and introduce a suite of benchmarking tasks for offline reinforcement
learning from visual observations designed to better represent the data
distributions present in real-world offline RL problems and guided by a set of
desiderata for offline RL from visual observations, including robustness to
visual distractions and visually identifiable changes in dynamics. Using this
suite of benchmarking tasks, we show that simple modifications to two popular
vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2,
suffice to outperform existing offline RL methods and establish competitive
baselines for continuous control in the visual domain. We rigorously evaluate
these algorithms and perform an empirical evaluation of the differences between
state-of-the-art model-based and model-free offline RL methods for continuous
control from visual observations. All code and data used in this evaluation are
open-sourced to facilitate progress in this domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.08137">An AI tool for automated analysis of large-scale unstructured clinical cine CMR databases. (arXiv:2206.08137v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mariscal_Harana_J/0/1/0/all/0/1">Jorge Mariscal-Harana</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Asher_C/0/1/0/all/0/1">Clint Asher</a> (1,2), <a href="http://arxiv.org/find/eess/1/au:+Vergani_V/0/1/0/all/0/1">Vittoria Vergani</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Rizvi_M/0/1/0/all/0/1">Maleeha Rizvi</a> (1,2), <a href="http://arxiv.org/find/eess/1/au:+Keehn_L/0/1/0/all/0/1">Louise Keehn</a> (3), <a href="http://arxiv.org/find/eess/1/au:+Kim_R/0/1/0/all/0/1">Raymond J. Kim</a> (4), <a href="http://arxiv.org/find/eess/1/au:+Judd_R/0/1/0/all/0/1">Robert M. Judd</a> (4), <a href="http://arxiv.org/find/eess/1/au:+Petersen_S/0/1/0/all/0/1">Steffen E. Petersen</a> (5,6,7,8), <a href="http://arxiv.org/find/eess/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a> (1,2), <a href="http://arxiv.org/find/eess/1/au:+King_A/0/1/0/all/0/1">Andrew King</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Ruijsink_B/0/1/0/all/0/1">Bram Ruijsink</a> (1,2,9), <a href="http://arxiv.org/find/eess/1/au:+Puyol_Anton_E/0/1/0/all/0/1">Esther Puyol-Ant&#xf3;n</a> (1) ((1) School of Biomedical Engineering and Imaging Sciences, King&#x27;s College London, London, UK, (2) Department of Adult and Paediatric Cardiology, Guy&#x27;s and St Thomas&#x27; NHS Foundation Trust, London, UK, (3) Department of Clinical Pharmacology, King&#x27;s College London British Heart Foundation Centre, St Thomas&#x27; Hospital, London, UK, (4) Division of Cardiology, Department of Medicine, Duke University, Durham, North Carolina, USA, (5) National Institute for Health Research (NIHR) Barts Biomedical Research Centre, William Harvey Research Institute, Queen Mary University London, London, UK, (6) Barts Heart Centre, St Bartholomew&#x27;s Hospital, Barts Health NHS Trust, London, UK, (7) Health Data Research UK, London, UK, (8) Alan Turing Institute, London, UK, (9) Department of Cardiology, Heart and Lung Division, University Medical Center Utrecht, Utrecht, The Netherlands)</p>
<p>Artificial intelligence (AI) techniques have been proposed for automating
analysis of short axis (SAX) cine cardiac magnetic resonance (CMR), but no CMR
analysis tool exists to automatically analyse large (unstructured) clinical CMR
datasets. We develop and validate a robust AI tool for start-to-end automatic
quantification of cardiac function from SAX cine CMR in large clinical
databases. Our pipeline for processing and analysing CMR databases includes
automated steps to identify the correct data, robust image pre-processing, an
AI algorithm for biventricular segmentation of SAX CMR and estimation of
functional biomarkers, and automated post-analysis quality control to detect
and correct errors. The segmentation algorithm was trained on 2793 CMR scans
from two NHS hospitals and validated on additional cases from this dataset
(n=414) and five external datasets (n=6888), including scans of patients with a
range of diseases acquired at 12 different centres using CMR scanners from all
major vendors. Median absolute errors in cardiac biomarkers were within the
range of inter-observer variability: &lt;8.4mL (left ventricle volume), &lt;9.2mL
(right ventricle volume), &lt;13.3g (left ventricular mass), and &lt;5.9% (ejection
fraction) across all datasets. Stratification of cases according to phenotypes
of cardiac disease and scanner vendors showed good performance across all
groups. We show that our proposed tool, which combines image pre-processing
steps, a domain-generalisable AI algorithm trained on a large-scale
multi-domain CMR dataset and quality control steps, allows robust analysis of
(clinical or research) databases from multiple centres, vendors, and cardiac
diseases. This enables translation of our tool for use in fully-automated
processing of large multi-centre databases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.13102">Modeling Content Creator Incentives on Algorithm-Curated Platforms. (arXiv:2206.13102v2 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hron_J/0/1/0/all/0/1">Jiri Hron</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauth_K/0/1/0/all/0/1">Karl Krauth</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1">Niki Kilbertus</a>, <a href="http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1">Sarah Dean</a></p>
<p>Content creators compete for user attention. Their reach crucially depends on
algorithmic choices made by developers on online platforms. To maximize
exposure, many creators adapt strategically, as evidenced by examples like the
sprawling search engine optimization industry. This begets competition for the
finite user attention pool. We formalize these dynamics in what we call an
exposure game, a model of incentives induced by algorithms, including modern
factorization and (deep) two-tower architectures. We prove that seemingly
innocuous algorithmic choices, e.g., non-negative vs. unconstrained
factorization, significantly affect the existence and character of (Nash)
equilibria in exposure games. We proffer use of creator behavior models, like
exposure games, for an (ex-ante) pre-deployment audit. Such an audit can
identify misalignment between desirable and incentivized content, and thus
complement post-hoc measures like content filtering and moderation. To this
end, we propose tools for numerically finding equilibria in exposure games, and
illustrate results of an audit on the MovieLens and LastFM datasets. Among
else, we find that the strategically produced content exhibits strong
dependence between algorithmic exploration and content diversity, and between
model expressivity and bias towards gender-based user and creator groups.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.10062">DataPerf: Benchmarks for Data-Centric AI Development. (arXiv:2207.10062v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mazumder_M/0/1/0/all/0/1">Mark Mazumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Banbury_C/0/1/0/all/0/1">Colby Banbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xiaozhe Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1">Bojan Karla&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_W/0/1/0/all/0/1">William Gaviria Rojas</a>, <a href="http://arxiv.org/find/cs/1/au:+Diamos_S/0/1/0/all/0/1">Sudnya Diamos</a>, <a href="http://arxiv.org/find/cs/1/au:+Diamos_G/0/1/0/all/0/1">Greg Diamos</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lynn He</a>, <a href="http://arxiv.org/find/cs/1/au:+Parrish_A/0/1/0/all/0/1">Alicia Parrish</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1">Hannah Rose Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Quaye_J/0/1/0/all/0/1">Jessica Quaye</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_C/0/1/0/all/0/1">Charvi Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurado_D/0/1/0/all/0/1">David Jurado</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanter_D/0/1/0/all/0/1">David Kanter</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosquera_R/0/1/0/all/0/1">Rafael Mosquera</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciro_J/0/1/0/all/0/1">Juan Ciro</a>, <a href="http://arxiv.org/find/cs/1/au:+Aroyo_L/0/1/0/all/0/1">Lora Aroyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Acun_B/0/1/0/all/0/1">Bilge Acun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lingjiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Raje_M/0/1/0/all/0/1">Mehul Smriti Raje</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartolo_M/0/1/0/all/0/1">Max Bartolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Eyuboglu_S/0/1/0/all/0/1">Sabri Eyuboglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghorbani_A/0/1/0/all/0/1">Amirata Ghorbani</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_E/0/1/0/all/0/1">Emmett Goodman</a>, <a href="http://arxiv.org/find/cs/1/au:+Inel_O/0/1/0/all/0/1">Oana Inel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kane_T/0/1/0/all/0/1">Tariq Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirkpatrick_C/0/1/0/all/0/1">Christine R. Kirkpatrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_T/0/1/0/all/0/1">Tzu-Sheng Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1">Jonas Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1">Tristan Thrush</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanschoren_J/0/1/0/all/0/1">Joaquin Vanschoren</a>, <a href="http://arxiv.org/find/cs/1/au:+Warren_M/0/1/0/all/0/1">Margaret Warren</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Adina Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1">Serena Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardalani_N/0/1/0/all/0/1">Newsha Ardalani</a>, <a href="http://arxiv.org/find/cs/1/au:+Paritosh_P/0/1/0/all/0/1">Praveen Paritosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Carole-Jean Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Coleman_C/0/1/0/all/0/1">Cody Coleman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattson_P/0/1/0/all/0/1">Peter Mattson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddi_V/0/1/0/all/0/1">Vijay Janapa Reddi</a></p>
<p>Machine learning research has long focused on models rather than datasets,
and prominent datasets are used for common ML tasks without regard to the
breadth, difficulty, and faithfulness of the underlying problems. Neglecting
the fundamental importance of data has given rise to inaccuracy, bias, and
fragility in real-world applications, and research is hindered by saturation
across existing dataset benchmarks. In response, we present DataPerf, a
community-led benchmark suite for evaluating ML datasets and data-centric
algorithms. We aim to foster innovation in data-centric AI through competition,
comparability, and reproducibility. We enable the ML community to iterate on
datasets, instead of just architectures, and we provide an open, online
platform with multiple rounds of challenges to support this iterative
development. The first iteration of DataPerf contains five benchmarks covering
a wide spectrum of data-centric techniques, tasks, and modalities in vision,
speech, acquisition, debugging, and diffusion prompting, and we support hosting
new contributed benchmarks from the community. The benchmarks, online
evaluation platform, and baseline implementations are open source, and the
MLCommons Association will maintain DataPerf to ensure long-term benefits to
academia and industry.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.11543">Evaluating the Planning and Operational Resilience of Electrical Distribution Systems with Distributed Energy Resources using Complex Network Theory. (arXiv:2208.11543v4 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Dwivedi_D/0/1/0/all/0/1">Divyanshi Dwivedi</a>, <a href="http://arxiv.org/find/eess/1/au:+Yemula_P/0/1/0/all/0/1">Pradeep Kumar Yemula</a>, <a href="http://arxiv.org/find/eess/1/au:+Pal_M/0/1/0/all/0/1">Mayukha Pal</a></p>
<p>Electrical Distribution Systems are extensively penetrated with Distributed
Energy Resources (DERs) to cater the energy demands with the general perception
that it enhances the system's resilience. However, integration of DERs may
adversely affect the grid operation and affect the system resilience due to
various factors like their intermittent availability, dynamics of weather
conditions, non-linearity, complexity, number of malicious threats, and
improved reliability requirements of consumers. This paper proposes a
methodology to evaluate the planning and operational resilience of power
distribution systems under extreme events and determines the withstand
capability of the electrical network. The proposed framework is developed by
effectively employing the complex network theory. Correlated networks for
undesirable configurations are developed from the time series data of active
power monitored at nodes of the electrical network. For these correlated
networks, computed the network parameters such as clustering coefficient,
assortative coefficient, average degree and power law exponent for the
anticipation; and percolation threshold for the determination of the network
withstand capability under extreme conditions. The proposed methodology is also
suitable for identifying the hosting capacity of solar panels in the system
while maintaining resilience under different unfavourable conditions and
identifying the most critical nodes of the system that could drive the system
into non-resilience. This framework is demonstrated on IEEE 123 node test
feeder by generating active power time-series data for a variety of electrical
conditions using simulation software, GridLAB-D. The percolation threshold
resulted as an effective metric for the determination of the planning and
operational resilience of the power distribution system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.05251">Spotting Virus from Satellites: Modeling the Circulation of West Nile Virus Through Graph Neural Networks. (arXiv:2209.05251v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bonicelli_L/0/1/0/all/0/1">Lorenzo Bonicelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Porrello_A/0/1/0/all/0/1">Angelo Porrello</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincenzi_S/0/1/0/all/0/1">Stefano Vincenzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ippoliti_C/0/1/0/all/0/1">Carla Ippoliti</a>, <a href="http://arxiv.org/find/cs/1/au:+Iapaolo_F/0/1/0/all/0/1">Federica Iapaolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Conte_A/0/1/0/all/0/1">Annamaria Conte</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderara_S/0/1/0/all/0/1">Simone Calderara</a></p>
<p>The occurrence of West Nile Virus (WNV) represents one of the most common
mosquito-borne zoonosis viral infections. Its circulation is usually associated
with climatic and environmental conditions suitable for vector proliferation
and virus replication. On top of that, several statistical models have been
developed to shape and forecast WNV circulation: in particular, the recent
massive availability of Earth Observation (EO) data, coupled with the
continuous advances in the field of Artificial Intelligence, offer valuable
opportunities.
</p>
<p>In this paper, we seek to predict WNV circulation by feeding Deep Neural
Networks (DNNs) with satellite images, which have been extensively shown to
hold environmental and climatic features. Notably, while previous approaches
analyze each geographical site independently, we propose a spatial-aware
approach that considers also the characteristics of close sites. Specifically,
we build upon Graph Neural Networks (GNN) to aggregate features from
neighbouring places, and further extend these modules to consider multiple
relations, such as the difference in temperature and soil moisture between two
sites, as well as the geographical distance. Moreover, we inject time-related
information directly into the model to take into account the seasonality of
virus spread.
</p>
<p>We design an experimental setting that combines satellite images - from
Landsat and Sentinel missions - with ground truth observations of WNV
circulation in Italy. We show that our proposed Multi-Adjacency Graph Attention
Network (MAGAT) consistently leads to higher performance when paired with an
appropriate pre-training stage. Finally, we assess the importance of each
component of MAGAT in our ablation studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.03069">PathProx: A Proximal Gradient Algorithm for Weight Decay Regularized Deep Neural Networks. (arXiv:2210.03069v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Liu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenouda_J/0/1/0/all/0/1">Joseph Shenouda</a>, <a href="http://arxiv.org/find/cs/1/au:+Papailiopoulos_D/0/1/0/all/0/1">Dimitris Papailiopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kangwook Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1">Robert D. Nowak</a></p>
<p>Weight decay is one of the most widely used forms of regularization in deep
learning, and has been shown to improve generalization and robustness. The
optimization objective driving weight decay is a sum of losses plus a term
proportional to the sum of squared weights. This paper argues that stochastic
gradient descent (SGD) may be an inefficient algorithm for this objective. For
neural networks with ReLU activations, solutions to the weight decay objective
are equivalent to those of a different objective in which the regularization
term is instead a sum of products of $\ell_2$ (not squared) norms of the input
and output weights associated with each ReLU neuron. This alternative (and
effectively equivalent) regularization suggests a novel proximal gradient
algorithm for network training. Theory and experiments support the new training
approach, showing that it can converge much faster to the sparse solutions it
shares with standard weight decay training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.04371">A Detailed Study of Interpretability of Deep Neural Network based Top Taggers. (arXiv:2210.04371v4 [hep-ex] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ex/1/au:+Khot_A/0/1/0/all/0/1">Ayush Khot</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Neubauer_M/0/1/0/all/0/1">Mark S. Neubauer</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Roy_A/0/1/0/all/0/1">Avik Roy</a></p>
<p>Recent developments in the methods of explainable AI (XAI) allow researchers
to explore the inner workings of deep neural networks (DNNs), revealing crucial
information about input-output relationships and realizing how data connects
with machine learning models. In this paper we explore interpretability of DNN
models designed to identify jets coming from top quark decay in high energy
proton-proton collisions at the Large Hadron Collider (LHC). We review a subset
of existing top tagger models and explore different quantitative methods to
identify which features play the most important roles in identifying the top
jets. We also investigate how and why feature importance varies across
different XAI metrics, how correlations among features impact their
explainability, and how latent space representations encode information as well
as correlate with physically meaningful quantities. Our studies uncover some
major pitfalls of existing XAI methods and illustrate how they can be overcome
to obtain consistent and meaningful interpretation of these models. We
additionally illustrate the activity of hidden layers as Neural Activation
Pattern (NAP) diagrams and demonstrate how they can be used to understand how
DNNs relay information across the layers and how this understanding can help to
make such models significantly simpler by allowing effective model
reoptimization and hyperparameter tuning. These studies not only facilitate a
methodological approach to interpreting models but also unveil new insights
about what these models learn. Incorporating these observations into augmented
model design, we propose the Particle Flow Interaction Network (PFIN) model and
demonstrate how interpretability-inspired model augmentation can improve top
tagging performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.12669">Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks. (arXiv:2210.12669v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shibo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Penwarden_M/0/1/0/all/0/1">Michael Penwarden</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yiming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tillinghast_C/0/1/0/all/0/1">Conor Tillinghast</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayan_A/0/1/0/all/0/1">Akil Narayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirby_R/0/1/0/all/0/1">Robert M. Kirby</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhe_S/0/1/0/all/0/1">Shandian Zhe</a></p>
<p>Physics-informed neural networks (PINNs) are emerging as popular mesh-free
solvers for partial differential equations (PDEs). Recent extensions decompose
the domain, apply different PINNs to solve the problem in each subdomain, and
stitch the subdomains at the interface. Thereby, they can further alleviate the
problem complexity, reduce the computational cost, and allow parallelization.
However, the performance of multi-domain PINNs is sensitive to the choice of
the interface conditions. While quite a few conditions have been proposed,
there is no suggestion about how to select the conditions according to specific
problems. To address this gap, we propose META Learning of Interface Conditions
(METALIC), a simple, efficient yet powerful approach to dynamically determine
appropriate interface conditions for solving a family of parametric PDEs.
Specifically, we develop two contextual multi-arm bandit (MAB) models. The
first one applies to the entire training course, and online updates a Gaussian
process (GP) reward that given the PDE parameters and interface conditions
predicts the performance. We prove a sub-linear regret bound for both UCB and
Thompson sampling, which in theory guarantees the effectiveness of our MAB. The
second one partitions the training into two stages, one is the stochastic phase
and the other deterministic phase; we update a GP reward for each phase to
enable different condition selections at the two stages to further bolster the
flexibility and performance. We have shown the advantage of METALIC on four
bench-mark PDE families.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.13235">Chaos Theory and Adversarial Robustness. (arXiv:2210.13235v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kent_J/0/1/0/all/0/1">Jonathan S. Kent</a></p>
<p>Neural networks, being susceptible to adversarial attacks, should face a
strict level of scrutiny before being deployed in critical or adversarial
applications. This paper uses ideas from Chaos Theory to explain, analyze, and
quantify the degree to which neural networks are susceptible to or robust
against adversarial attacks. To this end, we present a new metric, the
"susceptibility ratio," given by $\hat \Psi(h, \theta)$, which captures how
greatly a model's output will be changed by perturbations to a given input.
</p>
<p>Our results show that susceptibility to attack grows significantly with the
depth of the model, which has safety implications for the design of neural
networks for production environments. We provide experimental evidence of the
relationship between $\hat \Psi$ and the post-attack accuracy of classification
models, as well as a discussion of its application to tasks lacking hard
decision boundaries. We also demonstrate how to quickly and easily approximate
the certified robustness radii for extremely large models, which until now has
been computationally infeasible to calculate directly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.14896">DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (arXiv:2210.14896v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zijie J. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Montoya_E/0/1/0/all/0/1">Evan Montoya</a>, <a href="http://arxiv.org/find/cs/1/au:+Munechika_D/0/1/0/all/0/1">David Munechika</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haoyang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoover_B/0/1/0/all/0/1">Benjamin Hoover</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1">Duen Horng Chau</a></p>
<p>With recent advancements in diffusion models, users can generate high-quality
images by writing text prompts in natural language. However, generating images
with desired details requires proper prompts, and it is often unclear how a
model reacts to different prompts or what the best prompts are. To help
researchers tackle these critical challenges, we introduce DiffusionDB, the
first large-scale text-to-image prompt dataset totaling 6.5TB, containing 14
million images generated by Stable Diffusion, 1.8 million unique prompts, and
hyperparameters specified by real users. We analyze the syntactic and semantic
characteristics of prompts. We pinpoint specific hyperparameter values and
prompt styles that can lead to model errors and present evidence of potentially
harmful model usage, such as the generation of misinformation. The
unprecedented scale and diversity of this human-actuated dataset provide
exciting research opportunities in understanding the interplay between prompts
and generative models, detecting deepfakes, and designing human-AI interaction
tools to help users more easily use these models. DiffusionDB is publicly
available at: https://poloclub.github.io/diffusiondb.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.09721">A Finite-Particle Convergence Rate for Stein Variational Gradient Descent. (arXiv:2211.09721v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiaxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a></p>
<p>We provide the first finite-particle convergence rate for Stein variational
gradient descent (SVGD), a popular algorithm for approximating a probability
distribution with a collection of particles. Specifically, whenever the target
distribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and
an appropriate step size sequence drives the kernel Stein discrepancy to zero
at an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be
improved, and we hope that our explicit, non-asymptotic proof strategy will
serve as a template for future refinements.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.12386">A Recursively Recurrent Neural Network (R2N2) Architecture for Learning Iterative Algorithms. (arXiv:2211.12386v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Doncevic_D/0/1/0/all/0/1">Danimir T. Doncevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsos_A/0/1/0/all/0/1">Alexander Mitsos</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yue Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qianxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dietrich_F/0/1/0/all/0/1">Felix Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahmen_M/0/1/0/all/0/1">Manuel Dahmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kevrekidis_I/0/1/0/all/0/1">Ioannis G. Kevrekidis</a></p>
<p>Meta-learning of numerical algorithms for a given task consists of the
data-driven identification and adaptation of an algorithmic structure and the
associated hyperparameters. To limit the complexity of the meta-learning
problem, neural architectures with a certain inductive bias towards favorable
algorithmic structures can, and should, be used. We generalize our previously
introduced Runge-Kutta neural network to a recursively recurrent neural network
(R2N2) superstructure for the design of customized iterative algorithms. In
contrast to off-the-shelf deep learning approaches, it features a distinct
division into modules for generation of information and for the subsequent
assembly of this information towards a solution. Local information in the form
of a subspace is generated by subordinate, inner, iterations of recurrent
function evaluations starting at the current outer iterate. The update to the
next outer iterate is computed as a linear combination of these evaluations,
reducing the residual in this space, and constitutes the output of the network.
We demonstrate that regular training of the weight parameters inside the
proposed superstructure on input/output data of various computational problem
classes yields iterations similar to Krylov solvers for linear equation
systems, Newton-Krylov solvers for nonlinear equation systems, and Runge-Kutta
integrators for ordinary differential equations. Due to its modularity, the
superstructure can be readily extended with functionalities needed to represent
more general classes of iterative algorithms traditionally based on Taylor
series expansions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09811">Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model. (arXiv:2212.09811v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koishekenov_Y/0/1/0/all/0/1">Yeskendir Koishekenov</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1">Vassilina Nikoulina</a>, <a href="http://arxiv.org/find/cs/1/au:+Berard_A/0/1/0/all/0/1">Alexandre Berard</a></p>
<p>Compared to conventional bilingual translation systems, massively
multilingual machine translation is appealing because a single model can
translate into multiple languages and benefit from knowledge transfer for low
resource languages. On the other hand, massively multilingual models suffer
from the curse of multilinguality, unless scaling their size massively, which
increases their training and inference costs. Sparse Mixture-of-Experts models
are a way to drastically increase model capacity without the need for a
proportional amount of computing. The recently released NLLB-200 is an example
of such a model. It covers 202 languages but requires at least four 32GB GPUs
just for inference. In this work, we propose a pruning method that allows the
removal of up to 80\% of experts with a negligible loss in translation quality,
which makes it feasible to run the model on a single 32GB GPU. Further analysis
suggests that our pruning metrics allow to identify language-specific experts
and prune non-relevant experts for a given language pair.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.01054">Benchmarking common uncertainty estimation methods with histopathological images under domain shift and label noise. (arXiv:2301.01054v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mehrtens_H/0/1/0/all/0/1">Hendrik A. Mehrtens</a>, <a href="http://arxiv.org/find/eess/1/au:+Kurz_A/0/1/0/all/0/1">Alexander Kurz</a>, <a href="http://arxiv.org/find/eess/1/au:+Bucher_T/0/1/0/all/0/1">Tabea-Clara Bucher</a>, <a href="http://arxiv.org/find/eess/1/au:+Brinker_T/0/1/0/all/0/1">Titus J. Brinker</a></p>
<p>In the past years, deep learning has seen an increase in usage in the domain
of histopathological applications. However, while these approaches have shown
great potential, in high-risk environments deep learning models need to be able
to judge their uncertainty and be able to reject inputs when there is a
significant chance of misclassification. In this work, we conduct a rigorous
evaluation of the most commonly used uncertainty and robustness methods for the
classification of Whole Slide Images, with a focus on the task of selective
classification, where the model should reject the classification in situations
in which it is uncertain. We conduct our experiments on tile-level under the
aspects of domain shift and label noise, as well as on slide-level. In our
experiments, we compare Deep Ensembles, Monte-Carlo Dropout, Stochastic
Variational Inference, Test-Time Data Augmentation as well as ensembles of the
latter approaches. We observe that ensembles of methods generally lead to
better uncertainty estimates as well as an increased robustness towards domain
shifts and label noise, while contrary to results from classical computer
vision benchmarks no systematic gain of the other methods can be shown. Across
methods, a rejection of the most uncertain samples reliably leads to a
significant increase in classification accuracy on both in-distribution as well
as out-of-distribution data. Furthermore, we conduct experiments comparing
these methods under varying conditions of label noise. Lastly, we publish our
code framework to facilitate further research on uncertainty estimation on
histopathological data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.12313">Adapting Neural Link Predictors for Complex Query Answering. (arXiv:2301.12313v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arakelyan_E/0/1/0/all/0/1">Erik Arakelyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1">Pasquale Minervini</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a></p>
<p>Answering complex queries on incomplete knowledge graphs is a challenging
task where a model needs to answer complex logical queries in the presence of
missing knowledge. Recently, Arakelyan et al. (2021); Minervini et al. (2022)
showed that neural link predictors could also be used for answering complex
queries: their Continuous Query Decomposition (CQD) method works by decomposing
complex queries into atomic sub-queries, answers them using neural link
predictors and aggregates their scores via t-norms for ranking the answers to
each complex query. However, CQD does not handle negations and only uses the
training signal from atomic training queries: neural link prediction scores are
not calibrated to interact together via fuzzy logic t-norms during complex
query answering. In this work, we propose to address this problem by training a
parameter-efficient score adaptation model to re-calibrate neural link
prediction scores: this new component is trained on complex queries by
back-propagating through the complex query-answering process. Our method,
CQD$^{A}$, produces significantly more accurate results than current
state-of-the-art methods, improving from $34.4$ to $35.1$ Mean Reciprocal Rank
values averaged across all datasets and query types while using $\leq 35\%$ of
the available training query types. We further show that CQD$^{A}$ is
data-efficient, achieving competitive results with only $1\%$ of the training
data, and robust in out-of-domain evaluations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.13166">ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation. (arXiv:2301.13166v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiwen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kaizhi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1">Connor Pryor</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yilin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hongxia Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1">Lise Getoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Eric Wang</a></p>
<p>The ability to accurately locate and navigate to a specific object is a
crucial capability for embodied agents that operate in the real world and
interact with objects to complete tasks. Such object navigation tasks usually
require large-scale training in visual environments with labeled objects, which
generalizes poorly to novel objects in unknown environments. In this work, we
present a novel zero-shot object navigation method, Exploration with Soft
Commonsense constraints (ESC), that transfers commonsense knowledge in
pre-trained models to open-world object navigation without any navigation
experience nor any other training on the visual environments. First, ESC
leverages a pre-trained vision and language model for open-world prompt-based
grounding and a pre-trained commonsense language model for room and object
reasoning. Then ESC converts commonsense knowledge into navigation actions by
modeling it as soft logic predicates for efficient exploration. Extensive
experiments on MP3D, HM3D, and RoboTHOR benchmarks show that our ESC method
improves significantly over baselines, and achieves new state-of-the-art
results for zero-shot object navigation (e.g., 288% relative Success Rate
improvement than CoW on MP3D).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00736">Approximating the Shapley Value without Marginal Contributions. (arXiv:2302.00736v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kolpaczki_P/0/1/0/all/0/1">Patrick Kolpaczki</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengs_V/0/1/0/all/0/1">Viktor Bengs</a>, <a href="http://arxiv.org/find/cs/1/au:+Muschalik_M/0/1/0/all/0/1">Maximilian Muschalik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a></p>
<p>The Shapley value is arguably the most popular approach for assigning a
meaningful contribution value to players in a cooperative game, which has
recently been used intensively in explainable artificial intelligence. The
meaningfulness is due to axiomatic properties that only the Shapley value
satisfies, which, however, comes at the expense of an exact computation growing
exponentially with the number of agents. Accordingly, a number of works are
devoted to the efficient approximation of the Shapley values, most of them
revolve around the notion of an agent's marginal contribution. In this paper,
we propose with SVARM and Stratified SVARM two parameter-free and
domain-independent approximation algorithms based on a representation of the
Shapley value detached from the notion of marginal contributions. We prove
unmatched theoretical guarantees regarding their approximation quality and
provide empirical results including synthetic games as well as common
explainability use cases comparing ourselves with state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06529">Unleashing the Power of Electrocardiograms: A novel approach for Patient Identification in Healthcare Systems with ECG Signals. (arXiv:2302.06529v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fuster_Barcelo_C/0/1/0/all/0/1">Caterina Fuster-Barcel&#xf3;</a>, <a href="http://arxiv.org/find/cs/1/au:+Camara_C/0/1/0/all/0/1">Carmen C&#xe1;mara</a>, <a href="http://arxiv.org/find/cs/1/au:+Peris_Lopez_P/0/1/0/all/0/1">Pedro Peris-L&#xf3;pez</a></p>
<p>Over the course of the past two decades, a substantial body of research has
substantiated the viability of utilising cardiac signals as a biometric
modality. This paper presents a novel approach for patient identification in
healthcare systems using electrocardiogram signals. A convolutional neural
network is used to classify users based on images extracted from ECG signals.
The proposed identification system is evaluated in multiple databases,
providing a comprehensive understanding of its potential in real-world
scenarios. The impact of Cardiovascular Diseases on generic user identification
has been largely overlooked in previous studies. The presented method takes
into account the cardiovascular condition of the patients, ensuring that the
results obtained are not biased or limited. Furthermore, the results obtained
are consistent and reliable, with lower error rates and higher accuracy
metrics, as demonstrated through extensive experimentation. All these features
make the proposed method a valuable contribution to the field of patient
identification in healthcare systems, and make it a strong contender for
practical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.07729">Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings. (arXiv:2302.07729v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rehman_T/0/1/0/all/0/1">Tohida Rehman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanyal_D/0/1/0/all/0/1">Debarshi Kumar Sanyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1">Samiran Chattopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhowmick_P/0/1/0/all/0/1">Plaban Kumar Bhowmick</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1">Partha Pratim Das</a></p>
<p>Nowadays many research articles are prefaced with research highlights to
summarize the main findings of the paper. Highlights not only help researchers
precisely and quickly identify the contributions of a paper, they also enhance
the discoverability of the article via search engines. We aim to automatically
construct research highlights given certain segments of a research paper. We
use a pointer-generator network with coverage mechanism and a contextual
embedding layer at the input that encodes the input tokens into SciBERT
embeddings. We test our model on a benchmark dataset, CSPubSum, and also
present MixSub, a new multi-disciplinary corpus of papers for automatic
research highlight generation. For both CSPubSum and MixSub, we have observed
that the proposed model achieves the best performance compared to related
variants and other models proposed in the literature. On the CSPubSum dataset,
our model achieves the best performance when the input is only the abstract of
a paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2
and ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of
32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the
new MixSub dataset, where only the abstract is the input, our proposed model
(when trained on the whole training corpus without distinguishing between the
subject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,
9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02118">Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression. (arXiv:2303.02118v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Arpino_G/0/1/0/all/0/1">Gabriel Arpino</a>, <a href="http://arxiv.org/find/stat/1/au:+Venkataramanan_R/0/1/0/all/0/1">Ramji Venkataramanan</a></p>
<p>We consider the problem of mixed sparse linear regression with two
components, where two real $k$-sparse signals $\beta_1, \beta_2$ are to be
recovered from $n$ unlabelled noisy linear measurements. The sparsity is
allowed to be sublinear in the dimension, and additive noise is assumed to be
independent Gaussian with variance $\sigma^2$. Prior work has shown that the
problem suffers from a $\frac{k}{SNR^2}$-to-$\frac{k^2}{SNR^2}$
statistical-to-computational gap, resembling other computationally challenging
high-dimensional inference problems such as Sparse PCA and Robust Sparse Mean
Estimation; here $SNR$ is the signal-to-noise ratio. We establish the existence
of a more extensive computational barrier for this problem through the method
of low-degree polynomials, but show that the problem is computationally hard
only in a very narrow symmetric parameter regime. We identify a smooth
information-computation tradeoff between the sample complexity $n$ and runtime
for any randomized algorithm in this hard regime. Via a simple reduction, this
provides novel rigorous evidence for the existence of a computational barrier
to solving exact support recovery in sparse phase retrieval with sample
complexity $n = \tilde{o}(k^2)$. Our second contribution is to analyze a simple
thresholding algorithm which, outside of the narrow regime where the problem is
hard, solves the associated mixed regression detection problem in $O(np)$ time
with square-root the number of samples and matches the sample complexity
required for (non-mixed) sparse linear regression; this allows the recovery
problem to be subsequently solved by state-of-the-art techniques from the dense
case. As a special case of our results, we show that this simple algorithm is
order-optimal among a large family of algorithms in solving exact signed
support recovery in sparse linear regression.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02216">Denoise Pretraining on Nonequilibrium Molecules for Accurate and Transferable Neural Potentials. (arXiv:2303.02216v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Changwen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zijie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1">Amir Barati Farimani</a></p>
<p>Recent advances in equivariant graph neural networks (GNNs) have made deep
learning amenable to developing fast surrogate models to expensive ab initio
quantum mechanics (QM) approaches for molecular potential predictions. However,
building accurate and transferable potential models using GNNs remains
challenging, as the data is greatly limited by the expensive computational
costs and level of theory of QM methods, especially for large and complex
molecular systems. In this work, we propose denoise pretraining on
nonequilibrium molecular conformations to achieve more accurate and
transferable GNN potential predictions. Specifically, atomic coordinates of
sampled nonequilibrium conformations are perturbed by random noises and GNNs
are pretrained to denoise the perturbed molecular conformations which recovers
the original coordinates. Rigorous experiments on multiple benchmarks reveal
that pretraining significantly improves the accuracy of neural potentials.
Furthermore, we show that the proposed pretraining approach is model-agnostic,
as it improves the performance of different invariant and equivariant GNNs.
Notably, our models pretrained on small molecules demonstrate remarkable
transferability, improving performance when fine-tuned on diverse molecular
systems, including different elements, charged molecules, biomolecules, and
larger systems. These results highlight the potential for leveraging denoise
pretraining approaches to build more generalizable neural potentials for
complex molecular systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.03108">Gradient Norm Aware Minimization Seeks First-Order Flatness and Improves Generalization. (arXiv:2303.03108v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xingxuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Renzhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1">Hao Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1">Peng Cui</a></p>
<p>Recently, flat minima are proven to be effective for improving generalization
and sharpness-aware minimization (SAM) achieves state-of-the-art performance.
Yet the current definition of flatness discussed in SAM and its follow-ups are
limited to the zeroth-order flatness (i.e., the worst-case loss within a
perturbation radius). We show that the zeroth-order flatness can be
insufficient to discriminate minima with low generalization error from those
with high generalization error both when there is a single minimum or multiple
minima within the given perturbation radius. Thus we present first-order
flatness, a stronger measure of flatness focusing on the maximal gradient norm
within a perturbation radius which bounds both the maximal eigenvalue of
Hessian at local minima and the regularization function of SAM. We also present
a novel training procedure named Gradient norm Aware Minimization (GAM) to seek
minima with uniformly small curvature across all directions. Experimental
results show that GAM improves the generalization of models trained with
current optimizers such as SGD and AdamW on various datasets and networks.
Furthermore, we show that GAM can help SAM find flatter minima and achieve
better generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.03789">Fast and Multi-aspect Mining of Complex Time-stamped Event Streams. (arXiv:2303.03789v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nakamura_K/0/1/0/all/0/1">Kota Nakamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1">Yasuko Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawabata_K/0/1/0/all/0/1">Koki Kawabata</a>, <a href="http://arxiv.org/find/cs/1/au:+Umeda_Y/0/1/0/all/0/1">Yuhei Umeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Wada_Y/0/1/0/all/0/1">Yuichiro Wada</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakurai_Y/0/1/0/all/0/1">Yasushi Sakurai</a></p>
<p>Given a huge, online stream of time-evolving events with multiple attributes,
such as online shopping logs: (item, price, brand, time), and local mobility
activities: (pick-up and drop-off locations, time), how can we summarize large,
dynamic high-order tensor streams? How can we see any hidden patterns, rules,
and anomalies? Our answer is to focus on two types of patterns, i.e.,
''regimes'' and ''components'', for which we present CubeScope, an efficient
and effective method over high-order tensor streams. Specifically, it
identifies any sudden discontinuity and recognizes distinct dynamical patterns,
''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also
performs multi-way summarization for all attributes (e.g., item, price, brand,
and time) and discovers hidden ''components'' representing latent groups (e.g.,
item/brand groups) and their relationship. Thanks to its concise but effective
summarization, CubeScope can also detect the sudden appearance of anomalies and
identify the types of anomalies that occur in practice. Our proposed method has
the following properties: (a) Effective: it captures dynamical multi-aspect
patterns, i.e., regimes and components, and statistically summarizes all the
events; (b) General: it is practical for successful application to data
compression, pattern discovery, and anomaly detection on various types of
tensor streams; (c) Scalable: our algorithm does not depend on the length of
the data stream and its dimensionality. Extensive experiments on real datasets
demonstrate that CubeScope finds meaningful patterns and anomalies correctly,
and consistently outperforms the state-of-the-art methods as regards accuracy
and execution speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10135">Efficient and Feasible Robotic Assembly Sequence Planning via Graph Representation Learning. (arXiv:2303.10135v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Atad_M/0/1/0/all/0/1">Matan Atad</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianxiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_I/0/1/0/all/0/1">Ismael Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Durner_M/0/1/0/all/0/1">Maximilian Durner</a>, <a href="http://arxiv.org/find/cs/1/au:+Triebel_R/0/1/0/all/0/1">Rudolph Triebel</a></p>
<p>Automatic Robotic Assembly Sequence Planning (RASP) can significantly improve
productivity and resilience in modern manufacturing along with the growing need
for greater product customization. One of the main challenges in realizing such
automation resides in efficiently finding solutions from a growing number of
potential sequences for increasingly complex assemblies. Besides, costly
feasibility checks are always required for the robotic system. To address this,
we propose a holistic graphical approach including a graph representation
called Assembly Graph for product assemblies and a policy architecture, Graph
Assembly Processing Network, dubbed GRACE for assembly sequence generation.
Secondly, we use GRACE to extract meaningful information from the graph input
and predict assembly sequences in a step-by-step manner. In experiments, we
show that our approach can predict feasible assembly sequences across product
variants of aluminum profiles based on data collected in simulation of a
dual-armed robotic system. We further demonstrate that our method is capable of
detecting infeasible assemblies, substantially alleviating the undesirable
impacts from false predictions, and hence facilitating real-world deployment
soon. Code and training data are available at https://github.com/DLR-RM/GRACE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.11473">Sandwiched Video Compression: Efficiently Extending the Reach of Standard Codecs with Neural Wrappers. (arXiv:2303.11473v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Isik_B/0/1/0/all/0/1">Berivan Isik</a>, <a href="http://arxiv.org/find/eess/1/au:+Guleryuz_O/0/1/0/all/0/1">Onur G. Guleryuz</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_D/0/1/0/all/0/1">Danhang Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Taylor_J/0/1/0/all/0/1">Jonathan Taylor</a>, <a href="http://arxiv.org/find/eess/1/au:+Chou_P/0/1/0/all/0/1">Philip A. Chou</a></p>
<p>We propose sandwiched video compression -- a video compression system that
wraps neural networks around a standard video codec. The sandwich framework
consists of a neural pre- and post-processor with a standard video codec
between them. The networks are trained jointly to optimize a rate-distortion
loss function with the goal of significantly improving over the standard codec
in various compression scenarios. End-to-end training in this setting requires
a differentiable proxy for the standard video codec, which incorporates
temporal processing with motion compensation, inter/intra mode decisions, and
in-loop filtering. We propose differentiable approximations to key video codec
components and demonstrate that, in addition to providing meaningful
compression improvements over the standard codec, the neural codes of the
sandwich lead to significantly better rate-distortion performance in two
important scenarios.When transporting high-resolution video via low-resolution
HEVC, the sandwich system obtains 6.5 dB improvements over standard HEVC. More
importantly, using the well-known perceptual similarity metric, LPIPS, we
observe 30% improvements in rate at the same quality over HEVC. Last but not
least, we show that pre- and post-processors formed by very
modestly-parameterized, light-weight networks can closely approximate these
results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.01502">SLPerf: a Unified Framework for Benchmarking Split Learning. (arXiv:2304.01502v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianchen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhanyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bingzhe Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cen Chen</a></p>
<p>Data privacy concerns has made centralized training of data, which is
scattered across silos, infeasible, leading to the need for collaborative
learning frameworks. To address that, two prominent frameworks emerged, i.e.,
federated learning (FL) and split learning (SL). While FL has established
various benchmark frameworks and research libraries,SL currently lacks a
unified library despite its diversity in terms of label sharing, model
aggregation, and cut layer choice. This lack of standardization makes comparing
SL paradigms difficult. To address this, we propose SLPerf, a unified research
framework and open research library for SL, and conduct extensive experiments
on four widely-used datasets under both IID and Non-IID data settings. Our
contributions include a comprehensive survey of recently proposed SL paradigms,
a detailed benchmark comparison of different SL paradigms in different
situations, and rich engineering take-away messages and research insights for
improving SL paradigms. SLPerf can facilitate SL algorithm development and fair
performance comparisons. The code is available at
https://github.com/Rainysponge/Split-learning-Attacks .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.05463">An Automatic Guidance and Quality Assessment System for Doppler Imaging of Umbilical Artery. (arXiv:2304.05463v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wong_C/0/1/0/all/0/1">Chun Kit Wong</a>, <a href="http://arxiv.org/find/eess/1/au:+Lin_M/0/1/0/all/0/1">Manxi Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Raheli_A/0/1/0/all/0/1">Alberto Raheli</a>, <a href="http://arxiv.org/find/eess/1/au:+Bashir_Z/0/1/0/all/0/1">Zahra Bashir</a>, <a href="http://arxiv.org/find/eess/1/au:+Svendsen_M/0/1/0/all/0/1">Morten Bo S&#xf8;ndergaard Svendsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Tolsgaard_M/0/1/0/all/0/1">Martin Gr&#xf8;nneb&#xe6;k Tolsgaard</a>, <a href="http://arxiv.org/find/eess/1/au:+Feragen_A/0/1/0/all/0/1">Aasa Feragen</a>, <a href="http://arxiv.org/find/eess/1/au:+Christensen_A/0/1/0/all/0/1">Anders Nymark Christensen</a></p>
<p>Examination of the umbilical artery with Doppler ultrasonography is performed
to investigate blood supply to the fetus through the umbilical cord, which is
vital for the monitoring of fetal health. Such examination involves several
steps that must be performed correctly: identifying suitable sites on the
umbilical artery for the measurement, acquiring the blood flow curve in the
form of a Doppler spectrum, and ensuring compliance to a set of quality
standards. These steps rely heavily on the operator's skill, and the shortage
of experienced sonographers has thus created a demand for machine assistance.
In this work, we propose an automatic system to fill the gap. By using a
modified Faster R-CNN network, we obtain an algorithm that can suggest
locations suitable for Doppler measurement. Meanwhile, we have also developed a
method for assessment of the Doppler spectrum's quality. The proposed system is
validated on 657 images from a national ultrasound screening database, with
results demonstrating its potential as a guidance system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.13242">Learning to Predict Navigational Patterns from Partial Observations. (arXiv:2304.13242v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1">Robin Karlsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Carballo_A/0/1/0/all/0/1">Alexander Carballo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepe_Salazar_F/0/1/0/all/0/1">Francisco Lepe-Salazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1">Keisuke Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohtani_K/0/1/0/all/0/1">Kento Ohtani</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1">Kazuya Takeda</a></p>
<p>Human beings cooperatively navigate rule-constrained environments by adhering
to mutually known navigational patterns, which may be represented as
directional pathways or road lanes. Inferring these navigational patterns from
incompletely observed environments is required for intelligent mobile robots
operating in unmapped locations. However, algorithmically defining these
navigational patterns is nontrivial. This paper presents the first
self-supervised learning (SSL) method for learning to infer navigational
patterns in real-world environments from partial observations only. We explain
how geometric data augmentation, predictive world modeling, and an
information-theoretic regularizer enables our model to predict an unbiased
local directional soft lane probability (DSLP) field in the limit of infinite
data. We demonstrate how to infer global navigational patterns by fitting a
maximum likelihood graph to the DSLP field. Experiments show that our SSL model
outperforms two SOTA supervised lane graph prediction models on the nuScenes
dataset. We propose our SSL method as a scalable and interpretable continual
learning paradigm for navigation by perception. Code is available at
https://github.com/robin-karlsson0/dslp.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.13407">FedVS: Straggler-Resilient and Privacy-Preserving Vertical Federated Learning for Split Models. (arXiv:2304.13407v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Songze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_D/0/1/0/all/0/1">Duanyi Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jin Liu</a></p>
<p>In a vertical federated learning (VFL) system consisting of a central server
and many distributed clients, the training data are vertically partitioned such
that different features are privately stored on different clients. The problem
of split VFL is to train a model split between the server and the clients. This
paper aims to address two major challenges in split VFL: 1) performance
degradation due to straggling clients during training; and 2) data and model
privacy leakage from clients' uploaded data embeddings. We propose FedVS to
simultaneously address these two challenges. The key idea of FedVS is to design
secret sharing schemes for the local data and models, such that
information-theoretical privacy against colluding clients and curious server is
guaranteed, and the aggregation of all clients' embeddings is reconstructed
losslessly, via decrypting computation shares from the non-straggling clients.
Extensive experiments on various types of VFL datasets (including tabular, CV,
and multi-view) demonstrate the universal advantages of FedVS in straggler
mitigation and privacy protection over baseline protocols.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05677">Effects of data time lag in a decision-making system using machine learning for pork price prediction. (arXiv:2305.05677v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Suaza_Medina_M/0/1/0/all/0/1">Mario Suaza-Medina</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarazaga_Soria_F/0/1/0/all/0/1">F. Javier Zarazaga-Soria</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinilla_Lopez_J/0/1/0/all/0/1">Jorge Pinilla-Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Pellicer_F/0/1/0/all/0/1">Francisco J. L&#xf3;pez-Pellicer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacasta_J/0/1/0/all/0/1">Javier Lacasta</a></p>
<p>Spain is the third-largest producer of pork meat in the world, and many farms
in several regions depend on the evolution of this market. However, the current
pricing system is unfair, as some actors have better market information than
others. In this context, historical pricing is an easy-to-find and affordable
data source that can help all agents to be better informed. However, the time
lag in data acquisition can affect their pricing decisions. In this paper, we
study the effect that data acquisition delay has on a price prediction system
using multiple prediction algorithms. We describe the integration of the best
proposal into a decision support system prototype and test it in a real-case
scenario. Specifically, we use public data from the most important regional
pork meat markets in Spain published by the Ministry of Agriculture with a
two-week delay and subscription-based data of the same markets obtained on the
same day. The results show that the error difference between the best public
and data subscription models is 0.6 Euro cents in favor of the data without
delay. The market dimension makes these differences significant in the supply
chain, giving pricing agents a better tool to negotiate market prices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.07719">Intercomparison of Brown Dwarf Model Grids and Atmospheric Retrieval Using Machine Learning. (arXiv:2305.07719v2 [astro-ph.SR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Lueber_A/0/1/0/all/0/1">Anna Lueber</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Kitzmann_D/0/1/0/all/0/1">Daniel Kitzmann</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Fisher_C/0/1/0/all/0/1">Chloe E. Fisher</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bowler_B/0/1/0/all/0/1">Brendan P. Bowler</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Burgasser_A/0/1/0/all/0/1">Adam J. Burgasser</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Marley_M/0/1/0/all/0/1">Mark Marley</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Heng_K/0/1/0/all/0/1">Kevin Heng</a></p>
<p>Understanding differences between sub-stellar spectral data and models has
proven to be a major challenge, especially for self-consistent model grids that
are necessary for a thorough investigation of brown dwarf atmospheres. Using
the supervised machine learning method of the random forest, we study the
information content of 14 previously published model grids of brown dwarfs
(from 1997 to 2021). The random forest method allows us to analyze the
predictive power of these model grids, as well as interpret data within the
framework of Approximate Bayesian Computation (ABC). Our curated dataset
includes 3 benchmark brown dwarfs (Gl 570D, {\epsilon} Indi Ba and Bb) as well
as a sample of 19 L and T dwarfs; this sample was previously analyzed in Lueber
et al. (2022) using traditional Bayesian methods (nested sampling). We find
that the effective temperature of a brown dwarf can be robustly predicted
independent of the model grid chosen for the interpretation. However, inference
of the surface gravity is model-dependent. Specifically, the BT-Settl, Sonora
Bobcat and Sonora Cholla model grids tend to predict logg ~3-4 (cgs units) even
after data blueward of 1.2 {\mu}m have been disregarded to mitigate for our
incomplete knowledge of the shapes of alkali lines. Two major, longstanding
challenges associated with understanding the influence of clouds in brown dwarf
atmospheres remain: our inability to model them from first principles and also
to robustly validate these models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.10424">ZeroFlow: Fast Zero Label Scene Flow via Distillation. (arXiv:2305.10424v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1">Kyle Vedder</a>, <a href="http://arxiv.org/find/cs/1/au:+Peri_N/0/1/0/all/0/1">Neehar Peri</a>, <a href="http://arxiv.org/find/cs/1/au:+Chodosh_N/0/1/0/all/0/1">Nathaniel Chodosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Khatri_I/0/1/0/all/0/1">Ishan Khatri</a>, <a href="http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1">Eric Eaton</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1">Dinesh Jayaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hays_J/0/1/0/all/0/1">James Hays</a></p>
<p>Scene flow estimation is the task of describing the 3D motion field between
temporally successive point clouds. State-of-the-art methods use strong priors
and test-time optimization techniques, but require on the order of tens of
seconds for large-scale point clouds, making them unusable as computer vision
primitives for real-time applications such as open world object detection. Feed
forward methods are considerably faster, running on the order of tens to
hundreds of milliseconds for large-scale point clouds, but require expensive
human supervision. To address both limitations, we propose Scene Flow via
Distillation, a simple distillation framework that uses a label-free
optimization method to produce pseudo-labels to supervise a feed forward model.
Our instantiation of this framework, ZeroFlow, produces scene flow estimates in
real-time on large-scale point clouds at quality competitive with
state-of-the-art methods while using zero human labels. Notably, at test-time
ZeroFlow is over 1000$\times$ faster than label-free state-of-the-art
optimization-based methods on large-scale point clouds and over 1000$\times$
cheaper to train on unlabeled data compared to the cost of human annotation of
that data. To facilitate research reuse, we release our code, trained model
weights, and high quality pseudo-labels for the Argoverse 2 and Waymo Open
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.10457">Time Series Clustering With Random Convolutional Kernels. (arXiv:2305.10457v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marco_Blanco_J/0/1/0/all/0/1">Jorge Marco-Blanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuevas_R/0/1/0/all/0/1">Rub&#xe9;n Cuevas</a></p>
<p>Time series data, spanning applications ranging from climatology to finance
to healthcare, presents significant challenges in data mining due to its size
and complexity. One open issue lies in time series clustering, which is crucial
for processing large volumes of unlabeled time series data and unlocking
valuable insights. Traditional and modern analysis methods, however, often
struggle with these complexities. To address these limitations, we introduce
R-Clustering, a novel method that utilizes convolutional architectures with
randomly selected parameters. Through extensive evaluations, R-Clustering
demonstrates superior performance over existing methods in terms of clustering
accuracy, computational efficiency and scalability. Empirical results obtained
using the UCR archive demonstrate the effectiveness of our approach across
diverse time series datasets. The findings highlight the significance of
R-Clustering in various domains and applications, contributing to the
advancement of time series data mining.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13664">Layer-wise Adaptive Step-Sizes for Stochastic First-Order Methods for Deep Learning. (arXiv:2305.13664v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bahamou_A/0/1/0/all/0/1">Achraf Bahamou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1">Donald Goldfarb</a></p>
<p>We propose a new per-layer adaptive step-size procedure for stochastic
first-order optimization methods for minimizing empirical loss functions in
deep learning, eliminating the need for the user to tune the learning rate
(LR). The proposed approach exploits the layer-wise stochastic curvature
information contained in the diagonal blocks of the Hessian in deep neural
networks (DNNs) to compute adaptive step-sizes (i.e., LRs) for each layer. The
method has memory requirements that are comparable to those of first-order
methods, while its per-iteration time complexity is only increased by an amount
that is roughly equivalent to an additional gradient computation. Numerical
experiments show that SGD with momentum and AdamW combined with the proposed
per-layer step-sizes are able to choose effective LR schedules and outperform
fine-tuned LR versions of these methods as well as popular first-order and
second-order algorithms for training DNNs on Autoencoder, Convolutional Neural
Network (CNN) and Graph Convolutional Network (GCN) models. Finally, it is
proved that an idealized version of SGD with the layer-wise step sizes
converges linearly when using full-batch gradients.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.17251">Duality in Multi-View Restricted Kernel Machines. (arXiv:2305.17251v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Achten_S/0/1/0/all/0/1">Sonny Achten</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Arun Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Meulemeester_H/0/1/0/all/0/1">Hannes De Meulemeester</a>, <a href="http://arxiv.org/find/cs/1/au:+Moor_B/0/1/0/all/0/1">Bart De Moor</a>, <a href="http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1">Johan A. K. Suykens</a></p>
<p>We propose a unifying setting that combines existing restricted kernel
machine methods into a single primal-dual multi-view framework for kernel
principal component analysis in both supervised and unsupervised settings. We
derive the primal and dual representations of the framework and relate
different training and inference algorithms from a theoretical perspective. We
show how to achieve full equivalence in primal and dual formulations by
rescaling primal variables. Finally, we experimentally validate the equivalence
and provide insight into the relationships between different methods on a
number of time series data sets by recursively forecasting unseen test data and
visualizing the learned features.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18486">A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (arXiv:2305.18486v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1">Md Tahmid Rahman Laskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1">M Saiful Bari</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mizanur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhuiyan_M/0/1/0/all/0/1">Md Amran Hossen Bhuiyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jimmy Xiangji Huang</a></p>
<p>The development of large language models (LLMs) such as ChatGPT has brought a
lot of attention recently. However, their evaluation in the benchmark academic
datasets remains under-explored due to the difficulty of evaluating the
generative outputs produced by this model against the ground truth. In this
paper, we aim to present a thorough evaluation of ChatGPT's performance on
diverse academic datasets, covering tasks like question-answering, text
summarization, code generation, commonsense reasoning, mathematical
problem-solving, machine translation, bias detection, and ethical
considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze
255K responses it generates in these datasets. This makes our work the largest
evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate
the strengths and weaknesses of ChatGPT in various tasks and provide insights
for future research using LLMs. We also report a new emergent ability to follow
multi-query instructions that we mostly found in ChatGPT and other
instruction-tuned models. Our extensive evaluation shows that even though
ChatGPT is capable of performing a wide variety of tasks, and may obtain
impressive performance in several benchmark datasets, it is still far from
achieving the ability to reliably solve many challenging tasks. By providing a
thorough assessment of ChatGPT's performance across diverse NLP tasks, this
paper sets the stage for a targeted deployment of ChatGPT-like LLMs in
real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04220">Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL. (arXiv:2306.04220v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Peng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1">Xianyuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhihao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenjia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shoucheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Han Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Li Jiang</a></p>
<p>Offline reinforcement learning (RL) offers an appealing approach to
real-world tasks by learning policies from pre-collected datasets without
interacting with the environment. However, the performance of existing offline
RL algorithms heavily depends on the scale and state-action space coverage of
datasets. Real-world data collection is often expensive and uncontrollable,
leading to small and narrowly covered datasets and posing significant
challenges for practical deployments of offline RL. In this paper, we provide a
new insight that leveraging the fundamental symmetry of system dynamics can
substantially enhance offline RL performance under small datasets.
Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced
Dynamics Model (TDM), which establishes consistency between a pair of forward
and reverse latent dynamics. TDM provides both well-behaved representations for
small datasets and a new reliability measure for OOD samples based on
compliance with the T-symmetry. These can be readily used to construct a new
offline RL algorithm (TSRL) with less conservative policy constraints and a
reliable latent space data augmentation procedure. Based on extensive
experiments, we find TSRL achieves great performance on small benchmark
datasets with as few as 1% of the original samples, which significantly
outperforms the recent offline RL algorithms in terms of data efficiency and
generalizability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04504">Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers. (arXiv:2306.04504v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jahan_I/0/1/0/all/0/1">Israt Jahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1">Md Tahmid Rahman Laskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jimmy Huang</a></p>
<p>ChatGPT is a large language model developed by OpenAI. Despite its impressive
performance across various tasks, no prior work has investigated its capability
in the biomedical domain yet. To this end, this paper aims to evaluate the
performance of ChatGPT on various benchmark biomedical tasks, such as relation
extraction, document classification, question answering, and summarization. To
the best of our knowledge, this is the first work that conducts an extensive
evaluation of ChatGPT in the biomedical domain. Interestingly, we find based on
our evaluation that in biomedical datasets that have smaller training sets,
zero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative
transformer models, such as BioGPT and BioBART. This suggests that ChatGPT's
pre-training on large text corpora makes it quite specialized even in the
biomedical domain. Our findings demonstrate that ChatGPT has the potential to
be a valuable tool for various tasks in the biomedical domain that lack large
annotated data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04637">Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection. (arXiv:2306.04637v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yu Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1">Song Mei</a></p>
<p>Neural sequence models based on the transformer architecture have
demonstrated remarkable \emph{in-context learning} (ICL) abilities, where they
can perform new tasks when prompted with training and test examples, without
any parameter update to the model. This work first provides a comprehensive
statistical theory for transformers to perform ICL. Concretely, we show that
transformers can implement a broad class of standard machine learning
algorithms in context, such as least squares, ridge regression, Lasso, learning
generalized linear models, and gradient descent on two-layer neural networks,
with near-optimal predictive power on various in-context data distributions.
Using an efficient implementation of in-context gradient descent as the
underlying mechanism, our transformer constructions admit mild size bounds, and
can be learned with polynomially many pretraining sequences.
</p>
<p>Building on these ``base'' ICL algorithms, intriguingly, we show that
transformers can implement more complex ICL procedures involving
\emph{in-context algorithm selection}, akin to what a statistician can do in
real life -- A \emph{single} transformer can adaptively select different base
ICL algorithms -- or even perform qualitatively different tasks -- on different
input sequences, without any explicit prompting of the right algorithm or task.
We both establish this in theory by explicit constructions, and also observe
this phenomenon experimentally. In theory, we construct two general mechanisms
for algorithm selection with concrete examples: pre-ICL testing, and post-ICL
validation. As an example, we use the post-ICL validation mechanism to
construct a transformer that can perform nearly Bayes-optimal ICL on a
challenging task -- noisy linear models with mixed noise levels.
Experimentally, we demonstrate the strong in-context algorithm selection
capabilities of standard transformer architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06079">Deep Learning for Day Forecasts from Sparse Observations. (arXiv:2306.06079v3 [physics.ao-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Andrychowicz_M/0/1/0/all/0/1">Marcin Andrychowicz</a>, <a href="http://arxiv.org/find/physics/1/au:+Espeholt_L/0/1/0/all/0/1">Lasse Espeholt</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_D/0/1/0/all/0/1">Di Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Merchant_S/0/1/0/all/0/1">Samier Merchant</a>, <a href="http://arxiv.org/find/physics/1/au:+Merose_A/0/1/0/all/0/1">Alexander Merose</a>, <a href="http://arxiv.org/find/physics/1/au:+Zyda_F/0/1/0/all/0/1">Fred Zyda</a>, <a href="http://arxiv.org/find/physics/1/au:+Agrawal_S/0/1/0/all/0/1">Shreya Agrawal</a>, <a href="http://arxiv.org/find/physics/1/au:+Kalchbrenner_N/0/1/0/all/0/1">Nal Kalchbrenner</a></p>
<p>Deep neural networks offer an alternative paradigm for modeling weather
conditions. The ability of neural models to make a prediction in less than a
second once the data is available and to do so with very high temporal and
spatial resolution, and the ability to learn directly from atmospheric
observations, are just some of these models' unique advantages. Neural models
trained using atmospheric observations, the highest fidelity and lowest latency
data, have to date achieved good performance only up to twelve hours of lead
time when compared with state-of-the-art probabilistic Numerical Weather
Prediction models and only for the sole variable of precipitation. In this
paper, we present MetNet-3 that extends significantly both the lead time range
and the variables that an observation based neural model can predict well.
MetNet-3 learns from both dense and sparse data sensors and makes predictions
up to 24 hours ahead for precipitation, wind, temperature and dew point.
MetNet-3 introduces a key densification technique that implicitly captures data
assimilation and produces spatially dense forecasts in spite of the network
training on extremely sparse targets. MetNet-3 has a high temporal and spatial
resolution of, respectively, up to 2 minutes and 1 km as well as a low
operational latency. We find that MetNet-3 is able to outperform the best
single- and multi-member NWPs such as HRRR and ENS over the CONUS region for up
to 24 hours ahead setting a new performance milestone for observation based
neural models. MetNet-3 is operational and its forecasts are served in Google
Search in conjunction with other models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06767">The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders: Perspectives and Use Cases. (arXiv:2306.06767v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1">Jiancheng Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hongwei Bran Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wei_D/0/1/0/all/0/1">Donglai Wei</a></p>
<p>This study investigates the transformative potential of Large Language Models
(LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of public
data, these models, which possess remarkable language understanding and
generation capabilities, are augmenting the interpretive skills of
radiologists, enhancing patient-physician communication, and streamlining
clinical workflows. The paper introduces an analytic framework for presenting
the complex interactions between LLMs and the broader ecosystem of medical
imaging stakeholders, including businesses, insurance entities, governments,
research institutions, and hospitals (nicknamed BIGR-H). Through detailed
analyses, illustrative use cases, and discussions on the broader implications
and future directions, this perspective seeks to raise discussion in strategic
planning and decision-making in the era of AI-enabled healthcare.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10077">Stacking of Hyperparameter Tuned Models for Tagging Coding Problems. (arXiv:2306.10077v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+TS_S/0/1/0/all/0/1">Sathya Krishnan TS</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandian_S/0/1/0/all/0/1">S. Lakshmana Pandian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shunmugapriya_P/0/1/0/all/0/1">P. Shunmugapriya</a></p>
<p>Coding problems are problems that require a solution in the form of a
computer program. Coding problems are popular among students and professionals
as it enhances their skills and career opportunities. An AI system that would
help those who practice coding problems would be highly useful and there is a
huge potential for such a system. In this work, we propose a model which uses
stacking of hyperparameter tuned boosting models to achieve impressive metric
scores of 77.8% accuracy and 0.815 PR-AUC on the dataset that was scraped from
Codeforces and Leetcode. We open source the dataset and the models developed
for this work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10155">Fairness in Multi-Task Learning via Wasserstein Barycenters. (arXiv:2306.10155v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Hu_F/0/1/0/all/0/1">Fran&#xe7;ois Hu</a>, <a href="http://arxiv.org/find/stat/1/au:+Ratz_P/0/1/0/all/0/1">Philipp Ratz</a>, <a href="http://arxiv.org/find/stat/1/au:+Charpentier_A/0/1/0/all/0/1">Arthur Charpentier</a></p>
<p>Algorithmic Fairness is an established field in machine learning that aims to
reduce biases in data. Recent advances have proposed various methods to ensure
fairness in a univariate environment, where the goal is to de-bias a single
task. However, extending fairness to a multi-task setting, where more than one
objective is optimised using a shared representation, remains underexplored. To
bridge this gap, we develop a method that extends the definition of Strong
Demographic Parity to multi-task learning using multi-marginal Wasserstein
barycenters. Our approach provides a closed form solution for the optimal fair
multi-task predictor including both regression and binary classification tasks.
We develop a data-driven estimation procedure for the solution and run
numerical experiments on both synthetic and real datasets. The empirical
results highlight the practical value of our post-processing methodology in
promoting fair decision-making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10259">Active Policy Improvement from Multiple Black-box Oracles. (arXiv:2306.10259v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuefeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoneda_T/0/1/0/all/0/1">Takuma Yoneda</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaoqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1">Matthew R. Walter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a></p>
<p>Reinforcement learning (RL) has made significant strides in various complex
domains. However, identifying an effective policy via RL often necessitates
extensive exploration. Imitation learning aims to mitigate this issue by using
expert demonstrations to guide exploration. In real-world scenarios, one often
has access to multiple suboptimal black-box experts, rather than a single
optimal oracle. These experts do not universally outperform each other across
all states, presenting a challenge in actively deciding which oracle to use and
in which state. We introduce MAPS and MAPS-SE, a class of policy improvement
algorithms that perform imitation learning from multiple suboptimal oracles. In
particular, MAPS actively selects which of the oracles to imitate and improve
their value function estimates, and MAPS-SE additionally leverages an active
state exploration criterion to determine which states one should explore. We
provide a comprehensive theoretical analysis and demonstrate that MAPS and
MAPS-SE enjoy sample efficiency advantage over the state-of-the-art policy
improvement algorithms. Empirical results show that MAPS-SE significantly
accelerates policy optimization via state-wise imitation learning from multiple
oracles across a broad spectrum of control tasks in the DeepMind Control Suite.
Our code is publicly available at: https://github.com/ripl/maps.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11182">Co-design Hardware and Algorithm for Vector Search. (arXiv:2306.11182v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shigang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Licht_J/0/1/0/all/0/1">Johannes de Fine Licht</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhenhao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1">Runbin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Renggli_C/0/1/0/all/0/1">Cedric Renggli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1">Theodoros Rekatsinas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1">Torsten Hoefler</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_G/0/1/0/all/0/1">Gustavo Alonso</a></p>
<p>Vector search has emerged as the foundation for large-scale information
retrieval and machine learning systems, with search engines like Google and
Bing processing tens of thousands of queries per second on petabyte-scale
document datasets by evaluating vector similarities between encoded query texts
and web documents. As performance demands for vector search systems surge,
accelerated hardware offers a promising solution in the post-Moore's Law era.
We introduce \textit{FANNS}, an end-to-end and scalable vector search framework
on FPGAs. Given a user-provided recall requirement on a dataset and a hardware
resource budget, \textit{FANNS} automatically co-designs hardware and
algorithm, subsequently generating the corresponding accelerator. The framework
also supports scale-out by incorporating a hardware TCP/IP stack in the
accelerator. \textit{FANNS} attains up to 23.0$\times$ and 37.2$\times$ speedup
compared to FPGA and CPU baselines, respectively, and demonstrates superior
scalability to GPUs, achieving 5.5$\times$ and 7.6$\times$ speedup in median
and 95\textsuperscript{th} percentile (P95) latency within an eight-accelerator
configuration. The remarkable performance of \textit{FANNS} lays a robust
groundwork for future FPGA integration in data centers and AI supercomputers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15083">Balanced Filtering via Non-Disclosive Proxies. (arXiv:2306.15083v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Siqi Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Diana_E/0/1/0/all/0/1">Emily Diana</a>, <a href="http://arxiv.org/find/cs/1/au:+Kearns_M/0/1/0/all/0/1">Michael Kearns</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a></p>
<p>We study the problem of non-disclosively collecting a sample of data that is
balanced with respect to sensitive groups when group membership is unavailable
or prohibited from use at collection time. Specifically, our collection
mechanism does not reveal significantly more about group membership of any
individual sample than can be ascertained from base rates alone. To do this, we
adopt a fairness pipeline perspective, in which a learner can use a small set
of labeled data to train a proxy function that can later be used for this
filtering task. We then associate the range of the proxy function with sampling
probabilities; given a new candidate, we classify it using our proxy function,
and then select it for our sample with probability proportional to the sampling
probability corresponding to its proxy classification. Importantly, we require
that the proxy classification itself not reveal significant information about
the sensitive group membership of any individual sample (i.e., it should be
sufficiently non-disclosive). We show that under modest algorithmic
assumptions, we find such a proxy in a sample- and oracle-efficient manner.
Finally, we experimentally evaluate our algorithm and analyze generalization
properties.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15782">UTRNet: High-Resolution Urdu Text Recognition In Printed Documents. (arXiv:2306.15782v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1">Abdur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Arjun Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Arora_C/0/1/0/all/0/1">Chetan Arora</a></p>
<p>In this paper, we propose a novel approach to address the challenges of
printed Urdu text recognition using high-resolution, multi-scale semantic
feature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model,
demonstrates state-of-the-art performance on benchmark datasets. To address the
limitations of previous works, which struggle to generalize to the intricacies
of the Urdu script and the lack of sufficient annotated real-world data, we
have introduced the UTRSet-Real, a large-scale annotated real-world dataset
comprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000
lines closely resembling real-world and made corrections to the ground truth of
the existing IIITH dataset, making it a more reliable resource for future
research. We also provide UrduDoc, a benchmark dataset for Urdu text line
detection in scanned documents. Additionally, we have developed an online tool
for end-to-end Urdu OCR from printed documents by integrating UTRNet with a
text detection model. Our work not only addresses the current limitations of
Urdu OCR but also paves the way for future research in this area and
facilitates the continued advancement of Urdu OCR technology. The project page
with source code, datasets, annotations, trained models, and online tool is
available at abdur75648.github.io/UTRNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00968">REAL: A Representative Error-Driven Approach for Active Learning. (arXiv:2307.00968v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1">Lizi Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yueguo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xiaoyong Du</a></p>
<p>Given a limited labeling budget, active learning (AL) aims to sample the most
informative instances from an unlabeled pool to acquire labels for subsequent
model training. To achieve this, AL typically measures the informativeness of
unlabeled instances based on uncertainty and diversity. However, it does not
consider erroneous instances with their neighborhood error density, which have
great potential to improve the model performance. To address this limitation,
we propose $REAL$, a novel approach to select data instances with
$\underline{R}$epresentative $\underline{E}$rrors for $\underline{A}$ctive
$\underline{L}$earning. It identifies minority predictions as \emph{pseudo
errors} within a cluster and allocates an adaptive sampling budget for the
cluster based on estimated error density. Extensive experiments on five text
classification datasets demonstrate that $REAL$ consistently outperforms all
best-performing baselines regarding accuracy and F1-macro scores across a wide
range of hyperparameter settings. Our analysis also shows that $REAL$ selects
the most representative pseudo errors that match the distribution of
ground-truth errors along the decision boundary. Our code is publicly available
at https://github.com/withchencheng/ECML_PKDD_23_Real.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01317">Density-based Feasibility Learning with Normalizing Flows for Introspective Robotic Assembly. (arXiv:2307.01317v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianxiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Atad_M/0/1/0/all/0/1">Matan Atad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_I/0/1/0/all/0/1">Ismael Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Durner_M/0/1/0/all/0/1">Maximilian Durner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Triebel_R/0/1/0/all/0/1">Rudolph Triebel</a></p>
<p>Machine Learning (ML) models in Robotic Assembly Sequence Planning (RASP)
need to be introspective on the predicted solutions, i.e. whether they are
feasible or not, to circumvent potential efficiency degradation. Previous works
need both feasible and infeasible examples during training. However, the
infeasible ones are hard to collect sufficiently when re-training is required
for swift adaptation to new product variants. In this work, we propose a
density-based feasibility learning method that requires only feasible examples.
Concretely, we formulate the feasibility learning problem as
Out-of-Distribution (OOD) detection with Normalizing Flows (NF), which are
powerful generative models for estimating complex probability distributions.
Empirically, the proposed method is demonstrated on robotic assembly use cases
and outperforms other single-class baselines in detecting infeasible
assemblies. We further investigate the internal working mechanism of our method
and show that a large memory saving can be obtained based on an advanced
variant of NF.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01622">Renewable energy management in smart home environment via forecast embedded scheduling based on Recurrent Trend Predictive Neural Network. (arXiv:2307.01622v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nakip_M/0/1/0/all/0/1">Mert Nak&#x131;p</a>, <a href="http://arxiv.org/find/cs/1/au:+Copur_O/0/1/0/all/0/1">Onur &#xc7;opur</a>, <a href="http://arxiv.org/find/cs/1/au:+Biyik_E/0/1/0/all/0/1">Emrah Biyik</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzelis_C/0/1/0/all/0/1">C&#xfc;neyt G&#xfc;zeli&#x15f;</a></p>
<p>Smart home energy management systems help the distribution grid operate more
efficiently and reliably, and enable effective penetration of distributed
renewable energy sources. These systems rely on robust forecasting,
optimization, and control/scheduling algorithms that can handle the uncertain
nature of demand and renewable generation. This paper proposes an advanced ML
algorithm, called Recurrent Trend Predictive Neural Network based Forecast
Embedded Scheduling (rTPNN-FES), to provide efficient residential demand
control. rTPNN-FES is a novel neural network architecture that simultaneously
forecasts renewable energy generation and schedules household appliances. By
its embedded structure, rTPNN-FES eliminates the utilization of separate
algorithms for forecasting and scheduling and generates a schedule that is
robust against forecasting errors. This paper also evaluates the performance of
the proposed algorithm for an IoT-enabled smart home. The evaluation results
reveal that rTPNN-FES provides near-optimal scheduling $37.5$ times faster than
the optimization while outperforming state-of-the-art forecasting techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01715">Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework. (arXiv:2307.01715v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Segev_E/0/1/0/all/0/1">Eliya Segev</a>, <a href="http://arxiv.org/find/cs/1/au:+Alroy_M/0/1/0/all/0/1">Maya Alroy</a>, <a href="http://arxiv.org/find/cs/1/au:+Katsir_R/0/1/0/all/0/1">Ronen Katsir</a>, <a href="http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1">Noam Wies</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenhav_A/0/1/0/all/0/1">Ayana Shenhav</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_Oren_Y/0/1/0/all/0/1">Yael Ben-Oren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zar_D/0/1/0/all/0/1">David Zar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tadmor_O/0/1/0/all/0/1">Oren Tadmor</a>, <a href="http://arxiv.org/find/cs/1/au:+Bitterman_J/0/1/0/all/0/1">Jacob Bitterman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1">Amnon Shashua</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenwein_T/0/1/0/all/0/1">Tal Rosenwein</a></p>
<p>Connectionist Temporal Classification (CTC) is a widely used criterion for
training supervised sequence-to-sequence (seq2seq) models. It enables learning
the relations between input and output sequences, termed alignments, by
marginalizing over perfect alignments (that yield the ground truth), at the
expense of imperfect alignments. This binary differentiation of perfect and
imperfect alignments falls short of capturing other essential alignment
properties that hold significance in other real-world applications. Here we
propose $\textit{Align With Purpose}$, a $\textbf{general Plug-and-Play
framework}$ for enhancing a desired property in models trained with the CTC
criterion. We do that by complementing the CTC with an additional loss term
that prioritizes alignments according to a desired property. Our method does
not require any intervention in the CTC loss function, enables easy
optimization of a variety of properties, and allows differentiation between
both perfect and imperfect alignments. We apply our framework in the domain of
Automatic Speech Recognition (ASR) and show its generality in terms of property
selection, architectural choice, and scale of training dataset (up to 280,000
hours). To demonstrate the effectiveness of our framework, we apply it to two
unrelated properties: emission time and word error rate (WER). For the former,
we report an improvement of up to 570ms in latency optimization with a minor
reduction in WER, and for the latter, we report a relative improvement of 4.5%
WER over the baseline models. To the best of our knowledge, these applications
have never been demonstrated to work on a scale of data as large as ours.
Notably, our method can be implemented using only a few lines of code, and can
be extended to other alignment-free loss functions and to domains other than
ASR.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02263">Dynamical Isometry based Rigorous Fair Neural Architecture Search. (arXiv:2307.02263v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jianxiang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Junyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianji Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weihao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chuang Liu</a></p>
<p>Recently, the weight-sharing technique has significantly speeded up the
training and evaluation procedure of neural architecture search. However, most
existing weight-sharing strategies are solely based on experience or
observation, which makes the searching results lack interpretability and
rationality. In addition, due to the negligence of fairness, current methods
are prone to make misjudgments in module evaluation. To address these problems,
we propose a novel neural architecture search algorithm based on dynamical
isometry. We use the fix point analysis method in the mean field theory to
analyze the dynamics behavior in the steady state random neural network, and
how dynamic isometry guarantees the fairness of weight-sharing based NAS.
Meanwhile, we prove that our module selection strategy is rigorous fair by
estimating the generalization error of all modules with well-conditioned
Jacobian. Extensive experiments show that, with the same size, the architecture
searched by the proposed method can achieve state-of-the-art top-1 validation
accuracy on ImageNet classification. In addition, we demonstrate that our
method is able to achieve better and more stable training performance without
loss of generality.
</p>
</p>
</div>

    </div>
    </body>
    