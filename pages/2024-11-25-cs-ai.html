<!DOCTYPE html>
<html>
<head>
<title>2024-11-25-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    .copy-button {
        background-color: #007BFF;
        color: #fff;
        border: none;
        padding: 5px 10px;
        cursor: pointer;
        margin-top: 10px;
    }
    .copy-button:active {
        background-color: #0056b3;
    }
    .copy-message {
        display: none;
        background-color: #4CAF50;
        color: #fff;
        padding: 5px;
        margin-top: 10px;
        border-radius: 3px;
    }
    </style>
    <script>
    function copyToClipboard(text, buttonId) {
        const el = document.createElement('textarea');
        el.value = text;
        document.body.appendChild(el);
        el.select();
        document.execCommand('copy');
        document.body.removeChild(el);
        
        const messageElement = document.getElementById('copy-message-' + buttonId);
        messageElement.innerHTML = 'Copied "' + text + '" to clipboard';
        messageElement.style.display = 'block';
        setTimeout(function() {
            messageElement.style.display = 'none';
        }, 3000);
    }
    </script>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.14480">Associative Knowledge Graphs for Efficient Sequence Storage and Retrieval</a></h1>
<p><b>Authors:</b> Przemys{\l}aw Stok{\l}osa, Janusz A. Starzyk, Pawe{\l} Raif, Adrian Horzyk, Marcin Kowalik</p>
<p>Abstract: This paper presents a novel approach for constructing associative knowledge graphs that are highly effective for storing and recognizing sequences. The graph is created by representing overlapping sequences of objects, as tightly connected clusters within the larger graph. Individual objects (represented as nodes) can be a part of multiple sequences or appear repeatedly within a single sequence. To retrieve sequences, we leverage context, providing a subset of objects that triggers an association with the complete sequence. The system's memory capacity is determined by the size of the graph and the density of its connections. We have theoretically derived the relationships between the critical density of the graph and the memory capacity for storing sequences. The critical density is the point beyond which error-free sequence reconstruction becomes impossible. Furthermore, we have developed an efficient algorithm for ordering elements within a sequence. Through extensive experiments with various types of sequences, we have confirmed the validity of these relationships. This approach has potential applications in diverse fields, such as anomaly detection in financial transactions or predicting user behavior based on past actions.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14480', 0)">Copy Link</button>
<div id="copy-message-0" class="copy-message"></div>
</div>
<div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.14574">SRSA: A Cost-Efficient Strategy-Router Search Agent for Real-world Human-Machine Interactions</a></h1>
<p><b>Authors:</b> Yaqi Wang, Haipei Xu</p>
<p>Abstract: Recently, as Large Language Models (LLMs) have shown impressive emerging capabilities and gained widespread popularity, research on LLM-based search agents has proliferated. In real-world situations, users often input contextual and highly personalized queries to chatbots, challenging LLMs to capture context and generate appropriate answers. However, much of the prior research has not focused specifically on authentic human-machine dialogue scenarios. It also ignores the important balance between response quality and computational cost by forcing all queries to follow the same agent process. To address these gaps, we propose a Strategy-Router Search Agent (SRSA), routing different queries to appropriate search strategies and enabling fine-grained serial searches to obtain high-quality results at a relatively low cost. To evaluate our work, we introduce a new dataset, Contextual Query Enhancement Dataset (CQED), comprising contextual queries to simulate authentic and daily interactions between humans and chatbots. Using LLM-based automatic evaluation metrics, we assessed SRSA's performance in terms of informativeness, completeness, novelty, and actionability. To conclude, SRSA provides an approach that resolves the issue of simple serial searches leading to degenerate answers for lengthy and contextual queries, effectively and efficiently parses complex user queries, and generates more comprehensive and informative responses without fine-tuning an LLM.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14574', 1)">Copy Link</button>
<div id="copy-message-1" class="copy-message"></div>
</div>
<div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.14858">Domain and Range Aware Synthetic Negatives Generation for Knowledge Graph Embedding Models</a></h1>
<p><b>Authors:</b> Alberto Bernardi, Luca Costabello</p>
<p>Abstract: Knowledge Graph Embedding models, representing entities and edges in a low-dimensional space, have been extremely successful at solving tasks related to completing and exploring Knowledge Graphs (KGs). One of the key aspects of training most of these models is teaching to discriminate between true statements positives and false ones (negatives). However, the way in which negatives can be defined is not trivial, as facts missing from the KG are not necessarily false and a set of ground truth negatives is hardly ever given. This makes synthetic negative generation a necessity. Different generation strategies can heavily affect the quality of the embeddings, making it a primary aspect to consider. We revamp a strategy that generates corruptions during training respecting the domain and range of relations, we extend its capabilities and we show our methods bring substantial improvement (+10% MRR) for standard benchmark datasets and over +150% MRR for a larger ontology-backed dataset.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14858', 2)">Copy Link</button>
<div id="copy-message-2" class="copy-message"></div>
</div>
<div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.14991">Free Energy Projective Simulation (FEPS): Active inference with interpretability</a></h1>
<p><b>Authors:</b> Jos\'ephine Pazem, Marius Krumm, Alexander Q. Vining, Lukas J. Fiderer, Hans J. Briegel</p>
<p>Abstract: In the last decade, the free energy principle (FEP) and active inference (AIF) have achieved many successes connecting conceptual models of learning and cognition to mathematical models of perception and action. This effort is driven by a multidisciplinary interest in understanding aspects of self-organizing complex adaptive systems, including elements of agency. Various reinforcement learning (RL) models performing active inference have been proposed and trained on standard RL tasks using deep neural networks. Recent work has focused on improving such agents' performance in complex environments by incorporating the latest machine learning techniques. In this paper, we take an alternative approach. Within the constraints imposed by the FEP and AIF, we attempt to model agents in an interpretable way without deep neural networks by introducing Free Energy Projective Simulation (FEPS). Using internal rewards only, FEPS agents build a representation of their partially observable environments with which they interact. Following AIF, the policy to achieve a given task is derived from this world model by minimizing the expected free energy. Leveraging the interpretability of the model, techniques are introduced to deal with long-term goals and reduce prediction errors caused by erroneous hidden state estimation. We test the FEPS model on two RL environments inspired from behavioral biology: a timed response task and a navigation task in a partially observable grid. Our results show that FEPS agents fully resolve the ambiguity of both environments by appropriately contextualizing their observations based on prediction accuracy only. In addition, they infer optimal policies flexibly for any target observation in the environment.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14991', 3)">Copy Link</button>
<div id="copy-message-3" class="copy-message"></div>
</div>
<div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.14995">Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution</a></h1>
<p><b>Authors:</b> Jonas G\"osgens, Niklas Jansen, Hector Geffner</p>
<p>Abstract: Learning STRIPS action models from action traces alone is a challenging problem as it involves learning the domain predicates as well. In this work, a novel approach is introduced which, like the well-known LOCM systems, is scalable, but like SAT approaches, is sound and complete. Furthermore, the approach is general and imposes no restrictions on the hidden domain or the number or arity of the predicates. The new learning method is based on an \emph{efficient, novel test} that checks whether the assumption that a predicate is affected by a set of action patterns, namely, actions with specific argument positions, is consistent with the traces. The predicates and action patterns that pass the test provide the basis for the learned domain that is then easily completed with preconditions and static predicates. The new method is studied theoretically and experimentally. For the latter, the method is evaluated on traces and graphs obtained from standard classical domains like the 8-puzzle, which involve hundreds of thousands of states and transitions. The learned representations are then verified on larger instances.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14995', 4)">Copy Link</button>
<div id="copy-message-4" class="copy-message"></div>
</div>
<div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.15041">mR$^2$AG: Multimodal Retrieval-Reflection-Augmented Generation for Knowledge-Based VQA</a></h1>
<p><b>Authors:</b> Tao Zhang, Ziqi Zhang, Zongyang Ma, Yuxin Chen, Zhongang Qi, Chunfeng Yuan, Bing Li, Junfu Pu, Yuxuan Zhao, Zehua Xie, Jin Ma, Ying Shan, Weiming Hu</p>
<p>Abstract: Advanced Multimodal Large Language Models (MLLMs) struggle with recent Knowledge-based VQA tasks, such as INFOSEEK and Encyclopedic-VQA, due to their limited and frozen knowledge scope, often leading to ambiguous and inaccurate responses. Thus, multimodal Retrieval-Augmented Generation (mRAG) is naturally introduced to provide MLLMs with comprehensive and up-to-date knowledge, effectively expanding the knowledge scope. However, current mRAG methods have inherent drawbacks, including: 1) Performing retrieval even when external knowledge is not needed. 2) Lacking of identification of evidence that supports the query. 3) Increasing model complexity due to additional information filtering modules or rules. To address these shortcomings, we propose a novel generalized framework called \textbf{m}ultimodal \textbf{R}etrieval-\textbf{R}eflection-\textbf{A}ugmented \textbf{G}eneration (mR$^2$AG), which achieves adaptive retrieval and useful information localization to enable answers through two easy-to-implement reflection operations, preventing high model complexity. In mR$^2$AG, Retrieval-Reflection is designed to distinguish different user queries and avoids redundant retrieval calls, and Relevance-Reflection is introduced to guide the MLLM in locating beneficial evidence of the retrieved content and generating answers accordingly. In addition, mR$^2$AG can be integrated into any well-trained MLLM with efficient fine-tuning on the proposed mR$^2$AG Instruction-Tuning dataset (mR$^2$AG-IT). mR$^2$AG significantly outperforms state-of-the-art MLLMs (e.g., GPT-4v/o) and RAG-based MLLMs on INFOSEEK and Encyclopedic-VQA, while maintaining the exceptional capabilities of base MLLMs across a wide range of Visual-dependent tasks.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15041', 5)">Copy Link</button>
<div id="copy-message-5" class="copy-message"></div>
</div>
<div class="article">
<h1> new <a href="https://arxiv.org/abs/2411.15061">Empowering Clients: Transformation of Design Processes Due to Generative AI</a></h1>
<p><b>Authors:</b> Johannes Schneider, Kilic Sinem, Daniel Stockhammer</p>
<p>Abstract: The domain of computational design, driven by advancements in Generative AI, is transforming creative fields. We explore the transformative effects of Generative AI on the architectural design process and discuss the role of the architect. The case of architecture is interesting as designing houses is complex, involving extensive customer interaction. We employ a within-subject experiment using a popular general-purpose text-to-image tool for generating designs and providing feedback on existing designs, followed by expert interviews. The study reveals that AI can disrupt the ideation phase by enabling clients to engage in the design process through rapid visualization of their own ideas. In turn, the architect's role shifts more towards assessing the feasibility of designs generated conjointly by clients and AI. Our study also shows that while AI can provide valuable feedback on designs, it might fail to generate such designs, allowing for interesting connections to foundations in computer science, i.e., NP-completeness. AI's feedback also tends to hamper creativity and innovation by suggesting altering novel, innovative approaches toward more standardized designs. Our study also reveals that there is uncertainty among architects about the interpretative sovereignty of architecture and loss of meaning and identity when AI increasingly takes over authorship in the design process.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15061', 6)">Copy Link</button>
<div id="copy-message-6" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14433">Transforming Engineering Education Using Generative AI and Digital Twin Technologies</a></h1>
<p><b>Authors:</b> Yu-Zheng Lin, Ahmed Hussain J Alhamadah, Matthew William Redondo, Karan Himanshu Patel, Sujan Ghimire, Banafsheh Saber Latibari, Soheil Salehi, Pratik Satam</p>
<p>Abstract: Digital twin technology, traditionally used in industry, is increasingly recognized for its potential to enhance educational experiences. This study investigates the application of industrial digital twins (DTs) in education, focusing on how DT models of varying fidelity can support different stages of Bloom's taxonomy in the cognitive domain. We align Bloom's six cognitive stages with educational levels: undergraduate studies for "Remember" and "Understand," master's level for "Apply" and "Analyze," and doctoral level for "Evaluate" and "Create." Low-fidelity DTs aid essential knowledge acquisition and skill training, providing a low-risk environment for grasping fundamental concepts. Medium-fidelity DTs offer more detailed and dynamic simulations, enhancing application skills and problem-solving. High-fidelity DTs support advanced learners by replicating physical phenomena, allowing for innovative design and complex experiments. Within this framework, large language models (LLMs) serve as mentors, assessing progress, filling knowledge gaps, and assisting with DT interactions, parameter setting, and debugging. We evaluate the educational impact using the Kirkpatrick Model, examining how each DT model's fidelity influences learning outcomes. This framework helps educators make informed decisions on integrating DTs and LLMs to meet specific learning objectives.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14433', 7)">Copy Link</button>
<div id="copy-message-7" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14441">GeMID: Generalizable Models for IoT Device Identification</a></h1>
<p><b>Authors:</b> Kahraman Kostas, Rabia Yasa Kostas, Mike Just, Michael A. Lones</p>
<p>Abstract: With the proliferation of Internet of Things (IoT) devices, ensuring their security has become paramount. Device identification (DI), which distinguishes IoT devices based on their traffic patterns, plays a crucial role in both differentiating devices and identifying vulnerable ones, closing a serious security gap. However, existing approaches to DI that build machine learning models often overlook the challenge of model generalizability across diverse network environments. In this study, we propose a novel framework to address this limitation and evaluate the generalizability of DI models across datasets collected within different network environments. Our approach involves a two-step process: first, we develop a feature and model selection method that is more robust to generalization issues by using a genetic algorithm with external feedback and datasets from distinct environments to refine the selections. Second, the resulting DI models are then tested on further independent datasets in order to robustly assess their generalizability. We demonstrate the effectiveness of our method by empirically comparing it to alternatives, highlighting how fundamental limitations of commonly employed techniques such as sliding window and flow statistics limit their generalizability. Our findings advance research in IoT security and device identification, offering insights into improving model effectiveness and mitigating risks in IoT networks.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14441', 8)">Copy Link</button>
<div id="copy-message-8" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14449">Deferred Backdoor Functionality Attacks on Deep Learning Models</a></h1>
<p><b>Authors:</b> Jeongjin Shin, Sangdon Park</p>
<p>Abstract: Deep learning models are vulnerable to backdoor attacks, where adversaries inject malicious functionality during training that activates on trigger inputs at inference time. Extensive research has focused on developing stealthy backdoor attacks to evade detection and defense mechanisms. However, these approaches still have limitations that leave the door open for detection and mitigation due to their inherent design to cause malicious behavior in the presence of a trigger. To address this limitation, we introduce Deferred Backdoor Functionality Activation (DBFA), a new paradigm in backdoor attacks. Unlike conventional attacks, DBFA initially conceals its backdoor, producing benign outputs even when triggered. This stealthy behavior allows DBFA to bypass multiple detection and defense methods, remaining undetected during initial inspections. The backdoor functionality is strategically activated only after the model undergoes subsequent updates, such as retraining on benign data. DBFA attacks exploit the common practice in the life cycle of machine learning models to perform model updates and fine-tuning after initial deployment. To implement DBFA attacks, we approach the problem by making the unlearning of the backdoor fragile, allowing it to be easily cancelled and subsequently reactivate the backdoor functionality. To achieve this, we propose a novel two-stage training scheme, called DeferBad. Our extensive experiments across various fine-tuning scenarios, backdoor attack types, datasets, and model architectures demonstrate the effectiveness and stealthiness of DeferBad.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14449', 9)">Copy Link</button>
<div id="copy-message-9" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14456">Can Artificial Intelligence Generate Quality Research Topics Reflecting Patient Concerns?</a></h1>
<p><b>Authors:</b> Jiyeong Kim, Michael L. Chen, Shawheen J. Rezaei, Mariana Ramirez-Posada, Jennifer L. Caswell-Jin, Allison W. Kurian, Fauzia Riaz, Kavita Y. Sarin, Jean Y. Tang, Steven M. Asch, Eleni Linos</p>
<p>Abstract: Patient-centered research is increasingly important in narrowing the gap between research and patient care, yet incorporating patient perspectives into health research has been inconsistent. We propose an automated framework leveraging innovative natural language processing (NLP) and artificial intelligence (AI) with patient portal messages to generate research ideas that prioritize important patient issues. We further quantified the quality of AI-generated research topics. To define patient clinical concerns, we analyzed 614,464 patient messages from 25,549 individuals with breast or skin cancer obtained from a large academic hospital (2013 to 2024), constructing a 2-staged unsupervised NLP topic model. Then, we generated research topics to resolve the defined issues using a widely used AI (ChatGPT-4o, OpenAI Inc, April 2024 version) with prompt-engineering strategies. We guided AI to perform multi-level tasks: 1) knowledge interpretation and summarization (e.g., interpreting and summarizing the NLP-defined topics), 2) knowledge generation (e.g., generating research ideas corresponding to patients issues), 3) self-reflection and correction (e.g., ensuring and revising the research ideas after searching for scientific articles), and 4) self-reassurance (e.g., confirming and finalizing the research ideas). Six highly experienced breast oncologists and dermatologists assessed the significance and novelty of AI-generated research topics using a 5-point Likert scale (1-exceptional, 5-poor). One-third of the AI-suggested research topics were highly significant and novel when both scores were lower than the average. Two-thirds of the AI-suggested topics were novel in both cancers. Our findings demonstrate that AI-generated research topics reflecting patient perspectives via a large volume of patient messages can meaningfully guide future directions in patient-centered health research.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14456', 10)">Copy Link</button>
<div id="copy-message-10" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14458">Improving training time and GPU utilization in geo-distributed language model training</a></h1>
<p><b>Authors:</b>  Palak (Microsoft Research India), Rohan Gandhi (Microsoft Research India), Karan Tandon (Microsoft Research India), Debopam Bhattacherjee (Microsoft Research India), Venkata N. Padmanabhan (Microsoft Research India)</p>
<p>Abstract: The widespread adoption of language models (LMs) across multiple industries has caused huge surge in demand for GPUs. Training LMs requires tens of thousands of GPUs and housing them in the same datacenter (DCs) is becoming challenging. We focus on training such models across multiple DCs connected via Wide-Area-Network (WAN). We build ATLAS that speeds up such training time using novel temporal bandwidth sharing and many other design choices. While ATLAS improves the training time, it does not eliminate the bubbles (idle GPU cycles). We built BUBBLETEA that runs prefill-as-a-service (part of LM inference) during the bubbles that improves the GPU utilization substantially without any impact of training. Together, ATLAS and BUBBLETEA improve training time by up to 17X and achieve GPU utilization of up to 94%.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14458', 11)">Copy Link</button>
<div id="copy-message-11" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14459">Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation</a></h1>
<p><b>Authors:</b> Zhangchi Qiu, Linhao Luo, Shirui Pan, Alan Wee-Chung Liew</p>
<p>Abstract: Conversational Recommender Systems (CRSs) aim to provide personalized recommendations through dynamically capturing user preferences in interactive conversations. Conventional CRSs often extract user preferences as hidden representations, which are criticized for their lack of interpretability. This diminishes the transparency and trustworthiness of the recommendation process. Recent works have explored combining the impressive capabilities of Large Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs (KGs) to generate human-understandable recommendation explanations. Despite these efforts, the integration of LLMs and KGs for CRSs remains challenging due to the modality gap between unstructured dialogues and structured KGs. Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for analyzing user preferences, which require domain-specific knowledge. In this paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and KGs to unveil user preferences, enhancing the performance and explainability of existing CRSs. To address integration challenges, COMPASS employs a two-stage training approach: first, it bridges the gap between the structured KG and natural language through an innovative graph entity captioning pre-training mechanism. This enables the LLM to transform KG entities into concise natural language descriptions, allowing them to comprehend domain-specific knowledge. Following, COMPASS optimizes user preference modeling via knowledge-aware instruction fine-tuning, where the LLM learns to reason and summarize user preferences from both dialogue histories and KG-augmented context. This enables COMPASS to perform knowledge-aware reasoning and generate comprehensive and interpretable user preferences that can seamlessly integrate with existing CRS models for improving recommendation performance and explainability.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14459', 12)">Copy Link</button>
<div id="copy-message-12" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14460">LLaSA: Large Language and Structured Data Assistant</a></h1>
<p><b>Authors:</b> Yao Xu, Shizhu He, Zeng Xiangrong, Jiabei Chen, Guang Liu, Bingning Wang, Jun Zhao, Kang Liu</p>
<p>Abstract: Structured data, such as tables, graphs, and databases, play a critical role in plentiful NLP tasks such as question answering and dialogue system. Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs) have been introduced as an additional modality into the input of Large Language Models (LLMs) to improve their performance on Structured Knowledge Grounding (SKG) tasks. However, those GNN-enhanced LLMs have the following limitations: (1) They employ diverse GNNs to model varying types of structured data, rendering them unable to uniformly process various forms of structured data. (2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs from fully aligning with the textual space and limits their adaptability to other LLMs. To address these issues, we propose \textbf{L}arge \textbf{L}anguage and \textbf{S}tructured Data \textbf{A}ssistant (LLaSA), a general framework for enhancing LLMs' ability to handle structured data. Specifically, we represent various types of structured data in a unified hypergraph format, and use self-supervised learning to pretrain a hypergraph encoder, and a G-Former compressing encoded hypergraph representations with cross-attention. The compressed hypergraph representations are appended to the serialized inputs during training and inference stages of LLMs. Experimental results on multiple SKG tasks show that our pretrained hypergraph encoder can adapt to various LLMs and enhance their ability to process different types of structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous SOTA method using full parameters tuning.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14460', 13)">Copy Link</button>
<div id="copy-message-13" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14461">Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios</a></h1>
<p><b>Authors:</b> Shaochen Xu, Yifan Zhou, Zhengliang Liu, Zihao Wu, Tianyang Zhong, Huaqin Zhao, Yiwei Li, Hanqi Jiang, Yi Pan, Junhao Chen, Jin Lu, Wei Zhang, Tuo Zhang, Lu Zhang, Dajiang Zhu, Xiang Li, Wei Liu, Quanzheng Li, Andrea Sikora, Xiaoming Zhai, Zhen Xiang, Tianming Liu</p>
<p>Abstract: Artificial Intelligence (AI) has become essential in modern healthcare, with large language models (LLMs) offering promising advances in clinical decision-making. Traditional model-based approaches, including those leveraging in-context demonstrations and those with specialized medical fine-tuning, have demonstrated strong performance in medical language processing but struggle with real-time adaptability, multi-step reasoning, and handling complex medical tasks. Agent-based AI systems address these limitations by incorporating reasoning traces, tool selection based on context, knowledge retrieval, and both short- and long-term memory. These additional features enable the medical AI agent to handle complex medical scenarios where decision-making should be built on real-time interaction with the environment. Therefore, unlike conventional model-based approaches that treat medical queries as isolated questions, medical AI agents approach them as complex tasks and behave more like human doctors. In this paper, we study the choice of the backbone LLM for medical AI agents, which is the foundation for the agent's overall reasoning and action generation. In particular, we consider the emergent o1 model and examine its impact on agents' reasoning, tool-use adaptability, and real-time information retrieval across diverse clinical scenarios, including high-stakes settings such as intensive care units (ICUs). Our findings demonstrate o1's ability to enhance diagnostic accuracy and consistency, paving the way for smarter, more responsive AI tools that support better patient outcomes and decision-making efficacy in clinical practice.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14461', 14)">Copy Link</button>
<div id="copy-message-14" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14463">Leveraging AI and NLP for Bank Marketing: A Systematic Review and Gap Analysis</a></h1>
<p><b>Authors:</b> Christopher Gerling, Stefan Lessmann</p>
<p>Abstract: This paper explores the growing impact of AI and NLP in bank marketing, highlighting their evolving roles in enhancing marketing strategies, improving customer engagement, and creating value within this sector. While AI and NLP have been widely studied in general marketing, there is a notable gap in understanding their specific applications and potential within the banking sector. This research addresses this specific gap by providing a systematic review and strategic analysis of AI and NLP applications in bank marketing, focusing on their integration across the customer journey and operational excellence. Employing the PRISMA methodology, this study systematically reviews existing literature to assess the current landscape of AI and NLP in bank marketing. Additionally, it incorporates semantic mapping using Sentence Transformers and UMAP for strategic gap analysis to identify underexplored areas and opportunities for future research.
  The systematic review reveals limited research specifically focused on NLP applications in bank marketing. The strategic gap analysis identifies key areas where NLP can further enhance marketing strategies, including customer-centric applications like acquisition, retention, and personalized engagement, offering valuable insights for both academic research and practical implementation. This research contributes to the field of bank marketing by mapping the current state of AI and NLP applications and identifying strategic gaps. The findings provide actionable insights for developing NLP-driven growth and innovation frameworks and highlight the role of NLP in improving operational efficiency and regulatory compliance. This work has broader implications for enhancing customer experience, profitability, and innovation in the banking industry.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14463', 15)">Copy Link</button>
<div id="copy-message-15" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14464">JESTR: Joint Embedding Space Technique for Ranking Candidate Molecules for the Annotation of Untargeted Metabolomics Data</a></h1>
<p><b>Authors:</b> Apurva Kalia, Dilip Krishnan, Soha Hassoun</p>
<p>Abstract: Motivation: A major challenge in metabolomics is annotation: assigning molecular structures to mass spectral fragmentation patterns. Despite recent advances in molecule-to-spectra and in spectra-to-molecular fingerprint prediction (FP), annotation rates remain low. Results: We introduce in this paper a novel paradigm (JESTR) for annotation. Unlike prior approaches that explicitly construct molecular fingerprints or spectra, JESTR leverages the insight that molecules and their corresponding spectra are views of the same data and effectively embeds their representations in a joint space. Candidate structures are ranked based on cosine similarity between the embeddings of query spectrum and each candidate. We evaluate JESTR against mol-to-spec and spec-to-FP annotation tools on three datasets. On average, for rank@[1-5], JESTR outperforms other tools by 23.6%-71.6%. We further demonstrate the strong value of regularization with candidate molecules during training, boosting rank@1 performance by 11.4% and enhancing the model's ability to discern between target and candidate molecules. Through JESTR, we offer a novel promising avenue towards accurate annotation, therefore unlocking valuable insights into the metabolome.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14464', 16)">Copy Link</button>
<div id="copy-message-16" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14466">Learning to Ask: Conversational Product Search via Representation Learning</a></h1>
<p><b>Authors:</b> Jie Zou, Jimmy Xiangji Huang, Zhaochun Ren, Evangelos Kanoulas</p>
<p>Abstract: Online shopping platforms, such as Amazon and AliExpress, are increasingly prevalent in society, helping customers purchase products conveniently. With recent progress in natural language processing, researchers and practitioners shift their focus from traditional product search to conversational product search. Conversational product search enables user-machine conversations and through them collects explicit user feedback that allows to actively clarify the users' product preferences. Therefore, prospective research on an intelligent shopping assistant via conversations is indispensable. Existing publications on conversational product search either model conversations independently from users, queries, and products or lead to a vocabulary mismatch. In this work, we propose a new conversational product search model, ConvPS, to assist users in locating desirable items. The model is first trained to jointly learn the semantic representations of user, query, item, and conversation via a unified generative framework. After learning these representations, they are integrated to retrieve the target items in the latent semantic space. Meanwhile, we propose a set of greedy and explore-exploit strategies to learn to ask the user a sequence of high-performance questions for conversations. Our proposed ConvPS model can naturally integrate the representation learning of the user, query, item, and conversation into a unified generative framework, which provides a promising avenue for constructing accurate and robust conversational product search systems that are flexible and adaptive. Experimental results demonstrate that our ConvPS model significantly outperforms state-of-the-art baselines.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14466', 17)">Copy Link</button>
<div id="copy-message-17" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14468">A Neural Network Training Method Based on Distributed PID Control</a></h1>
<p><b>Authors:</b> Jiang Kun</p>
<p>Abstract: In the previous article, we introduced a neural network framework based on symmetric differential equations. This novel framework exhibits complete symmetry, endowing it with perfect mathematical properties. While we have examined some of the system's mathematical characteristics, a detailed discussion of the network training methodology has not yet been presented. Drawing on the principles of the traditional backpropagation algorithm, this study proposes an alternative training approach that utilizes differential equation signal propagation instead of chain rule derivation. This approach not only preserves the effectiveness of training but also offers enhanced biological interpretability. The foundation of this methodology lies in the system's reversibility, which stems from its inherent symmetry,a key aspect of our research. However, this method alone is insufficient for effective neural network training. To address this, we further introduce a distributed Proportional-Integral-Derivative (PID) control approach, emphasizing its implementation within a closed system. By incorporating this method, we achieved both faster training speeds and improved accuracy. This approach not only offers novel insights into neural network training but also extends the scope of research into control methodologies. To validate its effectiveness, we apply this method to the MNIST dataset, demonstrating its practical utility.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14468', 18)">Copy Link</button>
<div id="copy-message-18" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14469">Popular LLMs Amplify Race and Gender Disparities in Human Mobility</a></h1>
<p><b>Authors:</b> Xinhua Wu, Qi R. Wang</p>
<p>Abstract: As large language models (LLMs) are increasingly applied in areas influencing societal outcomes, it is critical to understand their tendency to perpetuate and amplify biases. This study investigates whether LLMs exhibit biases in predicting human mobility -- a fundamental human behavior -- based on race and gender. Using three prominent LLMs -- GPT-4, Gemini, and Claude -- we analyzed their predictions of visitations to points of interest (POIs) for individuals, relying on prompts that included names with and without explicit demographic details. We find that LLMs frequently reflect and amplify existing societal biases. Specifically, predictions for minority groups were disproportionately skewed, with these individuals being significantly less likely to be associated with wealth-related points of interest (POIs). Gender biases were also evident, as female individuals were consistently linked to fewer career-related POIs compared to their male counterparts. These biased associations suggest that LLMs not only mirror but also exacerbate societal stereotypes, particularly in contexts involving race and gender.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14469', 19)">Copy Link</button>
<div id="copy-message-19" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14471">Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes</a></h1>
<p><b>Authors:</b> Aurora Lithe Roy, Md Kamrul Siam, Nuzhat Noor Islam Prova, Sumaiya Jahan, Abdullah Al Maruf</p>
<p>Abstract: Diabetes, particularly Type 2 diabetes (T2D), poses a substantial global health burden, compounded by its associated complications such as cardiovascular diseases, kidney failure, and vision impairment. Early detection of T2D is critical for improving healthcare outcomes and optimizing resource allocation. In this study, we address the gap in early T2D detection by leveraging machine learning (ML) techniques on gene expression data obtained from T2D patients. Our primary objective was to enhance the accuracy of early T2D detection through advanced ML methodologies and increase the model's trustworthiness using the explainable artificial intelligence (XAI) technique. Analyzing the biological mechanisms underlying T2D through gene expression datasets represents a novel research frontier, relatively less explored in previous studies. While numerous investigations have focused on utilizing clinical and demographic data for T2D prediction, the integration of molecular insights from gene expression datasets offers a unique and promising avenue for understanding the pathophysiology of the disease. By employing six ML classifiers on data sourced from NCBI's Gene Expression Omnibus (GEO), we observed promising performance across all models. Notably, the XGBoost classifier exhibited the highest accuracy, achieving 97%. Our study addresses a notable gap in early T2D detection methodologies, emphasizing the importance of leveraging gene expression data and advanced ML techniques.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14471', 20)">Copy Link</button>
<div id="copy-message-20" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14473">Large Language Model for Qualitative Research -- A Systematic Mapping Study</a></h1>
<p><b>Authors:</b> Cau\~a Ferreira Barros, Bruna Borges Azevedo, Valdemar Vicente Graciano Neto, Mohamad Kassab, Marcos Kalinowski, Hugo Alexandre D. do Nascimento, Michelle C. G. S. P. Bandeira</p>
<p>Abstract: The exponential growth of text-based data in domains such as healthcare, education, and social sciences has outpaced the capacity of traditional qualitative analysis methods, which are time-intensive and prone to subjectivity. Large Language Models (LLMs), powered by advanced generative AI, have emerged as transformative tools capable of automating and enhancing qualitative analysis. This study systematically maps the literature on the use of LLMs for qualitative research, exploring their application contexts, configurations, methodologies, and evaluation metrics. Findings reveal that LLMs are utilized across diverse fields, demonstrating the potential to automate processes traditionally requiring extensive human input. However, challenges such as reliance on prompt engineering, occasional inaccuracies, and contextual limitations remain significant barriers. This research highlights opportunities for integrating LLMs with human expertise, improving model robustness, and refining evaluation methodologies. By synthesizing trends and identifying research gaps, this study aims to guide future innovations in the application of LLMs for qualitative analysis.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14473', 21)">Copy Link</button>
<div id="copy-message-21" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14476">StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model</a></h1>
<p><b>Authors:</b> Zongrong Li, Junhao Xu, Siqin Wang, Yifan Wu, Haiyang Li</p>
<p>Abstract: Geospatial predictions are crucial for diverse fields such as disaster management, urban planning, and public health. Traditional machine learning methods often face limitations when handling unstructured or multi-modal data like street view imagery. To address these challenges, we propose StreetViewLLM, a novel framework that integrates a large language model with the chain-of-thought reasoning and multimodal data sources. By combining street view imagery with geographic coordinates and textual data, StreetViewLLM improves the precision and granularity of geospatial predictions. Using retrieval-augmented generation techniques, our approach enhances geographic information extraction, enabling a detailed analysis of urban environments. The model has been applied to seven global cities, including Hong Kong, Tokyo, Singapore, Los Angeles, New York, London, and Paris, demonstrating superior performance in predicting urban indicators, including population density, accessibility to healthcare, normalized difference vegetation index, building height, and impervious surface. The results show that StreetViewLLM consistently outperforms baseline models, offering improved predictive accuracy and deeper insights into the built environment. This research opens new opportunities for integrating the large language model into urban analytics, decision-making in urban planning, infrastructure management, and environmental monitoring.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14476', 22)">Copy Link</button>
<div id="copy-message-22" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14479">GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning</a></h1>
<p><b>Authors:</b> Yuze Liu, Tingjie Liu, Tiehua Zhang, Youhua Xia, Jinze Wang, Zhishu Shen, Jiong Jin, Fei Richard Yu</p>
<p>Abstract: Large language models (LLMs) have demonstrated impressive success in a wide range of natural language processing (NLP) tasks due to their extensive general knowledge of the world. Recent works discovered that the performance of LLMs is heavily dependent on the input prompt. However, prompt engineering is usually done manually in a trial-and-error fashion, which can be labor-intensive and challenging in order to find the optimal prompts. To address these problems and unleash the utmost potential of LLMs, we propose a novel LLMs-agnostic framework for prompt optimization, namely GRL-Prompt, which aims to automatically construct optimal prompts via reinforcement learning (RL) in an end-to-end manner. To provide structured action/state representation for optimizing prompts, we construct a knowledge graph (KG) that better encodes the correlation between the user query and candidate in-context examples. Furthermore, a policy network is formulated to generate the optimal action by selecting a set of in-context examples in a rewardable order to construct the prompt. Additionally, the embedding-based reward shaping is utilized to stabilize the RL training process. The experimental results show that GRL-Prompt outperforms recent state-of-the-art methods, achieving an average increase of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in BLEU.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14479', 23)">Copy Link</button>
<div id="copy-message-23" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14483">Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat</a></h1>
<p><b>Authors:</b> Roland Daynauth, Christopher Clarke, Krisztian Flautner, Lingjia Tang, Jason Mars</p>
<p>Abstract: Deciding which large language model (LLM) to use is a complex challenge. Pairwise ranking has emerged as a new method for evaluating human preferences for LLMs. This approach entails humans evaluating pairs of model outputs based on a predefined criterion. By collecting these comparisons, a ranking can be constructed using methods such as Elo. However, applying these algorithms as constructed in the context of LLM evaluation introduces several challenges. In this paper, we explore the effectiveness of ranking systems for head-to-head comparisons of LLMs. We formally define a set of fundamental principles for effective ranking and conduct a series of extensive evaluations on the robustness of several ranking algorithms in the context of LLMs. Our analysis uncovers key insights into the factors that affect ranking accuracy and efficiency, offering guidelines for selecting the most appropriate methods based on specific evaluation contexts and resource constraints.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14483', 24)">Copy Link</button>
<div id="copy-message-24" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14484">Robust Planning with Compound LLM Architectures: An LLM-Modulo Approach</a></h1>
<p><b>Authors:</b> Atharva Gundawar, Karthik Valmeekam, Mudit Verma, Subbarao Kambhampati</p>
<p>Abstract: Previous work has attempted to boost Large Language Model (LLM) performance on planning and scheduling tasks through a variety of prompt engineering techniques. While these methods can work within the distributions tested, they are neither robust nor predictable. This limitation can be addressed through compound LLM architectures where LLMs work in conjunction with other components to ensure reliability. In this paper, we present a technical evaluation of a compound LLM architecture--the LLM-Modulo framework. In this framework, an LLM is paired with a complete set of sound verifiers that validate its output, re-prompting it if it fails. This approach ensures that the system can never output any fallacious output, and therefore that every output generated is guaranteed correct--something previous techniques have not been able to claim. Our results, evaluated across four scheduling domains, demonstrate significant performance gains with the LLM-Modulo framework using various models. Additionally, we explore modifications to the base configuration of the framework and assess their impact on overall system performance.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14484', 25)">Copy Link</button>
<div id="copy-message-25" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14485">Mediating Modes of Thought: LLM&#x27;s for design scripting</a></h1>
<p><b>Authors:</b> Moritz Rietschel, Fang Guo, Kyle Steinfeld</p>
<p>Abstract: Here is an updated version of your abstract, cleaned for submission to arXiv with potential "bad characters" corrected to conform to ASCII standards:
  Architects adopt visual scripting and parametric design tools to explore more expansive design spaces (Coates, 2010), refine their thinking about the geometric logic of their design (Woodbury, 2010), and overcome conventional software limitations (Burry, 2011). Despite two decades of effort to make design scripting more accessible, a disconnect between a designer's free ways of thinking and the rigidity of algorithms remains (Burry, 2011). Recent developments in Large Language Models (LLMs) suggest this might soon change, as LLMs encode a general understanding of human context and exhibit the capacity to produce geometric logic. This project speculates that if LLMs can effectively mediate between user intent and algorithms, they become a powerful tool to make scripting in design more widespread and fun. We explore if such systems can interpret natural language prompts to assemble geometric operations relevant to computational design scripting. In the system, multiple layers of LLM agents are configured with specific context to infer the user intent and construct a sequential logic. Given a user's high-level text prompt, a geometric description is created, distilled into a sequence of logic operations, and mapped to software-specific commands. The completed script is constructed in the user's visual programming interface. The system succeeds in generating complete visual scripts up to a certain complexity but fails beyond this complexity threshold. It shows how LLMs can make design scripting much more aligned with human creativity and thought. Future research should explore conversational interactions, expand to multimodal inputs and outputs, and assess the performance of these tools.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14485', 26)">Copy Link</button>
<div id="copy-message-26" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14486">The Impossible Test: A 2024 Unsolvable Dataset and A Chance for an AGI Quiz</a></h1>
<p><b>Authors:</b> David Noever, Forrest McKee</p>
<p>Abstract: This research introduces a novel evaluation framework designed to assess large language models' (LLMs) ability to acknowledge uncertainty on 675 fundamentally unsolvable problems. Using a curated dataset of graduate-level grand challenge questions with intentionally unknowable answers, we evaluated twelve state-of-the-art LLMs, including both open and closed-source models, on their propensity to admit ignorance rather than generate plausible but incorrect responses. The best models scored in 62-68% accuracy ranges for admitting the problem solution was unknown in fields ranging from biology to philosophy and mathematics. We observed an inverse relationship between problem difficulty and model accuracy, with GPT-4 demonstrating higher rates of uncertainty acknowledgment on more challenging problems (35.8%) compared to simpler ones (20.0%). This pattern indicates that models may be more prone to generate speculative answers when problems appear more tractable. The study also revealed significant variations across problem categories, with models showing difficulty in acknowledging uncertainty in invention and NP-hard problems while performing relatively better on philosophical and psychological challenges. These results contribute to the growing body of research on artificial general intelligence (AGI) assessment by highlighting the importance of uncertainty recognition as a critical component of future machine intelligence evaluation. This impossibility test thus extends previous theoretical frameworks for universal intelligence testing by providing empirical evidence of current limitations in LLMs' ability to recognize their own knowledge boundaries, suggesting new directions for improving model training architectures and evaluation approaches.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14486', 27)">Copy Link</button>
<div id="copy-message-27" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14487">Ensuring Safety and Trust: Analyzing the Risks of Large Language Models in Medicine</a></h1>
<p><b>Authors:</b> Yifan Yang, Qiao Jin, Robert Leaman, Xiaoyu Liu, Guangzhi Xiong, Maame Sarfo-Gyamfi, Changlin Gong, Santiago Ferri\`ere-Steinert, W. John Wilbur, Xiaojun Li, Jiaxin Yuan, Bang An, Kelvin S. Castro, Francisco Erramuspe \'Alvarez, Mat\'ias Stockle, Aidong Zhang, Furong Huang, Zhiyong Lu</p>
<p>Abstract: The remarkable capabilities of Large Language Models (LLMs) make them increasingly compelling for adoption in real-world healthcare applications. However, the risks associated with using LLMs in medical applications have not been systematically characterized. We propose using five key principles for safe and trustworthy medical AI: Truthfulness, Resilience, Fairness, Robustness, and Privacy, along with ten specific aspects. Under this comprehensive framework, we introduce a novel MedGuard benchmark with 1,000 expert-verified questions. Our evaluation of 11 commonly used LLMs shows that the current language models, regardless of their safety alignment mechanisms, generally perform poorly on most of our benchmarks, particularly when compared to the high performance of human physicians. Despite recent reports indicate that advanced LLMs like ChatGPT can match or even exceed human performance in various medical tasks, this study underscores a significant safety gap, highlighting the crucial need for human oversight and the implementation of AI safety guardrails.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14487', 28)">Copy Link</button>
<div id="copy-message-28" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14489">GhostRNN: Reducing State Redundancy in RNN with Cheap Operations</a></h1>
<p><b>Authors:</b> Hang Zhou, Xiaoxu Zheng, Yunhe Wang, Michael Bi Mi, Deyi Xiong, Kai Han</p>
<p>Abstract: Recurrent neural network (RNNs) that are capable of modeling long-distance dependencies are widely used in various speech tasks, eg., keyword spotting (KWS) and speech enhancement (SE). Due to the limitation of power and memory in low-resource devices, efficient RNN models are urgently required for real-world applications. In this paper, we propose an efficient RNN architecture, GhostRNN, which reduces hidden state redundancy with cheap operations. In particular, we observe that partial dimensions of hidden states are similar to the others in trained RNN models, suggesting that redundancy exists in specific RNNs. To reduce the redundancy and hence computational cost, we propose to first generate a few intrinsic states, and then apply cheap operations to produce ghost states based on the intrinsic states. Experiments on KWS and SE tasks demonstrate that the proposed GhostRNN significantly reduces the memory usage (~40%) and computation cost while keeping performance similar.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14489', 29)">Copy Link</button>
<div id="copy-message-29" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14491">A Survey on Human-Centric LLMs</a></h1>
<p><b>Authors:</b> Jing Yi Wang, Nicholas Sukiennik, Tong Li, Weikang Su, Qianyue Hao, Jingbo Xu, Zihan Huang, Fengli Xu, Yong Li</p>
<p>Abstract: The rapid evolution of large language models (LLMs) and their capacity to simulate human cognition and behavior has given rise to LLM-based frameworks and tools that are evaluated and applied based on their ability to perform tasks traditionally performed by humans, namely those involving cognition, decision-making, and social interaction. This survey provides a comprehensive examination of such human-centric LLM capabilities, focusing on their performance in both individual tasks (where an LLM acts as a stand-in for a single human) and collective tasks (where multiple LLMs coordinate to mimic group dynamics). We first evaluate LLM competencies across key areas including reasoning, perception, and social cognition, comparing their abilities to human-like skills. Then, we explore real-world applications of LLMs in human-centric domains such as behavioral science, political science, and sociology, assessing their effectiveness in replicating human behaviors and interactions. Finally, we identify challenges and future research directions, such as improving LLM adaptability, emotional intelligence, and cultural sensitivity, while addressing inherent biases and enhancing frameworks for human-AI collaboration. This survey aims to provide a foundational understanding of LLMs from a human-centric perspective, offering insights into their current capabilities and potential for future development.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14491', 30)">Copy Link</button>
<div id="copy-message-30" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14497">Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning</a></h1>
<p><b>Authors:</b> Hang Zhou, Yehui Tang, Haochen Qin, Yujie Yang, Renren Jin, Deyi Xiong, Kai Han, Yunhe Wang</p>
<p>Abstract: The efficacy of large language models (LLMs) on downstream tasks usually hinges on instruction tuning, which relies critically on the quality of training data. Unfortunately, collecting high-quality and diverse data is both expensive and time-consuming. To mitigate this issue, we propose a novel Star-Agents framework, which automates the enhancement of data quality across datasets through multi-agent collaboration and assessment. The framework adopts a three-pronged strategy. It initially generates diverse instruction data with multiple LLM agents through a bespoke sampling method. Subsequently, the generated data undergo a rigorous evaluation using a dual-model method that assesses both difficulty and quality. Finaly, the above process evolves in a dynamic refinement phase, where more effective LLMs are prioritized, enhancing the overall data quality. Our empirical studies, including instruction tuning experiments with models such as Pythia and LLaMA, demonstrate the effectiveness of the proposed framework. Optimized datasets have achieved substantial improvements, with an average increase of 12% and notable gains in specific metrics, such as a 40% improvement in Fermi, as evidenced by benchmarks like MT-bench, Vicuna bench, and WizardLM testset.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14497', 31)">Copy Link</button>
<div id="copy-message-31" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14499">Understanding World or Predicting Future? A Comprehensive Survey of World Models</a></h1>
<p><b>Authors:</b> Jingtao Ding, Yunke Zhang, Yu Shang, Yuheng Zhang, Zefang Zong, Jie Feng, Yuan Yuan, Hongyuan Su, Nian Li, Nicholas Sukiennik, Fengli Xu, Yong Li</p>
<p>Abstract: The concept of world models has garnered significant attention due to advancements in multimodal large language models such as GPT-4 and video generation models such as Sora, which are central to the pursuit of artificial general intelligence. This survey offers a comprehensive review of the literature on world models. Generally, world models are regarded as tools for either understanding the present state of the world or predicting its future dynamics. This review presents a systematic categorization of world models, emphasizing two primary functions: (1) constructing internal representations to understand the mechanisms of the world, and (2) predicting future states to simulate and guide decision-making. Initially, we examine the current progress in these two categories. We then explore the application of world models in key domains, including autonomous driving, robotics, and social simulacra, with a focus on how each domain utilizes these aspects. Finally, we outline key challenges and provide insights into potential future research directions.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14499', 32)">Copy Link</button>
<div id="copy-message-32" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14500">Exploring Accuracy-Fairness Trade-off in Large Language Models</a></h1>
<p><b>Authors:</b> Qingquan Zhang, Qiqi Duan, Bo Yuan, Yuhui Shi, Jialin Liu</p>
<p>Abstract: Large Language Models (LLMs) have made significant strides in the field of artificial intelligence, showcasing their ability to interact with humans and influence human cognition through information dissemination. However, recent studies have brought to light instances of bias inherent within these LLMs, presenting a critical issue that demands attention. In our research, we delve deeper into the intricate challenge of harmonising accuracy and fairness in the enhancement of LLMs. While improving accuracy can indeed enhance overall LLM performance, it often occurs at the expense of fairness. Overemphasising optimisation of one metric invariably leads to a significant degradation of the other. This underscores the necessity of taking into account multiple considerations during the design and optimisation phases of LLMs. Therefore, we advocate for reformulating the LLM training process as a multi-objective learning task. Our investigation reveals that multi-objective evolutionary learning (MOEL) methodologies offer promising avenues for tackling this challenge. Our MOEL framework enables the simultaneous optimisation of both accuracy and fairness metrics, resulting in a Pareto-optimal set of LLMs. In summary, our study sheds valuable lights on the delicate equilibrium between accuracy and fairness within LLMs, which is increasingly significant for their real-world applications. By harnessing MOEL, we present a promising pathway towards fairer and more efficacious AI technologies.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14500', 33)">Copy Link</button>
<div id="copy-message-33" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14502">Global Challenge for Safe and Secure LLMs Track 1</a></h1>
<p><b>Authors:</b> Xiaojun Jia, Yihao Huang, Yang Liu, Peng Yan Tan, Weng Kuan Yau, Mun-Thye Mak, Xin Ming Sim, Wee Siong Ng, See Kiong Ng, Hanqing Liu, Lifeng Zhou, Huanqian Yan, Xiaobing Sun, Wei Liu, Long Wang, Yiming Qian, Yong Liu, Junxiao Yang, Zhexin Zhang, Leqi Lei, Renmiao Chen, Yida Lu, Shiyao Cui, Zizhou Wang, Shaohua Li, Yan Wang, Rick Siow Mong Goh, Liangli Zhen, Yingjie Zhang, Zhe Zhao</p>
<p>Abstract: This paper introduces the Global Challenge for Safe and Secure Large Language Models (LLMs), a pioneering initiative organized by AI Singapore (AISG) and the CyberSG R&D Programme Office (CRPO) to foster the development of advanced defense mechanisms against automated jailbreaking attacks. With the increasing integration of LLMs in critical sectors such as healthcare, finance, and public administration, ensuring these models are resilient to adversarial attacks is vital for preventing misuse and upholding ethical standards. This competition focused on two distinct tracks designed to evaluate and enhance the robustness of LLM security frameworks. Track 1 tasked participants with developing automated methods to probe LLM vulnerabilities by eliciting undesirable responses, effectively testing the limits of existing safety protocols within LLMs. Participants were challenged to devise techniques that could bypass content safeguards across a diverse array of scenarios, from offensive language to misinformation and illegal activities. Through this process, Track 1 aimed to deepen the understanding of LLM vulnerabilities and provide insights for creating more resilient models.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14502', 34)">Copy Link</button>
<div id="copy-message-34" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14503">Planning-Driven Programming: A Large Language Model Programming Workflow</a></h1>
<p><b>Authors:</b> Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger</p>
<p>Abstract: The strong performance of large language models (LLMs) on natural language processing tasks raises extensive discussion on their application to code generation. Recent work suggests multiple sampling approaches to improve initial code generation accuracy or program repair approaches to refine the code. However, these methods suffer from LLMs' inefficiencies and limited reasoning capacity. In this work, we propose an LLM programming workflow (LPW) designed to improve both initial code generation and subsequent refinements within a structured two-phase workflow. Specifically, in the solution generation phase, the LLM first outlines a solution plan that decomposes the problem into manageable sub-problems and then verifies the generated solution plan through visible test cases. Subsequently, in the code implementation phase, the LLM initially drafts a code according to the solution plan and its verification. If the generated code fails the visible tests, the plan verification serves as the intended natural language solution to inform the refinement process for correcting bugs. We further introduce SLPW, a sampling variant of LPW, which initially generates multiple solution plans and plan verifications, produces a program for each plan and its verification, and refines each program as necessary until one successfully passes the visible tests. Compared to the state-of-the-art methods across various existing LLMs, our experimental results show that LPW significantly improves the Pass@1 accuracy by up to 16.4% on well-established text-to-code generation benchmarks, especially with a notable improvement of around 10% on challenging benchmarks. Additionally, SLPW demonstrates up to a 5.6% improvement over LPW and sets new state-of-the-art Pass@1 accuracy on various benchmarks, e.g., 98.2% on HumanEval, 84.8% on MBPP, 64.0% on APPS, and 35.3% on CodeContest, using GPT-4o as the backbone.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14503', 35)">Copy Link</button>
<div id="copy-message-35" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14507">FuseGPT: Learnable Layers Fusion of Generative Pre-trained Transformers</a></h1>
<p><b>Authors:</b> Zehua Pei, Hui-Ling Zhen, Xianzhi Yu, Sinno Jialin Pan, Mingxuan Yuan, Bei Yu</p>
<p>Abstract: Generative Pre-trained Transformers (GPTs) have demonstrated remarkable performance across diverse domains through the extensive scaling of model parameters. Recent works observe the redundancy across the transformer blocks and develop compression methods by structured pruning of the unimportant blocks. However, such straightforward elimination will always provide irreversible performance degradation. In this paper, we propose FuseGPT, a novel methodology to recycle the pruned transformer blocks to further recover the model performance. Firstly we introduce a new importance detection metric, Macro Influence (MI), to detect the long-term influence of each transformer block by calculating their loss of information after removal. Then we propose group-level layers fusion, which adopts the parameters in layers of the unimportant blocks and injects them into the corresponding layers inside the neighboring blocks. The fusion is not one-off but through iterative parameter updates by lightweight group-level fine-tuning. Specifically, these injected parameters are frozen but weighted with learnable rank decomposition matrices to reduce the overhead during fine-tuning. Our approach not only works well on large language models but also on large multimodal models. The experiments have shown that, by using modest amounts of data, FuseGPT can outperform previous works in both perplexity and zero-shot task performance.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14507', 36)">Copy Link</button>
<div id="copy-message-36" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14511">Variational Autoencoders for Efficient Simulation-Based Inference</a></h1>
<p><b>Authors:</b> Mayank Nautiyal, Andrey Shternshis, Andreas Hellander, Prashant Singh</p>
<p>Abstract: We present a generative modeling approach based on the variational inference framework for likelihood-free simulation-based inference. The method leverages latent variables within variational autoencoders to efficiently estimate complex posterior distributions arising from stochastic simulations. We explore two variations of this approach distinguished by their treatment of the prior distribution. The first model adapts the prior based on observed data using a multivariate prior network, enhancing generalization across various posterior queries. In contrast, the second model utilizes a standard Gaussian prior, offering simplicity while still effectively capturing complex posterior distributions. We demonstrate the efficacy of these models on well-established benchmark problems, achieving results comparable to flow-based approaches while maintaining computational efficiency and scalability.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14511', 37)">Copy Link</button>
<div id="copy-message-37" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14515">Are Anomaly Scores Telling the Whole Story? A Benchmark for Multilevel Anomaly Detection</a></h1>
<p><b>Authors:</b> Tri Cao, Minh-Huy Trinh, Ailin Deng, Quoc-Nam Nguyen, Khoa Duong, Ngai-Man Cheung, Bryan Hooi</p>
<p>Abstract: Anomaly detection (AD) is a machine learning task that identifies anomalies by learning patterns from normal training data. In many real-world scenarios, anomalies vary in severity, from minor anomalies with little risk to severe abnormalities requiring immediate attention. However, existing models primarily operate in a binary setting, and the anomaly scores they produce are usually based on the deviation of data points from normal data, which may not accurately reflect practical severity. In this paper, we address this gap by making three key contributions. First, we propose a novel setting, Multilevel AD (MAD), in which the anomaly score represents the severity of anomalies in real-world applications, and we highlight its diverse applications across various domains. Second, we introduce a novel benchmark, MAD-Bench, that evaluates models not only on their ability to detect anomalies, but also on how effectively their anomaly scores reflect severity. This benchmark incorporates multiple types of baselines and real-world applications involving severity. Finally, we conduct a comprehensive performance analysis on MAD-Bench. We evaluate models on their ability to assign severity-aligned scores, investigate the correspondence between their performance on binary and multilevel detection, and study their robustness. This analysis offers key insights into improving AD models for practical severity alignment. The code framework and datasets used for the benchmark will be made publicly available.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14515', 38)">Copy Link</button>
<div id="copy-message-38" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14520">Open Challenges in the Formal Verification of Autonomous Driving</a></h1>
<p><b>Authors:</b> Paolo Burgio (University of Modena,Reggio Emilia), Angelo Ferrando (University of Modena,Reggio Emilia), Marco Villani (University of Modena,Reggio Emilia)</p>
<p>Abstract: In the realm of autonomous driving, the development and integration of highly complex and heterogeneous systems are standard practice. Modern vehicles are not monolithic systems; instead, they are composed of diverse hardware components, each running its own software systems. An autonomous vehicle comprises numerous independent components, often developed by different and potentially competing companies. This diversity poses significant challenges for the certification process, as it necessitates certifying components that may not disclose their internal behaviour (black-boxes). In this paper, we present a real-world case study of an autonomous driving system, identify key open challenges associated with its development and integration, and explore how formal verification techniques can address these challenges to ensure system reliability and safety.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14520', 39)">Copy Link</button>
<div id="copy-message-39" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14550">The importance of the clustering model to detect new types of intrusion in data traffic</a></h1>
<p><b>Authors:</b> Noor Saud Abd, Kamel Karoui</p>
<p>Abstract: In the current digital age, the volume of data generated by various cyber activities has become enormous and is constantly increasing. The data may contain valuable insights that can be harnessed to improve cyber security measures. However, much of this data is unclassified and qualitative, which poses significant challenges to traditional analysis methods. Clustering facilitates the identification of hidden patterns and structures in data through grouping similar data points, which makes it simpler to identify and address threats. Clustering can be defined as a data mining (DM) approach, which uses similarity calculations for dividing a data set into several categories. Hierarchical, density-based, along with partitioning clustering algorithms are typical. The presented work use K-means algorithm, which is a popular clustering technique. Utilizing K-means algorithm, we worked with two different types of data: first, we gathered data with the use of XG-boost algorithm following completing the aggregation with K-means algorithm. Data was gathered utilizing Kali Linux environment, cicflowmeter traffic, and Putty Software tools with the use of diverse and simple attacks. The concept could assist in identifying new attack types, which are distinct from the known attacks, and labeling them based on the characteristics they will exhibit, as the dynamic nature regarding cyber threats means that new attack types often emerge, for which labeled data might not yet exist. The model counted the attacks and assigned numbers to each one of them. Secondly, We tried the same work on the ready data inside the Kaggle repository called (Intrusion Detection in Internet of Things Network), and the clustering model worked well and detected the number of attacks correctly as shown in the results section.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14550', 40)">Copy Link</button>
<div id="copy-message-40" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14571">Assessment of LLM Responses to End-user Security Questions</a></h1>
<p><b>Authors:</b> Vijay Prakash, Kevin Lee, Arkaprabha Bhattacharya, Danny Yuxing Huang, Jessica Staddon</p>
<p>Abstract: Answering end user security questions is challenging. While large language models (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have shown promise in answering a variety of questions outside of security. We studied LLM performance in the area of end user security by qualitatively evaluating 3 popular LLMs on 900 systematically collected end user security questions.
  While LLMs demonstrate broad generalist ``knowledge'' of end user security information, there are patterns of errors and limitations across LLMs consisting of stale and inaccurate answers, and indirect or unresponsive communication styles, all of which impacts the quality of information received. Based on these patterns, we suggest directions for model improvement and recommend user strategies for interacting with LLMs when seeking assistance with security.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14571', 41)">Copy Link</button>
<div id="copy-message-41" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14592">G-RAG: Knowledge Expansion in Material Science</a></h1>
<p><b>Authors:</b> Radeen Mostafa, Mirza Nihal Baig, Mashaekh Tausif Ehsan, Jakir Hasan</p>
<p>Abstract: In the field of Material Science, effective information retrieval systems are essential for facilitating research. Traditional Retrieval-Augmented Generation (RAG) approaches in Large Language Models (LLMs) often encounter challenges such as outdated information, hallucinations, limited interpretability due to context constraints, and inaccurate retrieval. To address these issues, Graph RAG integrates graph databases to enhance the retrieval process. Our proposed method processes Material Science documents by extracting key entities (referred to as MatIDs) from sentences, which are then utilized to query external Wikipedia knowledge bases (KBs) for additional relevant information. We implement an agent-based parsing technique to achieve a more detailed representation of the documents. Our improved version of Graph RAG called G-RAG further leverages a graph database to capture relationships between these entities, improving both retrieval accuracy and contextual understanding. This enhanced approach demonstrates significant improvements in performance for domains that require precise information retrieval, such as Material Science.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14592', 42)">Copy Link</button>
<div id="copy-message-42" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14593">A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry</a></h1>
<p><b>Authors:</b> Larry Schester, Luis E. Ortiz</p>
<p>Abstract: Vehicles today can drive themselves on highways and driverless robotaxis operate in major cities, with more sophisticated levels of autonomous driving expected to be available and become more common in the future. Yet, technically speaking, so-called "Level 5" (L5) operation, corresponding to full autonomy, has not been achieved. For that to happen, functions such as fully autonomous highway ramp entry must be available, and provide provably safe, and reliably robust behavior to enable full autonomy. We present a systematic study of a highway ramp function that controls the vehicles forward-moving actions to minimize collisions with the stream of highway traffic into which a merging (ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to this problem and study the use of controllers based on deep reinforcement learning (DRL). The virtual environment of the MA DRL uses self-play with simulated data where merging vehicles safely learn to control longitudinal position during a taper-type merge. The work presented in this paper extends existing work by studying the interaction of more than two vehicles (agents) and does so by systematically expanding the road scene with additional traffic and ego vehicles. While previous work on the two-vehicle setting established that collision-free controllers are theoretically impossible in fully decentralized, non-coordinated environments, we empirically show that controllers learned using our approach are nearly ideal when measured against idealized optimal controllers.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14593', 43)">Copy Link</button>
<div id="copy-message-43" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14612">Exploiting Boosting in Hyperdimensional Computing for Enhanced Reliability in Healthcare</a></h1>
<p><b>Authors:</b> SungHeon Jeong, Hamza Errahmouni Barkam, Sanggeon Yun, Yeseong Kim, Shaahin Angizi, Mohsen Imani</p>
<p>Abstract: Hyperdimensional computing (HDC) enables efficient data encoding and processing in high-dimensional space, benefiting machine learning and data analysis. However, underutilization of these spaces can lead to overfitting and reduced model reliability, especially in data-limited systems a critical issue in sectors like healthcare that demand robustness and consistent performance. We introduce BoostHD, an approach that applies boosting algorithms to partition the hyperdimensional space into subspaces, creating an ensemble of weak learners. By integrating boosting with HDC, BoostHD enhances performance and reliability beyond existing HDC methods. Our analysis highlights the importance of efficient utilization of hyperdimensional spaces for improved model performance. Experiments on healthcare datasets show that BoostHD outperforms state-of-the-art methods. On the WESAD dataset, it achieved an accuracy of 98.37%, surpassing Random Forest, XGBoost, and OnlineHD. BoostHD also demonstrated superior inference efficiency and stability, maintaining high accuracy under data imbalance and noise. In person-specific evaluations, it achieved an average accuracy of 96.19%, outperforming other models. By addressing the limitations of both boosting and HDC, BoostHD expands the applicability of HDC in critical domains where reliability and precision are paramount.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14612', 44)">Copy Link</button>
<div id="copy-message-44" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14625">Predictive Analytics of Air Alerts in the Russian-Ukrainian War</a></h1>
<p><b>Authors:</b> Demian Pavlyshenko, Bohdan Pavlyshenko</p>
<p>Abstract: The paper considers exploratory data analysis and approaches in predictive analytics for air alerts during the Russian-Ukrainian war which broke out on Feb 24, 2022. The results illustrate that alerts in regions correlate with one another and have geospatial patterns which make it feasible to build a predictive model which predicts alerts that are expected to take place in a certain region within a specified time period. The obtained results show that the alert status in a particular region is highly dependable on the features of its adjacent regions. Seasonality features like hours, days of a week and months are also crucial in predicting the target variable. Some regions highly rely on the time feature which equals to a number of days from the initial date of the dataset. From this, we can deduce that the air alert pattern changes throughout the time.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14625', 45)">Copy Link</button>
<div id="copy-message-45" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14626">Unveiling the Hidden: A Comprehensive Evaluation of Underwater Image Enhancement and Its Impact on Object Detection</a></h1>
<p><b>Authors:</b> Ali Awad (Michigan Technological University), Ashraf Saleem (Michigan Technological University), Sidike Paheding (Fairfield University), Evan Lucas (Michigan Technological University), Serein Al-Ratrout (Michigan Technological University), Timothy C. Havens (Michigan Technological University)</p>
<p>Abstract: Underwater imagery often suffers from severe degradation that results in low visual quality and object detection performance. This work aims to evaluate state-of-the-art image enhancement models, investigate their impact on underwater object detection, and explore their potential to improve detection performance. To this end, we selected representative underwater image enhancement models covering major enhancement categories and applied them separately to two recent datasets: 1) the Real-World Underwater Object Detection Dataset (RUOD), and 2) the Challenging Underwater Plant Detection Dataset (CUPDD). Following this, we conducted qualitative and quantitative analyses on the enhanced images and developed a quality index (Q-index) to compare the quality distribution of the original and enhanced images. Subsequently, we compared the performance of several YOLO-NAS detection models that are separately trained and tested on the original and enhanced image sets. Then, we performed a correlation study to examine the relationship between enhancement metrics and detection performance. We also analyzed the inference results from the trained detectors presenting cases where enhancement increased the detection performance as well as cases where enhancement revealed missed objects by human annotators. This study suggests that although enhancement generally deteriorates the detection performance, it can still be harnessed in some cases for increased detection performance and more accurate human annotation.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14626', 46)">Copy Link</button>
<div id="copy-message-46" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14627">Generative AI for Music and Audio</a></h1>
<p><b>Authors:</b> Hao-Wen Dong</p>
<p>Abstract: Generative AI has been transforming the way we interact with technology and consume content. In the next decade, AI technology will reshape how we create audio content in various media, including music, theater, films, games, podcasts, and short videos. In this dissertation, I introduce the three main directions of my research centered around generative AI for music and audio: 1) multitrack music generation, 2) assistive music creation tools, and 3) multimodal learning for audio and music. Through my research, I aim to answer the following two fundamental questions: 1) How can AI help professionals or amateurs create music and audio content? 2) Can AI learn to create music in a way similar to how humans learn music? My long-term goal is to lower the barrier of entry for music composition and democratize audio content creation</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14627', 47)">Copy Link</button>
<div id="copy-message-47" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14633">Evaluating Representational Similarity Measures from the Lens of Functional Correspondence</a></h1>
<p><b>Authors:</b> Yiqing Bo, Ansh Soni, Sudhanshu Srivastava, Meenakshi Khosla</p>
<p>Abstract: Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain -- spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods -- we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14633', 48)">Copy Link</button>
<div id="copy-message-48" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14652">Social Media Algorithms Can Shape Affective Polarization via Exposure to Antidemocratic Attitudes and Partisan Animosity</a></h1>
<p><b>Authors:</b> Tiziano Piccardi, Martin Saveski, Chenyan Jia, Jeffrey T. Hancock, Jeanne L. Tsai, Michael Bernstein</p>
<p>Abstract: There is widespread concern about the negative impacts of social media feed ranking algorithms on political polarization. Leveraging advancements in large language models (LLMs), we develop an approach to re-rank feeds in real-time to test the effects of content that is likely to polarize: expressions of antidemocratic attitudes and partisan animosity (AAPA). In a preregistered 10-day field experiment on X/Twitter with 1,256 consented participants, we increase or decrease participants' exposure to AAPA in their algorithmically curated feeds. We observe more positive outparty feelings when AAPA exposure is decreased and more negative outparty feelings when AAPA exposure is increased. Exposure to AAPA content also results in an immediate increase in negative emotions, such as sadness and anger. The interventions do not significantly impact traditional engagement metrics such as re-post and favorite rates. These findings highlight a potential pathway for developing feed algorithms that mitigate affective polarization by addressing content that undermines the shared values required for a healthy democracy.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14652', 49)">Copy Link</button>
<div id="copy-message-49" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14654">Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective</a></h1>
<p><b>Authors:</b> Jinming Xing, Ruilin Xing, Yan Sun</p>
<p>Abstract: Large Language Models (LLMs) have revolutionized natural language processing (NLP) by delivering state-of-the-art performance across a variety of tasks. Among these, Transformer-based models like BERT and GPT rely on pooling layers to aggregate token-level embeddings into sentence-level representations. Common pooling mechanisms such as Mean, Max, and Weighted Sum play a pivotal role in this aggregation process. Despite their widespread use, the comparative performance of these strategies on different LLM architectures remains underexplored. To address this gap, this paper investigates the effects of these pooling mechanisms on two prominent LLM families -- BERT and GPT, in the context of sentence-level sentiment analysis. Comprehensive experiments reveal that each pooling mechanism exhibits unique strengths and weaknesses depending on the task's specific requirements. Our findings underline the importance of selecting pooling methods tailored to the demands of particular applications, prompting a re-evaluation of common assumptions regarding pooling operations. By offering actionable insights, this study contributes to the optimization of LLM-based models for downstream tasks.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14654', 50)">Copy Link</button>
<div id="copy-message-50" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14672">Multiverse of Greatness: Generating Story Branches with LLMs</a></h1>
<p><b>Authors:</b> Pittawat Taveekitworachai, Chollakorn Nimpattanavong, Mustafa Can Gursesli, Antonio Lanata, Andrea Guazzini, Ruck Thawonmas</p>
<p>Abstract: This paper presents Dynamic Context Prompting/Programming (DCP/P), a novel framework for interacting with LLMs to generate graph-based content with a dynamic context window history. While there is an existing study utilizing LLMs to generate a visual novel game, the previous study involved a manual process of output extraction and did not provide flexibility in generating a longer, coherent story. We evaluate DCP/P against our baseline, which does not provide context history to an LLM and only relies on the initial story data. Through objective evaluation, we show that simply providing the LLM with a summary leads to a subpar story compared to additionally providing the LLM with the proper context of the story. We also provide an extensive qualitative analysis and discussion. We qualitatively examine the quality of the objectively best-performing generated game from each approach. In addition, we examine biases in word choices and word sentiment of the generated content. We find a consistent observation with previous studies that LLMs are biased towards certain words, even with a different LLM family. Finally, we provide a comprehensive discussion on opportunities for future studies.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14672', 51)">Copy Link</button>
<div id="copy-message-51" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14684">Cross Group Attention and Group-wise Rolling for Multimodal Medical Image Synthesis</a></h1>
<p><b>Authors:</b> Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Linda Wei, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang</p>
<p>Abstract: Multimodal MR image synthesis aims to generate missing modality image by fusing and mapping a few available MRI data. Most existing approaches typically adopt an image-to-image translation scheme. However, these methods often suffer from sub-optimal performance due to the spatial misalignment between different modalities while they are typically treated as input channels. Therefore, in this paper, we propose an Adaptive Group-wise Interaction Network (AGI-Net) that explores both inter-modality and intra-modality relationships for multimodal MR image synthesis. Specifically, groups are first pre-defined along the channel dimension and then we perform an adaptive rolling for the standard convolutional kernel to capture inter-modality spatial correspondences. At the same time, a cross-group attention module is introduced to fuse information across different channel groups, leading to better feature representation. We evaluated the effectiveness of our model on the publicly available IXI and BraTS2023 datasets, where the AGI-Net achieved state-of-the-art performance for multimodal MR image synthesis. Code will be released.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14684', 52)">Copy Link</button>
<div id="copy-message-52" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14696">Quantum Hamiltonian Descent for Graph Partition</a></h1>
<p><b>Authors:</b> Jinglei Cheng, Ruilin Zhou, Yuhang Gan, Chen Qian, Junyu Liu</p>
<p>Abstract: We introduce Quantum Hamiltonian Descent as a novel approach to solve the graph partition problem. By reformulating graph partition as a Quadratic Unconstrained Binary Optimization (QUBO) problem, we leverage QHD's quantum-inspired dynamics to identify optimal community structures. Our method implements a multi-level refinement strategy that alternates between QUBO formulation and QHD optimization to iteratively improve partition quality. Experimental results demonstrate that our QHD-based approach achieves superior modularity scores (up to 5.49\%) improvement with reduced computational overhead compared to traditional optimization methods. This work establishes QHD as an effective quantum-inspired framework for tackling graph partition challenges in large-scale networks.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14696', 53)">Copy Link</button>
<div id="copy-message-53" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14698">Improving Mathematical Reasoning Capabilities of Small Language Models via Feedback-Driven Distillation</a></h1>
<p><b>Authors:</b> Xunyu Zhu, Jian Li, Can Ma, Weiping Wang</p>
<p>Abstract: Large Language Models (LLMs) demonstrate exceptional reasoning capabilities, often achieving state-of-the-art performance in various tasks. However, their substantial computational and memory demands, due to billions of parameters, hinder deployment in resource-constrained environments. A promising solution is knowledge distillation, where LLMs transfer reasoning capabilities to Small Language Models (SLMs, $\le$ 1B parameters), enabling wider deployment on low-resource devices. Existing methods primarily focus on generating high-quality reasoning rationales for distillation datasets but often neglect the critical role of data quantity and quality. To address these challenges, we propose a Feedback-Driven Distillation (FDD) framework to enhance SLMs' mathematical reasoning capabilities. In the initialization stage, a distillation dataset is constructed by prompting LLMs to pair mathematical problems with corresponding reasoning rationales. We classify problems into easy and hard categories based on SLM performance. For easy problems, LLMs generate more complex variations, while for hard problems, new questions of similar complexity are synthesized. In addition, we propose a multi-round distillation paradigm to iteratively enrich the distillation datasets, thereby progressively improving the mathematical reasoning abilities of SLMs. Experimental results demonstrate that our method can make SLMs achieve SOTA mathematical reasoning performance.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14698', 54)">Copy Link</button>
<div id="copy-message-54" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14708">Understanding LLM Embeddings for Regression</a></h1>
<p><b>Authors:</b> Eric Tang, Bangding Yang, Xingyou Song</p>
<p>Abstract: With the rise of large language models (LLMs) for flexibly processing information as strings, a natural application is regression, specifically by preprocessing string representations into LLM embeddings as downstream features for metric prediction. In this paper, we provide one of the first comprehensive investigations into embedding-based regression and demonstrate that LLM embeddings as features can be better for high-dimensional regression tasks than using traditional feature engineering. This regression performance can be explained in part due to LLM embeddings over numeric data inherently preserving Lipschitz continuity over the feature space. Furthermore, we quantify the contribution of different model effects, most notably model size and language understanding, which we find surprisingly do not always improve regression performance.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14708', 55)">Copy Link</button>
<div id="copy-message-55" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14713">LIBER: Lifelong User Behavior Modeling Based on Large Language Models</a></h1>
<p><b>Authors:</b> Chenxu Zhu, Shigang Quan, Bo Chen, Jianghao Lin, Xiaoling Cai, Hong Zhu, Xiangyang Li, Yunjia Xi, Weinan Zhang, Ruiming Tang</p>
<p>Abstract: CTR prediction plays a vital role in recommender systems. Recently, large language models (LLMs) have been applied in recommender systems due to their emergence abilities. While leveraging semantic information from LLMs has shown some improvements in the performance of recommender systems, two notable limitations persist in these studies. First, LLM-enhanced recommender systems encounter challenges in extracting valuable information from lifelong user behavior sequences within textual contexts for recommendation tasks. Second, the inherent variability in human behaviors leads to a constant stream of new behaviors and irregularly fluctuating user interests. This characteristic imposes two significant challenges on existing models. On the one hand, it presents difficulties for LLMs in effectively capturing the dynamic shifts in user interests within these sequences, and on the other hand, there exists the issue of substantial computational overhead if the LLMs necessitate recurrent calls upon each update to the user sequences. In this work, we propose Lifelong User Behavior Modeling (LIBER) based on large language models, which includes three modules: (1) User Behavior Streaming Partition (UBSP), (2) User Interest Learning (UIL), and (3) User Interest Fusion (UIF). Initially, UBSP is employed to condense lengthy user behavior sequences into shorter partitions in an incremental paradigm, facilitating more efficient processing. Subsequently, UIL leverages LLMs in a cascading way to infer insights from these partitions. Finally, UIF integrates the textual outputs generated by the aforementioned processes to construct a comprehensive representation, which can be incorporated by any recommendation model to enhance performance. LIBER has been deployed on Huawei's music recommendation service and achieved substantial improvements in users' play count and play time by 3.01% and 7.69%.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14713', 56)">Copy Link</button>
<div id="copy-message-56" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14738">Universal and Context-Independent Triggers for Precise Control of LLM Outputs</a></h1>
<p><b>Authors:</b> Jiashuo Liang, Guancheng Li, Yang Yu</p>
<p>Abstract: Large language models (LLMs) have been widely adopted in applications such as automated content generation and even critical decision-making systems. However, the risk of prompt injection allows for potential manipulation of LLM outputs. While numerous attack methods have been documented, achieving full control over these outputs remains challenging, often requiring experienced attackers to make multiple attempts and depending heavily on the prompt context. Recent advancements in gradient-based white-box attack techniques have shown promise in tasks like jailbreaks and system prompt leaks. Our research generalizes gradient-based attacks to find a trigger that is (1) Universal: effective irrespective of the target output; (2) Context-Independent: robust across diverse prompt contexts; and (3) Precise Output: capable of manipulating LLM inputs to yield any specified output with high accuracy. We propose a novel method to efficiently discover such triggers and assess the effectiveness of the proposed attack. Furthermore, we discuss the substantial threats posed by such attacks to LLM-based applications, highlighting the potential for adversaries to taking over the decisions and actions made by AI agents.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14738', 57)">Copy Link</button>
<div id="copy-message-57" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14740">TEXGen: a Generative Diffusion Model for Mesh Textures</a></h1>
<p><b>Authors:</b> Xin Yu, Ze Yuan, Yuan-Chen Guo, Ying-Tian Liu, JianHui Liu, Yangguang Li, Yan-Pei Cao, Ding Liang, Xiaojuan Qi</p>
<p>Abstract: While high-quality texture maps are essential for realistic 3D asset rendering, few studies have explored learning directly in the texture space, especially on large-scale datasets. In this work, we depart from the conventional approach of relying on pre-trained 2D diffusion models for test-time optimization of 3D textures. Instead, we focus on the fundamental problem of learning in the UV texture space itself. For the first time, we train a large diffusion model capable of directly generating high-resolution texture maps in a feed-forward manner. To facilitate efficient learning in high-resolution UV spaces, we propose a scalable network architecture that interleaves convolutions on UV maps with attention layers on point clouds. Leveraging this architectural design, we train a 700 million parameter diffusion model that can generate UV texture maps guided by text prompts and single-view images. Once trained, our model naturally supports various extended applications, including text-guided texture inpainting, sparse-view texture completion, and text-driven texture synthesis. Project page is at http://cvmi-lab.github.io/TEXGen/.</p>
<p>URLs: <a href="http://cvmi-lab.github.io/TEXGen/.">http://cvmi-lab.github.io/TEXGen/.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14740, http://cvmi-lab.github.io/TEXGen/.', 58)">Copy Link</button>
<div id="copy-message-58" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14743">FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification</a></h1>
<p><b>Authors:</b> Zhengrui Guo, Conghao Xiong, Jiabo Ma, Qichen Sun, Lishuang Feng, Jinzhuo Wang, Hao Chen</p>
<p>Abstract: Few-shot learning presents a critical solution for cancer diagnosis in computational pathology (CPath), addressing fundamental limitations in data availability, particularly the scarcity of expert annotations and patient privacy constraints. A key challenge in this paradigm stems from the inherent disparity between the limited training set of whole slide images (WSIs) and the enormous number of contained patches, where a significant portion of these patches lacks diagnostically relevant information, potentially diluting the model's ability to learn and focus on critical diagnostic features. While recent works attempt to address this by incorporating additional knowledge, several crucial gaps hinder further progress: (1) despite the emergence of powerful pathology foundation models (FMs), their potential remains largely untapped, with most approaches limiting their use to basic feature extraction; (2) current language guidance mechanisms attempt to align text prompts with vast numbers of WSI patches all at once, struggling to leverage rich pathological semantic information. To this end, we introduce the knowledge-enhanced adaptive visual compression framework, dubbed FOCUS, which uniquely combines pathology FMs with language prior knowledge to enable a focused analysis of diagnostically relevant regions by prioritizing discriminative WSI patches. Our approach implements a progressive three-stage compression strategy: we first leverage FMs for global visual redundancy elimination, and integrate compressed features with language prompts for semantic relevance assessment, then perform neighbor-aware visual token filtering while preserving spatial coherence. Extensive experiments on pathological datasets spanning breast, lung, and ovarian cancers demonstrate its superior performance in few-shot pathology diagnosis. Code will be made available at https://github.com/dddavid4real/FOCUS.</p>
<p>URLs: <a href="https://github.com/dddavid4real/FOCUS.">https://github.com/dddavid4real/FOCUS.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14743, https://github.com/dddavid4real/FOCUS.', 59)">Copy Link</button>
<div id="copy-message-59" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14744">Point Cloud Understanding via Attention-Driven Contrastive Learning</a></h1>
<p><b>Authors:</b> Yi Wang, Jiaze Wang, Ziyu Guo, Renrui Zhang, Donghao Zhou, Guangyong Chen, Anfeng Liu, Pheng-Ann Heng</p>
<p>Abstract: Recently Transformer-based models have advanced point cloud understanding by leveraging self-attention mechanisms, however, these methods often overlook latent information in less prominent regions, leading to increased sensitivity to perturbations and limited global comprehension. To solve this issue, we introduce PointACL, an attention-driven contrastive learning framework designed to address these limitations. Our method employs an attention-driven dynamic masking strategy that guides the model to focus on under-attended regions, enhancing the understanding of global structures within the point cloud. Then we combine the original pre-training loss with a contrastive learning loss, improving feature discrimination and generalization. Extensive experiments validate the effectiveness of PointACL, as it achieves state-of-the-art performance across a variety of 3D understanding tasks, including object classification, part segmentation, and few-shot learning. Specifically, when integrated with different Transformer backbones like Point-MAE and PointGPT, PointACL demonstrates improved performance on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPart. This highlights its superior capability in capturing both global and local features, as well as its enhanced robustness against perturbations and incomplete data.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14744', 60)">Copy Link</button>
<div id="copy-message-60" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14751">TopoSD: Topology-Enhanced Lane Segment Perception with SDMap Prior</a></h1>
<p><b>Authors:</b> Sen Yang, Minyue Jiang, Ziwei Fan, Xiaolu Xie, Xiao Tan, Yingying Li, Errui Ding, Liang Wang, Jingdong Wang</p>
<p>Abstract: Recent advances in autonomous driving systems have shifted towards reducing reliance on high-definition maps (HDMaps) due to the huge costs of annotation and maintenance. Instead, researchers are focusing on online vectorized HDMap construction using on-board sensors. However, sensor-only approaches still face challenges in long-range perception due to the restricted views imposed by the mounting angles of onboard cameras, just as human drivers also rely on bird's-eye-view navigation maps for a comprehensive understanding of road structures. To address these issues, we propose to train the perception model to "see" standard definition maps (SDMaps). We encode SDMap elements into neural spatial map representations and instance tokens, and then incorporate such complementary features as prior information to improve the bird's eye view (BEV) feature for lane geometry and topology decoding. Based on the lane segment representation framework, the model simultaneously predicts lanes, centrelines and their topology. To further enhance the ability of geometry prediction and topology reasoning, we also use a topology-guided decoder to refine the predictions by exploiting the mutual relationships between topological and geometric features. We perform extensive experiments on OpenLane-V2 datasets to validate the proposed method. The results show that our model outperforms state-of-the-art methods by a large margin, with gains of +6.7 and +9.1 on the mAP and topology metrics. Our analysis also reveals that models trained with SDMap noise augmentation exhibit enhanced robustness.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14751', 61)">Copy Link</button>
<div id="copy-message-61" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14759">Hammer: Towards Efficient Hot-Cold Data Identification via Online Learning</a></h1>
<p><b>Authors:</b> Kai Lu, Siqi Zhao, Jiguang Wan</p>
<p>Abstract: Efficient management of storage resources in big data and cloud computing environments requires accurate identification of data's "cold" and "hot" states. Traditional methods, such as rule-based algorithms and early AI techniques, often struggle with dynamic workloads, leading to low accuracy, poor adaptability, and high operational overhead. To address these issues, we propose a novel solution based on online learning strategies. Our approach dynamically adapts to changing data access patterns, achieving higher accuracy and lower operational costs. Rigorous testing with both synthetic and real-world datasets demonstrates a significant improvement, achieving a 90% accuracy rate in hot-cold classification. Additionally, the computational and storage overheads are considerably reduced.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14759', 62)">Copy Link</button>
<div id="copy-message-62" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14762">Efficient Long Video Tokenization via Coordinated-based Patch Reconstruction</a></h1>
<p><b>Authors:</b> Huiwon Jang, Sihyun Yu, Jinwoo Shin, Pieter Abbeel, Younggyo Seo</p>
<p>Abstract: Efficient tokenization of videos remains a challenge in training vision models that can process long videos. One promising direction is to develop a tokenizer that can encode long video clips, as it would enable the tokenizer to leverage the temporal coherence of videos better for tokenization. However, training existing tokenizers on long videos often incurs a huge training cost as they are trained to reconstruct all the frames at once. In this paper, we introduce CoordTok, a video tokenizer that learns a mapping from coordinate-based representations to the corresponding patches of input videos, inspired by recent advances in 3D generative models. In particular, CoordTok encodes a video into factorized triplane representations and reconstructs patches that correspond to randomly sampled $(x,y,t)$ coordinates. This allows for training large tokenizer models directly on long videos without requiring excessive training resources. Our experiments show that CoordTok can drastically reduce the number of tokens for encoding long video clips. For instance, CoordTok can encode a 128-frame video with 128$\times$128 resolution into 1280 tokens, while baselines need 6144 or 8192 tokens to achieve similar reconstruction quality. We further show that this efficient video tokenization enables memory-efficient training of a diffusion transformer that can generate 128 frames at once.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14762', 63)">Copy Link</button>
<div id="copy-message-63" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14768">Grid and Road Expressions Are Complementary for Trajectory Representation Learning</a></h1>
<p><b>Authors:</b> Silin Zhou, Shuo Shang, Lisi Chen, Peng Han, Christian S. Jensen</p>
<p>Abstract: Trajectory representation learning (TRL) maps trajectories to vectors that can be used for many downstream tasks. Existing TRL methods use either grid trajectories, capturing movement in free space, or road trajectories, capturing movement in a road network, as input. We observe that the two types of trajectories are complementary, providing either region and location information or providing road structure and movement regularity. Therefore, we propose a novel multimodal TRL method, dubbed GREEN, to jointly utilize Grid and Road trajectory Expressions for Effective representatioN learning. In particular, we transform raw GPS trajectories into both grid and road trajectories and tailor two encoders to capture their respective information. To align the two encoders such that they complement each other, we adopt a contrastive loss to encourage them to produce similar embeddings for the same raw trajectory and design a mask language model (MLM) loss to use grid trajectories to help reconstruct masked road trajectories. To learn the final trajectory representation, a dual-modal interactor is used to fuse the outputs of the two encoders via cross-attention. We compare GREEN with 7 state-of-the-art TRL methods for 3 downstream tasks, finding that GREEN consistently outperforms all baselines and improves the accuracy of the best-performing baseline by an average of 15.99\%.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14768', 64)">Copy Link</button>
<div id="copy-message-64" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14773">Mode-conditioned music learning and composition: a spiking neural network inspired by neuroscience and psychology</a></h1>
<p><b>Authors:</b> Qian Liang, Yi Zeng, Menghaoran Tang</p>
<p>Abstract: Musical mode is one of the most critical element that establishes the framework of pitch organization and determines the harmonic relationships. Previous works often use the simplistic and rigid alignment method, and overlook the diversity of modes. However, in contrast to AI models, humans possess cognitive mechanisms for perceiving the various modes and keys. In this paper, we propose a spiking neural network inspired by brain mechanisms and psychological theories to represent musical modes and keys, ultimately generating musical pieces that incorporate tonality features. Specifically, the contributions are detailed as follows: 1) The model is designed with multiple collaborated subsystems inspired by the structures and functions of corresponding brain regions; 2)We incorporate mechanisms for neural circuit evolutionary learning that enable the network to learn and generate mode-related features in music, reflecting the cognitive processes involved in human music perception. 3)The results demonstrate that the proposed model shows a connection framework closely similar to the Krumhansl-Schmuckler model, which is one of the most significant key perception models in the music psychology domain. 4) Experiments show that the model can generate music pieces with characteristics of the given modes and keys. Additionally, the quantitative assessments of generated pieces reveals that the generating music pieces have both tonality characteristics and the melodic adaptability needed to generate diverse and musical content. By combining insights from neuroscience, psychology, and music theory with advanced neural network architectures, our research aims to create a system that not only learns and generates music but also bridges the gap between human cognition and artificial intelligence.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14773', 65)">Copy Link</button>
<div id="copy-message-65" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14774">Resolution-Agnostic Transformer-based Climate Downscaling</a></h1>
<p><b>Authors:</b> Declan Curran, Hira Saleem, Flora Salim, Sanaa Hobeichi</p>
<p>Abstract: Understanding future weather changes at regional and local scales is crucial for planning and decision-making, particularly in the context of extreme weather events, as well as for broader applications in agriculture, insurance, and infrastructure development. However, the computational cost of downscaling Global Climate Models (GCMs) to the fine resolutions needed for such applications presents a significant barrier. Drawing on advancements in weather forecasting models, this study introduces a cost-efficient downscaling method using a pretrained Earth Vision Transformer (Earth ViT) model. Initially trained on ERA5 data to downscale from 50 km to 25 km resolution, the model is then tested on the higher resolution BARRA-SY dataset at a 3 km resolution. Remarkably, it performs well without additional training, demonstrating its ability to generalize across different resolutions. This approach holds promise for generating large ensembles of regional climate simulations by downscaling GCMs with varying input resolutions without incurring additional training costs. Ultimately, this method could provide more comprehensive estimates of potential future changes in key climate variables, aiding in effective planning for extreme weather events and climate change adaptation strategies.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14774', 66)">Copy Link</button>
<div id="copy-message-66" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14790">KBAda: Efficient Self Adaptation on Specific Knowledge Bases</a></h1>
<p><b>Authors:</b> Zheni Zeng, Yuxuan Chen, Shi Yu, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun</p>
<p>Abstract: Humans can utilize techniques to quickly acquire knowledge from specific materials in advance, such as creating self-assessment questions, enabling us to achieving related tasks more efficiently. In contrast, large language models (LLMs) usually relies on retrieval-augmented generation to exploit knowledge materials in an instant manner, or requires external signals such as human preference data and stronger LLM annotations to conduct knowledge adaptation. To unleash the self-learning potential of LLMs, we propose KBAda, an approach designed for efficient adaptation to downstream tasks involving knowledge bases. Our method utilizes iterative training with self-annotated data such as Q&A pairs and revision suggestions, enabling the model to grasp the knowledge content efficiently. Experimental results on multiple datasets demonstrate the effectiveness of our approach, significantly boosting model performance in downstream tasks that require specific knowledge at a low cost. Notably, our approach achieves over 90% of the performance improvement that can be obtained by using GPT-4-turbo annotation, while relying entirely on self-supervision. We release our experimental data, models, and process analyses to the community for further exploration (https://github.com/thunlp/KBAda).</p>
<p>URLs: <a href="https://github.com/thunlp/KBAda).">https://github.com/thunlp/KBAda).</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14790, https://github.com/thunlp/KBAda).', 67)">Copy Link</button>
<div id="copy-message-67" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14794">VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection</a></h1>
<p><b>Authors:</b> Songhao Han, Wei Huang, Hairong Shi, Le Zhuo, Xiu Su, Shifeng Zhang, Xu Zhou, Xiaojuan Qi, Yue Liao, Si Liu</p>
<p>Abstract: The advancement of Large Vision Language Models (LVLMs) has significantly improved multimodal understanding, yet challenges remain in video reasoning tasks due to the scarcity of high-quality, large-scale datasets. Existing video question-answering (VideoQA) datasets often rely on costly manual annotations with insufficient granularity or automatic construction methods with redundant frame-by-frame analysis, limiting their scalability and effectiveness for complex reasoning. To address these challenges, we introduce VideoEspresso, a novel dataset that features VideoQA pairs preserving essential spatial details and temporal coherence, along with multimodal annotations of intermediate reasoning steps. Our construction pipeline employs a semantic-aware method to reduce redundancy, followed by generating QA pairs using GPT-4o. We further develop video Chain-of-Thought (CoT) annotations to enrich reasoning processes, guiding GPT-4o in extracting logical relationships from QA pairs and video content. To exploit the potential of high-quality VideoQA pairs, we propose a Hybrid LVLMs Collaboration framework, featuring a Frame Selector and a two-stage instruction fine-tuned reasoning LVLM. This framework adaptively selects core frames and performs CoT reasoning using multimodal evidence. Evaluated on our proposed benchmark with 14 tasks against 9 popular LVLMs, our method outperforms existing baselines on most tasks, demonstrating superior video reasoning capabilities. Our code and dataset will be released at: https://github.com/hshjerry/VideoEspresso</p>
<p>URLs: <a href="https://github.com/hshjerry/VideoEspresso">https://github.com/hshjerry/VideoEspresso</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14794, https://github.com/hshjerry/VideoEspresso', 68)">Copy Link</button>
<div id="copy-message-68" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14797">Continual SFT Matches Multimodal RLHF with Negative Supervision</a></h1>
<p><b>Authors:</b> Ke Zhu, Yu Wang, Yanpeng Sun, Qiang Chen, Jiangjiang Liu, Gang Zhang, Jingdong Wang</p>
<p>Abstract: Multimodal RLHF usually happens after supervised finetuning (SFT) stage to continually improve vision-language models' (VLMs) comprehension. Conventional wisdom holds its superiority over continual SFT during this preference alignment stage. In this paper, we observe that the inherent value of multimodal RLHF lies in its negative supervision, the logit of the rejected responses. We thus propose a novel negative supervised finetuning (nSFT) approach that fully excavates these information resided. Our nSFT disentangles this negative supervision in RLHF paradigm, and continually aligns VLMs with a simple SFT loss. This is more memory efficient than multimodal RLHF where 2 (e.g., DPO) or 4 (e.g., PPO) large VLMs are strictly required. The effectiveness of nSFT is rigorously proved by comparing it with various multimodal RLHF approaches, across different dataset sources, base VLMs and evaluation metrics. Besides, fruitful of ablations are provided to support our hypothesis. We hope this paper will stimulate further research to properly align large vision language models.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14797', 69)">Copy Link</button>
<div id="copy-message-69" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14808">High-Resolution Image Synthesis via Next-Token Prediction</a></h1>
<p><b>Authors:</b> Dengsheng Chen, Jie Hu, Tiezhu Yue, Xiaoming Wei</p>
<p>Abstract: Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), an autoregressive model, has demonstrated outstanding performance in class-conditional image generation. However, the application of next-token prediction in high-resolution text-to-image generation remains underexplored. In this paper, we introduce D-JEPA$\cdot$T2I, an extension of D-JEPA incorporating flow matching loss, designed to enable data-efficient continuous resolution learning. D-JEPA$\cdot$T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary Positional Embedding (VoPE) to facilitate continuous resolution learning. Furthermore, we devise a data feedback mechanism that significantly enhances data utilization efficiency. For the first time, we achieve state-of-the-art \textbf{high-resolution} image synthesis via next-token prediction.
  The experimental code and pretrained models will be open-sourced at \url{https://d-jepa.github.io/t2i}.</p>
<p>URLs: <a href="https://d-jepa.github.io/t2i">https://d-jepa.github.io/t2i</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14808, https://d-jepa.github.io/t2i', 70)">Copy Link</button>
<div id="copy-message-70" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14827">Physically Interpretable Probabilistic Domain Characterization</a></h1>
<p><b>Authors:</b> Ana\"is Halin, S\'ebastien Pi\'erard, Renaud Vandeghen, Beno\^it G\'erin, Maxime Zanella, Martin Colot, Jan Held, Anthony Cioppa, Emmanuel Jean, Gianluca Bontempi, Sa\"id Mahmoudi, Beno\^it Macq, Marc Van Droogenbroeck</p>
<p>Abstract: Characterizing domains is essential for models analyzing dynamic environments, as it allows them to adapt to evolving conditions or to hand the task over to backup systems when facing conditions outside their operational domain. Existing solutions typically characterize a domain by solving a regression or classification problem, which limits their applicability as they only provide a limited summarized description of the domain. In this paper, we present a novel approach to domain characterization by characterizing domains as probability distributions. Particularly, we develop a method to predict the likelihood of different weather conditions from images captured by vehicle-mounted cameras by estimating distributions of physical parameters using normalizing flows. To validate our proposed approach, we conduct experiments within the context of autonomous vehicles, focusing on predicting the distribution of weather parameters to characterize the operational domain. This domain is characterized by physical parameters (absolute characterization) and arbitrarily predefined domains (relative characterization). Finally, we evaluate whether a system can safely operate in a target domain by comparing it to multiple source domains where safety has already been established. This approach holds significant potential, as accurate weather prediction and effective domain adaptation are crucial for autonomous systems to adjust to dynamic environmental conditions.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14827', 71)">Copy Link</button>
<div id="copy-message-71" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14832">VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models</a></h1>
<p><b>Authors:</b> Camilo Chac\'on Sartori, Christian Blum, Filippo Bistaffa</p>
<p>Abstract: The fast advancement of Large Vision-Language Models (LVLMs) has shown immense potential. These models are increasingly capable of tackling abstract visual tasks. Geometric structures, particularly graphs with their inherent flexibility and complexity, serve as an excellent benchmark for evaluating these models' predictive capabilities. While human observers can readily identify subtle visual details and perform accurate analyses, our investigation reveals that state-of-the-art LVLMs exhibit consistent limitations in specific visual graph scenarios, especially when confronted with stylistic variations. In response to these challenges, we introduce VisGraphVar (Visual Graph Variability), a customizable benchmark generator able to produce graph images for seven distinct task categories (detection, classification, segmentation, pattern recognition, link prediction, reasoning, matching), designed to systematically evaluate the strengths and limitations of individual LVLMs. We use VisGraphVar to produce 990 graph images and evaluate six LVLMs, employing two distinct prompting strategies, namely zero-shot and chain-of-thought. The findings demonstrate that variations in visual attributes of images (e.g., node labeling and layout) and the deliberate inclusion of visual imperfections, such as overlapping nodes, significantly affect model performance. This research emphasizes the importance of a comprehensive evaluation across graph-related tasks, extending beyond reasoning alone. VisGraphVar offers valuable insights to guide the development of more reliable and robust systems capable of performing advanced visual graph analysis.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14832', 72)">Copy Link</button>
<div id="copy-message-72" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14842">Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Language Models</a></h1>
<p><b>Authors:</b> Wanqi Yang, Yanda Li, Meng Fang, Yunchao Wei, Tianyi Zhou, Ling Chen</p>
<p>Abstract: Adversarial audio attacks pose a significant threat to the growing use of large language models (LLMs) in voice-based human-machine interactions. While existing research has primarily focused on model-specific adversarial methods, real-world applications demand a more generalizable and universal approach to audio adversarial attacks. In this paper, we introduce the Chat-Audio Attacks (CAA) benchmark including four distinct types of audio attacks, which aims to explore the the vulnerabilities of LLMs to these audio attacks in conversational scenarios. To evaluate the robustness of LLMs, we propose three evaluation strategies: Standard Evaluation, utilizing traditional metrics to quantify model performance under attacks; GPT-4o-Based Evaluation, which simulates real-world conversational complexities; and Human Evaluation, offering insights into user perception and trust. We evaluate six state-of-the-art LLMs with voice interaction capabilities, including Gemini-1.5-Pro, GPT-4o, and others, using three distinct evaluation methods on the CAA benchmark. Our comprehensive analysis reveals the impact of four types of audio attacks on the performance of these models, demonstrating that GPT-4o exhibits the highest level of resilience.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14842', 73)">Copy Link</button>
<div id="copy-message-73" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14847">Dynamics-Aware Gaussian Splatting Streaming Towards Fast On-the-Fly Training for 4D Reconstruction</a></h1>
<p><b>Authors:</b> Zhening Liu, Yingdong Hu, Xinjie Zhang, Jiawei Shao, Zehong Lin, Jun Zhang</p>
<p>Abstract: The recent development of 3D Gaussian Splatting (3DGS) has led to great interest in 4D dynamic spatial reconstruction from multi-view visual inputs. While existing approaches mainly rely on processing full-length multi-view videos for 4D reconstruction, there has been limited exploration of iterative online reconstruction methods that enable on-the-fly training and per-frame streaming. Current 3DGS-based streaming methods treat the Gaussian primitives uniformly and constantly renew the densified Gaussians, thereby overlooking the difference between dynamic and static features and also neglecting the temporal continuity in the scene. To address these limitations, we propose a novel three-stage pipeline for iterative streamable 4D dynamic spatial reconstruction. Our pipeline comprises a selective inheritance stage to preserve temporal continuity, a dynamics-aware shift stage for distinguishing dynamic and static primitives and optimizing their movements, and an error-guided densification stage to accommodate emerging objects. Our method achieves state-of-the-art performance in online 4D reconstruction, demonstrating a 20% improvement in on-the-fly training speed, superior representation quality, and real-time rendering capability. Project page: https://www.liuzhening.top/DASS</p>
<p>URLs: <a href="https://www.liuzhening.top/DASS">https://www.liuzhening.top/DASS</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14847, https://www.liuzhening.top/DASS', 74)">Copy Link</button>
<div id="copy-message-74" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14863">Latent Schrodinger Bridge: Prompting Latent Diffusion for Fast Unpaired Image-to-Image Translation</a></h1>
<p><b>Authors:</b> Jeongsol Kim, Beomsu Kim, Jong Chul Ye</p>
<p>Abstract: Diffusion models (DMs), which enable both image generation from noise and inversion from data, have inspired powerful unpaired image-to-image (I2I) translation algorithms. However, they often require a larger number of neural function evaluations (NFEs), limiting their practical applicability. In this paper, we tackle this problem with Schrodinger Bridges (SBs), which are stochastic differential equations (SDEs) between distributions with minimal transport cost. We analyze the probability flow ordinary differential equation (ODE) formulation of SBs, and observe that we can decompose its vector field into a linear combination of source predictor, target predictor, and noise predictor. Inspired by this observation, we propose Latent Schrodinger Bridges (LSBs) that approximate the SB ODE via pre-trained Stable Diffusion, and develop appropriate prompt optimization and change of variables formula to match the training and inference between distributions. We demonstrate that our algorithm successfully conduct competitive I2I translation in unsupervised setting with only a fraction of computation cost required by previous DM-based I2I methods.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14863', 75)">Copy Link</button>
<div id="copy-message-75" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14869">BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence</a></h1>
<p><b>Authors:</b> Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Zhizhong Su</p>
<p>Abstract: In embodied intelligence systems, a key component is 3D perception algorithm, which enables agents to understand their surrounding environments. Previous algorithms primarily rely on point cloud, which, despite offering precise geometric information, still constrain perception performance due to inherent sparsity, noise, and data scarcity. In this work, we introduce a novel image-centric 3D perception model, BIP3D, which leverages expressive image features with explicit 3D position encoding to overcome the limitations of point-centric methods. Specifically, we leverage pre-trained 2D vision foundation models to enhance semantic understanding, and introduce a spatial enhancer module to improve spatial understanding. Together, these modules enable BIP3D to achieve multi-view, multi-modal feature fusion and end-to-end 3D perception. In our experiments, BIP3D outperforms current state-of-the-art results on the EmbodiedScan benchmark, achieving improvements of 5.69% in the 3D detection task and 15.25% in the 3D visual grounding task.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14869', 76)">Copy Link</button>
<div id="copy-message-76" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14870">Application of AI to formal methods -- an analysis of current trends</a></h1>
<p><b>Authors:</b> Sebastian Stock, Jannik Dunkelau, Atif Mashkoor</p>
<p>Abstract: With artificial intelligence (AI) being well established within the daily lives of research communities, we turn our gaze toward an application area that appears intuitively unsuited for probabilistic decision-making: the area of formal methods (FM). FM aim to provide sound and understandable reasoning about problems in computer science, which seemingly collides with the black-box nature that inhibits many AI approaches. However, many researchers have crossed this gap and applied AI techniques to enhance FM approaches. As this dichotomy of FM and AI sparked our interest, we conducted a systematic mapping study to map the current landscape of research publications. In this study, we investigate the previous five years of applied AI to FM (2019-2023), as these correspond to periods of high activity. This investigation results in 189 entries, which we explore in more detail to find current trends, highlight research gaps, and give suggestions for future research.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14870', 77)">Copy Link</button>
<div id="copy-message-77" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14871">Prioritize Denoising Steps on Diffusion Model Preference Alignment via Explicit Denoised Distribution Estimation</a></h1>
<p><b>Authors:</b> Dingyuan Shi, Yong Wang, Hangyu Li, Xiangxiang Chu</p>
<p>Abstract: Diffusion models have shown remarkable success in text-to-image generation, making alignment methods for these models increasingly important. A key challenge is the sparsity of preference labels, which are typically available only at the terminal of denoising trajectories. This raises the issue of how to assign credit across denoising steps based on these sparse labels. In this paper, we propose Denoised Distribution Estimation (DDE), a novel method for credit assignment. Unlike previous approaches that rely on auxiliary models or hand-crafted schemes, DDE derives its strategy more explicitly. The proposed DDE directly estimates the terminal denoised distribution from the perspective of each step. It is equipped with two estimation strategies and capable of representing the entire denoising trajectory with a single model inference. Theoretically and empirically, we show that DDE prioritizes optimizing the middle part of the denoising trajectory, resulting in a novel and effective credit assignment scheme. Extensive experiments demonstrate that our approach achieves superior performance, both quantitatively and qualitatively.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14871', 78)">Copy Link</button>
<div id="copy-message-78" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14883">Boundless Across Domains: A New Paradigm of Adaptive Feature and Cross-Attention for Domain Generalization in Medical Image Segmentation</a></h1>
<p><b>Authors:</b> Yuheng Xu, Taiping Zhang</p>
<p>Abstract: Domain-invariant representation learning is a powerful method for domain generalization. Previous approaches face challenges such as high computational demands, training instability, and limited effectiveness with high-dimensional data, potentially leading to the loss of valuable features. To address these issues, we hypothesize that an ideal generalized representation should exhibit similar pattern responses within the same channel across cross-domain images. Based on this hypothesis, we use deep features from the source domain as queries, and deep features from the generated domain as keys and values. Through a cross-channel attention mechanism, the original deep features are reconstructed into robust regularization representations, forming an explicit constraint that guides the model to learn domain-invariant representations. Additionally, style augmentation is another common method. However, existing methods typically generate new styles through convex combinations of source domains, which limits the diversity of training samples by confining the generated styles to the original distribution. To overcome this limitation, we propose an Adaptive Feature Blending (AFB) method that generates out-of-distribution samples while exploring the in-distribution space, significantly expanding the domain range. Extensive experimental results demonstrate that our proposed methods achieve superior performance on two standard domain generalization benchmarks for medical image segmentation.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14883', 79)">Copy Link</button>
<div id="copy-message-79" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14907">DAIRHuM: A Platform for Directly Aligning AI Representations with Human Musical Judgments applied to Carnatic Music</a></h1>
<p><b>Authors:</b> Prashanth Thattai Ravikumar</p>
<p>Abstract: Quantifying and aligning music AI model representations with human behavior is an important challenge in the field of MIR. This paper presents a platform for exploring the Direct alignment between AI music model Representations and Human Musical judgments (DAIRHuM). It is designed to enable musicians and experimentalists to label similarities in a dataset of music recordings, and examine a pre-trained model's alignment with their labels using quantitative scores and visual plots. DAIRHuM is applied to analyze alignment between NSynth representations, and a rhythmic duet between two percussionists in a Carnatic quartet ensemble, an example of a genre where annotated data is scarce and assessing alignment is non-trivial. The results demonstrate significant findings on model alignment with human judgments of rhythmic harmony, while highlighting key differences in rhythm perception and music similarity judgments specific to Carnatic music. This work is among the first efforts to enable users to explore human-AI model alignment in Carnatic music and advance MIR research in Indian music while dealing with data scarcity and cultural specificity. The development of this platform provides greater accessibility to music AI tools for under-represented genres.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14907', 80)">Copy Link</button>
<div id="copy-message-80" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14922">GOT4Rec: Graph of Thoughts for Sequential Recommendation</a></h1>
<p><b>Authors:</b> Zewen Long, Liang Wang, Shu Wu, Qiang Liu, Liang Wang</p>
<p>Abstract: With the advancement of large language models (LLMs), researchers have explored various methods to optimally leverage their comprehension and generation capabilities in sequential recommendation scenarios. However, several challenges persist in this endeavor. Firstly, most existing approaches rely on the input-output prompting paradigm, which can result in irrelevant or inaccurate responses. Secondly, while there have been attempts to enhance LLMs using prompting strategies such as chain-of-thought (CoT), these efforts have not fully harnessed the reasoning abilities of LLMs or effectively captured the multifaceted information contained within user sequences. To address these limitations, we propose GOT4Rec, a sequential recommendation method that utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we identify and utilize three key types of information within user history sequences: short-term interests, long-term interests and collaborative information from other users. Our approach enables LLMs to independently reason and generate recommendations based on these distinct types of information, subsequently aggregating the results within the GoT framework to derive the final recommended items. This method allows LLMs, with enhanced reasoning capabilities, to more effectively consider the diverse information within user sequences, resulting in more accurate recommendations and more comprehensive explanations. Extensive experiments on real-world datasets demonstrate the effectiveness of GOT4Rec, indicating that it outperforms existing state-of-the-art baselines. Our code is available at https://anonymous.4open.science/r/GOT4Rec-ED99.</p>
<p>URLs: <a href="https://anonymous.4open.science/r/GOT4Rec-ED99.">https://anonymous.4open.science/r/GOT4Rec-ED99.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14922, https://anonymous.4open.science/r/GOT4Rec-ED99.', 81)">Copy Link</button>
<div id="copy-message-81" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14925">Purrfessor: A Fine-tuned Multimodal LLaVA Diet Health Chatbot</a></h1>
<p><b>Authors:</b> Linqi Lu, Yifan Deng, Chuan Tian, Sijia Yang, Dhavan Shah</p>
<p>Abstract: This study introduces Purrfessor, an innovative AI chatbot designed to provide personalized dietary guidance through interactive, multimodal engagement. Leveraging the Large Language-and-Vision Assistant (LLaVA) model fine-tuned with food and nutrition data and a human-in-the-loop approach, Purrfessor integrates visual meal analysis with contextual advice to enhance user experience and engagement. We conducted two studies to evaluate the chatbot's performance and user experience: (a) simulation assessments and human validation were conducted to examine the performance of the fine-tuned model; (b) a 2 (Profile: Bot vs. Pet) by 3 (Model: GPT-4 vs. LLaVA vs. Fine-tuned LLaVA) experiment revealed that Purrfessor significantly enhanced users' perceptions of care ($\beta = 1.59$, $p = 0.04$) and interest ($\beta = 2.26$, $p = 0.01$) compared to the GPT-4 bot. Additionally, user interviews highlighted the importance of interaction design details, emphasizing the need for responsiveness, personalization, and guidance to improve user engagement.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14925', 82)">Copy Link</button>
<div id="copy-message-82" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14927">LiDAR-based End-to-end Temporal Perception for Vehicle-Infrastructure Cooperation</a></h1>
<p><b>Authors:</b> Zhenwei Yang, Jilei Mao, Wenxian Yang, Yibo Ai, Yu Kong, Haibao Yu, Weidong Zhang</p>
<p>Abstract: Temporal perception, the ability to detect and track objects over time, is critical in autonomous driving for maintaining a comprehensive understanding of dynamic environments. However, this task is hindered by significant challenges, including incomplete perception caused by occluded objects and observational blind spots, which are common in single-vehicle perception systems. To address these issues, we introduce LET-VIC, a LiDAR-based End-to-End Tracking framework for Vehicle-Infrastructure Cooperation (VIC). LET-VIC leverages Vehicle-to-Everything (V2X) communication to enhance temporal perception by fusing spatial and temporal data from both vehicle and infrastructure sensors. First, it spatially integrates Bird's Eye View (BEV) features from vehicle-side and infrastructure-side LiDAR data, creating a comprehensive view that mitigates occlusions and compensates for blind spots. Second, LET-VIC incorporates temporal context across frames, allowing the model to leverage historical data for enhanced tracking stability and accuracy. To further improve robustness, LET-VIC includes a Calibration Error Compensation (CEC) module to address sensor misalignments and ensure precise feature alignment. Experiments on the V2X-Seq-SPD dataset demonstrate that LET-VIC significantly outperforms baseline models, achieving at least a 13.7% improvement in mAP and a 13.1% improvement in AMOTA without considering communication delays. This work offers a practical solution and a new research direction for advancing temporal perception in autonomous driving through vehicle-infrastructure cooperation.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14927', 83)">Copy Link</button>
<div id="copy-message-83" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14937">Geminio: Language-Guided Gradient Inversion Attacks in Federated Learning</a></h1>
<p><b>Authors:</b> Junjie Shan, Ziqi Zhao, Jialin Lu, Rui Zhang, Siu Ming Yiu, Ka-Ho Chow</p>
<p>Abstract: Foundation models that bridge vision and language have made significant progress, inspiring numerous life-enriching applications. However, their potential for misuse to introduce new threats remains largely unexplored. This paper reveals that vision-language models (VLMs) can be exploited to overcome longstanding limitations in gradient inversion attacks (GIAs) within federated learning (FL), where an FL server reconstructs private data samples from gradients shared by victim clients. Current GIAs face challenges in reconstructing high-resolution images, especially when the victim has a large local data batch. While focusing reconstruction on valuable samples rather than the entire batch is promising, existing methods lack the flexibility to allow attackers to specify their target data. In this paper, we introduce Geminio, the first approach to transform GIAs into semantically meaningful, targeted attacks. Geminio enables a brand new privacy attack experience: attackers can describe, in natural language, the types of data they consider valuable, and Geminio will prioritize reconstruction to focus on those high-value samples. This is achieved by leveraging a pretrained VLM to guide the optimization of a malicious global model that, when shared with and optimized by a victim, retains only gradients of samples that match the attacker-specified query. Extensive experiments demonstrate Geminio's effectiveness in pinpointing and reconstructing targeted samples, with high success rates across complex datasets under FL and large batch sizes and showing resilience against existing defenses.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14937', 84)">Copy Link</button>
<div id="copy-message-84" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14942">Comparative Study of Neural Network Methods for Solving Topological Solitons</a></h1>
<p><b>Authors:</b> Koji Hashimoto, Koshiro Matsuo, Masaki Murata, Gakuto Ogiwara</p>
<p>Abstract: Topological solitons, which are stable, localized solutions of nonlinear differential equations, are crucial in various fields of physics and mathematics, including particle physics and cosmology. However, solving these solitons presents significant challenges due to the complexity of the underlying equations and the computational resources required for accurate solutions. To address this, we have developed a novel method using neural network (NN) to efficiently solve solitons. A similar NN approach is Physics-Informed Neural Networks (PINN). In a comparative analysis between our method and PINN, we find that our method achieves shorter computation times while maintaining the same level of accuracy. This advancement in computational efficiency not only overcomes current limitations but also opens new avenues for studying topological solitons and their dynamical behavior.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14942', 85)">Copy Link</button>
<div id="copy-message-85" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14946">Reliable Evaluation of Attribution Maps in CNNs: A Perturbation-Based Approach</a></h1>
<p><b>Authors:</b> Lars Nieradzik, Henrike Stephani, Janis Keuper</p>
<p>Abstract: In this paper, we present an approach for evaluating attribution maps, which play a central role in interpreting the predictions of convolutional neural networks (CNNs). We show that the widely used insertion/deletion metrics are susceptible to distribution shifts that affect the reliability of the ranking. Our method proposes to replace pixel modifications with adversarial perturbations, which provides a more robust evaluation framework. By using smoothness and monotonicity measures, we illustrate the effectiveness of our approach in correcting distribution shifts. In addition, we conduct the most comprehensive quantitative and qualitative assessment of attribution maps to date. Introducing baseline attribution maps as sanity checks, we find that our metric is the only contender to pass all checks. Using Kendall's $\tau$ rank correlation coefficient, we show the increased consistency of our metric across 15 dataset-architecture combinations. Of the 16 attribution maps tested, our results clearly show SmoothGrad to be the best map currently available. This research makes an important contribution to the development of attribution maps by providing a reliable and consistent evaluation framework. To ensure reproducibility, we will provide the code along with our results.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14946', 86)">Copy Link</button>
<div id="copy-message-86" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14953">Evaluating Vision Transformer Models for Visual Quality Control in Industrial Manufacturing</a></h1>
<p><b>Authors:</b> Miriam Alber, Christoph H\"ones, Patrick Baier</p>
<p>Abstract: One of the most promising use-cases for machine learning in industrial manufacturing is the early detection of defective products using a quality control system. Such a system can save costs and reduces human errors due to the monotonous nature of visual inspections. Today, a rich body of research exists which employs machine learning methods to identify rare defective products in unbalanced visual quality control datasets. These methods typically rely on two components: A visual backbone to capture the features of the input image and an anomaly detection algorithm that decides if these features are within an expected distribution. With the rise of transformer architecture as visual backbones of choice, there exists now a great variety of different combinations of these two components, ranging all along the trade-off between detection quality and inference time. Facing this variety, practitioners in the field often have to spend a considerable amount of time on researching the right combination for their use-case at hand. Our contribution is to help practitioners with this choice by reviewing and evaluating current vision transformer models together with anomaly detection methods. For this, we chose SotA models of both disciplines, combined them and evaluated them towards the goal of having small, fast and efficient anomaly detection models suitable for industrial manufacturing. We evaluated the results of our experiments on the well-known MVTecAD and BTAD datasets. Moreover, we give guidelines for choosing a suitable model architecture for a quality control system in practice, considering given use-case and hardware constraints.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14953', 87)">Copy Link</button>
<div id="copy-message-87" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14959">Design-o-meter: Towards Evaluating and Refining Graphic Designs</a></h1>
<p><b>Authors:</b> Sahil Goyal, Abhinav Mahajan, Swasti Mishra, Prateksha Udhayanan, Tripti Shukla, K J Joseph, Balaji Vasan Srinivasan</p>
<p>Abstract: Graphic designs are an effective medium for visual communication. They range from greeting cards to corporate flyers and beyond. Off-late, machine learning techniques are able to generate such designs, which accelerates the rate of content production. An automated way of evaluating their quality becomes critical. Towards this end, we introduce Design-o-meter, a data-driven methodology to quantify the goodness of graphic designs. Further, our approach can suggest modifications to these designs to improve its visual appeal. To the best of our knowledge, Design-o-meter is the first approach that scores and refines designs in a unified framework despite the inherent subjectivity and ambiguity of the setting. Our exhaustive quantitative and qualitative analysis of our approach against baselines adapted for the task (including recent Multimodal LLM-based approaches) brings out the efficacy of our methodology. We hope our work will usher more interest in this important and pragmatic problem setting.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14959', 88)">Copy Link</button>
<div id="copy-message-88" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14962">LLM for Barcodes: Generating Diverse Synthetic Data for Identity Documents</a></h1>
<p><b>Authors:</b> Hitesh Laxmichand Patel, Amit Agarwal, Bhargava Kumar, Karan Gupta, Priyaranjan Pattnayak</p>
<p>Abstract: Accurate barcode detection and decoding in Identity documents is crucial for applications like security, healthcare, and education, where reliable data extraction and verification are essential. However, building robust detection models is challenging due to the lack of diverse, realistic datasets an issue often tied to privacy concerns and the wide variety of document formats. Traditional tools like Faker rely on predefined templates, making them less effective for capturing the complexity of real-world identity documents. In this paper, we introduce a new approach to synthetic data generation that uses LLMs to create contextually rich and realistic data without relying on predefined field. Using the vast knowledge LLMs have about different documents and content, our method creates data that reflects the variety found in real identity documents. This data is then encoded into barcode and overlayed on templates for documents such as Driver's licenses, Insurance cards, Student IDs. Our approach simplifies the process of dataset creation, eliminating the need for extensive domain knowledge or predefined fields. Compared to traditional methods like Faker, data generated by LLM demonstrates greater diversity and contextual relevance, leading to improved performance in barcode detection models. This scalable, privacy-first solution is a big step forward in advancing machine learning for automated document processing and identity verification.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14962', 89)">Copy Link</button>
<div id="copy-message-89" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14967">SwissADT: An Audio Description Translation System for Swiss Languages</a></h1>
<p><b>Authors:</b> Lukas Fischer, Yingqiang Gao, Alexa Lintner, Sarah Ebling</p>
<p>Abstract: Audio description (AD) is a crucial accessibility service provided to blind persons and persons with visual impairment, designed to convey visual information in acoustic form. Despite recent advancements in multilingual machine translation research, the lack of well-crafted and time-synchronized AD data impedes the development of audio description translation (ADT) systems that address the needs of multilingual countries such as Switzerland. Furthermore, since the majority of ADT systems rely solely on text, uncertainty exists as to whether incorporating visual information from the corresponding video clips can enhance the quality of ADT outputs. In this work, we present SwissADT, the first ADT system implemented for three main Swiss languages and English. By collecting well-crafted AD data augmented with video clips in German, French, Italian, and English, and leveraging the power of Large Language Models (LLMs), we aim to enhance information accessibility for diverse language populations in Switzerland by automatically translating AD scripts to the desired Swiss language. Our extensive experimental ADT results, composed of both automatic and human evaluations of ADT quality, demonstrate the promising capability of SwissADT for the ADT task. We believe that combining human expertise with the generation power of LLMs can further enhance the performance of ADT systems, ultimately benefiting a larger multilingual target population.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14967', 90)">Copy Link</button>
<div id="copy-message-90" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14972">Open-Amp: Synthetic Data Framework for Audio Effect Foundation Models</a></h1>
<p><b>Authors:</b> Alec Wright, Alistair Carson, Lauri Juvela</p>
<p>Abstract: This paper introduces Open-Amp, a synthetic data framework for generating large-scale and diverse audio effects data. Audio effects are relevant to many musical audio processing and Music Information Retrieval (MIR) tasks, such as modelling of analog audio effects, automatic mixing, tone matching and transcription. Existing audio effects datasets are limited in scope, usually including relatively few audio effects processors and a limited amount of input audio signals. Our proposed framework overcomes these issues, by crowdsourcing neural network emulations of guitar amplifiers and effects, created by users of open-source audio effects emulation software. This allows users of Open-Amp complete control over the input signals to be processed by the effects models, as well as providing high-quality emulations of hundreds of devices. Open-Amp can render audio online during training, allowing great flexibility in data augmentation. Our experiments show that using Open-Amp to train a guitar effects encoder achieves new state-of-the-art results on multiple guitar effects classification tasks. Furthermore, we train a one-to-many guitar effects model using Open-Amp, and use it to emulate unseen analog effects via manipulation of its learned latent space, indicating transferability to analog guitar effects data.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14972', 91)">Copy Link</button>
<div id="copy-message-91" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.14975">Exploring Foundation Models Fine-Tuning for Cytology Classification</a></h1>
<p><b>Authors:</b> Manon Dausort, Tiffanie Godelaine, Maxime Zanella, Karim El Khoury, Isabelle Salmon, Beno\^it Macq</p>
<p>Abstract: Cytology slides are essential tools in diagnosing and staging cancer, but their analysis is time-consuming and costly. Foundation models have shown great potential to assist in these tasks. In this paper, we explore how existing foundation models can be applied to cytological classification. More particularly, we focus on low-rank adaptation, a parameter-efficient fine-tuning method suited to few-shot learning. We evaluated five foundation models across four cytological classification datasets. Our results demonstrate that fine-tuning the pre-trained backbones with LoRA significantly improves model performance compared to fine-tuning only the classifier head, achieving state-of-the-art results on both simple and complex classification tasks while requiring fewer data samples.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.14975', 92)">Copy Link</button>
<div id="copy-message-92" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15004">ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data</a></h1>
<p><b>Authors:</b> Junhong Shen, Atishay Jain, Zedian Xiao, Ishan Amlekar, Mouad Hadji, Aaron Podolny, Ameet Talwalkar</p>
<p>Abstract: Large Language Model (LLM) agents are rapidly improving to handle increasingly complex web-based tasks. Most of these agents rely on general-purpose, proprietary models like GPT-4 and focus on designing better prompts to improve their planning abilities. However, general-purpose LLMs are not specifically trained to understand specialized web contexts such as HTML, and they often struggle with long-horizon planning. We explore an alternative approach that fine-tunes open-source LLMs using production-scale workflow data collected from over 250 domains corresponding to 6 billion tokens. This simple yet effective approach shows substantial gains over prompting-based agents on existing benchmarks -- ScribeAgent achieves state-of-the-art direct generation performance on Mind2Web and improves the task success rate by 14.1% over the previous best text-only web agents on WebArena. We further perform detailed ablation studies on various fine-tuning design choices and provide insights into LLM selection, training recipes, context window optimization, and effect of dataset sizes.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15004', 93)">Copy Link</button>
<div id="copy-message-93" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15007">FTA generation using GenAI with an Autonomy sensor Usecase</a></h1>
<p><b>Authors:</b> Sneha Sudhir Shetiya, Divya Garikapati, Veeraja Sohoni</p>
<p>Abstract: Functional safety forms an important aspect in the design of systems. Its emphasis on the automotive industry has evolved significantly over the years. Till date many methods have been developed to get appropriate FTA(Fault Tree analysis) for various scenarios and features pertaining to Autonomous Driving. This paper is an attempt to explore the scope of using Generative Artificial Intelligence(GenAI) in order to develop Fault Tree Analysis(FTA) with the use case of malfunction for the Lidar sensor in mind. We explore various available open source Large Language Models(LLM) models and then dive deep into one of them to study its responses and provide our analysis. This paper successfully shows the possibility to train existing Large Language models through Prompt Engineering for fault tree analysis for any Autonomy usecase aided with PlantUML tool.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15007', 94)">Copy Link</button>
<div id="copy-message-94" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15027">Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot</a></h1>
<p><b>Authors:</b> Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone</p>
<p>Abstract: Robots are increasingly being used in dynamic environments like workplaces, hospitals, and homes. As a result, interactions with robots must be simple and intuitive, with robots perception adapting efficiently to human-induced changes. This paper presents a robot control architecture that addresses key challenges in human-robot interaction, with a particular focus on the dynamic creation and continuous update of the robot state representation. The architecture uses Large Language Models to integrate diverse information sources, including natural language commands, robotic skills representation, real-time dynamic semantic mapping of the perceived scene. This enables flexible and adaptive robotic behavior in complex, dynamic environments. Traditional robotic systems often rely on static, pre-programmed instructions and settings, limiting their adaptability to dynamic environments and real-time collaboration. In contrast, this architecture uses LLMs to interpret complex, high-level instructions and generate actionable plans that enhance human-robot collaboration. At its core, the system Perception Module generates and continuously updates a semantic scene graph using RGB-D sensor data, providing a detailed and structured representation of the environment. A particle filter is employed to ensure accurate object localization in dynamic, real-world settings. The Planner Module leverages this up-to-date semantic map to break down high-level tasks into sub-tasks and link them to robotic skills such as navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g., GOTO). By combining real-time perception, state tracking, and LLM-driven communication and task planning, the architecture enhances adaptability, task efficiency, and human-robot collaboration in dynamic environments.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15027', 95)">Copy Link</button>
<div id="copy-message-95" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15033">One to rule them all: natural language to bind communication, perception and action</a></h1>
<p><b>Authors:</b> Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone</p>
<p>Abstract: In recent years, research in the area of human-robot interaction has focused on developing robots capable of understanding complex human instructions and performing tasks in dynamic and diverse environments. These systems have a wide range of applications, from personal assistance to industrial robotics, emphasizing the importance of robots interacting flexibly, naturally and safely with humans. This paper presents an advanced architecture for robotic action planning that integrates communication, perception, and planning with Large Language Models (LLMs). Our system is designed to translate commands expressed in natural language into executable robot actions, incorporating environmental information and dynamically updating plans based on real-time feedback. The Planner Module is the core of the system where LLMs embedded in a modified ReAct framework are employed to interpret and carry out user commands. By leveraging their extensive pre-trained knowledge, LLMs can effectively process user requests without the need to introduce new knowledge on the changing environment. The modified ReAct framework further enhances the execution space by providing real-time environmental perception and the outcomes of physical actions. By combining robust and dynamic semantic map representations as graphs with control components and failure explanations, this architecture enhances a robot adaptability, task execution, and seamless collaboration with human users in shared and dynamic environments. Through the integration of continuous feedback loops with the environment the system can dynamically adjusts the plan to accommodate unexpected changes, optimizing the robot ability to perform tasks. Using a dataset of previous experience is possible to provide detailed feedback about the failure. Updating the LLMs context of the next iteration with suggestion on how to overcame the issue.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15033', 96)">Copy Link</button>
<div id="copy-message-96" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15042">Enhancing Autonomous Driving Safety through World Model-Based Predictive Navigation and Adaptive Learning Algorithms for 5G Wireless Applications</a></h1>
<p><b>Authors:</b> Hong Ding, Ziming Wang, Yi Ding, Hongjie Lin, SuYang Xi, Chia Chao Kang</p>
<p>Abstract: Addressing the challenge of ensuring safety in ever-changing and unpredictable environments, particularly in the swiftly advancing realm of autonomous driving in today's 5G wireless communication world, we present Navigation Secure (NavSecure). This vision-based navigation framework merges the strengths of world models with crucial safety-focused decision-making capabilities, enabling autonomous vehicles to navigate real-world complexities securely. Our approach anticipates potential threats and formulates safer routes by harnessing the predictive capabilities of world models, thus significantly reducing the need for extensive real-world trial-and-error learning. Additionally, our method empowers vehicles to autonomously learn and develop through continuous practice, ensuring the system evolves and adapts to new challenges. Incorporating radio frequency technology, NavSecure leverages 5G networks to enhance real-time data exchange, improving communication and responsiveness. Validated through rigorous experiments under simulation-to-real driving conditions, NavSecure has shown exceptional performance in safety-critical scenarios, such as sudden obstacle avoidance. Results indicate that NavSecure excels in key safety metrics, including collision prevention and risk reduction, surpassing other end-to-end methodologies. This framework not only advances autonomous driving safety but also demonstrates how world models can enhance decision-making in critical applications. NavSecure sets a new standard for developing more robust and trustworthy autonomous driving systems, capable of handling the inherent dynamics and uncertainties of real-world environments.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15042', 97)">Copy Link</button>
<div id="copy-message-97" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15056">Financial Risk Assessment via Long-term Payment Behavior Sequence Folding</a></h1>
<p><b>Authors:</b> Yiran Qiao, Yateng Tang, Xiang Ao, Qi Yuan, Ziming Liu, Chen Shen, Xuehao Zheng</p>
<p>Abstract: Online inclusive financial services encounter significant financial risks due to their expansive user base and low default costs. By real-world practice, we reveal that utilizing longer-term user payment behaviors can enhance models' ability to forecast financial risks. However, learning long behavior sequences is non-trivial for deep sequential models. Additionally, the diverse fields of payment behaviors carry rich information, requiring thorough exploitation. These factors collectively complicate the task of long-term user behavior modeling. To tackle these challenges, we propose a Long-term Payment Behavior Sequence Folding method, referred to as LBSF. In LBSF, payment behavior sequences are folded based on merchants, using the merchant field as an intrinsic grouping criterion, which enables informative parallelism without reliance on external knowledge. Meanwhile, we maximize the utility of payment details through a multi-field behavior encoding mechanism. Subsequently, behavior aggregation at the merchant level followed by relational learning across merchants facilitates comprehensive user financial representation. We evaluate LBSF on the financial risk assessment task using a large-scale real-world dataset. The results demonstrate that folding long behavior sequences based on internal behavioral cues effectively models long-term patterns and changes, thereby generating more accurate user financial profiles for practical applications.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15056', 98)">Copy Link</button>
<div id="copy-message-98" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15082">Towards Speaker Identification with Minimal Dataset and Constrained Resources using 1D-Convolution Neural Network</a></h1>
<p><b>Authors:</b> Irfan Nafiz Shahan, Pulok Ahmed Auvi</p>
<p>Abstract: Voice recognition and speaker identification are vital for applications in security and personal assistants. This paper presents a lightweight 1D-Convolutional Neural Network (1D-CNN) designed to perform speaker identification on minimal datasets. Our approach achieves a validation accuracy of 97.87%, leveraging data augmentation techniques to handle background noise and limited training samples. Future improvements include testing on larger datasets and integrating transfer learning methods to enhance generalizability. We provide all code, the custom dataset, and the trained models to facilitate reproducibility. These resources are available on our GitHub repository: https://github.com/IrfanNafiz/RecMe.</p>
<p>URLs: <a href="https://github.com/IrfanNafiz/RecMe.">https://github.com/IrfanNafiz/RecMe.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15082, https://github.com/IrfanNafiz/RecMe.', 99)">Copy Link</button>
<div id="copy-message-99" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15096">RED: Effective Trajectory Representation Learning with Comprehensive Information</a></h1>
<p><b>Authors:</b> Silin Zhou, Shuo Shang, Lisi Chen, Christian S. Jensen, Panos Kalnis</p>
<p>Abstract: Trajectory representation learning (TRL) maps trajectories to vectors that can then be used for various downstream tasks, including trajectory similarity computation, trajectory classification, and travel-time estimation. However, existing TRL methods often produce vectors that, when used in downstream tasks, yield insufficiently accurate results. A key reason is that they fail to utilize the comprehensive information encompassed by trajectories. We propose a self-supervised TRL framework, called RED, which effectively exploits multiple types of trajectory information. Overall, RED adopts the Transformer as the backbone model and masks the constituting paths in trajectories to train a masked autoencoder (MAE). In particular, RED considers the moving patterns of trajectories by employing a Road-aware masking strategy} that retains key paths of trajectories during masking, thereby preserving crucial information of the trajectories. RED also adopts a spatial-temporal-user joint Embedding scheme to encode comprehensive information when preparing the trajectories as model inputs. To conduct training, RED adopts Dual-objective task learning}: the Transformer encoder predicts the next segment in a trajectory, and the Transformer decoder reconstructs the entire trajectory. RED also considers the spatial-temporal correlations of trajectories by modifying the attention mechanism of the Transformer. We compare RED with 9 state-of-the-art TRL methods for 4 downstream tasks on 3 real-world datasets, finding that RED can usually improve the accuracy of the best-performing baseline by over 5%.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15096', 100)">Copy Link</button>
<div id="copy-message-100" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15098">OminiControl: Minimal and Universal Control for Diffusion Transformer</a></h1>
<p><b>Authors:</b> Zhenxiong Tan, Songhua Liu, Xingyi Yang, Qiaochu Xue, Xinchao Wang</p>
<p>Abstract: In this paper, we introduce OminiControl, a highly versatile and parameter-efficient framework that integrates image conditions into pre-trained Diffusion Transformer (DiT) models. At its core, OminiControl leverages a parameter reuse mechanism, enabling the DiT to encode image conditions using itself as a powerful backbone and process them with its flexible multi-modal attention processors. Unlike existing methods, which rely heavily on additional encoder modules with complex architectures, OminiControl (1) effectively and efficiently incorporates injected image conditions with only ~0.1% additional parameters, and (2) addresses a wide range of image conditioning tasks in a unified manner, including subject-driven generation and spatially-aligned conditions such as edges, depth, and more. Remarkably, these capabilities are achieved by training on images generated by the DiT itself, which is particularly beneficial for subject-driven generation. Extensive evaluations demonstrate that OminiControl outperforms existing UNet-based and DiT-adapted models in both subject-driven and spatially-aligned conditional generation. Additionally, we release our training dataset, Subjects200K, a diverse collection of over 200,000 identity-consistent images, along with an efficient data synthesis pipeline to advance research in subject-consistent generation.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15098', 101)">Copy Link</button>
<div id="copy-message-101" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15100">XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models</a></h1>
<p><b>Authors:</b> Yixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang Lai, Ziyi Xu, Yilong Zhao, Tianqi Chen</p>
<p>Abstract: The applications of LLM Agents are becoming increasingly complex and diverse, leading to a high demand for structured outputs that can be parsed into code, structured function calls, and embodied agent commands. These developments bring significant demands for structured generation in LLM inference. Context-free grammar is a flexible approach to enable structured generation via constrained decoding. However, executing context-free grammar requires going through several stack states over all tokens in vocabulary during runtime, bringing non-negligible overhead for structured generation. In this paper, we propose XGrammar, a flexible and efficient structure generation engine for large language models. XGrammar accelerates context-free grammar execution by dividing the vocabulary into context-independent tokens that can be prechecked and context-dependent tokens that need to be interpreted during runtime. We further build transformations to expand the grammar context and reduce the number of context-independent tokens. Additionally, we build an efficient persistent stack to accelerate the context-dependent token checks. Finally, we co-design the grammar engine with LLM inference engine to overlap grammar computation with GPU executions. Evaluation results show that XGrammar can achieve up to 100x speedup over existing solutions. Combined with an LLM inference engine, it can generate near-zero overhead structure generation in end-to-end low-LLM serving.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15100', 102)">Copy Link</button>
<div id="copy-message-102" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15106">About Time: Advances, Challenges, and Outlooks of Action Understanding</a></h1>
<p><b>Authors:</b> Alexandros Stergiou, Ronald Poppe</p>
<p>Abstract: We have witnessed impressive advances in video action understanding. Increased dataset sizes, variability, and computation availability have enabled leaps in performance and task diversification. Current systems can provide coarse- and fine-grained descriptions of video scenes, extract segments corresponding to queries, synthesize unobserved parts of videos, and predict context. This survey comprehensively reviews advances in uni- and multi-modal action understanding across a range of tasks. We focus on prevalent challenges, overview widely adopted datasets, and survey seminal works with an emphasis on recent advances. We broadly distinguish between three temporal scopes: (1) recognition tasks of actions observed in full, (2) prediction tasks for ongoing partially observed actions, and (3) forecasting tasks for subsequent unobserved action. This division allows us to identify specific action modeling and video representation challenges. Finally, we outline future directions to address current shortcomings.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15106', 103)">Copy Link</button>
<div id="copy-message-103" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15113">Efficient Pruning of Text-to-Image Models: Insights from Pruning Stable Diffusion</a></h1>
<p><b>Authors:</b> Samarth N Ramesh, Zhixue Zhao</p>
<p>Abstract: As text-to-image models grow increasingly powerful and complex, their burgeoning size presents a significant obstacle to widespread adoption, especially on resource-constrained devices. This paper presents a pioneering study on post-training pruning of Stable Diffusion 2, addressing the critical need for model compression in text-to-image domain. Our study tackles the pruning techniques for the previously unexplored multi-modal generation models, and particularly examines the pruning impact on the textual component and the image generation component separately. We conduct a comprehensive comparison on pruning the model or the single component of the model in various sparsities. Our results yield previously undocumented findings. For example, contrary to established trends in language model pruning, we discover that simple magnitude pruning outperforms more advanced techniques in text-to-image context. Furthermore, our results show that Stable Diffusion 2 can be pruned to 38.5% sparsity with minimal quality loss, achieving a significant reduction in model size. We propose an optimal pruning configuration that prunes the text encoder to 47.5% and the diffusion generator to 35%. This configuration maintains image generation quality while substantially reducing computational requirements. In addition, our work uncovers intriguing questions about information encoding in text-to-image models: we observe that pruning beyond certain thresholds leads to sudden performance drops (unreadable images), suggesting that specific weights encode critical semantics information. This finding opens new avenues for future research in model compression, interoperability, and bias identification in text-to-image models. By providing crucial insights into the pruning behavior of text-to-image models, our study lays the groundwork for developing more efficient and accessible AI-driven image generation systems</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15113', 104)">Copy Link</button>
<div id="copy-message-104" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15114">RE-Bench: Evaluating frontier AI R&amp;D capabilities of language model agents against human experts</a></h1>
<p><b>Authors:</b> Hjalmar Wijk, Tao Lin, Joel Becker, Sami Jawhar, Neev Parikh, Thomas Broadley, Lawrence Chan, Michael Chen, Josh Clymer, Jai Dhyani, Elena Ericheva, Katharyn Garcia, Brian Goodrich, Nikola Jurkovic, Megan Kinniment, Aron Lajko, Seraphina Nix, Lucas Sato, William Saunders, Maksym Taran, Ben West, Elizabeth Barnes</p>
<p>Abstract: Frontier AI safety policies highlight automation of AI research and development (R&D) by AI agents as an important capability to anticipate. However, there exist few evaluations for AI R&D capabilities, and none that are highly realistic and have a direct comparison to human performance. We introduce RE-Bench (Research Engineering Benchmark, v1), which consists of 7 challenging, open-ended ML research engineering environments and data from 71 8-hour attempts by 61 distinct human experts. We confirm that our experts make progress in the environments given 8 hours, with 82% of expert attempts achieving a non-zero score and 24% matching or exceeding our strong reference solutions. We compare humans to several public frontier models through best-of-k with varying time budgets and agent designs, and find that the best AI agents achieve a score 4x higher than human experts when both are given a total time budget of 2 hours per environment. However, humans currently display better returns to increasing time budgets, narrowly exceeding the top AI agent scores given an 8-hour budget, and achieving 2x the score of the top AI agent when both are given 32 total hours (across different attempts). Qualitatively, we find that modern AI agents possess significant expertise in many ML topics -- e.g. an agent wrote a faster custom Triton kernel than any of our human experts' -- and can generate and test solutions over ten times faster than humans, at much lower cost. We open-source the evaluation environments, human expert data, analysis code and agent trajectories to facilitate future research.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15114', 105)">Copy Link</button>
<div id="copy-message-105" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15115">VideoRepair: Improving Text-to-Video Generation via Misalignment Evaluation and Localized Refinement</a></h1>
<p><b>Authors:</b> Daeun Lee, Jaehong Yoon, Jaemin Cho, Mohit Bansal</p>
<p>Abstract: Recent text-to-video (T2V) diffusion models have demonstrated impressive generation capabilities across various domains. However, these models often generate videos that have misalignments with text prompts, especially when the prompts describe complex scenes with multiple objects and attributes. To address this, we introduce VideoRepair, a novel model-agnostic, training-free video refinement framework that automatically identifies fine-grained text-video misalignments and generates explicit spatial and textual feedback, enabling a T2V diffusion model to perform targeted, localized refinements. VideoRepair consists of four stages: In (1) video evaluation, we detect misalignments by generating fine-grained evaluation questions and answering those questions with MLLM. In (2) refinement planning, we identify accurately generated objects and then create localized prompts to refine other areas in the video. Next, in (3) region decomposition, we segment the correctly generated area using a combined grounding module. We regenerate the video by adjusting the misaligned regions while preserving the correct regions in (4) localized refinement. On two popular video generation benchmarks (EvalCrafter and T2V-CompBench), VideoRepair substantially outperforms recent baselines across various text-video alignment metrics. We provide a comprehensive analysis of VideoRepair components and qualitative examples.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15115', 106)">Copy Link</button>
<div id="copy-message-106" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15122">ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation</a></h1>
<p><b>Authors:</b> Xiaoman Zhang, Hong-Yu Zhou, Xiaoli Yang, Oishi Banerjee, Juli\'an N. Acosta, Josh Miller, Ouwen Huang, Pranav Rajpurkar</p>
<p>Abstract: AI-driven models have demonstrated significant potential in automating radiology report generation for chest X-rays. However, there is no standardized benchmark for objectively evaluating their performance. To address this, we present ReXrank, https://rexrank.ai, a public leaderboard and challenge for assessing AI-powered radiology report generation. Our framework incorporates ReXGradient, the largest test dataset consisting of 10,000 studies, and three public datasets (MIMIC-CXR, IU-Xray, CheXpert Plus) for report generation assessment. ReXrank employs 8 evaluation metrics and separately assesses models capable of generating only findings sections and those providing both findings and impressions sections. By providing this standardized evaluation framework, ReXrank enables meaningful comparisons of model performance and offers crucial insights into their robustness across diverse clinical settings. Beyond its current focus on chest X-rays, ReXrank's framework sets the stage for comprehensive evaluation of automated reporting across the full spectrum of medical imaging.</p>
<p>URLs: <a href="https://rexrank.ai,">https://rexrank.ai,</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15122, https://rexrank.ai,', 107)">Copy Link</button>
<div id="copy-message-107" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15128">Health AI Developer Foundations</a></h1>
<p><b>Authors:</b> Atilla P. Kiraly, Sebastien Baur, Kenneth Philbrick, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Nick George, Fayaz Jamil, Jing Tang, Kai Bailey, Faruk Ahmed, Akshay Goel, Abbi Ward, Lin Yang, Andrew Sellergren, Yossi Matias, Avinatan Hassidim, Shravya Shetty, Daniel Golden, Shekoofeh Azizi, David F. Steiner, Yun Liu, Tim Thelin, Rory Pilgrim, Can Kirmizibayrak</p>
<p>Abstract: Robust medical Machine Learning (ML) models have the potential to revolutionize healthcare by accelerating clinical research, improving workflows and outcomes, and producing novel insights or capabilities. Developing such ML models from scratch is cost prohibitive and requires substantial compute, data, and time (e.g., expert labeling). To address these challenges, we introduce Health AI Developer Foundations (HAI-DEF), a suite of pre-trained, domain-specific foundation models, tools, and recipes to accelerate building ML for health applications. The models cover various modalities and domains, including radiology (X-rays and computed tomography), histopathology, dermatological imaging, and audio. These models provide domain specific embeddings that facilitate AI development with less labeled data, shorter training times, and reduced computational costs compared to traditional approaches. In addition, we utilize a common interface and style across these models, and prioritize usability to enable developers to integrate HAI-DEF efficiently. We present model evaluations across various tasks and conclude with a discussion of their application and evaluation, covering the importance of ensuring efficacy, fairness, and equity. Finally, while HAI-DEF and specifically the foundation models lower the barrier to entry for ML in healthcare, we emphasize the importance of validation with problem- and population-specific data for each desired usage setting. This technical report will be updated over time as more modalities and features are added.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15128', 108)">Copy Link</button>
<div id="copy-message-108" class="copy-message"></div>
</div>
<div class="article">
<h1> cross <a href="https://arxiv.org/abs/2411.15129">Measuring Bullshit in the Language Games played by ChatGPT</a></h1>
<p><b>Authors:</b> Alessandro Trevisan, Harry Giddens, Sarah Dillon, Alan F. Blackwell</p>
<p>Abstract: Generative large language models (LLMs), which create text without direct correspondence to truth value, are widely understood to resemble the uses of language described in Frankfurt's popular monograph On Bullshit. In this paper, we offer a rigorous investigation of this topic, identifying how the phenomenon has arisen, and how it might be analysed. In this paper, we elaborate on this argument to propose that LLM-based chatbots play the 'language game of bullshit'. We use statistical text analysis to investigate the features of this Wittgensteinian language game, based on a dataset constructed to contrast the language of 1,000 scientific publications with typical pseudo-scientific text generated by ChatGPT. We then explore whether the same language features can be detected in two well-known contexts of social dysfunction: George Orwell's critique of politics and language, and David Graeber's characterisation of bullshit jobs. Using simple hypothesis-testing methods, we demonstrate that a statistical model of the language of bullshit can reliably relate the Frankfurtian artificial bullshit of ChatGPT to the political and workplace functions of bullshit as observed in natural human language.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.15129', 109)">Copy Link</button>
<div id="copy-message-109" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2303.06252">AI-Enhanced Intensive Care Unit: Revolutionizing Patient Care with Pervasive Sensing</a></h1>
<p><b>Authors:</b> Subhash Nerella, Ziyuan Guan, Scott Siegel, Jiaqing Zhang, Ruilin Zhu, Kia Khezeli, Azra Bihorac, Parisa Rashidi</p>
<p>Abstract: The intensive care unit (ICU) is a specialized hospital space where critically ill patients receive intensive care and monitoring. Comprehensive monitoring is imperative in assessing patients conditions, in particular acuity, and ultimately the quality of care. However, the extent of patient monitoring in the ICU is limited due to time constraints and the workload on healthcare providers. Currently, visual assessments for acuity, including fine details such as facial expressions, posture, and mobility, are sporadically captured, or not captured at all. These manual observations are subjective to the individual, prone to documentation errors, and overburden care providers with the additional workload. Artificial Intelligence (AI) enabled systems has the potential to augment the patient visual monitoring and assessment due to their exceptional learning capabilities. Such systems require robust annotated data to train. To this end, we have developed pervasive sensing and data processing system which collects data from multiple modalities depth images, color RGB images, accelerometry, electromyography, sound pressure, and light levels in ICU for developing intelligent monitoring systems for continuous and granular acuity, delirium risk, pain, and mobility assessment. This paper presents the Intelligent Intensive Care Unit (I2CU) system architecture we developed for real-time patient monitoring and visual assessment.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2303.06252', 110)">Copy Link</button>
<div id="copy-message-110" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2304.04640">NeuroBench: A Framework for Benchmarking Neuromorphic Computing Algorithms and Systems</a></h1>
<p><b>Authors:</b> Jason Yik, Korneel Van den Berghe, Douwe den Blanken, Younes Bouhadjar, Maxime Fabre, Paul Hueber, Weijie Ke, Mina A Khoei, Denis Kleyko, Noah Pacik-Nelson, Alessandro Pierro, Philipp Stratmann, Pao-Sheng Vincent Sun, Guangzhi Tang, Shenqi Wang, Biyan Zhou, Soikat Hasan Ahmed, George Vathakkattil Joseph, Benedetto Leto, Aurora Micheli, Anurag Kumar Mishra, Gregor Lenz, Tao Sun, Zergham Ahmed, Mahmoud Akl, Brian Anderson, Andreas G. Andreou, Chiara Bartolozzi, Arindam Basu, Petrut Bogdan, Sander Bohte, Sonia Buckley, Gert Cauwenberghs, Elisabetta Chicca, Federico Corradi, Guido de Croon, Andreea Danielescu, Anurag Daram, Mike Davies, Yigit Demirag, Jason Eshraghian, Tobias Fischer, Jeremy Forest, Vittorio Fra, Steve Furber, P. Michael Furlong, William Gilpin, Aditya Gilra, Hector A. Gonzalez, Giacomo Indiveri, Siddharth Joshi, Vedant Karia, Lyes Khacef, James C. Knight, Laura Kriener, Rajkumar Kubendran, Dhireesha Kudithipudi, Yao-Hong Liu, Shih-Chii Liu, Haoyuan Ma, Rajit Manohar, Josep Maria Margarit-Taul\'e, Christian Mayr, Konstantinos Michmizos, Dylan Muir, Emre Neftci, Thomas Nowotny, Fabrizio Ottati, Ayca Ozcelikkale, Priyadarshini Panda, Jongkil Park, Melika Payvand, Christian Pehle, Mihai A. Petrovici, Christoph Posch, Alpha Renner, Yulia Sandamirskaya, Clemens JS Schaefer, Andr\'e van Schaik, Johannes Schemmel, Samuel Schmidgall, Catherine Schuman, Jae-sun Seo, Sadique Sheik, Sumit Bam Shrestha, Manolis Sifalakis, Amos Sironi, Matthew Stewart, Kenneth Stewart, Terrence C. Stewart, Jonathan Timcheck, Nergis T\"omen, Gianvito Urgese, Marian Verhelst, Craig M. Vineyard, Bernhard Vogginger, Amirreza Yousefzadeh, Fatima Tuz Zohora, Charlotte Frenkel, Vijay Janapa Reddi</p>
<p>Abstract: Neuromorphic computing shows promise for advancing computing efficiency and capabilities of AI applications using brain-inspired principles. However, the neuromorphic research field currently lacks standardized benchmarks, making it difficult to accurately measure technological advancements, compare performance with conventional methods, and identify promising future research directions. Prior neuromorphic computing benchmark efforts have not seen widespread adoption due to a lack of inclusive, actionable, and iterative benchmark design and guidelines. To address these shortcomings, we present NeuroBench: a benchmark framework for neuromorphic computing algorithms and systems. NeuroBench is a collaboratively-designed effort from an open community of researchers across industry and academia, aiming to provide a representative structure for standardizing the evaluation of neuromorphic approaches. The NeuroBench framework introduces a common set of tools and systematic methodology for inclusive benchmark measurement, delivering an objective reference framework for quantifying neuromorphic approaches in both hardware-independent (algorithm track) and hardware-dependent (system track) settings. In this article, we outline tasks and guidelines for benchmarks across multiple application domains, and present initial performance baselines across neuromorphic and conventional approaches for both benchmark tracks. NeuroBench is intended to continually expand its benchmarks and features to foster and track the progress made by the research community.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2304.04640', 111)">Copy Link</button>
<div id="copy-message-111" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2306.05480">Artificial General Intelligence for Medical Imaging Analysis</a></h1>
<p><b>Authors:</b> Xiang Li, Lin Zhao, Lu Zhang, Zihao Wu, Zhengliang Liu, Hanqi Jiang, Chao Cao, Shaochen Xu, Yiwei Li, Haixing Dai, Yixuan Yuan, Jun Liu, Gang Li, Dajiang Zhu, Pingkun Yan, Quanzheng Li, Wei Liu, Tianming Liu, Dinggang Shen</p>
<p>Abstract: Large-scale Artificial General Intelligence (AGI) models, including Large Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented success in a variety of general domain tasks. Yet, when applied directly to specialized domains like medical imaging, which require in-depth expertise, these models face notable challenges arising from the medical field's inherent complexities and unique characteristics. In this review, we delve into the potential applications of AGI models in medical imaging and healthcare, with a primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We provide a thorough overview of the key features and enabling techniques of LLMs and AGI, and further examine the roadmaps guiding the evolution and implementation of AGI models in the medical sector, summarizing their present applications, potentialities, and associated challenges. In addition, we highlight potential future research directions, offering a holistic view on upcoming ventures. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare, and beyond.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2306.05480', 112)">Copy Link</button>
<div id="copy-message-112" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2310.00013">Adaptive Communications in Collaborative Perception with Domain Alignment for Autonomous Driving</a></h1>
<p><b>Authors:</b> Senkang Hu, Zhengru Fang, Haonan An, Guowen Xu, Yuan Zhou, Xianhao Chen, Yuguang Fang</p>
<p>Abstract: Collaborative perception among multiple connected and autonomous vehicles can greatly enhance perceptive capabilities by allowing vehicles to exchange supplementary information via communications. Despite advances in previous approaches, challenges still remain due to channel variations and data heterogeneity among collaborative vehicles. To address these issues, we propose ACC-DA, a channel-aware collaborative perception framework to dynamically adjust the communication graph and minimize the average transmission delay while mitigating the side effects from the data heterogeneity. Our novelties lie in three aspects. We first design a transmission delay minimization method, which can construct the communication graph and minimize the transmission delay according to different channel information state. We then propose an adaptive data reconstruction mechanism, which can dynamically adjust the rate-distortion trade-off to enhance perception efficiency. Moreover, it minimizes the temporal redundancy during data transmissions. Finally, we conceive a domain alignment scheme to align the data distribution from different vehicles, which can mitigate the domain gap between different vehicles and improve the performance of the target task. Comprehensive experiments demonstrate the effectiveness of our method in comparison to the existing state-of-the-art works.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2310.00013', 113)">Copy Link</button>
<div id="copy-message-113" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2405.06058">Large Language Models Show Human-like Social Desirability Biases in Survey Responses</a></h1>
<p><b>Authors:</b> Aadesh Salecha, Molly E. Ireland, Shashanka Subrahmanya, Jo\~ao Sedoc, Lyle H. Ungar, Johannes C. Eichstaedt</p>
<p>Abstract: As Large Language Models (LLMs) become widely used to model and simulate human behavior, understanding their biases becomes critical. We developed an experimental framework using Big Five personality surveys and uncovered a previously undetected social desirability bias in a wide range of LLMs. By systematically varying the number of questions LLMs were exposed to, we demonstrate their ability to infer when they are being evaluated. When personality evaluation is inferred, LLMs skew their scores towards the desirable ends of trait dimensions (i.e., increased extraversion, decreased neuroticism, etc). This bias exists in all tested models, including GPT-4/3.5, Claude 3, Llama 3, and PaLM-2. Bias levels appear to increase in more recent models, with GPT-4's survey responses changing by 1.20 (human) standard deviations and Llama 3's by 0.98 standard deviations-very large effects. This bias is robust to randomization of question order and paraphrasing. Reverse-coding all the questions decreases bias levels but does not eliminate them, suggesting that this effect cannot be attributed to acquiescence bias. Our findings reveal an emergent social desirability bias and suggest constraints on profiling LLMs with psychometric tests and on using LLMs as proxies for human participants.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2405.06058', 114)">Copy Link</button>
<div id="copy-message-114" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2405.19544">One-Shot Safety Alignment for Large Language Models via Optimal Dualization</a></h1>
<p><b>Authors:</b> Xinmeng Huang, Shuo Li, Edgar Dobriban, Osbert Bastani, Hamed Hassani, Dongsheng Ding</p>
<p>Abstract: The growing safety concerns surrounding large language models raise an urgent need to align them with diverse human preferences to simultaneously enhance their helpfulness and safety. A promising approach is to enforce safety constraints through Reinforcement Learning from Human Feedback (RLHF). For such constrained RLHF, typical Lagrangian-based primal-dual policy optimization methods are computationally expensive and often unstable. This paper presents a perspective of dualization that reduces constrained alignment to an equivalent unconstrained alignment problem. We do so by pre-optimizing a smooth and convex dual function that has a closed form. This shortcut eliminates the need for cumbersome primal-dual policy iterations, greatly reducing the computational burden and improving training stability. Our strategy leads to two practical algorithms in model-based and preference-based settings (MoCAN and PeCAN, respectively). A broad range of experiments demonstrate the effectiveness and merits of our algorithms.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2405.19544', 115)">Copy Link</button>
<div id="copy-message-115" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2407.04873">Evaluating Language Models for Generating and Judging Programming Feedback</a></h1>
<p><b>Authors:</b> Charles Koutcheme, Nicola Dainese, Arto Hellas, Sami Sarsa, Juho Leinonen, Syed Ashraf, Paul Denny</p>
<p>Abstract: The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.04873', 116)">Copy Link</button>
<div id="copy-message-116" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2408.00041">Con4m: Context-aware Consistency Learning Framework for Segmented Time Series Classification</a></h1>
<p><b>Authors:</b> Junru Chen, Tianyu Cao, Jing Xu, Jiahe Li, Zhilong Chen, Tao Xiao, Yang Yang</p>
<p>Abstract: Time Series Classification (TSC) encompasses two settings: classifying entire sequences or classifying segmented subsequences. The raw time series for segmented TSC usually contain Multiple classes with Varying Duration of each class (MVD). Therefore, the characteristics of MVD pose unique challenges for segmented TSC, yet have been largely overlooked by existing works. Specifically, there exists a natural temporal dependency between consecutive instances (segments) to be classified within MVD. However, mainstream TSC models rely on the assumption of independent and identically distributed (i.i.d.), focusing on independently modeling each segment. Additionally, annotators with varying expertise may provide inconsistent boundary labels, leading to unstable performance of noise-free TSC models. To address these challenges, we first formally demonstrate that valuable contextual information enhances the discriminative power of classification instances. Leveraging the contextual priors of MVD at both the data and label levels, we propose a novel consistency learning framework Con4m, which effectively utilizes contextual information more conducive to discriminating consecutive segments in segmented TSC tasks, while harmonizing inconsistent boundary labels for training. Extensive experiments across multiple datasets validate the effectiveness of Con4m in handling segmented TSC tasks on MVD.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2408.00041', 117)">Copy Link</button>
<div id="copy-message-117" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2408.10556">Hokoff: Real Game Dataset from Honor of Kings and its Offline Reinforcement Learning Benchmarks</a></h1>
<p><b>Authors:</b> Yun Qu, Boyuan Wang, Jianzhun Shao, Yuhang Jiang, Chen Chen, Zhenbin Ye, Lin Liu, Junfeng Yang, Lin Lai, Hongyang Qin, Minwen Deng, Juchao Zhuo, Deheng Ye, Qiang Fu, Wei Yang, Guang Yang, Lanxiao Huang, Xiangyang Ji</p>
<p>Abstract: The advancement of Offline Reinforcement Learning (RL) and Offline Multi-Agent Reinforcement Learning (MARL) critically depends on the availability of high-quality, pre-collected offline datasets that represent real-world complexities and practical applications. However, existing datasets often fall short in their simplicity and lack of realism. To address this gap, we propose Hokoff, a comprehensive set of pre-collected datasets that covers both offline RL and offline MARL, accompanied by a robust framework, to facilitate further research. This data is derived from Honor of Kings, a recognized Multiplayer Online Battle Arena (MOBA) game known for its intricate nature, closely resembling real-life situations. Utilizing this framework, we benchmark a variety of offline RL and offline MARL algorithms. We also introduce a novel baseline algorithm tailored for the inherent hierarchical action space of the game. We reveal the incompetency of current offline RL approaches in handling task complexity, generalization and multi-task learning.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2408.10556', 118)">Copy Link</button>
<div id="copy-message-118" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2410.07866">System 2 Reasoning via Generality and Adaptation</a></h1>
<p><b>Authors:</b> Sejin Kim, Sundong Kim</p>
<p>Abstract: While significant progress has been made in task-specific applications, current models struggle with deep reasoning, generality, and adaptation -- key components of System 2 reasoning that are crucial for achieving Artificial General Intelligence (AGI). Despite the promise of approaches such as program synthesis, language models, and transformers, these methods often fail to generalize beyond their training data and to adapt to novel tasks, limiting their ability to perform human-like reasoning. This paper explores the limitations of existing approaches in achieving advanced System 2 reasoning and highlights the importance of generality and adaptation for AGI. Moreover, we propose four key research directions to address these gaps: (1) learning human intentions from action sequences, (2) combining symbolic and neural models, (3) meta-learning for unfamiliar environments, and (4) reinforcement learning to reason multi-step. Through these directions, we aim to advance the ability to generalize and adapt, bringing computational models closer to the reasoning capabilities required for AGI.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.07866', 119)">Copy Link</button>
<div id="copy-message-119" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2410.18970">ConceptDrift: Uncovering Biases through the Lens of Foundation Models</a></h1>
<p><b>Authors:</b> Cristian Daniel P\u{a}duraru, Antonio B\u{a}rb\u{a}lau, Radu Filipescu, Andrei Liviu Nicolicioiu, Elena Burceanu</p>
<p>Abstract: An important goal of ML research is to identify and mitigate unwanted biases intrinsic to datasets and already incorporated into pre-trained models. Previous approaches have identified biases using highly curated validation subsets, that require human knowledge to create in the first place. This limits the ability to automate the discovery of unknown biases in new datasets. We solve this by using interpretable vision-language models, combined with a filtration method using LLMs and known concept hierarchies. More exactly, for a dataset, we use pre-trained CLIP models that have an associated embedding for each class and see how it drifts through learning towards embeddings that disclose hidden biases. We call this approach ConceptDrift and show that it can be scaled to automatically identify biases in datasets like ImageNet without human prior knowledge. We propose two bias identification evaluation protocols to fill the gap in the previous work and show that our method significantly improves over SoTA methods, both using our protocol and classical evaluations. Alongside validating the identified biases, we also show that they can be leveraged to improve the performance of different methods. Our method is not bounded to a single modality, and we empirically validate it both on image (Waterbirds, CelebA, ImageNet), and text datasets (CivilComments).</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.18970', 120)">Copy Link</button>
<div id="copy-message-120" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2411.03205">GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis</a></h1>
<p><b>Authors:</b> Temitope Akinboyewa, Zhenlong Li, Huan Ning, M. Naser Lessani</p>
<p>Abstract: Recent advancements in Generative AI offer promising capabilities for spatial analysis. Despite their potential, the integration of generative AI with established GIS platforms remains underexplored. In this study, we propose a framework for integrating LLMs directly into existing GIS platforms, using QGIS as an example. Our approach leverages the reasoning and programming capabilities of LLMs to autonomously generate spatial analysis workflows and code through an informed agent that has comprehensive documentation of key GIS tools and parameters. The implementation of this framework resulted in the development of a "GIS Copilot" that allows GIS users to interact with QGIS using natural language commands for spatial analysis. The GIS Copilot was evaluated with over 100 spatial analysis tasks with three complexity levels: basic tasks that require one GIS tool and typically involve one data layer to perform simple operations; intermediate tasks involving multi-step processes with multiple tools, guided by user instructions; and advanced tasks which involve multi-step processes that require multiple tools but not guided by user instructions, necessitating the agent to independently decide on and executes the necessary steps. The evaluation reveals that the GIS Copilot demonstrates strong potential in automating foundational GIS operations, with a high success rate in tool selection and code generation for basic and intermediate tasks, while challenges remain in achieving full autonomy for more complex tasks. This study contributes to the emerging vision of Autonomous GIS, providing a pathway for non-experts to engage with geospatial analysis with minimal prior expertise. While full autonomy is yet to be achieved, the GIS Copilot demonstrates significant potential for simplifying GIS workflows and enhancing decision-making processes.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.03205', 121)">Copy Link</button>
<div id="copy-message-121" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2411.03817">From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning</a></h1>
<p><b>Authors:</b> Zhirui Deng, Zhicheng Dou, Yutao Zhu, Ji-Rong Wen, Ruibin Xiong, Mang Wang, Weipeng Chen</p>
<p>Abstract: The outstanding capabilities of large language models (LLMs) render them a crucial component in various autonomous agent systems. While traditional methods depend on the inherent knowledge of LLMs without fine-tuning, more recent approaches have shifted toward the reinforcement learning strategy to further enhance agents' ability to solve complex interactive tasks with environments and tools. However, previous approaches are constrained by the sparse reward issue, where existing datasets solely provide a final scalar reward for each multi-step reasoning chain, potentially leading to ineffectiveness and inefficiency in policy learning. In this paper, we introduce StepAgent, which utilizes step-wise reward to optimize the agent's reinforcement learning process. Inheriting the spirit of novice-to-expert theory, we first compare the actions of the expert and the agent to automatically generate intermediate rewards for fine-grained optimization. Additionally, we propose implicit-reward and inverse reinforcement learning techniques to facilitate agent reflection and policy adjustment. Further theoretical analysis demonstrates that the action distribution of the agent can converge toward the expert action distribution over multiple training cycles. Experimental results across various datasets indicate that StepAgent outperforms existing baseline methods.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.03817', 122)">Copy Link</button>
<div id="copy-message-122" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2411.04282">Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding</a></h1>
<p><b>Authors:</b> Haolin Chen, Yihao Feng, Zuxin Liu, Weiran Yao, Akshara Prabhakar, Shelby Heinecke, Ricky Ho, Phil Mui, Silvio Savarese, Caiming Xiong, Huan Wang</p>
<p>Abstract: Large language models (LLMs) have shown impressive capabilities, but still struggle with complex reasoning tasks requiring multiple steps. While prompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at inference time, optimizing reasoning capabilities during training remains challenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled framework that formulates reasoning as sampling from a latent distribution and optimizes it via variational approaches. LaTRO enables LLMs to concurrently improve both their reasoning process and ability to evaluate reasoning quality, without requiring external feedback or reward models. We validate LaTRO through experiments on GSM8K and ARC-Challenge datasets using multiple model architectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of 12.5% over base models and 9.6% over supervised fine-tuning across Phi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that pre-trained LLMs possess latent reasoning capabilities that can be unlocked and enhanced through our proposed optimization approach in a self-improvement manner. The code of LaTRO is available at \url{https://github.com/SalesforceAIResearch/LaTRO}.</p>
<p>URLs: <a href="https://github.com/SalesforceAIResearch/LaTRO">https://github.com/SalesforceAIResearch/LaTRO</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.04282, https://github.com/SalesforceAIResearch/LaTRO', 123)">Copy Link</button>
<div id="copy-message-123" class="copy-message"></div>
</div>
<div class="article">
<h1> replace <a href="https://arxiv.org/abs/2411.04872">FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI</a></h1>
<p><b>Authors:</b> Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan Chen, Alex Gunning, Caroline Falkman Olsson, Jean-Stanislas Denain, Anson Ho, Emily de Oliveira Santos, Olli J\"arviniemi, Matthew Barnett, Robert Sandler, Matej Vrzala, Jaime Sevilla, Qiuyu Ren, Elizabeth Pratt, Lionel Levine, Grant Barkley, Natalie Stewart, Bogdan Grechuk, Tetiana Grechuk, Shreepranav Varma Enugandla, Mark Wildon</p>
<p>Abstract: We introduce FrontierMath, a benchmark of hundreds of original, exceptionally challenging mathematics problems crafted and vetted by expert mathematicians. The questions cover most major branches of modern mathematics -- from computationally intensive problems in number theory and real analysis to abstract questions in algebraic geometry and category theory. Solving a typical problem requires multiple hours of effort from a researcher in the relevant branch of mathematics, and for the upper end questions, multiple days. FrontierMath uses new, unpublished problems and automated verification to reliably evaluate models while minimizing risk of data contamination. Current state-of-the-art AI models solve under 2% of problems, revealing a vast gap between AI capabilities and the prowess of the mathematical community. As AI systems advance toward expert-level mathematical abilities, FrontierMath offers a rigorous testbed that quantifies their progress.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.04872', 124)">Copy Link</button>
<div id="copy-message-124" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2212.08162">Huber-energy measure quantization</a></h1>
<p><b>Authors:</b> Gabriel Turinici</p>
<p>Abstract: We describe a measure quantization procedure i.e., an algorithm which finds the best approximation of a target probability law (and more generally signed finite variation measure) by a sum of $Q$ Dirac masses ($Q$ being the quantization parameter). The procedure is implemented by minimizing the statistical distance between the original measure and its quantized version; the distance is built from a negative definite kernel and, if necessary, can be computed on the fly and feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We investigate theoretically the fundamental questions of existence of the optimal measure quantizer and identify what are the required kernel properties that guarantee suitable behavior. We propose two best linear unbiased (BLUE) estimators for the squared statistical distance and use them in an unbiased procedure, called HEMQ, to find the optimal quantization. We test HEMQ on several databases: multi-dimensional Gaussian mixtures, Wiener space cubature, Italian wine cultivars and the MNIST image database. The results indicate that the HEMQ algorithm is robust and versatile and, for the class of Huber-energy kernels, matches the expected intuitive behavior.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2212.08162', 125)">Copy Link</button>
<div id="copy-message-125" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2304.07741">Canvas: End-to-End Kernel Architecture Search in Neural Networks</a></h1>
<p><b>Authors:</b> Chenggang Zhao, Genghan Zhang, Ao Shen, Mingyu Gao</p>
<p>Abstract: The demands for higher performance and accuracy in neural networks (NNs) never end. Existing tensor compilation and Neural Architecture Search (NAS) techniques orthogonally optimize the two goals but actually share many similarities in their concrete strategies. We exploit such opportunities by combining the two into one and make a case for Kernel Architecture Search (KAS). KAS reviews NAS from a system perspective and zooms into a more fine-grained level to generate neural kernels with both high performance and good accuracy. To demonstrate the potential of KAS, we build an end-to-end framework, Canvas, to find high-quality kernels as convolution replacements. Canvas samples from a rich set of fine-grained primitives to stochastically and iteratively construct new kernels and evaluate them according to user-specified constraints. Canvas supports freely adjustable tensor dimension sizes inside the kernel and uses two levels of solvers to satisfy structural legality and fully utilize model budgets. The evaluation shows that by replacing standard convolutions with generated new kernels in common NNs, Canvas achieves average 1.5x speedups compared to the previous state-of-the-art with acceptable accuracy loss and search efficiency. Canvas verifies the practicability of KAS by rediscovering many manually designed kernels in the past and producing new structures that may inspire future machine learning innovations. For source code and implementation, we open-sourced Canvas at https://github.com/tsinghua-ideal/Canvas.</p>
<p>URLs: <a href="https://github.com/tsinghua-ideal/Canvas.">https://github.com/tsinghua-ideal/Canvas.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2304.07741, https://github.com/tsinghua-ideal/Canvas.', 126)">Copy Link</button>
<div id="copy-message-126" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2305.09145">Deep ReLU Networks Have Surprisingly Simple Polytopes</a></h1>
<p><b>Authors:</b> Feng-Lei Fan, Wei Huang, Xiangru Zhong, Lecheng Ruan, Tieyong Zeng, Huan Xiong, Fei Wang</p>
<p>Abstract: A ReLU network is a piecewise linear function over polytopes. Figuring out the properties of such polytopes is of fundamental importance for the research and development of neural networks. So far, either theoretical or empirical studies on polytopes only stay at the level of counting their number, which is far from a complete characterization. Here, we propose to study the shapes of polytopes via the number of faces of the polytope. Then, by computing and analyzing the histogram of faces across polytopes, we find that a ReLU network has relatively simple polytopes under both initialization and gradient descent, although these polytopes can be rather diverse and complicated by a specific design. This finding can be appreciated as a kind of generalized implicit bias, subjected to the intrinsic geometric constraint in space partition of a ReLU network. Next, we perform a combinatorial analysis to explain why adding depth does not generate a more complicated polytope by bounding the average number of faces of polytopes with the dimensionality. Our results concretely reveal what kind of simple functions a network learns and what will happen when a network goes deep. Also, by characterizing the shape of polytopes, the number of faces can be a novel leverage for other problems, \textit{e.g.}, serving as a generic tool to explain the power of popular shortcut networks such as ResNet and analyzing the impact of different regularization strategies on a network's space partition.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2305.09145', 127)">Copy Link</button>
<div id="copy-message-127" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2306.06077">Semantically-Prompted Language Models Improve Visual Descriptions</a></h1>
<p><b>Authors:</b> Michael Ogezi, Bradley Hauer, Grzegorz Kondrak</p>
<p>Abstract: Language-vision models like CLIP have made significant strides in vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive visual descriptions remains challenging; descriptions produced by current methods are often ambiguous and lacking in granularity. To tackle these issues, we propose V-GLOSS: Visual Glosses, a novel method built upon two key ideas. The first is Semantic Prompting, which conditions a language model on structured semantic knowledge. The second is a new contrastive algorithm that elicits fine-grained distinctions between similar concepts. With both ideas, we demonstrate that V-GLOSS improves visual descriptions and achieves strong results in the zero-shot setting on general and fine-grained image-classification datasets, including ImageNet, STL-10, FGVC Aircraft, and Flowers 102. Moreover, these descriptive capabilities contribute to enhancing image-generation performance. Finally, we introduce a quality-tested silver dataset with descriptions generated with V-GLOSS for all ImageNet classes.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2306.06077', 128)">Copy Link</button>
<div id="copy-message-128" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2306.06202">NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics</a></h1>
<p><b>Authors:</b> Anwar Said, Roza G. Bayrak, Tyler Derr, Mudassir Shabbir, Daniel Moyer, Catie Chang, Xenofon Koutsoukos</p>
<p>Abstract: Machine learning provides a valuable tool for analyzing high-dimensional functional neuroimaging data, and is proving effective in predicting various neurological conditions, psychiatric disorders, and cognitive patterns. In functional magnetic resonance imaging (MRI) research, interactions between brain regions are commonly modeled using graph-based representations. The potency of graph machine learning methods has been established across myriad domains, marking a transformative step in data interpretation and predictive modeling. Yet, despite their promise, the transposition of these techniques to the neuroimaging domain has been challenging due to the expansive number of potential preprocessing pipelines and the large parameter search space for graph-based dataset construction. In this paper, we introduce NeuroGraph, a collection of graph-based neuroimaging datasets, and demonstrated its utility for predicting multiple categories of behavioral and cognitive traits. We delve deeply into the dataset generation search space by crafting 35 datasets that encompass static and dynamic brain connectivity, running in excess of 15 baseline methods for benchmarking. Additionally, we provide generic frameworks for learning on both static and dynamic graphs. Our extensive experiments lead to several key observations. Notably, using correlation vectors as node features, incorporating larger number of regions of interest, and employing sparser graphs lead to improved performance. To foster further advancements in graph-based data driven neuroimaging analysis, we offer a comprehensive open-source Python package that includes the benchmark datasets, baseline implementations, model training, and standard evaluation.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2306.06202', 129)">Copy Link</button>
<div id="copy-message-129" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2312.03720">Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits</a></h1>
<p><b>Authors:</b> Johannes Schneider, Steffi Haag, Leona Chandra Kruse</p>
<p>Abstract: Large language models LLMs like ChatGPT have reached the 100 Mio user barrier in record time and might increasingly enter all areas of our life leading to a diverse set of interactions between those Artificial Intelligence models and humans. While many studies have discussed governance and regulations deductively from first-order principles, few studies provide an inductive, data-driven lens based on observing dialogues between humans and LLMs especially when it comes to non-collaborative, competitive situations that have the potential to pose a serious threat to people. In this work, we conduct a user study engaging over 40 individuals across all age groups in price negotiations with an LLM. We explore how people interact with an LLM, investigating differences in negotiation outcomes and strategies. Furthermore, we highlight shortcomings of LLMs with respect to their reasoning capabilities and, in turn, susceptiveness to prompt hacking, which intends to manipulate the LLM to make agreements that are against its instructions or beyond any rationality. We also show that the negotiated prices humans manage to achieve span a broad range, which points to a literacy gap in effectively interacting with LLMs.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2312.03720', 130)">Copy Link</button>
<div id="copy-message-130" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2402.04292">AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies</a></h1>
<p><b>Authors:</b> Xixi Hu, Bo Liu, Xingchao Liu, Qiang Liu</p>
<p>Abstract: Diffusion-based imitation learning improves Behavioral Cloning (BC) on multi-modal decision-making, but comes at the cost of significantly slower inference due to the recursion in the diffusion process. It urges us to design efficient policy generators while keeping the ability to generate diverse actions. To address this challenge, we propose AdaFlow, an imitation learning framework based on flow-based generative modeling. AdaFlow represents the policy with state-conditioned ordinary differential equations (ODEs), which are known as probability flows. We reveal an intriguing connection between the conditional variance of their training loss and the discretization error of the ODEs. With this insight, we propose a variance-adaptive ODE solver that can adjust its step size in the inference stage, making AdaFlow an adaptive decision-maker, offering rapid inference without sacrificing diversity. Interestingly, it automatically reduces to a one-step generator when the action distribution is uni-modal. Our comprehensive empirical evaluation shows that AdaFlow achieves high performance with fast inference speed.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2402.04292', 131)">Copy Link</button>
<div id="copy-message-131" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2402.14989">Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data</a></h1>
<p><b>Authors:</b> YongKyung Oh, Dongyoung Lim, Sungil Kim</p>
<p>Abstract: Irregular sampling intervals and missing values in real-world time series data present challenges for conventional methods that assume consistent intervals and complete data. Neural Ordinary Differential Equations (Neural ODEs) offer an alternative approach, utilizing neural networks combined with ODE solvers to learn continuous latent representations through parameterized vector fields. Neural Stochastic Differential Equations (Neural SDEs) extend Neural ODEs by incorporating a diffusion term, although this addition is not trivial, particularly when addressing irregular intervals and missing values. Consequently, careful design of drift and diffusion functions is crucial for maintaining stability and enhancing performance, while incautious choices can result in adverse properties such as the absence of strong solutions, stochastic destabilization, or unstable Euler discretizations, significantly affecting Neural SDEs' performance. In this study, we propose three stable classes of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE. Then, we rigorously demonstrate their robustness in maintaining excellent performance under distribution shift, while effectively preventing overfitting. To assess the effectiveness of our approach, we conduct extensive experiments on four benchmark datasets for interpolation, forecasting, and classification tasks, and analyze the robustness of our methods with 30 public datasets under different missing rates. Our results demonstrate the efficacy of the proposed method in handling real-world irregular time series data.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2402.14989', 132)">Copy Link</button>
<div id="copy-message-132" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2403.08936">Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning</a></h1>
<p><b>Authors:</b> Peihong Yu, Manav Mishra, Alec Koppel, Carl Busart, Priya Narayan, Dinesh Manocha, Amrit Bedi, Pratap Tokekar</p>
<p>Abstract: Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of efficient exploration due to the exponential increase in the size of the joint state-action space. While demonstration-guided learning has proven beneficial in single-agent settings, its direct applicability to MARL is hindered by the practical difficulty of obtaining joint expert demonstrations. In this work, we introduce a novel concept of personalized expert demonstrations, tailored for each individual agent or, more broadly, each individual type of agent within a heterogeneous team. These demonstrations solely pertain to single-agent behaviors and how each agent can achieve personal goals without encompassing any cooperative elements, thus naively imitating them will not achieve cooperation due to potential conflicts. To this end, we propose an approach that selectively utilizes personalized expert demonstrations as guidance and allows agents to learn to cooperate, namely personalized expert-guided MARL (PegMARL). This algorithm utilizes two discriminators: the first provides incentives based on the alignment of individual agent behavior with demonstrations, and the second regulates incentives based on whether the behaviors lead to the desired outcome. We evaluate PegMARL using personalized demonstrations in both discrete and continuous environments. The results demonstrate that PegMARL learns near-optimal policies even when provided with suboptimal demonstrations and outperforms state-of-the-art MARL algorithms in solving coordinated tasks. We also showcase PegMARL's capability of leveraging joint demonstrations in the StarCraft scenario and converging effectively even with demonstrations from non-co-trained policies.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2403.08936', 133)">Copy Link</button>
<div id="copy-message-133" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2404.13736">Interval Abstractions for Robust Counterfactual Explanations</a></h1>
<p><b>Authors:</b> Junqi Jiang, Francesco Leofante, Antonio Rago, Francesca Toni</p>
<p>Abstract: Counterfactual Explanations (CEs) have emerged as a major paradigm in explainable AI research, providing recourse recommendations for users affected by the decisions of machine learning models. However, CEs found by existing methods often become invalid when slight changes occur in the parameters of the model they were generated for. The literature lacks a way to provide exhaustive robustness guarantees for CEs under model changes, in that existing methods to improve CEs' robustness are mostly heuristic, and the robustness performances are evaluated empirically using only a limited number of retrained models. To bridge this gap, we propose a novel interval abstraction technique for parametric machine learning models, which allows us to obtain provable robustness guarantees for CEs under a possibly infinite set of plausible model changes $\Delta$. Based on this idea, we formalise a robustness notion for CEs, which we call $\Delta$-robustness, in both binary and multi-class classification settings. We present procedures to verify $\Delta$-robustness based on Mixed Integer Linear Programming, using which we further propose algorithms to generate CEs that are $\Delta$-robust. In an extensive empirical study involving neural networks and logistic regression models, we demonstrate the practical applicability of our approach. We discuss two strategies for determining the appropriate hyperparameters in our method, and we quantitatively benchmark CEs generated by eleven methods, highlighting the effectiveness of our algorithms in finding robust CEs.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2404.13736', 134)">Copy Link</button>
<div id="copy-message-134" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2404.14117">Hierarchical localization with panoramic views and triplet loss functions</a></h1>
<p><b>Authors:</b> Marcos Alfaro, Juan Jos\'e Cabrera, Mar\'ia Flores, \'Oscar Reinoso, Luis Pay\'a</p>
<p>Abstract: The main objective of this paper is to tackle visual localization, which is essential for the safe navigation of mobile robots. The solution we propose employs panoramic images and triplet convolutional neural networks. We seek to exploit the properties of such architectures to address both hierarchical and global localization in indoor environments, which are prone to visual aliasing and other phenomena. Considering their importance in these architectures, a complete comparative evaluation of different triplet loss functions is performed. The experimental section proves that triplet networks can be trained with a relatively low number of images captured under a specific lighting condition and even so, the resulting networks are a robust tool to perform visual localization under dynamic conditions. Our approach has been evaluated against some of these effects, such as changes in the lighting conditions, occlusions, noise and motion blurring. Furthermore, to explore the limits of our approach, triplet networks have been tested in different indoor environments simultaneously. In all the cases, these architectures have demonstrated a great capability to generalize to diverse and challenging scenarios. The code used in the experiments is available at https://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.</p>
<p>URLs: <a href="https://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.">https://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2404.14117, https://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.', 135)">Copy Link</button>
<div id="copy-message-135" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2404.17916">FedCRL: Personalized Federated Learning with Contrastive Shared Representations for Label Heterogeneity in Non-IID Data</a></h1>
<p><b>Authors:</b> Chenghao Huang, Xiaolu Chen, Yanru Zhang, Hao Wang</p>
<p>Abstract: Heterogeneity resulting from label distribution skew and data scarcity can lead to inaccuracy and unfairness in intelligent communication applications that mainly rely on distributed computing. To deal with it, this paper proposes a novel personalized federated learning algorithm, named Federated Contrastive Shareable Representations (FedCoSR), to facilitate knowledge sharing among clients while maintaining data privacy. Specifically, parameters of local models' shallow layers and typical local representations are both considered shareable information for the server and aggregated globally. To address poor performance caused by label distribution skew among clients, contrastive learning is adopted between local and global representations to enrich local knowledge. Additionally, to ensure fairness for clients with scarce data, FedCoSR introduces adaptive local aggregation to coordinate the global model involvement in each client. Our simulations demonstrate FedCoSR's effectiveness in mitigating label heterogeneity by achieving accuracy and fairness improvements over existing methods on datasets with varying degrees of label heterogeneity.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2404.17916', 136)">Copy Link</button>
<div id="copy-message-136" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2405.05966">Natural Language Processing RELIES on Linguistics</a></h1>
<p><b>Authors:</b> Juri Opitz, Shira Wein, Nathan Schneider</p>
<p>Abstract: Large Language Models (LLMs) have become capable of generating highly fluent text in certain languages, without modules specially designed to capture grammar or semantic coherence. What does this mean for the future of linguistic expertise in NLP? We highlight several aspects in which NLP (still) relies on linguistics, or where linguistic thinking can illuminate new directions. We argue our case around the acronym RELIES that encapsulates six major facets where linguistics contributes to NLP: Resources, Evaluation, Low-resource settings, Interpretability, Explanation, and the Study of language. This list is not exhaustive, nor is linguistics the main point of reference for every effort under these themes; but at a macro level, these facets highlight the enduring importance of studying machine systems vis-\`a-vis systems of human language.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2405.05966', 137)">Copy Link</button>
<div id="copy-message-137" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2406.14596">VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought</a></h1>
<p><b>Authors:</b> Gabriel Sarch, Lawrence Jang, Michael J. Tarr, William W. Cohen, Kenneth Marino, Katerina Fragkiadaki</p>
<p>Abstract: Large-scale generative language and vision-language models (LLMs and VLMs) excel in few-shot in-context learning for decision making and instruction following. However, they require high-quality exemplar demonstrations in their context window. In this work, we ask: Can LLMs and VLMs generate their own examples from generic, sub-optimal demonstrations? We propose In-Context Abstraction Learning (ICAL), a method that builds a memory of multimodal experience from sub-optimal demonstrations and human feedback. Given a task demonstration that may contain inefficiencies or mistakes, a VLM abstracts the trajectory into a generalized program of thoughts by correcting inefficient actions and annotating cognitive abstractions: causal relationships, object state changes, temporal subgoals, and task-relevant visual elements. These programs of thought are iteratively improved through human feedback while the agent executes the trajectory in a similar environment. The resulting examples significantly improve decision-making in retrieval-augmented LLM and VLM agents. Moreover, as the agent's library of examples grows, it becomes more efficient, relying less on human feedback and requiring fewer environment interactions per demonstration. Our ICAL agent surpasses the SOTA in dialogue-based instruction following in TEACh, multimodal web agents in VisualWebArena, and action anticipation in Ego4D. In TEACh, we achieve a 12.6% improvement in goal-condition success. In VisualWebArena, our task success rate improves over few-shot GPT4V. In Ego4D action forecasting, we improve over few-shot GPT-4V and remain competitive with supervised models. We show finetuning our retrieval-augmented in-context agent yields additional improvements. Our approach significantly reduces reliance on manual prompt engineering and consistently outperforms in-context learning from action plans that lack such programs of thought.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2406.14596', 138)">Copy Link</button>
<div id="copy-message-138" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2406.18060">AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning</a></h1>
<p><b>Authors:</b> Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang</p>
<p>Abstract: Fine-tuning large language models (LLMs) has achieved remarkable performance across various natural language processing tasks, yet it demands more and more memory as model sizes keep growing. To address this issue, the recently proposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs using only forward passes, thereby avoiding the need for a backpropagation graph. However, significant performance drops and a high risk of divergence have limited their widespread adoption. In this paper, we propose the Adaptive Zeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed to improve the performance and convergence of the ZO methods. To enhance dimension-dependent ZO estimation accuracy, we introduce a fast-forward, low-parameter tensorized adapter. To tackle the frequently observed divergence issue in large-scale ZO fine-tuning tasks, we propose an adaptive query number schedule that guarantees convergence. Detailed theoretical analysis and extensive experimental results on Roberta-Large and Llama-2-7B models substantiate the efficacy of our AdaZeta framework in terms of accuracy, memory efficiency, and convergence speed.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2406.18060', 139)">Copy Link</button>
<div id="copy-message-139" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2407.01782">Addressing a fundamental limitation in deep vision models: lack of spatial attention</a></h1>
<p><b>Authors:</b> Ali Borji</p>
<p>Abstract: The primary aim of this manuscript is to underscore a significant limitation in current deep learning models, particularly vision models. Unlike human vision, which efficiently selects only the essential visual areas for further processing, leading to high speed and low energy consumption, deep vision models process the entire image. In this work, we examine this issue from a broader perspective and propose two solutions that could pave the way for the next generation of more efficient vision models. In the first solution, convolution and pooling operations are selectively applied to altered regions, with a change map sent to subsequent layers. This map indicates which computations need to be repeated. In the second solution, only the modified regions are processed by a semantic segmentation model, and the resulting segments are inserted into the corresponding areas of the previous output map. The code is available at https://github.com/aliborji/spatial_attention.</p>
<p>URLs: <a href="https://github.com/aliborji/spatial_attention.">https://github.com/aliborji/spatial_attention.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.01782, https://github.com/aliborji/spatial_attention.', 140)">Copy Link</button>
<div id="copy-message-140" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2407.06194">More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models</a></h1>
<p><b>Authors:</b> Messi H. J. Lee, Jacob M. Montgomery, Calvin K. Lai</p>
<p>Abstract: Vision Language Models (VLMs), exemplified by GPT-4V, adeptly integrate text and vision modalities. This integration enhances Large Language Models' ability to mimic human perception, allowing them to process image inputs. Despite VLMs' advanced capabilities, however, there is a concern that VLMs inherit biases of both modalities in ways that make biases more pervasive and difficult to mitigate. Our study explores how VLMs perpetuate homogeneity bias and trait associations with regards to race and gender. When prompted to write stories based on images of human faces, GPT-4V describes subordinate racial and gender groups with greater homogeneity than dominant groups and relies on distinct, yet generally positive, stereotypes. Importantly, VLM stereotyping is driven by visual cues rather than group membership alone such that faces that are rated as more prototypically Black and feminine are subject to greater stereotyping. These findings suggest that VLMs may associate subtle visual cues related to racial and gender groups with stereotypes in ways that could be challenging to mitigate. We explore the underlying reasons behind this behavior and discuss its implications and emphasize the importance of addressing these biases as VLMs come to mirror human perception.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.06194', 141)">Copy Link</button>
<div id="copy-message-141" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2407.08713">GTA: A Benchmark for General Tool Agents</a></h1>
<p><b>Authors:</b> Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le</p>
<p>Abstract: Significant focus has been placed on integrating large language models (LLMs) with various tools in developing general-purpose agents. This poses a challenge to LLMs' tool-use capabilities. However, there are evident gaps between existing tool-use evaluations and real-world scenarios. Current evaluations often use AI-generated queries, single-step tasks, dummy tools, and text-only interactions, failing to reveal the agents' real-world problem-solving abilities effectively. To address this, we propose GTA, a benchmark for General Tool Agents, featuring three main aspects: (i) Real user queries: human-written queries with simple real-world objectives but implicit tool-use, requiring the LLM to reason the suitable tools and plan the solution steps. (ii) Real deployed tools: an evaluation platform equipped with tools across perception, operation, logic, and creativity categories to evaluate the agents' actual task execution performance. (iii) Real multimodal inputs: authentic image files, such as spatial scenes, web page screenshots, tables, code snippets, and printed/handwritten materials, used as the query contexts to align with real-world scenarios closely. We design 229 real-world tasks and executable tool chains to evaluate mainstream LLMs. Our findings show that real-world user queries are challenging for existing LLMs, with GPT-4 completing less than 50% of the tasks and most LLMs achieving below 25%. This evaluation reveals the bottlenecks in the tool-use capabilities of current LLMs in real-world scenarios, which provides future direction for advancing general-purpose tool agents. The code and dataset are available at https://github.com/open-compass/GTA.</p>
<p>URLs: <a href="https://github.com/open-compass/GTA.">https://github.com/open-compass/GTA.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.08713, https://github.com/open-compass/GTA.', 142)">Copy Link</button>
<div id="copy-message-142" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2407.12043">The Art of Saying No: Contextual Noncompliance in Language Models</a></h1>
<p><b>Authors:</b> Faeze Brahman, Sachin Kumar, Vidhisha Balachandran, Pradeep Dasigi, Valentina Pyatkin, Abhilasha Ravichander, Sarah Wiegreffe, Nouha Dziri, Khyathi Chandu, Jack Hessel, Yulia Tsvetkov, Noah A. Smith, Yejin Choi, Hannaneh Hajishirzi</p>
<p>Abstract: Chat-based language models are designed to be helpful, yet they should not comply with every user request. While most existing work primarily focuses on refusal of "unsafe" queries, we posit that the scope of noncompliance should be broadened. We introduce a comprehensive taxonomy of contextual noncompliance describing when and how models should not comply with user requests. Our taxonomy spans a wide range of categories including incomplete, unsupported, indeterminate, and humanizing requests (in addition to unsafe requests). To test noncompliance capabilities of language models, we use this taxonomy to develop a new evaluation suite of 1000 noncompliance prompts. We find that most existing models show significantly high compliance rates in certain previously understudied categories with models like GPT-4 incorrectly complying with as many as 30% of requests. To address these gaps, we explore different training strategies using a synthetically-generated training set of requests and expected noncompliant responses. Our experiments demonstrate that while direct finetuning of instruction-tuned models can lead to both over-refusal and a decline in general capabilities, using parameter efficient methods like low rank adapters helps to strike a good balance between appropriate noncompliance and other capabilities.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.12043', 143)">Copy Link</button>
<div id="copy-message-143" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2407.16485">Learning General Continuous Constraint from Demonstrations via Positive-Unlabeled Learning</a></h1>
<p><b>Authors:</b> Baiyu Peng, Aude Billard</p>
<p>Abstract: Planning for a wide range of real-world tasks necessitates to know and write all constraints. However, instances exist where these constraints are either unknown or challenging to specify accurately. A possible solution is to infer the unknown constraints from expert demonstration. The majority of prior works limit themselves to learning simple linear constraints, or require strong knowledge of the true constraint parameterization or environmental model. To mitigate these problems, this paper presents a positive-unlabeled (PU) learning approach to infer a continuous, arbitrary and possibly nonlinear, constraint from demonstration. From a PU learning view, We treat all data in demonstrations as positive (feasible) data, and learn a (sub)-optimal policy to generate high-reward-winning but potentially infeasible trajectories, which serve as unlabeled data containing both feasible and infeasible states. Under an assumption on data distribution, a feasible-infeasible classifier (i.e., constraint model) is learned from the two datasets through a postprocessing PU learning technique. The entire method employs an iterative framework alternating between updating the policy, which generates and selects higher-reward policies, and updating the constraint model. Additionally, a memory buffer is introduced to record and reuse samples from previous iterations to prevent forgetting. The effectiveness of the proposed method is validated in two Mujoco environments, successfully inferring continuous nonlinear constraints and outperforming a baseline method in terms of constraint accuracy and policy safety.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.16485', 144)">Copy Link</button>
<div id="copy-message-144" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2407.21753">Characterizing User Archetypes and Discussions on Scored.co</a></h1>
<p><b>Authors:</b> Andrea Failla, Salvatore Citraro, Giulio Rossetti, Francesco Cauteruccio</p>
<p>Abstract: In recent years, the proliferation of social platforms has drastically transformed the way individuals interact, organize, and share information. In this scenario, we experience an unprecedented increase in the scale and complexity of interactions and, at the same time, little to no research about some fringe social platforms. In this paper, we present a multi-dimensional framework for characterizing nodes and hyperedges in social hypernetworks, with a focus on the understudied alt-right platform Scored.co. Our approach integrates the possibility of studying higher-order interactions, thanks to the hypernetwork representation, and various node features such as user activity, sentiment, and toxicity, with the aim to define distinct user archetypes and understand their roles within the network. Utilizing a comprehensive dataset from Scored.co, we analyze the dynamics of these archetypes over time and explore their interactions and influence within the community. The framework's versatility allows for detailed analysis of both individual user behaviors and broader social structures. Our findings highlight the importance of higher-order interactions in understanding social dynamics, offering new insights into the roles and behaviors that emerge in complex online environments.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2407.21753', 145)">Copy Link</button>
<div id="copy-message-145" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2408.10517">Integrating Multi-Modal Input Token Mixer Into Mamba-Based Decision Models: Decision MetaMamba</a></h1>
<p><b>Authors:</b> Wall Kim</p>
<p>Abstract: Sequence modeling with State Space models (SSMs) has demonstrated performance surpassing that of Transformers in various tasks, raising expectations for their potential to outperform the Decision Transformer and its enhanced variants in offline reinforcement learning (RL). However, decision models based on Mamba, a state-of-the-art SSM, failed to achieve superior performance compared to these enhanced Decision Transformers. We hypothesize that this limitation arises from information loss during the selective scanning phase. To address this, we propose the Decision MetaMamba (DMM), which augments Mamba with a token mixer in its input layer. This mixer explicitly accounts for the multimodal nature of offline RL inputs, comprising state, action, and return-to-go. The DMM demonstrates improved performance while significantly reducing parameter count compared to prior models. Notably, similar performance gains were achieved using a simple linear token mixer, emphasizing the importance of preserving information from proximate time steps rather than the specific design of the token mixer itself. This novel modification to Mamba's input layer represents a departure from conventional timestamp-based encoding approaches used in Transformers. By enhancing performance of Mamba in offline RL, characterized by memory efficiency and fast inference, this work opens new avenues for its broader application in future RL research.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2408.10517', 146)">Copy Link</button>
<div id="copy-message-146" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2409.07779">AFFSegNet: Adaptive Feature Fusion Segmentation Network for Microtumors and Multi-Organ Segmentation</a></h1>
<p><b>Authors:</b> Fuchen Zheng, Xinyi Chen, Xuhang Chen, Haolun Li, Xiaojiao Guo, Guoheng Huang, Chi-Man Pun, Shoujun Zhou</p>
<p>Abstract: Medical image segmentation, a crucial task in computer vision, facilitates the automated delineation of anatomical structures and pathologies, supporting clinicians in diagnosis, treatment planning, and disease monitoring. Notably, transformers employing shifted window-based self-attention have demonstrated exceptional performance. However, their reliance on local window attention limits the fusion of local and global contextual information, crucial for segmenting microtumors and miniature organs. To address this limitation, we propose the Adaptive Semantic Segmentation Network (ASSNet), a transformer architecture that effectively integrates local and global features for precise medical image segmentation. ASSNet comprises a transformer-based U-shaped encoder-decoder network. The encoder utilizes shifted window self-attention across five resolutions to extract multi-scale features, which are then propagated to the decoder through skip connections. We introduce an augmented multi-layer perceptron within the encoder to explicitly model long-range dependencies during feature extraction. Recognizing the constraints of conventional symmetrical encoder-decoder designs, we propose an Adaptive Feature Fusion (AFF) decoder to complement our encoder. This decoder incorporates three key components: the Long Range Dependencies (LRD) block, the Multi-Scale Feature Fusion (MFF) block, and the Adaptive Semantic Center (ASC) block. These components synergistically facilitate the effective fusion of multi-scale features extracted by the decoder while capturing long-range dependencies and refining object boundaries. Comprehensive experiments on diverse medical image segmentation tasks, including multi-organ, liver tumor, and bladder tumor segmentation, demonstrate that ASSNet achieves state-of-the-art results. Code and models are available at: \url{https://github.com/lzeeorno/ASSNet}.</p>
<p>URLs: <a href="https://github.com/lzeeorno/ASSNet">https://github.com/lzeeorno/ASSNet</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2409.07779, https://github.com/lzeeorno/ASSNet', 147)">Copy Link</button>
<div id="copy-message-147" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2409.15371">Bone: Block-Affine Adaptation of Large Language Models</a></h1>
<p><b>Authors:</b> Jiale Kang</p>
<p>Abstract: Low-Rank Adaptation (LoRA) has achieved remarkable training results by freezing the original weights and training only low-rank matrices, establishing itself as the predominant fine-tuning method for LLMs. In pursuit of performance closer to full-parameter training, a series of LoRA variants have emerged, such as LoRA+, PISSA, Olora, and LoRA-GA. This paper introduces a novel PEFT technique distinct from LoRA, called Block-Affine Adaptation (Bone). By dividing the original weights into multiple subspaces that share a single matrix for weight updates, Bone simplifies the process by requiring the trainable matrix to be initialized to zero, eliminating the need for complex initialization as in some LoRA variants. Compared to LoRA, Bone significantly reduces memory usage and achieves faster computation. Evaluation of both NLU and NLG tasks demonstrates that Bone substantially outperforms LoRA and its variants. Inspired by Pissa, we further proposed the ``Weight Guide'' theory to better utilize the information from the original weights. By integrating ``Weight Guide'' with Bone, we developed a new structure called Block-Affine Transformation (Bat), and ablation experiments confirmed the effectiveness of ``Weight Guide''.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2409.15371', 148)">Copy Link</button>
<div id="copy-message-148" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2410.01966">Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker</a></h1>
<p><b>Authors:</b> Xinlong Hou, Sen Shen, Xueshen Li, Xinran Gao, Ziyi Huang, Steven J. Holiday, Matthew R. Cribbet, Susan W. White, Edward Sazonov, Yu Gan</p>
<p>Abstract: Being able to accurately monitor the screen exposure of young children is important for research on phenomena linked to screen use such as childhood obesity, physical activity, and social interaction. Most existing studies rely upon self-report or manual measures from bulky wearable sensors, thus lacking efficiency and accuracy in capturing quantitative screen exposure data. In this work, we developed a novel sensor informatics framework that utilizes egocentric images from a wearable sensor, termed the screen time tracker (STT), and a vision language model (VLM). In particular, we devised a multi-view VLM that takes multiple views from egocentric image sequences and interprets screen exposure dynamically. We validated our approach by using a dataset of children's free-living activities, demonstrating significant improvement over existing methods in plain vision language models and object detection models. Results supported the promise of this monitoring approach, which could optimize behavioral research on screen exposure in children's naturalistic settings.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.01966', 149)">Copy Link</button>
<div id="copy-message-149" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2410.04683">Towards Measuring Goal-Directedness in AI Systems</a></h1>
<p><b>Authors:</b> Dylan Xu, Juan-Pablo Rivera</p>
<p>Abstract: Recent advances in deep learning have brought attention to the possibility of creating advanced, general AI systems that outperform humans across many tasks. However, if these systems pursue unintended goals, there could be catastrophic consequences. A key prerequisite for AI systems pursuing unintended goals is whether they will behave in a coherent and goal-directed manner in the first place, optimizing for some unknown goal; there exists significant research trying to evaluate systems for said behaviors. However, the most rigorous definitions of goal-directedness we currently have are difficult to compute in real-world settings. Drawing upon this previous literature, we explore policy goal-directedness within reinforcement learning (RL) environments. In our findings, we propose a different family of definitions of the goal-directedness of a policy that analyze whether it is well-modeled as near-optimal for many (sparse) reward functions. We operationalize this preliminary definition of goal-directedness and test it in toy Markov decision process (MDP) environments. Furthermore, we explore how goal-directedness could be measured in frontier large-language models (LLMs). Our contribution is a definition of goal-directedness that is simpler and more easily computable in order to approach the question of whether AI systems could pursue dangerous goals. We recommend further exploration of measuring coherence and goal-directedness, based on our findings.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.04683', 150)">Copy Link</button>
<div id="copy-message-150" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2410.20772">Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting</a></h1>
<p><b>Authors:</b> Bong Gyun Kang, Dongjun Lee, HyunGi Kim, DoHyun Chung, Sungroh Yoon</p>
<p>Abstract: Sequence modeling faces challenges in capturing long-range dependencies across diverse tasks. Recent linear and transformer-based forecasters have shown superior performance in time series forecasting. However, they are constrained by their inherent inability to effectively address long-range dependencies in time series data, primarily due to using fixed-size inputs for prediction. Furthermore, they typically sacrifice essential temporal correlation among consecutive training samples by shuffling them into mini-batches. To overcome these limitations, we introduce a fast and effective Spectral Attention mechanism, which preserves temporal correlations among samples and facilitates the handling of long-range information while maintaining the base model structure. Spectral Attention preserves long-period trends through a low-pass filter and facilitates gradient to flow between samples. Spectral Attention can be seamlessly integrated into most sequence models, allowing models with fixed-sized look-back windows to capture long-range dependencies over thousands of steps. Through extensive experiments on 11 real-world time series datasets using 7 recent forecasting models, we consistently demonstrate the efficacy of our Spectral Attention mechanism, achieving state-of-the-art results.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.20772', 151)">Copy Link</button>
<div id="copy-message-151" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2410.22135">Lightweight Frequency Masker for Cross-Domain Few-Shot Semantic Segmentation</a></h1>
<p><b>Authors:</b> Jintao Tong, Yixiong Zou, Yuhua Li, Ruixuan Li</p>
<p>Abstract: Cross-domain few-shot segmentation (CD-FSS) is proposed to first pre-train the model on a large-scale source-domain dataset, and then transfer the model to data-scarce target-domain datasets for pixel-level segmentation. The significant domain gap between the source and target datasets leads to a sharp decline in the performance of existing few-shot segmentation (FSS) methods in cross-domain scenarios. In this work, we discover an intriguing phenomenon: simply filtering different frequency components for target domains can lead to a significant performance improvement, sometimes even as high as 14% mIoU. Then, we delve into this phenomenon for an interpretation, and find such improvements stem from the reduced inter-channel correlation in feature maps, which benefits CD-FSS with enhanced robustness against domain gaps and larger activated regions for segmentation. Based on this, we propose a lightweight frequency masker, which further reduces channel correlations by an Amplitude-Phase Masker (APM) module and an Adaptive Channel Phase Attention (ACPA) module. Notably, APM introduces only 0.01% additional parameters but improves the average performance by over 10%, and ACPA imports only 2.5% parameters but further improves the performance by over 1.5%, which significantly surpasses the state-of-the-art CD-FSS methods.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.22135', 152)">Copy Link</button>
<div id="copy-message-152" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2410.23054">Controlling Language and Diffusion Models by Transporting Activations</a></h1>
<p><b>Authors:</b> Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zappella, Nicholas Apostoloff, Marco Cuturi, Xavier Suau</p>
<p>Abstract: The increasing capabilities of large generative models and their ever more widespread deployment have raised concerns about their reliability, safety, and potential misuse. To address these issues, recent works have proposed to control model generation by steering model activations in order to effectively induce or prevent the emergence of concepts or behaviors in the generated output. In this paper we introduce Activation Transport (AcT), a general framework to steer activations guided by optimal transport theory that generalizes many previous activation-steering works. AcT is modality-agnostic and provides fine-grained control over the model behavior with negligible computational overhead, while minimally impacting model abilities. We experimentally show the effectiveness and versatility of our approach by addressing key challenges in large language models (LLMs) and text-to-image diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is, we show how AcT enables fine-grained style control and concept negation.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2410.23054', 153)">Copy Link</button>
<div id="copy-message-153" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.00554">Differentiable Physics-based System Identification for Robotic Manipulation of Elastoplastic Materials</a></h1>
<p><b>Authors:</b> Xintong Yang, Ze Ji, Yu-Kun Lai</p>
<p>Abstract: Robotic manipulation of volumetric elastoplastic deformable materials, from foods such as dough to construction materials like clay, is in its infancy, largely due to the difficulty of modelling and perception in a high-dimensional space. Simulating the dynamics of such materials is computationally expensive. It tends to suffer from inaccurately estimated physics parameters of the materials and the environment, impeding high-precision manipulation. Estimating such parameters from raw point clouds captured by optical cameras suffers further from heavy occlusions. To address this challenge, this work introduces a novel Differentiable Physics-based System Identification (DPSI) framework that enables a robot arm to infer the physics parameters of elastoplastic materials and the environment using simple manipulation motions and incomplete 3D point clouds, aligning the simulation with the real world. Extensive experiments show that with only a single real-world interaction, the estimated parameters, Young's modulus, Poisson's ratio, yield stress and friction coefficients, can accurately simulate visually and physically realistic deformation behaviours induced by unseen and long-horizon manipulation motions. Additionally, the DPSI framework inherently provides physically intuitive interpretations for the parameters in contrast to black-box approaches such as deep neural networks.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.00554', 154)">Copy Link</button>
<div id="copy-message-154" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.06387">Self-Training Meets Consistency: Improving LLMs&#x27; Reasoning With Consistency-Driven Rationale Evaluation</a></h1>
<p><b>Authors:</b> Jaehyeok Lee, Keisuke Sakaguchi, JinYeong Bak</p>
<p>Abstract: Self-training approach for large language models (LLMs) improves reasoning abilities by training the models on their self-generated rationales. Previous approaches have labeled rationales that produce correct answers for a given question as appropriate for training. However, a single measure risks misjudging rationale quality, leading the models to learn flawed reasoning patterns. To address this issue, we propose CREST (Consistency-driven Rationale Evaluation for Self-Training), a self-training framework that further evaluates each rationale through follow-up questions and leverages this evaluation to guide its training. Specifically, we introduce two methods: (1) filtering out rationales that frequently result in incorrect answers on follow-up questions and (2) preference learning based on mixed preferences from rationale evaluation results of both original and follow-up questions. Experiments on three question-answering datasets using open LLMs show that CREST not only improves the logical robustness and correctness of rationales but also improves reasoning abilities compared to previous self-training approaches.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.06387', 155)">Copy Link</button>
<div id="copy-message-155" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.07482">Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling</a></h1>
<p><b>Authors:</b> Jinming Xing, Ruilin Xing</p>
<p>Abstract: Link prediction is crucial for understanding complex networks but traditional Graph Neural Networks (GNNs) often rely on random negative sampling, leading to suboptimal performance. This paper introduces Fuzzy Graph Attention Networks (FGAT), a novel approach integrating fuzzy rough sets for dynamic negative sampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS) systematically selects high-quality negative edges based on fuzzy similarities, improving training efficiency. FGAT layer incorporates fuzzy rough set principles, enabling robust and discriminative node representations. Experiments on two research collaboration networks demonstrate FGAT's superior link prediction accuracy, outperforming state-of-the-art baselines by leveraging the power of fuzzy rough sets for effective negative sampling and node feature learning.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.07482', 156)">Copy Link</button>
<div id="copy-message-156" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.11458">HistoEncoder: a digital pathology foundation model for prostate cancer</a></h1>
<p><b>Authors:</b> Joona Pohjonen, Abderrahim-Oussama Batouche, Antti Rannikko, Kevin Sandeman, Andrew Erickson, Esa Pitkanen, Tuomas Mirtti</p>
<p>Abstract: Foundation models are trained on massive amounts of data to distinguish complex patterns and can be adapted to a wide range of downstream tasks with minimal computational resources. Here, we develop a foundation model for prostate cancer digital pathology called HistoEncoder by pre-training on 48 million prostate tissue tile images. We demonstrate that HistoEncoder features extracted from tile images with similar histological patterns map closely together in the feature space. HistoEncoder outperforms models pre-trained with natural images, even without fine-tuning or with 1000 times less training data. We describe two use cases that leverage the capabilities of HistoEncoder by fine-tuning the model with a limited amount of data and computational resources. First, we show how HistoEncoder can be used to automatically annotate large-scale datasets with high accuracy. Second, we combine histomics with commonly used clinical nomograms, significantly improving prostate cancer-specific death survival models. Foundation models such as HistoEncoder can allow organizations with limited resources to build effective clinical software tools without needing extensive datasets or significant amounts of computing.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.11458', 157)">Copy Link</button>
<div id="copy-message-157" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.12603">STREAM: A Universal State-Space Model for Sparse Geometric Data</a></h1>
<p><b>Authors:</b> Mark Sch\"one, Yash Bhisikar, Karan Bania, Khaleelulla Khan Nazeer, Christian Mayr, Anand Subramoney, David Kappel</p>
<p>Abstract: Handling sparse and unstructured geometric data, such as point clouds or event-based vision, is a pressing challenge in the field of machine vision. Recently, sequence models such as Transformers and state-space models entered the domain of geometric data. These methods require specialized preprocessing to create a sequential view of a set of points. Furthermore, prior works involving sequence models iterate geometric data with either uniform or learned step sizes, implicitly relying on the model to infer the underlying geometric structure. In this work, we propose to encode geometric structure explicitly into the parameterization of a state-space model. State-space models are based on linear dynamics governed by a one-dimensional variable such as time or a spatial coordinate. We exploit this dynamic variable to inject relative differences of coordinates into the step size of the state-space model. The resulting geometric operation computes interactions between all pairs of N points in O(N) steps. Our model deploys the Mamba selective state-space model with a modified CUDA kernel to efficiently map sparse geometric data to modern hardware. The resulting sequence model, which we call STREAM, achieves competitive results on a range of benchmarks from point-cloud classification to event-based vision and audio classification. STREAM demonstrates a powerful inductive bias for sparse geometric data by improving the PointMamba baseline when trained from scratch on the ModelNet40 and ScanObjectNN point cloud analysis datasets. It further achieves, for the first time, 100% test accuracy on all 11 classes of the DVS128 Gestures dataset.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.12603', 158)">Copy Link</button>
<div id="copy-message-158" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.12872">From Text to Pose to Image: Improving Diffusion Model Control and Quality</a></h1>
<p><b>Authors:</b> Cl\'ement Bonnet, Ariel N. Lee, Franck Wertel, Antoine Tamano, Tanguy Cizain, Pablo Ducru</p>
<p>Abstract: In the last two years, text-to-image diffusion models have become extremely popular. As their quality and usage increase, a major concern has been the need for better output control. In addition to prompt engineering, one effective method to improve the controllability of diffusion models has been to condition them on additional modalities such as image style, depth map, or keypoints. This forms the basis of ControlNets or Adapters. When attempting to apply these methods to control human poses in outputs of text-to-image diffusion models, two main challenges have arisen. The first challenge is generating poses following a wide range of semantic text descriptions, for which previous methods involved searching for a pose within a dataset of (caption, pose) pairs. The second challenge is conditioning image generation on a specified pose while keeping both high aesthetic and high pose fidelity. In this article, we fix these two main issues by introducing a text-to-pose (T2P) generative model alongside a new sampling algorithm, and a new pose adapter that incorporates more pose keypoints for higher pose fidelity. Together, these two new state-of-the-art models enable, for the first time, a generative text-to-pose-to-image framework for higher pose control in diffusion models. We release all models and the code used for the experiments at https://github.com/clement-bonnet/text-to-pose.</p>
<p>URLs: <a href="https://github.com/clement-bonnet/text-to-pose.">https://github.com/clement-bonnet/text-to-pose.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.12872, https://github.com/clement-bonnet/text-to-pose.', 159)">Copy Link</button>
<div id="copy-message-159" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.13147">GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation</a></h1>
<p><b>Authors:</b> Mengzhu Wang, Jiao Li, Houcheng Su, Nan Yin, Liang Yang, Shen Li</p>
<p>Abstract: Semi-supervised learning (SSL) has made notable advancements in medical image segmentation (MIS), particularly in scenarios with limited labeled data and significantly enhancing data utilization efficiency. Previous methods primarily focus on complex training strategies to utilize unlabeled data but neglect the importance of graph structural information. Different from existing methods, we propose a graph-based clustering for semi-supervised medical image segmentation (GraphCL) by jointly modeling graph data structure in a unified deep model. The proposed GraphCL model enjoys several advantages. Firstly, to the best of our knowledge, this is the first work to model the data structure information for semi-supervised medical image segmentation (SSMIS). Secondly, to get the clustered features across different graphs, we integrate both pairwise affinities between local image features and raw features as inputs. Extensive experimental results on three standard benchmarks show that the proposed GraphCL algorithm outperforms state-of-the-art semi-supervised medical image segmentation methods.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.13147', 160)">Copy Link</button>
<div id="copy-message-160" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.13152">AGLP: A Graph Learning Perspective for Semi-supervised Domain Adaptation</a></h1>
<p><b>Authors:</b> Houcheng Su, Mengzhu Wang, Jiao Li, Nan Yin, Liang Yang, Li Shen</p>
<p>Abstract: In semi-supervised domain adaptation (SSDA), the model aims to leverage partially labeled target domain data along with a large amount of labeled source domain data to enhance its generalization capability for the target domain. A key advantage of SSDA is its ability to significantly reduce reliance on labeled data, thereby lowering the costs and time associated with data preparation. Most existing SSDA methods utilize information from domain labels and class labels but overlook the structural information of the data. To address this issue, this paper proposes a graph learning perspective (AGLP) for semi-supervised domain adaptation. We apply the graph convolutional network to the instance graph which allows structural information to propagate along the weighted graph edges. The proposed AGLP model has several advantages. First, to the best of our knowledge, this is the first work to model structural information in SSDA. Second, the proposed model can effectively learn domain-invariant and semantic representations, reducing domain discrepancies in SSDA. Extensive experimental results on multiple standard benchmarks demonstrate that the proposed AGLP algorithm outperforms state-of-the-art semi-supervised domain adaptation methods.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.13152', 161)">Copy Link</button>
<div id="copy-message-161" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.13187">Engagement-Driven Content Generation with Large Language Models</a></h1>
<p><b>Authors:</b> Erica Coppolillo, Federico Cinus, Marco Minici, Francesco Bonchi, Giuseppe Manco</p>
<p>Abstract: Large Language Models (LLMs) exhibit significant persuasion capabilities in one-on-one interactions, but their influence within social networks remains underexplored. This study investigates the potential social impact of LLMs in these environments, where interconnected users and complex opinion dynamics pose unique challenges. In particular, we address the following research question: can LLMs learn to generate meaningful content that maximizes user engagement on social networks?
  To answer this question, we define a pipeline to guide the LLM-based content generation which employs reinforcement learning with simulated feedback. In our framework, the reward is based on an engagement model borrowed from the literature on opinion dynamics and information propagation. Moreover, we force the text generated by the LLM to be aligned with a given topic and to satisfy a minimum fluency requirement.
  Using our framework, we analyze the capabilities and limitations of LLMs in tackling the given task, specifically considering the relative positions of the LLM as an agent within the social network and the distribution of opinions in the network on the given topic. Our findings show the full potential of LLMs in creating social engagement. Notable properties of our approach are that the learning procedure is adaptive to the opinion distribution of the underlying network and agnostic to the specifics of the engagement model, which is embedded as a plug-and-play component. In this regard, our approach can be easily refined for more complex engagement tasks and interventions in computational social science.
  The code used for the experiments is publicly available at https://anonymous.4open.science/r/EDCG/.</p>
<p>URLs: <a href="https://anonymous.4open.science/r/EDCG/.">https://anonymous.4open.science/r/EDCG/.</a></p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.13187, https://anonymous.4open.science/r/EDCG/.', 162)">Copy Link</button>
<div id="copy-message-162" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.13485">Utilizing Large Language Models to Synthesize Product Desirability Datasets</a></h1>
<p><b>Authors:</b> John D. Hastings, Sherri Weitl-Harms, Joseph Doty, Zachary J. Myers, Warren Thompson</p>
<p>Abstract: This research explores the application of large language models (LLMs) to generate synthetic datasets for Product Desirability Toolkit (PDT) testing, a key component in evaluating user sentiment and product experience. Utilizing gpt-4o-mini, a cost-effective alternative to larger commercial LLMs, three methods, Word+Review, Review+Word, and Supply-Word, were each used to synthesize 1000 product reviews. The generated datasets were assessed for sentiment alignment, textual diversity, and data generation cost. Results demonstrated high sentiment alignment across all methods, with Pearson correlations ranging from 0.93 to 0.97. Supply-Word exhibited the highest diversity and coverage of PDT terms, although with increased generation costs. Despite minor biases toward positive sentiments, in situations with limited test data, LLM-generated synthetic data offers significant advantages, including scalability, cost savings, and flexibility in dataset production.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.13485', 163)">Copy Link</button>
<div id="copy-message-163" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.13528">Entropy Bootstrapping for Weakly Supervised Nuclei Detection</a></h1>
<p><b>Authors:</b> James Willoughby, Irina Voiculescu</p>
<p>Abstract: Microscopy structure segmentation, such as detecting cells or nuclei, generally requires a human to draw a ground truth contour around each instance. Weakly supervised approaches (e.g. consisting of only single point labels) have the potential to reduce this workload significantly. Our approach uses individual point labels for an entropy estimation to approximate an underlying distribution of cell pixels. We infer full cell masks from this distribution, and use Mask-RCNN to produce an instance segmentation output. We compare this point--annotated approach with training on the full ground truth masks. We show that our method achieves a comparatively good level of performance, despite a 95% reduction in pixel labels.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.13528', 164)">Copy Link</button>
<div id="copy-message-164" class="copy-message"></div>
</div>
<div class="article">
<h1> replace-cross <a href="https://arxiv.org/abs/2411.13587">Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics</a></h1>
<p><b>Authors:</b> Taowen Wang, Dongfang Liu, James Chenhao Liang, Wenhao Yang, Qifan Wang, Cheng Han, Jiebo Luo, Ruixiang Tang</p>
<p>Abstract: Recently in robotics, Vision-Language-Action (VLA) models have emerged as a transformative approach, enabling robots to execute complex tasks by integrating visual and linguistic inputs within an end-to-end learning framework. While VLA models offer significant capabilities, they also introduce new attack surfaces, making them vulnerable to adversarial attacks. With these vulnerabilities largely unexplored, this paper systematically quantifies the robustness of VLA-based robotic systems. Recognizing the unique demands of robotic execution, our attack objectives target the inherent spatial and functional characteristics of robotic systems. In particular, we introduce an untargeted position-aware attack objective that leverages spatial foundations to destabilize robotic actions, and a targeted attack objective that manipulates the robotic trajectory. Additionally, we design an adversarial patch generation approach that places a small, colorful patch within the camera's view, effectively executing the attack in both digital and physical environments. Our evaluation reveals a marked degradation in task success rates, with up to a 100\% reduction across a suite of simulated robotic tasks, highlighting critical security gaps in current VLA architectures. By unveiling these vulnerabilities and proposing actionable evaluation metrics, this work advances both the understanding and enhancement of safety for VLA-based robotic systems, underscoring the necessity for developing robust defense strategies prior to physical-world deployments.</p>
<button class="copy-button" onclick="copyToClipboard('https://arxiv.org/abs/2411.13587', 165)">Copy Link</button>
<div id="copy-message-165" class="copy-message"></div>
</div>

    </div>
    </body>
    