<!DOCTYPE html>
<html>
<head>
<title>2023-12-09-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2312.03715">Sentiment Analysis of Twitter Posts on Global Conflicts. (arXiv:2312.03715v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sasikumar_U/0/1/0/all/0/1">Ujwal Sasikumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaman_A/0/1/0/all/0/1">Ank Zaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mawlood_Yunis_A/0/1/0/all/0/1">Abdul-Rahman Mawlood-Yunis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_P/0/1/0/all/0/1">Prosenjit Chatterjee</a></p>
<p>Sentiment analysis of social media data is an emerging field with vast
applications in various domains. In this study, we developed a sentiment
analysis model to analyze social media sentiment, especially tweets, during
global conflicting scenarios. To establish our research experiment, we
identified a recent global dispute incident on Twitter and collected around
31,000 filtered Tweets for several months to analyze human sentiment worldwide.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03722">Leveraging AI-derived Data for Carbon Accounting: Information Extraction from Alternative Sources. (arXiv:2312.03722v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oladeji_O/0/1/0/all/0/1">Olamide Oladeji</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1">Seyed Shahabeddin Mousavi</a></p>
<p>Carbon accounting is a fundamental building block in our global path to
emissions reduction and decarbonization, yet many challenges exist in achieving
reliable and trusted carbon accounting measures. We motivate that carbon
accounting not only needs to be more data-driven, but also more
methodologically sound. We discuss the need for alternative, more diverse data
sources that can play a significant role on our path to trusted carbon
accounting procedures and elaborate on not only why, but how Artificial
Intelligence (AI) in general and Natural Language Processing (NLP) in
particular can unlock reasonable access to a treasure trove of alternative data
sets in light of the recent advances in the field that better enable the
utilization of unstructured data in this process. We present a case study of
the recent developments on real-world data via an NLP-powered analysis using
OpenAI's GPT API on financial and shipping data. We conclude the paper with a
discussion on how these methods and approaches can be integrated into a broader
framework for AI-enabled integrative carbon accounting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03723">ChatGPT Application In Summarizing An Evolution Of Deep Learning Techniques In Imaging: A Qualitative Study. (arXiv:2312.03723v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarraf_A/0/1/0/all/0/1">Arman Sarraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbaspour_A/0/1/0/all/0/1">Amirabbas Abbaspour</a></p>
<p>The pursuit of article or text summarization has captured the attention of
natural language processing (NLP) practitioners, presenting itself as a
formidable challenge. ChatGPT 3.5 exhibits the capacity to condense the content
of up to 3000 tokens into a single page, aiming to retain pivotal information
from a given text across diverse themes. In a conducted qualitative research
endeavor, we selected seven scientific articles and employed the publicly
available ChatGPT service to generate summaries of these articles.
Subsequently, we engaged six co-authors of the articles in a survey, presenting
five questions to evaluate the quality of the summaries compared to the
original content. The findings revealed that the summaries produced by ChatGPT
effectively encapsulated the crucial information present in the articles,
preserving the principal message of each manuscript. Nonetheless, there was a
slight diminishment in the technical depth of the summaries as opposed to the
original articles. As a result, our conclusion underscores ChatGPT's text
summarization capability as a potent tool for extracting essential insights in
a manner more aligned with reporting than purely scientific discourse.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03725">SCStory: Self-supervised and Continual Online Story Discovery. (arXiv:2312.03725v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Susik Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dongha Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a></p>
<p>We present a framework SCStory for online story discovery, that helps people
digest rapidly published news article streams in real-time without human
annotations. To organize news article streams into stories, existing approaches
directly encode the articles and cluster them based on representation
similarity. However, these methods yield noisy and inaccurate story discovery
results because the generic article embeddings do not effectively reflect the
story-indicative semantics in an article and cannot adapt to the rapidly
evolving news article streams. SCStory employs self-supervised and continual
learning with a novel idea of story-indicative adaptive modeling of news
article streams. With a lightweight hierarchical embedding module that first
learns sentence representations and then article representations, SCStory
identifies story-relevant information of news articles and uses them to
discover stories. The embedding module is continuously updated to adapt to
evolving news streams with a contrastive learning objective, backed up by two
unique techniques, confidence-aware memory replay and prioritized-augmentation,
employed for label absence and data scarcity problems. Thorough experiments on
real and the latest news data sets demonstrate that SCStory outperforms
existing state-of-the-art algorithms for unsupervised online story discovery.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03731">MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs. (arXiv:2312.03731v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xingtong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinming Zhang</a></p>
<p>Graphs can inherently model interconnected objects on the Web, thereby
facilitating a series of Web applications, such as web analyzing and content
recommendation. Recently, Graph Neural Networks (GNNs) have emerged as a
mainstream technique for graph representation learning. However, their efficacy
within an end-to-end supervised framework is significantly tied to the
availabilityof task-specific labels. To mitigate labeling costs and enhance
robustness in few-shot settings, pre-training on self-supervised tasks has
emerged as a promising method, while prompting has been proposed to further
narrow the objective gap between pretext and downstream tasks. Although there
has been some initial exploration of prompt-based learning on graphs, they
primarily leverage a single pretext task, resulting in a limited subset of
general knowledge that could be learned from the pre-training data. Hence, in
this paper, we propose MultiGPrompt, a novel multi-task pre-training and
prompting framework to exploit multiple pretext tasks for more comprehensive
pre-trained knowledge. First, in pre-training, we design a set of pretext
tokens to synergize multiple pretext tasks. Second, we propose a dual-prompt
mechanism consisting of composed and open prompts to leverage task-specific and
global pre-training knowledge, to guide downstream tasks in few-shot settings.
Finally, we conduct extensive experiments on six public datasets to evaluate
and analyze MultiGPrompt.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03732">A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA. (arXiv:2312.03732v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kalajdzievski_D/0/1/0/all/0/1">Damjan Kalajdzievski</a></p>
<p>As large language models (LLMs) have become increasingly compute and memory
intensive, parameter-efficient fine-tuning (PEFT) methods are now a common
strategy to fine-tune LLMs. A popular PEFT method is Low-Rank Adapters (LoRA),
which adds trainable low-rank "adapters" to selected layers. Each adapter
consists of a low-rank matrix product, multiplicatively scaled by a
rank-dependent factor. This scaling factor, which divides adapters by a factor
of the rank, results in slowed learning and stunted performance for LoRA with
higher-rank adapters. Consequently, the use of LoRA in practice has generally
been limited to very low ranks. In this work, we study the impact of the
scaling factor on the learning process and prove that LoRA adapters should be
divided by a factor of the square root of the rank. Modifying LoRA with the
appropriate scaling factor, which we call the rank-stabilized LoRA (rsLoRA)
method, easily provides for a fine-tuning compute/performance trade-off, where
larger ranks can be used to trade off increased computational resources during
training for better fine-tuning performance, with no change in inference
computing cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03736">De-identification of clinical free text using natural language processing: A systematic review of current approaches. (arXiv:2312.03736v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kovacevic_A/0/1/0/all/0/1">Aleksandar Kova&#x10d;evi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Basaragin_B/0/1/0/all/0/1">Bojana Ba&#x161;aragin</a>, <a href="http://arxiv.org/find/cs/1/au:+Milosevic_N/0/1/0/all/0/1">Nikola Milo&#x161;evi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1">Goran Nenadi&#x107;</a></p>
<p>Background: Electronic health records (EHRs) are a valuable resource for
data-driven medical research. However, the presence of protected health
information (PHI) makes EHRs unsuitable to be shared for research purposes.
De-identification, i.e. the process of removing PHI is a critical step in
making EHR data accessible. Natural language processing has repeatedly
demonstrated its feasibility in automating the de-identification process.
Objectives: Our study aims to provide systematic evidence on how the
de-identification of clinical free text has evolved in the last thirteen years,
and to report on the performances and limitations of the current
state-of-the-art systems. In addition, we aim to identify challenges and
potential research opportunities in this field. Methods: A systematic search in
PubMed, Web of Science and the DBLP was conducted for studies published between
January 2010 and February 2023. Titles and abstracts were examined to identify
the relevant studies. Selected studies were then analysed in-depth, and
information was collected on de-identification methodologies, data sources, and
measured performance. Results: A total of 2125 publications were identified for
the title and abstract screening. 69 studies were found to be relevant. Machine
learning (37 studies) and hybrid (26 studies) approaches are predominant, while
six studies relied only on rules. Majority of the approaches were trained and
evaluated on public corpora. The 2014 i2b2/UTHealth corpus is the most
frequently used (36 studies), followed by the 2006 i2b2 (18 studies) and 2016
CEGS N-GRID (10 studies) corpora.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03742">Clinical Risk Prediction Using Language Models: Benefits And Considerations. (arXiv:2312.03742v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1">Angeela Acharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrestha_S/0/1/0/all/0/1">Sulabh Shrestha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Conte_J/0/1/0/all/0/1">Joseph Conte</a>, <a href="http://arxiv.org/find/cs/1/au:+Avramovic_S/0/1/0/all/0/1">Sanja Avramovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Sikdar_S/0/1/0/all/0/1">Siddhartha Sikdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1">Antonios Anastasopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Sanmay Das</a></p>
<p>The utilization of Electronic Health Records (EHRs) for clinical risk
prediction is on the rise. However, strict privacy regulations limit access to
comprehensive health records, making it challenging to apply standard machine
learning algorithms in practical real-world scenarios. Previous research has
addressed this data limitation by incorporating medical ontologies and
employing transfer learning methods. In this study, we investigate the
potential of leveraging language models (LMs) as a means to incorporate
supplementary domain knowledge for improving the performance of various
EHR-based risk prediction tasks. Unlike applying LMs to unstructured EHR data
such as clinical notes, this study focuses on using textual descriptions within
structured EHR to make predictions exclusively based on that information. We
extensively compare against previous approaches across various data types and
sizes. We find that employing LMs to represent structured EHRs, such as
diagnostic histories, leads to improved or at least comparable performance in
diverse risk prediction tasks. Furthermore, LM-based approaches offer numerous
advantages, including few-shot learning, the capability to handle previously
unseen medical concepts, and adaptability to various medical vocabularies.
Nevertheless, we underscore, through various experiments, the importance of
being cautious when employing such models, as concerns regarding the
reliability of LMs persist.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03743">Easy Data Augmentation in Sentiment Analysis of Cyberbullying. (arXiv:2312.03743v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wirawan_A/0/1/0/all/0/1">Alwan Wirawan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cahyono_H/0/1/0/all/0/1">Hasan Dwi Cahyono</a>, <a href="http://arxiv.org/find/cs/1/au:+Winarno/0/1/0/all/0/1">Winarno</a></p>
<p>Instagram, a social media platform, has in the vicinity of 2 billion active
users in 2023. The platform allows users to post photos and videos with one
another. However, cyberbullying remains a significant problem for about 50% of
young Indonesians. To address this issue, sentiment analysis for comment
filtering uses a Support Vector Machine (SVM) and Easy Data Augmentation (EDA).
EDA will augment the dataset, enabling robust prediction and analysis of
cyberbullying by introducing more variation. Based on the tests, SVM
combination with EDA results in a 2.52% increase in the k-Fold Cross Validation
score. Our proposed approach shows an improved accuracy of 92.5%, 2.5% higher
than that of the existing state-of-the-art method. To maintain the
reproducibility and replicability of this research, the source code can be
accessed at uns.id/eda_svm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03746">Evaluating Large Language Model Creativity from a Literary Perspective. (arXiv:2312.03746v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1">Murray Shanahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Clarke_C/0/1/0/all/0/1">Catherine Clarke</a></p>
<p>This paper assesses the potential for large language models (LLMs) to serve
as assistive tools in the creative writing process, by means of a single,
in-depth case study. In the course of the study, we develop interactive and
multi-voice prompting strategies that interleave background descriptions (scene
setting, plot elements), instructions that guide composition, samples of text
in the target style, and critical discussion of the given samples. We
qualitatively evaluate the results from a literary critical perspective, as
well as from the standpoint of computational creativity (a sub-field of
artificial intelligence). Our findings lend support to the view that the
sophistication of the results that can be achieved with an LLM mirrors the
sophistication of the prompting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03747">Classifying patient voice in social media data using neural networks: A comparison of AI models on different data sources and therapeutic domains. (arXiv:2312.03747v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lysandrou_G/0/1/0/all/0/1">Giorgos Lysandrou</a>, <a href="http://arxiv.org/find/cs/1/au:+Owen_R/0/1/0/all/0/1">Roma English Owen</a>, <a href="http://arxiv.org/find/cs/1/au:+Popovic_V/0/1/0/all/0/1">Vanja Popovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Brun_G/0/1/0/all/0/1">Grant Le Brun</a>, <a href="http://arxiv.org/find/cs/1/au:+Alex_B/0/1/0/all/0/1">Beatrice Alex</a>, <a href="http://arxiv.org/find/cs/1/au:+Fairley_E/0/1/0/all/0/1">Elizabeth A. L. Fairley</a></p>
<p>It is essential that healthcare professionals and members of the healthcare
community can access and easily understand patient experiences in the real
world, so that care standards can be improved and driven towards personalised
drug treatment. Social media platforms and message boards are deemed suitable
sources of patient experience information, as patients have been observed to
discuss and exchange knowledge, look for and provide support online. This paper
tests the hypothesis that not all online patient experience information can be
treated and collected in the same way, as a result of the inherent differences
in the way individuals talk about their journeys, in different therapeutic
domains and or data sources.
</p>
<p>We used linguistic analysis to understand and identify similarities between
datasets, across patient language, between data sources (Reddit, SocialGist)
and therapeutic domains (cardiovascular, oncology, immunology, neurology). We
detected common vocabulary used by patients in the same therapeutic domain
across data sources, except for immunology patients, who use unique vocabulary
between the two data sources, and compared to all other datasets. We combined
linguistically similar datasets to train classifiers (CNN, transformer) to
accurately identify patient experience posts from social media, a task we refer
to as patient voice classification. The cardiovascular and neurology
transformer classifiers perform the best in their respective comparisons for
the Reddit data source, achieving F1-scores of 0.865 and 1.0 respectively. The
overall best performing classifier is the transformer classifier trained on all
data collected for this experiment, achieving F1-scores ranging between 0.863
and 0.995 across all therapeutic domain and data source specific test datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03755">Near-real-time Earthquake-induced Fatality Estimation using Crowdsourced Data and Large-Language Models. (arXiv:2312.03755v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Engler_D/0/1/0/all/0/1">Davis Engler</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuechun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">James Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wald_D/0/1/0/all/0/1">David J. Wald</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaiswal_K/0/1/0/all/0/1">Kishor Jaiswal</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Susu Xu</a></p>
<p>When a damaging earthquake occurs, immediate information about casualties is
critical for time-sensitive decision-making by emergency response and aid
agencies in the first hours and days. Systems such as Prompt Assessment of
Global Earthquakes for Response (PAGER) by the U.S. Geological Survey (USGS)
were developed to provide a forecast within about 30 minutes of any significant
earthquake globally. Traditional systems for estimating human loss in disasters
often depend on manually collected early casualty reports from global media, a
process that's labor-intensive and slow with notable time delays. Recently,
some systems have employed keyword matching and topic modeling to extract
relevant information from social media. However, these methods struggle with
the complex semantics in multilingual texts and the challenge of interpreting
ever-changing, often conflicting reports of death and injury numbers from
various unverified sources on social media platforms. In this work, we
introduce an end-to-end framework to significantly improve the timeliness and
accuracy of global earthquake-induced human loss forecasting using
multi-lingual, crowdsourced social media. Our framework integrates (1) a
hierarchical casualty extraction model built upon large language models, prompt
design, and few-shot learning to retrieve quantitative human loss claims from
social media, (2) a physical constraint-aware, dynamic-truth discovery model
that discovers the truthful human loss from massive noisy and potentially
conflicting human loss claims, and (3) a Bayesian updating loss projection
model that dynamically updates the final loss estimation using discovered
truths. We test the framework in real-time on a series of global earthquake
events in 2021 and 2022 and show that our framework streamlines casualty data
retrieval, achieving speed and accuracy comparable to manual methods by USGS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03756">LineConGraphs: Line Conversation Graphs for Effective Emotion Recognition using Graph Neural Networks. (arXiv:2312.03756v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Krishnan_G/0/1/0/all/0/1">Gokul S Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Padi_S/0/1/0/all/0/1">Sarala Padi</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenberg_C/0/1/0/all/0/1">Craig S. Greenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravindran_B/0/1/0/all/0/1">Balaraman Ravindran</a>, <a href="http://arxiv.org/find/cs/1/au:+Manoch_D/0/1/0/all/0/1">Dinesh Manoch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sriram_R/0/1/0/all/0/1">Ram D.Sriram</a></p>
<p>Emotion Recognition in Conversations (ERC) is a critical aspect of affective
computing, and it has many practical applications in healthcare, education,
chatbots, and social media platforms. Earlier approaches for ERC analysis
involved modeling both speaker and long-term contextual information using graph
neural network architectures. However, it is ideal to deploy
speaker-independent models for real-world applications. Additionally, long
context windows can potentially create confusion in recognizing the emotion of
an utterance in a conversation. To overcome these limitations, we propose novel
line conversation graph convolutional network (LineConGCN) and graph attention
(LineConGAT) models for ERC analysis. These models are speaker-independent and
built using a graph construction strategy for conversations -- line
conversation graphs (LineConGraphs). The conversational context in
LineConGraphs is short-term -- limited to one previous and future utterance,
and speaker information is not part of the graph. We evaluate the performance
of our proposed models on two benchmark datasets, IEMOCAP and MELD, and show
that our LineConGAT model outperforms the state-of-the-art methods with an
F1-score of 64.58% and 76.50%. Moreover, we demonstrate that embedding
sentiment shift information into line conversation graphs further enhances the
ERC performance in the case of GCN models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03761">Learning High-Dimensional Differential Graphs From Multi-Attribute Data. (arXiv:2312.03761v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Tugnait_J/0/1/0/all/0/1">Jitendra K Tugnait</a></p>
<p>We consider the problem of estimating differences in two Gaussian graphical
models (GGMs) which are known to have similar structure. The GGM structure is
encoded in its precision (inverse covariance) matrix. In many applications one
is interested in estimating the difference in two precision matrices to
characterize underlying changes in conditional dependencies of two sets of
data. Existing methods for differential graph estimation are based on
single-attribute (SA) models where one associates a scalar random variable with
each node. In multi-attribute (MA) graphical models, each node represents a
random vector. In this paper, we analyze a group lasso penalized D-trace loss
function approach for differential graph learning from multi-attribute data. An
alternating direction method of multipliers (ADMM) algorithm is presented to
optimize the objective function. Theoretical analysis establishing consistency
in support recovery and estimation in high-dimensional settings is provided.
Numerical results based on synthetic as well as real data are presented.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03762">Colour versus Shape Goal Misgeneralization in Reinforcement Learning: A Case Study. (arXiv:2312.03762v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramanauskas_K/0/1/0/all/0/1">Karolis Ramanauskas</a>, <a href="http://arxiv.org/find/cs/1/au:+Simsek_O/0/1/0/all/0/1">&#xd6;zg&#xfc;r &#x15e;im&#x15f;ek</a></p>
<p>We explore colour versus shape goal misgeneralization originally demonstrated
by Di Langosco et al. (2022) in the Procgen Maze environment, where, given an
ambiguous choice, the agents seem to prefer generalization based on colour
rather than shape. After training over 1,000 agents in a simplified version of
the environment and evaluating them on over 10 million episodes, we conclude
that the behaviour can be attributed to the agents learning to detect the goal
object through a specific colour channel. This choice is arbitrary.
Additionally, we show how, due to underspecification, the preferences can
change when retraining the agents using exactly the same procedure except for
using a different random seed for the training run. Finally, we demonstrate the
existence of outliers in out-of-distribution behaviour based on training random
seed alone.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03763">Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and Editing. (arXiv:2312.03763v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yushi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_F/0/1/0/all/0/1">Feitong Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_D/0/1/0/all/0/1">Di Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiangeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Genova_K/0/1/0/all/0/1">Kyle Genova</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fanello_S/0/1/0/all/0/1">Sean Fanello</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_R/0/1/0/all/0/1">Rohit Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Funkhouser_T/0/1/0/all/0/1">Thomas Funkhouser</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinda Zhang</a></p>
<p>We present a novel framework for generating photorealistic 3D human head and
subsequently manipulating and reposing them with remarkable flexibility. The
proposed approach leverages an implicit function representation of 3D human
heads, employing 3D Gaussians anchored on a parametric face model. To enhance
representational capabilities and encode spatial information, we embed a
lightweight tri-plane payload within each Gaussian rather than directly storing
color and opacity. Additionally, we parameterize the Gaussians in a 2D UV space
via a 3DMM, enabling effective utilization of the diffusion model for 3D head
avatar generation. Our method facilitates the creation of diverse and realistic
3D human heads with fine-grained editing over facial features and expressions.
Extensive experiments demonstrate the effectiveness of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03764">Similarity-based Knowledge Transfer for Cross-Domain Reinforcement Learning. (arXiv:2312.03764v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Serrano_S/0/1/0/all/0/1">Sergio A. Serrano</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_Carranza_J/0/1/0/all/0/1">Jose Martinez-Carranza</a>, <a href="http://arxiv.org/find/cs/1/au:+Sucar_L/0/1/0/all/0/1">L. Enrique Sucar</a></p>
<p>Transferring knowledge in cross-domain reinforcement learning is a
challenging setting in which learning is accelerated by reusing knowledge from
a task with different observation and/or action space. However, it is often
necessary to carefully select the source of knowledge for the receiving end to
benefit from the transfer process. In this article, we study how to measure the
similarity between cross-domain reinforcement learning tasks to select a source
of knowledge that will improve the performance of the learning agent. We
developed a semi-supervised alignment loss to match different spaces with a set
of encoder-decoders, and use them to measure similarity and transfer policies
across tasks. In comparison to prior works, our method does not require data to
be aligned, paired or collected by expert policies. Experimental results, on a
set of varied Mujoco control tasks, show the robustness of our method in
effectively selecting and transferring knowledge, without the supervision of a
tailored set of source tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03780">Predicting the Transportation Activities of Construction Waste Hauling Trucks: An Input-Output Hidden Markov Approach. (arXiv:2312.03780v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongtai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_B/0/1/0/all/0/1">Boyi Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Ke Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Luna Liu</a></p>
<p>Construction waste hauling trucks (CWHTs), as one of the most commonly seen
heavy-duty vehicles in major cities around the globe, are usually subject to a
series of regulations and spatial-temporal access restrictions because they not
only produce significant NOx and PM emissions but also causes on-road fugitive
dust. The timely and accurate prediction of CWHTs' destinations and dwell times
play a key role in effective environmental management. To address this
challenge, we propose a prediction method based on an interpretable
activity-based model, input-output hidden Markov model (IOHMM), and validate it
on 300 CWHTs in Chengdu, China. Contextual factors are considered in the model
to improve its prediction power. Results show that the IOHMM outperforms
several baseline models, including Markov chains, linear regression, and long
short-term memory. Factors influencing the predictability of CWHTs'
transportation activities are also explored using linear regression models.
Results suggest the proposed model holds promise in assisting authorities by
predicting the upcoming transportation activities of CWHTs and administering
intervention in a timely and effective manner.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03788">SmoothQuant+: Accurate and Efficient 4-bit Post-Training WeightQuantization for LLM. (arXiv:2312.03788v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jiayi Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengcan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kaifu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yangguang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhenyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1">Bin Feng</a></p>
<p>Large language models (LLMs) have shown remarkable capabilities in various
tasks. However their huge model size and the consequent demand for
computational and memory resources also pose challenges to model deployment.
Currently, 4-bit post-training quantization (PTQ) has achieved some success in
LLMs, reducing the memory footprint by approximately 75% compared to FP16
models, albeit with some accuracy loss. In this paper, we propose SmoothQuant+,
an accurate and efficient 4-bit weight-only PTQ that requires no additional
training, which enables lossless in accuracy for LLMs for the first time. Based
on the fact that the loss of weight quantization is amplified by the activation
outliers, SmoothQuant+ smoothes the activation outliers by channel before
quantization, while adjusting the corresponding weights for mathematical
equivalence, and then performs group-wise 4-bit weight quantization for linear
layers. We have integrated SmoothQuant+ into the vLLM framework, an advanced
high-throughput inference engine specially developed for LLMs, and equipped it
with an efficient W4A16 CUDA kernels, so that vLLM can seamlessly support
SmoothQuant+ 4-bit weight quantization. Our results show that, with
SmoothQuant+, the Code Llama-34B model can be quantized and deployed on a A100
40GB GPU, achieving lossless accuracy and a throughput increase of 1.9 to 4.0
times compared to the FP16 model deployed on two A100 40GB GPUs. Moreover, the
latency per token is only 68% of the FP16 model deployed on two A100 40GB GPUs.
This is the state-of-the-art 4-bit weight quantization for LLMs as we know.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03792">PCDP-SGD: Improving the Convergence of Differentially Private SGD via Projection in Advance. (arXiv:2312.03792v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sha_H/0/1/0/all/0/1">Haichao Sha</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruixuan Liu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixuan Liu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hong Chen</a> (1) ((1) Renmin University of China)</p>
<p>The paradigm of Differentially Private SGD~(DP-SGD) can provide a theoretical
guarantee for training data in both centralized and federated settings.
However, the utility degradation caused by DP-SGD limits its wide application
in high-stakes tasks, such as medical image diagnosis. In addition to the
necessary perturbation, the convergence issue is attributed to the information
loss on the gradient clipping. In this work, we propose a general framework
PCDP-SGD, which aims to compress redundant gradient norms and preserve more
crucial top gradient components via projection operation before gradient
clipping. Additionally, we extend PCDP-SGD as a fundamental component in
differential privacy federated learning~(DPFL) for mitigating the data
heterogeneous challenge and achieving efficient communication. We prove that
pre-projection enhances the convergence of DP-SGD by reducing the dependence of
clipping error and bias to a fraction of the top gradient eigenspace, and in
theory, limits cross-client variance to improve the convergence under
heterogeneous federation. Experimental results demonstrate that PCDP-SGD
achieves higher accuracy compared with state-of-the-art DP-SGD variants in
computer vision tasks. Moreover, PCDP-SGD outperforms current federated
learning frameworks when DP is guaranteed on local training sets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03796">Multi-Scale and Multi-Modal Contrastive Learning Network for Biomedical Time Series. (arXiv:2312.03796v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hongbo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinzi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoxing Wang</a></p>
<p>Multi-modal biomedical time series (MBTS) data offers a holistic view of the
physiological state, holding significant importance in various bio-medical
applications. Owing to inherent noise and distribution gaps across different
modalities, MBTS can be complex to model. Various deep learning models have
been developed to learn representations of MBTS but still fall short in
robustness due to the ignorance of modal-to-modal variations. This paper
presents a multi-scale and multi-modal biomedical time series representation
learning (MBSL) network with contrastive learning to migrate these variations.
Firstly, MBTS is grouped based on inter-modal distances, then each group with
minimum intra-modal variations can be effectively modeled by individual
encoders. Besides, to enhance the multi-scale feature extraction (encoder),
various patch lengths and mask ratios are designed to generate tokens with
semantic information at different scales and diverse contextual perspectives
respectively. Finally, cross-modal contrastive learning is proposed to maximize
consistency among inter-modal groups, maintaining useful information and
eliminating noises. Experiments against four bio-medical applications show that
MBSL outperforms state-of-the-art models by 33.9% mean average errors (MAE) in
respiration rate, by 13.8% MAE in exercise heart rate, by 1.41% accuracy in
human activity recognition, and by 1.14% F1-score in obstructive sleep
apnea-hypopnea syndrome.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03801">Generalization to New Sequential Decision Making Tasks with In-Context Learning. (arXiv:2312.03801v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Raparthy_S/0/1/0/all/0/1">Sharath Chandra Raparthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hambro_E/0/1/0/all/0/1">Eric Hambro</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirk_R/0/1/0/all/0/1">Robert Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Henaff_M/0/1/0/all/0/1">Mikael Henaff</a>, <a href="http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1">Roberta Raileanu</a></p>
<p>Training autonomous agents that can learn new tasks from only a handful of
demonstrations is a long-standing problem in machine learning. Recently,
transformers have been shown to learn new language or vision tasks without any
weight updates from only a few examples, also referred to as in-context
learning. However, the sequential decision making setting poses additional
challenges having a lower tolerance for errors since the environment's
stochasticity or the agent's actions can lead to unseen, and sometimes
unrecoverable, states. In this paper, we use an illustrative example to show
that naively applying transformers to sequential decision making problems does
not enable in-context learning of new tasks. We then demonstrate how training
on sequences of trajectories with certain distributional properties leads to
in-context learning of new sequential decision making tasks. We investigate
different design choices and find that larger model and dataset sizes, as well
as more task diversity, environment stochasticity, and trajectory burstiness,
all result in better in-context learning of new out-of-distribution tasks. By
training on large diverse offline datasets, our model is able to learn new
MiniHack and Procgen tasks without any weight updates from just a handful of
demonstrations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03806">XCube ($\mathcal{X}^3$): Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies. (arXiv:2312.03806v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xuanchi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiaohui Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Museth_K/0/1/0/all/0/1">Ken Museth</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_F/0/1/0/all/0/1">Francis Williams</a></p>
<p>We present $\mathcal{X}^3$ (pronounced XCube), a novel generative model for
high-resolution sparse 3D voxel grids with arbitrary attributes. Our model can
generate millions of voxels with a finest effective resolution of up to
$1024^3$ in a feed-forward fashion without time-consuming test-time
optimization. To achieve this, we employ a hierarchical voxel latent diffusion
model which generates progressively higher resolution grids in a coarse-to-fine
manner using a custom framework built on the highly efficient VDB data
structure. Apart from generating high-resolution objects, we demonstrate the
effectiveness of XCube on large outdoor scenes at scales of 100m$\times$100m
with a voxel size as small as 10cm. We observe clear qualitative and
quantitative improvements over past approaches. In addition to unconditional
generation, we show that our model can be used to solve a variety of tasks such
as user-guided editing, scene completion from a single scan, and text-to-3D.
More results and details can be found at
https://research.nvidia.com/labs/toronto-ai/xcube/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03807">Achieving ${O}(\epsilon^{-1.5})$ Complexity in Hessian/Jacobian-free Stochastic Bilevel Optimization. (arXiv:2312.03807v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1">Yifan Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Xiao_P/0/1/0/all/0/1">Peiyao Xiao</a>, <a href="http://arxiv.org/find/math/1/au:+Ji_K/0/1/0/all/0/1">Kaiyi Ji</a></p>
<p>In this paper, we revisit the bilevel optimization problem, in which the
upper-level objective function is generally nonconvex and the lower-level
objective function is strongly convex. Although this type of problem has been
studied extensively, it still remains an open question how to achieve an
${O}(\epsilon^{-1.5})$ sample complexity of ${O}(\epsilon^{-1.5})$ in
Hessian/Jacobian-free stochastic bilevel optimization without any second-order
derivative computation. To fill this gap, we propose a novel
Hessian/Jacobian-free bilevel optimizer named FdeHBO, which features a simple
fully single-loop structure, a projection-aided finite-difference
Hessian/Jacobian-vector approximation, and momentum-based updates.
Theoretically, we show that FdeHBO requires ${O}(\epsilon^{-1.5})$ iterations
(each using ${O}(1)$ samples and only first-order gradient information) to find
an $\epsilon$-accurate stationary point. As far as we know, this is the first
Hessian/Jacobian-free method with an ${O}(\epsilon^{-1.5})$ sample complexity
for nonconvex-strongly-convex stochastic bilevel optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03813">Improving Activation Steering in Language Models with Mean-Centring. (arXiv:2312.03813v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jorgensen_O/0/1/0/all/0/1">Ole Jorgensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cope_D/0/1/0/all/0/1">Dylan Cope</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoots_N/0/1/0/all/0/1">Nandi Schoots</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1">Murray Shanahan</a></p>
<p>Recent work in activation steering has demonstrated the potential to better
control the outputs of Large Language Models (LLMs), but it involves finding
steering vectors. This is difficult because engineers do not typically know how
features are represented in these models. We seek to address this issue by
applying the idea of mean-centring to steering vectors. We find that taking the
average of activations associated with a target dataset, and then subtracting
the mean of all training activations, results in effective steering vectors. We
test this method on a variety of models on natural language tasks by steering
away from generating toxic text, and steering the completion of a story towards
a target genre. We also apply mean-centring to extract function vectors, more
effectively triggering the execution of a range of natural language tasks by a
significant margin (compared to previous baselines). This suggests that
mean-centring can be used to easily improve the effectiveness of activation
steering in a wide range of contexts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03814">Pearl: A Production-ready Reinforcement Learning Agent. (arXiv:2312.03814v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheqing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Braz_R/0/1/0/all/0/1">Rodrigo de Salvo Braz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandari_J/0/1/0/all/0/1">Jalaj Bhandari</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daniel Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1">Yi Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1">Yonathan Efroni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hongbo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikulkov_A/0/1/0/all/0/1">Alex Nikulkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Korenkevych_D/0/1/0/all/0/1">Dmytro Korenkevych</a>, <a href="http://arxiv.org/find/cs/1/au:+Dogan_U/0/1/0/all/0/1">Urun Dogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1">Frank Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wanqiao Xu</a></p>
<p>Reinforcement Learning (RL) offers a versatile framework for achieving
long-term goals. Its generality allows us to formalize a wide range of problems
that real-world intelligent systems encounter, such as dealing with delayed
rewards, handling partial observability, addressing the exploration and
exploitation dilemma, utilizing offline data to improve online performance, and
ensuring safety constraints are met. Despite considerable progress made by the
RL research community in addressing these issues, existing open-source RL
libraries tend to focus on a narrow portion of the RL solution pipeline,
leaving other aspects largely unattended. This paper introduces Pearl, a
Production-ready RL agent software package explicitly designed to embrace these
challenges in a modular fashion. In addition to presenting preliminary
benchmark results, this paper highlights Pearl's industry adoptions to
demonstrate its readiness for production usage. Pearl is open sourced on Github
at github.com/facebookresearch/pearl and its official website is located at
pearlagent.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03815">LLM as OS (llmao), Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem. (arXiv:2312.03815v1 [cs.OS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yingqiang Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yujie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wenyue Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Juntao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a></p>
<p>This paper envisions a revolutionary AIOS-Agent ecosystem, where Large
Language Model (LLM) serves as the (Artificial) Intelligent Operating System
(IOS, or AIOS)--an operating system ``with soul''. Upon this foundation, a
diverse range of LLM-based AI Agent Applications (Agents, or AAPs) are
developed, enriching the AIOS-Agent ecosystem and signaling a paradigm shift
from the traditional OS-APP ecosystem. We envision that LLM's impact will not
be limited to the AI application level, instead, it will in turn revolutionize
the design and implementation of computer system, architecture, software, and
programming language, featured by several main concepts: LLM as OS
(system-level), Agents as Applications (application-level), Natural Language as
Programming Interface (user-level), and Tools as Devices/Libraries
(hardware/middleware-level).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03818">Alpha-CLIP: A CLIP Model Focusing on Wherever You Want. (arXiv:2312.03818v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zeyi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Ye Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1">Yuhang Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1">Shu Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaqi Wang</a></p>
<p>Contrastive Language-Image Pre-training (CLIP) plays an essential role in
extracting valuable content information from images across diverse tasks. It
aligns textual and visual modalities to comprehend the entire image, including
all the details, even those irrelevant to specific tasks. However, for a finer
understanding and controlled editing of images, it becomes crucial to focus on
specific regions of interest, which can be indicated as points, masks, or boxes
by humans or perception models. To fulfill the requirements, we introduce
Alpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to
suggest attentive regions and fine-tuned with constructed millions of RGBA
region-text pairs. Alpha-CLIP not only preserves the visual recognition ability
of CLIP but also enables precise control over the emphasis of image contents.
It demonstrates effectiveness in various tasks, including but not limited to
open-world recognition, multimodal large language models, and conditional 2D /
3D generation. It has a strong potential to serve as a versatile tool for
image-related tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03823">High Pileup Particle Tracking with Object Condensation. (arXiv:2312.03823v1 [physics.data-an])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Lieret_K/0/1/0/all/0/1">Kilian Lieret</a>, <a href="http://arxiv.org/find/physics/1/au:+DeZoort_G/0/1/0/all/0/1">Gage DeZoort</a>, <a href="http://arxiv.org/find/physics/1/au:+Chatterjee_D/0/1/0/all/0/1">Devdoot Chatterjee</a>, <a href="http://arxiv.org/find/physics/1/au:+Park_J/0/1/0/all/0/1">Jian Park</a>, <a href="http://arxiv.org/find/physics/1/au:+Miao_S/0/1/0/all/0/1">Siqi Miao</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a></p>
<p>Recent work has demonstrated that graph neural networks (GNNs) can match the
performance of traditional algorithms for charged particle tracking while
improving scalability to meet the computing challenges posed by the HL-LHC.
Most GNN tracking algorithms are based on edge classification and identify
tracks as connected components from an initial graph containing spurious
connections. In this talk, we consider an alternative based on object
condensation (OC), a multi-objective learning framework designed to cluster
points (hits) belonging to an arbitrary number of objects (tracks) and regress
the properties of each object. Building on our previous results, we present a
streamlined model and show progress toward a one-shot OC tracking algorithm in
a high-pileup environment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03824">nbi: the Astronomer&#x27;s Package for Neural Posterior Estimation. (arXiv:2312.03824v1 [astro-ph.IM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Zhang_K/0/1/0/all/0/1">Keming Zhang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bloom_J/0/1/0/all/0/1">Joshua Bloom</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Walt_S/0/1/0/all/0/1">St&#xe9;fan van der Walt</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Hernitschek_N/0/1/0/all/0/1">Nina Hernitschek</a></p>
<p>Despite the promise of Neural Posterior Estimation (NPE) methods in
astronomy, the adaptation of NPE into the routine inference workflow has been
slow. We identify three critical issues: the need for custom featurizer
networks tailored to the observed data, the inference inexactness, and the
under-specification of physical forward models. To address the first two
issues, we introduce a new framework and open-source software nbi (Neural
Bayesian Inference), which supports both amortized and sequential NPE. First,
nbi provides built-in "featurizer" networks with demonstrated efficacy on
sequential data, such as light curve and spectra, thus obviating the need for
this customization on the user end. Second, we introduce a modified algorithm
SNPE-IS, which facilities asymptotically exact inference by using the surrogate
posterior under NPE only as a proposal distribution for importance sampling.
These features allow nbi to be applied off-the-shelf to astronomical inference
problems involving light curves and spectra. We discuss how nbi may serve as an
effective alternative to existing methods such as Nested Sampling. Our package
is at https://github.com/kmzzhang/nbi.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03843">Exposing Disparities in Flood Adaptation for Equitable Future Interventions. (arXiv:2312.03843v1 [econ.GN])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Pecharroman_L/0/1/0/all/0/1">Lidia Cano Pecharroman</a>, <a href="http://arxiv.org/find/econ/1/au:+Hahn_C/0/1/0/all/0/1">ChangHoon Hahn</a></p>
<p>As governments race to implement new climate adaptation policies that prepare
for more frequent flooding, they must seek policies that are effective for all
communities and uphold climate justice. This requires evaluating policies not
only on their overall effectiveness but also on whether their benefits are felt
across all communities. We illustrate the importance of considering such
disparities for flood adaptation using the FEMA National Flood Insurance
Program Community Rating System and its dataset of $\sim$2.5 million flood
insurance claims. We use ${\rm C{\scriptsize AUSAL}F{\scriptsize LOW}}$, a
causal inference method based on deep generative models, to estimate the
treatment effect of flood adaptation interventions based on a community's
income, diversity, population, flood risk, educational attainment, and
precipitation. We find that the program saves communities \$5,000--15,000 per
household. However, these savings are not evenly spread across communities. For
example, for low-income communities savings sharply decline as flood-risk
increases in contrast to their high-income counterparts with all else equal.
Even among low-income communities, there is a gap in savings between
predominantly white and non-white communities: savings of predominantly white
communities can be higher by more than \$6000 per household. As communities
worldwide ramp up efforts to reduce losses inflicted by floods, simply
prescribing a series flood adaptation measures is not enough. Programs must
provide communities with the necessary technical and economic support to
compensate for historical patterns of disenfranchisement, racism, and
inequality. Future flood adaptation efforts should go beyond reducing losses
overall and aim to close existing gaps to equitably support communities in the
race for climate adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03853">Dr. Jekyll and Mr. Hyde: Two Faces of LLMs. (arXiv:2312.03853v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Collu_M/0/1/0/all/0/1">Matteo Gioele Collu</a>, <a href="http://arxiv.org/find/cs/1/au:+Janssen_Groesbeek_T/0/1/0/all/0/1">Tom Janssen-Groesbeek</a>, <a href="http://arxiv.org/find/cs/1/au:+Koffas_S/0/1/0/all/0/1">Stefanos Koffas</a>, <a href="http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1">Mauro Conti</a>, <a href="http://arxiv.org/find/cs/1/au:+Picek_S/0/1/0/all/0/1">Stjepan Picek</a></p>
<p>This year, we witnessed a rise in the use of Large Language Models,
especially when combined with applications like chatbot assistants. Safety
mechanisms and specialized training procedures are put in place to prevent
improper responses from these assistants. In this work, we bypass these
measures for ChatGPT and Bard (and, to some extent, Bing chat) by making them
impersonate complex personas with opposite characteristics as those of the
truthful assistants they are supposed to be. We start by creating elaborate
biographies of these personas, which we then use in a new session with the same
chatbots. Our conversation followed a role-play style to get the response the
assistant was not allowed to provide. By making use of personas, we show that
the response that is prohibited is actually provided, making it possible to
obtain unauthorized, illegal, or harmful information. This work shows that by
using adversarial personas, one can overcome safety mechanisms set out by
ChatGPT and Bard. It also introduces several ways of activating such
adversarial personas, altogether showing that both chatbots are vulnerable to
this kind of attack.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03865">Learning Genomic Sequence Representations using Graph Neural Networks over De Bruijn Graphs. (arXiv:2312.03865v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kapusniak_K/0/1/0/all/0/1">Kacper Kapu&#x15b;niak</a>, <a href="http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1">Manuel Burger</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1">Gunnar R&#xe4;tsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Joudaki_A/0/1/0/all/0/1">Amir Joudaki</a></p>
<p>The rapid expansion of genomic sequence data calls for new methods to achieve
robust sequence representations. Existing techniques often neglect intricate
structural details, emphasizing mainly contextual information. To address this,
we developed k-mer embeddings that merge contextual and structural string
information by enhancing De Bruijn graphs with structural similarity
connections. Subsequently, we crafted a self-supervised method based on
Contrastive Learning that employs a heterogeneous Graph Convolutional Network
encoder and constructs positive pairs based on node similarities. Our
embeddings consistently outperform prior techniques for Edit Distance
Approximation and Closest String Retrieval tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03867">Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing. (arXiv:2312.03867v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Paes_L/0/1/0/all/0/1">Lucas Monteiro Paes</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1">Ananda Theertha Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1">Alex Beutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1">Flavio P. Calmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1">Ahmad Beirami</a></p>
<p>Machine learning (ML) models used in prediction and classification tasks may
display performance disparities across population groups determined by
sensitive attributes (e.g., race, sex, age). We consider the problem of
evaluating the performance of a fixed ML model across population groups defined
by multiple sensitive attributes (e.g., race and sex and age). Here, the sample
complexity for estimating the worst-case performance gap across groups (e.g.,
the largest difference in error rates) increases exponentially with the number
of group-denoting sensitive attributes. To address this issue, we propose an
approach to test for performance disparities based on Conditional Value-at-Risk
(CVaR). By allowing a small probabilistic slack on the groups over which a
model has approximately equal performance, we show that the sample complexity
required for discovering performance violations is reduced exponentially to be
at most upper bounded by the square root of the number of groups. As a
byproduct of our analysis, when the groups are weighted by a specific prior
distribution, we show that R\'enyi entropy of order $2/3$ of the prior
distribution captures the sample complexity of the proposed CVaR test
algorithm. Finally, we also show that there exists a non-i.i.d. data collection
strategy that results in a sample complexity independent of the number of
groups.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03871">Hidden yet quantifiable: A lower bound for confounding strength using randomized trials. (arXiv:2312.03871v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Bartolomeis_P/0/1/0/all/0/1">Piersilvio De Bartolomeis</a>, <a href="http://arxiv.org/find/stat/1/au:+Abad_J/0/1/0/all/0/1">Javier Abad</a>, <a href="http://arxiv.org/find/stat/1/au:+Donhauser_K/0/1/0/all/0/1">Konstantin Donhauser</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_F/0/1/0/all/0/1">Fanny Yang</a></p>
<p>In the era of fast-paced precision medicine, observational studies play a
major role in properly evaluating new treatments in clinical practice. Yet,
unobserved confounding can significantly compromise causal conclusions drawn
from non-randomized data. We propose a novel strategy that leverages randomized
trials to quantify unobserved confounding. First, we design a statistical test
to detect unobserved confounding with strength above a given threshold. Then,
we use the test to estimate an asymptotically valid lower bound on the
unobserved confounding strength. We evaluate the power and validity of our
statistical test on several synthetic and semi-synthetic datasets. Further, we
show how our lower bound can correctly identify the absence and presence of
unobserved confounding in a real-world setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03872">The BigCode Project Governance Card. (arXiv:2312.03872v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+collaboration_BigCode/0/1/0/all/0/1">BigCode collaboration</a>: <a href="http://arxiv.org/find/cs/1/au:+Hughes_S/0/1/0/all/0/1">Sean Hughes</a>, <a href="http://arxiv.org/find/cs/1/au:+Vries_H/0/1/0/all/0/1">Harm de Vries</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1">Jennifer Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrandis_C/0/1/0/all/0/1">Carlos Mu&#xf1;oz Ferrandis</a>, <a href="http://arxiv.org/find/cs/1/au:+Allal_L/0/1/0/all/0/1">Loubna Ben Allal</a>, <a href="http://arxiv.org/find/cs/1/au:+Werra_L/0/1/0/all/0/1">Leandro von Werra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jennifer Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Paquet_S/0/1/0/all/0/1">Sebastien Paquet</a>, <a href="http://arxiv.org/find/cs/1/au:+Jernite_Y/0/1/0/all/0/1">Yacine Jernite</a></p>
<p>This document serves as an overview of the different mechanisms and areas of
governance in the BigCode project. It aims to support transparency by providing
relevant information about choices that were made during the project to the
broader public, and to serve as an example of intentional governance of an open
research project that future endeavors can leverage to shape their own
approach. The first section, Project Structure, covers the project
organization, its stated goals and values, its internal decision processes, and
its funding and resources. The second section, Data and Model Governance,
covers decisions relating to the questions of data subject consent, privacy,
and model release.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03873">Optimizing $CO_{2}$ Capture in Pressure Swing Adsorption Units: A Deep Neural Network Approach with Optimality Evaluation and Operating Maps for Decision-Making. (arXiv:2312.03873v1 [physics.chem-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Rebello_C/0/1/0/all/0/1">Carine Menezes Rebello</a>, <a href="http://arxiv.org/find/physics/1/au:+Nogueira_I/0/1/0/all/0/1">Idelfonso B. R. Nogueira</a></p>
<p>This study presents a methodology for surrogate optimization of cyclic
adsorption processes, focusing on enhancing Pressure Swing Adsorption units for
carbon dioxide ($CO_{2}$) capture. We developed and implemented a
multiple-input, single-output (MISO) framework comprising two deep neural
network (DNN) models, predicting key process performance indicators. These
models were then integrated into an optimization framework, leveraging particle
swarm optimization (PSO) and statistical analysis to generate a comprehensive
Pareto front representation. This approach delineated feasible operational
regions (FORs) and highlighted the spectrum of optimal decision-making
scenarios. A key aspect of our methodology was the evaluation of optimization
effectiveness. This was accomplished by testing decision variables derived from
the Pareto front against a phenomenological model, affirming the surrogate
models reliability. Subsequently, the study delved into analyzing the feasible
operational domains of these decision variables. A detailed correlation map was
constructed to elucidate the interplay between these variables, thereby
uncovering the most impactful factors influencing process behavior. The study
offers a practical, insightful operational map that aids operators in
pinpointing the optimal process location and prioritizing specific operational
goals.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03876">Scaling transformer neural networks for skillful and reliable medium-range weather forecasting. (arXiv:2312.03876v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Nguyen_T/0/1/0/all/0/1">Tung Nguyen</a>, <a href="http://arxiv.org/find/physics/1/au:+Shah_R/0/1/0/all/0/1">Rohan Shah</a>, <a href="http://arxiv.org/find/physics/1/au:+Bansal_H/0/1/0/all/0/1">Hritik Bansal</a>, <a href="http://arxiv.org/find/physics/1/au:+Arcomano_T/0/1/0/all/0/1">Troy Arcomano</a>, <a href="http://arxiv.org/find/physics/1/au:+Madireddy_S/0/1/0/all/0/1">Sandeep Madireddy</a>, <a href="http://arxiv.org/find/physics/1/au:+Maulik_R/0/1/0/all/0/1">Romit Maulik</a>, <a href="http://arxiv.org/find/physics/1/au:+Kotamarthi_V/0/1/0/all/0/1">Veerabhadra Kotamarthi</a>, <a href="http://arxiv.org/find/physics/1/au:+Foster_I/0/1/0/all/0/1">Ian Foster</a>, <a href="http://arxiv.org/find/physics/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a></p>
<p>Weather forecasting is a fundamental problem for anticipating and mitigating
the impacts of climate change. Recently, data-driven approaches for weather
forecasting based on deep learning have shown great promise, achieving
accuracies that are competitive with operational systems. However, those
methods often employ complex, customized architectures without sufficient
ablation analysis, making it difficult to understand what truly contributes to
their success. Here we introduce Stormer, a simple transformer model that
achieves state-of-the-art performance on weather forecasting with minimal
changes to the standard transformer backbone. We identify the key components of
Stormer through careful empirical analyses, including weather-specific
embedding, randomized dynamics forecast, and pressure-weighted loss. At the
core of Stormer is a randomized forecasting objective that trains the model to
forecast the weather dynamics over varying time intervals. During inference,
this allows us to produce multiple forecasts for a target lead time and combine
them to obtain better forecast accuracy. On WeatherBench 2, Stormer performs
competitively at short to medium-range forecasts and outperforms current
methods beyond 7 days, while requiring orders-of-magnitude less training data
and compute. Additionally, we demonstrate Stormer's favorable scaling
properties, showing consistent improvements in forecast accuracy with increases
in model size and training tokens. Code and checkpoints will be made publicly
available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03878">Domain constraints improve risk prediction when outcome data is missing. (arXiv:2312.03878v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Balachandar_S/0/1/0/all/0/1">Sidhika Balachandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_N/0/1/0/all/0/1">Nikhil Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pierson_E/0/1/0/all/0/1">Emma Pierson</a></p>
<p>Machine learning models are often trained to predict the outcome resulting
from a human decision. For example, if a doctor decides to test a patient for
disease, will the patient test positive? A challenge is that the human decision
censors the outcome data: we only observe test outcomes for patients doctors
historically tested. Untested patients, for whom outcomes are unobserved, may
differ from tested patients along observed and unobserved dimensions. We
propose a Bayesian model class which captures this setting. The purpose of the
model is to accurately estimate risk for both tested and untested patients.
Estimating this model is challenging due to the wide range of possibilities for
untested patients. To address this, we propose two domain constraints which are
plausible in health settings: a prevalence constraint, where the overall
disease prevalence is known, and an expertise constraint, where the human
decision-maker deviates from purely risk-based decision-making only along a
constrained feature set. We show theoretically and on synthetic data that
domain constraints improve parameter inference. We apply our model to a case
study of cancer risk prediction, showing that the model's inferred risk
predicts cancer diagnoses, its inferred testing policy captures known public
health policies, and it can identify suboptimalities in test allocation. Though
our case study is in healthcare, our analysis reveals a general class of domain
constraints which can improve model estimation in many settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03881">FoMo Rewards: Can we cast foundation models as reward functions?. (arXiv:2312.03881v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1">Ekdeep Singh Lubana</a>, <a href="http://arxiv.org/find/cs/1/au:+Brehmer_J/0/1/0/all/0/1">Johann Brehmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1">Pim de Haan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1">Taco Cohen</a></p>
<p>We explore the viability of casting foundation models as generic reward
functions for reinforcement learning. To this end, we propose a simple pipeline
that interfaces an off-the-shelf vision model with a large language model.
Specifically, given a trajectory of observations, we infer the likelihood of an
instruction describing the task that the user wants an agent to perform. We
show that this generic likelihood function exhibits the characteristics ideally
expected from a reward function: it associates high values with the desired
behaviour and lower values for several similar, but incorrect policies.
Overall, our work opens the possibility of designing open-ended agents for
interactive tasks via foundation models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03885">Adapting Newton&#x27;s Method to Neural Networks through a Summary of Higher-Order Derivatives. (arXiv:2312.03885v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wolinski_P/0/1/0/all/0/1">Pierre Wolinski</a></p>
<p>We consider a gradient-based optimization method applied to a function
$\mathcal{L}$ of a vector of variables $\boldsymbol{\theta}$, in the case where
$\boldsymbol{\theta}$ is represented as a tuple of tensors $(\mathbf{T}_1,
\cdots, \mathbf{T}_S)$. This framework encompasses many common use-cases, such
as training neural networks by gradient descent. First, we propose a
computationally inexpensive technique providing higher-order information on
$\mathcal{L}$, especially about the interactions between the tensors
$\mathbf{T}_s$, based on automatic differentiation and computational tricks.
Second, we use this technique at order 2 to build a second-order optimization
method which is suitable, among other things, for training deep neural networks
of various architectures. This second-order method leverages the partition
structure of $\boldsymbol{\theta}$ into tensors $(\mathbf{T}_1, \cdots,
\mathbf{T}_S)$, in such a way that it requires neither the computation of the
Hessian of $\mathcal{L}$ according to $\boldsymbol{\theta}$, nor any
approximation of it. The key part consists in computing a smaller matrix
interpretable as a "Hessian according to the partition", which can be computed
exactly and efficiently. In contrast to many existing practical second-order
methods used in neural networks, which perform a diagonal or block-diagonal
approximation of the Hessian or its inverse, the method we propose does not
neglect interactions between layers. Finally, we can tune the coarseness of the
partition to recover well-known optimization methods: the coarsest case
corresponds to Cauchy's steepest descent method, the finest case corresponds to
the usual Newton's method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03886">On The Fairness Impacts of Hardware Selection in Machine Learning. (arXiv:2312.03886v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nelaturu_S/0/1/0/all/0/1">Sree Harsha Nelaturu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_N/0/1/0/all/0/1">Nishaanth Kanna Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Cuong Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>, <a href="http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1">Ferdinando Fioretto</a></p>
<p>In the machine learning ecosystem, hardware selection is often regarded as a
mere utility, overshadowed by the spotlight on algorithms and data. This
oversight is particularly problematic in contexts like ML-as-a-service
platforms, where users often lack control over the hardware used for model
deployment. How does the choice of hardware impact generalization properties?
This paper investigates the influence of hardware on the delicate balance
between model performance and fairness. We demonstrate that hardware choices
can exacerbate existing disparities, attributing these discrepancies to
variations in gradient flows and loss surfaces across different demographic
groups. Through both theoretical and empirical analysis, the paper not only
identifies the underlying factors but also proposes an effective strategy for
mitigating hardware-induced performance imbalances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03889">A Masked Pruning Approach for Dimensionality Reduction in Communication-Efficient Federated Learning Systems. (arXiv:2312.03889v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gez_T/0/1/0/all/0/1">Tamir L.S. Gez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_K/0/1/0/all/0/1">Kobi Cohen</a></p>
<p>Federated Learning (FL) represents a growing machine learning (ML) paradigm
designed for training models across numerous nodes that retain local datasets,
all without directly exchanging the underlying private data with the parameter
server (PS). Its increasing popularity is attributed to notable advantages in
terms of training deep neural network (DNN) models under privacy aspects and
efficient utilization of communication resources. Unfortunately, DNNs suffer
from high computational and communication costs, as well as memory consumption
in intricate tasks. These factors restrict the applicability of FL algorithms
in communication-constrained systems with limited hardware resources.
</p>
<p>In this paper, we develop a novel algorithm that overcomes these limitations
by synergistically combining a pruning-based method with the FL process,
resulting in low-dimensional representations of the model with minimal
communication cost, dubbed Masked Pruning over FL (MPFL). The algorithm
operates by initially distributing weights to the nodes through the PS.
Subsequently, each node locally trains its model and computes pruning masks.
These low-dimensional masks are then transmitted back to the PS, which
generates a consensus pruning mask, broadcasted back to the nodes. This
iterative process enhances the robustness and stability of the masked pruning
model. The generated mask is used to train the FL model, achieving significant
bandwidth savings. We present an extensive experimental study demonstrating the
superior performance of MPFL compared to existing methods. Additionally, we
have developed an open-source software package for the benefit of researchers
and developers in related fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03891">Evaluation of Infrastructure-based Warning System on Driving Behaviors-A Roundabout Study. (arXiv:2312.03891v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1">Chi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Tianfang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yiheng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Proctor_R/0/1/0/all/0/1">Robert W. Proctor</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiansong Zhang</a></p>
<p>Smart intersections have the potential to improve road safety with sensing,
communication, and edge computing technologies. Perception sensors installed at
a smart intersection can monitor the traffic environment in real time and send
infrastructure-based warnings to nearby travelers through V2X communication.
This paper investigated how infrastructure-based warnings can influence driving
behaviors and improve roundabout safety through a driving-simulator study - a
challenging driving scenario for human drivers. A co-simulation platform
integrating Simulation of Urban Mobility (SUMO) and Webots was developed to
serve as the driving simulator. A real-world roundabout in Ann Arbor, Michigan
was built in the co-simulation platform as the study area, and the merging
scenarios were investigated. 36 participants were recruited and asked to
navigate the roundabout under three danger levels (e.g., low, medium, high) and
three collision warning designs (e.g., no warning, warning issued 1 second in
advance, warning issued 2 seconds in advance). Results indicated that advanced
warnings can significantly enhance safety by minimizing potential risks
compared to scenarios without warnings. Earlier warnings enabled smoother
driver responses and reduced abrupt decelerations. In addition, a personalized
intention prediction model was developed to predict drivers' stop-or-go
decisions when the warning is displayed. Among all tested machine learning
models, the XGBoost model achieved the highest prediction accuracy with a
precision rate of 95.56% and a recall rate of 97.73%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03895">HLoOP -- Hyperbolic 2-space Local Outlier Probabilities. (arXiv:2312.03895v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Allietta_C/0/1/0/all/0/1">Cl&#xe9;mence Allietta</a>, <a href="http://arxiv.org/find/stat/1/au:+Condomines_J/0/1/0/all/0/1">Jean-Philippe Condomines</a>, <a href="http://arxiv.org/find/stat/1/au:+Tourneret_J/0/1/0/all/0/1">Jean-Yves Tourneret</a>, <a href="http://arxiv.org/find/stat/1/au:+Lochin_E/0/1/0/all/0/1">Emmanuel Lochin</a></p>
<p>Hyperbolic geometry has recently garnered considerable attention in machine
learning due to its capacity to embed hierarchical graph structures with low
distortions for further downstream processing. This paper introduces a simple
framework to detect local outliers for datasets grounded in hyperbolic 2-space
referred to as HLoOP (Hyperbolic Local Outlier Probability). Within a Euclidean
space, well-known techniques for local outlier detection are based on the Local
Outlier Factor (LOF) and its variant, the LoOP (Local Outlier Probability),
which incorporates probabilistic concepts to model the outlier level of a data
vector. The developed HLoOP combines the idea of finding nearest neighbors,
density-based outlier scoring with a probabilistic, statistically oriented
approach. Therefore, the method consists in computing the Riemmanian distance
of a data point to its nearest neighbors following a Gaussian probability
density function expressed in a hyperbolic space. This is achieved by defining
a Gaussian cumulative distribution in this space. The HLoOP algorithm is tested
on the WordNet dataset yielding promising results. Code and data will be made
available on request for reproductibility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03903">Adaptive Dependency Learning Graph Neural Networks. (arXiv:2312.03903v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sriramulu_A/0/1/0/all/0/1">Abishek Sriramulu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fourrier_N/0/1/0/all/0/1">Nicolas Fourrier</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1">Christoph Bergmeir</a></p>
<p>Graph Neural Networks (GNN) have recently gained popularity in the
forecasting domain due to their ability to model complex spatial and temporal
patterns in tasks such as traffic forecasting and region-based demand
forecasting. Most of these methods require a predefined graph as input, whereas
in real-life multivariate time series problems, a well-predefined dependency
graph rarely exists. This requirement makes it harder for GNNs to be utilised
widely for multivariate forecasting problems in other domains such as retail or
energy. In this paper, we propose a hybrid approach combining neural networks
and statistical structure learning models to self-learn the dependencies and
construct a dynamically changing dependency graph from multivariate data aiming
to enable the use of GNNs for multivariate forecasting even when a well-defined
graph does not exist. The statistical structure modeling in conjunction with
neural networks provides a well-principled and efficient approach by bringing
in causal semantics to determine dependencies among the series. Finally, we
demonstrate significantly improved performance using our proposed approach on
real-world benchmark datasets without a pre-defined dependency graph.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03905">A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints. (arXiv:2312.03905v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahmed_K/0/1/0/all/0/1">Kareem Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1">Guy Van den Broeck</a></p>
<p>Neuro-symbolic AI bridges the gap between purely symbolic and neural
approaches to learning. This often requires maximizing the likelihood of a
symbolic constraint w.r.t the neural network's output distribution. Such output
distributions are typically assumed to be fully-factorized. This limits the
applicability of neuro-symbolic learning to the more expressive autoregressive
distributions, e.g., transformers. Under such distributions, computing the
likelihood of even simple constraints is #P-hard. Instead of attempting to
enforce the constraint on the entire output distribution, we propose to do so
on a random, local approximation thereof. More precisely, we optimize the
likelihood of the constraint under a pseudolikelihood-based approximation
centered around a model sample. Our approximation is factorized, allowing the
reuse of solutions to sub-problems, a main tenet for efficiently computing
neuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of
the likelihood, exhibiting low entropy and KL-divergence around the model
sample. We evaluate our approach on Sudoku and shortest-path prediction cast as
autoregressive generation, and observe that we greatly improve upon the base
model's ability to predict logically-consistent outputs. We also evaluate on
the task of detoxifying large language models. Using a simple constraint
disallowing a list of toxic words, we are able to steer the model's outputs
away from toxic generations, achieving SoTA detoxification compared to previous
approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03911">Improving Gradient-guided Nested Sampling for Posterior Inference. (arXiv:2312.03911v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lemos_P/0/1/0/all/0/1">Pablo Lemos</a>, <a href="http://arxiv.org/find/cs/1/au:+Malkin_N/0/1/0/all/0/1">Nikolay Malkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Handley_W/0/1/0/all/0/1">Will Handley</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Hezaveh_Y/0/1/0/all/0/1">Yashar Hezaveh</a>, <a href="http://arxiv.org/find/cs/1/au:+Perreault_Levasseur_L/0/1/0/all/0/1">Laurence Perreault-Levasseur</a></p>
<p>We present a performant, general-purpose gradient-guided nested sampling
algorithm, ${\tt GGNS}$, combining the state of the art in differentiable
programming, Hamiltonian slice sampling, clustering, mode separation, dynamic
nested sampling, and parallelization. This unique combination allows ${\tt
GGNS}$ to scale well with dimensionality and perform competitively on a variety
of synthetic and real-world problems. We also show the potential of combining
nested sampling with generative flow networks to obtain large amounts of
high-quality samples from the posterior distribution. This combination leads to
faster mode discovery and more accurate estimates of the partition function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03928">Adaptive Weighted Co-Learning for Cross-Domain Few-Shot Learning. (arXiv:2312.03928v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alchihabi_A/0/1/0/all/0/1">Abdullah Alchihabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidari_M/0/1/0/all/0/1">Marzi Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuhong Guo</a></p>
<p>Due to the availability of only a few labeled instances for the novel target
prediction task and the significant domain shift between the well annotated
source domain and the target domain, cross-domain few-shot learning (CDFSL)
induces a very challenging adaptation problem. In this paper, we propose a
simple Adaptive Weighted Co-Learning (AWCoL) method to address the CDFSL
challenge by adapting two independently trained source prototypical
classification models to the target task in a weighted co-learning manner. The
proposed method deploys a weighted moving average prediction strategy to
generate probabilistic predictions from each model, and then conducts adaptive
co-learning by jointly fine-tuning the two models in an alternating manner
based on the pseudo-labels and instance weights produced from the predictions.
Moreover, a negative pseudo-labeling regularizer is further deployed to improve
the fine-tuning process by penalizing false predictions. Comprehensive
experiments are conducted on multiple benchmark datasets and the empirical
results demonstrate that the proposed method produces state-of-the-art CDFSL
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03936">The Potential of Vision-Language Models for Content Moderation of Children&#x27;s Videos. (arXiv:2312.03936v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Syed Hammad Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengnan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukthankar_G/0/1/0/all/0/1">Gita Sukthankar</a></p>
<p>Natural language supervision has been shown to be effective for zero-shot
learning in many computer vision tasks, such as object detection and activity
recognition. However, generating informative prompts can be challenging for
more subtle tasks, such as video content moderation. This can be difficult, as
there are many reasons why a video might be inappropriate, beyond violence and
obscenity. For example, scammers may attempt to create junk content that is
similar to popular educational videos but with no meaningful information. This
paper evaluates the performance of several CLIP variations for content
moderation of children's cartoons in both the supervised and zero-shot setting.
We show that our proposed model (Vanilla CLIP with Projection Layer)
outperforms previous work conducted on the Malicious or Benign (MOB) benchmark
for video content moderation. This paper presents an in depth analysis of how
context-specific language prompts affect content moderation performance. Our
results indicate that it is important to include more context in content
moderation prompts, particularly for cartoon videos as they are not well
represented in the CLIP training data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03940">PECANN: Parallel Efficient Clustering with Graph-Based Approximate Nearest Neighbor Search. (arXiv:2312.03940v1 [cs.DS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shangdi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Engels_J/0/1/0/all/0/1">Joshua Engels</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yihao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shun_J/0/1/0/all/0/1">Julian Shun</a></p>
<p>This paper studies density-based clustering of point sets. These methods use
dense regions of points to detect clusters of arbitrary shapes. In particular,
we study variants of density peaks clustering, a popular type of algorithm that
has been shown to work well in practice. Our goal is to cluster large
high-dimensional datasets, which are prevalent in practice. Prior solutions are
either sequential, and cannot scale to large data, or are specialized for
low-dimensional data.
</p>
<p>This paper unifies the different variants of density peaks clustering into a
single framework, PECANN, by abstracting out several key steps common to this
class of algorithms. One such key step is to find nearest neighbors that
satisfy a predicate function, and one of the main contributions of this paper
is an efficient way to do this predicate search using graph-based approximate
nearest neighbor search (ANNS). To provide ample parallelism, we propose a
doubling search technique that enables points to find an approximate nearest
neighbor satisfying the predicate in a small number of rounds. Our technique
can be applied to many existing graph-based ANNS algorithms, which can all be
plugged into PECANN.
</p>
<p>We implement five clustering algorithms with PECANN and evaluate them on
synthetic and real-world datasets with up to 1.28 million points and up to 1024
dimensions on a 30-core machine with two-way hyper-threading. Compared to the
state-of-the-art FASTDP algorithm for high-dimensional density peaks
clustering, which is sequential, our best algorithm is 45x-734x faster while
achieving competitive ARI scores. Compared to the state-of-the-art parallel
DPC-based algorithm, which is optimized for low dimensions, we show that PECANN
is two orders of magnitude faster. As far as we know, our work is the first to
evaluate DPC variants on large high-dimensional real-world image and text
embedding datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03950">A Scalable and Generalizable Pathloss Map Prediction. (arXiv:2312.03950v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Ju-Hyung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Molisch_A/0/1/0/all/0/1">Andreas F. Molisch</a></p>
<p>Large-scale channel prediction, i.e., estimation of the pathloss from
geographical/morphological/building maps, is an essential component of wireless
network planning. Ray tracing (RT)-based methods have been widely used for many
years, but they require significant computational effort that may become
prohibitive with the increased network densification and/or use of higher
frequencies in B5G/6G systems. In this paper, we propose a data-driven,
model-free pathloss map prediction (PMP) method, called PMNet. PMNet uses a
supervised learning approach: it is trained on a limited amount of RT (or
channel measurement) data and map data. Once trained, PMNet can predict
pathloss over location with high accuracy (an RMSE level of $10^{-2}$) in a few
milliseconds. We further extend PMNet by employing transfer learning (TL). TL
allows PMNet to learn a new network scenario quickly (x5.6 faster training) and
efficiently (using x4.5 less data) by transferring knowledge from a pre-trained
model, while retaining accuracy. Our results demonstrate that PMNet is a
scalable and generalizable ML-based PMP method, showing its potential to be
used in several network optimization applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03951">Understanding the Role of Optimization in Double Descent. (arXiv:2312.03951v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chris Yuhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Flanigan_J/0/1/0/all/0/1">Jeffrey Flanigan</a></p>
<p>The phenomenon of model-wise double descent, where the test error peaks and
then reduces as the model size increases, is an interesting topic that has
attracted the attention of researchers due to the striking observed gap between
theory and practice \citep{Belkin2018ReconcilingMM}. Additionally, while double
descent has been observed in various tasks and architectures, the peak of
double descent can sometimes be noticeably absent or diminished, even without
explicit regularization, such as weight decay and early stopping. In this
paper, we investigate this intriguing phenomenon from the optimization
perspective and propose a simple optimization-based explanation for why double
descent sometimes occurs weakly or not at all. To the best of our knowledge, we
are the first to demonstrate that many disparate factors contributing to
model-wise double descent (initialization, normalization, batch size, learning
rate, optimization algorithm) are unified from the viewpoint of optimization:
model-wise double descent is observed if and only if the optimizer can find a
sufficiently low-loss minimum. These factors directly affect the condition
number of the optimization problem or the optimizer and thus affect the final
minimum found by the optimizer, reducing or increasing the height of the double
descent peak. We conduct a series of controlled experiments on random feature
models and two-layer neural networks under various optimization settings,
demonstrating this optimization-based unified view. Our results suggest the
following implication: Double descent is unlikely to be a problem for
real-world machine learning setups. Additionally, our results help explain the
gap between weak double descent peaks in practice and strong peaks observable
in carefully designed setups.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03957">PerSival: Neural-network-based visualisation for pervasive continuum-mechanical simulations in musculoskeletal biomechanics. (arXiv:2312.03957v1 [q-bio.TO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Rosin_D/0/1/0/all/0/1">David Rosin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kassinger_J/0/1/0/all/0/1">Johannes K&#xe4;ssinger</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yu_X/0/1/0/all/0/1">Xingyao Yu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Avci_O/0/1/0/all/0/1">Okan Avci</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bleiler_C/0/1/0/all/0/1">Christian Bleiler</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Rohrle_O/0/1/0/all/0/1">Oliver R&#xf6;hrle</a></p>
<p>This paper presents a novel neural network architecture for the purpose of
pervasive visualisation of a 3D human upper limb musculoskeletal system model.
Bringing simulation capabilities to resource-poor systems like mobile devices
is of growing interest across many research fields, to widen applicability of
methods and results. Until recently, this goal was thought to be out of reach
for realistic continuum-mechanical simulations of musculoskeletal systems, due
to prohibitive computational cost. Within this work we use a sparse grid
surrogate to capture the surface deformation of the m.~biceps brachii in order
to train a deep learning model, used for real-time visualisation of the same
muscle. Both these surrogate models take 5 muscle activation levels as input
and output Cartesian coordinate vectors for each mesh node on the muscle's
surface. Thus, the neural network architecture features a significantly lower
input than output dimension. 5 muscle activation levels were sufficient to
achieve an average error of 0.97 +/- 0.16 mm, or 0.57 +/- 0.10 % for the 2809
mesh node positions of the biceps. The model achieved evaluation times of 9.88
ms per predicted deformation state on CPU only and 3.48 ms with GPU-support,
leading to theoretical frame rates of 101 fps and 287 fps respectively. Deep
learning surrogates thus provide a way to make continuum-mechanical simulations
accessible for visual real-time applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03979">Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks. (arXiv:2312.03979v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yuni Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yulin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1">Bailin Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a></p>
<p>Deep Graph Learning (DGL) has emerged as a crucial technique across various
domains. However, recent studies have exposed vulnerabilities in DGL models,
such as susceptibility to evasion and poisoning attacks. While empirical and
provable robustness techniques have been developed to defend against graph
modification attacks (GMAs), the problem of certified robustness against graph
injection attacks (GIAs) remains largely unexplored. To bridge this gap, we
introduce the node-aware bi-smoothing framework, which is the first certifiably
robust approach for general node classification tasks against GIAs. Notably,
the proposed node-aware bi-smoothing scheme is model-agnostic and is applicable
for both evasion and poisoning attacks. Through rigorous theoretical analysis,
we establish the certifiable conditions of our smoothing scheme. We also
explore the practical implications of our node-aware bi-smoothing schemes in
two contexts: as an empirical defense approach against real-world GIAs and in
the context of recommendation systems. Furthermore, we extend two
state-of-the-art certified robustness frameworks to address node injection
attacks and compare our approach against them. Extensive evaluations
demonstrate the effectiveness of our proposed certificates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03989">Rapid detection of rare events from in situ X-ray diffraction data using machine learning. (arXiv:2312.03989v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weijian Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jun-Sang Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kenesei_P/0/1/0/all/0/1">Peter Kenesei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahsan Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengchun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1">Ian T. Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwarz_N/0/1/0/all/0/1">Nicholas Schwarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kettimuthu_R/0/1/0/all/0/1">Rajkumar Kettimuthu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miceli_A/0/1/0/all/0/1">Antonino Miceli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1">Hemant Sharma</a></p>
<p>High-energy X-ray diffraction methods can non-destructively map the 3D
microstructure and associated attributes of metallic polycrystalline
engineering materials in their bulk form. These methods are often combined with
external stimuli such as thermo-mechanical loading to take snapshots over time
of the evolving microstructure and attributes. However, the extreme data
volumes and the high costs of traditional data acquisition and reduction
approaches pose a barrier to quickly extracting actionable insights and
improving the temporal resolution of these snapshots. Here we present a fully
automated technique capable of rapidly detecting the onset of plasticity in
high-energy X-ray microscopy data. Our technique is computationally faster by
at least 50 times than the traditional approaches and works for data sets that
are up to 9 times sparser than a full data set. This new technique leverages
self-supervised image representation learning and clustering to transform
massive data into compact, semantic-rich representations of visually salient
characteristics (e.g., peak shapes). These characteristics can be a rapid
indicator of anomalous events such as changes in diffraction peak shapes. We
anticipate that this technique will provide just-in-time actionable information
to drive smarter experiments that effectively deploy multi-modal X-ray
diffraction methods that span many decades of length scales.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03991">MICRO: Model-Based Offline Reinforcement Learning with a Conservative Bellman Operator. (arXiv:2312.03991v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao-Yin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiao-Hu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guo-Tao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_M/0/1/0/all/0/1">Mei-Jiang Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tian-Yu Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">De-Xing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zeng-Guang Hou</a></p>
<p>Offline reinforcement learning (RL) faces a significant challenge of
distribution shift. Model-free offline RL penalizes the Q value for
out-of-distribution (OOD) data or constrains the policy closed to the behavior
policy to tackle this problem, but this inhibits the exploration of the OOD
region. Model-based offline RL, which uses the trained environment model to
generate more OOD data and performs conservative policy optimization within
that model, has become an effective method for this problem. However, the
current model-based algorithms rarely consider agent robustness when
incorporating conservatism into policy. Therefore, the new model-based offline
algorithm with a conservative Bellman operator (MICRO) is proposed. This method
trades off performance and robustness via introducing the robust Bellman
operator into the algorithm. Compared with previous model-based algorithms with
robust adversarial models, MICRO can significantly reduce the computation cost
by only choosing the minimal Q value in the state uncertainty set. Extensive
experiments demonstrate that MICRO outperforms prior RL algorithms in offline
RL benchmark and is considerably robust to adversarial perturbations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03998">Series2Vec: Similarity-based Self-supervised Representation Learning for Time Series Classification. (arXiv:2312.03998v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Foumani_N/0/1/0/all/0/1">Navid Mohammadi Foumani</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chang Wei Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1">Geoffrey I. Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+Salehi_M/0/1/0/all/0/1">Mahsa Salehi</a></p>
<p>We argue that time series analysis is fundamentally different in nature to
either vision or natural language processing with respect to the forms of
meaningful self-supervised learning tasks that can be defined. Motivated by
this insight, we introduce a novel approach called \textit{Series2Vec} for
self-supervised representation learning. Unlike other self-supervised methods
in time series, which carry the risk of positive sample variants being less
similar to the anchor sample than series in the negative set, Series2Vec is
trained to predict the similarity between two series in both temporal and
spectral domains through a self-supervised task. Series2Vec relies primarily on
the consistency of the unsupervised similarity step, rather than the intrinsic
quality of the similarity measurement, without the need for hand-crafted data
augmentation. To further enforce the network to learn similar representations
for similar time series, we propose a novel approach that applies
order-invariant attention to each representation within the batch during
training. Our evaluation of Series2Vec on nine large real-world datasets, along
with the UCR/UEA archive, shows enhanced performance compared to current
state-of-the-art self-supervised techniques for time series. Additionally, our
extensive experiments show that Series2Vec performs comparably with fully
supervised training and offers high efficiency in datasets with limited-labeled
data. Finally, we show that the fusion of Series2Vec with other representation
learning models leads to enhanced performance for time series classification.
Code and models are open-source at
\url{https://github.com/Navidfoumani/Series2Vec.}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04000">LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures. (arXiv:2312.04000v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thilak_V/0/1/0/all/0/1">Vimal Thilak</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Saremi_O/0/1/0/all/0/1">Omid Saremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinh_L/0/1/0/all/0/1">Laurent Dinh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_H/0/1/0/all/0/1">Hanlin Goh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1">Preetum Nakkiran</a>, <a href="http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1">Joshua M. Susskind</a>, <a href="http://arxiv.org/find/cs/1/au:+Littwin_E/0/1/0/all/0/1">Etai Littwin</a></p>
<p>Joint embedding (JE) architectures have emerged as a promising avenue for
acquiring transferable data representations. A key obstacle to using JE
methods, however, is the inherent challenge of evaluating learned
representations without access to a downstream task, and an annotated dataset.
Without efficient and reliable evaluation, it is difficult to iterate on
architectural and training choices for JE methods. In this paper, we introduce
LiDAR (Linear Discriminant Analysis Rank), a metric designed to measure the
quality of representations within JE architectures. Our metric addresses
several shortcomings of recent approaches based on feature covariance rank by
discriminating between informative and uninformative features. In essence,
LiDAR quantifies the rank of the Linear Discriminant Analysis (LDA) matrix
associated with the surrogate SSL task -- a measure that intuitively captures
the information content as it pertains to solving the SSL task. We empirically
demonstrate that LiDAR significantly surpasses naive rank based approaches in
its predictive power of optimal hyperparameters. Our proposed criterion
presents a more robust and intuitive means of assessing the quality of
representations within JE architectures, which we hope facilitates broader
adoption of these powerful techniques in various domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04021">A Study on the Calibration of In-context Learning. (arXiv:2312.04021v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi-Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaodong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1">Dhruv Madeka</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">Dean Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Hima Lakkaraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham Kakade</a></p>
<p>Modern auto-regressive language models are trained to minimize log loss on
broad data by predicting the next token so they are expected to get calibrated
answers when framing a problem as a next-token prediction task. We study this
for in-context learning (ICL), a widely used way to adapt frozen large language
models (LLMs) via crafting prompts, and investigate the trade-offs between
performance and calibration on a wide range of natural language understanding
and reasoning tasks. We conduct extensive experiments to show that such
trade-offs may get worse as we increase model size, incorporate more ICL
examples, and fine-tune models using instruction, dialog, or reinforcement
learning from human feedback (RLHF) on carefully curated datasets. Furthermore,
we find that common recalibration techniques that are widely effective such as
temperature scaling provide limited gains in calibration errors, suggesting
that new methods may be required for settings where models are expected to be
reliable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04024">k* Distribution: Evaluating the Latent Space of Deep Neural Networks using Local Neighborhood Analysis. (arXiv:2312.04024v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1">Shashank Kotyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatsuya_U/0/1/0/all/0/1">Ueda Tatsuya</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1">Danilo Vasconcellos Vargas</a></p>
<p>Most examinations of neural networks' learned latent spaces typically employ
dimensionality reduction techniques such as t-SNE or UMAP. While these methods
effectively capture the overall sample distribution in the entire learned
latent space, they tend to distort the structure of sample distributions within
specific classes in the subset of the latent space. This distortion complicates
the task of easily distinguishing classes identifiable by neural networks. In
response to this challenge, we introduce the k* Distribution methodology. This
approach focuses on capturing the characteristics and structure of sample
distributions for individual classes within the subset of the learned latent
space using local neighborhood analysis. The key concept is to facilitate easy
comparison of different k* distributions, enabling analysis of how various
classes are processed by the same neural network. This provides a more profound
understanding of existing contemporary visualizations. Our study reveals three
distinct distributions of samples within the learned latent space subset: a)
Fractured, b) Overlapped, and c) Clustered. We note and demonstrate that the
distribution of samples within the network's learned latent space significantly
varies depending on the class. Furthermore, we illustrate that our analysis can
be applied to explore the latent space of diverse neural network architectures,
various layers within neural networks, transformations applied to input
samples, and the distribution of training and testing data for neural networks.
We anticipate that our approach will facilitate more targeted investigations
into neural networks by collectively examining the distribution of different
samples within the learned latent space.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04027">The sample complexity of multi-distribution learning. (arXiv:2312.04027v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Binghui Peng</a></p>
<p>Multi-distribution learning generalizes the classic PAC learning to handle
data coming from multiple distributions. Given a set of $k$ data distributions
and a hypothesis class of VC dimension $d$, the goal is to learn a hypothesis
that minimizes the maximum population loss over $k$ distributions, up to
$\epsilon$ additive error. In this paper, we settle the sample complexity of
multi-distribution learning by giving an algorithm of sample complexity
$\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$. This matches the
lower bound up to sub-polynomial factor and resolves the COLT 2023 open problem
of Awasthi, Haghtalab and Zhao [AHZ23].
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04030">Modeling Boundedly Rational Agents with Latent Inference Budgets. (arXiv:2312.04030v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jacob_A/0/1/0/all/0/1">Athul Paul Jacob</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a></p>
<p>We study the problem of modeling a population of agents pursuing unknown
goals subject to unknown computational constraints. In standard models of
bounded rationality, sub-optimal decision-making is simulated by adding
homoscedastic noise to optimal decisions rather than explicitly simulating
constrained inference. In this work, we introduce a latent inference budget
model (L-IBM) that models agents' computational constraints explicitly, via a
latent variable (inferred jointly with a model of agents' goals) that controls
the runtime of an iterative inference algorithm. L-IBMs make it possible to
learn agent models using data from diverse populations of suboptimal actors. In
three modeling tasks -- inferring navigation goals from routes, inferring
communicative intents from human utterances, and predicting next moves in human
chess games -- we show that L-IBMs match or outperform Boltzmann models of
decision-making under uncertainty. Inferred inference budgets are themselves
meaningful, efficient to compute, and correlated with measures of player skill,
partner skill and task difficulty.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04032">RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training. (arXiv:2312.04032v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jaehyung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1">Rui Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hanchao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Davis Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1">Pascale Fung</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lifu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1">Madian Khabsa</a></p>
<p>Fine-tuning pre-trained language models (LMs) has become the de facto
standard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to
robustness issues, such as adversarial robustness and model calibration.
Several perspectives of robustness for LMs have been studied independently, but
lacking a unified consideration in multiple perspectives. In this paper, we
propose Robustifying LMs via Adversarial perturbation with Selective Training
(RoAST), a simple yet effective fine-tuning technique to enhance the
multi-perspective robustness of LMs in a unified way. RoAST effectively
incorporates two important sources for the model robustness, robustness on the
perturbed inputs and generalizable knowledge in pre-trained LMs. To be
specific, RoAST introduces adversarial perturbation during fine-tuning while
the model parameters are selectively updated upon their relative importance to
minimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by
incorporating four representative perspectives of model robustness, we
demonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning
methods on six different types of LMs, which indicates its usefulness in
practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04036">DiffusionPhase: Motion Diffusion in Frequency Domain. (arXiv:2312.04036v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1">Weilin Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shutong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Komura_T/0/1/0/all/0/1">Taku Komura</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1">Dinesh Jayaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a></p>
<p>In this study, we introduce a learning-based method for generating
high-quality human motion sequences from text descriptions (e.g., ``A person
walks forward"). Existing techniques struggle with motion diversity and smooth
transitions in generating arbitrary-length motion sequences, due to limited
text-to-motion datasets and the pose representations used that often lack
expressiveness or compactness. To address these issues, we propose the first
method for text-conditioned human motion generation in the frequency domain of
motions. We develop a network encoder that converts the motion space into a
compact yet expressive parameterized phase space with high-frequency details
encoded, capturing the local periodicity of motions in time and space with high
accuracy. We also introduce a conditional diffusion model for predicting
periodic motion parameters based on text descriptions and a start pose,
efficiently achieving smooth transitions between motion sequences associated
with different text descriptions. Experiments demonstrate that our approach
outperforms current methods in generating a broader variety of high-quality
motions, and synthesizing long sequences with natural transitions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04038">Reconstruction of dynamical systems from data without time labels. (arXiv:2312.04038v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhijun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Pipi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_C/0/1/0/all/0/1">Chenglong Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zuoqiang Shi</a></p>
<p>In this paper, we study the method to reconstruct dynamical systems from data
without time labels. Data without time labels appear in many applications, such
as molecular dynamics, single-cell RNA sequencing etc. Reconstruction of
dynamical system from time sequence data has been studied extensively. However,
these methods do not apply if time labels are unknown. Without time labels,
sequence data becomes distribution data. Based on this observation, we propose
to treat the data as samples from a probability distribution and try to
reconstruct the underlying dynamical system by minimizing the distribution
loss, sliced Wasserstein distance more specifically. Extensive experiment
results demonstrate the effectiveness of the proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04055">Jointly spatial-temporal representation learning for individual trajectories. (arXiv:2312.04055v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1">Jianrong Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yang Yue</a></p>
<p>Individual trajectories, containing substantial information on
human-environment interactions across space and time, is a crucial input for
geospatial foundation models (GeoFMs). However, existing attempts, leveraging
trajectory data for various applications have overlooked the implicit
spatial-temporal dependency within trajectories and failed to encode and
represent it in a format friendly to deep learning, posing a challenge in
obtaining general-purpose trajectory representations. Therefore, this paper
proposes a spatial-temporal joint representation learning method (ST-GraphRL)
to formalize learnable spatial-temporal dependencies into trajectory
representations. The proposed ST-GraphRL consists of three compositions: (i) a
weighted directed spatial-temporal graph to explicitly construct mobility
interactions over both space and time dimensions; (ii) a two-stage jointly
encoder (i.e., decoupling and fusion) to learn entangled spatial-temporal
dependencies by independently decomposing and jointly aggregating space and
time information; (iii) a decoder guides ST-GraphRL to learn explicit mobility
regularities by simulating the spatial-temporal distributions of trajectories.
Tested on three real-world human mobility datasets, the proposed ST-GraphRL
outperformed all the baseline models in predicting movement spatial-temporal
distributions and preserving trajectory similarity with high spatial-temporal
correlations. We also explore how spatial-temporal features presented in latent
space, validating that ST-GraphRL understands spatial-temporal patterns. This
method is also transferable for general-purpose geospatial data representations
for broad downstream tasks, as well advancing GeoFMs developing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04064">DiscoBAX: Discovery of Optimal Intervention Sets in Genomic Experiment Design. (arXiv:2312.04064v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Lyle_C/0/1/0/all/0/1">Clare Lyle</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mehrjou_A/0/1/0/all/0/1">Arash Mehrjou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Notin_P/0/1/0/all/0/1">Pascal Notin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jesson_A/0/1/0/all/0/1">Andrew Jesson</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Schwab_P/0/1/0/all/0/1">Patrick Schwab</a></p>
<p>The discovery of therapeutics to treat genetically-driven pathologies relies
on identifying genes involved in the underlying disease mechanisms. Existing
approaches search over the billions of potential interventions to maximize the
expected influence on the target phenotype. However, to reduce the risk of
failure in future stages of trials, practical experiment design aims to find a
set of interventions that maximally change a target phenotype via diverse
mechanisms. We propose DiscoBAX, a sample-efficient method for maximizing the
rate of significant discoveries per experiment while simultaneously probing for
a wide range of diverse mechanisms during a genomic experiment campaign. We
provide theoretical guarantees of approximate optimality under standard
assumptions, and conduct a comprehensive experimental evaluation covering both
synthetic as well as real-world experimental design tasks. DiscoBAX outperforms
existing state-of-the-art methods for experimental design, selecting effective
and diverse perturbations in biological systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04065">A Robust and Efficient Boundary Point Detection Method by Measuring Local Direction Dispersion. (arXiv:2312.04065v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Dehua Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_Z/0/1/0/all/0/1">Zhipeng Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huayi Wu</a></p>
<p>Boundary points pose a significant challenge for machine learning tasks,
including classification, clustering, and dimensionality reduction. Due to the
similarity of features, boundary areas can result in mixed-up classes or
clusters, leading to a crowding problem in dimensionality reduction. To address
this challenge, numerous boundary point detection methods have been developed,
but they are insufficiently to accurately and efficiently identify the boundary
points in non-convex structures and high-dimensional manifolds. In this work,
we propose a robust and efficient method for detecting boundary points using
Local Direction Dispersion (LoDD). LoDD considers that internal points are
surrounded by neighboring points in all directions, while neighboring points of
a boundary point tend to be distributed only in a certain directional range.
LoDD adopts a density-independent K-Nearest Neighbors (KNN) method to determine
neighboring points, and defines a statistic-based metric using the eigenvalues
of the covariance matrix of KNN coordinates to measure the centrality of a
query point. We demonstrated the validity of LoDD on five synthetic datasets
(2-D and 3-D) and ten real-world benchmarks, and tested its clustering
performance by equipping with two typical clustering methods, K-means and Ncut.
Our results show that LoDD achieves promising and robust detection accuracy in
a time-efficient manner.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04067">MeanCut: A Greedy-Optimized Graph Clustering via Path-based Similarity and Degree Descent Criterion. (arXiv:2312.04067v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Dehua Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_Z/0/1/0/all/0/1">Zhipeng Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huayi Wu</a></p>
<p>As the most typical graph clustering method, spectral clustering is popular
and attractive due to the remarkable performance, easy implementation, and
strong adaptability. Classical spectral clustering measures the edge weights of
graph using pairwise Euclidean-based metric, and solves the optimal graph
partition by relaxing the constraints of indicator matrix and performing
Laplacian decomposition. However, Euclidean-based similarity might cause skew
graph cuts when handling non-spherical data distributions, and the relaxation
strategy introduces information loss. Meanwhile, spectral clustering requires
specifying the number of clusters, which is hard to determine without enough
prior knowledge. In this work, we leverage the path-based similarity to enhance
intra-cluster associations, and propose MeanCut as the objective function and
greedily optimize it in degree descending order for a nondestructive graph
partition. This algorithm enables the identification of arbitrary shaped
clusters and is robust to noise. To reduce the computational complexity of
similarity calculation, we transform optimal path search into generating the
maximum spanning tree (MST), and develop a fast MST (FastMST) algorithm to
further improve its time-efficiency. Moreover, we define a density gradient
factor (DGF) for separating the weakly connected clusters. The validity of our
algorithm is demonstrated by testifying on real-world benchmarks and
application of face recognition. The source code of MeanCut is available at
https://github.com/ZPGuiGroupWhu/MeanCut-Clustering.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04068">Making Translators Privacy-aware on the User&#x27;s Side. (arXiv:2312.04068v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sato_R/0/1/0/all/0/1">Ryoma Sato</a></p>
<p>We propose PRISM to enable users of machine translation systems to preserve
the privacy of data on their own initiative. There is a growing demand to apply
machine translation systems to data that require privacy protection. While
several machine translation engines claim to prioritize privacy, the extent and
specifics of such protection are largely ambiguous. First, there is often a
lack of clarity on how and to what degree the data is protected. Even if
service providers believe they have sufficient safeguards in place,
sophisticated adversaries might still extract sensitive information. Second,
vulnerabilities may exist outside of these protective measures, such as within
communication channels, potentially leading to data leakage. As a result, users
are hesitant to utilize machine translation engines for data demanding high
levels of privacy protection, thereby missing out on their benefits. PRISM
resolves this problem. Instead of relying on the translation service to keep
data safe, PRISM provides the means to protect data on the user's side. This
approach ensures that even machine translation engines with inadequate privacy
measures can be used securely. For platforms already equipped with privacy
safeguards, PRISM acts as an additional protection layer, reinforcing their
security furthermore. PRISM adds these privacy features without significantly
compromising translation accuracy. Our experiments demonstrate the
effectiveness of PRISM using real-world translators, T5 and ChatGPT
(GPT-3.5-turbo), and the datasets with two languages. PRISM effectively
balances privacy protection with translation accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04070">A Transformer Model for Symbolic Regression towards Scientific Discovery. (arXiv:2312.04070v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lalande_F/0/1/0/all/0/1">Florian Lalande</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1">Yoshitomo Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiba_N/0/1/0/all/0/1">Naoya Chiba</a>, <a href="http://arxiv.org/find/cs/1/au:+Taniai_T/0/1/0/all/0/1">Tatsunori Taniai</a>, <a href="http://arxiv.org/find/cs/1/au:+Igarashi_R/0/1/0/all/0/1">Ryo Igarashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1">Yoshitala Ushiku</a></p>
<p>Symbolic Regression (SR) searches for mathematical expressions which best
describe numerical datasets. This allows to circumvent interpretation issues
inherent to artificial neural networks, but SR algorithms are often
computationally expensive. This work proposes a new Transformer model aiming at
Symbolic Regression particularly focused on its application for Scientific
Discovery. We propose three encoder architectures with increasing flexibility
but at the cost of column-permutation equivariance violation. Training results
indicate that the most flexible architecture is required to prevent from
overfitting. Once trained, we apply our best model to the SRSD datasets
(Symbolic Regression for Scientific Discovery datasets) which yields
state-of-the-art results using the normalized tree-based edit distance, at no
extra computational cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04083">On the adaptation of in-context learners for system identification. (arXiv:2312.04083v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Piga_D/0/1/0/all/0/1">Dario Piga</a>, <a href="http://arxiv.org/find/cs/1/au:+Pura_F/0/1/0/all/0/1">Filippo Pura</a>, <a href="http://arxiv.org/find/cs/1/au:+Forgione_M/0/1/0/all/0/1">Marco Forgione</a></p>
<p>In-context system identification aims at constructing meta-models to describe
classes of systems, differently from traditional approaches that model single
systems. This paradigm facilitates the leveraging of knowledge acquired from
observing the behaviour of different, yet related dynamics. This paper
discusses the role of meta-model adaptation. Through numerical examples, we
demonstrate how meta-model adaptation can enhance predictive performance in
three realistic scenarios: tailoring the meta-model to describe a specific
system rather than a class; extending the meta-model to capture the behaviour
of systems beyond the initial training class; and recalibrating the model for
new prediction tasks. Results highlight the effectiveness of meta-model
adaptation to achieve a more robust and versatile meta-learning framework for
system identification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04095">Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning Interference with Gradient Projection. (arXiv:2312.04095v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1">Tuan Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rana_S/0/1/0/all/0/1">Santu Rana</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Sunil Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1">Svetha Venkatesh</a></p>
<p>Recent data-privacy laws have sparked interest in machine unlearning, which
involves removing the effect of specific training samples from a learnt model
as if they were never present in the original training dataset. The challenge
of machine unlearning is to discard information about the ``forget'' data in
the learnt model without altering the knowledge about the remaining dataset and
to do so more efficiently than the naive retraining approach. To achieve this,
we adopt a projected-gradient based learning method, named as
Projected-Gradient Unlearning (PGU), in which the model takes steps in the
orthogonal direction to the gradient subspaces deemed unimportant for the
retaining dataset, so as to its knowledge is preserved. By utilizing Stochastic
Gradient Descent (SGD) to update the model weights, our method can efficiently
scale to any model and dataset size. We provide empirically evidence to
demonstrate that our unlearning method can produce models that behave similar
to models retrained from scratch across various metrics even when the training
dataset is no longer accessible. Our code is available at
https://github.com/hnanhtuan/projected_gradient_unlearning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04103">Enhancing the Rationale-Input Alignment for Self-explaining Rationalization. (arXiv:2312.04103v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haozhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhiying Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">YuanKai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruixuan Li</a></p>
<p>Rationalization empowers deep learning models with self-explaining
capabilities through a cooperative game, where a generator selects a
semantically consistent subset of the input as a rationale, and a subsequent
predictor makes predictions based on the selected rationale. In this paper, we
discover that rationalization is prone to a problem named \emph{rationale
shift}, which arises from the algorithmic bias of the cooperative game.
Rationale shift refers to a situation where the semantics of the selected
rationale may deviate from the original input, but the predictor still produces
accurate predictions based on the deviation, resulting in a compromised
generator with misleading feedback.
</p>
<p>To address this issue, we first demonstrate the importance of the alignment
between the rationale and the full input through both empirical observations
and theoretical analysis. Subsequently, we introduce a novel approach called
DAR (\textbf{D}iscriminatively \textbf{A}ligned \textbf{R}ationalization),
which utilizes an auxiliary module pretrained on the full input to
discriminatively align the selected rationale and the original input. We
theoretically illustrate how DAR accomplishes the desired alignment, thereby
overcoming the rationale shift problem. The experiments on two widely used
real-world benchmarks show that the proposed method significantly improves the
explanation quality (measured by the overlap between the model-selected
explanation and the human-annotated rationale) as compared to state-of-the-art
techniques. Additionally, results on two synthetic settings further validate
the effectiveness of DAR in addressing the rationale shift problem.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04110">Small Area Estimation of Case Growths for Timely COVID-19 Outbreak Detection. (arXiv:2312.04110v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+She_Z/0/1/0/all/0/1">Zhaowei She</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zilong Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Chhatwal_J/0/1/0/all/0/1">Jagpreet Chhatwal</a>, <a href="http://arxiv.org/find/stat/1/au:+Ayer_T/0/1/0/all/0/1">Turgay Ayer</a></p>
<p>The COVID-19 pandemic has exerted a profound impact on the global economy and
continues to exact a significant toll on human lives. The COVID-19 case growth
rate stands as a key epidemiological parameter to estimate and monitor for
effective detection and containment of the resurgence of outbreaks. A
fundamental challenge in growth rate estimation and hence outbreak detection is
balancing the accuracy-speed tradeoff, where accuracy typically degrades with
shorter fitting windows. In this paper, we develop a machine learning (ML)
algorithm, which we call Transfer Learning Generalized Random Forest (TLGRF),
that balances this accuracy-speed tradeoff. Specifically, we estimate the
instantaneous COVID-19 exponential growth rate for each U.S. county by using
TLGRF that chooses an adaptive fitting window size based on relevant day-level
and county-level features affecting the disease spread. Through transfer
learning, TLGRF can accurately estimate case growth rates for counties with
small sample sizes. Out-of-sample prediction analysis shows that TLGRF
outperforms established growth rate estimation methods. Furthermore, we
conducted a case study based on outbreak case data from the state of Colorado
and showed that the timely detection of outbreaks could have been improved by
up to 224% using TLGRF when compared to the decisions made by Colorado's
Department of Health and Environment (CDPHE). To facilitate implementation, we
have developed a publicly available outbreak detection tool for timely
detection of COVID-19 outbreaks in each U.S. county, which received substantial
attention from policymakers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04111">Breaking the Entanglement of Homophily and Heterophily in Semi-supervised Node Classification. (arXiv:2312.04111v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Henan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xunkai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhengyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1">Daohan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rong-Hua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoren Wang</a></p>
<p>Recently, graph neural networks (GNNs) have shown prominent performance in
semi-supervised node classification by leveraging knowledge from the graph
database. However, most existing GNNs follow the homophily assumption, where
connected nodes are more likely to exhibit similar feature distributions and
the same labels, and such an assumption has proven to be vulnerable in a
growing number of practical applications. As a supplement, heterophily reflects
dissimilarity in connected nodes, which has gained significant attention in
graph learning. To this end, data engineers aim to develop a powerful GNN model
that can ensure performance under both homophily and heterophily. Despite
numerous attempts, most existing GNNs struggle to achieve optimal node
representations due to the constraints of undirected graphs. The neglect of
directed edges results in sub-optimal graph representations, thereby hindering
the capacity of GNNs. To address this issue, we introduce AMUD, which
quantifies the relationship between node profiles and topology from a
statistical perspective, offering valuable insights for \underline{A}daptively
\underline{M}odeling the natural directed graphs as the \underline{U}ndirected
or \underline{D}irected graph to maximize the benefits from subsequent graph
learning. Furthermore, we propose \underline{A}daptive \underline{D}irected
\underline{P}attern \underline{A}ggregation (ADPA) as a new directed graph
learning paradigm for AMUD. Empirical studies have demonstrated that AMUD
guides efficient graph learning. Meanwhile, extensive experiments on 14
benchmark datasets substantiate the impressive performance of ADPA,
outperforming baselines by significant margins of 3.96\%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04118">Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic Play. (arXiv:2312.04118v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schaumloffel_T/0/1/0/all/0/1">Timothy Schauml&#xf6;ffel</a>, <a href="http://arxiv.org/find/cs/1/au:+Aubret_A/0/1/0/all/0/1">Arthur Aubret</a>, <a href="http://arxiv.org/find/cs/1/au:+Roig_G/0/1/0/all/0/1">Gemma Roig</a>, <a href="http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1">Jochen Triesch</a></p>
<p>Infants' ability to recognize and categorize objects develops gradually. The
second year of life is marked by both the emergence of more semantic visual
representations and a better understanding of word meaning. This suggests that
language input may play an important role in shaping visual representations.
However, even in suitable contexts for word learning like dyadic play sessions,
caregivers utterances are sparse and ambiguous, often referring to objects that
are different from the one to which the child attends. Here, we systematically
investigate to what extent caregivers' utterances can nevertheless enhance
visual representations. For this we propose a computational model of visual
representation learning during dyadic play. We introduce a synthetic dataset of
ego-centric images perceived by a toddler-agent that moves and rotates toy
objects in different parts of its home environment while hearing caregivers'
utterances, modeled as captions. We propose to model toddlers' learning as
simultaneously aligning representations for 1) close-in-time images and 2)
co-occurring images and utterances. We show that utterances with statistics
matching those of real caregivers give rise to representations supporting
improved category recognition. Our analysis reveals that a small
decrease/increase in object-relevant naming frequencies can drastically impact
the learned representations. This affects the attention on object names within
an utterance, which is required for efficient visuo-linguistic alignment.
Overall, our results support the hypothesis that caregivers' naming utterances
can improve toddlers' visual representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04135">A Novel Federated Learning-based Intrusion Detection System for Flying Ad Hoc Networks. (arXiv:2312.04135v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ceviz_O/0/1/0/all/0/1">Ozlem Ceviz</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Sadioglu_P/0/1/0/all/0/1">Pinar Sadioglu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1">Sevil Sen</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Vassilakis_V/0/1/0/all/0/1">Vassilios G. Vassilakis</a> (2) ((1) WISE Lab., Deparment of Computer Engineering, Hacettepe University, Ankara, Turkey (2) Department of Computer Science, University of York, York, United Kingdom)</p>
<p>Unmanned aerial vehicles (UAVs) in flying ad-hoc networks (FANETs) face
security challenges due to the dynamic and distributed nature of these
networks. This paper presents the Federated Learning-based Intrusion Detection
System (FL-IDS), an innovative approach designed to improve FANET security.
FL-IDS leverages federated learning to address privacy concerns of centralized
intrusion detection systems. FL-IDS operates in a decentralized manner,
enabling UAVs to collaboratively train a global intrusion detection model
without sharing raw data. Local models are assigned to each UAV, using
client-specific data, and only updated model weights are shared with a central
server. This preserves privacy while utilizing collective intelligence for
effective intrusion detection. Experimental results show FL-IDS's competitive
performance with Central IDS (C-IDS) while mitigating privacy concerns. The
Bias Towards Specific Clients (BTSC) method further enhances FL-IDS
performance, surpassing C-IDS even at lower attacker ratios. A comparative
analysis with traditional intrusion detection methods, including Local IDS
(L-IDS), provides insights into FL-IDS's strengths. This study significantly
contributes to FANET security by introducing a privacy-aware, decentralized
intrusion detection approach tailored to the unique challenges of UAV networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04142">TimeDRL: Disentangled Representation Learning for Multivariate Time-Series. (arXiv:2312.04142v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Ching Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1">Chiao-Tung Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei-Yao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wen-Chih Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tien-Fu Chen</a></p>
<p>Multivariate time-series data in numerous real-world applications (e.g.,
healthcare and industry) are informative but challenging due to the lack of
labels and high dimensionality. Recent studies in self-supervised learning have
shown their potential in learning rich representations without relying on
labels, yet they fall short in learning disentangled embeddings and addressing
issues of inductive bias (e.g., transformation-invariance). To tackle these
challenges, we propose TimeDRL, a generic multivariate time-series
representation learning framework with disentangled dual-level embeddings.
TimeDRL is characterized by three novel features: (i) disentangled derivation
of timestamp-level and instance-level embeddings from patched time-series data
using a [CLS] token strategy; (ii) utilization of timestamp-predictive and
instance-contrastive tasks for disentangled representation learning, with the
former optimizing timestamp-level embeddings with predictive loss, and the
latter optimizing instance-level embeddings with contrastive loss; and (iii)
avoidance of augmentation methods to eliminate inductive biases, such as
transformation-invariance from cropping and masking. Comprehensive experiments
on 6 time-series forecasting datasets and 5 time-series classification datasets
have shown that TimeDRL consistently surpasses existing representation learning
approaches, achieving an average improvement of forecasting by 57.98% in MSE
and classification by 1.25% in accuracy. Furthermore, extensive ablation
studies confirmed the relative contribution of each component in TimeDRL's
architecture, and semi-supervised learning evaluations demonstrated its
effectiveness in real-world scenarios, even with limited labeled data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04145">Diffusing Colors: Image Colorization with Text Guided Diffusion. (arXiv:2312.04145v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zabari_N/0/1/0/all/0/1">Nir Zabari</a>, <a href="http://arxiv.org/find/cs/1/au:+Azulay_A/0/1/0/all/0/1">Aharon Azulay</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorkor_A/0/1/0/all/0/1">Alexey Gorkor</a>, <a href="http://arxiv.org/find/cs/1/au:+Halperin_T/0/1/0/all/0/1">Tavi Halperin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fried_O/0/1/0/all/0/1">Ohad Fried</a></p>
<p>The colorization of grayscale images is a complex and subjective task with
significant challenges. Despite recent progress in employing large-scale
datasets with deep neural networks, difficulties with controllability and
visual quality persist. To tackle these issues, we present a novel image
colorization framework that utilizes image diffusion techniques with granular
text prompts. This integration not only produces colorization outputs that are
semantically appropriate but also greatly improves the level of control users
have over the colorization process. Our method provides a balance between
automation and control, outperforming existing techniques in terms of visual
quality and semantic coherence. We leverage a pretrained generative Diffusion
Model, and show that we can finetune it for the colorization task without
losing its generative power or attention to text prompts. Moreover, we present
a novel CLIP-based ranking model that evaluates color vividness, enabling
automatic selection of the most suitable level of vividness based on the
specific scene semantics. Our approach holds potential particularly for color
enhancement and historical image colorization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04155">Resource Allocation for Semantic Communication under Physical-layer Security. (arXiv:2312.04155v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xinyu Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a></p>
<p>Semantic communication is deemed as a revolution of Shannon's paradigm in the
six-generation (6G) wireless networks. It aims at transmitting the extracted
information rather than the original data, which receivers will try to recover.
Intuitively, the larger extracted information, the longer latency of semantic
communication will be. Besides, larger extracted information will result in
more accurate reconstructed information, thereby causing a higher utility of
the semantic communication system. Shorter latency and higher utility are
desirable objectives for the system, so there will be a trade-off between
utility and latency. This paper proposes a joint optimization algorithm for
total latency and utility. Moreover, security is essential for the semantic
communication system. We incorporate the secrecy rate, a physical-layer
security method, into the optimization problem. The secrecy rate is the
communication rate at which no information is disclosed to an eavesdropper.
Experimental results demonstrate that the proposed algorithm obtains the best
joint optimization performance compared to the baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04159">Zero-Touch Networks: Towards Next-Generation Network Automation. (arXiv:2312.04159v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rajab_M/0/1/0/all/0/1">Mirna El Rajab</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Li Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shami_A/0/1/0/all/0/1">Abdallah Shami</a></p>
<p>The Zero-touch network and Service Management (ZSM) framework represents an
emerging paradigm in the management of the fifth-generation (5G) and Beyond
(5G+) networks, offering automated self-management and self-healing
capabilities to address the escalating complexity and the growing data volume
of modern networks. ZSM frameworks leverage advanced technologies such as
Machine Learning (ML) to enable intelligent decision-making and reduce human
intervention. This paper presents a comprehensive survey of Zero-Touch Networks
(ZTNs) within the ZSM framework, covering network optimization, traffic
monitoring, energy efficiency, and security aspects of next-generational
networks. The paper explores the challenges associated with ZSM, particularly
those related to ML, which necessitate the need to explore diverse network
automation solutions. In this context, the study investigates the application
of Automated ML (AutoML) in ZTNs, to reduce network management costs and
enhance performance. AutoML automates the selection and tuning process of a ML
model for a given task. Specifically, the focus is on AutoML's ability to
predict application throughput and autonomously adapt to data drift.
Experimental results demonstrate the superiority of the proposed AutoML
pipeline over traditional ML in terms of prediction accuracy. Integrating
AutoML and ZSM concepts significantly reduces network configuration and
management efforts, allowing operators to allocate more time and resources to
other important tasks. The paper also provides a high-level 5G system
architecture incorporating AutoML and ZSM concepts. This research highlights
the potential of ZTNs and AutoML to revolutionize the management of 5G+
networks, enabling automated decision-making and empowering network operators
to achieve higher efficiency, improved performance, and enhanced user
experience.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04163">Multi-scale Residual Transformer for VLF Lightning Transients Classification. (arXiv:2312.04163v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Sun_J/0/1/0/all/0/1">Jinghao Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Ji_T/0/1/0/all/0/1">Tingting Ji</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_G/0/1/0/all/0/1">Guoyu Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a></p>
<p>The utilization of Very Low Frequency (VLF) electromagnetic signals in
navigation systems is widespread. However, the non-stationary behavior of
lightning signals can affect VLF electromagnetic signal transmission.
Accurately classifying lightning signals is important for reducing interference
and noise in VLF, thereby improving the reliability and overall performance of
navigation systems. In recent years, the evolution of deep learning,
specifically Convolutional Neural Network (CNNs), has sparked a transformation
in lightning classification, surpassing traditional statistical methodologies.
Existing CNN models have limitations as they overlook the diverse attributes of
lightning signals across different scales and neglect the significance of
temporal sequencing in sequential signals. This study introduces an innovative
multi-scale residual transform (MRTransformer) that not only has the ability to
discern intricate fine-grained patterns while also weighing the significance of
different aspects within the input lightning signal sequence. This model
performs the attributes of the lightning signal across different scales and the
level of accuracy reached 90% in the classification. In future work, this model
has the potential applied to a comprehensive understanding of the localization
and waveform characteristics of lightning signals.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04166">Improving Communication Efficiency of Federated Distillation via Accumulating Local Updates. (arXiv:2312.04166v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Sheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Min Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_T/0/1/0/all/0/1">Tian Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a></p>
<p>As an emerging federated learning paradigm, federated distillation enables
communication-efficient model training by transmitting only small-scale
knowledge during the learning process. To further improve the communication
efficiency of federated distillation, we propose a novel technique, ALU, which
accumulates multiple rounds of local updates before transferring the knowledge
to the central server. ALU drastically decreases the frequency of communication
in federated distillation, thereby significantly reducing the communication
overhead during the training process. Empirical experiments demonstrate the
substantial effect of ALU in improving the communication efficiency of
federated distillation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04167">Mixture of Dynamical Variational Autoencoders for Multi-Source Trajectory Modeling and Separation. (arXiv:2312.04167v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xiaoyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Girin_L/0/1/0/all/0/1">Laurent Girin</a>, <a href="http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1">Xavier Alameda-Pineda</a></p>
<p>In this paper, we propose a latent-variable generative model called mixture
of dynamical variational autoencoders (MixDVAE) to model the dynamics of a
system composed of multiple moving sources. A DVAE model is pre-trained on a
single-source dataset to capture the source dynamics. Then, multiple instances
of the pre-trained DVAE model are integrated into a multi-source mixture model
with a discrete observation-to-source assignment latent variable. The posterior
distributions of both the discrete observation-to-source assignment variable
and the continuous DVAE variables representing the sources content/position are
estimated using a variational expectation-maximization algorithm, leading to
multi-source trajectories estimation. We illustrate the versatility of the
proposed MixDVAE model on two tasks: a computer vision task, namely
multi-object tracking, and an audio processing task, namely single-channel
audio source separation. Experimental results show that the proposed method
works well on these two tasks, and outperforms several baseline methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04168">Augmentation-Free Dense Contrastive Knowledge Distillation for Efficient Semantic Segmentation. (arXiv:2312.04168v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jiawei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaolong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Meina Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1">Anbang Yao</a></p>
<p>In recent years, knowledge distillation methods based on contrastive learning
have achieved promising results on image classification and object detection
tasks. However, in this line of research, we note that less attention is paid
to semantic segmentation. Existing methods heavily rely on data augmentation
and memory buffer, which entail high computational resource demands when
applying them to handle semantic segmentation that requires to preserve
high-resolution feature maps for making dense pixel-wise predictions. In order
to address this problem, we present Augmentation-free Dense Contrastive
Knowledge Distillation (Af-DCD), a new contrastive distillation learning
paradigm to train compact and accurate deep neural networks for semantic
segmentation applications. Af-DCD leverages a masked feature mimicking
strategy, and formulates a novel contrastive learning loss via taking advantage
of tactful feature partitions across both channel and spatial dimensions,
allowing to effectively transfer dense and structured local knowledge learnt by
the teacher model to a target student model while maintaining training
efficiency. Extensive experiments on five mainstream benchmarks with various
teacher-student network pairs demonstrate the effectiveness of our approach.
For instance, the DeepLabV3-Res18|DeepLabV3-MBV2 model trained by Af-DCD
reaches 77.03%|76.38% mIOU on Cityscapes dataset when choosing DeepLabV3-Res101
as the teacher, setting new performance records. Besides that, Af-DCD achieves
an absolute mIOU improvement of 3.26%|3.04%|2.75%|2.30%|1.42% compared with
individually trained counterpart on Cityscapes|Pascal
VOC|Camvid|ADE20K|COCO-Stuff-164K. Code is available at
https://github.com/OSVAI/Af-DCD
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04171">A novel feature selection framework for incomplete data. (arXiv:2312.04171v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Cong Guo</a></p>
<p>Feature selection on incomplete datasets is an exceptionally challenging
task. Existing methods address this challenge by first employing imputation
methods to complete the incomplete data and then conducting feature selection
based on the imputed data. Since imputation and feature selection are entirely
independent steps, the importance of features cannot be considered during
imputation. However, in real-world scenarios or datasets, different features
have varying degrees of importance. To address this, we propose a novel
incomplete data feature selection framework that considers feature importance.
The framework mainly consists of two alternating iterative stages: the M-stage
and the W-stage. In the M-stage, missing values are imputed based on a given
feature importance vector and multiple initial imputation results. In the
W-stage, an improved reliefF algorithm is employed to learn the feature
importance vector based on the imputed data. Specifically, the feature
importance vector obtained in the current iteration of the W-stage serves as
input for the next iteration of the M-stage. Experimental results on both
artificially generated and real incomplete datasets demonstrate that the
proposed method outperforms other approaches significantly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04174">Coherent energy and force uncertainty in deep learning force fields. (arXiv:2312.04174v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Jorgensen_P/0/1/0/all/0/1">Peter Bj&#xf8;rn J&#xf8;rgensen</a>, <a href="http://arxiv.org/find/stat/1/au:+Busk_J/0/1/0/all/0/1">Jonas Busk</a>, <a href="http://arxiv.org/find/stat/1/au:+Winther_O/0/1/0/all/0/1">Ole Winther</a>, <a href="http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1">Mikkel N. Schmidt</a></p>
<p>In machine learning energy potentials for atomic systems, forces are commonly
obtained as the negative derivative of the energy function with respect to
atomic positions. To quantify aleatoric uncertainty in the predicted energies,
a widely used modeling approach involves predicting both a mean and variance
for each energy value. However, this model is not differentiable under the
usual white noise assumption, so energy uncertainty does not naturally
translate to force uncertainty. In this work we propose a machine learning
potential energy model in which energy and force aleatoric uncertainty are
linked through a spatially correlated noise process. We demonstrate our
approach on an equivariant messages passing neural network potential trained on
energies and forces on two out-of-equilibrium molecular datasets. Furthermore,
we also show how to obtain epistemic uncertainties in this setting based on a
Bayesian interpretation of deep ensemble models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04193">Language Model Knowledge Distillation for Efficient Question Answering in Spanish. (arXiv:2312.04193v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1">Adri&#xe1;n Bazaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1">Gos Micklem</a></p>
<p>Recent advances in the development of pre-trained Spanish language models has
led to significant progress in many Natural Language Processing (NLP) tasks,
such as question answering. However, the lack of efficient models imposes a
barrier for the adoption of such models in resource-constrained environments.
Therefore, smaller distilled models for the Spanish language could be proven to
be highly scalable and facilitate their further adoption on a variety of tasks
and scenarios. In this work, we take one step in this direction by developing
SpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient
question answering in Spanish. To achieve this, we employ knowledge
distillation from a large model onto a lighter model that allows for a wider
implementation, even in areas with limited computational resources, whilst
attaining negligible performance sacrifice. Our experiments show that the dense
distilled model can still preserve the performance of its larger counterpart,
while significantly increasing inference speedup. This work serves as a
starting point for further research and investigation of model compression
efforts for Spanish language models across various NLP tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04204">Wavelength-multiplexed Delayed Inputs for Memory Enhancement of Microring-based Reservoir Computing. (arXiv:2312.04204v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Castro_B/0/1/0/all/0/1">Bernard J. Giron Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Peucheret_C/0/1/0/all/0/1">Christophe Peucheret</a>, <a href="http://arxiv.org/find/cs/1/au:+Ros_F/0/1/0/all/0/1">Francesco Da Ros</a></p>
<p>We numerically demonstrate a silicon add-drop microring-based reservoir
computing scheme that combines parallel delayed inputs and wavelength division
multiplexing. The scheme solves memory-demanding tasks like time-series
prediction with good performance without requiring external optical feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04209">Constrained Hierarchical Clustering via Graph Coarsening and Optimal Cuts. (arXiv:2312.04209v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mauduit_E/0/1/0/all/0/1">Eliabelle Mauduit</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonetto_A/0/1/0/all/0/1">Andrea Simonetto</a></p>
<p>Motivated by extracting and summarizing relevant information in short
sentence settings, such as satisfaction questionnaires, hotel reviews, and
X/Twitter, we study the problem of clustering words in a hierarchical fashion.
In particular, we focus on the problem of clustering with horizontal and
vertical structural constraints. Horizontal constraints are typically
cannot-link and must-link among words, while vertical constraints are
precedence constraints among cluster levels. We overcome state-of-the-art
bottlenecks by formulating the problem in two steps: first, as a
soft-constrained regularized least-squares which guides the result of a
sequential graph coarsening algorithm towards the horizontal feasible set.
Then, flat clusters are extracted from the resulting hierarchical tree by
computing optimal cut heights based on the available constraints. We show that
the resulting approach compares very well with respect to existing algorithms
and is computationally light.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04215">Guided Reconstruction with Conditioned Diffusion Models for Unsupervised Anomaly Detection in Brain MRIs. (arXiv:2312.04215v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Behrendt_F/0/1/0/all/0/1">Finn Behrendt</a>, <a href="http://arxiv.org/find/eess/1/au:+Bhattacharya_D/0/1/0/all/0/1">Debayan Bhattacharya</a>, <a href="http://arxiv.org/find/eess/1/au:+Mieling_R/0/1/0/all/0/1">Robin Mieling</a>, <a href="http://arxiv.org/find/eess/1/au:+Maack_L/0/1/0/all/0/1">Lennart Maack</a>, <a href="http://arxiv.org/find/eess/1/au:+Kruger_J/0/1/0/all/0/1">Julia Kr&#xfc;ger</a>, <a href="http://arxiv.org/find/eess/1/au:+Opfer_R/0/1/0/all/0/1">Roland Opfer</a>, <a href="http://arxiv.org/find/eess/1/au:+Schlaefer_A/0/1/0/all/0/1">Alexander Schlaefer</a></p>
<p>Unsupervised anomaly detection in Brain MRIs aims to identify abnormalities
as outliers from a healthy training distribution. Reconstruction-based
approaches that use generative models to learn to reconstruct healthy brain
anatomy are commonly used for this task. Diffusion models are an emerging class
of deep generative models that show great potential regarding reconstruction
fidelity. However, they face challenges in preserving intensity characteristics
in the reconstructed images, limiting their performance in anomaly detection.
To address this challenge, we propose to condition the denoising mechanism of
diffusion models with additional information about the image to reconstruct
coming from a latent representation of the noise-free input image. This
conditioning enables high-fidelity reconstruction of healthy brain structures
while aligning local intensity characteristics of input-reconstruction pairs.
We evaluate our method's reconstruction quality, domain adaptation features and
finally segmentation performance on publicly available data sets with various
pathologies. Using our proposed conditioning mechanism we can reduce the
false-positive predictions and enable a more precise delineation of anomalies
which significantly enhances the anomaly detection performance compared to
established state-of-the-art approaches to unsupervised anomaly detection in
brain MRI. Furthermore, our approach shows promise in domain adaptation across
different MRI acquisitions and simulated contrasts, a crucial property of
general anomaly detection methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04216">CODEX: A Cluster-Based Method for Explainable Reinforcement Learning. (arXiv:2312.04216v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mathes_T/0/1/0/all/0/1">Timothy K. Mathes</a>, <a href="http://arxiv.org/find/cs/1/au:+Inman_J/0/1/0/all/0/1">Jessica Inman</a>, <a href="http://arxiv.org/find/cs/1/au:+Colon_A/0/1/0/all/0/1">Andr&#xe9;s Col&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Simon Khan</a></p>
<p>Despite the impressive feats demonstrated by Reinforcement Learning (RL),
these algorithms have seen little adoption in high-risk, real-world
applications due to current difficulties in explaining RL agent actions and
building user trust. We present Counterfactual Demonstrations for Explanation
(CODEX), a method that incorporates semantic clustering, which can effectively
summarize RL agent behavior in the state-action space. Experimentation on the
MiniGrid and StarCraft II gaming environments reveals the semantic clusters
retain temporal as well as entity information, which is reflected in the
constructed summary of agent behavior. Furthermore, clustering the
discrete+continuous game-state latent representations identifies the most
crucial episodic events, demonstrating a relationship between the latent and
semantic spaces. This work contributes to the growing body of work that strives
to unlock the power of RL for widespread use by leveraging and extending
techniques from Natural Language Processing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04234">Graph Convolutions Enrich the Self-Attention in Transformers!. (arXiv:2312.04234v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jeongwhan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wi_H/0/1/0/all/0/1">Hyowon Wi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jayoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yehjin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kookjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Trask_N/0/1/0/all/0/1">Nathaniel Trask</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a></p>
<p>Transformers, renowned for their self-attention mechanism, have achieved
state-of-the-art performance across various tasks in natural language
processing, computer vision, time-series modeling, etc. However, one of the
challenges with deep Transformer models is the oversmoothing problem, where
representations across layers converge to indistinguishable values, leading to
significant performance degradation. We interpret the original self-attention
as a simple graph filter and redesign it from a graph signal processing (GSP)
perspective. We propose graph-filter-based self-attention (GFSA) to learn a
general yet effective one, whose complexity, however, is slightly larger than
that of the original self-attention mechanism. We demonstrate that GFSA
improves the performance of Transformers in various fields, including computer
vision, natural language processing, graph pattern classification, speech
recognition, and code classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04273">Invariant Random Forest: Tree-Based Model Solution for OOD Generalization. (arXiv:2312.04273v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yufan Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xing Yan</a></p>
<p>Out-Of-Distribution (OOD) generalization is an essential topic in machine
learning. However, recent research is only focusing on the corresponding
methods for neural networks. This paper introduces a novel and effective
solution for OOD generalization of decision tree models, named Invariant
Decision Tree (IDT). IDT enforces a penalty term with regard to the
unstable/varying behavior of a split across different environments during the
growth of the tree. Its ensemble version, the Invariant Random Forest (IRF), is
constructed. Our proposed method is motivated by a theoretical result under
mild conditions, and validated by numerical tests with both synthetic and real
datasets. The superior performance compared to non-OOD tree models implies that
considering OOD generalization for tree models is absolutely necessary and
should be given more attention.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04275">Estimating Countries with Similar Maternal Mortality Rate using Cluster Analysis and Pairing Countries with Identical MMR. (arXiv:2312.04275v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nandini_S/0/1/0/all/0/1">S. Nandini</a>, <a href="http://arxiv.org/find/cs/1/au:+R_S/0/1/0/all/0/1">Sanjjushri Varshini R</a></p>
<p>In the evolving world, we require more additionally the young era to flourish
and evolve into developed land. Most of the population all around the world are
unaware of the complications involved in the routine they follow while they are
pregnant and how hospital facilities affect maternal health. Maternal Mortality
is the death of a pregnant woman due to intricacies correlated to pregnancy,
underlying circumstances exacerbated by the pregnancy or management of these
situations. It is crucial to consider the Maternal Mortality Rate (MMR) in
diverse locations and determine which human routines and hospital facilities
diminish the Maternal Mortality Rate (MMR). This research aims to examine and
discover the countries which are keeping more lavish threats of MMR and
countries alike in MMR encountered. Data is examined and collected for various
countries, data consists of the earlier years' observation. From the
perspective of Machine Learning, Unsupervised Machine Learning is implemented
to perform Cluster Analysis. Therefore the pairs of countries with similar MMR
as well as the extreme opposite pair concerning the MMR are found.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04281">Factor-Assisted Federated Learning for Personalized Optimization with Heterogeneous Data. (arXiv:2312.04281v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1">Feifei Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_H/0/1/0/all/0/1">Huiyun Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a></p>
<p>Federated learning is an emerging distributed machine learning framework
aiming at protecting data privacy. Data heterogeneity is one of the core
challenges in federated learning, which could severely degrade the convergence
rate and prediction performance of deep neural networks. To address this issue,
we develop a novel personalized federated learning framework for heterogeneous
data, which we refer to as FedSplit. This modeling framework is motivated by
the finding that, data in different clients contain both common knowledge and
personalized knowledge. Then the hidden elements in each neural layer can be
split into the shared and personalized groups. With this decomposition, a novel
objective function is established and optimized. We demonstrate FedSplit
enjoyers a faster convergence speed than the standard federated learning method
both theoretically and empirically. The generalization bound of the FedSplit
method is also studied. To practically implement the proposed method on real
datasets, factor analysis is introduced to facilitate the decoupling of hidden
elements. This leads to a practically implemented model for FedSplit and we
further refer to as FedFac. We demonstrated by simulation studies that, using
factor analysis can well recover the underlying shared/personalized
decomposition. The superior prediction performance of FedFac is further
verified empirically by comparison with various state-of-the-art federated
learning methods on several real datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04291">Simulating the Air Quality Impact of Prescribed Fires Using a Graph Neural Network-Based PM$_{2.5}$ Emissions Forecasting System. (arXiv:2312.04291v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Liao_K/0/1/0/all/0/1">Kyleen Liao</a>, <a href="http://arxiv.org/find/physics/1/au:+Buch_J/0/1/0/all/0/1">Jatan Buch</a>, <a href="http://arxiv.org/find/physics/1/au:+Lamb_K/0/1/0/all/0/1">Kara Lamb</a>, <a href="http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1">Pierre Gentine</a></p>
<p>The increasing size and severity of wildfires across western North America
have generated dangerous levels of PM$_{2.5}$ pollution in recent years. In a
warming climate, expanding the use of prescribed fires is widely considered to
be the most robust fire mitigation strategy. However, reliably forecasting the
potential air quality impact from these prescribed fires, a critical ingredient
in determining the fires' location and time, at hourly to daily time scales
remains a challenging problem. This paper proposes a novel integration of
prescribed fire simulation with a spatio-temporal graph neural network-based
PM$_{2.5}$ forecasting model. The experiments in this work focus on determining
the optimal time for implementing prescribed fires in California as well as
quantifying the potential air quality trade-offs involved in conducting more
prescribed fires outside the fire season.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04307">A Structural-Clustering Based Active Learning for Graph Neural Networks. (arXiv:2312.04307v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fajri_R/0/1/0/all/0/1">Ricky Maulana Fajri</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_Y/0/1/0/all/0/1">Yulong Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1">Lu Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a></p>
<p>In active learning for graph-structured data, Graph Neural Networks (GNNs)
have shown effectiveness. However, a common challenge in these applications is
the underutilization of crucial structural information. To address this
problem, we propose the Structural-Clustering PageRank method for improved
Active learning (SPA) specifically designed for graph-structured data. SPA
integrates community detection using the SCAN algorithm with the PageRank
scoring method for efficient and informative sample selection. SPA prioritizes
nodes that are not only informative but also central in structure. Through
extensive experiments, SPA demonstrates higher accuracy and macro-F1 score over
existing methods across different annotation budgets and achieves significant
reductions in query time. In addition, the proposed method only adds two
hyperparameters, $\epsilon$ and $\mu$ in the algorithm to finely tune the
balance between structural learning and node selection. This simplicity is a
key advantage in active learning scenarios, where extensive hyperparameter
tuning is often impractical.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04311">Finding Interpretable Class-Specific Patterns through Efficient Neural Search. (arXiv:2312.04311v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Walter_N/0/1/0/all/0/1">Nils Philipp Walter</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1">Jonas Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vreeken_J/0/1/0/all/0/1">Jilles Vreeken</a></p>
<p>Discovering patterns in data that best describe the differences between
classes allows to hypothesize and reason about class-specific mechanisms. In
molecular biology, for example, this bears promise of advancing the
understanding of cellular processes differing between tissues or diseases,
which could lead to novel treatments. To be useful in practice, methods that
tackle the problem of finding such differential patterns have to be readily
interpretable by domain experts, and scalable to the extremely high-dimensional
data.
</p>
<p>In this work, we propose a novel, inherently interpretable binary neural
network architecture DIFFNAPS that extracts differential patterns from data.
DiffNaps is scalable to hundreds of thousands of features and robust to noise,
thus overcoming the limitations of current state-of-the-art methods in
large-scale applications such as in biology. We show on synthetic and real
world data, including three biological applications, that, unlike its
competitors, DiffNaps consistently yields accurate, succinct, and interpretable
class descriptions
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04312">Stochastic-Constrained Stochastic Optimization with Markovian Data. (arXiv:2312.04312v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Kim_Y/0/1/0/all/0/1">Yeongjong Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1">Dabeen Lee</a></p>
<p>This paper considers stochastic-constrained stochastic optimization where the
stochastic constraint is to satisfy that the expectation of a random function
is below a certain threshold. In particular, we study the setting where data
samples are drawn from a Markov chain and thus are not independent and
identically distributed. We generalize the drift-plus-penalty framework, a
primal-dual stochastic gradient method developed for the i.i.d. case, to the
Markov chain sampling setting. We propose two variants of drift-plus-penalty;
one is for the case when the mixing time of the underlying Markov chain is
known while the other is for the case of unknown mixing time. In fact, our
algorithms apply to a more general setting of constrained online convex
optimization where the sequence of constraint functions follows a Markov chain.
Both algorithms are adaptive in that the first works without knowledge of the
time horizon while the second uses AdaGrad-style algorithm parameters, which is
of independent interest. We demonstrate the effectiveness of our proposed
methods through numerical experiments on classification with fairness
constraints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04318">MIMo: A Multi-Modal Infant Model for Studying Cognitive Development. (arXiv:2312.04318v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mattern_D/0/1/0/all/0/1">Dominik Mattern</a>, <a href="http://arxiv.org/find/cs/1/au:+Schumacher_P/0/1/0/all/0/1">Pierre Schumacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_F/0/1/0/all/0/1">Francisco M. L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Raabe_M/0/1/0/all/0/1">Marcel C. Raabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernst_M/0/1/0/all/0/1">Markus R. Ernst</a>, <a href="http://arxiv.org/find/cs/1/au:+Aubret_A/0/1/0/all/0/1">Arthur Aubret</a>, <a href="http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1">Jochen Triesch</a></p>
<p>Human intelligence and human consciousness emerge gradually during the
process of cognitive development. Understanding this development is an
essential aspect of understanding the human mind and may facilitate the
construction of artificial minds with similar properties. Importantly, human
cognitive development relies on embodied interactions with the physical and
social environment, which is perceived via complementary sensory modalities.
These interactions allow the developing mind to probe the causal structure of
the world. This is in stark contrast to common machine learning approaches,
e.g., for large language models, which are merely passively ``digesting'' large
amounts of training data, but are not in control of their sensory inputs.
However, computational modeling of the kind of self-determined embodied
interactions that lead to human intelligence and consciousness is a formidable
challenge. Here we present MIMo, an open-source multi-modal infant model for
studying early cognitive development through computer simulations. MIMo's body
is modeled after an 18-month-old child with detailed five-fingered hands. MIMo
perceives its surroundings via binocular vision, a vestibular system,
proprioception, and touch perception through a full-body virtual skin, while
two different actuation models allow control of his body. We describe the
design and interfaces of MIMo and provide examples illustrating its use. All
code is available at https://github.com/trieschlab/MIMo .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04323">Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms. (arXiv:2312.04323v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Jing_B/0/1/0/all/0/1">Bowen Jing</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jaakkola_T/0/1/0/all/0/1">Tommi Jaakkola</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Berger_B/0/1/0/all/0/1">Bonnie Berger</a></p>
<p>Molecular docking is critical to structure-based virtual screening, yet the
throughput of such workflows is limited by the expensive optimization of
scoring functions involved in most docking algorithms. We explore how machine
learning can accelerate this process by learning a scoring function with a
functional form that allows for more rapid optimization. Specifically, we
define the scoring function to be the cross-correlation of multi-channel ligand
and protein scalar fields parameterized by equivariant graph neural networks,
enabling rapid optimization over rigid-body degrees of freedom with fast
Fourier transforms. The runtime of our approach can be amortized at several
levels of abstraction, and is particularly favorable for virtual screening
settings with a common binding pocket. We benchmark our scoring functions on
two simplified docking-related tasks: decoy pose scoring and rigid conformer
docking. Our method attains similar but faster performance on crystal
structures compared to the widely-used Vina and Gnina scoring functions, and is
more robust on computationally predicted structures. Code is available at
https://github.com/bjing2016/scalar-fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04327">Learning to sample in Cartesian MRI. (arXiv:2312.04327v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sanchez_T/0/1/0/all/0/1">Thomas Sanchez</a></p>
<p>Despite its exceptional soft tissue contrast, Magnetic Resonance Imaging
(MRI) faces the challenge of long scanning times compared to other modalities
like X-ray radiography. Shortening scanning times is crucial in clinical
settings, as it increases patient comfort, decreases examination costs and
improves throughput. Recent advances in compressed sensing (CS) and deep
learning allow accelerated MRI acquisition by reconstructing high-quality
images from undersampled data. While reconstruction algorithms have received
most of the focus, designing acquisition trajectories to optimize
reconstruction quality remains an open question. This thesis explores two
approaches to address this gap in the context of Cartesian MRI. First, we
propose two algorithms, lazy LBCS and stochastic LBCS, that significantly
improve upon G\"ozc\"u et al.'s greedy learning-based CS (LBCS) approach. These
algorithms scale to large, clinically relevant scenarios like multi-coil 3D MR
and dynamic MRI, previously inaccessible to LBCS. Additionally, we demonstrate
that generative adversarial networks (GANs) can serve as a natural criterion
for adaptive sampling by leveraging variance in the measurement domain to guide
acquisition. Second, we delve into the underlying structures or assumptions
that enable mask design algorithms to perform well in practice. Our experiments
reveal that state-of-the-art deep reinforcement learning (RL) approaches, while
capable of adaptation and long-horizon planning, offer only marginal
improvements over stochastic LBCS, which is neither adaptive nor does long-term
planning. Altogether, our findings suggest that stochastic LBCS and similar
methods represent promising alternatives to deep RL. They shine in particular
by their scalability and computational efficiency and could be key in the
deployment of optimized acquisition trajectories in Cartesian MRI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04330">Surrogate Modelling for Sea Ice Concentration using Lightweight Neural Ensemble. (arXiv:2312.04330v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Borisova_J/0/1/0/all/0/1">Julia Borisova</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikitin_N/0/1/0/all/0/1">Nikolay O. Nikitin</a></p>
<p>The modeling and forecasting of sea ice conditions in the Arctic region are
important tasks for ship routing, offshore oil production, and environmental
monitoring. We propose the adaptive surrogate modeling approach named LANE-SI
(Lightweight Automated Neural Ensembling for Sea Ice) that uses ensemble of
relatively simple deep learning models with different loss functions for
forecasting of spatial distribution for sea ice concentration in the specified
water area. Experimental studies confirm the quality of a long-term forecast
based on a deep learning model fitted to the specific water area is comparable
to resource-intensive physical modeling, and for some periods of the year, it
is superior. We achieved a 20% improvement against the state-of-the-art
physics-based forecast system SEAS5 for the Kara Sea.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04339">Merging by Matching Models in Task Subspaces. (arXiv:2312.04339v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tam_D/0/1/0/all/0/1">Derek Tam</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1">Colin Raffel</a></p>
<p>Model merging aims to cheaply combine individual task-specific models into a
single multitask model. In this work, we view past merging methods as
leveraging different notions of a ''task subspace'' in which models are matched
before being merged. We connect the task subspace of a given model to its loss
landscape and formalize how this approach to model merging can be seen as
solving a linear system of equations. While past work has generally been
limited to linear systems that have a closed-form solution, we consider using
the conjugate gradient method to find a solution. We show that using the
conjugate gradient method can outperform closed-form solutions, enables merging
via linear systems that are otherwise intractable to solve, and flexibly allows
choosing from a wide variety of initializations and estimates for the ''task
subspace''. We ultimately demonstrate that our merging framework called
''Matching Models in their Task Subspace'' (MaTS) achieves state-of-the-art
results in multitask and intermediate-task model merging. We release all of the
code and checkpoints used in our work at https://github.com/r-three/mats.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04343">Causality and Explainability for Trustworthy Integrated Pest Management. (arXiv:2312.04343v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsoumas_I/0/1/0/all/0/1">Ilias Tsoumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Sitokonstantinou_V/0/1/0/all/0/1">Vasileios Sitokonstantinou</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannarakis_G/0/1/0/all/0/1">Georgios Giannarakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lampiri_E/0/1/0/all/0/1">Evagelia Lampiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Athanassiou_C/0/1/0/all/0/1">Christos Athanassiou</a>, <a href="http://arxiv.org/find/cs/1/au:+Camps_Valls_G/0/1/0/all/0/1">Gustau Camps-Valls</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontoes_C/0/1/0/all/0/1">Charalampos Kontoes</a>, <a href="http://arxiv.org/find/cs/1/au:+Athanasiadis_I/0/1/0/all/0/1">Ioannis Athanasiadis</a></p>
<p>Pesticides serve as a common tool in agricultural pest control but
significantly contribute to the climate crisis. To combat this, Integrated Pest
Management (IPM) stands as a climate-smart alternative. Despite its potential,
IPM faces low adoption rates due to farmers' skepticism about its
effectiveness. To address this challenge, we introduce an advanced data
analysis framework tailored to enhance IPM adoption. Our framework provides i)
robust pest population predictions across diverse environments with invariant
and causal learning, ii) interpretable pest presence predictions using
transparent models, iii) actionable advice through counterfactual explanations
for in-season IPM interventions, iv) field-specific treatment effect
estimations, and v) assessments of the effectiveness of our advice using causal
inference. By incorporating these features, our framework aims to alleviate
skepticism and encourage wider adoption of IPM practices among farmers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04344">Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on Prompt Engineering Strategies. (arXiv:2312.04344v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pengcheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziyan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhongying Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yanzhou Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Junjun He</a></p>
<p>OpenAI's latest large vision-language model (LVLM), GPT-4V(ision), has piqued
considerable interest for its potential in medical applications. Despite its
promise, recent studies and internal reviews highlight its underperformance in
specialized medical tasks. This paper explores the boundary of GPT-4V's
capabilities in medicine, particularly in processing complex imaging data from
endoscopies, CT scans, and MRIs etc. Leveraging open-source datasets, we
assessed its foundational competencies, identifying substantial areas for
enhancement. Our research emphasizes prompt engineering, an often-underutilized
strategy for improving AI responsiveness. Through iterative testing, we refined
the model's prompts, significantly improving its interpretative accuracy and
relevance in medical imaging. From our comprehensive evaluations, we distilled
10 effective prompt engineering techniques, each fortifying GPT-4V's medical
acumen. These methodical enhancements facilitate more reliable, precise, and
clinically valuable insights from GPT-4V, advancing its operability in critical
healthcare environments. Our findings are pivotal for those employing AI in
medicine, providing clear, actionable guidance on harnessing GPT-4V's full
diagnostic potential.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04346">Improved Efficient Two-Stage Denoising Diffusion Power System Measurement Recovery Against False Data Injection Attacks and Data Losses. (arXiv:2312.04346v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jianhua Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dongyuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Ping Wang</a></p>
<p>Measurement uncertainties, represented by cyber-attacks and data losses,
seriously degrade the quality of power system measurements. Fortunately, the
powerful generation ability of the denoising diffusion models can enable more
precise measurement generation for power system data recovery. However, the
controllable data generation and efficient computing methods of denoising
diffusion models for deterministic trajectory still need further investigation.
To this end, this paper proposes an improved two-stage denoising diffusion
model (TSDM) to identify and reconstruct the measurements with various
measurement uncertainties. The first stage of the model comprises a
classifier-guided conditional anomaly detection component, while the second
stage involves diffusion-based measurement imputation component. Moreover, the
proposed TSDM adopts precise means and optimal variances to accelerate the
diffusion generation process with subsequence sampling. Extensive numerical
case studies demonstrate that the proposed TSDM can accurately recover power
system measurements despite strong randomness under renewable energy
integration and highly nonlinear dynamics under complex cyber-physical
contingencies. Additionally, the proposed TSDM has stronger robustness compared
to existing reconstruction networks and exhibits lower computational complexity
than general denoising diffusion models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04350">CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhijing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1">Felix Leeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Gresele_L/0/1/0/all/0/1">Luigi Gresele</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamal_O/0/1/0/all/0/1">Ojasv Kamal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1">Zhiheng Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Blin_K/0/1/0/all/0/1">Kevin Blin</a>, <a href="http://arxiv.org/find/cs/1/au:+Adauto_F/0/1/0/all/0/1">Fernando Gonzalez Adauto</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleiman_Weiner_M/0/1/0/all/0/1">Max Kleiman-Weiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a></p>
<p>The ability to perform causal reasoning is widely considered a core feature
of intelligence. In this work, we investigate whether large language models
(LLMs) can coherently reason about causality. Much of the existing work in
natural language processing (NLP) focuses on evaluating commonsense causal
reasoning in LLMs, thus failing to assess whether a model can perform causal
inference in accordance with a set of well-defined formal rules. To address
this, we propose a new NLP task, causal inference in natural language, inspired
by the "causal inference engine" postulated by Judea Pearl et al. We compose a
large dataset, CLadder, with 10K samples: based on a collection of causal
graphs and queries (associational, interventional, and counterfactual), we
obtain symbolic questions and ground-truth answers, through an oracle causal
inference engine. These are then translated into natural language. We evaluate
multiple LLMs on our dataset, and we introduce and evaluate a bespoke
chain-of-thought prompting strategy, CausalCoT. We show that our task is highly
challenging for LLMs, and we conduct an in-depth analysis to gain deeper
insight into the causal reasoning abilities of LLMs. Our data is open-sourced
at https://huggingface.co/datasets/causalNLP/cladder, and our code can be found
at https://github.com/causalNLP/cladder.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04356">NeuJeans: Private Neural Network Inference with Joint Optimization of Convolution and Bootstrapping. (arXiv:2312.04356v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ju_J/0/1/0/all/0/1">Jae Hyung Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jaiyoung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jongmin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_J/0/1/0/all/0/1">Jung Ho Ahn</a></p>
<p>Fully homomorphic encryption (FHE) is a promising cryptographic primitive for
realizing private neural network inference (PI) services by allowing a client
to fully offload the inference task to a cloud server while keeping the client
data oblivious to the server. This work proposes NeuJeans, an FHE-based
solution for the PI of deep convolutional neural networks (CNNs). NeuJeans
tackles the critical problem of the enormous computational cost for the FHE
evaluation of convolutional layers (conv2d), mainly due to the high cost of
data reordering and bootstrapping. We first propose an encoding method
introducing nested structures inside encoded vectors for FHE, which enables us
to develop efficient conv2d algorithms with reduced data reordering costs.
However, the new encoding method also introduces additional computations for
conversion between encoding methods, which could negate its advantages. We
discover that fusing conv2d with bootstrapping eliminates such computations
while reducing the cost of bootstrapping. Then, we devise optimized execution
flows for various types of conv2d and apply them to end-to-end implementation
of CNNs. NeuJeans accelerates the performance of conv2d by up to 5.68 times
compared to state-of-the-art FHE-based PI work and performs the PI of a CNN at
the scale of ImageNet (ResNet18) within a mere few seconds
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04370">Investigating the Design Space of Diffusion Models for Speech Enhancement. (arXiv:2312.04370v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Gonzalez_P/0/1/0/all/0/1">Philippe Gonzalez</a>, <a href="http://arxiv.org/find/eess/1/au:+Tan_Z/0/1/0/all/0/1">Zheng-Hua Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Ostergaard_J/0/1/0/all/0/1">Jan &#xd8;stergaard</a>, <a href="http://arxiv.org/find/eess/1/au:+Jensen_J/0/1/0/all/0/1">Jesper Jensen</a>, <a href="http://arxiv.org/find/eess/1/au:+Alstrom_T/0/1/0/all/0/1">Tommy Sonne Alstr&#xf8;m</a>, <a href="http://arxiv.org/find/eess/1/au:+May_T/0/1/0/all/0/1">Tobias May</a></p>
<p>Diffusion models are a new class of generative models that have shown
outstanding performance in image generation literature. As a consequence,
studies have attempted to apply diffusion models to other tasks, such as speech
enhancement. A popular approach in adapting diffusion models to speech
enhancement consists in modelling a progressive transformation between the
clean and noisy speech signals. However, one popular diffusion model framework
previously laid in image generation literature did not account for such a
transformation towards the system input, which prevents from relating the
existing diffusion-based speech enhancement systems with the aforementioned
diffusion model framework. To address this, we extend this framework to account
for the progressive transformation between the clean and noisy speech signals.
This allows us to apply recent developments from image generation literature,
and to systematically investigate design aspects of diffusion models that
remain largely unexplored for speech enhancement, such as the neural network
preconditioning, the training loss weighting, the stochastic differential
equation (SDE), or the amount of stochasticity injected in the reverse process.
We show that the performance of previous diffusion-based speech enhancement
systems cannot be attributed to the progressive transformation between the
clean and noisy speech signals. Moreover, we show that a proper choice of
preconditioning, training loss weighting, SDE and sampler allows to outperform
a popular diffusion-based speech enhancement system in terms of perceptual
metrics while using fewer sampling steps, thus reducing the computational cost
by a factor of four.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04371">A Scalable Network-Aware Multi-Agent Reinforcement Learning Framework for Decentralized Inverter-based Voltage Control. (arXiv:2312.04371v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Xu_H/0/1/0/all/0/1">Han Xu</a>, <a href="http://arxiv.org/find/math/1/au:+Zheng_J/0/1/0/all/0/1">Jialin Zheng</a>, <a href="http://arxiv.org/find/math/1/au:+Qu_G/0/1/0/all/0/1">Guannan Qu</a></p>
<p>This paper addresses the challenges associated with decentralized voltage
control in power grids due to an increase in distributed generations (DGs).
Traditional model-based voltage control methods struggle with the rapid energy
fluctuations and uncertainties of these DGs. While multi-agent reinforcement
learning (MARL) has shown potential for decentralized secondary control,
scalability issues arise when dealing with a large number of DGs. This problem
lies in the dominant centralized training and decentralized execution (CTDE)
framework, where the critics take global observations and actions. To overcome
these challenges, we propose a scalable network-aware (SNA) framework that
leverages network structure to truncate the input to the critic's Q-function,
thereby improving scalability and reducing communication costs during training.
Further, the SNA framework is theoretically grounded with provable
approximation guarantee, and it can seamlessly integrate with multiple
multi-agent actor-critic algorithms. The proposed SNA framework is successfully
demonstrated in a system with 114 DGs, providing a promising solution for
decentralized voltage control in increasingly complex power grid systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04374">Deep Dynamics: Vehicle Dynamics Modeling with a Physics-Informed Neural Network for Autonomous Racing. (arXiv:2312.04374v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chrosniak_J/0/1/0/all/0/1">John Chrosniak</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_J/0/1/0/all/0/1">Jingyun Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Behl_M/0/1/0/all/0/1">Madhur Behl</a></p>
<p>Autonomous racing is a critical research area for autonomous driving,
presenting significant challenges in vehicle dynamics modeling, such as
balancing model precision and computational efficiency at high speeds
(&gt;280kmph), where minor errors in modeling have severe consequences. Existing
physics-based models for vehicle dynamics require elaborate testing setups and
tuning, which are hard to implement, time-intensive, and cost-prohibitive.
Conversely, purely data-driven approaches do not generalize well and cannot
adequately ensure physical constraints on predictions. This paper introduces
Deep Dynamics, a physics-informed neural network (PINN) for vehicle dynamics
modeling of an autonomous racecar. It combines physics coefficient estimation
and dynamical equations to accurately predict vehicle states at high speeds and
includes a unique Physics Guard layer to ensure internal coefficient estimates
remain within their nominal physical ranges. Open-loop and closed-loop
performance assessments, using a physics-based simulator and full-scale
autonomous Indy racecar data, highlight Deep Dynamics as a promising approach
for modeling racecar vehicle dynamics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04386">Model-Based Epistemic Variance of Values for Risk-Aware Policy Optimization. (arXiv:2312.04386v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luis_C/0/1/0/all/0/1">Carlos E. Luis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottero_A/0/1/0/all/0/1">Alessandro G. Bottero</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinogradska_J/0/1/0/all/0/1">Julia Vinogradska</a>, <a href="http://arxiv.org/find/cs/1/au:+Berkenkamp_F/0/1/0/all/0/1">Felix Berkenkamp</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a></p>
<p>We consider the problem of quantifying uncertainty over expected cumulative
rewards in model-based reinforcement learning. In particular, we focus on
characterizing the variance over values induced by a distribution over MDPs.
Previous work upper bounds the posterior variance over values by solving a
so-called uncertainty Bellman equation (UBE), but the over-approximation may
result in inefficient exploration. We propose a new UBE whose solution
converges to the true posterior variance over values and leads to lower regret
in tabular exploration problems. We identify challenges to apply the UBE theory
beyond tabular problems and propose a suitable approximation. Based on this
approximation, we introduce a general-purpose policy optimization algorithm,
Q-Uncertainty Soft Actor-Critic (QU-SAC), that can be applied for either
risk-seeking or risk-averse policy optimization with minimal changes.
Experiments in both online and offline RL demonstrate improved performance
compared to other uncertainty estimation methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04398">Intelligent Anomaly Detection for Lane Rendering Using Transformer with Self-Supervised Pre-Training and Customized Fine-Tuning. (arXiv:2312.04398v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yongqi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xingmin Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Wei Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Arem_B/0/1/0/all/0/1">Bart van Arem</a>, <a href="http://arxiv.org/find/cs/1/au:+Farah_H/0/1/0/all/0/1">Haneen Farah</a></p>
<p>The burgeoning navigation services using digital maps provide great
convenience to drivers. Nevertheless, the presence of anomalies in lane
rendering map images occasionally introduces potential hazards, as such
anomalies can be misleading to human drivers and consequently contribute to
unsafe driving conditions. In response to this concern and to accurately and
effectively detect the anomalies, this paper transforms lane rendering image
anomaly detection into a classification problem and proposes a four-phase
pipeline consisting of data pre-processing, self-supervised pre-training with
the masked image modeling (MiM) method, customized fine-tuning using
cross-entropy based loss with label smoothing, and post-processing to tackle it
leveraging state-of-the-art deep learning techniques, especially those
involving Transformer models. Various experiments verify the effectiveness of
the proposed pipeline. Results indicate that the proposed pipeline exhibits
superior performance in lane rendering image anomaly detection, and notably,
the self-supervised pre-training with MiM can greatly enhance the detection
accuracy while significantly reducing the total training time. For instance,
employing the Swin Transformer with Uniform Masking as self-supervised
pretraining (Swin-Trans-UM) yielded a heightened accuracy at 94.77% and an
improved Area Under The Curve (AUC) score of 0.9743 compared with the pure Swin
Transformer without pre-training (Swin-Trans) with an accuracy of 94.01% and an
AUC of 0.9498. The fine-tuning epochs were dramatically reduced to 41 from the
original 280. In conclusion, the proposed pipeline, with its incorporation of
self-supervised pre-training using MiM and other advanced deep learning
techniques, emerges as a robust solution for enhancing the accuracy and
efficiency of lane rendering image anomaly detection in digital navigation
systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04402">Semi-Supervised Active Learning for Semantic Segmentation in Unknown Environments Using Informative Path Planning. (arXiv:2312.04402v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ruckin_J/0/1/0/all/0/1">Julius R&#xfc;ckin</a>, <a href="http://arxiv.org/find/cs/1/au:+Magistri_F/0/1/0/all/0/1">Federico Magistri</a>, <a href="http://arxiv.org/find/cs/1/au:+Stachniss_C/0/1/0/all/0/1">Cyrill Stachniss</a>, <a href="http://arxiv.org/find/cs/1/au:+Popovic_M/0/1/0/all/0/1">Marija Popovi&#x107;</a></p>
<p>Semantic segmentation enables robots to perceive and reason about their
environments beyond geometry. Most of such systems build upon deep learning
approaches. As autonomous robots are commonly deployed in initially unknown
environments, pre-training on static datasets cannot always capture the variety
of domains and limits the robot's perception performance during missions.
Recently, self-supervised and fully supervised active learning methods emerged
to improve a robot's vision. These approaches rely on large in-domain
pre-training datasets or require substantial human labelling effort. We propose
a planning method for semi-supervised active learning of semantic segmentation
that substantially reduces human labelling requirements compared to fully
supervised approaches. We leverage an adaptive map-based planner guided towards
the frontiers of unexplored space with high model uncertainty collecting
training data for human labelling. A key aspect of our approach is to combine
the sparse high-quality human labels with pseudo labels automatically extracted
from highly certain environment map areas. Experimental results show that our
method reaches segmentation performance close to fully supervised approaches
with drastically reduced human labelling effort while outperforming
self-supervised approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04404">On the Impact of Multi-dimensional Local Differential Privacy on Fairness. (arXiv:2312.04404v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Makhlouf_k/0/1/0/all/0/1">karima Makhlouf</a>, <a href="http://arxiv.org/find/cs/1/au:+Arcolezi_H/0/1/0/all/0/1">Heber H. Arcolezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhioua_S/0/1/0/all/0/1">Sami Zhioua</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahim_G/0/1/0/all/0/1">Ghassen Ben Brahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1">Catuscia Palamidessi</a></p>
<p>Automated decision systems are increasingly used to make consequential
decisions in people's lives. Due to the sensitivity of the manipulated data as
well as the resulting decisions, several ethical concerns need to be addressed
for the appropriate use of such technologies, in particular, fairness and
privacy. Unlike previous work, which focused on centralized differential
privacy (DP) or local DP (LDP) for a single sensitive attribute, in this paper,
we examine the impact of LDP in the presence of several sensitive attributes
(i.e., multi-dimensional data) on fairness. Detailed empirical analysis on
synthetic and benchmark datasets revealed very relevant observations. In
particular, (1) multi-dimensional LDP is an efficient approach to reduce
disparity, (2) the multi-dimensional approach of LDP (independent vs. combined)
matters only at low privacy guarantees, and (3) the outcome Y distribution has
an important effect on which group is more sensitive to the obfuscation. Last,
we summarize our findings in the form of recommendations to guide practitioners
in adopting effective privacy-preserving practices while maintaining fairness
and utility in ML applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04416">Monitoring Sustainable Global Development Along Shared Socioeconomic Pathways. (arXiv:2312.04416v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1">Michelle W.L. Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1">Jeffrey N. Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Small_E/0/1/0/all/0/1">Edward A. Small</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayoral_E/0/1/0/all/0/1">Elena Fillola Mayoral</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1">Ra&#xfa;l Santos-Rodr&#xed;guez</a></p>
<p>Sustainable global development is one of the most prevalent challenges facing
the world today, hinging on the equilibrium between socioeconomic growth and
environmental sustainability. We propose approaches to monitor and quantify
sustainable development along the Shared Socioeconomic Pathways (SSPs),
including mathematically derived scoring algorithms, and machine learning
methods. These integrate socioeconomic and environmental datasets, to produce
an interpretable metric for SSP alignment. An initial study demonstrates
promising results, laying the groundwork for the application of different
methods to the monitoring of sustainable global development.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04432">FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning. (arXiv:2312.04432v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fereidooni_H/0/1/0/all/0/1">Hossein Fereidooni</a>, <a href="http://arxiv.org/find/cs/1/au:+Pegoraro_A/0/1/0/all/0/1">Alessandro Pegoraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieger_P/0/1/0/all/0/1">Phillip Rieger</a>, <a href="http://arxiv.org/find/cs/1/au:+Dmitrienko_A/0/1/0/all/0/1">Alexandra Dmitrienko</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadeghi_A/0/1/0/all/0/1">Ahmad-Reza Sadeghi</a></p>
<p>Federated learning (FL) is a collaborative learning paradigm allowing
multiple clients to jointly train a model without sharing their training data.
However, FL is susceptible to poisoning attacks, in which the adversary injects
manipulated model updates into the federated model aggregation process to
corrupt or destroy predictions (untargeted poisoning) or implant hidden
functionalities (targeted poisoning or backdoors). Existing defenses against
poisoning attacks in FL have several limitations, such as relying on specific
assumptions about attack types and strategies or data distributions or not
sufficiently robust against advanced injection techniques and strategies and
simultaneously maintaining the utility of the aggregated model. To address the
deficiencies of existing defenses, we take a generic and completely different
approach to detect poisoning (targeted and untargeted) attacks. We present
FreqFed, a novel aggregation mechanism that transforms the model updates (i.e.,
weights) into the frequency domain, where we can identify the core frequency
components that inherit sufficient information about weights. This allows us to
effectively filter out malicious updates during local training on the clients,
regardless of attack types, strategies, and clients' data distributions. We
extensively evaluate the efficiency and effectiveness of FreqFed in different
application domains, including image classification, word prediction, IoT
intrusion detection, and speech recognition. We demonstrate that FreqFed can
mitigate poisoning attacks effectively with a negligible impact on the utility
of the aggregated model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04447">Privacy-preserving quantum federated learning via gradient hiding. (arXiv:2312.04447v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Li_C/0/1/0/all/0/1">Changhao Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kumar_N/0/1/0/all/0/1">Niraj Kumar</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Song_Z/0/1/0/all/0/1">Zhixin Song</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chakrabarti_S/0/1/0/all/0/1">Shouvanik Chakrabarti</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pistoia_M/0/1/0/all/0/1">Marco Pistoia</a></p>
<p>Distributed quantum computing, particularly distributed quantum machine
learning, has gained substantial prominence for its capacity to harness the
collective power of distributed quantum resources, transcending the limitations
of individual quantum nodes. Meanwhile, the critical concern of privacy within
distributed computing protocols remains a significant challenge, particularly
in standard classical federated learning (FL) scenarios where data of
participating clients is susceptible to leakage via gradient inversion attacks
by the server. This paper presents innovative quantum protocols with quantum
communication designed to address the FL problem, strengthen privacy measures,
and optimize communication efficiency. In contrast to previous works that
leverage expressive variational quantum circuits or differential privacy
techniques, we consider gradient information concealment using quantum states
and propose two distinct FL protocols, one based on private inner-product
estimation and the other on incremental learning. These protocols offer
substantial advancements in privacy preservation with low communication
resources, forging a path toward efficient quantum communication-assisted FL
protocols and contributing to the development of secure distributed quantum
machine learning, thus addressing critical privacy concerns in the quantum
computing era.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2104.12928">If your data distribution shifts, use self-learning. (arXiv:2104.12928v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rusak_E/0/1/0/all/0/1">Evgenia Rusak</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1">Steffen Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Pachitariu_G/0/1/0/all/0/1">George Pachitariu</a>, <a href="http://arxiv.org/find/cs/1/au:+Eck_L/0/1/0/all/0/1">Luisa Eck</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehler_P/0/1/0/all/0/1">Peter Gehler</a>, <a href="http://arxiv.org/find/cs/1/au:+Bringmann_O/0/1/0/all/0/1">Oliver Bringmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>, <a href="http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1">Matthias Bethge</a></p>
<p>We demonstrate that self-learning techniques like entropy minimization and
pseudo-labeling are simple and effective at improving performance of a deployed
computer vision model under systematic domain shifts. We conduct a wide range
of large-scale experiments and show consistent improvements irrespective of the
model architecture, the pre-training technique or the type of distribution
shift. At the same time, self-learning is simple to use in practice because it
does not require knowledge or access to the original training data or scheme,
is robust to hyperparameter choices, is straight-forward to implement and
requires only a few adaptation epochs. This makes self-learning techniques
highly attractive for any practitioner who applies machine learning algorithms
in the real world. We present state-of-the-art adaptation results on CIFAR10-C
(8.5% error), ImageNet-C (22.0% mCE), ImageNet-R (17.4% error) and ImageNet-A
(14.8% error), theoretically study the dynamics of self-supervised adaptation
methods and propose a new classification dataset (ImageNet-D) which is
challenging even with adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.00198">Gradient play in stochastic games: stationary points, convergence, and sample complexity. (arXiv:2106.00198v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Runyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaolin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Na Li</a></p>
<p>We study the performance of the gradient play algorithm for stochastic games
(SGs), where each agent tries to maximize its own total discounted reward by
making decisions independently based on current state information which is
shared between agents. Policies are directly parameterized by the probability
of choosing a certain action at a given state. We show that Nash equilibria
(NEs) and first-order stationary policies are equivalent in this setting, and
give a local convergence rate around strict NEs. Further, for a subclass of SGs
called Markov potential games (which includes the setting with identical
rewards as an important special case), we design a sample-based reinforcement
learning algorithm and give a non-asymptotic global convergence rate analysis
for both exact gradient play and our sample-based learning algorithm. Our
result shows that the number of iterations to reach an $\epsilon$-NE scales
linearly, instead of exponentially, with the number of agents. Local geometry
and local stability are also considered, where we prove that strict NEs are
local maxima of the total potential function and fully-mixed NEs are saddle
points.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.09517">Deep Learning for Hate Speech Detection: A Comparative Study. (arXiv:2202.09517v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Singh Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1">Hezhe Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1">Guansong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1">Anton van den Hengel</a></p>
<p>Automated hate speech detection is an important tool in combating the spread
of hate speech, particularly in social media. Numerous methods have been
developed for the task, including a recent proliferation of deep-learning based
approaches. A variety of datasets have also been developed, exemplifying
various manifestations of the hate-speech detection problem. We present here a
large-scale empirical comparison of deep and shallow hate-speech detection
methods, mediated through the three most commonly used datasets. Our goal is to
illuminate progress in the area, and identify strengths and weaknesses in the
current state-of-the-art. We particularly focus our analysis on measures of
practical performance, including detection accuracy, computational efficiency,
capability in using pre-trained models, and domain generalization. In doing so
we aim to provide guidance as to the use of hate-speech detection in practice,
quantify the state-of-the-art, and identify future research directions. Code
and dataset are available at
https://github.com/jmjmalik22/Hate-Speech-Detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.04979">Convolutional layers are equivariant to discrete shifts but not continuous translations. (arXiv:2206.04979v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McGreivy_N/0/1/0/all/0/1">Nick McGreivy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakim_A/0/1/0/all/0/1">Ammar Hakim</a></p>
<p>The purpose of this short and simple note is to clarify a common
misconception about convolutional neural networks (CNNs). CNNs are made up of
convolutional layers which are shift equivariant due to weight sharing.
However, convolutional layers are not translation equivariant, even when
boundary effects are ignored and when pooling and subsampling are absent. This
is because shift equivariance is a discrete symmetry while translation
equivariance is a continuous symmetry. This fact is well known among
researchers in equivariant machine learning, but is usually overlooked among
non-experts. To minimize confusion, we suggest using the term `shift
equivariance' to refer to discrete shifts in pixels and `translation
equivariance' to refer to continuous translations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.08089">Constrained Few-Shot Learning: Human-Like Low Sample Complexity Learning and Non-Episodic Text Classification. (arXiv:2208.08089v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mar_J/0/1/0/all/0/1">Jaron Mar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiamou Liu</a></p>
<p>Few-shot learning (FSL) is an emergent paradigm of learning that attempts to
learn to reason with low sample complexity to mimic the way humans learn,
generalise and extrapolate from only a few seen examples. While FSL attempts to
mimic these human characteristics, fundamentally, the task of FSL as
conventionally formulated using meta-learning with episodic-based training does
not in actuality align with how humans acquire and reason with knowledge. FSL
with episodic training, while only requires $K$ instances of each test class,
still requires a large number of labelled training instances from disjoint
classes. In this paper, we introduce the novel task of constrained few-shot
learning (CFSL), a special case of FSL where $M$, the number of instances of
each training class is constrained such that $M \leq K$ thus applying a similar
restriction during FSL training and test. We propose a method for CFSL
leveraging Cat2Vec using a novel categorical contrastive loss inspired by
cognitive theories such as fuzzy trace theory and prototype theory.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.09943">Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition. (arXiv:2210.09943v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dooley_S/0/1/0/all/0/1">Samuel Dooley</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1">Rhea Sanjay Sukthanker</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John P. Dickerson</a>, <a href="http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1">Colin White</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a></p>
<p>Face recognition systems are widely deployed in safety-critical applications,
including law enforcement, yet they exhibit bias across a range of
socio-demographic dimensions, such as gender and race. Conventional wisdom
dictates that model biases arise from biased training data. As a consequence,
previous works on bias mitigation largely focused on pre-processing the
training data, adding penalties to prevent bias from effecting the model during
training, or post-processing predictions to debias them, yet these approaches
have shown limited success on hard problems such as face recognition. In our
work, we discover that biases are actually inherent to neural network
architectures themselves. Following this reframing, we conduct the first neural
architecture search for fairness, jointly with a search for hyperparameters.
Our search outputs a suite of models which Pareto-dominate all other
high-performance architectures and existing bias mitigation methods in terms of
accuracy and fairness, often by large margins, on the two most widely used
datasets for face identification, CelebA and VGGFace2. Furthermore, these
models generalize to other datasets and sensitive attributes. We release our
code, models and raw data files at https://github.com/dooleys/FR-NAS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.11407">Similarity of Neural Architectures using Adversarial Attack Transferability. (arXiv:2210.11407v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jaehui Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dongyoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Heo_B/0/1/0/all/0/1">Byeongho Heo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Song Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Sanghyuk Chun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jong-Seok Lee</a></p>
<p>In recent years, many deep neural architectures have been developed for image
classification. Whether they are similar or dissimilar and what factors
contribute to their (dis)similarities remains curious. To address this
question, we aim to design a quantitative and scalable similarity measure
between neural architectures. We propose Similarity by Attack Transferability
(SAT) from the observation that adversarial attack transferability contains
information related to input gradients and decision boundaries widely used to
understand model behaviors. We conduct a large-scale analysis on 69
state-of-the-art ImageNet classifiers using our proposed similarity function to
answer the question. Moreover, we observe neural architecture-related phenomena
using model similarity that model diversity can lead to better performance on
model ensembles and knowledge distillation under specific conditions. Our
results provide insights into why developing diverse neural architectures with
distinct components is necessary.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.12583">Active Learning of Discrete-Time Dynamics for Uncertainty-Aware Model Predictive Control. (arXiv:2210.12583v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saviolo_A/0/1/0/all/0/1">Alessandro Saviolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Frey_J/0/1/0/all/0/1">Jonathan Frey</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathod_A/0/1/0/all/0/1">Abhishek Rathod</a>, <a href="http://arxiv.org/find/cs/1/au:+Diehl_M/0/1/0/all/0/1">Moritz Diehl</a>, <a href="http://arxiv.org/find/cs/1/au:+Loianno_G/0/1/0/all/0/1">Giuseppe Loianno</a></p>
<p>Model-based control requires an accurate model of the system dynamics for
precisely and safely controlling the robot in complex and dynamic environments.
Moreover, in the presence of variations in the operating conditions, the model
should be continuously refined to compensate for dynamics changes. In this
paper, we present a self-supervised learning approach that actively models the
dynamics of nonlinear robotic systems. We combine offline learning from past
experience and online learning from current robot interaction with the unknown
environment. These two ingredients enable a highly sample-efficient and
adaptive learning process, capable of accurately inferring model dynamics in
real-time even in operating regimes that greatly differ from the training
distribution. Moreover, we design an uncertainty-aware model predictive
controller that is heuristically conditioned to the aleatoric (data)
uncertainty of the learned dynamics. This controller actively chooses the
optimal control actions that (i) optimize the control performance and (ii)
improve the efficiency of online learning sample collection. We demonstrate the
effectiveness of our method through a series of challenging real-world
experiments using a quadrotor system. Our approach showcases high resilience
and generalization capabilities by consistently adapting to unseen flight
conditions, while it significantly outperforms classical and adaptive control
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08586">Bandit Algorithms for Prophet Inequality and Pandora&#x27;s Box. (arXiv:2211.08586v2 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gatmiry_K/0/1/0/all/0/1">Khashayar Gatmiry</a>, <a href="http://arxiv.org/find/cs/1/au:+Kesselheim_T/0/1/0/all/0/1">Thomas Kesselheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifan Wang</a></p>
<p>The Prophet Inequality and Pandora's Box problems are fundamental stochastic
problem with applications in Mechanism Design, Online Algorithms, Stochastic
Optimization, Optimal Stopping, and Operations Research. A usual assumption in
these works is that the probability distributions of the $n$ underlying random
variables are given as input to the algorithm. Since in practice these
distributions need to be learned, we initiate the study of such stochastic
problems in the Multi-Armed Bandits model.
</p>
<p>In the Multi-Armed Bandits model we interact with $n$ unknown distributions
over $T$ rounds: in round $t$ we play a policy $x^{(t)}$ and receive a partial
(bandit) feedback on the performance of $x^{(t)}$. The goal is to minimize the
regret, which is the difference over $T$ rounds in the total value of the
optimal algorithm that knows the distributions vs. the total value of our
algorithm that learns the distributions from the partial feedback. Our main
results give near-optimal $\tilde{O}(\mathsf{poly}(n)\sqrt{T})$ total regret
algorithms for both Prophet Inequality and Pandora's Box.
</p>
<p>Our proofs proceed by maintaining confidence intervals on the unknown indices
of the optimal policy. The exploration-exploitation tradeoff prevents us from
directly refining these confidence intervals, so the main technique is to
design a regret upper bound that is learnable while playing low-regret Bandit
policies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08705">Resource Allocation of Federated Learning for the Metaverse with Mobile Augmented Reality. (arXiv:2211.08705v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xinyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a></p>
<p>The Metaverse has received much attention recently. Metaverse applications
via mobile augmented reality (MAR) require rapid and accurate object detection
to mix digital data with the real world. Federated learning (FL) is an
intriguing distributed machine learning approach due to its privacy-preserving
characteristics. Due to privacy concerns and the limited computation resources
on mobile devices, we incorporate FL into MAR systems of the Metaverse to train
a model cooperatively. Besides, to balance the trade-off between energy,
execution latency and model accuracy, thereby accommodating different demands
and application scenarios, we formulate an optimization problem to minimize a
weighted combination of total energy consumption, completion time and model
accuracy. Through decomposing the non-convex optimization problem into two
subproblems, we devise a resource allocation algorithm to determine the
bandwidth allocation, transmission power, CPU frequency and video frame
resolution for each participating device. We further present the convergence
analysis and computational complexity of the proposed algorithm. Numerical
results show that our proposed algorithm has better performance (in terms of
energy consumption, completion time and model accuracy) under different weight
parameters compared to existing benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.10558">Internal Representations of Vision Models Through the Lens of Frames on Data Manifolds. (arXiv:2211.10558v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1">Henry Kvinge</a>, <a href="http://arxiv.org/find/cs/1/au:+Jorgenson_G/0/1/0/all/0/1">Grayson Jorgenson</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1">Davis Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1">Charles Godfrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Emerson_T/0/1/0/all/0/1">Tegan Emerson</a></p>
<p>While the last five years have seen considerable progress in understanding
the internal representations of deep learning models, many questions remain.
This is especially true when trying to understand the impact of model design
choices, such as model architecture or training algorithm, on hidden
representation geometry and dynamics. In this work we present a new approach to
studying such representations inspired by the idea of a frame on the tangent
bundle of a manifold. Our construction, which we call a neural frame, is formed
by assembling a set of vectors representing specific types of perturbations of
a data point, for example infinitesimal augmentations, noise perturbations, or
perturbations produced by a generative model, and studying how these change as
they pass through a network. Using neural frames, we make observations about
the way that models process, layer-by-layer, specific modes of variation within
a small neighborhood of a datapoint. Our results provide new perspectives on a
number of phenomena, such as the manner in which training with augmentation
produces model invariance or the proposed trade-off between adversarial
training and model generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.14578">MAUVE Scores for Generative Models: Theory and Practice. (arXiv:2212.14578v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1">Krishna Pillutla</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1">John Thickstun</a>, <a href="http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1">Sean Welleck</a>, <a href="http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1">Swabha Swayamdipta</a>, <a href="http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1">Rowan Zellers</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Sewoong Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Harchaoui_Z/0/1/0/all/0/1">Zaid Harchaoui</a></p>
<p>Generative artificial intelligence has made significant strides, producing
text indistinguishable from human prose and remarkably photorealistic images.
Automatically measuring how close the generated data distribution is to the
target distribution is central to diagnosing existing models and developing
better ones. We present MAUVE, a family of comparison measures between pairs of
distributions such as those encountered in the generative modeling of text or
images. These scores are statistical summaries of divergence frontiers
capturing two types of errors in generative modeling. We explore three
approaches to statistically estimate these scores: vector quantization,
non-parametric estimation, and classifier-based estimation. We provide
statistical bounds for the vector quantization approach.
</p>
<p>Empirically, we find that the proposed scores paired with a range of
$f$-divergences and statistical estimation methods can quantify the gaps
between the distributions of human-written text and those of modern neural
language models by correlating with human judgments and identifying known
properties of the generated texts. We demonstrate in the vision domain that
MAUVE can identify known properties of generated images on par with or better
than existing metrics. In conclusion, we present practical recommendations for
using MAUVE effectively with language and image modalities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.00752">Point Cloud-based Proactive Link Quality Prediction for Millimeter-wave Communications. (arXiv:2301.00752v4 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ohta_S/0/1/0/all/0/1">Shoki Ohta</a>, <a href="http://arxiv.org/find/cs/1/au:+Nishio_T/0/1/0/all/0/1">Takayuki Nishio</a>, <a href="http://arxiv.org/find/cs/1/au:+Kudo_R/0/1/0/all/0/1">Riichi Kudo</a>, <a href="http://arxiv.org/find/cs/1/au:+Takahashi_K/0/1/0/all/0/1">Kahoko Takahashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagata_H/0/1/0/all/0/1">Hisashi Nagata</a></p>
<p>This study demonstrates the feasibility of point cloud-based proactive link
quality prediction for millimeter-wave (mmWave) communications. Previous
studies have proposed machine learning-based methods to predict received signal
strength for future time periods using time series of depth images to mitigate
the line-of-sight (LOS) path blockage by pedestrians in mmWave communication.
However, these image-based methods have limited applicability due to privacy
concerns as camera images may contain sensitive information. This study
proposes a point cloud-based method for mmWave link quality prediction and
demonstrates its feasibility through experiments. Point clouds represent
three-dimensional (3D) spaces as a set of points and are sparser and less
likely to contain sensitive information than camera images. Additionally, point
clouds provide 3D position and motion information, which is necessary for
understanding the radio propagation environment involving pedestrians. This
study designs the mmWave link quality prediction method and conducts realistic
indoor experiments, where the link quality fluctuates significantly due to
human blockage, using commercially available IEEE 802.11ad-based 60 GHz
wireless LAN devices and Kinect v2 RGB-D camera and Velodyne VLP-16 light
detection and ranging (LiDAR) for point cloud acquisition. The experimental
results showed that our proposed method can predict future large attenuation of
mmWave received signal strength and throughput induced by the LOS path blockage
by pedestrians with comparable or superior accuracy to image-based prediction
methods. Hence, our point cloud-based method can serve as a viable alternative
to image-based methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.05601">Sem@$K$: Is my knowledge graph embedding model semantic-aware?. (arXiv:2301.05601v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hubert_N/0/1/0/all/0/1">Nicolas Hubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1">Pierre Monnin</a>, <a href="http://arxiv.org/find/cs/1/au:+Brun_A/0/1/0/all/0/1">Armelle Brun</a>, <a href="http://arxiv.org/find/cs/1/au:+Monticolo_D/0/1/0/all/0/1">Davy Monticolo</a></p>
<p>Using knowledge graph embedding models (KGEMs) is a popular approach for
predicting links in knowledge graphs (KGs). Traditionally, the performance of
KGEMs for link prediction is assessed using rank-based metrics, which evaluate
their ability to give high scores to ground-truth entities. However, the
literature claims that the KGEM evaluation procedure would benefit from adding
supplementary dimensions to assess. That is why, in this paper, we extend our
previously introduced metric Sem@K that measures the capability of models to
predict valid entities w.r.t. domain and range constraints. In particular, we
consider a broad range of KGs and take their respective characteristics into
account to propose different versions of Sem@K. We also perform an extensive
study to qualify the abilities of KGEMs as measured by our metric. Our
experiments show that Sem@K provides a new perspective on KGEM quality. Its
joint analysis with rank-based metrics offers different conclusions on the
predictive power of models. Regarding Sem@K, some KGEMs are inherently better
than others, but this semantic superiority is not indicative of their
performance w.r.t. rank-based metrics. In this work, we generalize conclusions
about the relative performance of KGEMs w.r.t. rank-based and semantic-oriented
metrics at the level of families of models. The joint analysis of the
aforementioned metrics gives more insight into the peculiarities of each model.
This work paves the way for a more comprehensive evaluation of KGEM adequacy
for specific downstream tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.09820">A Stability Analysis of Fine-Tuning a Pre-Trained Model. (arXiv:2301.09820v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zihao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+So_A/0/1/0/all/0/1">Anthony Man-Cho So</a>, <a href="http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1">Nigel Collier</a></p>
<p>Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,
etc.) has proven to be one of the most promising paradigms in recent NLP
research. However, numerous recent works indicate that fine-tuning suffers from
the instability problem, i.e., tuning the same model under the same setting
results in significantly different performance. Many recent works have proposed
different methods to solve this problem, but there is no theoretical
understanding of why and how these methods work. In this paper, we propose a
novel theoretical stability analysis of fine-tuning that focuses on two
commonly used settings, namely, full fine-tuning and head tuning. We define the
stability under each setting and prove the corresponding stability bounds. The
theoretical bounds explain why and how several existing methods can stabilize
the fine-tuning procedure. In addition to being able to explain most of the
observed empirical discoveries, our proposed theoretical analysis framework can
also help in the design of effective and provable methods. Based on our theory,
we propose three novel strategies to stabilize the fine-tuning procedure,
namely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self
Unsupervised Re-Training (SURT). We extensively evaluate our proposed
approaches on 11 widely used real-world benchmark datasets, as well as hundreds
of synthetic classification datasets. The experiment results show that our
proposed methods significantly stabilize the fine-tuning procedure and also
corroborate our theoretical analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.03684">Temporal Robustness against Data Poisoning. (arXiv:2302.03684v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenxiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a></p>
<p>Data poisoning considers cases when an adversary manipulates the behavior of
machine learning algorithms through malicious training data. Existing threat
models of data poisoning center around a single metric, the number of poisoned
samples. In consequence, if attackers can poison more samples than expected
with affordable overhead, as in many practical scenarios, they may be able to
render existing defenses ineffective in a short time. To address this issue, we
leverage timestamps denoting the birth dates of data, which are often available
but neglected in the past. Benefiting from these timestamps, we propose a
temporal threat model of data poisoning with two novel metrics, earliness and
duration, which respectively measure how long an attack started in advance and
how long an attack lasted. Using these metrics, we define the notions of
temporal robustness against data poisoning, providing a meaningful sense of
protection even with unbounded amounts of poisoned samples when the attacks are
temporally bounded. We present a benchmark with an evaluation protocol
simulating continuous data collection and periodic deployments of updated
models, thus enabling empirical evaluation of temporal robustness. Lastly, we
develop and also empirically verify a baseline defense, namely temporal
aggregation, offering provable temporal robustness and highlighting the
potential of our temporal threat model for data poisoning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.10722">Characterizing the Optimal 0-1 Loss for Multi-class Classification with a Test-time Attacker. (arXiv:2302.10722v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Sihui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenxin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhagoji_A/0/1/0/all/0/1">Arjun Nitin Bhagoji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cullina_D/0/1/0/all/0/1">Daniel Cullina</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Ben Y. Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haitao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1">Prateek Mittal</a></p>
<p>Finding classifiers robust to adversarial examples is critical for their safe
deployment. Determining the robustness of the best possible classifier under a
given threat model for a given data distribution and comparing it to that
achieved by state-of-the-art training methods is thus an important diagnostic
tool. In this paper, we find achievable information-theoretic lower bounds on
loss in the presence of a test-time attacker for multi-class classifiers on any
discrete dataset. We provide a general framework for finding the optimal 0-1
loss that revolves around the construction of a conflict hypergraph from the
data and adversarial constraints. We further define other variants of the
attacker-classifier game that determine the range of the optimal loss more
efficiently than the full-fledged hypergraph construction. Our evaluation
shows, for the first time, an analysis of the gap to optimal robustness for
classifiers in the multi-class setting on benchmark datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.10903">Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks. (arXiv:2302.10903v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yanwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yongguo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Junyu Dong</a></p>
<p>Trajectory-User Linking (TUL) is crucial for human mobility modeling by
linking diferent trajectories to users with the exploration of complex mobility
patterns. Existing works mainly rely on the recurrent neural framework to
encode the temporal dependencies in trajectories, have fall short in capturing
spatial-temporal global context for TUL prediction. To ill this gap, this work
presents a new hierarchical spatio-temporal attention neural network, called
AttnTUL, to jointly encode the local trajectory transitional patterns and
global spatial dependencies for TUL. Speciically, our irst model component is
built over the graph neural architecture to preserve the local and global
context and enhance the representation paradigm of geographical regions and
user trajectories. Additionally, a hierarchically structured attention network
is designed to simultaneously encode the intra-trajectory and inter-trajectory
dependencies, with the integration of the temporal attention mechanism and
global elastic attentional encoder. Extensive experiments demonstrate the
superiority of our AttnTUL method as compared to state-of-the-art baselines on
various trajectory datasets. The source code of our model is available at
https://github.com/Onedean/AttnTUL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.11835">Reinforcement Learning for Combining Search Methods in the Calibration of Economic ABMs. (arXiv:2302.11835v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Glielmo_A/0/1/0/all/0/1">Aldo Glielmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Favorito_M/0/1/0/all/0/1">Marco Favorito</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanda_D/0/1/0/all/0/1">Debmallya Chanda</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatti_D/0/1/0/all/0/1">Domenico Delli Gatti</a></p>
<p>Calibrating agent-based models (ABMs) in economics and finance typically
involves a derivative-free search in a very large parameter space. In this
work, we benchmark a number of search methods in the calibration of a
well-known macroeconomic ABM on real data, and further assess the performance
of "mixed strategies" made by combining different methods. We find that methods
based on random-forest surrogates are particularly efficient, and that
combining search methods generally increases performance since the biases of
any single method are mitigated. Moving from these observations, we propose a
reinforcement learning (RL) scheme to automatically select and combine search
methods on-the-fly during a calibration run. The RL agent keeps exploiting a
specific method only as long as this keeps performing well, but explores new
strategies when the specific method reaches a performance plateau. The
resulting RL search scheme outperforms any other method or method combination
tested, and does not rely on any prior information or trial and error
procedure.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.13711">Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters. (arXiv:2302.13711v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arts_M/0/1/0/all/0/1">Marloes Arts</a>, <a href="http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1">Jes Frellsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Boomsma_W/0/1/0/all/0/1">Wouter Boomsma</a></p>
<p>After the recent ground-breaking advances in protein structure prediction,
one of the remaining challenges in protein machine learning is to reliably
predict distributions of structural states. Parametric models of fluctuations
are difficult to fit due to complex covariance structures between degrees of
freedom in the protein chain, often causing models to either violate local or
global structural constraints. In this paper, we present a new strategy for
modelling protein densities in internal coordinates, which uses constraints in
3D space to induce covariance structure between the internal degrees of
freedom. We illustrate the potential of the procedure by constructing a
variational autoencoder with full covariance output induced by the constraints
implied by the conditional mean in 3D, and demonstrate that our approach makes
it possible to scale density models of internal coordinates to full protein
backbones in two settings: 1) a unimodal setting for proteins exhibiting small
fluctuations and limited amounts of available data, and 2) a multimodal setting
for larger conformational changes in a high data regime.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16343">Facial recognition technology and human raters can predict political orientation from images of expressionless faces even when controlling for demographics and self-presentation. (arXiv:2303.16343v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kosinski_M/0/1/0/all/0/1">Michal Kosinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Khambatta_P/0/1/0/all/0/1">Poruz Khambatta</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yilun Wang</a></p>
<p>Carefully standardized facial images of 591 participants were taken in the
laboratory, while controlling for self-presentation, facial expression, head
orientation, and image properties. They were presented to human raters and a
facial recognition algorithm: both humans (r=.21) and the algorithm (r=.22)
could predict participants' scores on a political orientation scale (Cronbach's
alpha=.94) decorrelated with age, gender, and ethnicity. These effects are on
par with how well job interviews predict job success, or alcohol drives
aggressiveness. Algorithm's predictive accuracy was even higher (r=.31) when it
leveraged information on participants' age, gender, and ethnicity. Moreover,
the associations between facial appearance and political orientation seem to
generalize beyond our sample: The predictive model derived from standardized
images (while controlling for age, gender, and ethnicity) could predict
political orientation (r=.13) from naturalistic images of 3,401 politicians
from the U.S., UK, and Canada. The analysis of facial features associated with
political orientation revealed that conservatives tended to have larger lower
faces. The predictability of political orientation from standardized images has
critical implications for privacy, the regulation of facial recognition
technology, and understanding the origins and consequences of political
orientation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.18187">Contrastive-Signal-Dependent Plasticity: Forward-Forward Learning of Spiking Neural Systems. (arXiv:2303.18187v2 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1">Alexander Ororbia</a></p>
<p>We develop a neuro-mimetic architecture, composed of spiking neuronal units,
where individual layers of neurons operate in parallel and adapt their synaptic
efficacies without the use of feedback pathways. Specifically, we propose an
event-based generalization of forward-forward learning, which we call
contrastive-signal-dependent plasticity (CSDP), for a spiking neural system
that iteratively processes sensory input over a stimulus window. The dynamics
that underwrite this recurrent circuit entail computing the membrane potential
of each processing element, in each layer, as a function of local bottom-up,
top-down, and lateral signals, facilitating a dynamic, layer-wise parallel form
of neural computation. Unlike other models, such as spiking predictive coding,
which rely on feedback synapses to adjust neural electrical activity, our model
operates purely online and forward in time, offering a promising way to learn
distributed representations of sensory data patterns, with and without labeled
context information. Notably, our experimental results on several pattern
datasets demonstrate that the CSDP process works well for training a dynamic
recurrent spiking network capable of both classification and reconstruction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.00054">LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Just_H/0/1/0/all/0/1">Hoang Anh Just</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_F/0/1/0/all/0/1">Feiyang Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiachen T. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_M/0/1/0/all/0/1">Myeongseob Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Ming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ruoxi Jia</a></p>
<p>Traditionally, data valuation (DV) is posed as a problem of equitably
splitting the validation performance of a learning algorithm among the training
data. As a result, the calculated data values depend on many design choices of
the underlying learning algorithm. However, this dependence is undesirable for
many DV use cases, such as setting priorities over different data sources in a
data acquisition process and informing pricing mechanisms in a data
marketplace. In these scenarios, data needs to be valued before the actual
analysis and the choice of the learning algorithm is still undetermined then.
Another side-effect of the dependence is that to assess the value of individual
points, one needs to re-run the learning algorithm with and without a point,
which incurs a large computation burden. This work leapfrogs over the current
limits of data valuation methods by introducing a new framework that can value
training data in a way that is oblivious to the downstream learning algorithm.
Our main results are as follows. (1) We develop a proxy for the validation
performance associated with a training set based on a non-conventional
class-wise Wasserstein distance between training and validation sets. We show
that the distance characterizes the upper bound of the validation performance
for any given model under certain Lipschitz conditions. (2) We develop a novel
method to value individual data based on the sensitivity analysis of the
class-wise Wasserstein distance. Importantly, these values can be directly
obtained for free from the output of off-the-shelf optimization solvers when
computing the distance. (3) We evaluate our new data valuation framework over
various use cases related to detecting low-quality data and show that,
surprisingly, the learning-agnostic feature of our framework enables a
significant improvement over SOTA performance while being orders of magnitude
faster.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02041">Low-complexity subspace-descent over symmetric positive definite manifold. (arXiv:2305.02041v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Darmwal_Y/0/1/0/all/0/1">Yogesh Darmwal</a>, <a href="http://arxiv.org/find/stat/1/au:+Rajawat_K/0/1/0/all/0/1">Ketan Rajawat</a></p>
<p>This work puts forth low-complexity Riemannian subspace descent algorithms
for the minimization of functions over the symmetric positive definite (SPD)
manifold. Different from the existing Riemannian gradient descent variants, the
proposed approach utilizes carefully chosen subspaces that allow the update to
be written as a product of the Cholesky factor of the iterate and a sparse
matrix. The resulting updates avoid the costly matrix operations like matrix
exponentiation and dense matrix multiplication, which are generally required in
almost all other Riemannian optimization algorithms on SPD manifold. We further
identify a broad class of functions, arising in diverse applications, such as
kernel matrix learning, covariance estimation of Gaussian distributions,
maximum likelihood parameter estimation of elliptically contoured
distributions, and parameter estimation in Gaussian mixture model problems,
over which the Riemannian gradients can be calculated efficiently. The proposed
uni-directional and multi-directional Riemannian subspace descent variants
incur per-iteration complexities of $\O(n)$ and $\O(n^2)$ respectively, as
compared to the $\O(n^3)$ or higher complexity incurred by all existing
Riemannian gradient descent variants. The superior runtime and low
per-iteration complexity of the proposed algorithms is also demonstrated via
numerical tests on large-scale covariance estimation and matrix square root
problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.03514">Can Large Language Models Transform Computational Social Science?. (arXiv:2305.03514v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ziems_C/0/1/0/all/0/1">Caleb Ziems</a>, <a href="http://arxiv.org/find/cs/1/au:+Held_W/0/1/0/all/0/1">William Held</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_O/0/1/0/all/0/1">Omar Shaikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhehao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Diyi Yang</a></p>
<p>Large Language Models (LLMs) are capable of successfully performing many
language processing tasks zero-shot (without training data). If zero-shot LLMs
can also reliably classify and explain social phenomena like persuasiveness and
political ideology, then LLMs could augment the Computational Social Science
(CSS) pipeline in important ways. This work provides a road map for using LLMs
as CSS tools. Towards this end, we contribute a set of prompting best practices
and an extensive evaluation pipeline to measure the zero-shot performance of 13
language models on 25 representative English CSS benchmarks. On taxonomic
labeling tasks (classification), LLMs fail to outperform the best fine-tuned
models but still achieve fair levels of agreement with humans. On free-form
coding tasks (generation), LLMs produce explanations that often exceed the
quality of crowdworkers' gold references. We conclude that the performance of
today's LLMs can augment the CSS research pipeline in two ways: (1) serving as
zero-shot data annotators on human annotation teams, and (2) bootstrapping
challenging creative generation tasks (e.g., explaining the underlying
attributes of a text). In summary, LLMs are posed to meaningfully participate
in} social science analysis in partnership with humans.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.04120">A Latent Diffusion Model for Protein Structure Generation. (arXiv:2305.04120v2 [q-bio.BM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Fu_C/0/1/0/all/0/1">Cong Fu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yan_K/0/1/0/all/0/1">Keqiang Yan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1">Limei Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Au_W/0/1/0/all/0/1">Wing Yee Au</a>, <a href="http://arxiv.org/find/q-bio/1/au:+McThrow_M/0/1/0/all/0/1">Michael McThrow</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Komikado_T/0/1/0/all/0/1">Tao Komikado</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Maruhashi_K/0/1/0/all/0/1">Koji Maruhashi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Uchino_K/0/1/0/all/0/1">Kanji Uchino</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Qian_X/0/1/0/all/0/1">Xiaoning Qian</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a></p>
<p>Proteins are complex biomolecules that perform a variety of crucial functions
within living organisms. Designing and generating novel proteins can pave the
way for many future synthetic biology applications, including drug discovery.
However, it remains a challenging computational task due to the large modeling
space of protein structures. In this study, we propose a latent diffusion model
that can reduce the complexity of protein modeling while flexibly capturing the
distribution of natural protein structures in a condensed latent space.
Specifically, we propose an equivariant protein autoencoder that embeds
proteins into a latent space and then uses an equivariant diffusion model to
learn the distribution of the latent protein representations. Experimental
results demonstrate that our method can effectively generate novel protein
backbone structures with high designability and efficiency. The code will be
made publicly available at
https://github.com/divelab/AIRS/tree/main/OpenProt/LatentDiff
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13840">Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models. (arXiv:2305.13840v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yatai Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hefeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiashi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xin Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xuefeng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a></p>
<p>Recent advancements in diffusion models have unlocked unprecedented abilities
in visual creation. However, current text-to-video generation models struggle
with the trade-off among movement range, action coherence and object
consistency. To mitigate this issue, we present a controllable text-to-video
(T2V) diffusion model, called Control-A-Video, capable of maintaining
consistency while customizable video synthesis. Based on a pre-trained
conditional text-to-image (T2I) diffusion model, our model aims to generate
videos conditioned on a sequence of control signals, such as edge or depth
maps. For the purpose of improving object consistency, Control-A-Video
integrates motion priors and content priors into video generation. We propose
two motion-adaptive noise initialization strategies, which are based on pixel
residual and optical flow, to introduce motion priors from input videos,
producing more coherent videos. Moreover, a first-frame conditioned controller
is proposed to generate videos from content priors of the first frame, which
facilitates the semantic alignment with text and allows longer video generation
in an auto-regressive manner. With the proposed architecture and strategies,
our model achieves resource-efficient convergence and generate consistent and
coherent videos with fine-grained control. Extensive experiments demonstrate
its success in various video generative tasks such as video editing and video
style transfer, outperforming previous methods in terms of consistency and
quality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00245">From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces. (arXiv:2306.00245v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shaw_P/0/1/0/all/0/1">Peter Shaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1">Mandar Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohan_J/0/1/0/all/0/1">James Cohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1">Jonathan Berant</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1">Panupong Pasupat</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hexiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_U/0/1/0/all/0/1">Urvashi Khandelwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kenton Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Toutanova_K/0/1/0/all/0/1">Kristina Toutanova</a></p>
<p>Much of the previous work towards digital agents for graphical user
interfaces (GUIs) has relied on text-based representations (derived from HTML
or other structured data sources), which are not always readily available.
These input representations have been often coupled with custom, task-specific
action spaces. This paper focuses on creating agents that interact with the
digital world using the same conceptual interface that humans commonly use --
via pixel-based screenshots and a generic action space corresponding to
keyboard and mouse actions. Building upon recent progress in pixel-based
pretraining, we show, for the first time, that it is possible for such agents
to outperform human crowdworkers on the MiniWob++ benchmark of GUI-based
instruction following tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00857">Loss-Optimal Classification Trees: A Generalized Framework and the Logistic Case. (arXiv:2306.00857v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Aldinucci_T/0/1/0/all/0/1">Tommaso Aldinucci</a>, <a href="http://arxiv.org/find/stat/1/au:+Lapucci_M/0/1/0/all/0/1">Matteo Lapucci</a></p>
<p>The Classification Tree (CT) is one of the most common models in
interpretable machine learning. Although such models are usually built with
greedy strategies, in recent years, thanks to remarkable advances in
Mixer-Integer Programming (MIP) solvers, several exact formulations of the
learning problem have been developed. In this paper, we argue that some of the
most relevant ones among these training models can be encapsulated within a
general framework, whose instances are shaped by the specification of loss
functions and regularizers. Next, we introduce a novel realization of this
framework: specifically, we consider the logistic loss, handled in the MIP
setting by a linear piece-wise approximation, and couple it with
$\ell_1$-regularization terms. The resulting Optimal Logistic Tree model
numerically proves to be able to induce trees with enhanced interpretability
features and competitive generalization capabilities, compared to the
state-of-the-art MIP-based approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03088">DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics. (arXiv:2306.03088v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Turja_M/0/1/0/all/0/1">Md Asadullah Turja</a>, <a href="http://arxiv.org/find/cs/1/au:+Styner_M/0/1/0/all/0/1">Martin Styner</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guorong Wu</a></p>
<p>Functional brain dynamics is supported by parallel and overlapping functional
network modes that are associated with specific neural circuits. Decomposing
these network modes from fMRI data and finding their temporal characteristics
is challenging due to their time-varying nature and the non-linearity of the
functional dynamics. Dynamic Mode Decomposition (DMD) algorithms have been
quite popular for solving this decomposition problem in recent years. In this
work, we apply GraphDMD -- an extension of the DMD for network data -- to
extract the dynamic network modes and their temporal characteristics from the
fMRI time series in an interpretable manner. GraphDMD, however, regards the
underlying system as a linear dynamical system that is sub-optimal for
extracting the network modes from non-linear functional data. In this work, we
develop a generalized version of the GraphDMD algorithm -- DeepGraphDMD --
applicable to arbitrary non-linear graph dynamical systems. DeepGraphDMD is an
autoencoder-based deep learning model that learns Koopman eigenfunctions for
graph data and embeds the non-linear graph dynamics into a latent linear space.
We show the effectiveness of our method in both simulated data and the HCP
resting-state fMRI data. In the HCP data, DeepGraphDMD provides novel insights
into cognitive brain functions by discovering two major network modes related
to fluid and crystallized intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04843">Classical Verification of Quantum Learning. (arXiv:2306.04843v2 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1">Matthias C. Caro</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hinsche_M/0/1/0/all/0/1">Marcel Hinsche</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ioannou_M/0/1/0/all/0/1">Marios Ioannou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1">Ryan Sweke</a></p>
<p>Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call "mixture-of-superpositions"
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05566">Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations. (arXiv:2306.05566v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wu_M/0/1/0/all/0/1">Mohan Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Lysy_M/0/1/0/all/0/1">Martin Lysy</a></p>
<p>Estimating the parameters of ordinary differential equations (ODEs) is of
fundamental importance in many scientific applications. While ODEs are
typically approximated with deterministic algorithms, new research on
probabilistic solvers indicates that they produce more reliable parameter
estimates by better accounting for numerical errors. However, many ODE systems
are highly sensitive to their parameter values. This produces deep local maxima
in the likelihood function -- a problem which existing probabilistic solvers
have yet to resolve. Here we present a novel probabilistic ODE likelihood
approximation, DALTON, which can dramatically reduce parameter sensitivity by
learning from noisy ODE measurements in a data-adaptive manner. Our
approximation scales linearly in both ODE variables and time discretization
points, and is applicable to ODEs with both partially-unobserved components and
non-Gaussian measurement models. Several examples demonstrate that DALTON
produces more accurate parameter estimates via numerical optimization than
existing probabilistic ODE solvers, and even in some cases than the exact ODE
likelihood itself.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06503">Preserving privacy in domain transfer of medical AI models comes at no performance costs: The integral role of differential privacy. (arXiv:2306.06503v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arasteh_S/0/1/0/all/0/1">Soroosh Tayebi Arasteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotfinia_M/0/1/0/all/0/1">Mahshad Lotfinia</a>, <a href="http://arxiv.org/find/cs/1/au:+Nolte_T/0/1/0/all/0/1">Teresa Nolte</a>, <a href="http://arxiv.org/find/cs/1/au:+Saehn_M/0/1/0/all/0/1">Marwin Saehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Isfort_P/0/1/0/all/0/1">Peter Isfort</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhl_C/0/1/0/all/0/1">Christiane Kuhl</a>, <a href="http://arxiv.org/find/cs/1/au:+Nebelung_S/0/1/0/all/0/1">Sven Nebelung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>, <a href="http://arxiv.org/find/cs/1/au:+Truhn_D/0/1/0/all/0/1">Daniel Truhn</a></p>
<p>Developing robust and effective artificial intelligence (AI) models in
medicine requires access to large amounts of patient data. The use of AI models
solely trained on large multi-institutional datasets can help with this, yet
the imperative to ensure data privacy remains, particularly as membership
inference risks breaching patient confidentiality. As a proposed remedy, we
advocate for the integration of differential privacy (DP). We specifically
investigate the performance of models trained with DP as compared to models
trained without DP on data from institutions that the model had not seen during
its training (i.e., external validation) - the situation that is reflective of
the clinical use of AI models. By leveraging more than 590,000 chest
radiographs from five institutions, we evaluated the efficacy of DP-enhanced
domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion,
pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed
DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness
using the area under the receiver operating characteristic curve (AUC) as the
main metric, as well as accuracy, sensitivity, and specificity. Our results
show that DP-DT, even with exceptionally high privacy levels (epsilon around
1), performs comparably to non-DP-DT (P&gt;0.119 across all domains). Furthermore,
DP-DT led to marginal AUC differences - less than 1% - for nearly all
subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that
DP models induce significant performance degradation for on-domain
applications, we show that off-domain performance is almost not affected.
Therefore, we ardently advocate for the adoption of DP in training diagnostic
medical AI models, given its minimal impact on performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12816">XAI-TRIS: Non-linear image benchmarks to quantify false positive post-hoc attribution of feature importance. (arXiv:2306.12816v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Clark_B/0/1/0/all/0/1">Benedict Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilming_R/0/1/0/all/0/1">Rick Wilming</a>, <a href="http://arxiv.org/find/cs/1/au:+Haufe_S/0/1/0/all/0/1">Stefan Haufe</a></p>
<p>The field of 'explainable' artificial intelligence (XAI) has produced highly
cited methods that seek to make the decisions of complex machine learning (ML)
methods 'understandable' to humans, for example by attributing 'importance'
scores to input features. Yet, a lack of formal underpinning leaves it unclear
as to what conclusions can safely be drawn from the results of a given XAI
method and has also so far hindered the theoretical verification and empirical
validation of XAI methods. This means that challenging non-linear problems,
typically solved by deep neural networks, presently lack appropriate remedies.
Here, we craft benchmark datasets for three different non-linear classification
scenarios, in which the important class-conditional features are known by
design, serving as ground truth explanations. Using novel quantitative metrics,
we benchmark the explanation performance of a wide set of XAI methods across
three deep learning model architectures. We show that popular XAI methods are
often unable to significantly outperform random performance baselines and edge
detection methods. Moreover, we demonstrate that explanations derived from
different model architectures can be vastly different; thus, prone to
misinterpretation even under controlled conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08360">Universal Online Learning with Gradient Variations: A Multi-layer Online Ensemble Approach. (arXiv:2307.08360v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yu-Hu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a></p>
<p>In this paper, we propose an online convex optimization approach with two
different levels of adaptivity. On a higher level, our approach is agnostic to
the unknown types and curvatures of the online functions, while at a lower
level, it can exploit the unknown niceness of the environments and attain
problem-dependent guarantees. Specifically, we obtain $\mathcal{O}(\log V_T)$,
$\mathcal{O}(d \log V_T)$ and $\widehat{\mathcal{O}}(\sqrt{V_T})$ regret bounds
for strongly convex, exp-concave and convex loss functions, respectively, where
$d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and
the $\widehat{\mathcal{O}}(\cdot)$-notation omits $\log V_T$ factors. Our
result not only safeguards the worst-case guarantees but also directly implies
the small-loss bounds in analysis. Moreover, when applied to
adversarial/stochastic convex optimization and game theory problems, our result
enhances the existing universal guarantees. Our approach is based on a
multi-layer online ensemble framework incorporating novel ingredients,
including a carefully designed optimism for unifying diverse function types and
cascaded corrections for algorithmic stability. Notably, despite its
multi-layer structure, our algorithm necessitates only one gradient query per
round, making it favorable when the gradient evaluation is time-consuming. This
is facilitated by a novel regret decomposition with carefully designed
surrogate losses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.11086">PAPR: Proximity Attention Point Rendering. (arXiv:2307.11086v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanshu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shichong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Moazeni_A/0/1/0/all/0/1">Alireza Moazeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a></p>
<p>Learning accurate and parsimonious point cloud representations of scene
surfaces from scratch remains a challenge in 3D representation learning.
Existing point-based methods often suffer from the vanishing gradient problem
or require a large number of points to accurately model scene geometry and
texture. To address these limitations, we propose Proximity Attention Point
Rendering (PAPR), a novel method that consists of a point-based scene
representation and a differentiable renderer. Our scene representation uses a
point cloud where each point is characterized by its spatial position,
influence score, and view-independent feature vector. The renderer selects the
relevant points for each ray and produces accurate colours using their
associated features. PAPR effectively learns point cloud positions to represent
the correct scene geometry, even when the initialization drastically differs
from the target geometry. Notably, our method captures fine texture details
while using only a parsimonious set of points. We also demonstrate four
practical applications of our method: zero-shot geometry editing, object
manipulation, texture transfer, and exposure control. More results and code are
available on our project website at https://zvict.github.io/papr/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12409">A Machine Learning Approach to Two-Stage Adaptive Robust Optimization. (arXiv:2307.12409v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1">Dimitris Bertsimas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Cheol Woo Kim</a></p>
<p>We propose an approach based on machine learning to solve two-stage linear
adaptive robust optimization (ARO) problems with binary here-and-now variables
and polyhedral uncertainty sets. We encode the optimal here-and-now decisions,
the worst-case scenarios associated with the optimal here-and-now decisions,
and the optimal wait-and-see decisions into what we denote as the strategy. We
solve multiple similar ARO instances in advance using the column and constraint
generation algorithm and extract the optimal strategies to generate a training
set. We train a machine learning model that predicts high-quality strategies
for the here-and-now decisions, the worst-case scenarios associated with the
optimal here-and-now decisions, and the wait-and-see decisions. We also
introduce an algorithm to reduce the number of different target classes the
machine learning algorithm needs to be trained on. We apply the proposed
approach to the facility location, the multi-item inventory control and the
unit commitment problems. Our approach solves ARO problems drastically faster
than the state-of-the-art algorithms with high accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13423">Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals using Self Supervised Speech Representations. (arXiv:2307.13423v3 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Close_G/0/1/0/all/0/1">George Close</a>, <a href="http://arxiv.org/find/cs/1/au:+Hain_T/0/1/0/all/0/1">Thomas Hain</a>, <a href="http://arxiv.org/find/cs/1/au:+Goetze_S/0/1/0/all/0/1">Stefan Goetze</a></p>
<p>Self-supervised speech representations (SSSRs) have been successfully applied
to a number of speech-processing tasks, e.g. as feature extractor for speech
quality (SQ) prediction, which is, in turn, relevant for assessment and
training speech enhancement systems for users with normal or impaired hearing.
However, exact knowledge of why and how quality-related information is encoded
well in such representations remains poorly understood. In this work,
techniques for non-intrusive prediction of SQ ratings are extended to the
prediction of intelligibility for hearing-impaired users. It is found that
self-supervised representations are useful as input features to non-intrusive
prediction models, achieving competitive performance to more complex systems. A
detailed analysis of the performance depending on Clarity Prediction Challenge
1 listeners and enhancement systems indicates that more data might be needed to
allow generalisation to unknown systems and (hearing-impaired) individuals
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14023">Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?. (arXiv:2307.14023v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kajitsuka_T/0/1/0/all/0/1">Tokio Kajitsuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a></p>
<p>Existing analyses of the expressive capacity of Transformer models have
required excessively deep layers for data memorization, leading to a
discrepancy with the Transformers actually used in practice. This is primarily
due to the interpretation of the softmax function as an approximation of the
hardmax function. By clarifying the connection between the softmax function and
the Boltzmann operator, we prove that a single layer of self-attention with
low-rank weight matrices possesses the capability to perfectly capture the
context of an entire input sequence. As a consequence, we show that one-layer
and single-head Transformers have a memorization capacity for finite samples,
and that Transformers consisting of one self-attention layer with two
feed-forward neural networks are universal approximators for continuous
permutation equivariant functions on a compact domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.09778">Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models. (arXiv:2308.09778v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rajabi_N/0/1/0/all/0/1">Navid Rajabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosecka_J/0/1/0/all/0/1">Jana Kosecka</a></p>
<p>With pre-training of vision-and-language models (VLMs) on large-scale
datasets of image-text pairs, several recent works showed that these
pre-trained models lack fine-grained understanding, such as the ability to
count and recognize verbs, attributes, or relationships. The focus of this work
is to study the ability of these models to understand spatial relations.
Previously, this has been tackled using image-text matching (e.g., Visual
Spatial Reasoning benchmark) or visual question answering (e.g., GQA or VQAv2),
both showing poor performance and a large gap compared to human performance. In
this work, we use explainability tools to understand the causes of poor
performance better and present an alternative fine-grained, compositional
approach for ranking spatial clauses. We combine the evidence from grounding
noun phrases corresponding to objects and their locations to compute the final
rank of the spatial clause. We demonstrate the approach on representative VLMs
(such as LXMERT, GPV, and MDETR) and compare and highlight their abilities to
reason about spatial relationships.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.01860">Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation. (arXiv:2309.01860v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hakim_Z/0/1/0/all/0/1">Zaber Ibn Abdul Hakim</a>, <a href="http://arxiv.org/find/cs/1/au:+Swargo_R/0/1/0/all/0/1">Rasman Mubtasim Swargo</a>, <a href="http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1">Muhammad Abdullah Adnan</a></p>
<p>In this paper, we devise a mechanism for the addition of multi-modal
information with an existing pipeline for continuous sign language recognition
and translation. In our procedure, we have incorporated optical flow
information with RGB images to enrich the features with movement-related
information. This work studies the feasibility of such modality inclusion using
a cross-modal encoder. The plugin we have used is very lightweight and doesn't
need to include a separate feature extractor for the new modality in an
end-to-end manner. We have applied the changes in both sign language
recognition and translation, improving the result in each case. We have
evaluated the performance on the RWTH-PHOENIX-2014 dataset for sign language
recognition and the RWTH-PHOENIX-2014T dataset for translation. On the
recognition task, our approach reduced the WER by 0.9, and on the translation
task, our approach increased most of the BLEU scores by ~0.6 on the test set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03409">Large Language Models as Optimizers. (arXiv:2309.03409v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chengrun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuezhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yifeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Denny Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a></p>
<p>Optimization is ubiquitous. While derivative-based algorithms have been
powerful tools for various problems, the absence of gradient imposes challenges
on many real-world applications. In this work, we propose Optimization by
PROmpting (OPRO), a simple and effective approach to leverage large language
models (LLMs) as optimizers, where the optimization task is described in
natural language. In each optimization step, the LLM generates new solutions
from the prompt that contains previously generated solutions with their values,
then the new solutions are evaluated and added to the prompt for the next
optimization step. We first showcase OPRO on linear regression and traveling
salesman problems, then move on to prompt optimization where the goal is to
find instructions that maximize the task accuracy. With a variety of LLMs, we
demonstrate that the best prompts optimized by OPRO outperform human-designed
prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks. Code at
https://github.com/google-deepmind/opro.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03755">TSGBench: Time Series Generation Benchmark. (arXiv:2309.03755v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ang_Y/0/1/0/all/0/1">Yihao Ang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1">Yifan Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1">Anthony K. H. Tung</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiyong Huang</a></p>
<p>Synthetic Time Series Generation (TSG) is crucial in a range of applications,
including data augmentation, anomaly detection, and privacy preservation.
Although significant strides have been made in this field, existing methods
exhibit three key limitations: (1) They often benchmark against similar model
types, constraining a holistic view of performance capabilities. (2) The use of
specialized synthetic and private datasets introduces biases and hampers
generalizability. (3) Ambiguous evaluation measures, often tied to custom
networks or downstream tasks, hinder consistent and fair comparison.
</p>
<p>To overcome these limitations, we introduce \textsf{TSGBench}, the inaugural
Time Series Generation Benchmark, designed for a unified and comprehensive
assessment of TSG methods. It comprises three modules: (1) a curated collection
of publicly available, real-world datasets tailored for TSG, together with a
standardized preprocessing pipeline; (2) a comprehensive evaluation measures
suite including vanilla measures, new distance-based assessments, and
visualization tools; (3) a pioneering generalization test rooted in Domain
Adaptation (DA), compatible with all methods. We have conducted comprehensive
experiments using \textsf{TSGBench} across a spectrum of ten real-world
datasets from diverse domains, utilizing ten advanced TSG methods and twelve
evaluation measures. The results highlight the reliability and efficacy of
\textsf{TSGBench} in evaluating TSG methods. Crucially, \textsf{TSGBench}
delivers a statistical analysis of the performance rankings of these methods,
illuminating their varying performance across different datasets and measures
and offering nuanced insights into the effectiveness of each method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.06240">Calibration in Machine Learning Uncertainty Quantification: beyond consistency to target adaptivity. (arXiv:2309.06240v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Pernot_P/0/1/0/all/0/1">Pascal Pernot</a></p>
<p>Reliable uncertainty quantification (UQ) in machine learning (ML) regression
tasks is becoming the focus of many studies in materials and chemical science.
It is now well understood that average calibration is insufficient, and most
studies implement additional methods testing the conditional calibration with
respect to uncertainty, i.e. consistency. Consistency is assessed mostly by
so-called reliability diagrams. There exists however another way beyond average
calibration, which is conditional calibration with respect to input features,
i.e. adaptivity. In practice, adaptivity is the main concern of the final users
of a ML-UQ method, seeking for the reliability of predictions and uncertainties
for any point in features space. This article aims to show that consistency and
adaptivity are complementary validation targets, and that a good consistency
does not imply a good adaptivity. Adapted validation methods are proposed and
illustrated on a representative example.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02074">ACE: A fast, skillful learned global atmospheric model for climate prediction. (arXiv:2310.02074v2 [physics.ao-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Watt_Meyer_O/0/1/0/all/0/1">Oliver Watt-Meyer</a>, <a href="http://arxiv.org/find/physics/1/au:+Dresdner_G/0/1/0/all/0/1">Gideon Dresdner</a>, <a href="http://arxiv.org/find/physics/1/au:+McGibbon_J/0/1/0/all/0/1">Jeremy McGibbon</a>, <a href="http://arxiv.org/find/physics/1/au:+Clark_S/0/1/0/all/0/1">Spencer K. Clark</a>, <a href="http://arxiv.org/find/physics/1/au:+Henn_B/0/1/0/all/0/1">Brian Henn</a>, <a href="http://arxiv.org/find/physics/1/au:+Duncan_J/0/1/0/all/0/1">James Duncan</a>, <a href="http://arxiv.org/find/physics/1/au:+Brenowitz_N/0/1/0/all/0/1">Noah D. Brenowitz</a>, <a href="http://arxiv.org/find/physics/1/au:+Kashinath_K/0/1/0/all/0/1">Karthik Kashinath</a>, <a href="http://arxiv.org/find/physics/1/au:+Pritchard_M/0/1/0/all/0/1">Michael S. Pritchard</a>, <a href="http://arxiv.org/find/physics/1/au:+Bonev_B/0/1/0/all/0/1">Boris Bonev</a>, <a href="http://arxiv.org/find/physics/1/au:+Peters_M/0/1/0/all/0/1">Matthew E. Peters</a>, <a href="http://arxiv.org/find/physics/1/au:+Bretherton_C/0/1/0/all/0/1">Christopher S. Bretherton</a></p>
<p>Existing ML-based atmospheric models are not suitable for climate prediction,
which requires long-term stability and physical consistency. We present ACE
(AI2 Climate Emulator), a 200M-parameter, autoregressive machine learning
emulator of an existing comprehensive 100-km resolution global atmospheric
model. The formulation of ACE allows evaluation of physical laws such as the
conservation of mass and moisture. The emulator is stable for 100 years, nearly
conserves column moisture without explicit constraints and faithfully
reproduces the reference model's climate, outperforming a challenging baseline
on over 90% of tracked variables. ACE requires nearly 100x less wall clock time
and is 100x more energy efficient than the reference model using typically
available resources. Without fine-tuning, ACE can stably generalize to a
previously unseen historical sea surface temperature dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02563">Practical, Private Assurance of the Value of Collaboration. (arXiv:2310.02563v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Asghar_H/0/1/0/all/0/1">Hassan Jameel Asghar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhigang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhongrui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaafar_D/0/1/0/all/0/1">Dali Kaafar</a></p>
<p>Two parties wish to collaborate on their datasets. However, before they
reveal their datasets to each other, the parties want to have the guarantee
that the collaboration would be fruitful. We look at this problem from the
point of view of machine learning, where one party is promised an improvement
on its prediction model by incorporating data from the other party. The parties
would only wish to collaborate further if the updated model shows an
improvement in accuracy. Before this is ascertained, the two parties would not
want to disclose their models and datasets. In this work, we construct an
interactive protocol for this problem based on the fully homomorphic encryption
scheme over the Torus (TFHE) and label differential privacy, where the
underlying machine learning model is a neural network. Label differential
privacy is used to ensure that computations are not done entirely in the
encrypted domain, which is a significant bottleneck for neural network training
according to the current state-of-the-art FHE implementations. We prove the
security of our scheme in the universal composability framework assuming
honest-but-curious parties, but where one party may not have any expertise in
labelling its initial dataset. Experiments show that we can obtain the output,
i.e., the accuracy of the updated model, with time many orders of magnitude
faster than a protocol using entirely FHE operations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.04856">LIPEx-Locally Interpretable Probabilistic Explanations-To Look Beyond The True Class. (arXiv:2310.04856v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongbo Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cangelosi_A/0/1/0/all/0/1">Angelo Cangelosi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_P/0/1/0/all/0/1">Procheta Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1">Anirbit Mukherjee</a></p>
<p>In this work, we instantiate a novel perturbation-based multi-class
explanation framework, LIPEx (Locally Interpretable Probabilistic Explanation).
We demonstrate that LIPEx not only locally replicates the probability
distributions output by the widely used complex classification models but also
provides insight into how every feature deemed to be important affects the
prediction probability for each of the possible classes. We achieve this by
defining the explanation as a matrix obtained via regression with respect to
the Hellinger distance in the space of probability distributions. Ablation
tests on text and image data, show that LIPEx-guided removal of important
features from the data causes more change in predictions for the underlying
model than similar tests based on other saliency-based or feature
importance-based Explainable AI (XAI) methods. It is also shown that compared
to LIME, LIPEx is more data efficient in terms of using a lesser number of
perturbations of the data to obtain a reliable explanation. This
data-efficiency is seen to manifest as LIPEx being able to compute its
explanation matrix around 53% faster than all-class LIME, for classification
experiments with text data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.06725">Growing ecosystem of deep learning methods for modeling protein$\unicode{x2013}$protein interactions. (arXiv:2310.06725v2 [q-bio.BM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Rogers_J/0/1/0/all/0/1">Julia R. Rogers</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Nikolenyi_G/0/1/0/all/0/1">Gerg&#x151; Nikol&#xe9;nyi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+AlQuraishi_M/0/1/0/all/0/1">Mohammed AlQuraishi</a></p>
<p>Numerous cellular functions rely on protein$\unicode{x2013}$protein
interactions. Efforts to comprehensively characterize them remain challenged
however by the diversity of molecular recognition mechanisms employed within
the proteome. Deep learning has emerged as a promising approach for tackling
this problem by exploiting both experimental data and basic biophysical
knowledge about protein interactions. Here, we review the growing ecosystem of
deep learning methods for modeling protein interactions, highlighting the
diversity of these biophysically-informed models and their respective
trade-offs. We discuss recent successes in using representation learning to
capture complex features pertinent to predicting protein interactions and
interaction sites, geometric deep learning to reason over protein structures
and predict complex structures, and generative modeling to design de novo
protein assemblies. We also outline some of the outstanding challenges and
promising new directions. Opportunities abound to discover novel interactions,
elucidate their physical mechanisms, and engineer binders to modulate their
functions using deep learning and, ultimately, unravel how protein interactions
orchestrate complex cellular behaviors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08224">Emergence of Latent Binary Encoding in Deep Neural Network Classifiers. (arXiv:2310.08224v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sbailo_L/0/1/0/all/0/1">Luigi Sbail&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghiringhelli_L/0/1/0/all/0/1">Luca Ghiringhelli</a></p>
<p>We observe the emergence of binary encoding within the latent space of
deep-neural-network classifiers. Such binary encoding is induced by introducing
a linear penultimate layer, which is equipped during training with a loss
function that grows as $\exp(\vec{x}^2)$, where $\vec{x}$ are the coordinates
in the latent space. The phenomenon we describe represents a specific instance
of a well-documented occurrence known as \textit{neural collapse}, which arises
in the terminal phase of training and entails the collapse of latent class
means to the vertices of a simplex equiangular tight frame (ETF). We show that
binary encoding accelerates convergence toward the simplex ETF and enhances
classification accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09819">Optimizing K-means for Big Data: A Comparative Study. (arXiv:2310.09819v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mussabayev_R/0/1/0/all/0/1">Ravil Mussabayev</a>, <a href="http://arxiv.org/find/cs/1/au:+Mussabayev_R/0/1/0/all/0/1">Rustam Mussabayev</a></p>
<p>This paper presents a comparative analysis of different optimization
techniques for the K-means algorithm in the context of big data. K-means is a
widely used clustering algorithm, but it can suffer from scalability issues
when dealing with large datasets. The paper explores different approaches to
overcome these issues, including parallelization, approximation, and sampling
methods. The authors evaluate the performance of these techniques on various
benchmark datasets and compare them in terms of speed, quality of clustering,
and scalability according to the LIMA dominance criterion. The results show
that different techniques are more suitable for different types of datasets and
provide insights into the trade-offs between speed and accuracy in K-means
clustering for big data. Overall, the paper offers a comprehensive guide for
practitioners and researchers on how to optimize K-means for big data
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18805">Inverse distance weighting attention. (arXiv:2310.18805v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McCarter_C/0/1/0/all/0/1">Calvin McCarter</a></p>
<p>We report the effects of replacing the scaled dot-product (within softmax)
attention with the negative-log of Euclidean distance. This form of attention
simplifies to inverse distance weighting interpolation. Used in simple one
hidden layer networks and trained with vanilla cross-entropy loss on
classification problems, it tends to produce a key matrix containing prototypes
and a value matrix with corresponding logits. We also show that the resulting
interpretable networks can be augmented with manually-constructed prototypes to
perform low-impact handling of special cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00502">Efficient LLM Inference on CPUs. (arXiv:2311.00502v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Haihao Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Hanwen Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1">Bo Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yu Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1">Hengyu Meng</a></p>
<p>Large language models (LLMs) have demonstrated remarkable performance and
tremendous potential across a wide range of tasks. However, deploying these
models has been challenging due to the astronomical amount of model parameters,
which requires a demand for large memory capacity and high memory bandwidth. In
this paper, we propose an effective approach that can make the deployment of
LLMs more efficiently. We support an automatic INT4 weight-only quantization
flow and design a special LLM runtime with highly-optimized kernels to
accelerate the LLM inference on CPUs. We demonstrate the general applicability
of our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase
the extreme inference efficiency on CPUs. The code is publicly available at:
https://github.com/intel/intel-extension-for-transformers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00519">Retrieval-Based Reconstruction For Time-series Contrastive Learning. (arXiv:2311.00519v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Maxwell A. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1">Alexander Moreno</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Hui Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlin_B/0/1/0/all/0/1">Benjamin M. Marlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1">James M. Rehg</a></p>
<p>The success of self-supervised contrastive learning hinges on identifying
positive data pairs that, when pushed together in embedding space, encode
useful information for subsequent downstream tasks. However, in time-series,
this is challenging because creating positive pairs via augmentations may break
the original semantic meaning. We hypothesize that if we can retrieve
information from one subsequence to successfully reconstruct another
subsequence, then they should form a positive pair. Harnessing this intuition,
we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR)
contrastive learning. First, we utilize a convolutional cross-attention
architecture to calculate the REBAR error between two different time-series.
Then, through validation experiments, we show that the REBAR error is a
predictor of mutual class membership, justifying its usage as a
positive/negative labeler. Finally, once integrated into a contrastive learning
framework, our REBAR method can learn an embedding that achieves
state-of-the-art performance on downstream tasks across various modalities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05587">Bayesian Methods for Media Mix Modelling with shape and funnel effects. (arXiv:2311.05587v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marin_J/0/1/0/all/0/1">Javier Marin</a></p>
<p>In recent years, significant progress in generative AI has highlighted the
important role of physics-inspired models that utilize advanced mathematical
concepts based on fundamental physics principles to enhance artificial
intelligence capabilities. Among these models, those based on diffusion
equations have greatly improved image quality. This study aims to explore the
potential uses of Maxwell-Boltzmann equation, which forms the basis of the
kinetic theory of gases, and the Michaelis-Menten model in Marketing Mix
Modelling (MMM) applications. We propose incorporating these equations into
Hierarchical Bayesian models to analyse consumer behaviour in the context of
advertising. These equation sets excel in accurately describing the random
dynamics in complex systems like social interactions and consumer-advertising
interactions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07625">Activity Sparsity Complements Weight Sparsity for Efficient RNN Inference. (arXiv:2311.07625v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mukherji_R/0/1/0/all/0/1">Rishav Mukherji</a>, <a href="http://arxiv.org/find/cs/1/au:+Schone_M/0/1/0/all/0/1">Mark Sch&#xf6;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazeer_K/0/1/0/all/0/1">Khaleelulla Khan Nazeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayr_C/0/1/0/all/0/1">Christian Mayr</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramoney_A/0/1/0/all/0/1">Anand Subramoney</a></p>
<p>Artificial neural networks open up unprecedented machine learning
capabilities at the cost of ever growing computational requirements.
Sparsifying the parameters, often achieved through weight pruning, has been
identified as a powerful technique to compress the number of model parameters
and reduce the computational operations of neural networks. Yet, sparse
activations, while omnipresent in both biological neural networks and deep
learning systems, have not been fully utilized as a compression technique in
deep learning. Moreover, the interaction between sparse activations and weight
pruning is not fully understood. In this work, we demonstrate that activity
sparsity can compose multiplicatively with parameter sparsity in a recurrent
neural network model based on the GRU that is designed to be activity sparse.
We achieve up to $20\times$ reduction of computation while maintaining
perplexities below $60$ on the Penn Treebank language modeling task. This
magnitude of reduction has not been achieved previously with solely sparsely
connected LSTMs, and the language modeling performance of our model has not
been achieved previously with any sparsely activated recurrent neural networks
or spiking neural networks. Neuromorphic computing devices are especially good
at taking advantage of the dynamic activity sparsity, and our results provide
strong evidence that making deep learning models activity sparse and porting
them to neuromorphic devices can be a viable strategy that does not compromise
on task performance. Our results also drive further convergence of methods from
deep learning and neuromorphic computing for efficient machine learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09200">ExpM+NF Tractable Exponential Mechanism via Normalizing Flow, A Path through the Accuracy-Privacy Ceiling Constraining Differentially Private ML. (arXiv:2311.09200v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Bridges_R/0/1/0/all/0/1">Robert A. Bridges</a>, <a href="http://arxiv.org/find/stat/1/au:+Tombs_V/0/1/0/all/0/1">Vandy J. Tombs</a>, <a href="http://arxiv.org/find/stat/1/au:+Stanley_C/0/1/0/all/0/1">Christopher B. Stanley</a></p>
<p>The Exponential Mechanism (ExpM), a differentially private optimization
method, promises many advantages over Differentially Private Stochastic
Gradient Descent (DPSGD), the state-of-the-art (SOTA) and de facto method for
differentially private machine learning (ML). Yet, ExpM has been historically
stymied from differentially private training of modern ML algorithms by two
obstructions: ExpM requires a sensitivity bound for the given loss function;
ExpM requires sampling from a historically intractable density. We prove a
sensitivity bound for $\ell(2)$ loss, and investigate using Normalizing Flows
(NFs), deep networks furnishing approximate sampling from the otherwise
intractable ExpM distribution. We prove that as the NF output converges to ExpM
distribution, the privacy ($\varepsilon$) of an NF sample converges to that of
the ExpM distribution. Under the assumption that the NF output distribution is
the ExpM distribution, we empirically test ExpM+NF against DPSGD using the SOTA
implementation (Opacus \cite{opacus} with PRV accounting) in multiple
classification tasks on the Adult Dataset (census data) and MIMIC-III Dataset
(healthcare records) using Logistic Regression and GRU-D, a deep learning
recurrent neural network with \smallsim 20K-100K parameters. In all experiments
we find ExpM+NF achieves greater than 94\% of the non-private training accuracy
(AUC) with $\varepsilon$-DP for $\varepsilon$ a low as $1\mathrm{e}{-3}$ --
three orders of magnitude stronger privacy with similar accuracy. Further,
performance results show ExpM+NF training time is comparable to (slightly less)
than DPSGD. Limitations and future directions are provided; notably, research
on NF approximation accuracy and its effect on privacy are a promising avenue
to substantially advancing the field. Code for these experiments \hl{will be
provided after review}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11642">Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging. (arXiv:2311.11642v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Muqeet_A/0/1/0/all/0/1">Abdul Muqeet</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyuchul Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Bumsoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yohan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyungrae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1">Woonggon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">KwangHee Lee</a></p>
<p>Video face re-aging deals with altering the apparent age of a person to the
target age in videos. This problem is challenging due to the lack of paired
video datasets maintaining temporal consistency in identity and age. Most
re-aging methods process each image individually without considering the
temporal consistency of videos. While some existing works address the issue of
temporal coherence through video facial attribute manipulation in latent space,
they often fail to deliver satisfactory performance in age transformation. To
tackle the issues, we propose (1) a novel synthetic video dataset that features
subjects across a diverse range of age groups; (2) a baseline architecture
designed to validate the effectiveness of our proposed dataset, and (3) the
development of three novel metrics tailored explicitly for evaluating the
temporal consistency of video re-aging techniques. Our comprehensive
experiments on public datasets, such as VFHQ and CelebV-HQ, show that our
method outperforms the existing approaches in terms of both age transformation
and temporal consistency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13060">Training Deep 3D Convolutional Neural Networks to Extract BSM Physics Parameters Directly from HEP Data: a Proof-of-Concept Study Using Monte Carlo Simulations. (arXiv:2311.13060v2 [hep-ex] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ex/1/au:+Dubey_S/0/1/0/all/0/1">S. Dubey</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Browder_T/0/1/0/all/0/1">T.E. Browder</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Kohani_S/0/1/0/all/0/1">S.Kohani</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Mandal_R/0/1/0/all/0/1">R. Mandal</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Sibidanov_A/0/1/0/all/0/1">A. Sibidanov</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Sinha_R/0/1/0/all/0/1">R. Sinha</a></p>
<p>We report on a novel application of computer vision techniques to extract
beyond the Standard Model (BSM) parameters directly from high energy physics
(HEP) flavor data. We develop a method of transforming angular and kinematic
distributions into "quasi-images" that can be used to train a convolutional
neural network to perform regression tasks, similar to fitting. This contrasts
with the usual classification functions performed using ML/AI in HEP. As a
proof-of-concept, we train a 34-layer Residual Neural Network to regress on
these images and determine the Wilson Coefficient $C_{9}$ in MC (Monte Carlo)
simulations of $B \rightarrow K^{*}\mu^{+}\mu^{-}$ decays. The technique
described here can be generalized and may find applicability across various HEP
experiments and elsewhere.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13434">Recurrent neural networks and transfer learning for elasto-plasticity in woven composites. (arXiv:2311.13434v2 [cond-mat.mtrl-sci] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Ghane_E/0/1/0/all/0/1">Ehsan Ghane</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fagerstrom_M/0/1/0/all/0/1">Martin Fagerstr&#xf6;m</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Mirkhalaf_M/0/1/0/all/0/1">Mohsen Mirkhalaf</a></p>
<p>As a surrogate for computationally intensive meso-scale simulation of woven
composites, this article presents Recurrent Neural Network (RNN) models.
Leveraging the power of transfer learning, the initialization challenges and
sparse data issues inherent in cyclic shear strain loads are addressed in the
RNN models. A mean-field model generates a comprehensive data set representing
elasto-plastic behavior. In simulations, arbitrary six-dimensional strain
histories are used to predict stresses under random walking as the source task
and cyclic loading conditions as the target task. Incorporating sub-scale
properties enhances RNN versatility. In order to achieve accurate predictions,
the model uses a grid search method to tune network architecture and
hyper-parameter configurations. The results of this study demonstrate that
transfer learning can be used to effectively adapt the RNN to varying strain
conditions, which establishes its potential as a useful tool for modeling
path-dependent responses in woven composites.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14388">A Parameterized Generative Adversarial Network Using Cyclic Projection for Explainable Medical Image Classification. (arXiv:2311.14388v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiong_X/0/1/0/all/0/1">Xiangyu Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yue Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaohong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_C/0/1/0/all/0/1">Chan-Tong Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_T/0/1/0/all/0/1">Tong Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qinquan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_W/0/1/0/all/0/1">Wei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tao Tan</a></p>
<p>Although current data augmentation methods are successful to alleviate the
data insufficiency, conventional augmentation are primarily intra-domain while
advanced generative adversarial networks (GANs) generate images remaining
uncertain, particularly in small-scale datasets. In this paper, we propose a
parameterized GAN (ParaGAN) that effectively controls the changes of synthetic
samples among domains and highlights the attention regions for downstream
classification. Specifically, ParaGAN incorporates projection distance
parameters in cyclic projection and projects the source images to the decision
boundary to obtain the class-difference maps. Our experiments show that ParaGAN
can consistently outperform the existing augmentation methods with explainable
classification on two small-scale medical datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.15327">FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots. (arXiv:2311.15327v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Onishi_A/0/1/0/all/0/1">Akinari Onishi</a></p>
<p>The reinforcement learning algorithms have often been applied to social
robots. However, most reinforcement learning algorithms were not optimized for
the use of social robots, and consequently they may bore users. We proposed a
new reinforcement learning method specialized for the social robot, the
FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists
of a forgetting process in addition to randomizing and categorizing processes.
This study evaluated interest and boredom hardness scores of the
FRAC-Q-learning by a comparison with the traditional Q-learning. The
FRAC-Q-learning showed significantly higher trend of interest score, and
indicated significantly harder to bore users compared to the traditional
Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social
robot that will not bore users. The proposed algorithm can also find
applications in Web-based communication and educational systems. This paper
presents the entire process, detailed implementation and a detailed evaluation
method of the of the FRAC-Q-learning for the first time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.15549">From Prediction to Action: Critical Role of Performance Estimation for Machine-Learning-Driven Materials Discovery. (arXiv:2311.15549v2 [cond-mat.mtrl-sci] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Boley_M/0/1/0/all/0/1">Mario Boley</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Luong_F/0/1/0/all/0/1">Felix Luong</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Teshuva_S/0/1/0/all/0/1">Simon Teshuva</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Schmidt_D/0/1/0/all/0/1">Daniel F Schmidt</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Foppa_L/0/1/0/all/0/1">Lucas Foppa</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Scheffler_M/0/1/0/all/0/1">Matthias Scheffler</a></p>
<p>Materials discovery driven by statistical property models is an iterative
decision process, during which an initial data collection is extended with new
data proposed by a model-informed acquisition function--with the goal to
maximize a certain "reward" over time, such as the maximum property value
discovered so far. While the materials science community achieved much progress
in developing property models that predict well on average with respect to the
training distribution, this form of in-distribution performance measurement is
not directly coupled with the discovery reward. This is because an iterative
discovery process has a shifting reward distribution that is
over-proportionally determined by the model performance for exceptional
materials. We demonstrate this problem using the example of bulk modulus
maximization among double perovskite oxides. We find that the in-distribution
predictive performance suggests random forests as superior to Gaussian process
regression, while the results are inverse in terms of the discovery rewards. We
argue that the lack of proper performance estimation methods from pre-computed
data collections is a fundamental problem for improving data-driven materials
discovery, and we propose a novel such estimator that, in contrast to na\"ive
reward estimation, successfully predicts Gaussian processes with the "expected
improvement" acquisition function as the best out of four options in our
demonstrational study for double perovskites. Importantly, it does so without
requiring the over thousand ab initio computations that were needed to confirm
this prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00209">On the Interplay Between Stepsize Tuning and Progressive Sharpening. (arXiv:2312.00209v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roulet_V/0/1/0/all/0/1">Vincent Roulet</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwala_A/0/1/0/all/0/1">Atish Agarwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1">Fabian Pedregosa</a></p>
<p>Recent empirical work has revealed an intriguing property of deep learning
models by which the sharpness (largest eigenvalue of the Hessian) increases
throughout optimization until it stabilizes around a critical value at which
the optimizer operates at the edge of stability, given a fixed stepsize (Cohen
et al, 2022). We investigate empirically how the sharpness evolves when using
stepsize-tuners, the Armijo linesearch and Polyak stepsizes, that adapt the
stepsize along the iterations to local quantities such as, implicitly, the
sharpness itself. We find that the surprisingly poor performance of a classical
Armijo linesearch may be well explained by its tendency to ever-increase the
sharpness of the objective in the full or large batch regimes. On the other
hand, we observe that Polyak stepsizes operate generally at the edge of
stability or even slightly beyond, while outperforming its Armijo and constant
stepsizes counterparts. We conclude with an analysis that suggests unlocking
stepsize tuners requires an understanding of the joint dynamics of the step
size and the sharpness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00271">Towards Clinical Prediction with Transparency: An Explainable AI Approach to Survival Modelling in Residential Aged Care. (arXiv:2312.00271v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Susnjak_T/0/1/0/all/0/1">Teo Susnjak</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffin_E/0/1/0/all/0/1">Elise Griffin</a>, <a href="http://arxiv.org/find/cs/1/au:+McCutcheon_M/0/1/0/all/0/1">Mitchell McCutcheon</a>, <a href="http://arxiv.org/find/cs/1/au:+Potter_K/0/1/0/all/0/1">Kathleen Potter</a></p>
<p>Background: Accurate survival time estimates aid end-of-life medical
decision-making. Objectives: Develop an interpretable survival model for
elderly residential aged care residents using advanced machine learning.
Setting: A major Australasian residential aged care provider. Participants:
Residents aged 65+ admitted for long-term care from July 2017 to August 2023.
Sample size: 11,944 residents across 40 facilities. Predictors: Factors include
age, gender, health status, co-morbidities, cognitive function, mood,
nutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome:
Probability of survival post-admission, specifically calibrated for 6-month
survival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB,
and RF models in 20 experiments with a 90/10 train/test split. Evaluated
accuracy using C-index, Harrell's C-index, dynamic AUROC, IBS, and calibrated
ROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month
predictions using Platt scaling. Employed SHAP values to analyze predictor
impacts. Results: GB, XGB, and RF models showed the highest C-Index values
(0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival
prediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors
include age, male gender, mobility, health status, pressure ulcer risk, and
appetite. Conclusions: The study successfully applies machine learning to
create a survival model for aged care, aligning with clinical insights on
mortality risk factors and enhancing model interpretability and clinical
utility through explainable AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01227">Distributed Bayesian Estimation in Sensor Networks: Consensus on Marginal Densities. (arXiv:2312.01227v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Paritosh_P/0/1/0/all/0/1">Parth Paritosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Atanasov_N/0/1/0/all/0/1">Nikolay Atanasov</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_S/0/1/0/all/0/1">Sonia Martinez</a></p>
<p>In this paper, we aim to design and analyze distributed Bayesian estimation
algorithms for sensor networks. The challenges we address are to (i) derive a
distributed provably-correct algorithm in the functional space of probability
distributions over continuous variables, and (ii) leverage these results to
obtain new distributed estimators restricted to subsets of variables observed
by individual agents. This relates to applications such as cooperative
localization and federated learning, where the data collected at any agent
depends on a subset of all variables of interest. We present Bayesian density
estimation algorithms using data from non-linear likelihoods at agents in
centralized, distributed, and marginal distributed settings. After setting up a
distributed estimation objective, we prove almost-sure convergence to the
optimal set of pdfs at each agent. Then, we prove the same for a storage-aware
algorithm estimating densities only over relevant variables at each agent.
Finally, we present a Gaussian version of these algorithms and implement it in
a mapping problem using variational inference to handle non-linear likelihood
models associated with LiDAR sensing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01530">Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings. (arXiv:2312.01530v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kleist_H/0/1/0/all/0/1">Henrik von Kleist</a>, <a href="http://arxiv.org/find/stat/1/au:+Zamanian_A/0/1/0/all/0/1">Alireza Zamanian</a>, <a href="http://arxiv.org/find/stat/1/au:+Shpitser_I/0/1/0/all/0/1">Ilya Shpitser</a>, <a href="http://arxiv.org/find/stat/1/au:+Ahmidi_N/0/1/0/all/0/1">Narges Ahmidi</a></p>
<p>Machine learning methods often assume input features are available at no
cost. However, in domains like healthcare, where acquiring features could be
expensive or harmful, it is necessary to balance a feature's acquisition cost
against its predictive value. The task of training an AI agent to decide which
features to acquire is called active feature acquisition (AFA). By deploying an
AFA agent, we effectively alter the acquisition strategy and trigger a
distribution shift. To safely deploy AFA agents under this distribution shift,
we present the problem of active feature acquisition performance evaluation
(AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating
that acquisitions don't affect the underlying feature values; and ii) a no
unobserved confounding (NUC) assumption, stating that retrospective feature
acquisition decisions were only based on observed features. We show that one
can apply offline reinforcement learning under the NUC assumption and missing
data methods under the NDE assumption. When NUC and NDE hold, we propose a
novel semi-offline reinforcement learning framework, which requires a weaker
positivity assumption and yields more data-efficient estimators. We introduce
three novel estimators: a direct method (DM), an inverse probability weighting
(IPW), and a double reinforcement learning (DRL) estimator.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01619">How Many Validation Labels Do You Need? Exploring the Design Space of Label-Efficient Model Ranking. (arXiv:2312.01619v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhengyu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jieyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yuchen Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hui Xiong</a></p>
<p>The paper introduces LEMR, a framework that reduces annotation costs for
model selection tasks. Our approach leverages ensemble methods to generate
pseudo-labels, employs uncertainty sampling for target acquisition, and
utilizes a Z-score mechanism for iterative committee reelection to refine model
ranks. We present a systematic study across various selection metrics,
demonstrating that LEMR achieves comparable results to fully labeled datasets
with a fraction of the labeling budget. Our findings indicate that LEMR not
only economizes the labeling effort in weak supervision and semi-supervised
learning settings but also effectively guides prompt selection for large
language models. With extensive experiments across 23 tasks, we reveal that our
framework can dramatically decrease the labeling cost without compromising the
accuracy of model selection, thereby offering a cost-effective alternative to
traditional practices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.02914">Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training. (arXiv:2312.02914v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1">Arun Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1">William Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivera_C/0/1/0/all/0/1">Corban Rivera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_K/0/1/0/all/0/1">Ketul Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Melo_C/0/1/0/all/0/1">Celso M. de Melo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1">Rama Chellappa</a></p>
<p>In this work, we tackle the problem of unsupervised domain adaptation (UDA)
for video action recognition. Our approach, which we call UNITE, uses an image
teacher model to adapt a video student model to the target domain. UNITE first
employs self-supervised pre-training to promote discriminative feature learning
on target domain videos using a teacher-guided masked distillation objective.
We then perform self-training on masked target data, using the video student
model and image teacher model together to generate improved pseudolabels for
unlabeled target videos. Our self-training process successfully leverages the
strengths of both models to achieve strong transfer performance across domains.
We evaluate our approach on multiple video domain adaptation benchmarks and
observe significant improvements upon previously reported results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.02959">Detecting algorithmic bias in medical AI-models. (arXiv:2312.02959v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Smith_J/0/1/0/all/0/1">Jeffrey Smith</a>, <a href="http://arxiv.org/find/stat/1/au:+Holder_A/0/1/0/all/0/1">Andre Holder</a>, <a href="http://arxiv.org/find/stat/1/au:+Kamaleswaran_R/0/1/0/all/0/1">Rishikesan Kamaleswaran</a>, <a href="http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1">Yao Xie</a></p>
<p>With the growing prevalence of machine learning and artificial
intelligence-based medical decision support systems, it is equally important to
ensure that these systems provide patient outcomes in a fair and equitable
fashion. This paper presents an innovative framework for detecting areas of
algorithmic bias in medical-AI decision support systems. Our approach
efficiently identifies potential biases in medical-AI models, specifically in
the context of sepsis prediction, by employing the Classification and
Regression Trees (CART) algorithm. We verify our methodology by conducting a
series of synthetic data experiments, showcasing its ability to estimate areas
of bias in controlled settings precisely. The effectiveness of the concept is
further validated by experiments using electronic medical records from Grady
Memorial Hospital in Atlanta, Georgia. These tests demonstrate the practical
implementation of our strategy in a clinical environment, where it can function
as a vital instrument for guaranteeing fairness and equity in AI-based medical
decisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03196">Domain Invariant Representation Learning and Sleep Dynamics Modeling for Automatic Sleep Staging. (arXiv:2312.03196v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungyeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Thai-Hoang Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Ping Zhang</a></p>
<p>Sleep staging has become a critical task in diagnosing and treating sleep
disorders to prevent sleep related diseases. With rapidly growing large scale
public sleep databases and advances in machine learning, significant progress
has been made toward automatic sleep staging. However, previous studies face
some critical problems in sleep studies; the heterogeneity of subjects'
physiological signals, the inability to extract meaningful information from
unlabeled sleep signal data to improve predictive performances, the difficulty
in modeling correlations between sleep stages, and the lack of an effective
mechanism to quantify predictive uncertainty. In this study, we propose a
neural network based automatic sleep staging model, named DREAM, to learn
domain generalized representations from physiological signals and models sleep
dynamics. DREAM learns sleep related and subject invariant representations from
diverse subjects' sleep signal segments and models sleep dynamics by capturing
interactions between sequential signal segments and between sleep stages. In
the experiments, we demonstrate that DREAM outperforms the existing sleep
staging methods on three datasets. The case study demonstrates that our model
can learn the generalized decision function resulting in good prediction
performances for the new subjects, especially in case there are differences
between testing and training subjects. The usage of unlabeled data shows the
benefit of leveraging unlabeled EEG data. Further, uncertainty quantification
demonstrates that DREAM provides prediction uncertainty, making the model
reliable and helping sleep experts in real world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03406">SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting. (arXiv:2312.03406v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Liang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a></p>
<p>Spatiotemporal forecasting tasks, such as weather forecasting and traffic
prediction, offer significant societal benefits. These tasks can be effectively
approached as image forecasting problems using computer vision models. Vector
quantization (VQ) is a well-known method for discrete representation that
improves the latent space, leading to enhanced generalization and transfer
learning capabilities. One of the main challenges in using VQ for
spatiotemporal forecasting is how to balance between keeping enough details and
removing noises from the original patterns for better generalization. We
address this challenge by developing sparse vector quantization, or {\bf SVQ}
for short, that leverages sparse regression to make better trade-off between
the two objectives. The main innovation of this work is to approximate sparse
regression by a two-layer MLP and a randomly fixed or learnable matrix,
dramatically improving its computational efficiency. Through experiments
conducted on diverse datasets in multiple fields including weather forecasting,
traffic flow prediction, and video forecasting, we unequivocally demonstrate
that our proposed method consistently enhances the performance of base models
and achieves state-of-the-art results across all benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03510">Towards Sobolev Pruning. (arXiv:2312.03510v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kichler_N/0/1/0/all/0/1">Neil Kichler</a>, <a href="http://arxiv.org/find/cs/1/au:+Afghan_S/0/1/0/all/0/1">Sher Afghan</a>, <a href="http://arxiv.org/find/cs/1/au:+Naumann_U/0/1/0/all/0/1">Uwe Naumann</a></p>
<p>The increasing use of stochastic models for describing complex phenomena
warrants surrogate models that capture the reference model characteristics at a
fraction of the computational cost, foregoing potentially expensive Monte Carlo
simulation. The predominant approach of fitting a large neural network and then
pruning it to a reduced size has commonly neglected shortcomings. The produced
surrogate models often will not capture the sensitivities and uncertainties
inherent in the original model. In particular, (higher-order) derivative
information of such surrogates could differ drastically. Given a large enough
network, we expect this derivative information to match. However, the pruned
model will almost certainly not share this behavior.
</p>
<p>In this paper, we propose to find surrogate models by using sensitivity
information throughout the learning and pruning process. We build on work using
Interval Adjoint Significance Analysis for pruning and combine it with the
recent advancements in Sobolev Training to accurately model the original
sensitivity information in the pruned neural network based surrogate model. We
experimentally underpin the method on an example of pricing a multidimensional
Basket option modelled through a stochastic differential equation with Brownian
motion. The proposed method is, however, not limited to the domain of
quantitative finance, which was chosen as a case study for intuitive
interpretations of the sensitivities. It serves as a foundation for building
further surrogate modelling techniques considering sensitivity information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03619">Evaluation of Active Feature Acquisition Methods for Static Feature Settings. (arXiv:2312.03619v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kleist_H/0/1/0/all/0/1">Henrik von Kleist</a>, <a href="http://arxiv.org/find/stat/1/au:+Zamanian_A/0/1/0/all/0/1">Alireza Zamanian</a>, <a href="http://arxiv.org/find/stat/1/au:+Shpitser_I/0/1/0/all/0/1">Ilya Shpitser</a>, <a href="http://arxiv.org/find/stat/1/au:+Ahmidi_N/0/1/0/all/0/1">Narges Ahmidi</a></p>
<p>Active feature acquisition (AFA) agents, crucial in domains like healthcare
where acquiring features is often costly or harmful, determine the optimal set
of features for a subsequent classification task. As deploying an AFA agent
introduces a shift in missingness distribution, it's vital to assess its
expected performance at deployment using retrospective data. In a companion
paper, we introduce a semi-offline reinforcement learning (RL) framework for
active feature acquisition performance evaluation (AFAPE) where features are
assumed to be time-dependent. Here, we study and extend the AFAPE problem to
cover static feature settings, where features are time-invariant, and hence
provide more flexibility to the AFA agents in deciding the order of the
acquisitions. In this static feature setting, we derive and adapt new inverse
probability weighting (IPW), direct method (DM), and double reinforcement
learning (DRL) estimators within the semi-offline RL framework. These
estimators can be applied when the missingness in the retrospective dataset
follows a missing-at-random (MAR) pattern. They also can be applied to
missing-not-at-random (MNAR) patterns in conjunction with appropriate existing
missing data techniques. We illustrate the improved data efficiency offered by
the semi-offline RL estimators in synthetic and real-world data experiments
under synthetic MAR and MNAR missingness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03651">MIRACLE: Inverse Reinforcement and Curriculum Learning Model for Human-inspired Mobile Robot Navigation. (arXiv:2312.03651v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gunukula_N/0/1/0/all/0/1">Nihal Gunukula</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_K/0/1/0/all/0/1">Kshitij Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Bera_A/0/1/0/all/0/1">Aniket Bera</a></p>
<p>In emergency scenarios, mobile robots must navigate like humans, interpreting
stimuli to locate potential victims rapidly without interfering with first
responders. Existing socially-aware navigation algorithms face computational
and adaptability challenges. To overcome these, we propose a solution, MIRACLE
-- an inverse reinforcement and curriculum learning model, that employs
gamified learning to gather stimuli-driven human navigational data. This data
is then used to train a Deep Inverse Maximum Entropy Reinforcement Learning
model, reducing reliance on demonstrator abilities. Testing reveals a low loss
of 2.7717 within a 400-sized environment, signifying human-like response
replication. Current databases lack comprehensive stimuli-driven data,
necessitating our approach. By doing so, we enable robots to navigate emergency
situations with human-like perception, enhancing their life-saving
capabilities.
</p>
</p>
</div>

    </div>
    </body>
    