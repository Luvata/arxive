<!DOCTYPE html>
<html>
<head>
<title>2023-12-16-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2312.08377">ALGNet: Attention Light Graph Memory Network for Medical Recommendation System. (arXiv:2312.08377v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh-Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Duy-Thinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Trinh_Q/0/1/0/all/0/1">Quoc-Huy Trinh</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_B/0/1/0/all/0/1">Bac-Hoai Le</a></p>
<p>Medication recommendation is a vital task for improving patient care and
reducing adverse events. However, existing methods often fail to capture the
complex and dynamic relationships among patient medical records, drug efficacy
and safety, and drug-drug interactions (DDI). In this paper, we propose ALGNet,
a novel model that leverages light graph convolutional networks (LGCN) and
augmentation memory networks (AMN) to enhance medication recommendation. LGCN
can efficiently encode the patient records and the DDI graph into
low-dimensional embeddings, while AMN can augment the patient representation
with external knowledge from a memory module. We evaluate our model on the
MIMIC-III dataset and show that it outperforms several baselines in terms of
recommendation accuracy and DDI avoidance. We also conduct an ablation study to
analyze the effects of different components of our model. Our results
demonstrate that ALGNet can achieve superior performance with less computation
and more interpretability. The implementation of this paper can be found at:
https://github.com/huyquoctrinh/ALGNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08381">An Explainable Machine Learning Framework for the Accurate Diagnosis of Ovarian Cancer. (arXiv:2312.08381v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Newaz_A/0/1/0/all/0/1">Asif Newaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Taharat_A/0/1/0/all/0/1">Abdullah Taharat</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Md Sakibul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Akanda_A/0/1/0/all/0/1">A.G.M. Fuad Hasan Akanda</a></p>
<p>Ovarian cancer (OC) is one of the most prevalent types of cancer in women.
Early and accurate diagnosis is crucial for the survival of the patients.
However, the majority of women are diagnosed in advanced stages due to the lack
of effective biomarkers and accurate screening tools. While previous studies
sought a common biomarker, our study suggests different biomarkers for the
premenopausal and postmenopausal populations. This can provide a new
perspective in the search for novel predictors for the effective diagnosis of
OC. Lack of explainability is one major limitation of current AI systems. The
stochastic nature of the ML algorithms raises concerns about the reliability of
the system as it is difficult to interpret the reasons behind the decisions. To
increase the trustworthiness and accountability of the diagnostic system as
well as to provide transparency and explanations behind the predictions,
explainable AI has been incorporated into the ML framework. SHAP is employed to
quantify the contributions of the selected biomarkers and determine the most
discriminative features. A hybrid decision support system has been established
that can eliminate the bottlenecks caused by the black-box nature of the ML
algorithms providing a safe and trustworthy AI tool. The diagnostic accuracy
obtained from the proposed system outperforms the existing methods as well as
the state-of-the-art ROMA algorithm by a substantial margin which signifies its
potential to be an effective tool in the differential diagnosis of OC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08383">Improving age prediction: Utilizing LSTM-based dynamic forecasting for data augmentation in multivariate time series analysis. (arXiv:2312.08383v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yutong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_C/0/1/0/all/0/1">Charles A. Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Calhoun_V/0/1/0/all/0/1">Vince D. Calhoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_R/0/1/0/all/0/1">Robyn L. Miller</a></p>
<p>The high dimensionality and complexity of neuroimaging data necessitate large
datasets to develop robust and high-performing deep learning models. However,
the neuroimaging field is notably hampered by the scarcity of such datasets. In
this work, we proposed a data augmentation and validation framework that
utilizes dynamic forecasting with Long Short-Term Memory (LSTM) networks to
enrich datasets. We extended multivariate time series data by predicting the
time courses of independent component networks (ICNs) in both one-step and
recursive configurations. The effectiveness of these augmented datasets was
then compared with the original data using various deep learning models
designed for chronological age prediction tasks. The results suggest that our
approach improves model performance, providing a robust solution to overcome
the challenges presented by the limited size of neuroimaging datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08384">Taking it further: leveraging pseudo labels for field delineation across label-scarce smallholder regions. (arXiv:2312.08384v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rufin_P/0/1/0/all/0/1">Philippe Rufin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sherrie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lisboa_S/0/1/0/all/0/1">S&#xe1; Nogueira Lisboa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemmerling_J/0/1/0/all/0/1">Jan Hemmerling</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulbure_M/0/1/0/all/0/1">Mirela G. Tulbure</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyfroidt_P/0/1/0/all/0/1">Patrick Meyfroidt</a></p>
<p>Transfer learning allows for resource-efficient geographic transfer of
pre-trained field delineation models. However, the scarcity of labeled data for
complex and dynamic smallholder landscapes, particularly in Sub-Saharan Africa,
remains a major bottleneck for large-area field delineation. This study
explores opportunities of using sparse field delineation pseudo labels for
fine-tuning models across geographies and sensor characteristics. We build on a
FracTAL ResUNet trained for crop field delineation in India (median field size
of 0.24 ha) and use this pre-trained model to generate pseudo labels in
Mozambique (median field size of 0.06 ha). We designed multiple pseudo label
selection strategies and compared the quantities, area properties, seasonal
distribution, and spatial agreement of the pseudo labels against
human-annotated training labels (n = 1,512). We then used the human-annotated
labels and the pseudo labels for model fine-tuning and compared predictions
against human field annotations (n = 2,199). Our results indicate i) a good
baseline performance of the pre-trained model in both field delineation and
field size estimation, and ii) the added value of regional fine-tuning with
performance improvements in nearly all experiments. Moreover, we found iii)
substantial performance increases when using only pseudo labels (up to 77% of
the IoU increases and 68% of the RMSE decreases obtained by human labels), and
iv) additional performance increases when complementing human annotations with
pseudo labels. Pseudo labels can be efficiently generated at scale and thus
facilitate domain adaptation in label-scarce settings. The workflow presented
here is a stepping stone for overcoming the persisting data gaps in
heterogeneous smallholder agriculture of Sub-Saharan Africa, where labels are
commonly scarce.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08388">Exploring Graph Based Approaches for Author Name Disambiguation. (arXiv:2312.08388v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rastogi_C/0/1/0/all/0/1">Chetanya Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1">Prabhat Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shreya Singh</a></p>
<p>In many applications, such as scientific literature management, researcher
search, social network analysis and etc, Name Disambiguation (aiming at
disambiguating WhoIsWho) has been a challenging problem. In addition, the
growth of scientific literature makes the problem more difficult and urgent.
Although name disambiguation has been extensively studied in academia and
industry, the problem has not been solved well due to the clutter of data and
the complexity of the same name scenario. In this work, we aim to explore
models that can perform the task of name disambiguation using the network
structure that is intrinsic to the problem and present an analysis of the
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08397">Personalized Decision Supports based on Theory of Mind Modeling and Explainable Reinforcement Learning. (arXiv:2312.08397v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yao Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Keyang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1">Michael Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1">Katia Sycara</a></p>
<p>In this paper, we propose a novel personalized decision support system that
combines Theory of Mind (ToM) modeling and explainable Reinforcement Learning
(XRL) to provide effective and interpretable interventions. Our method
leverages DRL to provide expert action recommendations while incorporating ToM
modeling to understand users' mental states and predict their future actions,
enabling appropriate timing for intervention. To explain interventions, we use
counterfactual explanations based on RL's feature importance and users' ToM
model structure. Our proposed system generates accurate and personalized
interventions that are easily interpretable by end-users. We demonstrate the
effectiveness of our approach through a series of crowd-sourcing experiments in
a simulated team decision-making task, where our system outperforms control
baselines in terms of task performance. Our proposed approach is agnostic to
task environment and RL model structure, therefore has the potential to be
generalized to a wide range of applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08398">Accelerating Meta-Learning by Sharing Gradients. (arXiv:2312.08398v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1">Oscar Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1">Hod Lipson</a></p>
<p>The success of gradient-based meta-learning is primarily attributed to its
ability to leverage related tasks to learn task-invariant information. However,
the absence of interactions between different tasks in the inner loop leads to
task-specific over-fitting in the initial phase of meta-training. While this is
eventually corrected by the presence of these interactions in the outer loop,
it comes at a significant cost of slower meta-learning. To address this
limitation, we explicitly encode task relatedness via an inner loop
regularization mechanism inspired by multi-task learning. Our algorithm shares
gradient information from previously encountered tasks as well as concurrent
tasks in the same task batch, and scales their contribution with meta-learned
parameters. We show using two popular few-shot classification datasets that
gradient sharing enables meta-learning under bigger inner loop learning rates
and can accelerate the meta-training process by up to 134%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08399">Principled Weight Initialization for Hypernetworks. (arXiv:2312.08399v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1">Oscar Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Flokas_L/0/1/0/all/0/1">Lampros Flokas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1">Hod Lipson</a></p>
<p>Hypernetworks are meta neural networks that generate weights for a main
neural network in an end-to-end differentiable manner. Despite extensive
applications ranging from multi-task learning to Bayesian deep learning, the
problem of optimizing hypernetworks has not been studied to date. We observe
that classical weight initialization methods like Glorot &amp; Bengio (2010) and He
et al. (2015), when applied directly on a hypernet, fail to produce weights for
the mainnet in the correct scale. We develop principled techniques for weight
initialization in hypernets, and show that they lead to more stable mainnet
weights, lower training loss, and faster convergence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08401">Balanced and Deterministic Weight-sharing Helps Network Performance. (arXiv:2312.08401v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1">Oscar Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1">Hod Lipson</a></p>
<p>Weight-sharing plays a significant role in the success of many deep neural
networks, by increasing memory efficiency and incorporating useful inductive
priors about the problem into the network. But understanding how weight-sharing
can be used effectively in general is a topic that has not been studied
extensively. Chen et al. [2015] proposed HashedNets, which augments a
multi-layer perceptron with a hash table, as a method for neural network
compression. We generalize this method into a framework (ArbNets) that allows
for efficient arbitrary weight-sharing, and use it to study the role of
weight-sharing in neural networks. We show that common neural networks can be
expressed as ArbNets with different hash functions. We also present two novel
hash functions, the Dirichlet hash and the Neighborhood hash, and use them to
demonstrate experimentally that balanced and deterministic weight-sharing helps
with the performance of a neural network.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08402">LDM$^2$: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement. (arXiv:2312.08402v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingjin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Daniel Zeng</a></p>
<p>With the rapid development of large language models (LLMs), it is highly
demanded that LLMs can be adopted to make decisions to enable the artificial
general intelligence. Most approaches leverage manually crafted examples to
prompt the LLMs to imitate the decision process of human. However, designing
optimal prompts is difficult and the patterned prompts can hardly be
generalized to more complex environments. In this paper, we propose a novel
model named Large Decision Model with Memory (LDM$^2$), which leverages a
dynamic memory mechanism to construct dynamic prompts, guiding the LLMs in
making proper decisions according to the faced state. LDM$^2$ consists of two
stages: memory formation and memory refinement. In the former stage, human
behaviors are decomposed into state-action tuples utilizing the powerful
summarizing ability of LLMs. Then, these tuples are stored in the memory, whose
indices are generated by the LLMs, to facilitate the retrieval of the most
relevant subset of memorized tuples based on the current state. In the latter
stage, our LDM$^2$ employs tree exploration to discover more suitable decision
processes and enrich the memory by adding valuable state-action tuples. The
dynamic circle of exploration and memory enhancement provides LDM$^2$ a better
understanding of the global environment. Extensive experiments conducted in two
interactive environments have shown that our LDM$^2$ outperforms the baselines
in terms of both score and success rate, which demonstrates its effectiveness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08408">Explainable AI in Grassland Monitoring: Enhancing Model Performance and Domain Adaptability. (arXiv:2312.08408v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shanghua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hedstrom_A/0/1/0/all/0/1">Anna Hedstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Basavegowda_D/0/1/0/all/0/1">Deepak Hanike Basavegowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Weltzien_C/0/1/0/all/0/1">Cornelia Weltzien</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_M/0/1/0/all/0/1">Marina M.-C. H&#xf6;hne</a></p>
<p>Grasslands are known for their high biodiversity and ability to provide
multiple ecosystem services. Challenges in automating the identification of
indicator plants are key obstacles to large-scale grassland monitoring. These
challenges stem from the scarcity of extensive datasets, the distributional
shifts between generic and grassland-specific datasets, and the inherent
opacity of deep learning models. This paper delves into the latter two
challenges, with a specific focus on transfer learning and eXplainable
Artificial Intelligence (XAI) approaches to grassland monitoring, highlighting
the novelty of XAI in this domain. We analyze various transfer learning methods
to bridge the distributional gaps between generic and grassland-specific
datasets. Additionally, we showcase how explainable AI techniques can unveil
the model's domain adaptation capabilities, employing quantitative assessments
to evaluate the model's proficiency in accurately centering relevant input
features around the object of interest. This research contributes valuable
insights for enhancing model performance through transfer learning and
measuring domain adaptability with explainable AI, showing significant promise
for broader applications within the agricultural community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08410">Universal Approximation Property of Random Neural Networks. (arXiv:2312.08410v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Neufeld_A/0/1/0/all/0/1">Ariel Neufeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmocker_P/0/1/0/all/0/1">Philipp Schmocker</a></p>
<p>In this paper, we study random neural networks which are single-hidden-layer
feedforward neural networks whose weights and biases are randomly initialized.
After this random initialization, only the linear readout needs to be trained,
which can be performed efficiently, e.g., by the least squares method. By
viewing random neural networks as Banach space-valued random variables, we
prove their universal approximation properties within suitable Bochner spaces.
Hereby, the corresponding Banach space can be more general than the space of
continuous functions over a compact subset of a Euclidean space, namely, e.g.,
an $L^p$-space or a Sobolev space, where the latter includes the approximation
of the derivatives. Moreover, we derive some approximation rates and develop an
explicit algorithm to learn a deterministic function by a random neural
network. In addition, we provide a full error analysis and study when random
neural networks overcome the curse of dimensionality in the sense that the
training costs scale at most polynomially in the input and output dimension.
Furthermore, we show in two numerical examples the empirical advantages of
random neural networks compared to fully trained deterministic neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08413">Privacy Constrained Fairness Estimation for Decision Trees. (arXiv:2312.08413v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Steen_F/0/1/0/all/0/1">Florian van der Steen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vink_F/0/1/0/all/0/1">Fr&#xe9; Vink</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaya_H/0/1/0/all/0/1">Heysem Kaya</a></p>
<p>The protection of sensitive data becomes more vital, as data increases in
value and potency. Furthermore, the pressure increases from regulators and
society on model developers to make their Artificial Intelligence (AI) models
non-discriminatory. To boot, there is a need for interpretable, transparent AI
models for high-stakes tasks. In general, measuring the fairness of any AI
model requires the sensitive attributes of the individuals in the dataset, thus
raising privacy concerns. In this work, the trade-offs between fairness,
privacy and interpretability are further explored. We specifically examine the
Statistical Parity (SP) of Decision Trees (DTs) with Differential Privacy (DP),
that are each popular methods in their respective subfield. We propose a novel
method, dubbed Privacy-Aware Fairness Estimation of Rules (PAFER), that can
estimate SP in a DP-aware manner for DTs. DP, making use of a third-party legal
entity that securely holds this sensitive data, guarantees privacy by adding
noise to the sensitive data. We experimentally compare several DP mechanisms.
We show that using the Laplacian mechanism, the method is able to estimate SP
with low error while guaranteeing the privacy of the individuals in the dataset
with high certainty. We further show experimentally and theoretically that the
method performs better for DTs that humans generally find easier to interpret.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08417">EmbAu: A Novel Technique to Embed Audio Data Using Shuffled Frog Leaping Algorithm. (arXiv:2312.08417v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1">Sahil Nokhwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Pahune_S/0/1/0/all/0/1">Saurabh Pahune</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1">Ankit Chaudhary</a></p>
<p>The aim of steganographic algorithms is to identify the appropriate pixel
positions in the host or cover image, where bits of sensitive information can
be concealed for data encryption. Work is being done to improve the capacity to
integrate sensitive information and to maintain the visual appearance of the
steganographic image. Consequently, steganography is a challenging research
area. In our currently proposed image steganographic technique, we used the
Shuffled Frog Leaping Algorithm (SFLA) to determine the order of pixels by
which sensitive information can be placed in the cover image. To achieve
greater embedding capacity, pixels from the spatial domain of the cover image
are carefully chosen and used for placing the sensitive data. Bolstered via
image steganography, the final image after embedding is resistant to
steganalytic attacks. The SFLA algorithm serves in the optimal pixels selection
of any colored (RGB) cover image for secret bit embedding. Using the fitness
function, the SFLA benefits by reaching a minimum cost value in an acceptable
amount of time. The pixels for embedding are meticulously chosen to minimize
the host image's distortion upon embedding. Moreover, an effort has been taken
to make the detection of embedded data in the steganographic image a formidable
challenge. Due to the enormous need for audio data encryption in the current
world, we feel that our suggested method has significant potential in
real-world applications. In this paper, we propose and compare our strategy to
existing steganographic methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08418">Automatic Bug Detection in Games using LSTM Networks. (arXiv:2312.08418v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Azizi_E/0/1/0/all/0/1">Elham Azizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaman_L/0/1/0/all/0/1">Loutfouz Zaman</a></p>
<p>We introduced a new framework to detect perceptual bugs using a Long
Short-Term Memory (LSTM) network, which detects bugs in video games as
anomalies. The detected buggy frames are then clustered to determine the
category of the occurred bug. The framework was evaluated on two First Person
Shooter (FPS) games. Results show the effectiveness of the framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08461">Space-Time Approximation with Shallow Neural Networks in Fourier Lebesgue spaces. (arXiv:2312.08461v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdeljawad_A/0/1/0/all/0/1">Ahmed Abdeljawad</a>, <a href="http://arxiv.org/find/cs/1/au:+Dittrich_T/0/1/0/all/0/1">Thomas Dittrich</a></p>
<p>Approximation capabilities of shallow neural networks (SNNs) form an integral
part in understanding the properties of deep neural networks (DNNs). In the
study of these approximation capabilities some very popular classes of target
functions are the so-called spectral Barron spaces. This spaces are of special
interest when it comes to the approximation of partial differential equation
(PDE) solutions. It has been shown that the solution of certain static PDEs
will lie in some spectral Barron space. In order to alleviate the limitation to
static PDEs and include a time-domain that might have a different regularity
than the space domain, we extend the notion of spectral Barron spaces to
anisotropic weighted Fourier-Lebesgue spaces. In doing so, we consider target
functions that have two blocks of variables, among which each block is allowed
to have different decay and integrability properties. For these target
functions we first study the inclusion of anisotropic weighted Fourier-Lebesgue
spaces in the Bochner-Sobolev spaces. With that we can now also measure the
approximation error in terms of an anisotropic Sobolev norm, namely the
Bochner-Sobolev norm. We use this observation in a second step where we
establish a bound on the approximation rate for functions from the anisotropic
weighted Fourier-Lebesgue spaces and approximation via SNNs in the
Bochner-Sobolev norm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08470">Best practices for machine learning in antibody discovery and development. (arXiv:2312.08470v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Wossnig_L/0/1/0/all/0/1">Leonard Wossnig</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Furtmann_N/0/1/0/all/0/1">Norbert Furtmann</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Buchanan_A/0/1/0/all/0/1">Andrew Buchanan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kumar_S/0/1/0/all/0/1">Sandeep Kumar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Greiff_V/0/1/0/all/0/1">Victor Greiff</a></p>
<p>Over the past 40 years, the discovery and development of therapeutic
antibodies to treat disease has become common practice. However, as therapeutic
antibody constructs are becoming more sophisticated (e.g., multi-specifics),
conventional approaches to optimisation are increasingly inefficient. Machine
learning (ML) promises to open up an in silico route to antibody discovery and
help accelerate the development of drug products using a reduced number of
experiments and hence cost. Over the past few years, we have observed rapid
developments in the field of ML-guided antibody discovery and development
(D&amp;D). However, many of the results are difficult to compare or hard to assess
for utility by other experts in the field due to the high diversity in the
datasets and evaluation techniques and metrics that are across industry and
academia. This limitation of the literature curtails the broad adoption of ML
across the industry and slows down overall progress in the field, highlighting
the need to develop standards and guidelines that may help improve the
reproducibility of ML models across different research groups. To address these
challenges, we set out in this perspective to critically review current
practices, explain common pitfalls, and clearly define a set of method
development and evaluation guidelines that can be applied to different types of
ML-based techniques for therapeutic antibody D&amp;D. Specifically, we address in
an end-to-end analysis, challenges associated with all aspects of the ML
process and recommend a set of best practices for each stage.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08472">AutoNumerics-Zero: Automated Discovery of State-of-the-Art Mathematical Functions. (arXiv:2312.08472v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Real_E/0/1/0/all/0/1">Esteban Real</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossini_M/0/1/0/all/0/1">Mirko Rossini</a>, <a href="http://arxiv.org/find/cs/1/au:+Souza_C/0/1/0/all/0/1">Connal de Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1">Manav Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Verghese_A/0/1/0/all/0/1">Akhil Verghese</a>, <a href="http://arxiv.org/find/cs/1/au:+Firsching_M/0/1/0/all/0/1">Moritz Firsching</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Cubuk_E/0/1/0/all/0/1">Ekin Dogus Cubuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">David H. Park</a></p>
<p>Computers calculate transcendental functions by approximating them through
the composition of a few limited-precision instructions. For example, an
exponential can be calculated with a Taylor series. These approximation methods
were developed over the centuries by mathematicians, who emphasized the
attainability of arbitrary precision. Computers, however, operate on few
limited precision types, such as the popular float32. In this study, we show
that when aiming for limited precision, existing approximation methods can be
outperformed by programs automatically discovered from scratch by a simple
evolutionary algorithm. In particular, over real numbers, our method can
approximate the exponential function reaching orders of magnitude more
precision for a given number of operations when compared to previous
approaches. More practically, over float32 numbers and constrained to less than
1 ULP of error, the same method attains a speedup over baselines by generating
code that triggers better XLA/LLVM compilation paths. In other words, in both
cases, evolution searched a vast space of possible programs, without knowledge
of mathematics, to discover previously unknown optimized approximations to high
precision, for the first time. We also give evidence that these results extend
beyond the exponential. The ubiquity of transcendental functions suggests that
our method has the potential to reduce the cost of scientific computing
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08489">Connectivity Oracles for Predictable Vertex Failures. (arXiv:2312.08489v1 [cs.DS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bingbing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosinas_E/0/1/0/all/0/1">Evangelos Kosinas</a>, <a href="http://arxiv.org/find/cs/1/au:+Polak_A/0/1/0/all/0/1">Adam Polak</a></p>
<p>The problem of designing connectivity oracles supporting vertex failures is
one of the basic data structures problems for undirected graphs. It is already
well understood: previous works [Duan--Pettie STOC'10; Long--Saranurak FOCS'22]
achieve query time linear in the number of failed vertices, and it is
conditionally optimal as long as we require preprocessing time polynomial in
the size of the graph and update time polynomial in the number of failed
vertices.
</p>
<p>We revisit this problem in the paradigm of algorithms with predictions: we
ask if the query time can be improved if the set of failed vertices can be
predicted beforehand up to a small number of errors. More specifically, we
design a data structure that, given a graph $G=(V,E)$ and a set of vertices
predicted to fail $\widehat{D} \subseteq V$ of size $d=|\widehat{D}|$,
preprocesses it in time $\tilde{O}(d|E|)$ and then can receive an update given
as the symmetric difference between the predicted and the actual set of failed
vertices $\widehat{D} \triangle D = (\widehat{D} \setminus D) \cup (D \setminus
\widehat{D})$ of size $\eta = |\widehat{D} \triangle D|$, process it in time
$\tilde{O}(\eta^4)$, and after that answer connectivity queries in $G \setminus
D$ in time $O(\eta)$. Viewed from another perspective, our data structure
provides an improvement over the state of the art for the \emph{fully dynamic
subgraph connectivity problem} in the \emph{sensitivity setting}
[Henzinger--Neumann ESA'16].
</p>
<p>We argue that the preprocessing time and query time of our data structure are
conditionally optimal under standard fine-grained complexity assumptions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08493">Deep learning-based estimation of time-dependent parameters in Markov models with application to nonlinear regression and SDEs. (arXiv:2312.08493v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kaluza_A/0/1/0/all/0/1">Andrzej Ka&#x142;u&#x17c;a</a>, <a href="http://arxiv.org/find/stat/1/au:+Morkisz_P/0/1/0/all/0/1">Pawe&#x142; M. Morkisz</a>, <a href="http://arxiv.org/find/stat/1/au:+Mulewicz_B/0/1/0/all/0/1">Bart&#x142;omiej Mulewicz</a>, <a href="http://arxiv.org/find/stat/1/au:+Przybylowicz_P/0/1/0/all/0/1">Pawe&#x142; Przyby&#x142;owicz</a>, <a href="http://arxiv.org/find/stat/1/au:+Wiacek_M/0/1/0/all/0/1">Martyna Wi&#x105;cek</a></p>
<p>We present a novel deep learning method for estimating time-dependent
parameters in Markov processes through discrete sampling. Departing from
conventional machine learning, our approach reframes parameter approximation as
an optimization problem using the maximum likelihood approach. Experimental
validation focuses on parameter estimation in multivariate regression and
stochastic differential equations (SDEs). Theoretical results show that the
real solution is close to SDE with parameters approximated using our neural
network-derived under specific conditions. Our work contributes to SDE-based
model parameter estimation, offering a versatile tool for diverse fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08494">PerMod: Perceptually Grounded Voice Modification with Latent Diffusion Models. (arXiv:2312.08494v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Netzorg_R/0/1/0/all/0/1">Robin Netzorg</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalal_A/0/1/0/all/0/1">Ajil Jalal</a>, <a href="http://arxiv.org/find/cs/1/au:+McNulty_L/0/1/0/all/0/1">Luna McNulty</a>, <a href="http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1">Gopala Krishna Anumanchipalli</a></p>
<p>Perceptual modification of voice is an elusive goal. While non-experts can
modify an image or sentence perceptually with available tools, it is not clear
how to similarly modify speech along perceptual axes. Voice conversion does
make it possible to convert one voice to another, but these modifications are
handled by black box models, and the specifics of what perceptual qualities to
modify and how to modify them are unclear. Towards allowing greater perceptual
control over voice, we introduce PerMod, a conditional latent diffusion model
that takes in an input voice and a perceptual qualities vector, and produces a
voice with the matching perceptual qualities. Unlike prior work, PerMod
generates a new voice corresponding to specific perceptual modifications.
Evaluating perceptual quality vectors with RMSE from both human and predicted
labels, we demonstrate that PerMod produces voices with the desired perceptual
qualities for typical voices, but performs poorly on atypical voices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08495">Beyond Accuracy: Automated De-Identification of Large Real-World Clinical Text Datasets. (arXiv:2312.08495v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kocaman_V/0/1/0/all/0/1">Veysel Kocaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Haq_H/0/1/0/all/0/1">Hasham Ul Haq</a>, <a href="http://arxiv.org/find/cs/1/au:+Talby_D/0/1/0/all/0/1">David Talby</a></p>
<p>Recent research advances achieve human-level accuracy for de-identifying
free-text clinical notes on research datasets, but gaps remain in reproducing
this in large real-world settings. This paper summarizes lessons learned from
building a system used to de-identify over one billion real clinical notes, in
a fully automated way, that was independently certified by multiple
organizations for production use. A fully automated solution requires a very
high level of accuracy that does not require manual review. A hybrid
context-based model architecture is described, which outperforms a Named Entity
Recogniton (NER) - only model by 10% on the i2b2-2014 benchmark. The proposed
system makes 50%, 475%, and 575% fewer errors than the comparable AWS, Azure,
and GCP services respectively while also outperforming ChatGPT by 33%. It
exceeds 98% coverage of sensitive data across 7 European languages, without a
need for fine tuning. A second set of described models enable data obfuscation
-- replacing sensitive data with random surrogates -- while retaining name,
date, gender, clinical, and format consistency. Both the practical need and the
solution architecture that provides for reliable &amp; linked anonymized documents
are described.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08511">The Relative Value of Prediction in Algorithmic Decision Making. (arXiv:2312.08511v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Perdomo_J/0/1/0/all/0/1">Juan Carlos Perdomo</a></p>
<p>Algorithmic predictions are increasingly used to inform the allocations of
goods and interventions in the public sphere. In these domains, predictions
serve as a means to an end. They provide stakeholders with insights into
likelihood of future events as a means to improve decision making quality, and
enhance social welfare. However, if maximizing welfare is the ultimate goal,
prediction is only a small piece of the puzzle. There are various other policy
levers a social planner might pursue in order to improve bottom-line outcomes,
such as expanding access to available goods, or increasing the effect sizes of
interventions.
</p>
<p>Given this broad range of design decisions, a basic question to ask is: What
is the relative value of prediction in algorithmic decision making? How do the
improvements in welfare arising from better predictions compare to those of
other policy levers? The goal of our work is to initiate the formal study of
these questions. Our main results are theoretical in nature. We identify
simple, sharp conditions determining the relative value of prediction
vis-\`a-vis expanding access, within several statistical models that are
popular amongst quantitative social scientists. Furthermore, we illustrate how
these theoretical insights may be used to guide the design of algorithmic
decision making systems in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08515">Simplicial Representation Learning with Neural $k$-forms. (arXiv:2312.08515v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maggs_K/0/1/0/all/0/1">Kelly Maggs</a>, <a href="http://arxiv.org/find/cs/1/au:+Hacker_C/0/1/0/all/0/1">Celia Hacker</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1">Bastian Rieck</a></p>
<p>Geometric deep learning extends deep learning to incorporate information
about the geometry and topology data, especially in complex domains like
graphs. Despite the popularity of message passing in this field, it has
limitations such as the need for graph rewiring, ambiguity in interpreting
data, and over-smoothing. In this paper, we take a different approach, focusing
on leveraging geometric information from simplicial complexes embedded in
$\mathbb{R}^n$ using node coordinates. We use differential k-forms in
\mathbb{R}^n to create representations of simplices, offering interpretability
and geometric consistency without message passing. This approach also enables
us to apply differential geometry tools and achieve universal approximation.
Our method is efficient, versatile, and applicable to various input complexes,
including graphs, simplicial complexes, and cell complexes. It outperforms
existing message passing neural networks in harnessing information from
geometrical graphs with node features serving as coordinates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08528">auto-sktime: Automated Time Series Forecasting. (arXiv:2312.08528v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zoller_M/0/1/0/all/0/1">Marc-Andr&#xe9; Z&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1">Marius Lindauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1">Marco F. Huber</a></p>
<p>In today's data-driven landscape, time series forecasting is pivotal in
decision-making across various sectors. Yet, the proliferation of more diverse
time series data, coupled with the expanding landscape of available forecasting
methods, poses significant challenges for forecasters. To meet the growing
demand for efficient forecasting, we introduce auto-sktime, a novel framework
for automated time series forecasting. The proposed framework uses the power of
automated machine learning (AutoML) techniques to automate the creation of the
entire forecasting pipeline. The framework employs Bayesian optimization, to
automatically construct pipelines from statistical, machine learning (ML) and
deep neural network (DNN) models. Furthermore, we propose three essential
improvements to adapt AutoML to time series data: First, pipeline templates to
account for the different supported forecasting models. Second, a novel
warm-starting technique to start the optimization from prior optimization runs.
Third, we adapt multi-fidelity optimizations to make them applicable to a
search space containing statistical, ML and DNN models. Experimental results on
64 diverse real-world time series datasets demonstrate the effectiveness and
efficiency of the framework, outperforming traditional methods while requiring
minimal human involvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08531">Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods. (arXiv:2312.08531v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a></p>
<p>In the past several years, the convergence of the last iterate of the
Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due
to its good performance in practice but lack of theoretical understanding. For
Lipschitz and convex functions, different works have established the optimal
$O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$
high-probability convergence rates for the final iterate, where $T$ is the time
horizon and $\delta$ is the failure probability. However, to prove these
bounds, all the existing works are limited to compact domains or require almost
surely bounded noises. It is natural to ask whether the last iterate of SGD can
still guarantee the optimal convergence rate but without these two restrictive
assumptions. Besides this important question, there are still lots of
theoretical problems lacking an answer. For example, compared with the last
iterate convergence of SGD for non-smooth problems, only few results for smooth
optimization have yet been developed. Additionally, the existing results are
all limited to a non-composite objective and the standard Euclidean norm. It
still remains unclear whether the last-iterate convergence can be provably
extended to wider composite optimization and non-Euclidean norms. In this work,
to address the issues mentioned above, we revisit the last-iterate convergence
of stochastic gradient methods and provide the first unified way to prove the
convergence rates both in expectation and in high probability to accommodate
general domains, composite objectives, non-Euclidean norms, Lipschitz
conditions, smoothness and (strong) convexity simultaneously. Additionally, we
extend our analysis to obtain the last-iterate convergence under heavy-tailed
noises.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08532">Cooperative Learning for Cost-Adaptive Inference. (arXiv:2312.08532v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xingli Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bradford_R/0/1/0/all/0/1">Richard Bradford</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jung-Eun Kim</a></p>
<p>We propose a cooperative training framework for deep neural network
architectures that enables the runtime network depths to change to satisfy
dynamic computing resource requirements. In our framework, the number of layers
participating in computation can be chosen dynamically to meet performance-cost
trade-offs at inference runtime. Our method trains two Teammate nets and a
Leader net, and two sets of Teammate sub-networks with various depths through
knowledge distillation. The Teammate nets derive sub-networks and transfer
knowledge to them, and to each other, while the Leader net guides Teammate nets
to ensure accuracy. The approach trains the framework atomically at once
instead of individually training various sizes of models; in a sense, the
various-sized networks are all trained at once, in a "package deal." The
proposed framework is not tied to any specific architecture but can incorporate
any existing models/architectures, therefore it can maintain stable results and
is insensitive to the size of a dataset's feature map. Compared with other
related approaches, it provides comparable accuracy to its full network while
various sizes of models are available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08533">World Models via Policy-Guided Trajectory Diffusion. (arXiv:2312.08533v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rigter_M/0/1/0/all/0/1">Marc Rigter</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamada_J/0/1/0/all/0/1">Jun Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Posner_I/0/1/0/all/0/1">Ingmar Posner</a></p>
<p>World models are a powerful tool for developing intelligent agents. By
predicting the outcome of a sequence of actions, world models enable policies
to be optimised via on-policy reinforcement learning (RL) using synthetic data,
i.e. in ``in imagination''. Existing world models are autoregressive, and
interleave predicting the next state with sampling the next action from the
policy. Thus, the prediction error inevitably compounds as the trajectory
length grows. In this work, we propose a novel world modelling approach that is
not autoregressive and generates entire on-policy trajectories via a single
pass through a diffusion model. Our approach, Policy-Guided Trajectory
Diffusion (PolyGRAD), leverages a denoising model in addition to the gradient
of the action distribution of the policy to diffuse a trajectory of initially
random states and actions into an on-policy synthetic trajectory. We analyse
the capabilities of our approach and demonstrate that it obtains competitive
prediction errors to state-of-the-art autoregressive baselines. PolyGRAD also
enables performant policies to be trained via on-policy RL in imagination. We
believe that PolyGRAD introduces a promising paradigm for world modelling with
many possible extensions to explore in future work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08535">Occupancy Detection Based on Electricity Consumption. (arXiv:2312.08535v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brilland_T/0/1/0/all/0/1">Thomas Brilland</a>, <a href="http://arxiv.org/find/cs/1/au:+Matheron_G/0/1/0/all/0/1">Guillaume Matheron</a>, <a href="http://arxiv.org/find/cs/1/au:+Leduc_L/0/1/0/all/0/1">Laetitia Leduc</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakada_Y/0/1/0/all/0/1">Yukihide Nakada</a></p>
<p>This article presents a new methodology for extracting intervals when a home
is vacant from low-frequency electricity consumption data. The approach
combines multiple algorithms, including change point detection, classification,
period detection, and periodic spikes retrieval. It shows encouraging results
on both simulated and real consumption curves. This approach offers practical
insights for optimizing energy use and holds potential benefits for residential
consumers and utility companies in terms of energy cost reduction and
sustainability. Further research is needed to enhance its applicability in
diverse settings and with larger datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08536">Markov Decision Processes with Noisy State Observation. (arXiv:2312.08536v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Afsharrad_A/0/1/0/all/0/1">Amirhossein Afsharrad</a>, <a href="http://arxiv.org/find/cs/1/au:+Lall_S/0/1/0/all/0/1">Sanjay Lall</a></p>
<p>This paper addresses the challenge of a particular class of noisy state
observations in Markov Decision Processes (MDPs), a common issue in various
real-world applications. We focus on modeling this uncertainty through a
confusion matrix that captures the probabilities of misidentifying the true
state. Our primary goal is to estimate the inherent measurement noise, and to
this end, we propose two novel algorithmic approaches. The first, the method of
second-order repetitive actions, is designed for efficient noise estimation
within a finite time window, providing identifiable conditions for system
analysis. The second approach comprises a family of Bayesian algorithms, which
we thoroughly analyze and compare in terms of performance and limitations. We
substantiate our theoretical findings with simulations, demonstrating the
effectiveness of our methods in different scenarios, particularly highlighting
their behavior in environments with varying stationary distributions. Our work
advances the understanding of reinforcement learning in noisy environments,
offering robust techniques for more accurate state estimation in MDPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08538">Contractive error feedback for gradient compression. (arXiv:2312.08538v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bingcong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_P/0/1/0/all/0/1">Parameswaran Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Anshumali Shrivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1">Georgios B. Giannakis</a></p>
<p>On-device memory concerns in distributed deep learning have become severe due
to (i) the growth of model size in multi-GPU training, and (ii) the wide
adoption of deep neural networks for federated learning on IoT devices which
have limited storage. In such settings, communication efficient optimization
methods are attractive alternatives, however they still struggle with memory
issues. To tackle these challenges, we propose an communication efficient
method called contractive error feedback (ConEF). As opposed to SGD with
error-feedback (EFSGD) that inefficiently manages memory, ConEF obtains the
sweet spot of convergence and memory usage, and achieves communication
efficiency by leveraging biased and all-reducable gradient compression. We
empirically validate ConEF on various learning tasks that include image
classification, language modeling, and machine translation and observe that
ConEF saves 80\% - 90\% of the extra memory in EFSGD with almost no loss on
test performance, while also achieving 1.3x - 5x speedup of SGD. Through our
work, we also demonstrate the feasibility and convergence of ConEF to clear up
the theoretical barrier of integrating ConEF to popular memory efficient
frameworks such as ZeRO-3.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08550">Harmonics of Learning: Universal Fourier Features Emerge in Invariant Networks. (arXiv:2312.08550v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marchetti_G/0/1/0/all/0/1">Giovanni Luca Marchetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hillar_C/0/1/0/all/0/1">Christopher Hillar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kragic_D/0/1/0/all/0/1">Danica Kragic</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanborn_S/0/1/0/all/0/1">Sophia Sanborn</a></p>
<p>In this work, we formally prove that, under certain conditions, if a neural
network is invariant to a finite group then its weights recover the Fourier
transform on that group. This provides a mathematical explanation for the
emergence of Fourier features -- a ubiquitous phenomenon in both biological and
artificial learning systems. The results hold even for non-commutative groups,
in which case the Fourier transform encodes all the irreducible unitary group
representations. Our findings have consequences for the problem of symmetry
discovery. Specifically, we demonstrate that the algebraic structure of an
unknown group can be recovered from the weights of a network that is at least
approximately invariant within certain bounds. Overall, this work contributes
to a foundation for an algebraic learning theory of invariant neural network
representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08555">KDAS3: Knowledge distillation via Attention Supervision, and Symmetrical structure guiding for Polyp Segmentation. (arXiv:2312.08555v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Trinh_Q/0/1/0/all/0/1">Quoc-Huy Trinh</a></p>
<p>Polyp segmentation, a contentious issue in medical imaging, has seen numerous
proposed methods aimed at improving the quality of segmented masks. Currently,
state-of-the-art techniques yield impressive results. However, the sheer size
of these models poses challenges for practical industry applications. To
address this, we present a Knowledge Distillation framework, incorporating
attention supervision and the symmetrical guiding method. This framework is
designed to facilitate knowledge transfer from a teacher model to a more
compact student model with fewer parameters. Our experimental evaluation of the
framework assesses its effectiveness in enabling the student model to acquire
knowledge from the teacher efficiently. Additionally, our method serves to
prevent the student model from incorporating redundant features that could lead
to inaccurate predictions. Consequently, our method, boasting approximately 5
million parameters, achieves competitive results comparable to the
state-of-the-art approaches. The implementation can be found at:
https://github.com/huyquoctrinh/KDAS3
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08559">Fair Active Learning in Low-Data Regimes. (arXiv:2312.08559v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Camilleri_R/0/1/0/all/0/1">Romain Camilleri</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1">Andrew Wagenmaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgenstern_J/0/1/0/all/0/1">Jamie Morgenstern</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_L/0/1/0/all/0/1">Lalit Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1">Kevin Jamieson</a></p>
<p>In critical machine learning applications, ensuring fairness is essential to
avoid perpetuating social inequities. In this work, we address the challenges
of reducing bias and improving accuracy in data-scarce environments, where the
cost of collecting labeled data prohibits the use of large, labeled datasets.
In such settings, active learning promises to maximize marginal accuracy gains
of small amounts of labeled data. However, existing applications of active
learning for fairness fail to deliver on this, typically requiring large
labeled datasets, or failing to ensure the desired fairness tolerance is met on
the population distribution.
</p>
<p>To address such limitations, we introduce an innovative active learning
framework that combines an exploration procedure inspired by posterior sampling
with a fair classification subroutine. We demonstrate that this framework
performs effectively in very data-scarce regimes, maximizing accuracy while
satisfying fairness constraints with high probability. We evaluate our proposed
approach using well-established real-world benchmark datasets and compare it
against state-of-the-art methods, demonstrating its effectiveness in producing
fair models, and improvement over existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08567">ConFormer: A Novel Collection of Deep Learning Models to Assist Cardiologists in the Assessment of Cardiac Function. (arXiv:2312.08567v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Thomas_E/0/1/0/all/0/1">Ethan Thomas</a>, <a href="http://arxiv.org/find/eess/1/au:+Aslam_S/0/1/0/all/0/1">Salman Aslam</a></p>
<p>Cardiovascular diseases, particularly heart failure, are a leading cause of
death globally. The early detection of heart failure through routine
echocardiogram screenings is often impeded by the high cost and labor-intensive
nature of these procedures, a barrier that can mean the difference between life
and death. This paper presents ConFormer, a novel deep learning model designed
to automate the estimation of Ejection Fraction (EF) and Left Ventricular Wall
Thickness from echocardiograms. The implementation of ConFormer has the
potential to enhance preventative cardiology by enabling cost-effective,
accessible, and comprehensive heart health monitoring, thereby saving countless
lives. The source code is available at https://github.com/Aether111/ConFormer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08579">Identifying Planetary Names in Astronomy Papers: A Multi-Step Approach. (arXiv:2312.08579v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shapurian_G/0/1/0/all/0/1">Golnaz Shapurian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurtz_M/0/1/0/all/0/1">Michael J Kurtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Accomazzi_A/0/1/0/all/0/1">Alberto Accomazzi</a></p>
<p>The automatic identification of planetary feature names in astronomy
publications presents numerous challenges. These features include craters,
defined as roughly circular depressions resulting from impact or volcanic
activity; dorsas, which are elongate raised structures or wrinkle ridges; and
lacus, small irregular patches of dark, smooth material on the Moon, referred
to as "lake" (Planetary Names Working Group, n.d.). Many feature names overlap
with places or people's names that they are named after, for example, Syria,
Tempe, Einstein, and Sagan, to name a few (U.S. Geological Survey, n.d.). Some
feature names have been used in many contexts, for instance, Apollo, which can
refer to mission, program, sample, astronaut, seismic, seismometers, core, era,
data, collection, instrument, and station, in addition to the crater on the
Moon. Some feature names can appear in the text as adjectives, like the lunar
craters Black, Green, and White. Some feature names in other contexts serve as
directions, like craters West and South on the Moon. Additionally, some
features share identical names across different celestial bodies, requiring
disambiguation, such as the Adams crater, which exists on both the Moon and
Mars. We present a multi-step pipeline combining rule-based filtering,
statistical relevance analysis, part-of-speech (POS) tagging, named entity
recognition (NER) model, hybrid keyword harvesting, knowledge graph (KG)
matching, and inference with a locally installed large language model (LLM) to
reliably identify planetary names despite these challenges. When evaluated on a
dataset of astronomy papers from the Astrophysics Data System (ADS), this
methodology achieves an F1-score over 0.97 in disambiguating planetary feature
names.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08585">Unraveling Key Factors of Knowledge Distillation. (arXiv:2312.08585v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jingxuan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Linzhuang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bihui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1">Ruifeng Guo</a></p>
<p>Knowledge distillation, a technique for model compression and performance
enhancement, has gained significant traction in Neural Machine Translation
(NMT). However, existing research primarily focuses on empirical applications,
and there is a lack of comprehensive understanding of how student model
capacity, data complexity, and decoding strategies collectively influence
distillation effectiveness. Addressing this gap, our study conducts an in-depth
investigation into these factors, particularly focusing on their interplay in
word-level and sequence-level distillation within NMT. Through extensive
experimentation across datasets like IWSLT13 En$\rightarrow$Fr, IWSLT14
En$\rightarrow$De, and others, we empirically validate hypotheses related to
the impact of these factors on knowledge distillation. Our research not only
elucidates the significant influence of model capacity, data complexity, and
decoding strategies on distillation effectiveness but also introduces a novel,
optimized distillation approach. This approach, when applied to the IWSLT14
de$\rightarrow$en translation task, achieves state-of-the-art performance,
demonstrating its practical efficacy in advancing the field of NMT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08586">Estimating calibration error under label shift without labels. (arXiv:2312.08586v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Popordanoska_T/0/1/0/all/0/1">Teodora Popordanoska</a>, <a href="http://arxiv.org/find/cs/1/au:+Radevski_G/0/1/0/all/0/1">Gorjan Radevski</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1">Tinne Tuytelaars</a>, <a href="http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1">Matthew B. Blaschko</a></p>
<p>In the face of dataset shift, model calibration plays a pivotal role in
ensuring the reliability of machine learning systems. Calibration error (CE) is
an indicator of the alignment between the predicted probabilities and the
classifier accuracy. While prior works have delved into the implications of
dataset shift on calibration, existing CE estimators assume access to labels
from the target domain, which are often unavailable in practice, i.e., when the
model is deployed and used. This work addresses such challenging scenario, and
proposes a novel CE estimator under label shift, which is characterized by
changes in the marginal label distribution $p(Y)$, while keeping the
conditional $p(X|Y)$ constant between the source and target distributions. Our
contribution is an approach, which, by leveraging importance re-weighting of
the labeled source distribution, provides consistent and asymptotically
unbiased CE estimation with respect to the shifted target distribution.
Empirical results across diverse real-world datasets, under various conditions
and label-shift intensities, demonstrate the effectiveness and reliability of
the proposed estimator.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08589">Consistent and Asymptotically Unbiased Estimation of Proper Calibration Errors. (arXiv:2312.08589v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Popordanoska_T/0/1/0/all/0/1">Teodora Popordanoska</a>, <a href="http://arxiv.org/find/cs/1/au:+Gruber_S/0/1/0/all/0/1">Sebastian G. Gruber</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiulpin_A/0/1/0/all/0/1">Aleksei Tiulpin</a>, <a href="http://arxiv.org/find/cs/1/au:+Buettner_F/0/1/0/all/0/1">Florian Buettner</a>, <a href="http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1">Matthew B. Blaschko</a></p>
<p>Proper scoring rules evaluate the quality of probabilistic predictions,
playing an essential role in the pursuit of accurate and well-calibrated
models. Every proper score decomposes into two fundamental components -- proper
calibration error and refinement -- utilizing a Bregman divergence. While
uncertainty calibration has gained significant attention, current literature
lacks a general estimator for these quantities with known statistical
properties. To address this gap, we propose a method that allows consistent,
and asymptotically unbiased estimation of all proper calibration errors and
refinement terms. In particular, we introduce Kullback--Leibler calibration
error, induced by the commonly used cross-entropy loss. As part of our results,
we prove the relation between refinement and f-divergences, which implies
information monotonicity in neural networks, regardless of which proper scoring
rule is optimized. Our experiments validate empirically the claimed properties
of the proposed estimator and suggest that the selection of a post-hoc
calibration method should be determined by the particular calibration error of
interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08598">MotherNet: A Foundational Hypernetwork for Tabular Classification. (arXiv:2312.08598v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Muller_A/0/1/0/all/0/1">Andreas M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Curino_C/0/1/0/all/0/1">Carlo Curino</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_R/0/1/0/all/0/1">Raghu Ramakrishnan</a></p>
<p>The advent of Foundation Models is transforming machine learning across many
modalities (e.g., language, images, videos) with prompt engineering replacing
training in many settings. Recent work on tabular data (e.g., TabPFN) hints at
a similar opportunity to build Foundation Models for classification for
numerical data. In this paper, we go one step further and propose a
hypernetwork architecture that we call MotherNet, trained on millions of
classification tasks, that, once prompted with a never-seen-before training set
generates the weights of a trained ``child'' neural-network. Like other
Foundation Models, MotherNet replaces training on specific datasets with
in-context learning through a single forward pass. In contrast to existing
hypernetworks that were either task-specific or trained for relatively
constraint multi-task settings, MotherNet is trained to generate networks to
perform multiclass classification on arbitrary tabular datasets without any
dataset specific gradient descent.
</p>
<p>The child network generated by MotherNet using in-context learning
outperforms neural networks trained using gradient descent on small datasets,
and is competitive with predictions by TabPFN and standard ML methods like
Gradient Boosting. Unlike a direct application of transformer models like
TabPFN, MotherNet generated networks are highly efficient at inference time.
This methodology opens up a new approach to building predictive models on
tabular data that is both efficient and robust, without any dataset-specific
training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08602">Omega-Regular Decision Processes. (arXiv:2312.08602v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hahn_E/0/1/0/all/0/1">Ernst Moritz Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1">Mateo Perez</a>, <a href="http://arxiv.org/find/cs/1/au:+Schewe_S/0/1/0/all/0/1">Sven Schewe</a>, <a href="http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1">Fabio Somenzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1">Ashutosh Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1">Dominik Wojtczak</a></p>
<p>Regular decision processes (RDPs) are a subclass of non-Markovian decision
processes where the transition and reward functions are guarded by some regular
property of the past (a lookback). While RDPs enable intuitive and succinct
representation of non-Markovian decision processes, their expressive power
coincides with finite-state Markov decision processes (MDPs). We introduce
omega-regular decision processes (ODPs) where the non-Markovian aspect of the
transition and reward functions are extended to an omega-regular lookahead over
the system evolution. Semantically, these lookaheads can be considered as
promises made by the decision maker or the learning agent about her future
behavior. In particular, we assume that, if the promised lookaheads are not
met, then the payoff to the decision maker is $\bot$ (least desirable payoff),
overriding any rewards collected by the decision maker. We enable optimization
and learning for ODPs under the discounted-reward objective by reducing them to
lexicographic optimization and learning over finite MDPs. We present
experimental results demonstrating the effectiveness of the proposed reduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08604">Verification of Neural Reachable Tubes via Scenario Optimization and Conformal Prediction. (arXiv:2312.08604v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1">Albert Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_S/0/1/0/all/0/1">Somil Bansal</a></p>
<p>Learning-based approaches for controlling safety-critical systems are rapidly
growing in popularity; thus, it is important to assure their performance and
safety. Hamilton-Jacobi (HJ) reachability analysis is a popular formal
verification tool for providing such guarantees, since it can handle general
nonlinear system dynamics, bounded adversarial system disturbances, and state
and input constraints. However, its computational and memory complexity scales
exponentially with the state dimension, making it intractable for large-scale
systems. To overcome this challenge, neural approaches, such as DeepReach, have
been used to synthesize reachable tubes and safety controllers for
high-dimensional systems. However, verifying these neural reachable tubes
remains challenging. In this work, we propose two verification methods, based
on robust scenario optimization and conformal prediction, to provide
probabilistic safety guarantees for neural reachable tubes. Our methods allow a
direct trade-off between resilience to outlier errors in the neural tube, which
are inevitable in a learning-based approach, and the strength of the
probabilistic safety guarantee. Furthermore, we show that split conformal
prediction, a widely used method in the machine learning community for
uncertainty quantification, reduces to a scenario-based approach, making the
two methods equivalent not only for verification of neural reachable tubes but
also more generally. To our knowledge, our proof is the first in the literature
to show a strong relationship between conformal prediction and scenario
optimization. Finally, we propose an outlier-adjusted verification approach
that uses the error distribution in neural reachable tubes to recover greater
safe volumes. We demonstrate the efficacy of the proposed approaches for the
high-dimensional problems of multi-vehicle collision avoidance and rocket
landing with no-go zones.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08622">Scalable Ensemble-based Detection Method against Adversarial Attacks for speaker verification. (arXiv:2312.08622v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wu_H/0/1/0/all/0/1">Haibin Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kuo_H/0/1/0/all/0/1">Heng-Cheng Kuo</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1">Yu Tsao</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a></p>
<p>Automatic speaker verification (ASV) is highly susceptible to adversarial
attacks. Purification modules are usually adopted as a pre-processing to
mitigate adversarial noise. However, they are commonly implemented across
diverse experimental settings, rendering direct comparisons challenging. This
paper comprehensively compares mainstream purification techniques in a unified
framework. We find these methods often face a trade-off between user experience
and security, as they struggle to simultaneously maintain genuine sample
performance and reduce adversarial perturbations. To address this challenge,
some efforts have extended purification modules to encompass detection
capabilities, aiming to alleviate the trade-off. However, advanced purification
modules will always come into the stage to surpass previous detection method.
As a result, we further propose an easy-to-follow ensemble approach that
integrates advanced purification modules for detection, achieving
state-of-the-art (SOTA) performance in countering adversarial noise. Our
ensemble method has great potential due to its compatibility with future
advanced purification techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08625">Graph Network Surrogate Model for Subsurface Flow Optimization. (arXiv:2312.08625v1 [physics.geo-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Tang_H/0/1/0/all/0/1">Haoyu Tang</a>, <a href="http://arxiv.org/find/physics/1/au:+Durlofsky_L/0/1/0/all/0/1">Louis J. Durlofsky</a></p>
<p>The optimization of well locations and controls is an important step in the
design of subsurface flow operations such as oil production or geological CO2
storage. These optimization problems can be computationally expensive, however,
as many potential candidate solutions must be evaluated. In this study, we
propose a graph network surrogate model (GNSM) for optimizing well placement
and controls. The GNSM transforms the flow model into a computational graph
that involves an encoding-processing-decoding architecture. Separate networks
are constructed to provide global predictions for the pressure and saturation
state variables. Model performance is enhanced through the inclusion of the
single-phase steady-state pressure solution as a feature. A multistage
multistep strategy is used for training. The trained GNSM is applied to predict
flow responses in a 2D unstructured model of a channelized reservoir. Results
are presented for a large set of test cases, in which five injection wells and
five production wells are placed randomly throughout the model, with a random
control variable (bottom-hole pressure) assigned to each well. Median relative
error in pressure and saturation for 300 such test cases is 1-2%. The ability
of the trained GNSM to provide accurate predictions for a new (geologically
similar) permeability realization is demonstrated. Finally, the trained GNSM is
used to optimize well locations and controls with a differential evolution
algorithm. GNSM-based optimization results are comparable to those from
simulation-based optimization, with a runtime speedup of a factor of 36. Much
larger speedups are expected if the method is used for robust optimization, in
which each candidate solution is evaluated on multiple geological models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08651">Towards Inductive Robustness: Distilling and Fostering Wave-induced Resonance in Transductive GCNs Against Graph Adversarial Attacks. (arXiv:2312.08651v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Ao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenshan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hanyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a></p>
<p>Graph neural networks (GNNs) have recently been shown to be vulnerable to
adversarial attacks, where slight perturbations in the graph structure can lead
to erroneous predictions. However, current robust models for defending against
such attacks inherit the transductive limitations of graph convolutional
networks (GCNs). As a result, they are constrained by fixed structures and do
not naturally generalize to unseen nodes. Here, we discover that transductive
GCNs inherently possess a distillable robustness, achieved through a
wave-induced resonance process. Based on this, we foster this resonance to
facilitate inductive and robust learning. Specifically, we first prove that the
signal formed by GCN-driven message passing (MP) is equivalent to the
edge-based Laplacian wave, where, within a wave system, resonance can naturally
emerge between the signal and its transmitting medium. This resonance provides
inherent resistance to malicious perturbations inflicted on the signal system.
We then prove that merely three MP iterations within GCNs can induce signal
resonance between nodes and edges, manifesting as a coupling between nodes and
their distillable surrounding local subgraph. Consequently, we present Graph
Resonance-fostering Network (GRN) to foster this resonance via learning node
representations from their distilled resonating subgraphs. By capturing the
edge-transmitted signals within this subgraph and integrating them with the
node signal, GRN embeds these combined signals into the central node's
representation. This node-wise embedding approach allows for generalization to
unseen nodes. We validate our theoretical findings with experiments, and
demonstrate that GRN generalizes robustness to unseen nodes, whilst maintaining
state-of-the-art classification accuracy on perturbed graphs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08654">Automated detection of Zika and dengue in Aedes aegypti using neural spiking analysis. (arXiv:2312.08654v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Javed_N/0/1/0/all/0/1">Nouman Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Paradkar_P/0/1/0/all/0/1">Prasad N. Paradkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_U/0/1/0/all/0/1">U. Rajendra Acharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatti_A/0/1/0/all/0/1">Asim Bhatti</a></p>
<p>Mosquito-borne diseases present considerable risks to the health of both
animals and humans. Aedes aegypti mosquitoes are the primary vectors for
numerous medically important viruses such as dengue, Zika, yellow fever, and
chikungunya. To characterize this mosquito neural activity, it is essential to
classify the generated electrical spikes. However, no open-source neural spike
classification method is currently available for mosquitoes. Our work presented
in this paper provides an innovative artificial intelligence-based method to
classify the neural spikes in uninfected, dengue-infected, and Zika-infected
mosquitoes. Aiming for outstanding performance, the method employs a fusion of
normalization, feature importance, and dimension reduction for the
preprocessing and combines convolutional neural network and extra gradient
boosting (XGBoost) for classification. The method uses the electrical spiking
activity data of mosquito neurons recorded by microelectrode array technology.
We used data from 0, 1, 2, 3, and 7 days post-infection, containing over 15
million samples, to analyze the method's performance. The performance of the
proposed method was evaluated using accuracy, precision, recall, and the F1
scores. The results obtained from the method highlight its remarkable
performance in differentiating infected vs uninfected mosquito samples,
achieving an average of 98.1%. The performance was also compared with 6 other
machine learning algorithms to further assess the method's capability. The
method outperformed all other machine learning algorithms' performance.
Overall, this research serves as an efficient method to classify the neural
spikes of Aedes aegypti mosquitoes and can assist in unraveling the complex
interactions between pathogens and mosquitoes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08656">MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training. (arXiv:2312.08656v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hongwu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Shivdikar_K/0/1/0/all/0/1">Kaustubh Shivdikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">MD Amit Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiahui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shaoyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_O/0/1/0/all/0/1">Omer Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaeli_D/0/1/0/all/0/1">David Kaeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Caiwen Ding</a></p>
<p>In the acceleration of deep neural network training, the GPU has become the
mainstream platform. GPUs face substantial challenges on GNNs, such as workload
imbalance and memory access irregularities, leading to underutilized hardware.
Existing solutions such as PyG, DGL with cuSPARSE, and GNNAdvisor frameworks
partially address these challenges but memory traffic is still significant.
</p>
<p>We argue that drastic performance improvements can only be achieved by the
vertical optimization of algorithm and system innovations, rather than treating
the speedup optimization as an "after-thought" (i.e., (i) given a GNN
algorithm, designing an accelerator, or (ii) given hardware, mainly optimizing
the GNN algorithm). In this paper, we present MaxK-GNN, an advanced
high-performance GPU training system integrating algorithm and system
innovation. (i) We introduce the MaxK nonlinearity and provide a theoretical
analysis of MaxK nonlinearity as a universal approximator, and present the
Compressed Balanced Sparse Row (CBSR) format, designed to store the data and
index of the feature matrix after nonlinearity; (ii) We design a coalescing
enhanced forward computation with row-wise product-based SpGEMM Kernel using
CBSR for input feature matrix fetching and strategic placement of a sparse
output accumulation buffer in shared memory; (iii) We develop an optimized
backward computation with outer product-based and SSpMM Kernel.
</p>
<p>We conduct extensive evaluations of MaxK-GNN and report the end-to-end system
run-time. Experiments show that MaxK-GNN system could approach the theoretical
speedup limit according to Amdahl's law. We achieve comparable accuracy to SOTA
GNNs, but at a significantly increased speed: 3.22/4.24 times speedup (vs.
theoretical limits, 5.52/7.27 times) on Reddit compared to DGL and GNNAdvisor
implementations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08658">Real-time Autonomous Control of a Continuous Macroscopic Process as Demonstrated by Plastic Forming. (arXiv:2312.08658v1 [cond-mat.soft])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Muroga_S/0/1/0/all/0/1">Shun Muroga</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Honda_T/0/1/0/all/0/1">Takashi Honda</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Miki_Y/0/1/0/all/0/1">Yasuaki Miki</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Nakajima_H/0/1/0/all/0/1">Hideaki Nakajima</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Futaba_D/0/1/0/all/0/1">Don N. Futaba</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Hata_K/0/1/0/all/0/1">Kenji Hata</a></p>
<p>To meet the demands for more adaptable and expedient approaches to augment
both research and manufacturing, we report an autonomous system using real-time
in-situ characterization and an autonomous, decision-making processer based on
an active learning algorithm. This system was applied to a plastic film forming
system to highlight its efficiency and accuracy in determining the process
conditions for specified target film dimensions, importantly, without any human
intervention. Application of this system towards nine distinct film dimensions
demonstrated the system ability to quickly determine the appropriate and stable
process conditions (average 11 characterization-adjustment iterations, 19
minutes) and the ability to avoid traps, such as repetitive over-correction.
Furthermore, comparison of the achieved film dimensions to the target values
showed a high accuracy (R2 = 0.87, 0.90) for film width and thickness,
respectively. In addition, the use of an active learning algorithm afforded our
system to proceed optimization with zero initial training data, which was
unavailable due to the complex relationships between the control factors
(material supply rate, applied force, material viscosity) within the plastic
forming process. As our system is intrinsically general and can be applied to
any most material processes, these results have significant implications in
accelerating both research and industrial processes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08670">Temporal-Spatial Entropy Balancing for Causal Continuous Treatment-Effect Estimation. (arXiv:2312.08670v1 [stat.ME])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Hu_T/0/1/0/all/0/1">Tao Hu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1">Honglong Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeng_F/0/1/0/all/0/1">Fan Zeng</a>, <a href="http://arxiv.org/find/stat/1/au:+Du_M/0/1/0/all/0/1">Min Du</a>, <a href="http://arxiv.org/find/stat/1/au:+Du_X/0/1/0/all/0/1">XiangKun Du</a>, <a href="http://arxiv.org/find/stat/1/au:+Zheng_Y/0/1/0/all/0/1">Yue Zheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1">Mengran Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_D/0/1/0/all/0/1">Dan Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_J/0/1/0/all/0/1">Jihao Wu</a></p>
<p>In the field of intracity freight transportation, changes in order volume are
significantly influenced by temporal and spatial factors. When building subsidy
and pricing strategies, predicting the causal effects of these strategies on
order volume is crucial. In the process of calculating causal effects,
confounding variables can have an impact. Traditional methods to control
confounding variables handle data from a holistic perspective, which cannot
ensure the precision of causal effects in specific temporal and spatial
dimensions. However, temporal and spatial dimensions are extremely critical in
the logistics field, and this limitation may directly affect the precision of
subsidy and pricing strategies. To address these issues, this study proposes a
technique based on flexible temporal-spatial grid partitioning. Furthermore,
based on the flexible grid partitioning technique, we further propose a
continuous entropy balancing method in the temporal-spatial domain, which named
TS-EBCT (Temporal-Spatial Entropy Balancing for Causal Continue Treatments).
The method proposed in this paper has been tested on two simulation datasets
and two real datasets, all of which have achieved excellent performance. In
fact, after applying the TS-EBCT method to the intracity freight transportation
field, the prediction accuracy of the causal effect has been significantly
improved. It brings good business benefits to the company's subsidy and pricing
strategies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08671">Uplifting the Expressive Power of Graph Neural Networks through Graph Partitioning. (arXiv:2312.08671v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hevapathige_A/0/1/0/all/0/1">Asela Hevapathige</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a></p>
<p>Graph Neural Networks (GNNs) have paved its way for being a cornerstone in
graph related learning tasks. From a theoretical perspective, the expressive
power of GNNs is primarily characterised according to their ability to
distinguish non-isomorphic graphs. It is a well-known fact that most of the
conventional GNNs are upper-bounded by Weisfeiler-Lehman graph isomorphism test
(1-WL). In this work, we study the expressive power of graph neural networks
through the lens of graph partitioning. This follows from our observation that
permutation invariant graph partitioning enables a powerful way of exploring
structural interactions among vertex sets and subgraphs, and can help uplifting
the expressive power of GNNs efficiently. Based on this, we first establish a
theoretical connection between graph partitioning and graph isomorphism. Then
we introduce a novel GNN architecture, namely Graph Partitioning Neural
Networks (GPNNs). We theoretically analyse how a graph partitioning scheme and
different kinds of structural interactions relate to the k-WL hierarchy.
Empirically, we demonstrate its superior performance over existing GNN models
in a variety of graph benchmark tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08672">CAT: A Causally Graph Attention Network for Trimming Heterophilic Graph. (arXiv:2312.08672v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Silu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1">Qinyao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xinsha Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Ling Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_R/0/1/0/all/0/1">Ronghua Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lia_H/0/1/0/all/0/1">Haifeng Lia</a></p>
<p>Local Attention-guided Message Passing Mechanism (LAMP) adopted in Graph
Attention Networks (GATs) is designed to adaptively learn the importance of
neighboring nodes for better local aggregation on the graph, which can bring
the representations of similar neighbors closer effectively, thus showing
stronger discrimination ability. However, existing GATs suffer from a
significant discrimination ability decline in heterophilic graphs because the
high proportion of dissimilar neighbors can weaken the self-attention of the
central node, jointly resulting in the deviation of the central node from
similar nodes in the representation space. This kind of effect generated by
neighboring nodes is called the Distraction Effect (DE) in this paper. To
estimate and weaken the DE of neighboring nodes, we propose a Causally graph
Attention network for Trimming heterophilic graph (CAT). To estimate the DE,
since the DE are generated through two paths (grab the attention assigned to
neighbors and reduce the self-attention of the central node), we use Total
Effect to model DE, which is a kind of causal estimand and can be estimated
from intervened data; To weaken the DE, we identify the neighbors with the
highest DE (we call them Distraction Neighbors) and remove them. We adopt three
representative GATs as the base model within the proposed CAT framework and
conduct experiments on seven heterophilic datasets in three different sizes.
Comparative experiments show that CAT can improve the node classification
accuracy of all base GAT models. Ablation experiments and visualization further
validate the enhancement of discrimination ability brought by CAT. The source
code is available at https://github.com/GeoX-Lab/CAT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08677">Adaptive Shortcut Debiasing for Online Continual Learning. (arXiv:2312.08677v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Doyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dongmin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yooju Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bang_J/0/1/0/all/0/1">Jihwan Bang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hwanjun Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae-Gil Lee</a></p>
<p>We propose a novel framework DropTop that suppresses the shortcut bias in
online continual learning (OCL) while being adaptive to the varying degree of
the shortcut bias incurred by continuously changing environment. By the
observed high-attention property of the shortcut bias, highly-activated
features are considered candidates for debiasing. More importantly, resolving
the limitation of the online environment where prior knowledge and auxiliary
data are not ready, two novel techniques -- feature map fusion and adaptive
intensity shifting -- enable us to automatically determine the appropriate
level and proportion of the candidate shortcut features to be dropped.
Extensive experiments on five benchmark datasets demonstrate that, when
combined with various OCL algorithms, DropTop increases the average accuracy by
up to 10.4% and decreases the forgetting by up to 63.2%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08678">Deep Learning with Physics Priors as Generalized Regularizers. (arXiv:2312.08678v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Frank Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Agniva Chowdhury</a></p>
<p>In various scientific and engineering applications, there is typically an
approximate model of the underlying complex system, even though it contains
both aleatoric and epistemic uncertainties. In this paper, we present a
principled method to incorporate these approximate models as physics priors in
modeling, to prevent overfitting and enhancing the generalization capabilities
of the trained models. Utilizing the structural risk minimization (SRM)
inductive principle pioneered by Vapnik, this approach structures the physics
priors into generalized regularizers. The experimental results demonstrate that
our method achieves up to two orders of magnitude of improvement in testing
accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08685">Privacy Amplification by Iteration for ADMM with (Strongly) Convex Objective Functions. (arXiv:2312.08685v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1">T-H. Hubert Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Hao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengshi Zhao</a></p>
<p>We examine a private ADMM variant for (strongly) convex objectives which is a
primal-dual iterative method. Each iteration has a user with a private function
used to update the primal variable, masked by Gaussian noise for local privacy,
without directly adding noise to the dual variable. Privacy amplification by
iteration explores if noises from later iterations can enhance the privacy
guarantee when releasing final variables after the last iteration. Cyffers et
al. [ICML 2023] explored privacy amplification by iteration for the proximal
ADMM variant, where a user's entire private function is accessed and noise is
added to the primal variable. In contrast, we examine a private ADMM variant
requiring just one gradient access to a user's function, but both primal and
dual variables must be passed between successive iterations. To apply Balle et
al.'s [NeurIPS 2019] coupling framework to the gradient ADMM variant, we tackle
technical challenges with novel ideas. First, we address the non-expansive
mapping issue in ADMM iterations by using a customized norm. Second, because
the dual variables are not masked with any noise directly, their privacy
guarantees are achieved by treating two consecutive noisy ADMM iterations as a
Markov operator. Our main result is that the privacy guarantee for the gradient
ADMM variant can be amplified proportionally to the number of iterations. For
strongly convex objective functions, this amplification exponentially increases
with the number of iterations. These amplification results align with the
previously studied special case of stochastic gradient descent.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08697">Incomplete Contrastive Multi-View Clustering with High-Confidence Guiding. (arXiv:2312.08697v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chao_G/0/1/0/all/0/1">Guoqing Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_D/0/1/0/all/0/1">Dianhui Chu</a></p>
<p>Incomplete multi-view clustering becomes an important research problem, since
multi-view data with missing values are ubiquitous in real-world applications.
Although great efforts have been made for incomplete multi-view clustering,
there are still some challenges: 1) most existing methods didn't make full use
of multi-view information to deal with missing values; 2) most methods just
employ the consistent information within multi-view data but ignore the
complementary information; 3) For the existing incomplete multi-view clustering
methods, incomplete multi-view representation learning and clustering are
treated as independent processes, which leads to performance gap. In this work,
we proposed a novel Incomplete Contrastive Multi-View Clustering method with
high-confidence guiding (ICMVC). Firstly, we proposed a multi-view consistency
relation transfer plus graph convolutional network to tackle missing values
problem. Secondly, instance-level attention fusion and high-confidence guiding
are proposed to exploit the complementary information while instance-level
contrastive learning for latent representation is designed to employ the
consistent information. Thirdly, an end-to-end framework is proposed to
integrate multi-view missing values handling, multi-view representation
learning and clustering assignment for joint optimization. Experiments compared
with state-of-the-art approaches demonstrated the effectiveness and superiority
of our method. Our code is publicly available at
https://github.com/liunian-Jay/ICMVC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08700">RdimKD: Generic Distillation Paradigm by Dimensionality Reduction. (arXiv:2312.08700v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yiqian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1">Haotong Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_V/0/1/0/all/0/1">Van Tung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shouda Liu</a></p>
<p>Knowledge Distillation (KD) emerges as one of the most promising compression
technologies to run advanced deep neural networks on resource-limited devices.
In order to train a small network (student) under the guidance of a large
network (teacher), the intuitive method is regularizing the feature maps or
logits of the student using the teacher's information. However, existing
methods either over-restrict the student to learn all information from the
teacher, which lead to some bad local minimum, or use various fancy and
elaborate modules to process and align features, which are complex and lack
generality. In this work, we proposed an abstract and general paradigm for the
KD task, referred to as DIMensionality Reduction KD (RdimKD), which solely
relies on dimensionality reduction, with a very minor modification to naive L2
loss. RdimKD straightforwardly utilizes a projection matrix to project both the
teacher's and student's feature maps onto a low-dimensional subspace, which are
then optimized during training. RdimKD achieves the goal in the simplest way
that not only does the student get valuable information from the teacher, but
it also ensures sufficient flexibility to adapt to the student's low-capacity
reality. Our extensive empirical findings indicate the effectiveness of RdimKD
across various learning tasks and diverse network architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08710">Gradient Informed Proximal Policy Optimization. (arXiv:2312.08710v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Son_S/0/1/0/all/0/1">Sanghyun Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Laura Yu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_R/0/1/0/all/0/1">Ryan Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yi-Ling Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Ming C. Lin</a></p>
<p>We introduce a novel policy learning method that integrates analytical
gradients from differentiable environments with the Proximal Policy
Optimization (PPO) algorithm. To incorporate analytical gradients into the PPO
framework, we introduce the concept of an {\alpha}-policy that stands as a
locally superior policy. By adaptively modifying the {\alpha} value, we can
effectively manage the influence of analytical policy gradients during
learning. To this end, we suggest metrics for assessing the variance and bias
of analytical gradients, reducing dependence on these gradients when high
variance or bias is detected. Our proposed approach outperforms baseline
algorithms in various scenarios, such as function optimization, physics
simulations, and traffic control environments. Our code can be found online:
https://github.com/SonSang/gippo.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08723">StemGen: A music generation model that listens. (arXiv:2312.08723v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Parker_J/0/1/0/all/0/1">Julian D. Parker</a>, <a href="http://arxiv.org/find/cs/1/au:+Spijkervet_J/0/1/0/all/0/1">Janne Spijkervet</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosta_K/0/1/0/all/0/1">Katerina Kosta</a>, <a href="http://arxiv.org/find/cs/1/au:+Yesiler_F/0/1/0/all/0/1">Furkan Yesiler</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuznetsov_B/0/1/0/all/0/1">Boris Kuznetsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Ju-Chiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Avent_M/0/1/0/all/0/1">Matt Avent</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jitong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1">Duc Le</a></p>
<p>End-to-end generation of musical audio using deep learning techniques has
seen an explosion of activity recently. However, most models concentrate on
generating fully mixed music in response to abstract conditioning information.
In this work, we present an alternative paradigm for producing music generation
models that can listen and respond to musical context. We describe how such a
model can be constructed using a non-autoregressive, transformer-based model
architecture and present a number of novel architectural and sampling
improvements. We train the described architecture on both an open-source and a
proprietary dataset. We evaluate the produced models using standard quality
metrics and a new approach based on music information retrieval descriptors.
The resulting model reaches the audio quality of state-of-the-art
text-conditioned models, as well as exhibiting strong musical coherence with
its context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08724">Personalized Path Recourse. (arXiv:2312.08724v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Dat Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tong Wang</a></p>
<p>This paper introduces Personalized Path Recourse, a novel method that
generates recourse paths for an agent. The objective is to achieve desired
goals (e.g., better outcomes compared to the agent's original paths of action),
while ensuring a high similarity to the agent's original paths and being
personalized to the agent. Personalization refers to the extent to which the
new path is tailored to the agent's observed behavior patterns from their
policy function. We train a personalized recourse agent to generate such
personalized paths, which are obtained using reward functions that consider the
goal, similarity, and personalization. The proposed method is applicable to
both reinforcement learning and supervised learning settings for correcting or
improving sequences of actions or sequences of data to achieve a pre-determined
goal. The method is evaluated in various settings and demonstrates promising
results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08725">A Comparative Analysis of Fine-Tuned LLMs and Few-Shot Learning of LLMs for Financial Sentiment Analysis. (arXiv:2312.08725v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fatemi_S/0/1/0/all/0/1">Sorouralsadat Fatemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuheng Hu</a></p>
<p>Financial sentiment analysis plays a crucial role in uncovering latent
patterns and detecting emerging trends, enabling individuals to make
well-informed decisions that may yield substantial advantages within the
constantly changing realm of finance. Recently, Large Language Models (LLMs)
have demonstrated their effectiveness in diverse domains, showcasing remarkable
capabilities even in zero-shot and few-shot in-context learning for various
Natural Language Processing (NLP) tasks. Nevertheless, their potential and
applicability in the context of financial sentiment analysis have not been
thoroughly explored yet. To bridge this gap, we employ two approaches:
in-context learning (with a focus on gpt-3.5-turbo model) and fine-tuning LLMs
on a finance-domain dataset. Given the computational costs associated with
fine-tuning LLMs with large parameter sizes, our focus lies on smaller LLMs,
spanning from 250M to 3B parameters for fine-tuning. We then compare the
performances with state-of-the-art results to evaluate their effectiveness in
the finance-domain. Our results demonstrate that fine-tuned smaller LLMs can
achieve comparable performance to state-of-the-art fine-tuned LLMs, even with
models having fewer parameters and a smaller training dataset. Additionally,
the zero-shot and one-shot performance of LLMs produces comparable results with
fine-tuned smaller LLMs and state-of-the-art outcomes. Furthermore, our
analysis demonstrates that there is no observed enhancement in performance for
finance-domain sentiment analysis when the number of shots for in-context
learning is increased.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08740">Learning a Low-Rank Feature Representation: Achieving Better Trade-Off between Stability and Plasticity in Continual Learning. (arXiv:2312.08740v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenrong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yi Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yik-Chung Wu</a></p>
<p>In continual learning, networks confront a trade-off between stability and
plasticity when trained on a sequence of tasks. To bolster plasticity without
sacrificing stability, we propose a novel training algorithm called LRFR. This
approach optimizes network parameters in the null space of the past tasks'
feature representation matrix to guarantee the stability. Concurrently, we
judiciously select only a subset of neurons in each layer of the network while
training individual tasks to learn the past tasks' feature representation
matrix in low-rank. This increases the null space dimension when designing
network parameters for subsequent tasks, thereby enhancing the plasticity.
Using CIFAR-100 and TinyImageNet as benchmark datasets for continual learning,
the proposed approach consistently outperforms state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08749">Mitigating Label Bias in Machine Learning: Fairness through Confident Learning. (arXiv:2312.08749v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zenan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a></p>
<p>Discrimination can occur when the underlying unbiased labels are overwritten
by an agent with potential bias, resulting in biased datasets that unfairly
harm specific groups and cause classifiers to inherit these biases. In this
paper, we demonstrate that despite only having access to the biased labels, it
is possible to eliminate bias by filtering the fairest instances within the
framework of confident learning. In the context of confident learning, low
self-confidence usually indicates potential label errors; however, this is not
always the case. Instances, particularly those from underrepresented groups,
might exhibit low confidence scores for reasons other than labeling errors. To
address this limitation, our approach employs truncation of the confidence
score and extends the confidence interval of the probabilistic threshold.
Additionally, we incorporate with co-teaching paradigm for providing a more
robust and reliable selection of fair instances and effectively mitigating the
adverse effects of biased labels. Through extensive experimentation and
evaluation of various datasets, we demonstrate the efficacy of our approach in
promoting fairness and reducing the impact of label bias in machine learning
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08751">Improve Robustness of Reinforcement Learning against Observation Perturbations via $l_\infty$ Lipschitz Policy Networks. (arXiv:2312.08751v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nie_B/0/1/0/all/0/1">Buqing Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jingtian Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yangqing Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a></p>
<p>Deep Reinforcement Learning (DRL) has achieved remarkable advances in
sequential decision tasks. However, recent works have revealed that DRL agents
are susceptible to slight perturbations in observations. This vulnerability
raises concerns regarding the effectiveness and robustness of deploying such
agents in real-world applications. In this work, we propose a novel robust
reinforcement learning method called SortRL, which improves the robustness of
DRL policies against observation perturbations from the perspective of the
network architecture. We employ a novel architecture for the policy network
that incorporates global $l_\infty$ Lipschitz continuity and provide a
convenient method to enhance policy robustness based on the output margin.
Besides, a training framework is designed for SortRL, which solves given tasks
while maintaining robustness against $l_\infty$ bounded perturbations on the
observations. Several experiments are conducted to evaluate the effectiveness
of our method, including classic control tasks and video games. The results
demonstrate that SortRL achieves state-of-the-art robustness performance
against different perturbation strength.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08763">Learning from Polar Representation: An Extreme-Adaptive Model for Long-Term Time Series Forecasting. (arXiv:2312.08763v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasiu_D/0/1/0/all/0/1">David C. Anastasiu</a></p>
<p>In the hydrology field, time series forecasting is crucial for efficient
water resource management, improving flood and drought control and increasing
the safety and quality of life for the general population. However, predicting
long-term streamflow is a complex task due to the presence of extreme events.
It requires the capture of long-range dependencies and the modeling of rare but
important extreme values. Existing approaches often struggle to tackle these
dual challenges simultaneously. In this paper, we specifically delve into these
issues and propose Distance-weighted Auto-regularized Neural network (DAN), a
novel extreme-adaptive model for long-range forecasting of stremflow enhanced
by polar representation learning. DAN utilizes a distance-weighted multi-loss
mechanism and stackable blocks to dynamically refine indicator sequences from
exogenous data, while also being able to handle uni-variate time-series by
employing Gaussian Mixture probability modeling to improve robustness to severe
events. We also introduce Kruskal-Wallis sampling and gate control vectors to
handle imbalanced extreme data. On four real-life hydrologic streamflow
datasets, we demonstrate that DAN significantly outperforms both
state-of-the-art hydrologic time series prediction methods and general methods
designed for long-term time series prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08766">A Dual Convolutional Neural Network Pipeline for Melanoma Diagnostics and Prognostics. (arXiv:2312.08766v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Bo_Sande_M/0/1/0/all/0/1">Marie B&#xf8;-Sande</a>, <a href="http://arxiv.org/find/eess/1/au:+Benjaminsen_E/0/1/0/all/0/1">Edvin Benjaminsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Kanwal_N/0/1/0/all/0/1">Neel Kanwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Fuster_S/0/1/0/all/0/1">Saul Fuster</a>, <a href="http://arxiv.org/find/eess/1/au:+Hardardottir_H/0/1/0/all/0/1">Helga Hardardottir</a>, <a href="http://arxiv.org/find/eess/1/au:+Lundal_I/0/1/0/all/0/1">Ingrid Lundal</a>, <a href="http://arxiv.org/find/eess/1/au:+Janssen_E/0/1/0/all/0/1">Emiel A.M. Janssen</a>, <a href="http://arxiv.org/find/eess/1/au:+Engan_K/0/1/0/all/0/1">Kjersti Engan</a></p>
<p>Melanoma is a type of cancer that begins in the cells controlling the pigment
of the skin, and it is often referred to as the most dangerous skin cancer.
Diagnosing melanoma can be time-consuming, and a recent increase in melanoma
incidents indicates a growing demand for a more efficient diagnostic process.
This paper presents a pipeline for melanoma diagnostics, leveraging two
convolutional neural networks, a diagnosis, and a prognosis model. The
diagnostic model is responsible for localizing malignant patches across whole
slide images and delivering a patient-level diagnosis as malignant or benign.
Further, the prognosis model utilizes the diagnostic model's output to provide
a patient-level prognosis as good or bad. The full pipeline has an F1 score of
0.79 when tested on data from the same distribution as it was trained on.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08773">Offshore Wind Plant Instance Segmentation Using Sentinel-1 Time Series, GIS, and Semantic Segmentation Models. (arXiv:2312.08773v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Carvalho_O/0/1/0/all/0/1">Osmar Luiz Ferreira de Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_O/0/1/0/all/0/1">Osmar Abilio de Carvalho Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Albuquerque_A/0/1/0/all/0/1">Anesmar Olino de Albuquerque</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1">Daniel Guerreiro e Silva</a></p>
<p>Offshore wind farms represent a renewable energy source with a significant
global growth trend, and their monitoring is strategic for territorial and
environmental planning. This study's primary objective is to detect offshore
wind plants at an instance level using semantic segmentation models and
Sentinel-1 time series. The secondary objectives are: (a) to develop a database
consisting of labeled data and S-1 time series; (b) to compare the performance
of five deep semantic segmentation architectures (U-Net, U-Net++, Feature
Pyramid Network - FPN, DeepLabv3+, and LinkNet); (c) develop a novel
augmentation strategy that shuffles the positions of the images within the time
series; (d) investigate different dimensions of time series intervals (1, 5,
10, and 15 images); and (e) evaluate the semantic-to-instance conversion
procedure. LinkNet was the top-performing model, followed by U-Net++ and U-Net,
while FPN and DeepLabv3+ presented the worst results. The evaluation of
semantic segmentation models reveals enhanced Intersection over Union (IoU)
(25%) and F-score metrics (18%) with the augmentation of time series images.
The study showcases the augmentation strategy's capability to mitigate biases
and precisely detect invariant targets. Furthermore, the conversion from
semantic to instance segmentation demonstrates its efficacy in accurately
isolating individual instances within classified regions - simplifying training
data and reducing annotation effort and complexity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08782">Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis. (arXiv:2312.08782v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yafei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1">Quanting Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1">Vidhi Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1">Jonathan Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Patrikar_J/0/1/0/all/0/1">Jay Patrikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Keetha_N/0/1/0/all/0/1">Nikhil Keetha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seungchan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yaqi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhibo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_Y/0/1/0/all/0/1">Yu-Quan Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1">Katia Sycara</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_Roberson_M/0/1/0/all/0/1">Matthew Johnson-Roberson</a>, <a href="http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1">Dhruv Batra</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a></p>
<p>Building general-purpose robots that can operate seamlessly, in any
environment, with any object, and utilizing various skills to complete diverse
tasks has been a long-standing goal in Artificial Intelligence. Unfortunately,
however, most existing robotic systems have been constrained - having been
designed for specific tasks, trained on specific datasets, and deployed within
specific environments. These systems usually require extensively-labeled data,
rely on task-specific models, have numerous generalization issues when deployed
in real-world scenarios, and struggle to remain robust to distribution shifts.
Motivated by the impressive open-set performance and content generation
capabilities of web-scale, large-capacity pre-trained models (i.e., foundation
models) in research fields such as Natural Language Processing (NLP) and
Computer Vision (CV), we devote this survey to exploring (i) how these existing
foundation models from NLP and CV can be applied to the field of robotics, and
also exploring (ii) what a robotics-specific foundation model would look like.
We begin by providing an overview of what constitutes a conventional robotic
system and the fundamental barriers to making it universally applicable. Next,
we establish a taxonomy to discuss current work exploring ways to leverage
existing foundation models for robotics and develop ones catered to robotics.
Finally, we discuss key challenges and promising future directions in using
foundation models for enabling general-purpose robotic systems. We encourage
readers to view our ``living`` GitHub repository of resources, including papers
reviewed in this survey as well as related projects and repositories for
developing foundation models for robotics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08785">Managing the unknown: a survey on Open Set Recognition and tangential areas. (arXiv:2312.08785v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barcina_Blanco_M/0/1/0/all/0/1">Marcos Barcina-Blanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Lobo_J/0/1/0/all/0/1">Jesus L. Lobo</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Bringas_P/0/1/0/all/0/1">Pablo Garcia-Bringas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ser_J/0/1/0/all/0/1">Javier Del Ser</a></p>
<p>In real-world scenarios classification models are often required to perform
robustly when predicting samples belonging to classes that have not appeared
during its training stage. Open Set Recognition addresses this issue by
devising models capable of detecting unknown classes from samples arriving
during the testing phase, while maintaining a good level of performance in the
classification of samples belonging to known classes. This review
comprehensively overviews the recent literature related to Open Set
Recognition, identifying common practices, limitations, and connections of this
field with other machine learning research areas, such as continual learning,
out-of-distribution detection, novelty detection, and uncertainty estimation.
Our work also uncovers open problems and suggests several research directions
that may motivate and articulate future efforts towards more safe Artificial
Intelligence methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08793">Forbidden Facts: An Investigation of Competing Objectives in Llama-2. (arXiv:2312.08793v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tony T. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Miles Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hariharan_K/0/1/0/all/0/1">Kaivu Hariharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shavit_N/0/1/0/all/0/1">Nir Shavit</a></p>
<p>LLMs often face competing pressures (for example helpfulness vs.
harmlessness). To understand how models resolve such conflicts, we study
Llama-2-chat models on the forbidden fact task. Specifically, we instruct
Llama-2 to truthfully complete a factual recall statement while forbidding it
from saying the correct answer. This often makes the model give incorrect
answers. We decompose Llama-2 into 1000+ components, and rank each one with
respect to how useful it is for forbidding the correct answer. We find that in
aggregate, around 35 components are enough to reliably implement the full
suppression behavior. However, these components are fairly heterogeneous and
many operate using faulty heuristics. We discover that one of these heuristics
can be exploited via a manually designed adversarial attack which we call The
California Attack. Our results highlight some roadblocks standing in the way of
being able to successfully interpret advanced ML systems. Project website
available at https://forbiddenfacts.github.io .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08800">Evaluating Large Language Models for Health-related Queries with Presuppositions. (arXiv:2312.08800v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kaur_N/0/1/0/all/0/1">Navreet Kaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1">Monojit Choudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1">Danish Pruthi</a></p>
<p>As corporations rush to integrate large language models (LLMs) to their
search offerings, it is critical that they provide factually accurate
information that is robust to any presuppositions that a user may express. In
this work, we introduce UPHILL, a dataset consisting of health-related queries
with varying degrees of presuppositions. Using UPHILL, we evaluate the factual
accuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find
that while model responses rarely disagree with true health claims (posed as
questions), they often fail to challenge false claims: responses from
InstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.
As we increase the extent of presupposition in input queries, the responses
from InstructGPT and ChatGPT agree with the claim considerably more often,
regardless of its veracity. Responses from BingChat, which rely on retrieved
webpages, are not as susceptible. Given the moderate factual accuracy, and the
inability of models to consistently correct false assumptions, our work calls
for a careful assessment of current LLMs for use in high-stakes scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08809">Performance evaluation of matrix factorization for fMRI data. (arXiv:2312.08809v1 [q-bio.NC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Endo_Y/0/1/0/all/0/1">Yusuke Endo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Takeda_K/0/1/0/all/0/1">Koujin Takeda</a></p>
<p>In the study of the brain, there is a hypothesis that sparse coding is
realized in information representation of external stimuli, which is
experimentally confirmed for visual stimulus recently. However, unlike the
specific functional region in the brain, sparse coding in information
processing in the whole brain has not been clarified sufficiently. In this
study, we investigate the validity of sparse coding in the whole human brain by
applying various matrix factorization methods to functional magnetic resonance
imaging data of neural activities in the whole human brain. The result suggests
sparse coding hypothesis in information representation in the whole human
brain, because extracted features from sparse MF method, SparsePCA or MOD under
high sparsity setting, or approximate sparse MF method, FastICA, can classify
external visual stimuli more accurately than non-sparse MF method or sparse MF
method under low sparsity setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08810">Deep Learning-Based Cyber-Attack Detection Model for Smart Grids. (arXiv:2312.08810v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1">Mojtaba Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Aflaki_A/0/1/0/all/0/1">Arshia Aflaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kavousifard_A/0/1/0/all/0/1">Abdollah Kavousifard</a>, <a href="http://arxiv.org/find/cs/1/au:+Gitizadeh_M/0/1/0/all/0/1">Mohsen Gitizadeh</a></p>
<p>In this paper, a novel artificial intelligence-based cyber-attack detection
model for smart grids is developed to stop data integrity cyber-attacks (DIAs)
on the received load data by supervisory control and data acquisition (SCADA).
In the proposed model, first the load data is forecasted using a regression
model and after processing stage, the processed data is clustered using the
unsupervised learning method. In this work, in order to achieve the best
performance, three load forecasting methods (i.e. extra tree regression (ETR),
long short-term memory (LSTM) and bidirectional long short-term memory
(BiLSTM)) are utilized as regression models and their performance is compared.
For clustering and outlying detection, the covariance elliptic envelope (EE) is
employed as an unsupervised learning method. To examine the proposed model, the
hourly load data of the power company of the city of Johor in Malaysia is
employed and Two common DIAs, which are DIAs targeting economic loss and DIAs
targeting blackouts, are used to evaluate the accuracy of detection methods in
several scenarios. The simulation results show that the proposed EE-BiLSTM
method can perform more robust and accurate compared to the other two methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08818">A Cyber-Physical Architecture for Microgrids based on Deep learning and LORA Technology. (arXiv:2312.08818v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1">Mojtaba Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+KavousiFard_A/0/1/0/all/0/1">Abdollah KavousiFard</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabbaghjamanesh_M/0/1/0/all/0/1">Mortza Dabbaghjamanesh</a></p>
<p>This paper proposes a cyber-physical architecture for the secured social
operation of isolated hybrid microgrids (HMGs). On the physical side of the
proposed architecture, an optimal scheduling scheme considering various
renewable energy sources (RESs) and fossil fuel-based distributed generation
units (DGs) is proposed. Regarding the cyber layer of MGs, a wireless
architecture based on low range wide area (LORA) technology is introduced for
advanced metering infrastructure (AMI) in smart electricity grids. In the
proposed architecture, the LORA data frame is described in detail and designed
for the application of smart meters considering DGs and ac-dc converters.
Additionally, since the cyber layer of smart grids is highly vulnerable to
cyber-attacks, t1his paper proposes a deep-learning-based cyber-attack
detection model (CADM) based on bidirectional long short-term memory (BLSTM)
and sequential hypothesis testing (SHT) to detect false data injection attacks
(FDIA) on the smart meters within AMI. The performance of the proposed energy
management architecture is evaluated using the IEEE 33-bus test system. In
order to investigate the effect of FDIA on the isolated HMGs and highlight the
interactions between the cyber layer and physical layer, an FDIA is launched
against the test system. The results showed that a successful attack can highly
damage the system and cause widespread load shedding. Also, the performance of
the proposed CADM is examined using a real-world dataset. Results prove the
effectiveness of the proposed CADM in detecting the attacks using only two
samples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08820">How to Raise a Robot -- A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots. (arXiv:2312.08820v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hemken_N/0/1/0/all/0/1">Niklas Hemken</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacob_F/0/1/0/all/0/1">Florian Jacob</a>, <a href="http://arxiv.org/find/cs/1/au:+Peller_Konrad_F/0/1/0/all/0/1">Fabian Peller-Konrad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kartmann_R/0/1/0/all/0/1">Rainer Kartmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1">Tamim Asfour</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartenstein_H/0/1/0/all/0/1">Hannes Hartenstein</a></p>
<p>Humanoid robots will be able to assist humans in their daily life, in
particular due to their versatile action capabilities. However, while these
robots need a certain degree of autonomy to learn and explore, they also should
respect various constraints, for access control and beyond. We explore the
novel field of incorporating privacy, security, and access control constraints
with robot task planning approaches. We report preliminary results on the
classical symbolic approach, deep-learned neural networks, and modern ideas
using large language models as knowledge base. From analyzing their trade-offs,
we conclude that a hybrid approach is necessary, and thereby present a new use
case for the emerging field of neuro-symbolic artificial intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08821">Reconstruction of Sound Field through Diffusion Models. (arXiv:2312.08821v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Miotello_F/0/1/0/all/0/1">Federico Miotello</a>, <a href="http://arxiv.org/find/eess/1/au:+Comanducci_L/0/1/0/all/0/1">Luca Comanducci</a>, <a href="http://arxiv.org/find/eess/1/au:+Pezzoli_M/0/1/0/all/0/1">Mirco Pezzoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Bernardini_A/0/1/0/all/0/1">Alberto Bernardini</a>, <a href="http://arxiv.org/find/eess/1/au:+Antonacci_F/0/1/0/all/0/1">Fabio Antonacci</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarti_A/0/1/0/all/0/1">Augusto Sarti</a></p>
<p>Reconstructing the sound field in a room is an important task for several
applications, such as sound control and augmented (AR) or virtual reality (VR).
In this paper, we propose a data-driven generative model for reconstructing the
magnitude of acoustic fields in rooms with a focus on the modal frequency
range. We introduce, for the first time, the use of a conditional Denoising
Diffusion Probabilistic Model (DDPM) trained in order to reconstruct the sound
field (SF-Diff) over an extended domain. The architecture is devised in order
to be conditioned on a set of limited available measurements at different
frequencies and generate the sound field in target, unknown, locations. The
results show that SF-Diff is able to provide accurate reconstructions,
outperforming a state-of-the-art baseline based on kernel interpolation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08823">Fast sampling from constrained spaces using the Metropolis-adjusted Mirror Langevin Algorithm. (arXiv:2312.08823v1 [stat.CO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Srinivasan_V/0/1/0/all/0/1">Vishwak Srinivasan</a>, <a href="http://arxiv.org/find/stat/1/au:+Wibisono_A/0/1/0/all/0/1">Andre Wibisono</a>, <a href="http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1">Ashia Wilson</a></p>
<p>We propose a new method called the Metropolis-adjusted Mirror Langevin
algorithm for approximate sampling from distributions whose support is a
compact and convex set. This algorithm adds an accept-reject filter to the
Markov chain induced by a single step of the mirror Langevin algorithm (Zhang
et al., 2020), which is a basic discretisation of the mirror Langevin dynamics.
Due to the inclusion of this filter, our method is unbiased relative to the
target, while known discretisations of the mirror Langevin dynamics including
the mirror Langevin algorithm have an asymptotic bias. We give upper bounds for
the mixing time of the proposed algorithm when the potential is relatively
smooth, convex, and Lipschitz with respect to a self-concordant mirror
function. As a consequence of the reversibility of the Markov chain induced by
the algorithm, we obtain an exponentially better dependence on the error
tolerance for approximate sampling. We also present numerical experiments that
corroborate our theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08837">Learning Safety Constraints From Demonstration Using One-Class Decision Trees. (arXiv:2312.08837v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Baert_M/0/1/0/all/0/1">Mattijs Baert</a>, <a href="http://arxiv.org/find/cs/1/au:+Leroux_S/0/1/0/all/0/1">Sam Leroux</a>, <a href="http://arxiv.org/find/cs/1/au:+Simoens_P/0/1/0/all/0/1">Pieter Simoens</a></p>
<p>The alignment of autonomous agents with human values is a pivotal challenge
when deploying these agents within physical environments, where safety is an
important concern. However, defining the agent's objective as a reward and/or
cost function is inherently complex and prone to human errors. In response to
this challenge, we present a novel approach that leverages one-class decision
trees to facilitate learning from expert demonstrations. These decision trees
provide a foundation for representing a set of constraints pertinent to the
given environment as a logical formula in disjunctive normal form. The learned
constraints are subsequently employed within an oracle constrained
reinforcement learning framework, enabling the acquisition of a safe policy. In
contrast to other methods, our approach offers an interpretable representation
of the constraints, a vital feature in safety-critical environments. To
validate the effectiveness of our proposed method, we conduct experiments in
synthetic benchmark domains and a realistic driving environment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08843">Diffusion-C: Unveiling the Generative Challenges of Diffusion Models through Corrupted Data. (arXiv:2312.08843v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bae_K/0/1/0/all/0/1">Keywoong Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Suan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wookey Lee</a></p>
<p>In our contemporary academic inquiry, we present "Diffusion-C," a
foundational methodology to analyze the generative restrictions of Diffusion
Models, particularly those akin to GANs, DDPM, and DDIM. By employing input
visual data that has been subjected to a myriad of corruption modalities and
intensities, we elucidate the performance characteristics of those Diffusion
Models. The noise component takes center stage in our analysis, hypothesized to
be a pivotal element influencing the mechanics of deep learning systems. In our
rigorous expedition utilizing Diffusion-C, we have discerned the following
critical observations: (I) Within the milieu of generative models under the
Diffusion taxonomy, DDPM emerges as a paragon, consistently exhibiting superior
performance metrics. (II) Within the vast spectrum of corruption frameworks,
the fog and fractal corruptions notably undermine the functional robustness of
both DDPM and DDIM. (III) The vulnerability of Diffusion Models to these
particular corruptions is significantly influenced by topological and
statistical similarities, particularly concerning the alignment between mean
and variance. This scholarly work highlights Diffusion-C's core understandings
regarding the impacts of various corruptions, setting the stage for future
research endeavors in the realm of generative models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08846">TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training. (arXiv:2312.08846v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Chaoya Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+ye_W/0/1/0/all/0/1">Wei ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qinghao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Ji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shikun Zhang</a></p>
<p>Self-supervised Multi-modal Contrastive Learning (SMCL) remarkably advances
modern Vision-Language Pre-training (VLP) models by aligning visual and
linguistic modalities. Due to noises in web-harvested text-image pairs,
however, scaling up training data volume in SMCL presents considerable
obstacles in terms of computational cost and data inefficiency. To improve data
efficiency in VLP, we propose Text-aware Image Mixing (TiMix), which integrates
mix-based data augmentation techniques into SMCL, yielding significant
performance improvements without significantly increasing computational
overhead. We provide a theoretical analysis of TiMixfrom a mutual information
(MI) perspective, showing that mixed data samples for cross-modal contrastive
learning implicitly serve as a regularizer for the contrastive loss. The
experimental results demonstrate that TiMix exhibits a comparable performance
on downstream tasks, even with a reduced amount of training data and shorter
training time, when benchmarked against existing methods. This work empirically
and theoretically demonstrates the potential of data mixing for data-efficient
and computationally viable VLP, benefiting broader VLP model adoption in
practical scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08847">Knowledge-Driven Modulation of Neural Networks with Attention Mechanism for Next Activity Prediction. (arXiv:2312.08847v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Donadello_I/0/1/0/all/0/1">Ivan Donadello</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">Jonghyeon Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Maggi_F/0/1/0/all/0/1">Fabrizio Maria Maggi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendling_J/0/1/0/all/0/1">Jan Mendling</a>, <a href="http://arxiv.org/find/cs/1/au:+Riva_F/0/1/0/all/0/1">Francesco Riva</a>, <a href="http://arxiv.org/find/cs/1/au:+Weidlich_M/0/1/0/all/0/1">Matthias Weidlich</a></p>
<p>Predictive Process Monitoring (PPM) aims at leveraging historic process
execution data to predict how ongoing executions will continue up to their
completion. In recent years, PPM techniques for the prediction of the next
activities have matured significantly, mainly thanks to the use of Neural
Networks (NNs) as a predictor. While their performance is difficult to beat in
the general case, there are specific situations where background process
knowledge can be helpful. Such knowledge can be leveraged for improving the
quality of predictions for exceptional process executions or when the process
changes due to a concept drift. In this paper, we present a Symbolic[Neuro]
system that leverages background knowledge expressed in terms of a procedural
process model to offset the under-sampling in the training data. More
specifically, we make predictions using NNs with attention mechanism, an
emerging technology in the NN field. The system has been tested on several
real-life logs showing an improvement in the performance of the prediction
task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08852">ERASE: Error-Resilient Representation Learning on Graphs for Label Noise Tolerance. (arXiv:2312.08852v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Ling-Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuanshuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Taohua Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Liangcai Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zeyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xiaobo Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a></p>
<p>Deep learning has achieved remarkable success in graph-related tasks, yet
this accomplishment heavily relies on large-scale high-quality annotated
datasets. However, acquiring such datasets can be cost-prohibitive, leading to
the practical use of labels obtained from economically efficient sources such
as web searches and user tags. Unfortunately, these labels often come with
noise, compromising the generalization performance of deep networks. To tackle
this challenge and enhance the robustness of deep learning models against label
noise in graph-based tasks, we propose a method called ERASE (Error-Resilient
representation learning on graphs for lAbel noiSe tolerancE). The core idea of
ERASE is to learn representations with error tolerance by maximizing coding
rate reduction. Particularly, we introduce a decoupled label propagation method
for learning representations. Before training, noisy labels are pre-corrected
through structural denoising. During training, ERASE combines prototype
pseudo-labels with propagated denoised labels and updates representations with
error resilience, which significantly improves the generalization performance
in node classification. The proposed method allows us to more effectively
withstand errors caused by mislabeled nodes, thereby strengthening the
robustness of deep networks in handling noisy graph data. Extensive
experimental results show that our method can outperform multiple baselines
with clear margins in broad noise levels and enjoy great scalability. Codes are
released at https://github.com/eraseai/erase.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08877">May the Noise be with you: Adversarial Training without Adversarial Examples. (arXiv:2312.08877v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arous_A/0/1/0/all/0/1">Ayoub Arous</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Lopera_A/0/1/0/all/0/1">Andres F Lopez-Lopera</a>, <a href="http://arxiv.org/find/cs/1/au:+Abu_Ghazaleh_N/0/1/0/all/0/1">Nael Abu-Ghazaleh</a>, <a href="http://arxiv.org/find/cs/1/au:+Alouani_I/0/1/0/all/0/1">Ihsen Alouani</a></p>
<p>In this paper, we investigate the following question: Can we obtain
adversarially-trained models without training on adversarial examples? Our
intuition is that training a model with inherent stochasticity, i.e.,
optimizing the parameters by minimizing a stochastic loss function, yields a
robust expectation function that is non-stochastic. In contrast to related
methods that introduce noise at the input level, our proposed approach
incorporates inherent stochasticity by embedding Gaussian noise within the
layers of the NN model at training time. We model the propagation of noise
through the layers, introducing a closed-form stochastic loss function that
encapsulates a noise variance parameter. Additionally, we contribute a
formalized noise-aware gradient, enabling the optimization of model parameters
while accounting for stochasticity. Our experimental results confirm that the
expectation model of a stochastic architecture trained on benign distribution
is adversarially robust. Interestingly, we find that the impact of the applied
Gaussian noise's standard deviation on both robustness and baseline accuracy
closely mirrors the impact of the noise magnitude employed in adversarial
training. Our work contributes adversarially trained networks using a
completely different approach, with empirically similar robustness to
adversarial training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08878">Domain Prompt Learning with Quaternion Networks. (arXiv:2312.08878v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qinglong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhengqin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuntian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a></p>
<p>Prompt learning has emerged as an effective and data-efficient technique in
large Vision-Language Models (VLMs). However, when adapting VLMs to specialized
domains such as remote sensing and medical imaging, domain prompt learning
remains underexplored. While large-scale domain-specific foundation models can
help tackle this challenge, their concentration on a single vision level makes
it challenging to prompt both vision and language modalities. To overcome this,
we propose to leverage domain-specific knowledge from domain-specific
foundation models to transfer the robust recognition ability of VLMs from
generalized to specialized domains, using quaternion networks. Specifically,
the proposed method involves using domain-specific vision features from
domain-specific foundation models to guide the transformation of generalized
contextual embeddings from the language branch into a specialized space within
the quaternion networks. Moreover, we present a hierarchical approach that
generates vision prompt features by analyzing intermodal relationships between
hierarchical language prompt features and domain-specific vision features. In
this way, quaternion networks can effectively mine the intermodal relationships
in the specific domain, facilitating domain-specific vision-language
contrastive learning. Extensive experiments on domain-specific datasets show
that our proposed method achieves new state-of-the-art results in prompt
learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08884">Global Rewards in Multi-Agent Deep Reinforcement Learning for Autonomous Mobility on Demand Systems. (arXiv:2312.08884v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hoppe_H/0/1/0/all/0/1">Heiko Hoppe</a>, <a href="http://arxiv.org/find/cs/1/au:+Enders_T/0/1/0/all/0/1">Tobias Enders</a>, <a href="http://arxiv.org/find/cs/1/au:+Cappart_Q/0/1/0/all/0/1">Quentin Cappart</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiffer_M/0/1/0/all/0/1">Maximilian Schiffer</a></p>
<p>We study vehicle dispatching in autonomous mobility on demand (AMoD) systems,
where a central operator assigns vehicles to customer requests or rejects these
with the aim of maximizing its total profit. Recent approaches use multi-agent
deep reinforcement learning (MADRL) to realize scalable yet performant
algorithms, but train agents based on local rewards, which distorts the reward
signal with respect to the system-wide profit, leading to lower performance. We
therefore propose a novel global-rewards-based MADRL algorithm for vehicle
dispatching in AMoD systems, which resolves so far existing goal conflicts
between the trained agents and the operator by assigning rewards to agents
leveraging a counterfactual baseline. Our algorithm shows statistically
significant improvements across various settings on real-world data compared to
state-of-the-art MADRL algorithms with local rewards. We further provide a
structural analysis which shows that the utilization of global rewards can
improve implicit vehicle balancing and demand forecasting abilities. Our code
is available at https://github.com/tumBAIS/GR-MADRL-AMoD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08887">SpeedUpNet: A Plug-and-Play Hyper-Network for Accelerating Text-to-Image Diffusion Models. (arXiv:2312.08887v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chai_W/0/1/0/all/0/1">Weilong Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">DanDan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jiajiong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiquan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changbao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chenguang Ma</a></p>
<p>Text-to-image diffusion models (SD) exhibit significant advancements while
requiring extensive computational resources. Though many acceleration methods
have been proposed, they suffer from generation quality degradation or extra
training cost generalizing to new fine-tuned models. To address these
limitations, we propose a novel and universal Stable-Diffusion (SD)
acceleration module called SpeedUpNet(SUN). SUN can be directly plugged into
various fine-tuned SD models without extra training. This technique utilizes
cross-attention layers to learn the relative offsets in the generated image
results between negative and positive prompts achieving classifier-free
guidance distillation with negative prompts controllable, and introduces a
Multi-Step Consistency (MSC) loss to ensure a harmonious balance between
reducing inference steps and maintaining consistency in the generated output.
Consequently, SUN significantly reduces the number of inference steps to just 4
steps and eliminates the need for classifier-free guidance. It leads to an
overall speedup of more than 10 times for SD models compared to the
state-of-the-art 25-step DPM-solver++, and offers two extra advantages: (1)
classifier-free guidance distillation with controllable negative prompts and
(2) seamless integration into various fine-tuned Stable-Diffusion models
without training. The effectiveness of the SUN has been verified through
extensive experimentation. Project Page:
https://williechai.github.io/speedup-plugin-for-stable-diffusions.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08888">Read Between the Layers: Leveraging Intra-Layer Representations for Rehearsal-Free Continual Learning with Pre-Trained Models. (arXiv:2312.08888v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahrens_K/0/1/0/all/0/1">Kyra Ahrens</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_H/0/1/0/all/0/1">Hans Hergen Lehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae Hee Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1">Stefan Wermter</a></p>
<p>We address the Continual Learning (CL) problem, where a model has to learn a
sequence of tasks from non-stationary distributions while preserving prior
knowledge as it encounters new experiences. With the advancement of foundation
models, CL research has shifted focus from the initial learning-from-scratch
paradigm to the use of generic features from large-scale pre-training. However,
existing approaches to CL with pre-trained models only focus on separating the
class-specific features from the final representation layer and neglect the
power of intermediate representations that capture low- and mid-level features
naturally more invariant to domain shifts. In this work, we propose LayUP, a
new class-prototype-based approach to continual learning that leverages
second-order feature statistics from multiple intermediate layers of a
pre-trained network. Our method is conceptually simple, does not require any
replay buffer, and works out of the box with any foundation model. LayUP
improves over the state-of-the-art on four of the seven class-incremental
learning settings at a considerably reduced memory and computational footprint
compared with the next best baseline. Our results demonstrate that fully
exhausting the representational capacities of pre-trained models in CL goes far
beyond their final embeddings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08890">Defenses in Adversarial Machine Learning: A Survey. (arXiv:2312.08890v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Baoyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Shaokui Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingli Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Meixi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mingda Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hongrui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_D/0/1/0/all/0/1">Danni Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Li Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingshan Liu</a></p>
<p>Adversarial phenomenon has been widely observed in machine learning (ML)
systems, especially in those using deep neural networks, describing that ML
systems may produce inconsistent and incomprehensible predictions with humans
at some particular cases. This phenomenon poses a serious security threat to
the practical application of ML systems, and several advanced attack paradigms
have been developed to explore it, mainly including backdoor attacks, weight
attacks, and adversarial examples. For each individual attack paradigm, various
defense paradigms have been developed to improve the model robustness against
the corresponding attack paradigm. However, due to the independence and
diversity of these defense paradigms, it is difficult to examine the overall
robustness of an ML system against different kinds of attacks.This survey aims
to build a systematic review of all existing defense paradigms from a unified
perspective. Specifically, from the life-cycle perspective, we factorize a
complete machine learning system into five stages, including pre-training,
training, post-training, deployment, and inference stages, respectively. Then,
we present a clear taxonomy to categorize and review representative defense
methods at each individual stage. The unified perspective and presented
taxonomies not only facilitate the analysis of the mechanism of each defense
paradigm but also help us to understand connections and differences among
different defense paradigms, which may inspire future research to develop more
advanced, comprehensive defenses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08891">High-Dimensional Bayesian Optimisation with Large-Scale Constraints -- An Application to Aeroelastic Tailoring. (arXiv:2312.08891v1 [cs.CE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maathuis_H/0/1/0/all/0/1">Hauke Maathuis</a>, <a href="http://arxiv.org/find/cs/1/au:+Breuker_R/0/1/0/all/0/1">Roeland De Breuker</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_S/0/1/0/all/0/1">Saullo G. P. Castro</a></p>
<p>Design optimisation potentially leads to lightweight aircraft structures with
lower environmental impact. Due to the high number of design variables and
constraints, these problems are ordinarily solved using gradient-based
optimisation methods, leading to a local solution in the design space while the
global space is neglected. Bayesian Optimisation is a promising path towards
sample-efficient, global optimisation based on probabilistic surrogate models.
While Bayesian optimisation methods have demonstrated their strength for
problems with a low number of design variables, the scalability to
high-dimensional problems while incorporating large-scale constraints is still
lacking. Especially in aeroelastic tailoring where directional stiffness
properties are embodied into the structural design of aircraft, to control
aeroelastic deformations and to increase the aerodynamic and structural
performance, the safe operation of the system needs to be ensured by involving
constraints resulting from different analysis disciplines. Hence, a global
design space search becomes even more challenging. The present study attempts
to tackle the problem by using high-dimensional Bayesian Optimisation in
combination with a dimensionality reduction approach to solve the optimisation
problem occurring in aeroelastic tailoring, presenting a novel approach for
high-dimensional problems with large-scale constraints. Experiments on
well-known benchmark cases with black-box constraints show that the proposed
approach can incorporate large-scale constraints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08893">Solving Dense Linear Systems Faster than via Preconditioning. (arXiv:2312.08893v1 [cs.DS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Derezinski_M/0/1/0/all/0/1">Micha&#x142; Derezi&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaming Yang</a></p>
<p>We give a stochastic optimization algorithm that solves a dense $n\times n$
real-valued linear system $Ax=b$, returning $\tilde x$ such that $\|A\tilde
x-b\|\leq \epsilon\|b\|$ in time: $$\tilde
O((n^2+nk^{\omega-1})\log1/\epsilon),$$ where $k$ is the number of singular
values of $A$ larger than $O(1)$ times its smallest positive singular value,
$\omega &lt; 2.372$ is the matrix multiplication exponent, and $\tilde O$ hides a
poly-logarithmic in $n$ factor. When $k=O(n^{1-\theta})$ (namely, $A$ has a
flat-tailed spectrum, e.g., due to noisy data or regularization), this improves
on both the cost of solving the system directly, as well as on the cost of
preconditioning an iterative method such as conjugate gradient. In particular,
our algorithm has an $\tilde O(n^2)$ runtime when $k=O(n^{0.729})$. We further
adapt this result to sparse positive semidefinite matrices and least squares
regression.
</p>
<p>Our main algorithm can be viewed as a randomized block coordinate descent
method, where the key challenge is simultaneously ensuring good convergence and
fast per-iteration time. In our analysis, we use theory of majorization for
elementary symmetric polynomials to establish a sharp convergence guarantee
when coordinate blocks are sampled using a determinantal point process. We then
use a Markov chain coupling argument to show that similar convergence can be
attained with a cheaper sampling scheme, and accelerate the block coordinate
descent update via matrix sketching.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08894">HAROOD: Human Activity Classification and Out-of-Distribution Detection with Short-Range FMCW Radar. (arXiv:2312.08894v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kahya_S/0/1/0/all/0/1">Sabri Mustafa Kahya</a>, <a href="http://arxiv.org/find/cs/1/au:+Yavuz_M/0/1/0/all/0/1">Muhammet Sami Yavuz</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinbach_E/0/1/0/all/0/1">Eckehard Steinbach</a></p>
<p>We propose HAROOD as a short-range FMCW radar-based human activity classifier
and out-of-distribution (OOD) detector. It aims to classify human sitting,
standing, and walking activities and to detect any other moving or stationary
object as OOD. We introduce a two-stage network. The first stage is trained
with a novel loss function that includes intermediate reconstruction loss,
intermediate contrastive loss, and triplet loss. The second stage uses the
first stage's output as its input and is trained with cross-entropy loss. It
creates a simple classifier that performs the activity classification. On our
dataset collected by 60 GHz short-range FMCW radar, we achieve an average
classification accuracy of 96.51%. Also, we achieve an average AUROC of 95.04%
as an OOD detector. Additionally, our extensive evaluations demonstrate the
superiority of HAROOD over the state-of-the-art OOD detection methods in terms
of standard OOD detection metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08898">Detection and Defense of Unlearnable Examples. (arXiv:2312.08898v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yifan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lijia Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiao-Shan Gao</a></p>
<p>Privacy preserving has become increasingly critical with the emergence of
social media. Unlearnable examples have been proposed to avoid leaking personal
information on the Internet by degrading generalization abilities of deep
learning models. However, our study reveals that unlearnable examples are
easily detectable. We provide theoretical results on linear separability of
certain unlearnable poisoned dataset and simple network based detection methods
that can identify all existing unlearnable examples, as demonstrated by
extensive experiments. Detectability of unlearnable examples with simple
networks motivates us to design a novel defense method. We propose using
stronger data augmentations coupled with adversarial noises generated by simple
networks, to degrade the detectability and thus provide effective defense
against unlearnable examples with a lower cost. Adversarial training with large
budgets is a widely-used defense method on unlearnable examples. We establish
quantitative criteria between the poison and adversarial budgets which
determine the existence of robust unlearnable examples or the failure of the
adversarial defense.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08900">Context-PEFT: Efficient Multi-Modal, Multi-Task Fine-Tuning. (arXiv:2312.08900v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hadji_Kyriacou_A/0/1/0/all/0/1">Avelina Asada Hadji-Kyriacou</a>, <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1">Ognjen Arandjelovic</a></p>
<p>This paper introduces a novel Parameter-Efficient Fine-Tuning (PEFT)
framework for multi-modal, multi-task transfer learning with pre-trained
language models. PEFT techniques such as LoRA, BitFit and IA3 have demonstrated
comparable performance to full fine-tuning of pre-trained models for specific
downstream tasks, all while demanding significantly fewer trainable parameters
and reduced GPU memory consumption. However, in the context of multi-modal
fine-tuning, the need for architectural modifications or full fine-tuning often
becomes apparent. To address this we propose Context-PEFT, which learns
different groups of adaptor parameters based on the token's domain. This
approach enables LoRA-like weight injection without requiring additional
architectural changes. Our method is evaluated on the COCO captioning task,
where it outperforms full fine-tuning under similar data constraints while
simultaneously offering a substantially more parameter-efficient and
computationally economical solution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08933">Multi-Modal Learning-based Reconstruction of High-Resolution Spatial Wind Speed Fields. (arXiv:2312.08933v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zambra_M/0/1/0/all/0/1">Matteo Zambra</a>, <a href="http://arxiv.org/find/cs/1/au:+Farrugia_N/0/1/0/all/0/1">Nicolas Farrugia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cazau_D/0/1/0/all/0/1">Dorian Cazau</a>, <a href="http://arxiv.org/find/cs/1/au:+Gensse_A/0/1/0/all/0/1">Alexandre Gensse</a>, <a href="http://arxiv.org/find/cs/1/au:+Fablet_R/0/1/0/all/0/1">Ronan Fablet</a></p>
<p>Wind speed at sea surface is a key quantity for a variety of scientific
applications and human activities. Due to the non-linearity of the phenomenon,
a complete description of such variable is made infeasible on both the small
scale and large spatial extents. Methods relying on Data Assimilation
techniques, despite being the state-of-the-art for Numerical Weather
Prediction, can not provide the reconstructions with a spatial resolution that
can compete with satellite imagery. In this work we propose a framework based
on Variational Data Assimilation and Deep Learning concepts. This framework is
applied to recover rich-in-time, high-resolution information on sea surface
wind speed. We design our experiments using synthetic wind data and different
sampling schemes for high-resolution and low-resolution versions of original
data to emulate the real-world scenario of spatio-temporally heterogeneous
observations. Extensive numerical experiments are performed to assess
systematically the impact of low and high-resolution wind fields and in-situ
observations on the model reconstruction performance. We show that in-situ
observations with richer temporal resolution represent an added value in terms
of the model reconstruction performance. We show how a multi-modal approach,
that explicitly informs the model about the heterogeneity of the available
observations, can improve the reconstruction task by exploiting the
complementary information in spatial and local point-wise data. To conclude, we
propose an analysis to test the robustness of the chosen framework against
phase delay and amplitude biases in low-resolution data and against
interruptions of in-situ observations supply at evaluation time
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08935">Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in Mathematical Reasoning. (arXiv:2312.08935v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peiyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhihong Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">R.X. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Damai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yifei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Deli Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Y.Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1">Zhifang Sui</a></p>
<p>Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks. However, even the most advanced open-source LLMs, such
as the LLaMA family models, still face challenges when it comes to accurately
solving complex multi-step mathematical problems. In this paper, we present an
innovative process-oriented math verifier called \textbf{Math-Shepherd}, which
assigns a reward score to each step of the LLM's outputs on math problems. The
training of Math-Shepherd is achieved using automatically constructed
process-wise supervision data, breaking the bottleneck of heavy reliance on
manual annotation in existing work. With the guidance of Math-Shepherd, a
series of open-source LLMs demonstrate exceptional performance. Among them,
DeepSeek 67B \citep{DeepSeek-llm} stands out by achieving accuracy rates of
93.3\% on the GSM8K dataset and 48.1\% on the MATH dataset, without external
enhancement such as tool usage. Our Math-Shepherd also outperforms the
self-consistency method and other existing verification models. We believe that
automatic process supervision holds significant potential for the future
evolution of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08937">BiPFT: Binary Pre-trained Foundation Transformer with Low-rank Estimation of Binarization Residual Polynomials. (arXiv:2312.08937v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1">Xingrun Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Li Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xianlin Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yequan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiajun Zhang</a></p>
<p>Pretrained foundation models offer substantial benefits for a wide range of
downstream tasks, which can be one of the most potential techniques to access
artificial general intelligence. However, scaling up foundation transformers
for maximal task-agnostic knowledge has brought about computational challenges,
especially on resource-limited devices such as mobiles. This work proposes the
first Binary Pretrained Foundation Transformer (BiPFT) for natural language
understanding (NLU) tasks, which remarkably saves 56 times operations and 28
times memory. In contrast to previous task-specific binary transformers, BiPFT
exhibits a substantial enhancement in the learning capabilities of binary
neural networks (BNNs), promoting BNNs into the era of pre-training. Benefiting
from extensive pretraining data, we further propose a data-driven binarization
method. Specifically, we first analyze the binarization error in self-attention
operations and derive the polynomials of binarization error. To simulate
full-precision self-attention, we define binarization error as binarization
residual polynomials, and then introduce low-rank estimators to model these
polynomials. Extensive experiments validate the effectiveness of BiPFTs,
surpassing task-specific baseline by 15.4% average performance on the GLUE
benchmark. BiPFT also demonstrates improved robustness to hyperparameter
changes, improved optimization efficiency, and reduced reliance on downstream
distillation, which consequently generalize on various NLU tasks and simplify
the downstream pipeline of BNNs. Our code and pretrained models are publicly
available at https://github.com/Xingrun-Xing/BiPFT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08939">EAT: Towards Long-Tailed Out-of-Distribution Detection. (arXiv:2312.08939v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1">Tong Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bo-Lin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min-Ling Zhang</a></p>
<p>Despite recent advancements in out-of-distribution (OOD) detection, most
current studies assume a class-balanced in-distribution training dataset, which
is rarely the case in real-world scenarios. This paper addresses the
challenging task of long-tailed OOD detection, where the in-distribution data
follows a long-tailed class distribution. The main difficulty lies in
distinguishing OOD data from samples belonging to the tail classes, as the
ability of a classifier to detect OOD instances is not strongly correlated with
its accuracy on the in-distribution classes. To overcome this issue, we propose
two simple ideas: (1) Expanding the in-distribution class space by introducing
multiple abstention classes. This approach allows us to build a detector with
clear decision boundaries by training on OOD data using virtual labels. (2)
Augmenting the context-limited tail classes by overlaying images onto the
context-rich OOD data. This technique encourages the model to pay more
attention to the discriminative features of the tail classes. We provide a clue
for separating in-distribution and OOD data by analyzing gradient noise.
Through extensive experiments, we demonstrate that our method outperforms the
current state-of-the-art on various benchmark datasets. Moreover, our method
can be used as an add-on for existing long-tail learning approaches,
significantly enhancing their OOD detection performance. Code is available at:
https://github.com/Stomach-ache/Long-Tailed-OOD-Detection .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08944">What&#x27;s Next? Predicting Hamiltonian Dynamics from Discrete Observations of a Vector Field. (arXiv:2312.08944v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khoo_Z/0/1/0/all/0/1">Zi-Yu Khoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Delong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bressan_S/0/1/0/all/0/1">St&#xe9;phane Bressan</a></p>
<p>We present several methods for predicting the dynamics of Hamiltonian systems
from discrete observations of their vector field. Each method is either
informed or uninformed of the Hamiltonian property. We empirically and
comparatively evaluate the methods and observe that information that the system
is Hamiltonian can be effectively informed, and that different methods strike
different trade-offs between efficiency and effectiveness for different
dynamical systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08948">LSTM Network Analysis of Vehicle-Type Fatalities on Great Britain&#x27;s Roads. (arXiv:2312.08948v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oketunji_A/0/1/0/all/0/1">Abiodun Finbarrs Oketunji</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanify_J/0/1/0/all/0/1">James Hanify</a>, <a href="http://arxiv.org/find/cs/1/au:+Heffron_Smith_S/0/1/0/all/0/1">Salter Heffron-Smith</a></p>
<p>This study harnesses the predictive capabilities of Long Short-Term Memory
(LSTM) networks to analyse and predict road traffic accidents in Great Britain.
It addresses the challenge of traffic accident forecasting, which is paramount
for devising effective preventive measures. We utilised an extensive dataset
encompassing reported collisions, casualties, and vehicles involvements from
1926 to 2022, provided by the Department for Transport (DfT). The data
underwent stringent processing to rectify missing values and normalise
features, ensuring robust LSTM network input.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08958">LiFT: Unsupervised Reinforcement Learning with Foundation Models as Teachers. (arXiv:2312.08958v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nam_T/0/1/0/all/0/1">Taewook Nam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juyong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jesse Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1">Joseph J. Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Pertsch_K/0/1/0/all/0/1">Karl Pertsch</a></p>
<p>We propose a framework that leverages foundation models as teachers, guiding
a reinforcement learning agent to acquire semantically meaningful behavior
without human feedback. In our framework, the agent receives task instructions
grounded in a training environment from large language models. Then, a
vision-language model guides the agent in learning the multi-task
language-conditioned policy by providing reward feedback. We demonstrate that
our method can learn semantically meaningful skills in a challenging open-ended
MineDojo environment while prior unsupervised skill discovery methods struggle.
Additionally, we discuss observed challenges of using off-the-shelf foundation
models as teachers and our efforts to address them.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08976">Entity-Augmented Code Generation. (arXiv:2312.08976v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shapkin_A/0/1/0/all/0/1">Anton Shapkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Litvinov_D/0/1/0/all/0/1">Denis Litvinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bryksin_T/0/1/0/all/0/1">Timofey Bryksin</a></p>
<p>The current state-of-the-art large language models (LLMs) are effective in
generating high-quality text and encapsulating a broad spectrum of world
knowledge. However, these models often hallucinate during generation and are
not designed to utilize external information sources. To enable requests to the
external knowledge bases, also called knowledge grounding, retrieval-augmented
LLMs were introduced. For now, their applications have largely involved Open
Domain Question Answering, Abstractive Question Answering, and such. In this
paper, we broaden the scope of retrieval-augmented LLMs by venturing into a new
task - code generation using external entities. For this task, we collect and
publish a new dataset for project-level code generation, where the model should
reuse functions defined in the project during generation. As we show, existing
retrieval-augmented LLMs fail to assign relevance scores between similar entity
names, and to mitigate it, they expand entity names with description context
and append it to the input. In practice, due to the limited context size they
can not accommodate the indefinitely large context of the whole project. To
solve this issue, we propose a novel end-to-end trainable architecture with an
scalable entity retriever injected directly into the LLM decoder. We
demonstrate that our model can outperform common baselines in several
scenarios, including project-level code generation, as well as Bash and SQL
scripting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08977">Weighted Ensemble Models Are Strong Continual Learners. (arXiv:2312.08977v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marouf_I/0/1/0/all/0/1">Imad Eddine Marouf</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhankar Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Tartaglione_E/0/1/0/all/0/1">Enzo Tartaglione</a>, <a href="http://arxiv.org/find/cs/1/au:+Lathuiliere_S/0/1/0/all/0/1">St&#xe9;phane Lathuili&#xe8;re</a></p>
<p>In this work, we study the problem of continual learning (CL) where the goal
is to learn a model on a sequence of tasks, such that the data from the
previous tasks becomes unavailable while learning on the current task data. CL
is essentially a balancing act between being able to learn on the new task
(i.e., plasticity) and maintaining the performance on the previously learned
concepts (i.e., stability). With an aim to address the stability-plasticity
trade-off, we propose to perform weight-ensembling of the model parameters of
the previous and current task. This weight-ensembled model, which we call
Continual Model Averaging (or CoMA), attains high accuracy on the current task
by leveraging plasticity, while not deviating too far from the previous weight
configuration, ensuring stability. We also propose an improved variant of CoMA,
named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively
weighs each parameter in the weight ensemble by leveraging the Fisher
information of the weights of the model. Both the variants are conceptually
simple, easy to implement, and effective in attaining state-of-the-art
performance on several standard CL benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08994">PANDA: Architecture-Level Power Evaluation by Unifying Analytical and Machine Learning Solutions. (arXiv:2312.08994v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qijun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shiyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guanglei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jingyu Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chen-Chia Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhiyao Xie</a></p>
<p>Power efficiency is a critical design objective in modern microprocessor
design. To evaluate the impact of architectural-level design decisions, an
accurate yet efficient architecture-level power model is desired. However,
widely adopted data-independent analytical power models like McPAT and Wattch
have been criticized for their unreliable accuracy. While some machine learning
(ML) methods have been proposed for architecture-level power modeling, they
rely on sufficient known designs for training and perform poorly when the
number of available designs is limited, which is typically the case in
realistic scenarios.
</p>
<p>In this work, we derive a general formulation that unifies existing
architecture-level power models. Based on the formulation, we propose PANDA, an
innovative architecture-level solution that combines the advantages of
analytical and ML power models. It achieves unprecedented high accuracy on
unknown new designs even when there are very limited designs for training,
which is a common challenge in practice. Besides being an excellent power
model, it can predict area, performance, and energy accurately. PANDA further
supports power prediction for unknown new technology nodes. In our experiments,
besides validating the superior performance and the wide range of
functionalities of PANDA, we also propose an application scenario, where PANDA
proves to identify high-performance design configurations given a power
constraint.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08999">Conformalised data synthesis with statistical quality guarantees. (arXiv:2312.08999v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meister_J/0/1/0/all/0/1">Julia A. Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Khuong An Nguyen</a></p>
<p>With the proliferation of ever more complicated Deep Learning architectures,
data synthesis is a highly promising technique to address the demand of
data-hungry models. However, reliably assessing the quality of a 'synthesiser'
model's output is an open research question with significant associated risks
for high-stake domains. To address this challenge, we have designed a unique
confident data synthesis algorithm that introduces statistical confidence
guarantees through a novel extension of the Conformal Prediction framework. We
support our proposed algorithm with theoretical proofs and an extensive
empirical evaluation of five benchmark datasets. To show our approach's
versatility on ubiquitous real-world challenges, the datasets were carefully
selected for their variety of difficult characteristics: low sample count,
class imbalance and non-separability, and privacy-sensitive data. In all
trials, training sets extended with our confident synthesised data performed at
least as well as the original, and frequently significantly improved Deep
Learning performance by up to +65% F1-score.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09002">Localization with Reconfigurable Intelligent Surface: An Active Sensing Approach. (arXiv:2312.09002v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhongze Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wei Yu</a></p>
<p>This paper addresses an uplink localization problem in which a base station
(BS) aims to locate a remote user with the help of reconfigurable intelligent
surfaces (RISs). We propose a strategy in which the user transmits pilots
sequentially and the BS adaptively adjusts the sensing vectors, including the
BS beamforming vector and multiple RIS reflection coefficients based on the
observations already made, to eventually produce an estimated user position.
This is a challenging active sensing problem for which finding an optimal
solution involves searching through a complicated functional space whose
dimension increases with the number of measurements. We show that the long
short-term memory (LSTM) network can be used to exploit the latent temporal
correlation between measurements to automatically construct scalable state
vectors. Subsequently, the state vector is mapped to the sensing vectors for
the next time frame via a deep neural network (DNN). A final DNN is used to map
the state vector to the estimated user position. Numerical result illustrates
the advantage of the active sensing design as compared to non-active sensing
methods. The proposed solution produces interpretable results and is
generalizable in the number of sensing stages. Remarkably, we show that a
network with one BS and multiple RISs can outperform a comparable setting with
multiple BSs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09004">Holistic chemical evaluation reveals pitfalls in reaction prediction models. (arXiv:2312.09004v1 [physics.chem-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Gil_V/0/1/0/all/0/1">Victor Sabanza Gil</a>, <a href="http://arxiv.org/find/physics/1/au:+Bran_A/0/1/0/all/0/1">Andres M. Bran</a>, <a href="http://arxiv.org/find/physics/1/au:+Franke_M/0/1/0/all/0/1">Malte Franke</a>, <a href="http://arxiv.org/find/physics/1/au:+Schlama_R/0/1/0/all/0/1">Remi Schlama</a>, <a href="http://arxiv.org/find/physics/1/au:+Luterbacher_J/0/1/0/all/0/1">Jeremy S. Luterbacher</a>, <a href="http://arxiv.org/find/physics/1/au:+Schwaller_P/0/1/0/all/0/1">Philippe Schwaller</a></p>
<p>The prediction of chemical reactions has gained significant interest within
the machine learning community in recent years, owing to its complexity and
crucial applications in chemistry. However, model evaluation for this task has
been mostly limited to simple metrics like top-k accuracy, which obfuscates
fine details of a model's limitations. Inspired by progress in other fields, we
propose a new assessment scheme that builds on top of current approaches,
steering towards a more holistic evaluation. We introduce the following key
components for this goal: CHORISO, a curated dataset along with multiple
tailored splits to recreate chemically relevant scenarios, and a collection of
metrics that provide a holistic view of a model's advantages and limitations.
Application of this method to state-of-the-art models reveals important
differences on sensitive fronts, especially stereoselectivity and chemical
out-of-distribution generalization. Our work paves the way towards robust
prediction models that can ultimately accelerate chemical discovery.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09006">FedSSA: Semantic Similarity-based Aggregation for Efficient Model-Heterogeneous Personalized Federated Learning. (arXiv:2312.09006v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yi_L/0/1/0/all/0/1">Liping Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoguang Liu</a></p>
<p>Federated learning (FL) is a privacy-preserving collaboratively machine
learning paradigm. Traditional FL requires all data owners (a.k.a. FL clients)
to train the same local model. This design is not well-suited for scenarios
involving data and/or system heterogeneity. Model-Heterogeneous Personalized FL
(MHPFL) has emerged to address this challenge. Existing MHPFL approaches often
rely on having a public dataset with the same nature of the learning task, or
incur high computation and communication costs. To address these limitations,
we propose the Federated Semantic Similarity Aggregation (FedSSA) approach,
which splits each client's model into a heterogeneous (structure-different)
feature extractor and a homogeneous (structure-same) classification header. It
performs local-to-global knowledge transfer via semantic similarity-based
header parameter aggregation. In addition, global-to-local knowledge transfer
is achieved via an adaptive parameter stabilization strategy which fuses the
seen-class parameters of historical local headers with that of the latest
global header for each client. In this way, FedSSA does not rely on public
datasets, while only requiring partial header parameter transmission (thereby
saving costs). Theoretical analysis proves the convergence of FedSSA. Extensive
experiments demonstrate that FedSSA achieves up to $3.62 \times\%$ higher
accuracy, $15.54$ times higher communication efficiency, and $15.52 \times$
higher computational efficiency compared to 7 state-of-the-art MHPFL baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09015">Uncertainty in GNN Learning Evaluations: A Comparison Between Measures for Quantifying Randomness in GNN Community Detection. (arXiv:2312.09015v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leeney_W/0/1/0/all/0/1">William Leeney</a>, <a href="http://arxiv.org/find/cs/1/au:+McConville_R/0/1/0/all/0/1">Ryan McConville</a></p>
<p>(1) The enhanced capability of Graph Neural Networks (GNNs) in unsupervised
community detection of clustered nodes is attributed to their capacity to
encode both the connectivity and feature information spaces of graphs. The
identification of latent communities holds practical significance in various
domains, from social networks to genomics. Current real-world performance
benchmarks are perplexing due to the multitude of decisions influencing GNN
evaluations for this task. (2) Three metrics are compared to assess the
consistency of algorithm rankings in the presence of randomness. The
consistency and quality of performance between the results under a
hyperparameter optimisation with the default hyperparameters is evaluated. (3)
The results compare hyperparameter optimisation with default hyperparameters,
revealing a significant performance loss when neglecting hyperparameter
investigation. A comparison of metrics indicates that ties in ranks can
substantially alter the quantification of randomness. (4) Ensuring adherence to
the same evaluation criteria may result in notable differences in the reported
performance of methods for this task. The $W$ Randomness coefficient, based on
the Wasserstein distance, is identified as providing the most robust assessment
of randomness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09016">Symmetry Breaking and Equivariant Neural Networks. (arXiv:2312.09016v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kaba_S/0/1/0/all/0/1">S&#xe9;kou-Oumar Kaba</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravanbakhsh_S/0/1/0/all/0/1">Siamak Ravanbakhsh</a></p>
<p>Using symmetry as an inductive bias in deep learning has been proven to be a
principled approach for sample-efficient model design. However, the
relationship between symmetry and the imperative for equivariance in neural
networks is not always obvious. Here, we analyze a key limitation that arises
in equivariant functions: their incapacity to break symmetry at the level of
individual data samples. In response, we introduce a novel notion of 'relaxed
equivariance' that circumvents this limitation. We further demonstrate how to
incorporate this relaxation into equivariant multilayer perceptrons (E-MLPs),
offering an alternative to the noise-injection method. The relevance of
symmetry breaking is then discussed in various application domains: physics,
graph representation learning, combinatorial optimization and equivariant
decoding.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09023">A Framework for Exploring Federated Community Detection. (arXiv:2312.09023v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leeney_W/0/1/0/all/0/1">William Leeney</a>, <a href="http://arxiv.org/find/cs/1/au:+McConville_R/0/1/0/all/0/1">Ryan McConville</a></p>
<p>Federated Learning is machine learning in the context of a network of clients
whilst maintaining data residency and/or privacy constraints. Community
detection is the unsupervised discovery of clusters of nodes within
graph-structured data. The intersection of these two fields uncovers much
opportunity, but also challenge. For example, it adds complexity due to missing
connectivity information between privately held graphs. In this work, we
explore the potential of federated community detection by conducting initial
experiments across a range of existing datasets that showcase the gap in
performance introduced by the distributed data. We demonstrate that isolated
models would benefit from collaboration establishing a framework for
investigating challenges within this domain. The intricacies of these research
frontiers are discussed alongside proposed solutions to these issues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09038">Object Recognition from Scientific Document based on Compartment Refinement Framework. (arXiv:2312.09038v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinghong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_W/0/1/0/all/0/1">Wen Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ota_K/0/1/0/all/0/1">Koichi Ota</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasegawa_S/0/1/0/all/0/1">Shinobu Hasegawa</a></p>
<p>With the rapid development of the internet in the past decade, it has become
increasingly important to extract valuable information from vast resources
efficiently, which is crucial for establishing a comprehensive digital
ecosystem, particularly in the context of research surveys and comprehension.
The foundation of these tasks focuses on accurate extraction and deep mining of
data from scientific documents, which are essential for building a robust data
infrastructure. However, parsing raw data or extracting data from complex
scientific documents have been ongoing challenges. Current data extraction
methods for scientific documents typically use rule-based (RB) or machine
learning (ML) approaches. However, using rule-based methods can incur high
coding costs for articles with intricate typesetting. Conversely, relying
solely on machine learning methods necessitates annotation work for complex
content types within the scientific document, which can be costly.
Additionally, few studies have thoroughly defined and explored the hierarchical
layout within scientific documents. The lack of a comprehensive definition of
the internal structure and elements of the documents indirectly impacts the
accuracy of text classification and object recognition tasks. From the
perspective of analyzing the standard layout and typesetting used in the
specified publication, we propose a new document layout analysis framework
called CTBR(Compartment &amp; Text Blocks Refinement). Firstly, we define
scientific documents into hierarchical divisions: base domain, compartment, and
text blocks. Next, we conduct an in-depth exploration and classification of the
meanings of text blocks. Finally, we utilize the results of text block
classification to implement object recognition within scientific documents
based on rule-based compartment segmentation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2104.11893">LGD-GCN: Local and Global Disentangled Graph Convolutional Networks. (arXiv:2104.11893v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jingwei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xinping Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a></p>
<p>Disentangled Graph Convolutional Network (DisenGCN) is an encouraging
framework to disentangle the latent factors arising in a real-world graph.
However, it relies on disentangling information heavily from a local range
(i.e., a node and its 1-hop neighbors), while the local information in many
cases can be uneven and incomplete, hindering the interpretabiliy power and
model performance of DisenGCN. In this paper\footnote{This paper is a lighter
version of \href{https://jingweio.github.io/assets/pdf/tnnls22.pdf}{"Learning
Disentangled Graph Convolutional Networks Locally and Globally"} where the
results and analysis have been reworked substantially. Digital Object
Identifier \url{https://doi.org/10.1109/TNNLS.<a href="/abs/2022.31953">2022.31953</a>36}.}, we introduce a
novel Local and Global Disentangled Graph Convolutional Network (LGD-GCN) to
capture both local and global information for graph disentanglement. LGD-GCN
performs a statistical mixture modeling to derive a factor-aware latent
continuous space, and then constructs different structures w.r.t. different
factors from the revealed space. In this way, the global factor-specific
information can be efficiently and selectively encoded via a message passing
along these built structures, strengthening the intra-factor consistency. We
also propose a novel diversity promoting regularizer employed with the latent
space modeling, to encourage inter-factor diversity. Evaluations of the
proposed LGD-GCN on the synthetic and real-world datasets show a better
interpretability and improved performance in node classification over the
existing competitive models. Code is available at
\url{https://github.com/jingweio/LGD-GCN}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.04720">Amicable Aid: Perturbing Images to Improve Classification Performance. (arXiv:2112.04720v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juyeop Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jun-Ho Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1">Soobeom Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jong-Seok Lee</a></p>
<p>While adversarial perturbation of images to attack deep image classification
models pose serious security concerns in practice, this paper suggests a novel
paradigm where the concept of image perturbation can benefit classification
performance, which we call amicable aid. We show that by taking the opposite
search direction of perturbation, an image can be modified to yield higher
classification confidence and even a misclassified image can be made correctly
classified. This can be also achieved with a large amount of perturbation by
which the image is made unrecognizable by human eyes. The mechanism of the
amicable aid is explained in the viewpoint of the underlying natural image
manifold. Furthermore, we investigate the universal amicable aid, i.e., a fixed
perturbation can be applied to multiple images to improve their classification
results. While it is challenging to find such perturbations, we show that
making the decision boundary as perpendicular to the image manifold as possible
via training with modified data is effective to obtain a model for which
universal amicable perturbations are more easily found.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.10083">A Unified Experiment Design Approach for Cyclic and Acyclic Causal Models. (arXiv:2205.10083v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mokhtarian_E/0/1/0/all/0/1">Ehsan Mokhtarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Salehkaleybar_S/0/1/0/all/0/1">Saber Salehkaleybar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1">AmirEmad Ghassami</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1">Negar Kiyavash</a></p>
<p>We study experiment design for unique identification of the causal graph of a
simple SCM, where the graph may contain cycles. The presence of cycles in the
structure introduces major challenges for experiment design as, unlike acyclic
graphs, learning the skeleton of causal graphs with cycles may not be possible
from merely the observational distribution. Furthermore, intervening on a
variable in such graphs does not necessarily lead to orienting all the edges
incident to it. In this paper, we propose an experiment design approach that
can learn both cyclic and acyclic graphs and hence, unifies the task of
experiment design for both types of graphs. We provide a lower bound on the
number of experiments required to guarantee the unique identification of the
causal graph in the worst case, showing that the proposed approach is
order-optimal in terms of the number of experiments up to an additive
logarithmic term. Moreover, we extend our result to the setting where the size
of each experiment is bounded by a constant. For this case, we show that our
approach is optimal in terms of the size of the largest experiment required for
uniquely identifying the causal graph in the worst case.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.10347">Diverse super-resolution with pretrained deep hiererarchical VAEs. (arXiv:2205.10347v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Prost_J/0/1/0/all/0/1">Jean Prost</a>, <a href="http://arxiv.org/find/cs/1/au:+Houdard_A/0/1/0/all/0/1">Antoine Houdard</a>, <a href="http://arxiv.org/find/cs/1/au:+Almansa_A/0/1/0/all/0/1">Andr&#xe9;s Almansa</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadakis_N/0/1/0/all/0/1">Nicolas Papadakis</a></p>
<p>We investigate the problem of producing diverse solutions to an image
super-resolution problem. From a probabilistic perspective, this can be done by
sampling from the posterior distribution of an inverse problem, which requires
the definition of a prior distribution on the high-resolution images. In this
work, we propose to use a pretrained hierarchical variational autoencoder
(HVAE) as a prior. We train a lightweight stochastic encoder to encode
low-resolution images in the latent space of a pretrained HVAE. At inference,
we combine the low-resolution encoder and the pretrained generative model to
super-resolve an image. We demonstrate on the task of face super-resolution
that our method provides an advantageous trade-off between the computational
efficiency of conditional normalizing flows techniques and the sample quality
of diffusion based methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.14683">The impact of memory on learning sequence-to-sequence tasks. (arXiv:2205.14683v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seif_A/0/1/0/all/0/1">Alireza Seif</a>, <a href="http://arxiv.org/find/cs/1/au:+Loos_S/0/1/0/all/0/1">Sarah A.M. Loos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tucci_G/0/1/0/all/0/1">Gennaro Tucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Roldan_E/0/1/0/all/0/1">&#xc9;dgar Rold&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldt_S/0/1/0/all/0/1">Sebastian Goldt</a></p>
<p>The recent success of neural networks in natural language processing has
drawn renewed attention to learning sequence-to-sequence (seq2seq) tasks. While
there exists a rich literature that studies classification and regression tasks
using solvable models of neural networks, seq2seq tasks have not yet been
studied from this perspective. Here, we propose a simple model for a seq2seq
task that has the advantage of providing explicit control over the degree of
memory, or non-Markovianity, in the sequences -- the stochastic
switching-Ornstein-Uhlenbeck (SSOU) model. We introduce a measure of
non-Markovianity to quantify the amount of memory in the sequences. For a
minimal auto-regressive (AR) learning model trained on this task, we identify
two learning regimes corresponding to distinct phases in the stationary state
of the SSOU process. These phases emerge from the interplay between two
different time scales that govern the sequence statistics. Moreover, we observe
that while increasing the integration window of the AR model always improves
performance, albeit with diminishing returns, increasing the non-Markovianity
of the input sequences can improve or degrade its performance. Finally, we
perform experiments with recurrent and convolutional neural networks that show
that our observations carry over to more complicated neural network
architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.05575">MammoFL: Mammographic Breast Density Estimation using Federated Learning. (arXiv:2206.05575v5 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Muthukrishnan_R/0/1/0/all/0/1">Ramya Muthukrishnan</a>, <a href="http://arxiv.org/find/eess/1/au:+Heyler_A/0/1/0/all/0/1">Angelina Heyler</a>, <a href="http://arxiv.org/find/eess/1/au:+Katti_K/0/1/0/all/0/1">Keshava Katti</a>, <a href="http://arxiv.org/find/eess/1/au:+Pati_S/0/1/0/all/0/1">Sarthak Pati</a>, <a href="http://arxiv.org/find/eess/1/au:+Mankowski_W/0/1/0/all/0/1">Walter Mankowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Alahari_A/0/1/0/all/0/1">Aprupa Alahari</a>, <a href="http://arxiv.org/find/eess/1/au:+Sanborn_M/0/1/0/all/0/1">Michael Sanborn</a>, <a href="http://arxiv.org/find/eess/1/au:+Conant_E/0/1/0/all/0/1">Emily F. Conant</a>, <a href="http://arxiv.org/find/eess/1/au:+Scott_C/0/1/0/all/0/1">Christopher Scott</a>, <a href="http://arxiv.org/find/eess/1/au:+Winham_S/0/1/0/all/0/1">Stacey Winham</a>, <a href="http://arxiv.org/find/eess/1/au:+Vachon_C/0/1/0/all/0/1">Celine Vachon</a>, <a href="http://arxiv.org/find/eess/1/au:+Chaudhari_P/0/1/0/all/0/1">Pratik Chaudhari</a>, <a href="http://arxiv.org/find/eess/1/au:+Kontos_D/0/1/0/all/0/1">Despina Kontos</a>, <a href="http://arxiv.org/find/eess/1/au:+Bakas_S/0/1/0/all/0/1">Spyridon Bakas</a></p>
<p>In this study, we automate quantitative mammographic breast density
estimation with neural networks and show that this tool is a strong use case
for federated learning on multi-institutional datasets. Our dataset included
bilateral CC-view and MLO-view mammographic images from two separate
institutions. Two U-Nets were separately trained on algorithm-generated labels
to perform segmentation of the breast and dense tissue from these images and
subsequently calculate breast percent density (PD). The networks were trained
with federated learning and compared to three non-federated baselines, one
trained on each single-institution dataset and one trained on the aggregated
multi-institution dataset. We demonstrate that training on multi-institution
datasets is critical to algorithm generalizability. We further show that
federated learning on multi-institutional datasets improves model
generalization to unseen data at nearly the same level as centralized training
on multi-institutional datasets, indicating that federated learning can be
applied to our method to improve algorithm generalizability while maintaining
patient privacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.05724">Concealing Sensitive Samples against Gradient Leakage in Federated Learning. (arXiv:2209.05724v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1">Munawar Hayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Harandi_M/0/1/0/all/0/1">Mehrtash Harandi</a></p>
<p>Federated Learning (FL) is a distributed learning paradigm that enhances
users privacy by eliminating the need for clients to share raw, private data
with the server. Despite the success, recent studies expose the vulnerability
of FL to model inversion attacks, where adversaries reconstruct users private
data via eavesdropping on the shared gradient information. We hypothesize that
a key factor in the success of such attacks is the low entanglement among
gradients per data within the batch during stochastic optimization. This
creates a vulnerability that an adversary can exploit to reconstruct the
sensitive data. Building upon this insight, we present a simple, yet effective
defense strategy that obfuscates the gradients of the sensitive data with
concealed samples. To achieve this, we propose synthesizing concealed samples
to mimic the sensitive data at the gradient level while ensuring their visual
dissimilarity from the actual sensitive data. Compared to the previous art, our
empirical evaluations suggest that the proposed technique provides the
strongest protection while simultaneously maintaining the FL performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.17178">Learning to Optimize Permutation Flow Shop Scheduling via Graph-based Imitation Learning. (arXiv:2210.17178v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Longkang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1">Siyuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Chris Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Baoyuan Wu</a></p>
<p>The permutation flow shop scheduling (PFSS), aiming at finding the optimal
permutation of jobs, is widely used in manufacturing systems. When solving
large-scale PFSS problems, traditional optimization algorithms such as
heuristics could hardly meet the demands of both solution accuracy and
computational efficiency, thus learning-based methods have recently garnered
more attention. Some work attempts to solve the problems by reinforcement
learning methods, which suffer from slow convergence issues during training and
are still not accurate enough regarding the solutions. To that end, we propose
to train the model via expert-driven imitation learning, which accelerates
convergence more stably and accurately. Moreover, in order to extract better
feature representations of input jobs, we incorporate the graph structure as
the encoder. The extensive experiments reveal that our proposed model obtains
significant promotion and presents excellent generalizability in large-scale
problems with up to 1000 jobs. Compared to the state-of-the-art reinforcement
learning method, our model's network parameters are reduced to only 37\% of
theirs, and the solution gap of our model towards the expert solutions
decreases from 6.8\% to 1.3\% on average. The code is available at:
\url{https://github.com/longkangli/PFSS-IL}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08622">Impact of Redundancy on Resilience in Distributed Optimization and Learning. (arXiv:2211.08622v2 [cs.DC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nirupam Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaidya_N/0/1/0/all/0/1">Nitin H. Vaidya</a></p>
<p>This report considers the problem of resilient distributed optimization and
stochastic learning in a server-based architecture. The system comprises a
server and multiple agents, where each agent has its own local cost function.
The agents collaborate with the server to find a minimum of the aggregate of
the local cost functions. In the context of stochastic learning, the local cost
of an agent is the loss function computed over the data at that agent. In this
report, we consider this problem in a system wherein some of the agents may be
Byzantine faulty and some of the agents may be slow (also called stragglers).
In this setting, we investigate the conditions under which it is possible to
obtain an "approximate" solution to the above problem. In particular, we
introduce the notion of $(f, r; \epsilon)$-resilience to characterize how well
the true solution is approximated in the presence of up to $f$ Byzantine faulty
agents, and up to $r$ slow agents (or stragglers) -- smaller $\epsilon$
represents a better approximation. We also introduce a measure named $(f, r;
\epsilon)$-redundancy to characterize the redundancy in the cost functions of
the agents. Greater redundancy allows for a better approximation when solving
the problem of aggregate cost minimization.
</p>
<p>In this report, we constructively show (both theoretically and empirically)
that $(f, r; \mathcal{O}(\epsilon))$-resilience can indeed be achieved in
practice, given that the local cost functions are sufficiently redundant.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.12986">Physics-informed neural networks for pathloss prediction. (arXiv:2211.12986v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Limmer_S/0/1/0/all/0/1">Steffen Limmer</a>, <a href="http://arxiv.org/find/stat/1/au:+Alba_A/0/1/0/all/0/1">Alberto Martinez Alba</a>, <a href="http://arxiv.org/find/stat/1/au:+Michailow_N/0/1/0/all/0/1">Nicola Michailow</a></p>
<p>This paper introduces a physics-informed machine learning approach for
pathloss prediction. This is achieved by including in the training phase
simultaneously (i) physical dependencies between spatial loss field and (ii)
measured pathloss values in the field. It is shown that the solution to a
proposed learning problem improves generalization and prediction quality with a
small number of neural network layers and parameters. The latter leads to fast
inference times which are favorable for downstream tasks such as localization.
Moreover, the physics-informed formulation allows training and prediction with
a small amount of training data which makes it appealing for a wide range of
practical pathloss prediction scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.14158">An Isolation-Aware Online Virtual Network Embedding via Deep Reinforcement Learning. (arXiv:2211.14158v3 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gohar_A/0/1/0/all/0/1">Ali Gohar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_C/0/1/0/all/0/1">Chunming Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sanghwan Lee</a></p>
<p>Virtualization technologies are the foundation of modern ICT infrastructure,
enabling service providers to create dedicated virtual networks (VNs) that can
support a wide range of smart city applications. These VNs continuously
generate massive amounts of data, necessitating stringent reliability and
security requirements. In virtualized network environments, however, multiple
VNs may coexist on the same physical infrastructure and, if not properly
isolated, may interfere with or provide unauthorized access to one another. The
former causes performance degradation, while the latter compromises the
security of VNs. Service assurance for infrastructure providers becomes
significantly more complicated when a specific VN violates the isolation
requirement.
</p>
<p>In an effort to address the isolation issue, this paper proposes isolation
during virtual network embedding (VNE), the procedure of allocating VNs onto
physical infrastructure. We define a simple abstracted concept of isolation
levels to capture the variations in isolation requirements and then formulate
isolation-aware VNE as an optimization problem with resource and isolation
constraints. A deep reinforcement learning (DRL)-based VNE algorithm
ISO-DRL_VNE, is proposed that considers resource and isolation constraints and
is compared to the existing three state-of-the-art algorithms: NodeRank, Global
Resource Capacity (GRC), and Mote-Carlo Tree Search (MCTS). Evaluation results
show that the ISO-DRL_VNE algorithm outperforms others in acceptance ratio,
long-term average revenue, and long-term average revenue-to-cost ratio by 6%,
13%, and 15%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.08949">Managing Temporal Resolution in Continuous Value Estimation: A Fundamental Trade-off. (arXiv:2212.08949v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zichen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirschner_J/0/1/0/all/0/1">Johannes Kirschner</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junxi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanini_F/0/1/0/all/0/1">Francesco Zanini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayoub_A/0/1/0/all/0/1">Alex Ayoub</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehghan_M/0/1/0/all/0/1">Masood Dehghan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1">Dale Schuurmans</a></p>
<p>A default assumption in reinforcement learning (RL) and optimal control is
that observations arrive at discrete time points on a fixed clock cycle. Yet,
many applications involve continuous-time systems where the time
discretization, in principle, can be managed. The impact of time discretization
on RL methods has not been fully characterized in existing theory, but a more
detailed analysis of its effect could reveal opportunities for improving
data-efficiency. We address this gap by analyzing Monte-Carlo policy evaluation
for LQR systems and uncover a fundamental trade-off between approximation and
statistical error in value estimation. Importantly, these two errors behave
differently to time discretization, leading to an optimal choice of temporal
resolution for a given data budget. These findings show that managing the
temporal resolution can provably improve policy evaluation efficiency in LQR
systems with finite data. Empirically, we demonstrate the trade-off in
numerical simulations of LQR instances and standard RL benchmarks for
non-linear continuous control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.13120">Neural Structure Fields with Application to Crystal Structure Autoencoders. (arXiv:2212.13120v2 [cond-mat.mtrl-sci] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Chiba_N/0/1/0/all/0/1">Naoya Chiba</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Suzuki_Y/0/1/0/all/0/1">Yuta Suzuki</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Taniai_T/0/1/0/all/0/1">Tatsunori Taniai</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Igarashi_R/0/1/0/all/0/1">Ryo Igarashi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ushiku_Y/0/1/0/all/0/1">Yoshitaka Ushiku</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Saito_K/0/1/0/all/0/1">Kotaro Saito</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ono_K/0/1/0/all/0/1">Kanta Ono</a></p>
<p>Representing crystal structures of materials to facilitate determining them
via neural networks is crucial for enabling machine-learning applications
involving crystal structure estimation. Among these applications, the inverse
design of materials can contribute to explore materials with desired properties
without relying on luck or serendipity. We propose neural structure fields
(NeSF) as an accurate and practical approach for representing crystal
structures using neural networks. Inspired by the concepts of vector fields in
physics and implicit neural representations in computer vision, the proposed
NeSF considers a crystal structure as a continuous field rather than as a
discrete set of atoms. Unlike existing grid-based discretized spatial
representations, the NeSF overcomes the tradeoff between spatial resolution and
computational complexity and can represent any crystal structure. We propose an
autoencoder of crystal structures that can recover various crystal structures,
such as those of perovskite structure materials and cuprate superconductors.
Extensive quantitative results demonstrate the superior performance of the NeSF
compared with the existing grid-based approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.12562">Simplifying Subgraph Representation Learning for Scalable Link Prediction. (arXiv:2301.12562v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Louis_P/0/1/0/all/0/1">Paul Louis</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacob_S/0/1/0/all/0/1">Shweta Ann Jacob</a>, <a href="http://arxiv.org/find/cs/1/au:+Salehi_Abari_A/0/1/0/all/0/1">Amirali Salehi-Abari</a></p>
<p>Link prediction on graphs is a fundamental problem. Subgraph representation
learning approaches (SGRLs), by transforming link prediction to graph
classification on the subgraphs around the links, have achieved
state-of-the-art performance in link prediction. However, SGRLs are
computationally expensive, and not scalable to large-scale graphs due to
expensive subgraph-level operations. To unlock the scalability of SGRLs, we
propose a new class of SGRLs, that we call Scalable Simplified SGRL (S3GRL).
Aimed at faster training and inference, S3GRL simplifies the message passing
and aggregation operations in each link's subgraph. S3GRL, as a scalability
framework, accommodates various subgraph sampling strategies and diffusion
operators to emulate computationally-expensive SGRLs. We propose multiple
instances of S3GRL and empirically study them on small to large-scale graphs.
Our extensive experiments demonstrate that the proposed S3GRL models scale up
SGRLs without significant performance compromise (even with considerable gains
in some cases), while offering substantially lower computational footprints
(e.g., multi-fold inference and training speedup).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.12677">Distributed Stochastic Optimization under a General Variance Condition. (arXiv:2301.12677v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Li_X/0/1/0/all/0/1">Xiao Li</a>, <a href="http://arxiv.org/find/math/1/au:+Pu_S/0/1/0/all/0/1">Shi Pu</a></p>
<p>Distributed stochastic optimization has drawn great attention recently due to
its effectiveness in solving large-scale machine learning problems. Though
numerous algorithms have been proposed and successfully applied to general
practical problems, their theoretical guarantees mainly rely on certain
boundedness conditions on the stochastic gradients, varying from uniform
boundedness to the relaxed growth condition. In addition, how to characterize
the data heterogeneity among the agents and its impacts on the algorithmic
performance remains challenging. In light of such motivations, we revisit the
classical Federated Averaging (FedAvg) algorithm (McMahan et al., 2017) as well
as the more recent SCAFFOLD method (Karimireddy et al., 2020) for solving the
distributed stochastic optimization problem and establish the convergence
results under only a mild variance condition on the stochastic gradients for
smooth nonconvex objective functions. Almost sure convergence to a stationary
point is also established under the condition. Moreover, we discuss a more
informative measurement for data heterogeneity as well as its implications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00919">QCM-SGM+: Improved Quantized Compressed Sensing With Score-Based Generative Models. (arXiv:2302.00919v3 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Meng_X/0/1/0/all/0/1">Xiangming Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Kabashima_Y/0/1/0/all/0/1">Yoshiyuki Kabashima</a></p>
<p>In practical compressed sensing (CS), the obtained measurements typically
necessitate quantization to a limited number of bits prior to transmission or
storage. This nonlinear quantization process poses significant recovery
challenges, particularly with extreme coarse quantization such as 1-bit.
Recently, an efficient algorithm called QCS-SGM was proposed for quantized CS
(QCS) which utilizes score-based generative models (SGM) as an implicit prior.
Due to the adeptness of SGM in capturing the intricate structures of natural
signals, QCS-SGM substantially outperforms previous QCS methods. However,
QCS-SGM is constrained to (approximately) row-orthogonal sensing matrices as
the computation of the likelihood score becomes intractable otherwise. To
address this limitation, we introduce an advanced variant of QCS-SGM, termed
QCS-SGM+, capable of handling general matrices effectively. The key idea is a
Bayesian inference perspective on the likelihood score computation, wherein
expectation propagation is employed for its approximate computation. Extensive
experiments are conducted, demonstrating the substantial superiority of
QCS-SGM+ over QCS-SGM for general sensing matrices beyond mere
row-orthogonality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.01313">Double Equivariance for Inductive Link Prediction for Both New Nodes and New Relation Types. (arXiv:2302.01313v7 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yangze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jincheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1">Bruno Ribeiro</a></p>
<p>The task of inductive link prediction in knowledge graphs (KGs) generally
focuses on test predictions with solely new nodes but not both new nodes and
new relation types. In this work, we formally define the concept of double
permutation-equivariant representations that are equivariant to permutations of
both node identities and edge relation types. We then show how
double-equivariant architectures are able to self-supervise pre-train on
distinct KG domains and zero-shot predict links on a new KG domain (with
completely new entities and new relation types). We also introduce the concept
of distributionally double equivariant positional embeddings designed to
perform the same task. Finally, we empirically demonstrate the capability of
the proposed models against baselines on a set of novel real-world benchmarks.
More interestingly, we show that self-supervised pre-training on more KG
domains increases the zero-shot ability of our model to predict on new relation
types over new entities on unseen KG domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06228">Unsupervised Detection of Behavioural Drifts with Dynamic Clustering and Trajectory Analysis. (arXiv:2302.06228v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Prenkaj_B/0/1/0/all/0/1">Bardh Prenkaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Velardi_P/0/1/0/all/0/1">Paola Velardi</a></p>
<p>Real-time monitoring of human behaviours, especially in e-Health
applications, has been an active area of research in the past decades. On top
of IoT-based sensing environments, anomaly detection algorithms have been
proposed for the early detection of abnormalities. Gradual change procedures,
commonly referred to as drift anomalies, have received much less attention in
the literature because they represent a much more challenging scenario than
sudden temporary changes (point anomalies). In this paper, we propose, for the
first time, a fully unsupervised real-time drift detection algorithm named
DynAmo, which can identify drift periods as they are happening. DynAmo
comprises a dynamic clustering component to capture the overall trends of
monitored behaviours and a trajectory generation component, which extracts
features from the densest cluster centroids. Finally, we apply an ensemble of
divergence tests on sliding reference and detection windows to detect drift
periods in the behavioural sequence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.09639">An overview of differentiable particle filters for data-adaptive sequential Bayesian inference. (arXiv:2302.09639v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunpeng Li</a></p>
<p>By approximating posterior distributions with weighted samples, particle
filters (PFs) provide an efficient mechanism for solving non-linear sequential
state estimation problems. While the effectiveness of particle filters has been
recognised in various applications, their performance relies on the knowledge
of dynamic models and measurement models, as well as the construction of
effective proposal distributions. An emerging trend involves constructing
components of particle filters using neural networks and optimising them by
gradient descent, and such data-adaptive particle filtering approaches are
often called differentiable particle filters. Due to the expressiveness of
neural networks, differentiable particle filters are a promising computational
tool for performing inference on sequential data in complex, high-dimensional
tasks, such as vision-based robot localisation. In this paper, we review recent
advances in differentiable particle filters and their applications. We place
special emphasis on different design choices for key components of
differentiable particle filters, including dynamic models, measurement models,
proposal distributions, optimisation objectives, and differentiable resampling
techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.13020">DCLP: Neural Architecture Predictor with Curriculum Contrastive Learning. (arXiv:2302.13020v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shenghe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tianyu Mu</a></p>
<p>Neural predictors have shown great potential in the evaluation process of
neural architecture search (NAS). However, current predictor-based approaches
overlook the fact that training a predictor necessitates a considerable number
of trained neural networks as the labeled training set, which is costly to
obtain. Therefore, the critical issue in utilizing predictors for NAS is to
train a high-performance predictor using as few trained neural networks as
possible. Although some methods attempt to address this problem through
unsupervised learning, they often result in inaccurate predictions. We argue
that the unsupervised tasks intended for the common graph data are too
challenging for neural networks, causing unsupervised training to be
susceptible to performance crashes in NAS. To address this issue, we propose a
Curricumum-guided Contrastive Learning framework for neural Predictor (DCLP).
Our method simplifies the contrastive task by designing a novel curriculum to
enhance the stability of unlabeled training data distribution during
contrastive training. Specifically, we propose a scheduler that ranks the
training data according to the contrastive difficulty of each data and then
inputs them to the contrastive learner in order. This approach concentrates the
training data distribution and makes contrastive training more efficient. By
using our method, the contrastive learner incrementally learns feature
representations via unsupervised data on a smooth learning curve, avoiding
performance crashes that may occur with excessively variable training data
distributions. We experimentally demonstrate that DCLP has high accuracy and
efficiency compared with existing predictors, and shows promising potential to
discover superior architectures in various search spaces when combined with
search strategies. Our code is available at:
https://github.com/Zhengsh123/DCLP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.01141">DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint Satisfaction. (arXiv:2303.01141v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1">Kshitij Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumancic_S/0/1/0/all/0/1">Sebastijan Dumancic</a>, <a href="http://arxiv.org/find/cs/1/au:+Blockeel_H/0/1/0/all/0/1">Hendrik Blockeel</a></p>
<p>As machine learning models, specifically neural networks, are becoming
increasingly popular, there are concerns regarding their trustworthiness,
specially in safety-critical applications, e.g. actions of an autonomous
vehicle must be safe. There are approaches that can train neural networks where
such domain requirements are enforced as constraints, but they either cannot
guarantee that the constraint will be satisfied by all possible predictions
(even on unseen data) or they are limited in the type of constraints that can
be enforced. In this paper, we present an approach to train neural networks
which can enforce a wide variety of constraints and guarantee that the
constraint is satisfied by all possible predictions. The approach builds on
earlier work where learning linear models is formulated as a constraint
satisfaction problem (CSP). To make this idea applicable to neural networks,
two crucial new elements are added: constraint propagation over the network
layers, and weight updates based on a mix of gradient descent and CSP solving.
Evaluation on various machine learning tasks demonstrates that our approach is
flexible enough to enforce a wide variety of domain constraints and is able to
guarantee them in neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.01903">Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1">Xuecheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhenwei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jun Yu</a></p>
<p>Knowledge-based visual question answering (VQA) requires external knowledge
beyond the image to answer the question. Early studies retrieve required
knowledge from explicit knowledge bases (KBs), which often introduces
irrelevant information to the question, hence restricting the performance of
their models. Recent works have resorted to using a powerful large language
model (LLM) as an implicit knowledge engine to acquire the necessary knowledge
for answering. Despite the encouraging results achieved by these methods, we
argue that they have not fully activated the capacity of the blind LLM as the
provided textual input is insufficient to depict the required visual
information to answer the question. In this paper, we present Prophet -- a
conceptually simple, flexible, and general framework designed to prompt LLM
with answer heuristics for knowledge-based VQA. Specifically, we first train a
vanilla VQA model on a specific knowledge-based VQA dataset without external
knowledge. After that, we extract two types of complementary answer heuristics
from the VQA model: answer candidates and answer-aware examples. Finally, the
two types of answer heuristics are jointly encoded into a formatted prompt to
facilitate the LLM's understanding of both the image and question, thus
generating a more accurate answer. By incorporating the state-of-the-art LLM
GPT-3, Prophet significantly outperforms existing state-of-the-art methods on
four challenging knowledge-based VQA datasets. To demonstrate the generality of
our approach, we instantiate Prophet with the combinations of different VQA
models (i.e., both discriminative and generative ones) and different LLMs
(i.e., both commercial and open-source ones).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.03381">Real-World Humanoid Locomotion with Reinforcement Learning. (arXiv:2303.03381v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Radosavovic_I/0/1/0/all/0/1">Ilija Radosavovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tete Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bike Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreenath_K/0/1/0/all/0/1">Koushil Sreenath</a></p>
<p>Humanoid robots that can autonomously operate in diverse environments have
the potential to help address labour shortages in factories, assist elderly at
homes, and colonize new planets. While classical controllers for humanoid
robots have shown impressive results in a number of settings, they are
challenging to generalize and adapt to new environments. Here, we present a
fully learning-based approach for real-world humanoid locomotion. Our
controller is a causal transformer that takes the history of proprioceptive
observations and actions as input and predicts the next action. We hypothesize
that the observation-action history contains useful information about the world
that a powerful transformer model can use to adapt its behavior in-context,
without updating its weights. We train our model with large-scale model-free
reinforcement learning on an ensemble of randomized environments in simulation
and deploy it to the real world zero-shot. Our controller can walk over various
outdoor terrains, is robust to external disturbances, and can adapt in context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.03919">Data Portraits: Recording Foundation Model Training Data. (arXiv:2303.03919v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marone_M/0/1/0/all/0/1">Marc Marone</a>, <a href="http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1">Benjamin Van Durme</a></p>
<p>Foundation models are trained on increasingly immense and opaque datasets.
Even while these models are now key in AI system building, it can be difficult
to answer the straightforward question: has the model already encountered a
given example during training? We therefore propose a widespread adoption of
Data Portraits: artifacts that record training data and allow for downstream
inspection. First we outline the properties of such an artifact and discuss how
existing solutions can be used to increase transparency. We then propose and
implement a solution based on data sketching, stressing fast and space
efficient querying. Using our tools, we document a popular language modeling
corpus (The Pile) and a recently released code modeling dataset (The Stack). We
show that our solution enables answering questions about test set leakage and
model plagiarism. Our tool is lightweight and fast, costing only 3% of the
dataset size in overhead. We release a live interface of our tools at
https://dataportraits.org/ and call on dataset and model creators to release
Data Portraits as a complement to current documentation practices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.04416">Inference on Optimal Dynamic Policies via Softmax Approximation. (arXiv:2303.04416v3 [econ.EM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Chen_Q/0/1/0/all/0/1">Qizhao Chen</a>, <a href="http://arxiv.org/find/econ/1/au:+Austern_M/0/1/0/all/0/1">Morgane Austern</a>, <a href="http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1">Vasilis Syrgkanis</a></p>
<p>Estimating optimal dynamic policies from offline data is a fundamental
problem in dynamic decision making. In the context of causal inference, the
problem is known as estimating the optimal dynamic treatment regime. Even
though there exists a plethora of methods for estimation, constructing
confidence intervals for the value of the optimal regime and structural
parameters associated with it is inherently harder, as it involves non-linear
and non-differentiable functionals of unknown quantities that need to be
estimated. Prior work resorted to sub-sample approaches that can deteriorate
the quality of the estimate. We show that a simple soft-max approximation to
the optimal treatment regime, for an appropriately fast growing temperature
parameter, can achieve valid inference on the truly optimal regime. We
illustrate our result for a two-period optimal dynamic regime, though our
approach should directly extend to the finite horizon case. Our work combines
techniques from semi-parametric inference and $g$-estimation, together with an
appropriate triangular array central limit theorem, as well as a novel analysis
of the asymptotic influence and asymptotic bias of softmax approximations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.13056">Predicting the Initial Conditions of the Universe using a Deterministic Neural Network. (arXiv:2303.13056v2 [astro-ph.CO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Jindal_V/0/1/0/all/0/1">Vaibhav Jindal</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Liang_A/0/1/0/all/0/1">Albert Liang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Singh_A/0/1/0/all/0/1">Aarti Singh</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1">Shirley Ho</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Jamieson_D/0/1/0/all/0/1">Drew Jamieson</a></p>
<p>Finding the initial conditions that led to the current state of the universe
is challenging because it involves searching over an intractable input space of
initial conditions, along with modeling their evolution via tools such as
N-body simulations which are computationally expensive. Recently, deep learning
has emerged as a surrogate for N-body simulations by directly learning the
mapping between the linear input of an N-body simulation and the final
nonlinear output from the simulation, significantly accelerating the forward
modeling. However, this still does not reduce the search space for initial
conditions. In this work, we pioneer the use of a deterministic convolutional
neural network for learning the reverse mapping and show that it accurately
recovers the initial linear displacement field over a wide range of scales
($&lt;1$-$2\%$ error up to nearly $k\simeq0.8$-$0.9 \text{ Mpc}^{-1}h$), despite
the one-to-many mapping of the inverse problem (due to the divergent backward
trajectories at smaller scales). Specifically, we train a V-Net architecture,
which outputs the linear displacement of an N-body simulation, given the
nonlinear displacement at redshift $z=0$ and the cosmological parameters. The
results of our method suggest that a simple deterministic neural network is
sufficient for accurately approximating the initial linear states, potentially
obviating the need for the more complex and computationally demanding backward
modeling methods that were recently proposed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.10337">Prediction of the evolution of the nuclear reactor core parameters using artificial neural network. (arXiv:2304.10337v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Palmi_K/0/1/0/all/0/1">Krzysztof Palmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubinski_W/0/1/0/all/0/1">Wojciech Kubinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Darnowski_P/0/1/0/all/0/1">Piotr Darnowski</a></p>
<p>A nuclear reactor based on MIT BEAVRS benchmark was used as a typical power
generating Pressurized Water Reactor (PWR). The PARCS v3.2 nodal-diffusion core
simulator was used as a full-core reactor physics solver to emulate the
operation of a reactor and to generate training, and validation data for the
ANN. The ANN was implemented with dedicated Python 3.8 code with Google's
TensorFlow 2.0 library. The effort was based to a large extent on the process
of appropriate automatic transformation of data generated by PARCS simulator,
which was later used in the process of the ANN development. Various methods
that allow obtaining better accuracy of the ANN predicted results were studied,
such as trying different ANN architectures to find the optimal number of
neurons in the hidden layers of the network. Results were later compared with
the architectures proposed in the literature. For the selected best
architecture predictions were made for different core parameters and their
dependence on core loading patterns. In this study, a special focus was put on
the prediction of the fuel cycle length for a given core loading pattern, as it
can be considered one of the targets for plant economic operation. For
instance, the length of a single fuel cycle depending on the initial core
loading pattern was predicted with very good accuracy (&gt;99%). This work
contributes to the exploration of the usefulness of neural networks in solving
nuclear reactor design problems. Thanks to the application of ANN, designers
can avoid using an excessive amount of core simulator runs and more rapidly
explore the space of possible solutions before performing more detailed design
considerations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16846">Lagrangian Flow Networks for Conservation Laws. (arXiv:2305.16846v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Torres_F/0/1/0/all/0/1">F. Arend Torres</a>, <a href="http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1">Marcello Massimo Negri</a>, <a href="http://arxiv.org/find/cs/1/au:+Inversi_M/0/1/0/all/0/1">Marco Inversi</a>, <a href="http://arxiv.org/find/cs/1/au:+Aellen_J/0/1/0/all/0/1">Jonathan Aellen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_V/0/1/0/all/0/1">Volker Roth</a></p>
<p>We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities
and velocities continuously in space and time. By construction, the proposed
LFlows satisfy the continuity equation, a PDE describing mass conservation in
its differentiable form. Our model is based on the insight that solutions to
the continuity equation can be expressed as time-dependent density
transformations via differentiable and invertible maps. This follows from
classical theory of the existence and uniqueness of Lagrangian flows for smooth
vector fields. Hence, we model fluid densities by transforming a base density
with parameterized diffeomorphisms conditioned on time. The key benefit
compared to methods relying on numerical ODE solvers or PINNs is that the
analytic expression of the velocity is always consistent with changes in
density. Furthermore, we require neither expensive numerical solvers, nor
additional penalties to enforce the PDE. LFlows show higher predictive accuracy
in density modeling tasks compared to competing models in 2D and 3D, while
being computationally efficient. As a real-world application, we model bird
migration based on sparse weather radar measurements.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03480">GSHOT: Few-shot Generative Modeling of Labeled Graphs. (arXiv:2306.03480v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manchanda_S/0/1/0/all/0/1">Sahil Manchanda</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Shubham Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranu_S/0/1/0/all/0/1">Sayan Ranu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bedathur_S/0/1/0/all/0/1">Srikanta Bedathur</a></p>
<p>Deep graph generative modeling has gained enormous attraction in recent years
due to its impressive ability to directly learn the underlying hidden graph
distribution. Despite their initial success, these techniques, like much of the
existing deep generative methods, require a large number of training samples to
learn a good model. Unfortunately, large number of training samples may not
always be available in scenarios such as drug discovery for rare diseases. At
the same time, recent advances in few-shot learning have opened door to
applications where available training data is limited. In this work, we
introduce the hitherto unexplored paradigm of few-shot graph generative
modeling. Towards this, we develop GSHOT, a meta-learning based framework for
few-shot labeled graph generative modeling. GSHOT learns to transfer
meta-knowledge from similar auxiliary graph datasets. Utilizing these prior
experiences, GSHOT quickly adapts to an unseen graph dataset through self-paced
fine-tuning. Through extensive experiments on datasets from diverse domains
having limited training samples, we establish that GSHOT generates graphs of
superior fidelity compared to existing baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09202">An Optimal Algorithm for the Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit. (arXiv:2306.09202v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1">Shintaro Nakamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a></p>
<p>We study the real-valued combinatorial pure exploration problem in the
stochastic multi-armed bandit (R-CPE-MAB). We study the case where the size of
the action set is polynomial with respect to the number of arms. In such a
case, the R-CPE-MAB can be seen as a special case of the so-called transductive
linear bandits. Existing methods in the R-CPE-MAB and transductive linear
bandits have a gap of problem-dependent constant terms and logarithmic terms
between the upper and lower bounds of the sample complexity, respectively. We
close these gaps by proposing an algorithm named the combinatorial gap-based
exploration (CombGapE) algorithm, whose sample complexity upper bound matches
the lower bound. Finally, we numerically show that the CombGapE algorithm
outperforms existing methods significantly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10007">Robot Learning with Sensorimotor Pre-training. (arXiv:2306.10007v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Radosavovic_I/0/1/0/all/0/1">Ilija Radosavovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Baifeng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_L/0/1/0/all/0/1">Letian Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1">Ken Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Malik</a></p>
<p>We present a self-supervised sensorimotor pre-training approach for robotics.
Our model, called RPT, is a Transformer that operates on sequences of
sensorimotor tokens. Given a sequence of camera images, proprioceptive robot
states, and actions, we encode the sequence into tokens, mask out a subset, and
train a model to predict the missing content from the rest. We hypothesize that
if a robot can predict the masked-out content it will have acquired a good
model of the physical world that can enable it to act. RPT is designed to
operate on latent visual representations which makes prediction tractable,
enables scaling to larger models, and allows fast inference on a real robot. To
evaluate our approach, we collected a dataset of 20,000 real-world trajectories
over 9 months using a combination of motion planning and grasping algorithms.
We find that sensorimotor pre-training consistently outperforms training from
scratch, has favorable scaling properties, and enables transfer across
different tasks, environments, and robots.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00293">AutoST: Training-free Neural Architecture Search for Spiking Transformers. (arXiv:2307.00293v2 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qidong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jinku Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dongkuan Xu</a></p>
<p>Spiking Transformers have gained considerable attention because they achieve
both the energy efficiency of Spiking Neural Networks (SNNs) and the high
capacity of Transformers. However, the existing Spiking Transformer
architectures, derived from Artificial Neural Networks (ANNs), exhibit a
notable architectural gap, resulting in suboptimal performance compared to
their ANN counterparts. Manually discovering optimal architectures is
time-consuming. To address these limitations, we introduce AutoST, a
training-free NAS method for Spiking Transformers, to rapidly identify
high-performance Spiking Transformer architectures. Unlike existing
training-free NAS methods, which struggle with the non-differentiability and
high sparsity inherent in SNNs, we propose to utilize Floating-Point Operations
(FLOPs) as a performance metric, which is independent of model computations and
training dynamics, leading to a stronger correlation with performance. Our
extensive experiments show that AutoST models outperform state-of-the-art
manually or automatically designed SNN architectures on static and neuromorphic
datasets. Full code, model, and data are released for reproduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01146">AVSegFormer: Audio-Visual Segmentation with Transformer. (arXiv:2307.01146v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shengyi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a></p>
<p>The combination of audio and vision has long been a topic of interest in the
multi-modal community. Recently, a new audio-visual segmentation (AVS) task has
been introduced, aiming to locate and segment the sounding objects in a given
video. This task demands audio-driven pixel-level scene understanding for the
first time, posing significant challenges. In this paper, we propose
AVSegFormer, a novel framework for AVS tasks that leverages the transformer
architecture. Specifically, we introduce audio queries and learnable queries
into the transformer decoder, enabling the network to selectively attend to
interested visual features. Besides, we present an audio-visual mixer, which
can dynamically adjust visual features by amplifying relevant and suppressing
irrelevant spatial channels. Additionally, we devise an intermediate mask loss
to enhance the supervision of the decoder, encouraging the network to produce
more accurate intermediate predictions. Extensive experiments demonstrate that
AVSegFormer achieves state-of-the-art results on the AVS benchmark. The code is
available at https://github.com/vvvb-github/AVSegFormer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03223">Neural Network Field Theories: Non-Gaussianity, Actions, and Locality. (arXiv:2307.03223v2 [hep-th] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-th/1/au:+Demirtas_M/0/1/0/all/0/1">Mehmet Demirtas</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Halverson_J/0/1/0/all/0/1">James Halverson</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Maiti_A/0/1/0/all/0/1">Anindita Maiti</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Schwartz_M/0/1/0/all/0/1">Matthew D. Schwartz</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Stoner_K/0/1/0/all/0/1">Keegan Stoner</a></p>
<p>Both the path integral measure in field theory and ensembles of neural
networks describe distributions over functions. When the central limit theorem
can be applied in the infinite-width (infinite-$N$) limit, the ensemble of
networks corresponds to a free field theory. Although an expansion in $1/N$
corresponds to interactions in the field theory, others, such as in a small
breaking of the statistical independence of network parameters, can also lead
to interacting theories. These other expansions can be advantageous over the
$1/N$-expansion, for example by improved behavior with respect to the universal
approximation theorem. Given the connected correlators of a field theory, one
can systematically reconstruct the action order-by-order in the expansion
parameter, using a new Feynman diagram prescription whose vertices are the
connected correlators. This method is motivated by the Edgeworth expansion and
allows one to derive actions for neural network field theories. Conversely, the
correspondence allows one to engineer architectures realizing a given field
theory by representing action deformations as deformations of neural network
parameter densities. As an example, $\phi^4$ theory is realized as an
infinite-$N$ neural network field theory.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12971">Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jahin_M/0/1/0/all/0/1">Md Abrar Jahin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shovon_M/0/1/0/all/0/1">Md Sakib Hossain Shovon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jungpil Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ridoy_I/0/1/0/all/0/1">Istiyaque Ahmed Ridoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomioka_Y/0/1/0/all/0/1">Yoichi Tomioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Mridha_M/0/1/0/all/0/1">M. F. Mridha</a></p>
<p>This article intends to systematically identify and comparatively analyze
state-of-the-art supply chain (SC) forecasting strategies and technologies. A
novel framework has been proposed incorporating Big Data Analytics in SC
Management (problem identification, data sources, exploratory data analysis,
machine-learning model training, hyperparameter tuning, performance evaluation,
and optimization), forecasting effects on human-workforce, inventory, and
overall SC. Initially, the need to collect data according to SC strategy and
how to collect them has been discussed. The article discusses the need for
different types of forecasting according to the period or SC objective. The SC
KPIs and the error-measurement systems have been recommended to optimize the
top-performing model. The adverse effects of phantom inventory on forecasting
and the dependence of managerial decisions on the SC KPIs for determining model
performance parameters and improving operations management, transparency, and
planning efficiency have been illustrated. The cyclic connection within the
framework introduces preprocessing optimization based on the post-process KPIs,
optimizing the overall control process (inventory management, workforce
determination, cost, production and capacity planning). The contribution of
this research lies in the standard SC process framework proposal, recommended
forecasting data analysis, forecasting effects on SC performance, machine
learning algorithms optimization followed, and in shedding light on future
research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.16506">Explainable Equivariant Neural Networks for Particle Physics: PELICAN. (arXiv:2307.16506v3 [hep-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ph/1/au:+Bogatskiy_A/0/1/0/all/0/1">Alexander Bogatskiy</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Hoffman_T/0/1/0/all/0/1">Timothy Hoffman</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Miller_D/0/1/0/all/0/1">David W. Miller</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Offermann_J/0/1/0/all/0/1">Jan T. Offermann</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Liu_X/0/1/0/all/0/1">Xiaoyang Liu</a></p>
<p>PELICAN is a novel permutation equivariant and Lorentz invariant or covariant
aggregator network designed to overcome common limitations found in
architectures applied to particle physics problems. Compared to many approaches
that use non-specialized architectures that neglect underlying physics
principles and require very large numbers of parameters, PELICAN employs a
fundamentally symmetry group-based architecture that demonstrates benefits in
terms of reduced complexity, increased interpretability, and raw performance.
We present a comprehensive study of the PELICAN algorithm architecture in the
context of both tagging (classification) and reconstructing (regression)
Lorentz-boosted top quarks, including the difficult task of specifically
identifying and measuring the $W$-boson inside the dense environment of the
Lorentz-boosted top-quark hadronic final state. We also extend the application
of PELICAN to the tasks of identifying quark-initiated vs.~gluon-initiated
jets, and a multi-class identification across five separate target categories
of jets. When tested on the standard task of Lorentz-boosted top-quark tagging,
PELICAN outperforms existing competitors with much lower model complexity and
high sample efficiency. On the less common and more complex task of 4-momentum
regression, PELICAN also outperforms hand-crafted, non-machine learning
algorithms. We discuss the implications of symmetry-restricted architectures
for the wider field of machine learning for physics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01890">DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations. (arXiv:2308.01890v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Ping Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Ximeng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1">Stan Sclaroff</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a></p>
<p>Multi-label image recognition in the low-label regime is a task of great
challenge and practical significance. Previous works have focused on learning
the alignment between textual and visual spaces to compensate for limited image
labels, yet may suffer from reduced accuracy due to the scarcity of
high-quality multi-label annotations. In this research, we leverage the
powerful alignment between textual and visual features pretrained with millions
of auxiliary image-text pairs. We introduce an efficient and effective
framework called Evidence-guided Dual Context Optimization (DualCoOp++), which
serves as a unified approach for addressing partial-label and zero-shot
multi-label recognition. In DualCoOp++ we separately encode evidential,
positive, and negative contexts for target classes as parametric components of
the linguistic input (i.e., prompts). The evidential context aims to discover
all the related visual content for the target class, and serves as guidance to
aggregate positive and negative contexts from the spatial domain of the image,
enabling better distinguishment between similar categories. Additionally, we
introduce a Winner-Take-All module that promotes inter-class interaction during
training, while avoiding the need for extra parameters and costs. As DualCoOp++
imposes minimal additional learnable overhead on the pretrained vision-language
framework, it enables rapid adaptation to multi-label recognition tasks with
limited annotations and even unseen classes. Experiments on standard
multi-label recognition benchmarks across two challenging low-label settings
demonstrate the superior performance of our approach compared to
state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02668">Guided Distillation for Semi-Supervised Instance Segmentation. (arXiv:2308.02668v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Berrada_T/0/1/0/all/0/1">Tariq Berrada</a>, <a href="http://arxiv.org/find/cs/1/au:+Couprie_C/0/1/0/all/0/1">Camille Couprie</a>, <a href="http://arxiv.org/find/cs/1/au:+Alahari_K/0/1/0/all/0/1">Karteek Alahari</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1">Jakob Verbeek</a></p>
<p>Although instance segmentation methods have improved considerably, the
dominant paradigm is to rely on fully-annotated training images, which are
tedious to obtain. To alleviate this reliance, and boost results,
semi-supervised approaches leverage unlabeled data as an additional training
signal that limits overfitting to the labeled samples. In this context, we
present novel design choices to significantly improve teacher-student
distillation models. In particular, we (i) improve the distillation approach by
introducing a novel "guided burn-in" stage, and (ii) evaluate different
instance segmentation architectures, as well as backbone networks and
pre-training strategies. Contrary to previous work which uses only supervised
data for the burn-in period of the student model, we also use guidance of the
teacher model to exploit unlabeled data in the burn-in period. Our improved
distillation approach leads to substantial improvements over previous
state-of-the-art results. For example, on the Cityscapes dataset we improve
mask-AP from 23.7 to 33.9 when using labels for 10\% of images, and on the COCO
dataset we improve mask-AP from 18.3 to 34.1 when using labels for only 1\% of
the training data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03443">Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Shimizu_T/0/1/0/all/0/1">Tatsuhiro Shimizu</a>, <a href="http://arxiv.org/find/stat/1/au:+Forastiere_L/0/1/0/all/0/1">Laura Forastiere</a></p>
<p>We study Off-Policy Evaluation (OPE) in contextual bandit settings with large
action spaces. The benchmark estimators suffer from severe bias and variance
tradeoffs. Parametric approaches suffer from bias due to difficulty specifying
the correct model, whereas ones with importance weight suffer from variance. To
overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was
proposed to mitigate the estimator's variance via embeddings of an action.
Nevertheless, MIPS is unbiased under the no direct effect, which assumes that
the action embedding completely mediates the effect of an action on a reward.
To overcome the dependency on these unrealistic assumptions, we propose a
Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the
proposed estimator is unbiased under weaker assumptions than MIPS while
reducing the variance against MIPS. The empirical experiment verifies the
supremacy of MDR against existing estimators with large action spaces.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03669">Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shimizu_T/0/1/0/all/0/1">Tatsuhiro Shimizu</a></p>
<p>We study how to extend the use of the diffusion model to answer the causal
question from the observational data under the existence of unmeasured
confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to
capture the causal intervention, a Diffusion-based Causal Model (DCM) was
proposed incorporating the diffusion model to answer the causal questions more
accurately, assuming that all of the confounders are observed. However,
unmeasured confounders in practice exist, which hinders DCM from being
applicable. To alleviate this limitation of DCM, we propose an extended model
called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the
Backdoor criterion to find the variables in DAG to be included in the decoding
process of the diffusion model so that we can extend DCM to the case with
unmeasured confounders. Synthetic data experiment demonstrates that our
proposed model captures the counterfactual distribution more precisely than DCM
under the unmeasured confounders.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03793">ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation. (arXiv:2308.03793v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuefeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Ke Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1">Lu Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Albert Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiajia Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuyin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Ken Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_N/0/1/0/all/0/1">Nan Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Min Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">Cheng-Hao Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nevatia_R/0/1/0/all/0/1">Ram Nevatia</a></p>
<p>Large-scale Pre-Training Vision-Language Model such as CLIP has demonstrated
outstanding performance in zero-shot classification, e.g. achieving 76.3% top-1
accuracy on ImageNet without seeing any example, which leads to potential
benefits to many tasks that have no labeled data. However, while applying CLIP
to a downstream target domain, the presence of visual and text domain gaps and
cross-modality misalignment can greatly impact the model performance. To
address such challenges, we propose ReCLIP, the first source-free domain
adaptation method for vision-language models, which does not require any source
data or target labeled data. ReCLIP first learns a projection space to mitigate
the misaligned visual-text embeddings and learns pseudo labels, and then
deploys cross-modality self-training with the pseudo labels, to update visual
and text encoders, refine labels and reduce domain gaps and misalignments
iteratively. With extensive experiments, we demonstrate ReCLIP reduces the
average error rate of CLIP from 30.17% to 25.06% on 22 image classification
benchmarks. Code available at https://github.com/michiganleon/ReCLIP_WACV.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.06221">Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms. (arXiv:2308.06221v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tyagi_K/0/1/0/all/0/1">Kanishka Tyagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rane_C/0/1/0/all/0/1">Chinmay Rane</a>, <a href="http://arxiv.org/find/cs/1/au:+Manry_M/0/1/0/all/0/1">Michael Manry</a></p>
<p>We propose a multi-step training method for designing generalized linear
classifiers. First, an initial multi-class linear classifier is found through
regression. Then validation error is minimized by pruning of unnecessary
inputs. Simultaneously, desired outputs are improved via a method similar to
the Ho-Kashyap rule. Next, the output discriminants are scaled to be net
functions of sigmoidal output units in a generalized linear classifier. We then
develop a family of batch training algorithm for the multi layer perceptron
that optimizes its hidden layer size and number of training epochs. Next, we
combine pruning with a growing approach. Later, the input units are scaled to
be the net function of the sigmoidal output units that are then feed into as
input to the MLP. We then propose resulting improvements in each of the deep
learning blocks thereby improving the overall performance of the deep
architecture. We discuss the principles and formulation regarding learning
algorithms for deep autoencoders. We investigate several problems in deep
autoencoders networks including training issues, the theoretical, mathematical
and experimental justification that the networks are linear, optimizing the
number of hidden units in each layer and determining the depth of the deep
learning model. A direct implication of the current work is the ability to
construct fast deep learning models using desktop level computational
resources. This, in our opinion, promotes our design philosophy of building
small but powerful algorithms. Performance gains are demonstrated at each step.
Using widely available datasets, the final network's ten fold testing error is
shown to be less than that of several other linear, generalized linear
classifiers, multi layer perceptron and deep learners reported in the
literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10273">Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks. (arXiv:2308.10273v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zuheng Xu</a></p>
<p>Continuous Conditional Generative Adversarial Networks (CcGANs) enable
generative modeling conditional on continuous scalar variables (termed
regression labels). However, they can produce subpar fake images due to limited
training data. Although Negative Data Augmentation (NDA) effectively enhances
unconditional and class-conditional GANs by introducing anomalies into real
training images, guiding the GANs away from low-quality outputs, its impact on
CcGANs is limited, as it fails to replicate negative samples that may occur
during the CcGAN sampling. We present a novel NDA approach called Dual-NDA
specifically tailored for CcGANs to address this problem. Dual-NDA employs two
types of negative samples: visually unrealistic images generated from a
pre-trained CcGAN and label-inconsistent images created by manipulating real
images' labels. Leveraging these negative samples, we introduce a novel
discriminator objective alongside a modified CcGAN training algorithm.
Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA
consistently enhances the visual fidelity and label consistency of fake images
generated by CcGANs, exhibiting a substantial performance gain over the vanilla
NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable
advancement beyond the capabilities of state-of-the-art conditional GANs and
diffusion models, establishing a new pinnacle of performance. Our codes can be
found at https://github.com/UBCDingXin/Dual-NDA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05395">SABLE: Secure And Byzantine robust LEarning. (arXiv:2309.05395v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Choffrut_A/0/1/0/all/0/1">Antoine Choffrut</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1">Rachid Guerraoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1">Rafael Pinot</a>, <a href="http://arxiv.org/find/cs/1/au:+Sirdey_R/0/1/0/all/0/1">Renaud Sirdey</a>, <a href="http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1">John Stephan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuber_M/0/1/0/all/0/1">Martin Zuber</a></p>
<p>Due to the widespread availability of data, machine learning (ML) algorithms
are increasingly being implemented in distributed topologies, wherein various
nodes collaborate to train ML models via the coordination of a central server.
However, distributed learning approaches face significant vulnerabilities,
primarily stemming from two potential threats. Firstly, the presence of
Byzantine nodes poses a risk of corrupting the learning process by transmitting
inaccurate information to the server. Secondly, a curious server may compromise
the privacy of individual nodes, sometimes reconstructing the entirety of the
nodes' data. Homomorphic encryption (HE) has emerged as a leading security
measure to preserve privacy in distributed learning under non-Byzantine
scenarios. However, the extensive computational demands of HE, particularly for
high-dimensional ML models, have deterred attempts to design purely homomorphic
operators for non-linear robust aggregators. This paper introduces SABLE, the
first homomorphic and Byzantine robust distributed learning algorithm. SABLE
leverages HTS, a novel and efficient homomorphic operator implementing the
prominent coordinate-wise trimmed mean robust aggregator. Designing HTS enables
us to implement HMED, a novel homomorphic median aggregator. Extensive
experiments on standard ML tasks demonstrate that SABLE achieves practical
execution times while maintaining an ML accuracy comparable to its non-private
counterpart.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.06157">Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines. (arXiv:2309.06157v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1">Khoa Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_H/0/1/0/all/0/1">Hai-Canh Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_L/0/1/0/all/0/1">Lam Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Boudaoud_N/0/1/0/all/0/1">Nassim Boudaoud</a></p>
<p>In this paper, a Robust Multi-branch Deep learning-based system for remaining
useful life (RUL) prediction and condition operations (CO) identification of
rotating machines is proposed. In particular, the proposed system comprises
main components: (1) an LSTM-Autoencoder to denoise the vibration data; (2) a
feature extraction to generate time-domain, frequency-domain, and
time-frequency based features from the denoised data; (3) a novel and robust
multi-branch deep learning network architecture to exploit the multiple
features. The performance of our proposed system was evaluated and compared to
the state-of-the-art systems on two benchmark datasets of XJTU-SY and
PRONOSTIA. The experimental results prove that our proposed system outperforms
the state-of-the-art systems and presents potential for real-life applications
on bearing machines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.06869">Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning. (arXiv:2309.06869v2 [cond-mat.soft] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Lieu_U/0/1/0/all/0/1">Uyen Tu Lieu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Yoshinaga_N/0/1/0/all/0/1">Natsuhiko Yoshinaga</a></p>
<p>We propose reinforcement learning to control the dynamical self-assembly of
the dodecagonal quasicrystal (DDQC) from patchy particles. The patchy particles
have anisotropic interactions with other particles and form DDQC. However,
their structures at steady states are significantly influenced by the kinetic
pathways of their structural formation. We estimate the best policy of
temperature control trained by the Q-learning method and demonstrate that we
can generate DDQC with few defects using the estimated policy. The temperature
schedule obtained by reinforcement learning can reproduce the desired structure
more efficiently than the conventional pre-fixed temperature schedule, such as
annealing. To clarify the success of the learning, we also analyse a simple
model describing the kinetics of structural changes through the motion in a
triple-well potential. We have found that reinforcement learning autonomously
discovers the critical temperature at which structural fluctuations enhance the
chance of forming a globally stable state. The estimated policy guides the
system toward the critical temperature to assist the formation of DDQC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07579">Structure-Preserving Transformers for Sequences of SPD Matrices. (arXiv:2309.07579v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seraphim_M/0/1/0/all/0/1">Mathieu Seraphim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lechervy_A/0/1/0/all/0/1">Alexis Lechervy</a>, <a href="http://arxiv.org/find/cs/1/au:+Yger_F/0/1/0/all/0/1">Florian Yger</a>, <a href="http://arxiv.org/find/cs/1/au:+Brun_L/0/1/0/all/0/1">Luc Brun</a>, <a href="http://arxiv.org/find/cs/1/au:+Etard_O/0/1/0/all/0/1">Olivier Etard</a></p>
<p>In recent years, Transformer-based auto-attention mechanisms have been
successfully applied to the analysis of a variety of context-reliant data
types, from texts to images and beyond, including data from non-Euclidean
geometries. In this paper, we present such a mechanism, designed to classify
sequences of Symmetric Positive Definite matrices while preserving their
Riemannian geometry throughout the analysis. We apply our method to automatic
sleep staging on timeseries of EEG-derived covariance matrices from a standard
dataset, obtaining high levels of stage-wise performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.08628">Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vats_A/0/1/0/all/0/1">Arpita Vats</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_P/0/1/0/all/0/1">Peng Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1">Debjyoti Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yingyi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yutong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1">Zeeshan Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1">Ozlem Kalinli</a></p>
<p>Model adaptation is crucial to handle the discrepancy between proxy training
data and actual users data received. To effectively perform adaptation, textual
data of users is typically stored on servers or their local devices, where
downstream natural language processing (NLP) models can be directly trained
using such in-domain data. However, this might raise privacy and security
concerns due to the extra risks of exposing user information to adversaries.
Replacing identifying information in textual data with a generic marker has
been recently explored. In this work, we leverage large language models (LLMs)
to suggest substitutes of masked tokens and have their effectiveness evaluated
on downstream language modeling tasks. Specifically, we propose multiple
pre-trained and fine-tuned LLM-based approaches and perform empirical studies
on various datasets for the comparison of these methods. Experimental results
show that models trained on the obfuscation corpora are able to achieve
comparable performance with the ones trained on the original data without
privacy-preserving token masking.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.14780">Transferring climate change knowledge. (arXiv:2309.14780v2 [physics.ao-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Immorlano_F/0/1/0/all/0/1">Francesco Immorlano</a>, <a href="http://arxiv.org/find/physics/1/au:+Eyring_V/0/1/0/all/0/1">Veronika Eyring</a>, <a href="http://arxiv.org/find/physics/1/au:+Gouville_T/0/1/0/all/0/1">Thomas le Monnier de Gouville</a>, <a href="http://arxiv.org/find/physics/1/au:+Accarino_G/0/1/0/all/0/1">Gabriele Accarino</a>, <a href="http://arxiv.org/find/physics/1/au:+Elia_D/0/1/0/all/0/1">Donatello Elia</a>, <a href="http://arxiv.org/find/physics/1/au:+Aloisio_G/0/1/0/all/0/1">Giovanni Aloisio</a>, <a href="http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1">Pierre Gentine</a></p>
<p>Accurate climate projections are required for climate adaptation and
mitigation. Earth system model simulations, used to project climate change,
inherently make approximations in their representation of small-scale physical
processes, such as the formation of clouds, that are at the root of the
uncertainties in global mean temperature's response to increased greenhouse gas
concentrations. Several approaches have been developed to use historical
observations to constrain future projections and reduce uncertainties in
climate projections and climate feedbacks. Yet those methods cannot capture the
non-linear complexity inherent in the climate system. Using a Transfer Learning
approach, we show that Machine Learning, in particular Deep Neural Networks,
can be used to optimally leverage and merge the knowledge gained from Earth
system model simulations and historical observations to more accurately project
global surface temperature fields in the 21st century. We reach a reduction in
the 5-95% uncertainty range of global surface air temperature in 2081-2098 of
up to 56% and 52% - across the Shared Socioeconomic Pathways considered - with
respect to state-of-the-art approaches and the Sixth Assessment Report from the
Intergovernmental Panel on Climate Change, respectively. We give evidence that
our novel method provides narrower multi-model uncertainty together with more
accurate climate projections, urgently required for climate adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00268">Unravel Anomalies: An End-to-end Seasonal-Trend Decomposition Approach for Time Series Anomaly Detection. (arXiv:2310.00268v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1">Ran Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuantao Gu</a></p>
<p>Traditional Time-series Anomaly Detection (TAD) methods often struggle with
the composite nature of complex time-series data and a diverse array of
anomalies. We introduce TADNet, an end-to-end TAD model that leverages
Seasonal-Trend Decomposition to link various types of anomalies to specific
decomposition components, thereby simplifying the analysis of complex
time-series and enhancing detection performance. Our training methodology,
which includes pre-training on a synthetic dataset followed by fine-tuning,
strikes a balance between effective decomposition and precise anomaly
detection. Experimental validation on real-world datasets confirms TADNet's
state-of-the-art performance across a diverse range of anomalies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.01794">GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking. (arXiv:2310.01794v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kosan_M/0/1/0/all/0/1">Mert Kosan</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1">Samidha Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Armgaan_B/0/1/0/all/0/1">Burouj Armgaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pahwa_K/0/1/0/all/0/1">Khushbu Pahwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Ambuj Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Medya_S/0/1/0/all/0/1">Sourav Medya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranu_S/0/1/0/all/0/1">Sayan Ranu</a></p>
<p>Numerous explainability methods have been proposed to shed light on the inner
workings of GNNs. Despite the inclusion of empirical evaluations in all the
proposed algorithms, the interrogative aspects of these evaluations lack
diversity. As a result, various facets of explainability pertaining to GNNs,
such as a comparative analysis of counterfactual reasoners, their stability to
variational factors such as different GNN architectures, noise, stochasticity
in non-convex loss surfaces, feasibility amidst domain constraints, and so
forth, have yet to be formally investigated. Motivated by this need, we present
a benchmarking study on perturbation-based explainability methods for GNNs,
aiming to systematically evaluate and compare a wide range of explainability
techniques. Among the key findings of our study, we identify the Pareto-optimal
methods that exhibit superior efficacy and stability in the presence of noise.
Nonetheless, our study reveals that all algorithms are affected by stability
issues when faced with noisy data. Furthermore, we have established that the
current generation of counterfactual explainers often fails to provide feasible
recourses due to violations of topological constraints encoded by
domain-specific considerations. Overall, this benchmarking study empowers
stakeholders in the field of GNNs with a comprehensive understanding of the
state-of-the-art explainability methods, potential research problems for
further enhancement, and the implications of their application in real-world
scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02207">Language Models Represent Space and Time. (arXiv:2310.02207v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gurnee_W/0/1/0/all/0/1">Wes Gurnee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tegmark_M/0/1/0/all/0/1">Max Tegmark</a></p>
<p>The capabilities of large language models (LLMs) have sparked debate over
whether such systems just learn an enormous collection of superficial
statistics or a coherent model of the data generation process -- a world model.
We find preliminary evidence for the latter by analyzing the learned
representations of three spatial datasets (world, US, NYC places) and three
temporal datasets (historical figures, artworks, news headlines) in the Llama-2
family of models. We discover that LLMs learn linear representations of space
and time across multiple scales. These representations are robust to prompting
variations and unified across different entity types (e.g. cities and
landmarks). In addition, we identify individual ``space neurons'' and ``time
neurons'' that reliably encode spatial and temporal coordinates. While further
investigation is needed, our results suggest modern LLMs learn rich
spatiotemporal representations of the real world and possess basic ingredients
of a world model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02299">Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution. (arXiv:2310.02299v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Han Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1">Robin Walters</a>, <a href="http://arxiv.org/find/cs/1/au:+Smidt_T/0/1/0/all/0/1">Tess E.Smidt</a></p>
<p>Finding symmetry breaking is essential for understanding the fundamental
changes in the behaviors and properties of physical systems, from microscopic
particle interactions to macroscopic phenomena like fluid dynamics and cosmic
structures. Relaxed group convolution emerges as a solution for instances when
physical systems without perfect symmetries and perfectly equivariant models
are restrictive. In this paper, we provide both theoretical and empirical
evidence that this flexible convolution technique allows the model to maintain
the highest level of equivariance that is consistent with data and discover the
subtle symmetry-breaking factors in various physical systems. We employ various
relaxed group convolution architectures to uncover various symmetry-breaking
factors in different physical systems, including the phase transition of
crystal structure, the isotropy and homogeneity breaking in turbulence, and the
time-reversal symmetry breaking in pendulum systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.04723">Subspace Identification for Multi-Source Domain Adaptation. (arXiv:2310.04723v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Boyang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhifeng Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a></p>
<p>Multi-source domain adaptation (MSDA) methods aim to transfer knowledge from
multiple labeled source domains to an unlabeled target domain. Although current
methods achieve target joint distribution identifiability by enforcing minimal
changes across domains, they often necessitate stringent conditions, such as an
adequate number of domains, monotonic transformation of latent variables, and
invariant label distributions. These requirements are challenging to satisfy in
real-world applications. To mitigate the need for these strict assumptions, we
propose a subspace identification theory that guarantees the disentanglement of
domain-invariant and domain-specific variables under less restrictive
constraints regarding domain numbers and transformation properties, thereby
facilitating domain adaptation by minimizing the impact of domain shifts on
invariant variables. Based on this theory, we develop a Subspace Identification
Guarantee (SIG) model that leverages variational inference. Furthermore, the
SIG model incorporates class-aware conditional alignment to accommodate target
shifts where label distributions change with the domains. Experimental results
demonstrate that our SIG model outperforms existing MSDA techniques on various
benchmark datasets, highlighting its effectiveness in real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.06372">Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data. (arXiv:2310.06372v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1">Lukas Struppek</a>, <a href="http://arxiv.org/find/cs/1/au:+Hentschel_M/0/1/0/all/0/1">Martin B. Hentschel</a>, <a href="http://arxiv.org/find/cs/1/au:+Poth_C/0/1/0/all/0/1">Clifton Poth</a>, <a href="http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1">Dominik Hintersdorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a></p>
<p>Backdoor attacks pose a serious security threat for training neural networks
as they surreptitiously introduce hidden functionalities into a model. Such
backdoors remain silent during inference on clean inputs, evading detection due
to inconspicuous behavior. However, once a specific trigger pattern appears in
the input data, the backdoor activates, causing the model to execute its
concealed function. Detecting such poisoned samples within vast datasets is
virtually impossible through manual inspection. To address this challenge, we
propose a novel approach that enables model training on potentially poisoned
datasets by utilizing the power of recent diffusion models. Specifically, we
create synthetic variations of all training samples, leveraging the inherent
resilience of diffusion models to potential trigger patterns in the data. By
combining this generative approach with knowledge distillation, we produce
student models that maintain their general performance on the task while
exhibiting robust resistance to backdoor triggers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10605">ForceGen: End-to-end de novo protein generation based on nonlinear mechanical unfolding responses using a language diffusion model. (arXiv:2310.10605v2 [cond-mat.mtrl-sci] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Ni_B/0/1/0/all/0/1">Bo Ni</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kaplan_D/0/1/0/all/0/1">David L. Kaplan</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1">Markus J. Buehler</a></p>
<p>Through evolution, nature has presented a set of remarkable protein
materials, including elastins, silks, keratins and collagens with superior
mechanical performances that play crucial roles in mechanobiology. However,
going beyond natural designs to discover proteins that meet specified
mechanical properties remains challenging. Here we report a generative model
that predicts protein designs to meet complex nonlinear mechanical
property-design objectives. Our model leverages deep knowledge on protein
sequences from a pre-trained protein language model and maps mechanical
unfolding responses to create novel proteins. Via full-atom molecular
simulations for direct validation, we demonstrate that the designed proteins
are novel, and fulfill the targeted mechanical properties, including unfolding
energy and mechanical strength, as well as the detailed unfolding
force-separation curves. Our model offers rapid pathways to explore the
enormous mechanobiological protein sequence space unconstrained by biological
synthesis, using mechanical features as target to enable the discovery of
protein materials with superior mechanical properties.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15140">AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models. (arXiv:2310.15140v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Sicheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruiyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bang An</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Gang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrow_J/0/1/0/all/0/1">Joe Barrow</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zichao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nenkova_A/0/1/0/all/0/1">Ani Nenkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tong Sun</a></p>
<p>Safety alignment of Large Language Models (LLMs) can be compromised with
manual jailbreak attacks and (automatic) adversarial attacks. Recent studies
suggest that defending against these attacks is possible: adversarial attacks
generate unlimited but unreadable gibberish prompts, detectable by
perplexity-based filters; manual jailbreak attacks craft readable prompts, but
their limited number due to the necessity of human creativity allows for easy
blocking. In this paper, we show that these solutions may be too optimistic. We
introduce AutoDAN, an interpretable, gradient-based adversarial attack that
merges the strengths of both attack types. Guided by the dual goals of
jailbreak and readability, AutoDAN optimizes and generates tokens one by one
from left to right, resulting in readable prompts that bypass perplexity
filters while maintaining high attack success rates. Notably, these prompts,
generated from scratch using gradients, are interpretable and diverse, with
emerging strategies commonly seen in manual jailbreak attacks. They also
generalize to unforeseen harmful behaviors and transfer to black-box LLMs
better than their unreadable counterparts when using limited training data or a
single proxy model. Furthermore, we show the versatility of AutoDAN by
automatically leaking system prompts using a customized objective. Our work
offers a new way to red-team LLMs and understand jailbreak mechanisms via
interpretability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.16121">19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics. (arXiv:2310.16121v3 [hep-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ph/1/au:+Bogatskiy_A/0/1/0/all/0/1">Alexander Bogatskiy</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Hoffman_T/0/1/0/all/0/1">Timothy Hoffman</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Offermann_J/0/1/0/all/0/1">Jan T. Offermann</a></p>
<p>As particle accelerators increase their collision rates, and deep learning
solutions prove their viability, there is a growing need for lightweight and
fast neural network architectures for low-latency tasks such as triggering. We
examine the potential of one recent Lorentz- and permutation-symmetric
architecture, PELICAN, and present its instances with as few as 19 trainable
parameters that outperform generic architectures with tens of thousands of
parameters when compared on the binary classification task of top quark jet
tagging.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18168">Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nitish Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rando_J/0/1/0/all/0/1">Javier Rando</a>, <a href="http://arxiv.org/find/cs/1/au:+Saparov_A/0/1/0/all/0/1">Abulhair Saparov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Najoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a></p>
<p>Large Language Models (LLMs) are trained on vast amounts of text from the
internet, which contains both factual and misleading information about the
world. Can language models discern truth from falsehood in this contradicting
data? Expanding on the view that LLMs can model different communicative agents,
we present the persona hypothesis: LLMs can cluster agents into personas using
common features of their generations. For instance, a truthful persona is a
group of agents that are likely to produce truthful text and that share similar
features like formal writing styles and scientific references. By modeling this
persona, LLMs can generalize truthfulness beyond the specific contexts in which
each agent generated the training text. For example, the model can infer that
the agent "Wikipedia" will behave truthfully on topics that were only generated
by "Science" because they both belong to the truthful persona. We show evidence
for the persona hypothesis via two observations: (1) we can probe whether a
model's answer will be truthful before it is generated; (2) finetuning a model
on a set of facts improves its truthfulness on unseen topics. Next, using
arithmetics as a synthetic environment, we show that language models can
separate true and false statements, and generalize truthfulness across agents;
but only if agents in the training data share a truthful generative process
that enables the creation of a truthful persona. Overall, our findings suggest
that models can exploit hierarchical structures in the data to learn abstract
concepts like truthfulness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18893">Ever Evolving Evaluator (EV3): Towards Flexible and Reliable Meta-Optimization for Knowledge Distillation. (arXiv:2310.18893v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Li Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoghi_M/0/1/0/all/0/1">Masrour Zoghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1">Guy Tennenholtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Karimzadehgan_M/0/1/0/all/0/1">Maryam Karimzadehgan</a></p>
<p>We introduce EV3, a novel meta-optimization framework designed to efficiently
train scalable machine learning models through an intuitive
explore-assess-adapt protocol. In each iteration of EV3, we explore various
model parameter updates, assess them using pertinent evaluation methods, and
then adapt the model based on the optimal updates and previous progress
history. EV3 offers substantial flexibility without imposing stringent
constraints like differentiability on the key objectives relevant to the tasks
of interest, allowing for exploratory updates with intentionally-biased
gradients and through a diversity of losses and optimizers. Additionally, the
assessment phase provides reliable safety controls to ensure robust
generalization, and can dynamically prioritize tasks in scenarios with multiple
objectives. With inspiration drawn from evolutionary algorithms, meta-learning,
and neural architecture search, we investigate an application of EV3 to
knowledge distillation. Our experimental results illustrate EV3's capability to
safely explore the modeling landscape, while hinting at its potential
applicability across numerous domains due to its inherent flexibility and
adaptability. Finally, we provide a JAX implementation of EV3, along with
source code for experiments, available at:
https://github.com/google-research/google-research/tree/master/ev3.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19704">A Survey on Knowledge Editing of Neural Networks. (arXiv:2310.19704v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrani_A/0/1/0/all/0/1">Alessandro Pedrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Caciolai_A/0/1/0/all/0/1">Andrea Caciolai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottmann_K/0/1/0/all/0/1">Kay Rottmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernardi_D/0/1/0/all/0/1">Davide Bernardi</a></p>
<p>Deep neural networks are becoming increasingly pervasive in academia and
industry, matching and surpassing human performance on a wide variety of fields
and related tasks. However, just as humans, even the largest artificial neural
networks make mistakes, and once-correct predictions can become invalid as the
world progresses in time. Augmenting datasets with samples that account for
mistakes or up-to-date information has become a common workaround in practical
applications. However, the well-known phenomenon of catastrophic forgetting
poses a challenge in achieving precise changes in the implicitly memorized
knowledge of neural network parameters, often requiring a full model
re-training to achieve desired behaviors. That is expensive, unreliable, and
incompatible with the current trend of large self-supervised pre-training,
making it necessary to find more efficient and effective methods for adapting
neural network models to changing data. To address this need, knowledge editing
is emerging as a novel area of research that aims to enable reliable,
data-efficient, and fast changes to a pre-trained target model, without
affecting model behaviors on previously learned tasks. In this survey, we
provide a brief review of this recent artificial intelligence field of
research. We first introduce the problem of editing neural networks, formalize
it in a common framework and differentiate it from more notorious branches of
research such as continuous learning. Next, we provide a review of the most
relevant knowledge editing approaches and datasets proposed so far, grouping
works under four different families: regularization techniques, meta-learning,
direct model editing, and architectural strategies. Finally, we outline some
intersections with other fields of research and potential directions for future
works.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.20092">Beyond U: Making Diffusion Models Faster &amp; Lighter. (arXiv:2310.20092v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Calvo_Ordonez_S/0/1/0/all/0/1">Sergio Calvo-Ordonez</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lipei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Schonlieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1">Angelica I Aviles-Rivero</a></p>
<p>Diffusion models are a family of generative models that yield record-breaking
performance in tasks such as image synthesis, video generation, and molecule
design. Despite their capabilities, their efficiency, especially in the reverse
denoising process, remains a challenge due to slow convergence rates and high
computational costs. In this work, we introduce an approach that leverages
continuous dynamical systems to design a novel denoising network for diffusion
models that is more parameter-efficient, exhibits faster convergence, and
demonstrates increased noise robustness. Experimenting with denoising
probabilistic diffusion models, our framework operates with approximately a
quarter of the parameters and $\sim 30\%$ of the Floating Point Operations
(FLOPs) compared to standard U-Nets in Denoising Diffusion Probabilistic Models
(DDPMs). Furthermore, our model is faster in inference than the baseline models
when measured in equal conditions while converging to better quality solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01683">Amide Proton Transfer (APT) imaging in tumor with a machine learning approach using partially synthetic data. (arXiv:2311.01683v2 [physics.med-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Viswanathan_M/0/1/0/all/0/1">Malvika Viswanathan</a>, <a href="http://arxiv.org/find/physics/1/au:+Yin_L/0/1/0/all/0/1">Leqi Yin</a>, <a href="http://arxiv.org/find/physics/1/au:+Kurmi_Y/0/1/0/all/0/1">Yashwant Kurmi</a>, <a href="http://arxiv.org/find/physics/1/au:+Zu_Z/0/1/0/all/0/1">Zhongliang Zu</a></p>
<p>Machine learning (ML) has been increasingly used to quantify chemical
exchange saturation transfer (CEST) effect. ML models are typically trained
using either measured data or fully simulated data. However, training with
measured data often lacks sufficient training data, while training with fully
simulated data may introduce bias due to limited simulations pools. This study
introduces a new platform that combines simulated and measured components to
generate partially synthetic CEST data, and to evaluate its feasibility for
training ML models to predict amide proton transfer (APT) effect. Partially
synthetic CEST signals were created using an inverse summation of APT effects
from simulations and the other components from measurements. Training data were
generated by varying APT simulation parameters and applying scaling factors to
adjust the measured components, achieving a balance between simulation
flexibility and fidelity. First, tissue-mimicking CEST signals along with
ground truth information were created using multiple-pool model simulations to
validate this method. Second, an ML model was trained individually on partially
synthetic data, in vivo data, and fully simulated data, to predict APT effect
in rat brains bearing 9L tumors. Experiments on tissue-mimicking data suggest
that the ML method using the partially synthetic data is accurate in predicting
APT. In vivo experiments suggest that our method provides more accurate and
robust prediction than the training using in vivo data and fully synthetic
data. Partially synthetic CEST data can address the challenges in conventional
ML methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08141">GMTR: Graph Matching Transformers. (arXiv:2311.08141v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jinpei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaofeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runzhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a></p>
<p>Vision transformers (ViTs) have recently been used for visual matching beyond
object detection and segmentation. However, the original grid dividing strategy
of ViTs neglects the spatial information of the keypoints, limiting the
sensitivity to local information. Therefore, we propose QueryTrans (Query
Transformer), which adopts a cross-attention module and keypoints-based center
crop strategy for better spatial information extraction. We further integrate
the graph attention module and devise a transformer-based graph matching
approach GMTR (Graph Matching TRansformers) whereby the combinatorial nature of
GM is addressed by a graph transformer neural GM solver. On standard GM
benchmarks, GMTR shows competitive performance against the SOTA frameworks.
Specifically, on Pascal VOC, GMTR achieves $\mathbf{83.6\%}$ accuracy,
$\mathbf{0.9\%}$ higher than the SOTA framework. On Spair-71k, GMTR shows great
potential and outperforms most of the previous works. Meanwhile, on Pascal VOC,
QueryTrans improves the accuracy of NGMv2 from $80.1\%$ to $\mathbf{83.3\%}$,
and BBGM from $79.0\%$ to $\mathbf{84.5\%}$. On Spair-71k, QueryTrans improves
NGMv2 from $80.6\%$ to $\mathbf{82.5\%}$, and BBGM from $82.1\%$ to
$\mathbf{83.9\%}$. Source code will be made publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08945">A Single-Loop Algorithm for Decentralized Bilevel Optimization. (arXiv:2311.08945v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Dong_Y/0/1/0/all/0/1">Youran Dong</a>, <a href="http://arxiv.org/find/math/1/au:+Ma_S/0/1/0/all/0/1">Shiqian Ma</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1">Junfeng Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_C/0/1/0/all/0/1">Chao Yin</a></p>
<p>Bilevel optimization has received more and more attention recently due to its
wide applications in machine learning. In this paper, we consider bilevel
optimization in decentralized networks. In particular, we propose a novel
single-loop algorithm for solving decentralized bilevel optimization with
strongly convex lower level problem. Our algorithm is fully single-loop and
does not require heavy matrix-vector multiplications when approximating the
hypergradient. Moreover, unlike existing methods for decentralized bilevel
optimization and federated bilevel optimization, our algorithm does not require
any gradient heterogeneity assumption. Our analysis shows that the proposed
algorithm achieves a sublinear convergence rate. Experimental results on
hyperparameter optimization problem with both synthetic and MNIST data sets
demonstrate the efficiency of the proposed algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11473">CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection. (arXiv:2311.11473v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yifan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhen Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1">Kai Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zongsheng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1">Yu Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huan Liu</a></p>
<p>Graph Neural Networks (GNNs) have emerged as a powerful tool for
representation learning on graphs, but they often suffer from overfitting and
label noise issues, especially when the data is scarce or imbalanced. Different
from the paradigm of previous methods that rely on single-node confidence, in
this paper, we introduce a novel Class-wise Selection for Graph Neural
Networks, dubbed CSGNN, which employs a neighbor-aggregated latent space to
adaptively select reliable nodes across different classes. Specifically, 1) to
tackle the class imbalance issue, we introduce a dynamic class-wise selection
mechanism, leveraging the clustering technique to identify clean nodes based on
the neighbor-aggregated confidences. In this way, our approach can avoid the
pitfalls of biased sampling which is common with global threshold techniques.
2) To alleviate the problem of noisy labels, built on the concept of the
memorization effect, CSGNN prioritizes learning from clean nodes before noisy
ones, thereby iteratively enhancing model performance while mitigating label
noise. Through extensive experiments, we demonstrate that CSGNN outperforms
state-of-the-art methods in terms of both effectiveness and robustness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.12304">Discovering Effective Policies for Land-Use Planning. (arXiv:2311.12304v2 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1">Risto Miikkulainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Francon_O/0/1/0/all/0/1">Olivier Francon</a>, <a href="http://arxiv.org/find/cs/1/au:+Young_D/0/1/0/all/0/1">Daniel Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyerson_E/0/1/0/all/0/1">Elliot Meyerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bieker_J/0/1/0/all/0/1">Jacob Bieker</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunha_H/0/1/0/all/0/1">Hugo Cunha</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodjat_B/0/1/0/all/0/1">Babak Hodjat</a></p>
<p>How areas of land are allocated for different uses, such as forests, urban,
and agriculture, has a large effect on carbon balance, and therefore climate
change. Based on available historical data on changes in land use and a
simulation of carbon emissions/absorption, a surrogate model can be learned
that makes it possible to evaluate the different options available to
decision-makers efficiently. An evolutionary search process can then be used to
discover effective land-use policies for specific locations. Such a system was
built on the Project Resilience platform and evaluated with the Land-Use
Harmonization dataset and the BLUE simulator. It generates Pareto fronts that
trade off carbon impact and amount of change customized to different locations,
thus providing a potentially useful tool for land-use planning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14388">A Parameterized Generative Adversarial Network Using Cyclic Projection for Explainable Medical Image Classification. (arXiv:2311.14388v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiong_X/0/1/0/all/0/1">Xiangyu Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yue Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaohong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_C/0/1/0/all/0/1">Chan-Tong Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_T/0/1/0/all/0/1">Tong Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qinquan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_W/0/1/0/all/0/1">Wei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tao Tan</a></p>
<p>Although current data augmentation methods are successful to alleviate the
data insufficiency, conventional augmentation are primarily intra-domain while
advanced generative adversarial networks (GANs) generate images remaining
uncertain, particularly in small-scale datasets. In this paper, we propose a
parameterized GAN (ParaGAN) that effectively controls the changes of synthetic
samples among domains and highlights the attention regions for downstream
classification. Specifically, ParaGAN incorporates projection distance
parameters in cyclic projection and projects the source images to the decision
boundary to obtain the class-difference maps. Our experiments show that ParaGAN
can consistently outperform the existing augmentation methods with explainable
classification on two small-scale medical datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18044">Transfer Learning in Robotics: An Upcoming Breakthrough? A Review of Promises and Challenges. (arXiv:2311.18044v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jaquier_N/0/1/0/all/0/1">No&#xe9;mie Jaquier</a>, <a href="http://arxiv.org/find/cs/1/au:+Welle_M/0/1/0/all/0/1">Michael C. Welle</a>, <a href="http://arxiv.org/find/cs/1/au:+Gams_A/0/1/0/all/0/1">Andrej Gams</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_K/0/1/0/all/0/1">Kunpeng Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fichera_B/0/1/0/all/0/1">Bernardo Fichera</a>, <a href="http://arxiv.org/find/cs/1/au:+Billard_A/0/1/0/all/0/1">Aude Billard</a>, <a href="http://arxiv.org/find/cs/1/au:+Ude_A/0/1/0/all/0/1">Ale&#x161; Ude</a>, <a href="http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1">Tamim Asfour</a>, <a href="http://arxiv.org/find/cs/1/au:+Kragic_D/0/1/0/all/0/1">Danica Kragic</a></p>
<p>Transfer learning is a conceptually-enticing paradigm in pursuit of truly
intelligent embodied agents. The core concept -- reusing prior knowledge to
learn in and from novel situations -- is successfully leveraged by humans to
handle novel situations. In recent years, transfer learning has received
renewed interest from the community from different perspectives, including
imitation learning, domain adaptation, and transfer of experience from
simulation to the real world, among others. In this paper, we unify the concept
of transfer learning in robotics and provide the first taxonomy of its kind
considering the key concepts of robot, task, and environment. Through a review
of the promises and challenges in the field, we identify the need of
transferring at different abstraction levels, the need of quantifying the
transfer gap and the quality of transfer, as well as the dangers of negative
transfer. Via this position paper, we hope to channel the effort of the
community towards the most significant roadblocks to realize the full potential
of transfer learning in robotics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18274">Semiparametric Efficient Inference in Adaptive Experiments. (arXiv:2311.18274v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Cook_T/0/1/0/all/0/1">Thomas Cook</a>, <a href="http://arxiv.org/find/stat/1/au:+Mishler_A/0/1/0/all/0/1">Alan Mishler</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1">Aaditya Ramdas</a></p>
<p>We consider the problem of efficient inference of the Average Treatment
Effect in a sequential experiment where the policy governing the assignment of
subjects to treatment or control can change over time. We first provide a
central limit theorem for the Adaptive Augmented Inverse-Probability Weighted
estimator, which is semiparametric efficient, under weaker assumptions than
those previously made in the literature. This central limit theorem enables
efficient inference at fixed sample sizes. We then consider a sequential
inference setting, deriving both asymptotic and nonasymptotic confidence
sequences that are considerably tighter than previous methods. These
anytime-valid methods enable inference under data-dependent stopping times
(sample sizes). Additionally, we use propensity score truncation techniques
from the recent off-policy estimation literature to reduce the finite sample
variance of our estimator without affecting the asymptotic variance. Empirical
results demonstrate that our methods yield narrower confidence sequences than
those previously developed in the literature while maintaining time-uniform
error control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01397">Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective. (arXiv:2312.01397v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Can Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tianjin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihua Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a></p>
<p>The rapid development of large-scale deep learning models questions the
affordability of hardware platforms, which necessitates the pruning to reduce
their computational and memory footprints. Sparse neural networks as the
product, have demonstrated numerous favorable benefits like low complexity,
undamaged generalization, etc. Most of the prominent pruning strategies are
invented from a model-centric perspective, focusing on searching and preserving
crucial weights by analyzing network topologies. However, the role of data and
its interplay with model-centric pruning has remained relatively unexplored. In
this research, we introduce a novel data-model co-design perspective: to
promote superior weight sparsity by learning important model topology and
adequate input data in a synergetic manner. Specifically, customized Visual
Prompts are mounted to upgrade neural Network sparsification in our proposed
VPNs framework. As a pioneering effort, this paper conducts systematic
investigations about the impact of different visual prompts on model pruning
and suggests an effective joint optimization approach. Extensive experiments
with 3 network architectures and 8 datasets evidence the substantial
performance improvements from VPNs over existing start-of-the-art pruning
algorithms. Furthermore, we find that subnetworks discovered by VPNs from
pre-trained models enjoy better transferability across diverse downstream
scenarios. These insights shed light on new promising possibilities of
data-model co-designs for vision model sparsification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01878">HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xingtong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zemin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinming Zhang</a></p>
<p>Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs)
are prominent techniques for homogeneous and heterogeneous graph representation
learning, yet their performance in an end-to-end supervised framework greatly
depends on the availability of task-specific supervision. To reduce the
labeling cost, pre-training on self-supervised pretext tasks has become a
popular paradigm,but there is often a gap between the pre-trained model and
downstream tasks, stemming from the divergence in their objectives. To bridge
the gap, prompt learning has risen as a promising direction especially in
few-shot settings, without the need to fully fine-tune the pre-trained model.
While there has been some early exploration of prompt-based learning on graphs,
they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs
that are prevalent in downstream applications. In this paper, we propose
HGPROMPT, a novel pre-training and prompting framework to unify not only
pre-training and downstream tasks but also homogeneous and heterogeneous graphs
via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to
assist a downstream task in locating the most relevant prior to bridge the gaps
caused by not only feature variations but also heterogeneity differences across
tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive
experiments on three public datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.02027">Stochastic Optimal Control Matching. (arXiv:2312.02027v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Domingo_Enrich_C/0/1/0/all/0/1">Carles Domingo-Enrich</a>, <a href="http://arxiv.org/find/math/1/au:+Han_J/0/1/0/all/0/1">Jiequn Han</a>, <a href="http://arxiv.org/find/math/1/au:+Amos_B/0/1/0/all/0/1">Brandon Amos</a>, <a href="http://arxiv.org/find/math/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_R/0/1/0/all/0/1">Ricky T. Q. Chen</a></p>
<p>Stochastic optimal control, which has the goal of driving the behavior of
noisy systems, is broadly applicable in science, engineering and artificial
intelligence. Our work introduces Stochastic Optimal Control Matching (SOCM), a
novel Iterative Diffusion Optimization (IDO) technique for stochastic optimal
control that stems from the same philosophy as the conditional score matching
loss for diffusion models. That is, the control is learned via a least squares
problem by trying to fit a matching vector field. The training loss, which is
closely connected to the cross-entropy loss, is optimized with respect to both
the control function and a family of reparameterization matrices which appear
in the matching vector field. The optimization with respect to the
reparameterization matrices aims at minimizing the variance of the matching
vector field. Experimentally, our algorithm achieves lower error than all the
existing IDO techniques for stochastic optimal control for three out of four
control problems, in some cases by an order of magnitude. The key idea
underlying SOCM is the path-wise reparameterization trick, a novel technique
that is of independent interest, e.g., for generative modeling. Code at
https://github.com/facebookresearch/SOC-matching
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03404">A Cyclical Route Linking Fundamental Mechanism and AI Algorithm: An Example from Poisson&#x27;s Ratio in Amorphous Networks. (arXiv:2312.03404v2 [cond-mat.soft] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Zhu_C/0/1/0/all/0/1">Changliang Zhu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fang_C/0/1/0/all/0/1">Chenchao Fang</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Jin_Z/0/1/0/all/0/1">Zhipeng Jin</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Li_B/0/1/0/all/0/1">Baowen Li</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Shen_X/0/1/0/all/0/1">Xiangying Shen</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Xu_L/0/1/0/all/0/1">Lei Xu</a></p>
<p>"AI for science" is widely recognized as a future trend in the development of
scientific research. Currently, although machine learning algorithms have
played a crucial role in scientific research with numerous successful cases,
relatively few instances exist where AI assists researchers in uncovering the
underlying physical mechanisms behind a certain phenomenon and subsequently
using that mechanism to improve machine learning algorithms' efficiency. This
article uses the investigation into the relationship between extreme Poisson's
ratio values and the structure of amorphous networks as a case study to
illustrate how machine learning methods can assist in revealing underlying
physical mechanisms. Upon recognizing that the Poisson's ratio relies on the
low-frequency vibrational modes of dynamical matrix, we can then employ a
convolutional neural network, trained on the dynamical matrix instead of
traditional image recognition, to predict the Poisson's ratio of amorphous
networks with a much higher efficiency. Through this example, we aim to
showcase the role that artificial intelligence can play in revealing
fundamental physical mechanisms, which subsequently improves the machine
learning algorithms significantly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03731">MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs. (arXiv:2312.03731v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xingtong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinming Zhang</a></p>
<p>Graphs can inherently model interconnected objects on the Web, thereby
facilitating a series of Web applications, such as web analyzing and content
recommendation. Recently, Graph Neural Networks (GNNs) have emerged as a
mainstream technique for graph representation learning. However, their efficacy
within an end-to-end supervised framework is significantly tied to the
availabilityof task-specific labels. To mitigate labeling costs and enhance
robustness in few-shot settings, pre-training on self-supervised tasks has
emerged as a promising method, while prompting has been proposed to further
narrow the objective gap between pretext and downstream tasks. Although there
has been some initial exploration of prompt-based learning on graphs, they
primarily leverage a single pretext task, resulting in a limited subset of
general knowledge that could be learned from the pre-training data. Hence, in
this paper, we propose MultiGPrompt, a novel multi-task pre-training and
prompting framework to exploit multiple pretext tasks for more comprehensive
pre-trained knowledge. First, in pre-training, we design a set of pretext
tokens to synergize multiple pretext tasks. Second, we propose a dual-prompt
mechanism consisting of composed and open prompts to leverage task-specific and
global pre-training knowledge, to guide downstream tasks in few-shot settings.
Finally, we conduct extensive experiments on six public datasets to evaluate
and analyze MultiGPrompt.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03818">Alpha-CLIP: A CLIP Model Focusing on Wherever You Want. (arXiv:2312.03818v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zeyi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Ye Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1">Yuhang Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1">Shu Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaqi Wang</a></p>
<p>Contrastive Language-Image Pre-training (CLIP) plays an essential role in
extracting valuable content information from images across diverse tasks. It
aligns textual and visual modalities to comprehend the entire image, including
all the details, even those irrelevant to specific tasks. However, for a finer
understanding and controlled editing of images, it becomes crucial to focus on
specific regions of interest, which can be indicated as points, masks, or boxes
by humans or perception models. To fulfill the requirements, we introduce
Alpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to
suggest attentive regions and fine-tuned with constructed millions of RGBA
region-text pairs. Alpha-CLIP not only preserves the visual recognition ability
of CLIP but also enables precise control over the emphasis of image contents.
It demonstrates effectiveness in various tasks, including but not limited to
open-world recognition, multimodal large language models, and conditional 2D /
3D generation. It has a strong potential to serve as a versatile tool for
image-related tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04070">A Transformer Model for Symbolic Regression towards Scientific Discovery. (arXiv:2312.04070v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lalande_F/0/1/0/all/0/1">Florian Lalande</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1">Yoshitomo Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiba_N/0/1/0/all/0/1">Naoya Chiba</a>, <a href="http://arxiv.org/find/cs/1/au:+Taniai_T/0/1/0/all/0/1">Tatsunori Taniai</a>, <a href="http://arxiv.org/find/cs/1/au:+Igarashi_R/0/1/0/all/0/1">Ryo Igarashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1">Yoshitaka Ushiku</a></p>
<p>Symbolic Regression (SR) searches for mathematical expressions which best
describe numerical datasets. This allows to circumvent interpretation issues
inherent to artificial neural networks, but SR algorithms are often
computationally expensive. This work proposes a new Transformer model aiming at
Symbolic Regression particularly focused on its application for Scientific
Discovery. We propose three encoder architectures with increasing flexibility
but at the cost of column-permutation equivariance violation. Training results
indicate that the most flexible architecture is required to prevent from
overfitting. Once trained, we apply our best model to the SRSD datasets
(Symbolic Regression for Scientific Discovery datasets) which yields
state-of-the-art results using the normalized tree-based edit distance, at no
extra computational cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04386">Model-Based Epistemic Variance of Values for Risk-Aware Policy Optimization. (arXiv:2312.04386v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luis_C/0/1/0/all/0/1">Carlos E. Luis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottero_A/0/1/0/all/0/1">Alessandro G. Bottero</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinogradska_J/0/1/0/all/0/1">Julia Vinogradska</a>, <a href="http://arxiv.org/find/cs/1/au:+Berkenkamp_F/0/1/0/all/0/1">Felix Berkenkamp</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a></p>
<p>We consider the problem of quantifying uncertainty over expected cumulative
rewards in model-based reinforcement learning. In particular, we focus on
characterizing the variance over values induced by a distribution over MDPs.
Previous work upper bounds the posterior variance over values by solving a
so-called uncertainty Bellman equation (UBE), but the over-approximation may
result in inefficient exploration. We propose a new UBE whose solution
converges to the true posterior variance over values and leads to lower regret
in tabular exploration problems. We identify challenges to apply the UBE theory
beyond tabular problems and propose a suitable approximation. Based on this
approximation, we introduce a general-purpose policy optimization algorithm,
Q-Uncertainty Soft Actor-Critic (QU-SAC), that can be applied for either
risk-seeking or risk-averse policy optimization with minimal changes.
Experiments in both online and offline RL demonstrate improved performance
compared to other uncertainty estimation methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05955">Learning Differentiable Particle Filter on the Fly. (arXiv:2312.05955v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunpeng Li</a></p>
<p>Differentiable particle filters are an emerging class of sequential Bayesian
inference techniques that use neural networks to construct components in state
space models. Existing approaches are mostly based on offline supervised
training strategies. This leads to the delay of the model deployment and the
obtained filters are susceptible to distribution shift of test-time data. In
this paper, we propose an online learning framework for differentiable particle
filters so that model parameters can be updated as data arrive. The technical
constraint is that there is no known ground truth state information in the
online inference setting. We address this by adopting an unsupervised loss to
construct the online model updating procedure, which involves a sequence of
filtering operations for online maximum likelihood-based parameter estimation.
We empirically evaluate the effectiveness of the proposed method, and compare
it with supervised learning methods in simulation settings including a
multivariate linear Gaussian state-space model and a simulated object tracking
experiment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06036">AI Competitions and Benchmarks: towards impactful challenges with post-challenge papers, benchmarks and other dissemination actions. (arXiv:2312.06036v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marot_A/0/1/0/all/0/1">Antoine Marot</a>, <a href="http://arxiv.org/find/cs/1/au:+Rousseau_D/0/1/0/all/0/1">David Rousseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhen Xu</a></p>
<p>Organising an AI challenge does not end with the final event. The
long-lasting impact also needs to be organised. This chapter covers the various
activities after the challenge is formally finished. The target audience of
different post-challenge activities is identified. The various outputs of the
challenge are listed with the means to collect them. The main part of the
chapter is a template for a typical post-challenge paper, including possible
graphs as well as advice on how to turn the challenge into a long-lasting
benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06528">Transformers Implement Functional Gradient Descent to Learn Non-Linear Functions In Context. (arXiv:2312.06528v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1">Suvrit Sra</a></p>
<p>Many neural network architectures have been shown to be Turing Complete, and
can thus implement arbitrary algorithms. However, Transformers are unique in
that they can implement gradient-based learning algorithms \emph{under simple
parameter configurations}. A line of recent work shows that linear Transformers
naturally learn to implement gradient descent (GD) when trained on a linear
regression in-context learning task. But the linearity assumption (either in
the Transformer architecture or in the learning task) is far from realistic
settings where non-linear activations crucially enable Transformers to learn
complicated non-linear functions. In this paper, we provide theoretical and
empirical evidence that non-linear Transformers can, and \emph{in fact do},
learn to implement learning algorithms to learn non-linear functions in
context. Our results apply to a broad class of combinations of non-linear
architectures, and non-linear in-context learning tasks. Interestingly, we show
that the optimal choice of non-linear activation depends in a natural way on
the non-linearity of the learning task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06887">Understanding and Leveraging the Learning Phases of Neural Networks. (arXiv:2312.06887v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Johannes Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabhushankar_M/0/1/0/all/0/1">Mohit Prabhushankar</a></p>
<p>The learning dynamics of deep neural networks are not well understood. The
information bottleneck (IB) theory proclaimed separate fitting and compression
phases. But they have since been heavily debated. We comprehensively analyze
the learning dynamics by investigating a layer's reconstruction ability of the
input and prediction performance based on the evolution of parameters during
training. We empirically show the existence of three phases using common
datasets and architectures such as ResNet and VGG: (i) near constant
reconstruction loss, (ii) decrease, and (iii) increase. We also derive an
empirically grounded data model and prove the existence of phases for
single-layer networks. Technically, our approach leverages classical complexity
analysis. It differs from IB by relying on measuring reconstruction loss rather
than information theoretic measures to relate information of intermediate
layers and inputs. Our work implies a new best practice for transfer learning:
We show empirically that the pre-training of a classifier should stop well
before its performance is optimal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06937">Can a Transformer Represent a Kalman Filter?. (arXiv:2312.06937v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goel_G/0/1/0/all/0/1">Gautam Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1">Peter Bartlett</a></p>
<p>Transformers are a class of autoregressive deep learning architectures which
have recently achieved state-of-the-art performance in various vision,
language, and robotics tasks. We revisit the problem of Kalman Filtering in
linear dynamical systems and show that Transformers can approximate the Kalman
Filter in a strong sense. Specifically, for any observable LTI system we
construct an explicit causally-masked Transformer which implements the Kalman
Filter, up to a small additive error which is bounded uniformly in time; we
call our construction the Transformer Filter. Our construction is based on a
two-step reduction. We first show that a softmax self-attention block can
exactly represent a certain Gaussian kernel smoothing estimator. We then show
that this estimator closely approximates the Kalman Filter. We also investigate
how the Transformer Filter can be used for measurement-feedback control and
prove that the resulting nonlinear controllers closely approximate the
performance of standard optimal control policies such as the LQG controller.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07492">SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in Generative Language Models. (arXiv:2312.07492v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nagireddy_M/0/1/0/all/0/1">Manish Nagireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiazor_L/0/1/0/all/0/1">Lamogha Chiazor</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Moninder Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldini_I/0/1/0/all/0/1">Ioana Baldini</a></p>
<p>Current datasets for unwanted social bias auditing are limited to studying
protected demographic features such as race and gender. In this work, we
introduce a comprehensive benchmark that is meant to capture the amplification
of social bias, via stigmas, in generative language models. We start with a
comprehensive list of 93 stigmas documented in social science literature and
curate a question-answering (QA) dataset which involves simple social
situations. Our benchmark, SocialStigmaQA, contains roughly 10K prompts, with a
variety of prompt styles, carefully constructed to systematically test for both
social bias and model robustness. We present results for SocialStigmaQA with
two widely used open source generative language models and we demonstrate that
the output generated by these models considerably amplifies existing social
bias against stigmatized groups. Specifically, we find that the proportion of
socially biased output ranges from 45% to 59% across a variety of decoding
strategies and prompting styles. We discover that the deliberate design of the
templates in our benchmark (e.g., by adding biasing text to the prompt or
varying the answer that indicates bias) impact the model tendencies to generate
socially biased output. Additionally, we report on patterns in the generated
chain-of-thought output, finding a variety of problems from subtle bias to
evidence of a lack of reasoning.
</p>
<p>Warning: This paper contains examples of text which is toxic, biased, and
harmful.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07851">Noise in the reverse process improves the approximation capabilities of diffusion models. (arXiv:2312.07851v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Elamvazhuthi_K/0/1/0/all/0/1">Karthik Elamvazhuthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1">Samet Oymak</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasqualetti_F/0/1/0/all/0/1">Fabio Pasqualetti</a></p>
<p>In Score based Generative Modeling (SGMs), the state-of-the-art in generative
modeling, stochastic reverse processes are known to perform better than their
deterministic counterparts. This paper delves into the heart of this
phenomenon, comparing neural ordinary differential equations (ODEs) and neural
stochastic differential equations (SDEs) as reverse processes. We use a control
theoretic perspective by posing the approximation of the reverse process as a
trajectory tracking problem. We analyze the ability of neural SDEs to
approximate trajectories of the Fokker-Planck equation, revealing the
advantages of stochasticity. First, neural SDEs exhibit a powerful regularizing
effect, enabling $L^2$ norm trajectory approximation surpassing the Wasserstein
metric approximation achieved by neural ODEs under similar conditions, even
when the reference vector field or score function is not Lipschitz. Applying
this result, we establish the class of distributions that can be sampled using
score matching in SGMs, relaxing the Lipschitz requirement on the gradient of
the data distribution in existing literature. Second, we show that this
approximation property is preserved when network width is limited to the input
dimension of the network. In this limited width case, the weights act as
control inputs, framing our analysis as a controllability problem for neural
SDEs in probability density space. This sheds light on how noise helps to steer
the system towards the desired solution and illuminates the empirical success
of stochasticity in generative modeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07953">Enhancing Robotic Navigation: An Evaluation of Single and Multi-Objective Reinforcement Learning Strategies. (arXiv:2312.07953v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Young_V/0/1/0/all/0/1">Vicki Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_J/0/1/0/all/0/1">Jumman Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1">Nirmalya Roy</a></p>
<p>This study presents a comparative analysis between single-objective and
multi-objective reinforcement learning methods for training a robot to navigate
effectively to an end goal while efficiently avoiding obstacles. Traditional
reinforcement learning techniques, namely Deep Q-Network (DQN), Deep
Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3), have been
evaluated using the Gazebo simulation framework in a variety of environments
with parameters such as random goal and robot starting locations. These methods
provide a numerical reward to the robot, offering an indication of action
quality in relation to the goal. However, their limitations become apparent in
complex settings where multiple, potentially conflicting, objectives are
present. To address these limitations, we propose an approach employing
Multi-Objective Reinforcement Learning (MORL). By modifying the reward function
to return a vector of rewards, each pertaining to a distinct objective, the
robot learns a policy that effectively balances the different goals, aiming to
achieve a Pareto optimal solution. This comparative study highlights the
potential for MORL in complex, dynamic robotic navigation tasks, setting the
stage for future investigations into more adaptable and robust robotic
behaviors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07987">SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention. (arXiv:2312.07987v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1">R&#xf3;bert Csord&#xe1;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1">Piotr Pi&#x119;kos</a>, <a href="http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1">Kazuki Irie</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a></p>
<p>The costly self-attention layers in modern Transformers require memory and
compute quadratic in sequence length. Existing approximation methods usually
underperform and fail to obtain significant speedups in practice. Here we
present SwitchHead - a novel method that reduces both compute and memory
requirements and achieves wall-clock speedup, while matching the language
modeling performance of baseline Transformers with the same parameter budget.
SwitchHead uses Mixture-of-Experts (MoE) layers for the value and output
projections and requires 4 to 8 times fewer attention matrices than standard
Transformers. Our novel attention can also be combined with MoE MLP layers,
resulting in an efficient fully-MoE "SwitchAll" Transformer model. Our code is
public.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08221">Curriculum-Enhanced Residual Soft An-Isotropic Normalization for Over-smoothness in Deep GNNs. (arXiv:2312.08221v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qirong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuling Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longkun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yang-Geng Fu</a></p>
<p>Despite Graph neural networks' significant performance gain over many classic
techniques in various graph-related downstream tasks, their successes are
restricted in shallow models due to over-smoothness and the difficulties of
optimizations among many other issues. In this paper, to alleviate the
over-smoothing issue, we propose a soft graph normalization method to preserve
the diversities of node embeddings and prevent indiscrimination due to possible
over-closeness. Combined with residual connections, we analyze the reason why
the method can effectively capture the knowledge in both input graph structures
and node features even with deep networks. Additionally, inspired by Curriculum
Learning that learns easy examples before the hard ones, we propose a novel
label-smoothing-based learning framework to enhance the optimization of deep
GNNs, which iteratively smooths labels in an auxiliary graph and constructs
many gradual non-smooth tasks for extracting increasingly complex knowledge and
gradually discriminating nodes from coarse to fine. The method arguably reduces
the risk of overfitting and generalizes better results. Finally, extensive
experiments are carried out to demonstrate the effectiveness and potential of
the proposed model and learning framework through comparison with twelve
existing baselines including the state-of-the-art methods on twelve real-world
node classification benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02506">String Diagrams with Factorized Densities. (arXiv:2305.02506v5 [cs.PL] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sennesh_E/0/1/0/all/0/1">Eli Sennesh</a> (Northeastern University), <a href="http://arxiv.org/find/cs/1/au:+Meent_J/0/1/0/all/0/1">Jan-Willem van de Meent</a> (University of Amsterdam)</p>
<p>A growing body of research on probabilistic programs and causal models has
highlighted the need to reason compositionally about model classes that extend
directed graphical models. Both probabilistic programs and causal models define
a joint probability density over a set of random variables, and exhibit sparse
structure that can be used to reason about causation and conditional
independence. This work builds on recent work on Markov categories of
probabilistic mappings to define a category whose morphisms combine a joint
density, factorized over each sample space, with a deterministic mapping from
samples to return values. This is a step towards closing the gap between recent
category-theoretic descriptions of probability measures, and the operational
definitions of factorized densities that are commonly employed in probabilistic
programming and causal inference.
</p>
</p>
</div>

    </div>
    </body>
    