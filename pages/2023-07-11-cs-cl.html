<!DOCTYPE html>
<html>
<head>
<title>2023-07-11-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.03762">Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models. (arXiv:2307.03762v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yuxi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Song-Chun Zhu</a></p>
<p>In this perspective paper, we first comprehensively review existing
evaluations of Large Language Models (LLMs) using both standardized tests and
ability-oriented benchmarks. We pinpoint several problems with current
evaluation methods that tend to overstate the capabilities of LLMs. We then
articulate what artificial general intelligence should encompass beyond the
capabilities of LLMs. We propose four characteristics of generally intelligent
agents: 1) they can perform unlimited tasks; 2) they can generate new tasks
within a context; 3) they operate based on a value system that underpins task
generation; and 4) they have a world model reflecting reality, which shapes
their interaction with the world. Building on this viewpoint, we highlight the
missing pieces in artificial general intelligence, that is, the unity of
knowing and acting. We argue that active engagement with objects in the real
world delivers more robust signals for forming conceptual representations.
Additionally, knowledge acquisition isn't solely reliant on passive input but
requires repeated trials and errors. We conclude by outlining promising future
research directions in the field of artificial general intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03764">For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran&#x27;s Gender Struggles. (arXiv:2307.03764v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khorramrouz_A/0/1/0/all/0/1">Adel Khorramrouz</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Sujan Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+KhudaBukhsh_A/0/1/0/all/0/1">Ashiqur R. KhudaBukhsh</a></p>
<p>In this paper, we present a computational analysis of the Persian language
Twitter discourse with the aim to estimate the shift in stance toward gender
equality following the death of Mahsa Amini in police custody. We present an
ensemble active learning pipeline to train a stance classifier. Our novelty
lies in the involvement of Iranian women in an active role as annotators in
building this AI system. Our annotators not only provide labels, but they also
suggest valuable keywords for more meaningful corpus creation as well as
provide short example documents for a guided sampling step. Our analyses
indicate that Mahsa Amini's death triggered polarized Persian language
discourse where both fractions of negative and positive tweets toward gender
equality increased. The increase in positive tweets was slightly greater than
the increase in negative tweets. We also observe that with respect to account
creation time, between the state-aligned Twitter accounts and pro-protest
Twitter accounts, pro-protest accounts are more similar to baseline Persian
Twitter activity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03823">Linguistic representations for fewer-shot relation extraction across domains. (arXiv:2307.03823v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gururaja_S/0/1/0/all/0/1">Sireesh Gururaja</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutt_R/0/1/0/all/0/1">Ritam Dutt</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_T/0/1/0/all/0/1">Tinglong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rose_C/0/1/0/all/0/1">Carolyn Rose</a></p>
<p>Recent work has demonstrated the positive impact of incorporating linguistic
representations as additional context and scaffolding on the in-domain
performance of several NLP tasks. We extend this work by exploring the impact
of linguistic representations on cross-domain performance in a few-shot
transfer setting. An important question is whether linguistic representations
enhance generalizability by providing features that function as cross-domain
pivots. We focus on the task of relation extraction on three datasets of
procedural text in two domains, cooking and materials science. Our approach
augments a popular transformer-based architecture by alternately incorporating
syntactic and semantic graphs constructed by freely available off-the-shelf
tools. We examine their utility for enhancing generalization, and investigate
whether earlier findings, e.g. that semantic representations can be more
helpful than syntactic ones, extend to relation extraction in multiple domains.
We find that while the inclusion of these graphs results in significantly
higher performance in few-shot transfer, both types of graph exhibit roughly
equivalent utility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03838">RADAR: Robust AI-Text Detection via Adversarial Learning. (arXiv:2307.03838v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaomeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_T/0/1/0/all/0/1">Tsung-Yi Ho</a></p>
<p>Recent advances in large language models (LLMs) and the intensifying
popularity of ChatGPT-like applications have blurred the boundary of
high-quality text generation between humans and machines. However, in addition
to the anticipated revolutionary changes to our technology and society, the
difficulty of distinguishing LLM-generated texts (AI-text) from human-generated
texts poses new challenges of misuse and fairness, such as fake content
generation, plagiarism, and false accusation of innocent writers. While
existing works show that current AI-text detectors are not robust to LLM-based
paraphrasing, this paper aims to bridge this gap by proposing a new framework
called RADAR, which jointly trains a Robust AI-text Detector via Adversarial
leaRning. RADAR is based on adversarial training of a paraphraser and a
detector. The paraphraser's goal is to generate realistic contents to evade
AI-text detection. RADAR uses the feedback from the detector to update the
paraphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly
2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets,
experimental results show that RADAR significantly outperforms existing AI-text
detection methods, especially when paraphrasing is in place. We also identify
the strong transferability of RADAR from instruction-tuned LLMs to other LLMs,
and evaluate the improved capability of RADAR via GPT-3.5.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03859">MDACE: MIMIC Documents Annotated with Code Evidence. (arXiv:2307.03859v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hua Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jafari_R/0/1/0/all/0/1">Rana Jafari</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_A/0/1/0/all/0/1">April Russell</a>, <a href="http://arxiv.org/find/cs/1/au:+Klopfer_R/0/1/0/all/0/1">Russell Klopfer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_E/0/1/0/all/0/1">Edmond Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Striner_B/0/1/0/all/0/1">Benjamin Striner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gormley_M/0/1/0/all/0/1">Matthew R. Gormley</a></p>
<p>We introduce a dataset for evidence/rationale extraction on an extreme
multi-label classification task over long medical documents. One such task is
Computer-Assisted Coding (CAC) which has improved significantly in recent
years, thanks to advances in machine learning technologies. Yet simply
predicting a set of final codes for a patient encounter is insufficient as CAC
systems are required to provide supporting textual evidence to justify the
billing codes. A model able to produce accurate and reliable supporting
evidence for each code would be a tremendous benefit. However, a human
annotated code evidence corpus is extremely difficult to create because it
requires specialized knowledge. In this paper, we introduce MDACE, the first
publicly available code evidence dataset, which is built on a subset of the
MIMIC-III clinical records. The dataset -- annotated by professional medical
coders -- consists of 302 Inpatient charts with 3,934 evidence spans and 52
Profee charts with 5,563 evidence spans. We implemented several evidence
extraction methods based on the EffectiveCAN model (Liu et al., 2021) to
establish baseline performance on this dataset. MDACE can be used to evaluate
code evidence extraction methods for CAC systems, as well as the accuracy and
interpretability of deep learning models for multi-label classification. We
believe that the release of MDACE will greatly improve the understanding and
application of deep learning technologies for medical coding and document
classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03875">Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mellou_K/0/1/0/all/0/1">Konstantina Mellou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathuri_J/0/1/0/all/0/1">Jeevan Pathuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Menache_I/0/1/0/all/0/1">Ishai Menache</a></p>
<p>Supply chain operations traditionally involve a variety of complex decision
making problems. Over the last few decades, supply chains greatly benefited
from advances in computation, which allowed the transition from manual
processing to automation and cost-effective optimization. Nonetheless, business
operators still need to spend substantial efforts in \emph{explaining} and
interpreting the optimization outcomes to stakeholders. Motivated by the recent
advances in Large Language Models (LLMs), we study how this disruptive
technology can help bridge the gap between supply chain automation and human
comprehension and trust thereof. We design \name{} -- a framework that accepts
as input queries in plain text, and outputs insights about the underlying
optimization outcomes. Our framework does not forgo the state-of-the-art
combinatorial optimization technology, but rather leverages it to
quantitatively answer what-if scenarios (e.g., how would the cost change if we
used supplier B instead of supplier A for a given demand?). Importantly, our
design does not require sending proprietary data over to LLMs, which can be a
privacy concern in some circumstances. We demonstrate the effectiveness of our
framework on a real server placement scenario within Microsoft's cloud supply
chain. Along the way, we develop a general evaluation benchmark, which can be
used to evaluate the accuracy of the LLM output in other scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03892">Embedding Mental Health Discourse for Community Recommendation. (arXiv:2307.03892v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dang_H/0/1/0/all/0/1">Hy Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziems_N/0/1/0/all/0/1">Noah Ziems</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a></p>
<p>Our paper investigates the use of discourse embedding techniques to develop a
community recommendation system that focuses on mental health support groups on
social media. Social media platforms provide a means for users to anonymously
connect with communities that cater to their specific interests. However, with
the vast number of online communities available, users may face difficulties in
identifying relevant groups to address their mental health concerns. To address
this challenge, we explore the integration of discourse information from
various subreddit communities using embedding techniques to develop an
effective recommendation system. Our approach involves the use of content-based
and collaborative filtering techniques to enhance the performance of the
recommendation system. Our findings indicate that the proposed approach
outperforms the use of each technique separately and provides interpretability
in the recommendation process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03897">Answering Ambiguous Questions via Iterative Prompting. (arXiv:2307.03897v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Weiwei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hengyi Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hongshen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Pengjie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaochun Ren</a></p>
<p>In open-domain question answering, due to the ambiguity of questions,
multiple plausible answers may exist. To provide feasible answers to an
ambiguous question, one approach is to directly predict all valid answers, but
this can struggle with balancing relevance and diversity. An alternative is to
gather candidate answers and aggregate them, but this method can be
computationally costly and may neglect dependencies among answers. In this
paper, we present AmbigPrompt to address the imperfections of existing
approaches to answering ambiguous questions. Specifically, we integrate an
answering model with a prompting model in an iterative manner. The prompting
model adaptively tracks the reading process and progressively triggers the
answering model to compose distinct and relevant answers. Additionally, we
develop a task-specific post-pretraining approach for both the answering model
and the prompting model, which greatly improves the performance of our
framework. Empirical studies on two commonly-used open benchmarks show that
AmbigPrompt achieves state-of-the-art or competitive results while using less
memory and having a lower inference latency than competing approaches.
Additionally, AmbigPrompt also performs well in low-resource settings. The code
are available at: https://github.com/sunnweiwei/AmbigPrompt.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03906">ScriptWorld: Text Based Environment For Learning Procedural Knowledge. (arXiv:2307.03906v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Abhinav Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_A/0/1/0/all/0/1">Areeb Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_U/0/1/0/all/0/1">Umang Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1">Ashutosh Modi</a></p>
<p>Text-based games provide a framework for developing natural language
understanding and commonsense knowledge about the world in reinforcement
learning based agents. Existing text-based environments often rely on fictional
situations and characters to create a gaming framework and are far from
real-world scenarios. In this paper, we introduce ScriptWorld: a text-based
environment for teaching agents about real-world daily chores and hence
imparting commonsense knowledge. To the best of our knowledge, it is the first
interactive text-based gaming framework that consists of daily real-world human
activities designed using scripts dataset. We provide gaming environments for
10 daily activities and perform a detailed analysis of the proposed
environment. We develop RL-based baseline models/agents to play the games in
Scriptworld. To understand the role of language models in such environments, we
leverage features obtained from pre-trained language models in the RL agents.
Our experiments show that prior knowledge obtained from a pre-trained language
model helps to solve real-world text-based gaming environments. We release the
environment via Github: https://github.com/Exploration-Lab/ScriptWorld
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03917">On decoder-only architecture for speech-to-text and large language model integration. (arXiv:2307.03917v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gaur_Y/0/1/0/all/0/1">Yashesh Gaur</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_L/0/1/0/all/0/1">Long Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1">Yimeng Zhu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1">Tianrui Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jinyu Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1">Shujie Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ren_B/0/1/0/all/0/1">Bo Ren</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_L/0/1/0/all/0/1">Linquan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a></p>
<p>Large language models (LLMs) have achieved remarkable success in the field of
natural language processing, enabling better human-computer interaction using
natural language. However, the seamless integration of speech signals into LLMs
has not been explored well. The "decoder-only" architecture has also not been
well studied for speech processing tasks. In this research, we introduce
Speech-LLaMA, a novel approach that effectively incorporates acoustic
information into text-based large language models. Our method leverages
Connectionist Temporal Classification and a simple audio encoder to map the
compressed acoustic features to the continuous semantic space of the LLM. In
addition, we further probe the decoder-only architecture for speech-to-text
tasks by training a smaller scale randomly initialized speech-LLaMA model from
speech-text paired data alone. We conduct experiments on multilingual
speech-to-text translation tasks and demonstrate a significant improvement over
strong baselines, highlighting the potential advantages of decoder-only models
for speech-to-text conversion.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03941">Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions. (arXiv:2307.03941v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dawen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Finckenberg_Broman_P/0/1/0/all/0/1">Pamela Finckenberg-Broman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1">Thong Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shidong Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhenchang Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Staples_M/0/1/0/all/0/1">Mark Staples</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiwei Xu</a></p>
<p>The Right to be Forgotten (RTBF) was first established as the result of the
ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and
was later included as the Right to Erasure under the General Data Protection
Regulation (GDPR) of European Union to allow individuals the right to request
personal data be deleted by organizations. Specifically for search engines,
individuals can send requests to organizations to exclude their information
from the query results. With the recent development of Large Language Models
(LLMs) and their use in chatbots, LLM-enabled software systems have become
popular. But they are not excluded from the RTBF. Compared with the indexing
approach used by search engines, LLMs store, and process information in a
completely different way. This poses new challenges for compliance with the
RTBF. In this paper, we explore these challenges and provide our insights on
how to implement technical solutions for the RTBF, including the use of machine
unlearning, model editing, and prompting engineering.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03952">Is ChatGPT a Good Personality Recognizer? A Preliminary Study. (arXiv:2307.03952v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yu Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Liang He</a></p>
<p>In recent years, personality has been regarded as a valuable personal factor
being incorporated into numerous tasks such as sentiment analysis and product
recommendation. This has led to widespread attention to text-based personality
recognition task, which aims to identify an individual's personality based on
given text. Considering that ChatGPT has recently exhibited remarkable
abilities on various natural language processing tasks, we provide a
preliminary evaluation of ChatGPT on text-based personality recognition task
for generating effective personality data. Concretely, we employ a variety of
prompting strategies to explore ChatGPT's ability in recognizing personality
from given text, especially the level-oriented prompting strategy we designed
for guiding ChatGPT in analyzing given text at a specified level. We compare
the performance of ChatGPT on two representative real-world datasets with
traditional neural network, fine-tuned RoBERTa, and corresponding
state-of-the-art task-specific model. The experimental results show that
ChatGPT with zero-shot chain-of-thought prompting exhibits impressive
personality recognition ability. Triggered by zero-shot chain-of-thought
prompting, ChatGPT outperforms fine-tuned RoBERTa on the two datasets and is
capable to provide natural language explanations through text-based logical
reasoning. Furthermore, relative to zero-shot chain-of-thought prompting,
zero-shot level-oriented chain-of-thought prompting enhances the personality
prediction ability of ChatGPT and reduces the performance gap between ChatGPT
and corresponding state-of-the-art task-specific model. Besides, we also
conduct experiments to observe the fairness of ChatGPT when identifying
personality and discover that ChatGPT shows unfairness to some sensitive
demographic attributes such as gender and age.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03972">Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task. (arXiv:2307.03972v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qu_F/0/1/0/all/0/1">Fanyi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yunfang Wu</a></p>
<p>Large-scale language models (LLMs) has shown remarkable capability in various
of Natural Language Processing (NLP) tasks and attracted lots of attention
recently. However, some studies indicated that large language models fail to
achieve promising result beyond the state-of-the-art models in English
grammatical error correction (GEC) tasks. In this report, we aim to explore the
how large language models perform on Chinese grammatical error correction tasks
and provide guidance for future work. We conduct experiments with 3 different
LLMs of different model scale on 4 Chinese GEC dataset. Our experimental
results indicate that the performances of LLMs on automatic evaluation metrics
falls short of the previous sota models because of the problem of
over-correction. Furthermore, we also discover notable variations in the
performance of LLMs when evaluated on different data distributions. Our
findings demonstrates that further investigation is required for the
application of LLMs on Chinese GEC task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03987">A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation. (arXiv:2307.03987v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Wenlin Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dong Yu</a></p>
<p>Recently developed large language models have achieved remarkable success in
generating fluent and coherent text. However, these models often tend to
'hallucinate' which critically hampers their reliability. In this work, we
address this crucial problem and propose an approach that actively detects and
mitigates hallucinations during the generation process. Specifically, we first
identify the candidates of potential hallucination leveraging the model's logit
output values, check their correctness through a validation procedure, mitigate
the detected hallucinations, and then continue with the generation process.
Through extensive experiments with the 'article generation task', we first
demonstrate the individual efficacy of our detection and mitigation techniques.
Specifically, the detection technique achieves a recall of 88% and the
mitigation technique successfully mitigates 57.6% of the correctly detected
hallucinations. Importantly, our mitigation technique does not introduce new
hallucinations even in the case of incorrectly detected hallucinations, i.e.,
false positives. Then, we show that the proposed active detection and
mitigation approach successfully reduces the hallucinations of the GPT-3 model
from 47.5% to 14.5% on average. In summary, our work contributes to improving
the reliability and trustworthiness of large language models, a crucial step en
route to enabling their widespread adoption in real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04008">Toward Interactive Dictation. (arXiv:2307.04008v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Belinda Z. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1">Jason Eisner</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauls_A/0/1/0/all/0/1">Adam Pauls</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomson_S/0/1/0/all/0/1">Sam Thomson</a></p>
<p>Voice dictation is an increasingly important text input modality. Existing
systems that allow both dictation and editing-by-voice restrict their command
language to flat templates invoked by trigger words. In this work, we study the
feasibility of allowing users to interrupt their dictation with spoken editing
commands in open-ended natural language. We introduce a new task and dataset,
TERTiUS, to experiment with such systems. To support this flexibility in
real-time, a system must incrementally segment and classify spans of speech as
either dictation or command, and interpret the spans that are commands. We
experiment with using large pre-trained language models to predict the edited
text, or alternatively, to predict a small text-editing program. Experiments
show a natural trade-off between model accuracy and latency: a smaller model
achieves 30% end-state accuracy with 1.3 seconds of latency, while a larger
model achieves 55% end-state accuracy with 7 seconds of latency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04018">Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation. (arXiv:2307.04018v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yulong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huajian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yijie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xuefeng Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yueguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1">Ming Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jianhao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yafu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Judy Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Michael Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a></p>
<p>Most existing cross-lingual summarization (CLS) work constructs CLS corpora
by simply and directly translating pre-annotated summaries from one language to
another, which can contain errors from both summarization and translation
processes. To address this issue, we propose ConvSumX, a cross-lingual
conversation summarization benchmark, through a new annotation schema that
explicitly considers source input context. ConvSumX consists of 2 sub-tasks
under different real-world scenarios, with each covering 3 language directions.
We conduct thorough analysis on ConvSumX and 3 widely-used manually annotated
CLS corpora and empirically find that ConvSumX is more faithful towards input
text. Additionally, based on the same intuition, we propose a 2-Step method,
which takes both conversation and summary as input to simulate human annotation
process. Experimental results show that 2-Step method surpasses strong
baselines on ConvSumX under both automatic and human evaluation. Analysis shows
that both source input text and summary are crucial for modeling cross-lingual
summaries.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04053">How is Fatherhood Framed Online in Singapore?. (arXiv:2307.04053v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Van_T/0/1/0/all/0/1">Tran Hien Van</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1">Abhay Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddique_M/0/1/0/all/0/1">Muhammad Siddique</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_L/0/1/0/all/0/1">Lam Yin Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Parekh_N/0/1/0/all/0/1">Nimay Parekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jonathan Y Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+McCrickerd_K/0/1/0/all/0/1">Keri McCrickerd</a>, <a href="http://arxiv.org/find/cs/1/au:+Tandoc_E/0/1/0/all/0/1">Edson C Tandoc Jr.</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_G/0/1/0/all/0/1">Gerard Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1">Navin Kumar</a></p>
<p>The proliferation of discussion about fatherhood in Singapore attests to its
significance, indicating the need for an exploration of how fatherhood is
framed, aiding policy-making around fatherhood in Singapore. Sound and holistic
policy around fatherhood in Singapore may reduce stigma and apprehension around
being a parent, critical to improving the nations flagging birth rate. We
analyzed 15,705 articles and 56,221 posts to study how fatherhood is framed in
Singapore across a range of online platforms (news outlets, parenting forums,
Twitter). We used NLP techniques to understand these differences. While
fatherhood was framed in a range of ways on the Singaporean online environment,
it did not seem that fathers were framed as central to the Singaporean family
unit. A strength of our work is how the different techniques we have applied
validate each other.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04057">Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wibisono_K/0/1/0/all/0/1">Kevin Christian Wibisono</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixin Wang</a></p>
<p>Bidirectional attention $\unicode{x2013}$ composed of self-attention with
positional encodings and the masked language model (MLM) objective
$\unicode{x2013}$ has emerged as a key component of modern large language
models (LLMs). Despite its empirical success, few studies have examined its
statistical underpinnings: What statistical model is bidirectional attention
implicitly fitting? What sets it apart from its non-attention predecessors? We
explore these questions in this paper. The key observation is that fitting a
single-layer single-head bidirectional attention, upon reparameterization, is
equivalent to fitting a continuous bag of words (CBOW) model with
mixture-of-experts (MoE) weights. Further, bidirectional attention with
multiple heads and multiple layers is equivalent to stacked MoEs and a mixture
of MoEs, respectively. This statistical viewpoint reveals the distinct use of
MoE in bidirectional attention, which aligns with its practical effectiveness
in handling heterogeneous data. It also suggests an immediate extension to
categorical tabular data, if we view each word location in a sentence as a
tabular feature. Across empirical studies, we find that this extension
outperforms existing tabular extensions of transformers in out-of-distribution
(OOD) generalization. Finally, this statistical perspective of bidirectional
attention enables us to theoretically characterize when linear word analogies
are present in its word embeddings. These analyses show that bidirectional
attention can require much stronger assumptions to exhibit linear word
analogies than its non-attention predecessors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04090">DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs. (arXiv:2307.04090v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roush_A/0/1/0/all/0/1">Allen Roush</a></p>
<p>Recent work within the Argument Mining community has shown the applicability
of Natural Language Processing systems for solving problems found within
competitive debate. One of the most important tasks within competitive debate
is for debaters to create high quality debate cases. We show that effective
debate cases can be constructed using constrained shortest path traversals on
Argumentative Semantic Knowledge Graphs. We study this potential in the context
of a type of American Competitive Debate, called Policy Debate, which already
has a large scale dataset targeting it called DebateSum. We significantly
improve upon DebateSum by introducing 53180 new examples, as well as further
useful metadata for every example, to the dataset. We leverage the txtai
semantic search and knowledge graph toolchain to produce and contribute 9
semantic knowledge graphs built on this dataset. We create a unique method for
evaluating which knowledge graphs are better in the context of producing policy
debate cases. A demo which automatically generates debate cases, along with all
other code and the Knowledge Graphs, are open-sourced and made available to the
public here: https://github.com/Hellisotherpeople/DebateKG
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04096">Optimal Transport Posterior Alignment for Cross-lingual Semantic Parsing. (arXiv:2307.04096v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1">Tom Sherborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosking_T/0/1/0/all/0/1">Tom Hosking</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1">Mirella Lapata</a></p>
<p>Cross-lingual semantic parsing transfers parsing capability from a
high-resource language (e.g., English) to low-resource languages with scarce
training data. Previous work has primarily considered silver-standard data
augmentation or zero-shot methods, however, exploiting few-shot gold data is
comparatively unexplored. We propose a new approach to cross-lingual semantic
parsing by explicitly minimizing cross-lingual divergence between probabilistic
latent variables using Optimal Transport. We demonstrate how this direct
guidance improves parsing from natural languages using fewer examples and less
training. We evaluate our method on two datasets, MTOP and MultiATIS++SQL,
establishing state-of-the-art results under a few-shot cross-lingual regime.
Ablation studies further reveal that our method improves performance even
without parallel input translations. In addition, we show that our model better
captures cross-lingual structure in the latent space to improve semantic
representation similarity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04114">FILM: How can Few-Shot Image Classification Benefit from Pre-Trained Language Models?. (arXiv:2307.04114v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zihao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_Y/0/1/0/all/0/1">Yunkai Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_D/0/1/0/all/0/1">Dong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huishuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weiran Huang</a></p>
<p>Few-shot learning aims to train models that can be generalized to novel
classes with only a few samples. Recently, a line of works are proposed to
enhance few-shot learning with accessible semantic information from class
names. However, these works focus on improving existing modules such as visual
prototypes and feature extractors of the standard few-shot learning framework.
This limits the full potential use of semantic information. In this paper, we
propose a novel few-shot learning framework that uses pre-trained language
models based on contrastive learning. To address the challenge of alignment
between visual features and textual embeddings obtained from text-based
pre-trained language model, we carefully design the textual branch of our
framework and introduce a metric module to generalize the cosine similarity.
For better transferability, we let the metric module adapt to different
few-shot tasks and adopt MAML to train the model via bi-level optimization.
Moreover, we conduct extensive experiments on multiple benchmarks to
demonstrate the effectiveness of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04123">Towards cross-language prosody transfer for dialog. (arXiv:2307.04123v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Avila_J/0/1/0/all/0/1">Jonathan E. Avila</a>, <a href="http://arxiv.org/find/cs/1/au:+Ward_N/0/1/0/all/0/1">Nigel G. Ward</a></p>
<p>Speech-to-speech translation systems today do not adequately support use for
dialog purposes. In particular, nuances of speaker intent and stance can be
lost due to improper prosody transfer. We present an exploration of what needs
to be done to overcome this. First, we developed a data collection protocol in
which bilingual speakers re-enact utterances from an earlier conversation in
their other language, and used this to collect an English-Spanish corpus, so
far comprising 1871 matched utterance pairs. Second, we developed a simple
prosodic dissimilarity metric based on Euclidean distance over a broad set of
prosodic features. We then used these to investigate cross-language prosodic
differences, measure the likely utility of three simple baseline models, and
identify phenomena which will require more powerful modeling. Our findings
should inform future research on cross-language prosody and the design of
speech-to-speech translation systems capable of effective prosody transfer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04167">Dream Content Discovery from Reddit with an Unsupervised Mixed-Method Approach. (arXiv:2307.04167v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Anubhab Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Scepanovic_S/0/1/0/all/0/1">Sanja &#x160;&#x107;epanovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Aiello_L/0/1/0/all/0/1">Luca Maria Aiello</a>, <a href="http://arxiv.org/find/cs/1/au:+Mallett_R/0/1/0/all/0/1">Remington Mallett</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrett_D/0/1/0/all/0/1">Deirdre Barrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Quercia_D/0/1/0/all/0/1">Daniele Quercia</a></p>
<p>Dreaming is a fundamental but not fully understood part of human experience
that can shed light on our thought patterns. Traditional dream analysis
practices, while popular and aided by over 130 unique scales and rating
systems, have limitations. Mostly based on retrospective surveys or lab
studies, they struggle to be applied on a large scale or to show the importance
and connections between different dream themes. To overcome these issues, we
developed a new, data-driven mixed-method approach for identifying topics in
free-form dream reports through natural language processing. We tested this
method on 44,213 dream reports from Reddit's r/Dreams subreddit, where we found
217 topics, grouped into 22 larger themes: the most extensive collection of
dream topics to date. We validated our topics by comparing it to the
widely-used Hall and van de Castle scale. Going beyond traditional scales, our
method can find unique patterns in different dream types (like nightmares or
recurring dreams), understand topic importance and connections, and observe
changes in collective dream experiences over time and around major events, like
the COVID-19 pandemic and the recent Russo-Ukrainian war. We envision that the
applications of our method will provide valuable insights into the intricate
nature of dreaming.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04172">Can Generative Large Language Models Perform ASR Error Correction?. (arXiv:2307.04172v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1">Rao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1">Mengjie Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1">Potsawee Manakul</a>, <a href="http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1">Mark Gales</a>, <a href="http://arxiv.org/find/cs/1/au:+Knill_K/0/1/0/all/0/1">Kate Knill</a></p>
<p>ASR error correction continues to serve as an important part of
post-processing for speech recognition systems. Traditionally, these models are
trained with supervised training using the decoding results of the underlying
ASR system and the reference text. This approach is computationally intensive
and the model needs to be re-trained when switching the underlying ASR model.
Recent years have seen the development of large language models and their
ability to perform natural language processing tasks in a zero-shot manner. In
this paper, we take ChatGPT as an example to examine its ability to perform ASR
error correction in the zero-shot or 1-shot settings. We use the ASR N-best
list as model input and propose unconstrained error correction and N-best
constrained error correction methods. Results on a Conformer-Transducer model
and the pre-trained Whisper model show that we can largely improve the ASR
system performance with error correction using the powerful ChatGPT model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04192">SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering. (arXiv:2307.04192v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1">Min-Yen Kan</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a></p>
<p>Video question--answering is a fundamental task in the field of video
understanding. Although current vision--language models (VLMs) equipped with
Video Transformers have enabled temporal modeling and yielded superior results,
they are at the cost of huge computational power and thus too expensive to
deploy in real-time application scenarios. An economical workaround only
samples a small portion of frames to represent the main content of that video
and tune an image--text model on these sampled frames. Recent video
understanding models usually randomly sample a set of frames or clips,
regardless of internal correlations between their visual contents, nor their
relevance to the problem. We argue that such kinds of aimless sampling may omit
the key frames from which the correct answer can be deduced, and the situation
gets worse when the sampling sparsity increases, which always happens as the
video lengths increase. To mitigate this issue, we propose two frame sampling
strategies, namely the most domain frames (MDF) and most implied frames (MIF),
to maximally preserve those frames that are most likely vital to the given
questions. MDF passively minimizes the risk of key frame omission in a
bootstrap manner, while MIS actively searches key frames customized for each
video--question pair with the assistance of auxiliary models. The experimental
results on three public datasets from three advanced VLMs (CLIP, GIT and
All-in-one) demonstrate that our proposed strategies can boost the performance
for image--text pretrained models. The source codes pertaining to the method
proposed in this paper are publicly available at
https://github.com/declare-lab/sas-vqa.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04251">ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey. (arXiv:2307.04251v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mohamadi_S/0/1/0/all/0/1">Salman Mohamadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mujtaba_G/0/1/0/all/0/1">Ghulam Mujtaba</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1">Gianfranco Doretto</a>, <a href="http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1">Donald A. Adjeroh</a></p>
<p>ChatGPT is a large language model (LLM) created by OpenAI that has been
carefully trained on a large amount of data. It has revolutionized the field of
natural language processing (NLP) and has pushed the boundaries of LLM
capabilities. ChatGPT has played a pivotal role in enabling widespread public
interaction with generative artificial intelligence (GAI) on a large scale. It
has also sparked research interest in developing similar technologies and
investigating their applications and implications. In this paper, our primary
goal is to provide a concise survey on the current lines of research on ChatGPT
and its evolution. We considered both the glass box and black box views of
ChatGPT, encompassing the components and foundational elements of the
technology, as well as its applications, impacts, and implications. The glass
box approach focuses on understanding the inner workings of the technology, and
the black box approach embraces it as a complex system, and thus examines its
inputs, outputs, and effects. This paves the way for a comprehensive
exploration of the technology and provides a road map for further research and
experimentation. We also lay out essential foundational literature on LLMs and
GAI in general and their connection with ChatGPT. This overview sheds light on
existing and missing research lines in the emerging field of LLMs, benefiting
both public users and developers. Furthermore, the paper delves into the broad
spectrum of applications and significant concerns in fields such as education,
research, healthcare, finance, etc.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04274">Assessing the efficacy of large language models in generating accurate teacher responses. (arXiv:2307.04274v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hicke_Y/0/1/0/all/0/1">Yann Hicke</a>, <a href="http://arxiv.org/find/cs/1/au:+Masand_A/0/1/0/all/0/1">Abhishek Masand</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Wentao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangavarapu_T/0/1/0/all/0/1">Tushaar Gangavarapu</a></p>
<p>(Tack et al., 2023) organized the shared task hosted by the 18th Workshop on
Innovative Use of NLP for Building Educational Applications on generation of
teacher language in educational dialogues. Following the structure of the
shared task, in this study, we attempt to assess the generative abilities of
large language models in providing informative and helpful insights to
students, thereby simulating the role of a knowledgeable teacher. To this end,
we present an extensive evaluation of several benchmarking generative models,
including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and
fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we
fine-tuned the Flan-T5 model using reinforcement learning. Our experimental
findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of
GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT.
</p>
<p>We hypothesize that several dataset characteristics, including sampling,
representativeness, and dialog completeness, pose significant challenges to
fine-tuning, thus contributing to the poor generalizability of the fine-tuned
models. Finally, we note the need for these generative models to be evaluated
with a metric that relies not only on dialog coherence and matched language
modeling distribution but also on the model's ability to showcase pedagogical
skills.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04276">Automated Essay Scoring in Argumentative Writing: DeBERTeachingAssistant. (arXiv:2307.04276v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hicke_Y/0/1/0/all/0/1">Yann Hicke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_T/0/1/0/all/0/1">Tonghua Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_K/0/1/0/all/0/1">Karan Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Choong Hee Kim</a></p>
<p>Automated Essay scoring has been explored as a research and industry problem
for over 50 years. It has drawn a lot of attention from the NLP community
because of its clear educational value as a research area that can engender the
creation of valuable time-saving tools for educators around the world. Yet,
these tools are generally focused on detecting good grammar, spelling mistakes,
and organization quality but tend to fail at incorporating persuasiveness
features in their final assessment. The responsibility to give actionable
feedback to the student to improve the strength of their arguments is left
solely on the teacher's shoulders. In this work, we present a transformer-based
architecture capable of achieving above-human accuracy in annotating
argumentative writing discourse elements for their persuasiveness quality and
we expand on planned future work investigating the explainability of our model
so that actionable feedback can be offered to the student and thus potentially
enable a partnership between the teacher's advice and the machine's advice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04285">HistRED: A Historical Document-Level Relation Extraction Dataset. (arXiv:2307.04285v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Soyoung Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1">Minseok Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1">Youngwoo Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a></p>
<p>Despite the extensive applications of relation extraction (RE) tasks in
various domains, little has been explored in the historical context, which
contains promising data across hundreds and thousands of years. To promote the
historical RE research, we present HistRED constructed from Yeonhaengnok.
Yeonhaengnok is a collection of records originally written in Hanja, the
classical Chinese writing, which has later been translated into Korean. HistRED
provides bilingual annotations such that RE can be performed on Korean and
Hanja texts. In addition, HistRED supports various self-contained subtexts with
different lengths, from a sentence level to a document level, supporting
diverse context settings for researchers to evaluate the robustness of their RE
models. To demonstrate the usefulness of our dataset, we propose a bilingual RE
model that leverages both Korean and Hanja contexts to predict relations
between entities. Our model outperforms monolingual baselines on HistRED,
showing that employing multiple language contexts supplements the RE
predictions. The dataset is publicly available at:
https://huggingface.co/datasets/Soyoung/HistRED under CC BY-NC-ND 4.0 license.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04303">Learning to Generate Equitable Text in Dialogue from Biased Training Data. (arXiv:2307.04303v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sicilia_A/0/1/0/all/0/1">Anthony Sicilia</a>, <a href="http://arxiv.org/find/cs/1/au:+Alikhani_M/0/1/0/all/0/1">Malihe Alikhani</a></p>
<p>The ingrained principles of fairness in a dialogue system's decision-making
process and generated responses are crucial for user engagement, satisfaction,
and task achievement. Absence of equitable and inclusive principles can hinder
the formation of common ground, which in turn negatively impacts the overall
performance of the system. For example, misusing pronouns in a user interaction
may cause ambiguity about the intended subject. Yet, there is no comprehensive
study of equitable text generation in dialogue. Aptly, in this work, we use
theories of computational learning to study this problem. We provide formal
definitions of equity in text generation, and further, prove formal connections
between learning human-likeness and learning equity: algorithms for improving
equity ultimately reduce to algorithms for improving human-likeness (on
augmented data). With this insight, we also formulate reasonable conditions
under which text generation algorithms can learn to generate equitable text
without any modifications to the biased training data on which they learn. To
exemplify our theory in practice, we look at a group of algorithms for the
GuessWhat?! visual dialogue game and, using this example, test our theory
empirically. Our theory accurately predicts relative-performance of multiple
algorithms in generating equitable text as measured by both human and automated
evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2009.04975">Forecasting financial markets with semantic network analysis in the COVID-19 crisis. (arXiv:2009.04975v4 [q-fin.GN] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Colladon_A/0/1/0/all/0/1">A. Fronzetti Colladon</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Grassi_S/0/1/0/all/0/1">S. Grassi</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Ravazzolo_F/0/1/0/all/0/1">F. Ravazzolo</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Violante_F/0/1/0/all/0/1">F. Violante</a></p>
<p>This paper uses a new textual data index for predicting stock market data.
The index is applied to a large set of news to evaluate the importance of one
or more general economic-related keywords appearing in the text. The index
assesses the importance of the economic-related keywords, based on their
frequency of use and semantic network position. We apply it to the Italian
press and construct indices to predict Italian stock and bond market returns
and volatilities in a recent sample period, including the COVID-19 crisis. The
evidence shows that the index captures the different phases of financial time
series well. Moreover, results indicate strong evidence of predictability for
bond market data, both returns and volatilities, short and long maturities, and
stock market volatility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.02364">KenSwQuAD -- A Question Answering Dataset for Swahili Low Resource Language. (arXiv:2205.02364v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wanjawa_B/0/1/0/all/0/1">Barack W. Wanjawa</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Wanzare_L/0/1/0/all/0/1">Lilian D.A. Wanzare</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Indede_F/0/1/0/all/0/1">Florence Indede</a> (2), <a href="http://arxiv.org/find/cs/1/au:+McOnyango_O/0/1/0/all/0/1">Owen McOnyango</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Muchemi_L/0/1/0/all/0/1">Lawrence Muchemi</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ombui_E/0/1/0/all/0/1">Edward Ombui</a> (3) ((1) University of Nairobi Kenya, (2) Maseno University Kenya (3) Africa Nazarene University Kenya)</p>
<p>The need for Question Answering datasets in low resource languages is the
motivation of this research, leading to the development of Kencorpus Swahili
Question Answering Dataset, KenSwQuAD. This dataset is annotated from raw story
texts of Swahili low resource language, which is a predominantly spoken in
Eastern African and in other parts of the world. Question Answering (QA)
datasets are important for machine comprehension of natural language for tasks
such as internet search and dialog systems. Machine learning systems need
training data such as the gold standard Question Answering set developed in
this research. The research engaged annotators to formulate QA pairs from
Swahili texts collected by the Kencorpus project, a Kenyan languages corpus.
The project annotated 1,445 texts from the total 2,585 texts with at least 5 QA
pairs each, resulting into a final dataset of 7,526 QA pairs. A quality
assurance set of 12.5% of the annotated texts confirmed that the QA pairs were
all correctly annotated. A proof of concept on applying the set to the QA task
confirmed that the dataset can be usable for such tasks. KenSwQuAD has also
contributed to resourcing of the Swahili language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.01307">Multilingual Coreference Resolution in Multiparty Dialogue. (arXiv:2208.01307v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Boyuan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_P/0/1/0/all/0/1">Patrick Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yarmohammadi_M/0/1/0/all/0/1">Mahsa Yarmohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1">Benjamin Van Durme</a></p>
<p>Existing multiparty dialogue datasets for entity coreference resolution are
nascent, and many challenges are still unaddressed. We create a large-scale
dataset, Multilingual Multiparty Coref (MMC), for this task based on TV
transcripts. Due to the availability of gold-quality subtitles in multiple
languages, we propose reusing the annotations to create silver coreference
resolution data in other languages (Chinese and Farsi) via annotation
projection. On the gold (English) data, off-the-shelf models perform relatively
poorly on MMC, suggesting that MMC has broader coverage of multiparty
coreference than prior datasets. On the silver data, we find success both using
it for data augmentation and training from scratch, which effectively simulates
the zero-shot cross-lingual setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.10264">Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. (arXiv:2208.10264v5 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aher_G/0/1/0/all/0/1">Gati Aher</a>, <a href="http://arxiv.org/find/cs/1/au:+Arriaga_R/0/1/0/all/0/1">Rosa I. Arriaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1">Adam Tauman Kalai</a></p>
<p>We introduce a new type of test, called a Turing Experiment (TE), for
evaluating to what extent a given language model, such as GPT models, can
simulate different aspects of human behavior. A TE can also reveal consistent
distortions in a language model's simulation of a specific human behavior.
Unlike the Turing Test, which involves simulating a single arbitrary
individual, a TE requires simulating a representative sample of participants in
human subject research. We carry out TEs that attempt to replicate
well-established findings from prior studies. We design a methodology for
simulating TEs and illustrate its use to compare how well different language
models are able to reproduce classic economic, psycholinguistic, and social
psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock
Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings
were replicated using recent models, while the last TE reveals a
"hyper-accuracy distortion" present in some language models (including ChatGPT
and GPT-4), which could affect downstream applications in education and the
arts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.12306">Multimedia Generative Script Learning for Task Planning. (arXiv:2208.12306v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Manling Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1">Hou Pong Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lifu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hockenmaier_J/0/1/0/all/0/1">Julia Hockenmaier</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a></p>
<p>Goal-oriented generative script learning aims to generate subsequent steps to
reach a particular goal, which is an essential task to assist robots or humans
in performing stereotypical activities. An important aspect of this process is
the ability to capture historical states visually, which provides detailed
information that is not covered by text and will guide subsequent steps.
Therefore, we propose a new task, Multimedia Generative Script Learning, to
generate subsequent steps by tracking historical states in both text and vision
modalities, as well as presenting the first benchmark containing 5,652 tasks
and 79,089 multimedia steps. This task is challenging in three aspects: the
multimedia challenge of capturing the visual states in images, the induction
challenge of performing unseen tasks, and the diversity challenge of covering
different information in individual steps. We propose to encode visual state
changes through a selective multimedia encoder to address the multimedia
challenge, transfer knowledge from previously observed tasks using a
retrieval-augmented decoder to overcome the induction challenge, and further
present distinct information at each step by optimizing a diversity-oriented
contrastive learning objective. We define metrics to evaluate both generation
and inductive quality. Experiment results demonstrate that our approach
significantly outperforms strong baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.08917">Mars: Modeling Context &amp; State Representations with Contrastive Learning for End-to-End Task-Oriented Dialog. (arXiv:2210.08917v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haipeng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Junwei Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Youzheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a></p>
<p>Traditional end-to-end task-oriented dialog systems first convert dialog
context into belief state and action state before generating the system
response. The system response performance is significantly affected by the
quality of the belief state and action state. We first explore what dialog
context representation is beneficial to improving the quality of the belief
state and action state, which further enhances the generated response quality.
To tackle our exploration, we propose Mars, an end-to-end task-oriented dialog
system with two contrastive learning strategies to model the relationship
between dialog context and belief/action state representations. Empirical
results show dialog context representations, which are more different from
semantic state representations, are more conducive to multi-turn task-oriented
dialog. Moreover, our proposed Mars achieves state-of-the-art performance on
the MultiWOZ 2.0, CamRest676, and CrossWOZ.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.05750">Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control. (arXiv:2211.05750v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_Y/0/1/0/all/0/1">Yiwei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Paul Pu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1">Louis-Philippe Morency</a></p>
<p>Pretrained language models have demonstrated extraordinary capabilities in
language generation. However, real-world tasks often require controlling the
distribution of generated text in order to mitigate bias, promote fairness, and
achieve personalization. Existing techniques for controlling the distribution
of generated text only work with quantified distributions, which require
pre-defined categories, proportions of the distribution, or an existing corpus
following the desired distributions. However, many important distributions,
such as personal preferences, are unquantified. In this work, we tackle the
problem of generating text following arbitrary distributions (quantified and
unquantified) by proposing Nano, a few-shot human-in-the-loop training
algorithm that continuously learns from human feedback. Nano achieves
state-of-the-art results on single topic/attribute as well as quantified
distribution control compared to previous works. We also show that Nano is able
to learn unquantified distributions, achieves personalization, and captures
differences between different individuals' personal preferences with high
sample efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.12316">Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions. (arXiv:2211.12316v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhattamishra_S/0/1/0/all/0/1">Satwik Bhattamishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1">Arkil Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanade_V/0/1/0/all/0/1">Varun Kanade</a>, <a href="http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1">Phil Blunsom</a></p>
<p>Despite the widespread success of Transformers on NLP tasks, recent works
have found that they struggle to model several formal languages when compared
to recurrent models. This raises the question of why Transformers perform well
in practice and whether they have any properties that enable them to generalize
better than recurrent models. In this work, we conduct an extensive empirical
study on Boolean functions to demonstrate the following: (i) Random
Transformers are relatively more biased towards functions of low sensitivity.
(ii) When trained on Boolean functions, both Transformers and LSTMs prioritize
learning functions of low sensitivity, with Transformers ultimately converging
to functions of lower sensitivity. (iii) On sparse Boolean functions which have
low sensitivity, we find that Transformers generalize near perfectly even in
the presence of noisy labels whereas LSTMs overfit and achieve poor
generalization accuracy. Overall, our results provide strong quantifiable
evidence that suggests differences in the inductive biases of Transformers and
recurrent models which may help explain Transformer's effective generalization
performance despite relatively limited expressiveness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09739">LENS: A Learnable Evaluation Metric for Text Simplification. (arXiv:2212.09739v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maddela_M/0/1/0/all/0/1">Mounica Maddela</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1">Yao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Heineman_D/0/1/0/all/0/1">David Heineman</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a></p>
<p>Training learnable metrics using modern language models has recently emerged
as a promising method for the automatic evaluation of machine translation.
However, existing human evaluation datasets for text simplification have
limited annotations that are based on unitary or outdated models, making them
unsuitable for this approach. To address these issues, we introduce the
SimpEval corpus that contains: SimpEval_past, comprising 12K human ratings on
2.4K simplifications of 24 past systems, and SimpEval_2022, a challenging
simplification benchmark consisting of over 1K human ratings of 360
simplifications including GPT-3.5 generated text. Training on SimpEval, we
present LENS, a Learnable Evaluation Metric for Text Simplification. Extensive
empirical results show that LENS correlates much better with human judgment
than existing metrics, paving the way for future progress in the evaluation of
text simplification. We also introduce Rank and Rate, a human evaluation
framework that rates simplifications from several models in a list-wise manner
using an interactive interface, which ensures both consistency and accuracy in
the evaluation process and is used to create the SimpEval datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.10515">CausalDialogue: Modeling Utterance-level Causality in Conversations. (arXiv:2212.10515v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1">Yi-Lin Tuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1">Alon Albalak</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenda Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1">Michael Saxon</a>, <a href="http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1">Connor Pryor</a>, <a href="http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1">Lise Getoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a></p>
<p>Despite their widespread adoption, neural conversation models have yet to
exhibit natural chat capabilities with humans. In this research, we examine
user utterances as causes and generated responses as effects, recognizing that
changes in a cause should produce a different effect. To further explore this
concept, we have compiled and expanded upon a new dataset called CausalDialogue
through crowd-sourcing. This dataset includes multiple cause-effect pairs
within a directed acyclic graph (DAG) structure. Our analysis reveals that
traditional loss functions struggle to effectively incorporate the DAG
structure, leading us to propose a causality-enhanced method called Exponential
Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at
the utterance level in training neural conversation models. To evaluate the
needs of considering causality in dialogue generation, we built a comprehensive
benchmark on CausalDialogue dataset using different models, inference, and
training methods. Through experiments, we find that a causality-inspired loss
like ExMATE can improve the diversity and agility of conventional loss function
and there is still room for improvement to reach human-level quality on this
new dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.11489">Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation. (arXiv:2301.11489v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leszczynski_M/0/1/0/all/0/1">Megan Leszczynski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganti_R/0/1/0/all/0/1">Ravi Ganti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Balog_K/0/1/0/all/0/1">Krisztian Balog</a>, <a href="http://arxiv.org/find/cs/1/au:+Radlinski_F/0/1/0/all/0/1">Filip Radlinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1">Fernando Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaganty_A/0/1/0/all/0/1">Arun Tejasvi Chaganty</a></p>
<p>Recommendation systems are ubiquitous yet often difficult for users to
control and adjust when recommendation quality is poor. This has motivated the
development of conversational recommendation systems (CRSs), with control over
recommendations provided through natural language feedback. However, building
conversational recommendation systems requires conversational training data
involving user utterances paired with items that cover a diverse range of
preferences. Such data has proved challenging to collect scalably using
conventional methods like crowdsourcing. We address it in the context of
item-set recommendation, noting the increasing attention to this task motivated
by use cases like music, news and recipe recommendation. We present a new
technique, TalkTheWalk, that synthesizes realistic high-quality conversational
data by leveraging domain expertise encoded in widely available curated item
collections, showing how these can be transformed into corresponding item set
curation conversations. Specifically, TalkTheWalk generates a sequence of
hypothetical yet plausible item sets returned by a system, then uses a language
model to produce corresponding user utterances. Applying TalkTheWalk to music
recommendation, we generate over one million diverse playlist curation
conversations. A human evaluation shows that the conversations contain
consistent utterances with relevant item sets, nearly matching the quality of
small human-collected conversational data for this task. At the same time, when
the synthetic corpus is used to train a CRS, it improves Hits@100 by 10.5
points on a benchmark dataset over standard baselines and is preferred over the
top-performing baseline in an online evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.00786">Building High-accuracy Multilingual ASR with Gated Language Experts and Curriculum Training. (arXiv:2303.00786v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1">Eric Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuxuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yimeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Long Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jian Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Linquan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shujie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1">Edward Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yifan Gong</a></p>
<p>We propose gated language experts and curriculum training to enhance
multilingual transformer transducer models without requiring language
identification (LID) input from users during inference. Our method incorporates
a gating mechanism and LID loss, enabling transformer experts to learn
language-specific information. By combining gated transformer experts with
shared transformer layers, we construct multilingual transformer blocks and
utilize linear experts to effectively regularize the joint network. The
curriculum training scheme leverages LID to guide the gated experts in
improving their respective language performance. Experimental results on a
bilingual task involving English and Spanish demonstrate significant
improvements, with average relative word error reductions of 12.5% and 7.3%
compared to the baseline bilingual and monolingual models, respectively.
Notably, our method achieves performance comparable to the upper-bound model
trained and inferred with oracle LID. Extending our approach to trilingual,
quadrilingual, and pentalingual models reveals similar advantages to those
observed in the bilingual models, highlighting its ease of extension to
multiple languages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.04526">Student&#x27;s t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce. (arXiv:2303.04526v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gladkoff_S/0/1/0/all/0/1">Serge Gladkoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lifeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1">Goran Nenadic</a></p>
<p>In natural language processing (NLP) we always rely on human judgement as the
golden quality evaluation method. However, there has been an ongoing debate on
how to better evaluate inter-rater reliability (IRR) levels for certain
evaluation tasks, such as translation quality evaluation (TQE), especially when
the data samples (observations) are very scarce. In this work, we first
introduce the study on how to estimate the confidence interval for the
measurement value when only one data (evaluation) point is available. Then,
this leads to our example with two human-generated observational scores, for
which, we introduce ``Student's \textit{t}-Distribution'' method and explain
how to use it to measure the IRR score using only these two data points, as
well as the confidence intervals (CIs) of the quality evaluation. We give
quantitative analysis on how the evaluation confidence can be greatly improved
by introducing more observations, even if only one extra observation. We
encourage researchers to report their IRR scores in all possible means, e.g.
using Student's \textit{t}-Distribution method whenever possible; thus making
the NLP evaluation more meaningful, transparent, and trustworthy. This
\textit{t}-Distribution method can be also used outside of NLP fields to
measure IRR level for trustworthy evaluation of experimental investigations,
whenever the observational data is scarce.
</p>
<p>Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence
Intervals (CIs); Natural Language Processing (NLP); Translation Quality
Evaluation (TQE); Student's \textit{t}-Distribution
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.00008">On the Creativity of Large Language Models. (arXiv:2304.00008v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Franceschelli_G/0/1/0/all/0/1">Giorgio Franceschelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Musolesi_M/0/1/0/all/0/1">Mirco Musolesi</a></p>
<p>Large Language Models (LLMs) are revolutionizing several areas of Artificial
Intelligence. One of the most remarkable applications is creative writing,
e.g., poetry or storytelling: the generated outputs are often of astonishing
quality. However, a natural question arises: can LLMs be really considered
creative? In this article we firstly analyze the development of LLMs under the
lens of creativity theories, investigating the key open questions and
challenges. In particular, we focus our discussion around the dimensions of
value, novelty and surprise as proposed by Margaret Boden in her work. Then, we
consider different classic perspectives, namely product, process, press and
person. We discuss a set of ``easy'' and ``hard'' problems in machine
creativity, presenting them in relation to LLMs. Finally, we examine the
societal impact of these technologies with a particular focus on the creative
industries, analyzing the opportunities offered by them, the challenges arising
by them and the potential associated risks, from both legal and ethical points
of view.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.00215">Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers. (arXiv:2304.00215v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1">Zhendong Mao</a></p>
<p>Relation prediction on knowledge graphs (KGs) is a key research topic.
Dominant embedding-based methods mainly focus on the transductive setting and
lack the inductive ability to generalize to new entities for inference.
Existing methods for inductive reasoning mostly mine the connections between
entities, i.e., relational paths, without considering the nature of head and
tail entities contained in the relational context. This paper proposes a novel
method that captures both connections between entities and the intrinsic nature
of entities, by simultaneously aggregating RElational Paths and cOntext with a
unified hieRarchical Transformer framework, namely REPORT. REPORT relies solely
on relation semantics and can naturally generalize to the fully-inductive
setting, where KGs for training and inference have no common entities. In the
experiments, REPORT performs consistently better than all baselines on almost
all the eight version subsets of two fully-inductive datasets. Moreover. REPORT
is interpretable by providing each element's contribution to the prediction
results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06569">How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v4 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wenyue Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yingqiang Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a></p>
<p>Recommendation foundation model utilizes large language models (LLM) for
recommendation by converting recommendation tasks into natural language tasks.
It enables generative recommendation which directly generates the item(s) to
recommend rather than calculating a ranking score for each and every candidate
item in traditional recommendation models, simplifying the recommendation
pipeline from multi-stage filtering to single-stage filtering. To avoid
generating excessively long text when deciding which item(s) to recommend,
creating LLM-compatible item IDs is essential for recommendation foundation
models. In this study, we systematically examine the item indexing problem for
recommendation foundation models, using P5 as the representative backbone model
and replicating its results with various indexing methods. To emphasize the
importance of item indexing, we first discuss the issues of several trivial
item indexing methods, such as independent indexing, title indexing, and random
indexing. We then propose four simple yet effective solutions, including
sequential indexing, collaborative indexing, semantic (content-based) indexing,
and hybrid indexing. Our reproducibility study of P5 highlights the significant
influence of item indexing methods on the model performance, and our results on
real-world datasets validate the effectiveness of our proposed solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.07230">When Giant Language Brains Just Aren&#x27;t Enough! Domain Pizzazz with Knowledge Sparkle Dust. (arXiv:2305.07230v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh-Tien Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Duy-Hung Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabahi_S/0/1/0/all/0/1">Shahab Sabahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jeff Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hotta_H/0/1/0/all/0/1">Hajime Hotta</a></p>
<p>Large language models (LLMs) have significantly advanced the field of natural
language processing, with GPT models at the forefront. While their remarkable
performance spans a range of tasks, adapting LLMs for real-world business
scenarios still poses challenges warranting further investigation. This paper
presents an empirical analysis aimed at bridging the gap in adapting LLMs to
practical use cases. To do that, we select the question answering (QA) task of
insurance as a case study due to its challenge of reasoning. Based on the task
we design a new model relied on LLMs which are empowered by additional
knowledge extracted from insurance policy rulebooks and DBpedia. The additional
knowledge helps LLMs to understand new concepts of insurance for domain
adaptation. Preliminary results on two QA datasets show that knowledge
enhancement significantly improves the reasoning ability of GPT-3.5 (55.80% and
57.83% in terms of accuracy). The analysis also indicates that existing public
knowledge bases, e.g., DBPedia is beneficial for knowledge enhancement. Our
findings reveal that the inherent complexity of business scenarios often
necessitates the incorporation of domain-specific knowledge and external
resources for effective problem-solving.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18096">Improving Textless Spoken Language Understanding with Discrete Units as Intermediate Target. (arXiv:2305.18096v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guan-Wei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guan-Ting Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shang-Wen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a></p>
<p>Spoken Language Understanding (SLU) is a task that aims to extract semantic
information from spoken utterances. Previous research has made progress in
end-to-end SLU by using paired speech-text data, such as pre-trained Automatic
Speech Recognition (ASR) models or paired text as intermediate targets.
However, acquiring paired transcripts is expensive and impractical for
unwritten languages. On the other hand, Textless SLU extracts semantic
information from speech without utilizing paired transcripts. However, the
absence of intermediate targets and training guidance for textless SLU often
results in suboptimal performance. In this work, inspired by the
content-disentangled discrete units from self-supervised speech models, we
proposed to use discrete units as intermediate guidance to improve textless SLU
performance. Our method surpasses the baseline method on five SLU benchmark
corpora. Additionally, we find that unit guidance facilitates few-shot learning
and enhances the model's ability to handle noise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18185">Syntax and Semantics Meet in the &quot;Middle&quot;: Probing the Syntax-Semantics Interface of LMs Through Agentivity. (arXiv:2305.18185v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tjuatja_L/0/1/0/all/0/1">Lindia Tjuatja</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1">Emmy Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Levin_L/0/1/0/all/0/1">Lori Levin</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a></p>
<p>Recent advances in large language models have prompted researchers to examine
their abilities across a variety of linguistic tasks, but little has been done
to investigate how models handle the interactions in meaning across words and
larger syntactic forms -- i.e. phenomena at the intersection of syntax and
semantics. We present the semantic notion of agentivity as a case study for
probing such interactions. We created a novel evaluation dataset by utilitizing
the unique linguistic properties of a subset of optionally transitive English
verbs. This dataset was used to prompt varying sizes of three model classes to
see if they are sensitive to agentivity at the lexical level, and if they can
appropriately employ these word-level priors given a specific syntactic
context. Overall, GPT-3 text-davinci-003 performs extremely well across all
experiments, outperforming all other models tested by far. In fact, the results
are even better correlated with human judgements than both syntactic and
semantic corpus statistics. This suggests that LMs may potentially serve as
more useful tools for linguistic annotation, theory testing, and discovery than
select corpora for certain tasks. Code is available at
https://github.com/lindiatjuatja/lm_sem
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18404">Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_B/0/1/0/all/0/1">Bhawesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Charlie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1">Gauri Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Palepu_A/0/1/0/all/0/1">Anil Palepu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellamy_D/0/1/0/all/0/1">David Bellamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskar_R/0/1/0/all/0/1">Ramesh Raskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1">Andrew Beam</a></p>
<p>As large language models continue to be widely developed, robust uncertainty
quantification techniques will become crucial for their safe deployment in
high-stakes scenarios. In this work, we explore how conformal prediction can be
used to provide uncertainty quantification in language models for the specific
task of multiple-choice question-answering. We find that the uncertainty
estimates from conformal prediction are tightly correlated with prediction
accuracy. This observation can be useful for downstream applications such as
selective classification and filtering out low-quality predictions. We also
investigate the exchangeability assumption required by conformal prediction to
out-of-subject questions, which may be a more realistic scenario for many
practical applications. Our work contributes towards more trustworthy and
reliable usage of large language models in safety-critical situations, where
robust guarantees of error rate are required.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18703">Large Language Models, Natural Language Processing, Domain Specialization. (arXiv:2305.18703v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1">Chen Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xujiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiaying Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1">Chengyuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Can Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_T/0/1/0/all/0/1">Tanmoy Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tianjiao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Panalkar_A/0/1/0/all/0/1">Amit Panalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanchi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengzhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1">Chris White</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Quanquan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a></p>
<p>Large language models (LLMs) have significantly advanced the field of natural
language processing (NLP), providing a highly useful, task-agnostic foundation
for a wide range of applications. However, directly applying LLMs to solve
sophisticated problems in specific domains meets many hurdles, caused by the
heterogeneity of domain data, the sophistication of domain knowledge, the
uniqueness of domain objectives, and the diversity of the constraints (e.g.,
various social norms, cultural conformity, religious beliefs, and ethical
standards in the domain applications). Domain specification techniques are key
to make large language models disruptive in many applications. Specifically, to
solve these hurdles, there has been a notable increase in research and
practices conducted in recent years on the domain specialization of LLMs. This
emerging field of study, with its substantial potential for impact,
necessitates a comprehensive and systematic review to better summarize and
guide ongoing work in this area. In this article, we present a comprehensive
survey on domain specification techniques for large language models, an
emerging direction critical for large language model applications. First, we
propose a systematic taxonomy that categorizes the LLM domain-specialization
techniques based on the accessibility to LLMs and summarizes the framework for
all the subcategories as well as their relations and differences to each other.
Second, we present an extensive taxonomy of critical application domains that
can benefit dramatically from specialized LLMs, discussing their practical
significance and open challenges. Last, we offer our insights into the current
research status and future trends in this area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01076">Quantization-Aware and Tensor-Compressed Training of Transformers for Natural Language Understanding. (arXiv:2306.01076v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1">Samridhi Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunzmann_S/0/1/0/all/0/1">Siegfried Kunzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a></p>
<p>Fine-tuned transformer models have shown superior performances in many
natural language tasks. However, the large model size prohibits deploying
high-performance transformer models on resource-constrained devices. This paper
proposes a quantization-aware tensor-compressed training approach to reduce the
model size, arithmetic operations, and ultimately runtime latency of
transformer-based models. We compress the embedding and linear layers of
transformers into small low-rank tensor cores, which significantly reduces
model parameters. A quantization-aware training with learnable scale factors is
used to further obtain low-precision representations of the tensor-compressed
models. The developed approach can be used for both end-to-end training and
distillation-based training. To improve the convergence, a layer-by-layer
distillation is applied to distill a quantized and tensor-compressed student
model from a pre-trained transformer. The performance is demonstrated in two
natural language understanding tasks, showing up to $63\times$ compression
ratio, little accuracy loss and remarkable inference and training speedup.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01385">Task-Agnostic Structured Pruning of Speech Representation Models. (arXiv:2306.01385v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Siyuan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Suo_H/0/1/0/all/0/1">Hongbin Suo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wan_Y/0/1/0/all/0/1">Yulong Wan</a></p>
<p>Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have
been shown to significantly improve many speech tasks. However, their large
memory and strong computational requirements hinder their industrial
applicability. Structured pruning is a hardware-friendly model compression
technique but usually results in a larger loss of accuracy. In this paper, we
propose a fine-grained attention head pruning method to compensate for the
performance degradation. In addition, we also introduce the straight through
estimator into the L0 regularization to further accelerate the pruned model.
Experiments on the SUPERB benchmark show that our model can achieve comparable
performance to the dense model in multiple tasks and outperforms the Wav2vec
2.0 base model on average, with 72% fewer parameters and 2 times faster
inference speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01505">Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations. (arXiv:2306.01505v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1">Yinan Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songlin Hu</a></p>
<p>Extracting generalized and robust representations is a major challenge in
emotion recognition in conversations (ERC). To address this, we propose a
supervised adversarial contrastive learning (SACL) framework for learning
class-spread structured representations in a supervised manner. SACL applies
contrast-aware adversarial training to generate worst-case samples and uses
joint class-spread contrastive learning to extract structured representations.
It can effectively utilize label-level feature consistency and retain
fine-grained intra-class features. To avoid the negative impact of adversarial
perturbations on context-dependent data, we design a contextual adversarial
training (CAT) strategy to learn more diverse features from context and enhance
the model's context robustness. Under the framework with CAT, we develop a
sequence-based SACL-LSTM to learn label-consistent and context-robust features
for ERC. Experiments on three datasets show that SACL-LSTM achieves
state-of-the-art performance on ERC. Extended experiments prove the
effectiveness of SACL and CAT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01657">DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation. (arXiv:2306.01657v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bi_G/0/1/0/all/0/1">Guanqun Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Lei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yanan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Meng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuqiang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a></p>
<p>Empathy is a crucial factor in open-domain conversations, which naturally
shows one's caring and understanding to others. Though several methods have
been proposed to generate empathetic responses, existing works often lead to
monotonous empathy that refers to generic and safe expressions. In this paper,
we propose to use explicit control to guide the empathy expression and design a
framework DiffusEmp based on conditional diffusion language model to unify the
utilization of dialogue context and attribute-oriented control signals.
Specifically, communication mechanism, intent, and semantic frame are imported
as multi-grained signals that control the empathy realization from coarse to
fine levels. We then design a specific masking strategy to reflect the
relationship between multi-grained signals and response tokens, and integrate
it into the diffusion model to influence the generative process. Experimental
results on a benchmark dataset EmpatheticDialogue show that our framework
outperforms competitive baselines in terms of controllability, informativeness,
and diversity without the loss of context-relatedness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03734">A Cross-Linguistic Pressure for Uniform Information Density in Word Order. (arXiv:2306.03734v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Clark_T/0/1/0/all/0/1">Thomas Hikaru Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1">Clara Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1">Tiago Pimentel</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_M/0/1/0/all/0/1">Michael Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>, <a href="http://arxiv.org/find/cs/1/au:+Futrell_R/0/1/0/all/0/1">Richard Futrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1">Roger Levy</a></p>
<p>While natural languages differ widely in both canonical word order and word
order flexibility, their word orders still follow shared cross-linguistic
statistical patterns, often attributed to functional pressures. In the effort
to identify these pressures, prior work has compared real and counterfactual
word orders. Yet one functional pressure has been overlooked in such
investigations: the uniform information density (UID) hypothesis, which holds
that information should be spread evenly throughout an utterance. Here, we ask
whether a pressure for UID may have influenced word order patterns
cross-linguistically. To this end, we use computational models to test whether
real orders lead to greater information uniformity than counterfactual orders.
In our empirical study of 10 typologically diverse languages, we find that: (i)
among SVO languages, real word orders consistently have greater uniformity than
reverse word orders, and (ii) only linguistically implausible counterfactual
orders consistently exceed the uniformity of real orders. These findings are
compatible with a pressure for information uniformity in the development and
usage of natural languages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07848">GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yu Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yanni Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuguang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jixun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_W/0/1/0/all/0/1">Wen Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Heng Lu</a></p>
<p>Contrastive learning based pretraining methods have recently exhibited
impressive success in diverse fields. In this paper, we propose GEmo-CLAP, a
kind of efficient gender-attribute-enhanced contrastive language-audio
pretraining (CLAP) model for speech emotion recognition. To be specific, we
first build an effective emotion CLAP model Emo-CLAP for emotion recognition,
utilizing various self-supervised learning based pre-trained models. Then,
considering the importance of the gender attribute in speech emotion modeling,
two GEmo-CLAP approaches are further proposed to integrate the emotion and
gender information of speech signals, forming more reasonable objectives.
Extensive experiments on the IEMOCAP corpus demonstrate that our proposed two
GEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with
different pre-trained models, while also achieving superior recognition
performance compared with other state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09170">Can ChatGPT pass the Vietnamese National High School Graduation Examination?. (arXiv:2306.09170v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dao_X/0/1/0/all/0/1">Xuan-Quy Dao</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngoc-Bich Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_X/0/1/0/all/0/1">Xuan-Dung Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngo_B/0/1/0/all/0/1">Bac-Bien Ngo</a></p>
<p>This research article highlights the potential of AI-powered chatbots in
education and presents the results of using ChatGPT, a large language model, to
complete the Vietnamese National High School Graduation Examination (VNHSGE).
The study dataset included 30 essays in the literature test case and 1,700
multiple-choice questions designed for other subjects. The results showed that
ChatGPT was able to pass the examination with an average score of 6-7,
demonstrating the technology's potential to revolutionize the educational
landscape. The analysis of ChatGPT performance revealed its proficiency in a
range of subjects, including mathematics, English, physics, chemistry, biology,
history, geography, civic education, and literature, which suggests its
potential to provide effective support for learners. However, further research
is needed to assess ChatGPT performance on more complex exam questions and its
potential to support learners in different contexts. As technology continues to
evolve and improve, we can expect to see the use of AI tools like ChatGPT
become increasingly common in educational settings, ultimately enhancing the
educational experience for both students and educators.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11197">Sparse Modular Activation for Efficient Sequence Modeling. (arXiv:2306.11197v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1">Liliang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuohang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yichong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenguang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1">ChengXiang Zhai</a></p>
<p>Linear State Space Models (SSMs) have demonstrated strong performance in a
variety of sequence modeling tasks due to their efficient encoding of the
recurrent structure. However, in more comprehensive tasks like language
modeling and machine translation, self-attention-based models still outperform
SSMs. Hybrid models employing both SSM and self-attention generally show
promising performance, but current approaches apply attention modules
statically and uniformly to all elements in the input sequences, leading to
sub-optimal quality-efficiency trade-offs. In this work, we introduce Sparse
Modular Activation (SMA), a general mechanism enabling neural networks to
sparsely and dynamically activate sub-modules for sequence elements in a
differentiable manner. Through allowing each element to skip non-activated
sub-modules, SMA reduces computation and memory consumption at both training
and inference stages of sequence modeling. As a specific instantiation of SMA,
we design a novel neural architecture, SeqBoat, which employs SMA to sparsely
activate a Gated Attention Unit (GAU) based on the state representations
learned from an SSM. By constraining the GAU to only conduct local attention on
the activated inputs, SeqBoat can achieve linear inference complexity with
theoretically infinite attention span, and provide substantially better
quality-efficiency trade-off than the chunking-based models. With experiments
on a wide range of tasks, including language modeling, speech classification
and long-range arena, SeqBoat brings new state-of-the-art results among hybrid
models with linear complexity and reveals the amount of attention needed for
each task through the learned sparse activation patterns.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15666">Testing of Detection Tools for AI-Generated Text. (arXiv:2306.15666v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weber_Wulff_D/0/1/0/all/0/1">Debora Weber-Wulff</a> (University of Applied Sciences HTW Berlin, Germany), <a href="http://arxiv.org/find/cs/1/au:+Anohina_Naumeca_A/0/1/0/all/0/1">Alla Anohina-Naumeca</a> (Riga Technical University, Latvia), <a href="http://arxiv.org/find/cs/1/au:+Bjelobaba_S/0/1/0/all/0/1">Sonja Bjelobaba</a> (Uppsala University, Sweden), <a href="http://arxiv.org/find/cs/1/au:+Foltynek_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Folt&#xfd;nek</a> (Masaryk University, Czechia), <a href="http://arxiv.org/find/cs/1/au:+Guerrero_Dib_J/0/1/0/all/0/1">Jean Guerrero-Dib</a> (Universidad de Monterrey, Mexico), <a href="http://arxiv.org/find/cs/1/au:+Popoola_O/0/1/0/all/0/1">Olumide Popoola</a> (Queen Mary University of London, UK), <a href="http://arxiv.org/find/cs/1/au:+Sigut_P/0/1/0/all/0/1">Petr &#x160;igut</a> (Masaryk University, Czechia), <a href="http://arxiv.org/find/cs/1/au:+Waddington_L/0/1/0/all/0/1">Lorna Waddington</a> (University of Leeds, UK)</p>
<p>Recent advances in generative pre-trained transformer large language models
have emphasised the potential risks of unfair use of artificial intelligence
(AI) generated content in an academic environment and intensified efforts in
searching for solutions to detect such content. The paper examines the general
functionality of detection tools for artificial intelligence generated text and
evaluates them based on accuracy and error type analysis. Specifically, the
study seeks to answer research questions about whether existing detection tools
can reliably differentiate between human-written text and ChatGPT-generated
text, and whether machine translation and content obfuscation techniques affect
the detection of AI-generated text. The research covers 12 publicly available
tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely
used in the academic setting. The researchers conclude that the available
detection tools are neither accurate nor reliable and have a main bias towards
classifying the output as human-written rather than detecting AI-generated
text. Furthermore, content obfuscation techniques significantly worsen the
performance of tools. The study makes several significant contributions. First,
it summarises up-to-date similar scientific and non-scientific efforts in the
field. Second, it presents the result of one of the most comprehensive tests
conducted so far, based on a rigorous research methodology, an original
document set, and a broad coverage of tools. Third, it discusses the
implications and drawbacks of using detection tools for AI-generated text in
academic settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.17181">Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jun-Min Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_T/0/1/0/all/0/1">Tae-Bin Ha</a></p>
<p>Generative Adversarial Networks (GAN) is a model for data synthesis, which
creates plausible data through the competition of generator and discriminator.
Although GAN application to image synthesis is extensively studied, it has
inherent limitations to natural language generation. Because natural language
is composed of discrete tokens, a generator has difficulty updating its
gradient through backpropagation; therefore, most text-GAN studies generate
sentences starting with a random token based on a reward system. Thus, the
generators of previous studies are pre-trained in an autoregressive way before
adversarial training, causing data memorization that synthesized sentences
reproduce the training data. In this paper, we synthesize sentences using a
framework similar to the original GAN. More specifically, we propose Text
Embedding Space Generative Adversarial Networks (TESGAN) which generate
continuous text embedding spaces instead of discrete tokens to solve the
gradient backpropagation problem. Furthermore, TESGAN conducts unsupervised
learning which does not directly refer to the text of the training data to
overcome the data memorization issue. By adopting this novel method, TESGAN can
synthesize new sentences, showing the potential of unsupervised learning for
text synthesis. We expect to see extended research combining Large Language
Models with a new perspective of viewing text as an continuous space.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.17649">Biomedical Language Models are Robust to Sub-optimal Tokenization. (arXiv:2306.17649v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_B/0/1/0/all/0/1">Bernal Jim&#xe9;nez Guti&#xe9;rrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yu Su</a></p>
<p>As opposed to general English, many concepts in biomedical terminology have
been designed in recent history by biomedical professionals with the goal of
being precise and concise. This is often achieved by concatenating meaningful
biomedical morphemes to create new semantic units. Nevertheless, most modern
biomedical language models (LMs) are pre-trained using standard domain-specific
tokenizers derived from large scale biomedical corpus statistics without
explicitly leveraging the agglutinating nature of biomedical language. In this
work, we first find that standard open-domain and biomedical tokenizers are
largely unable to segment biomedical terms into meaningful components.
Therefore, we hypothesize that using a tokenizer which segments biomedical
terminology more accurately would enable biomedical LMs to improve their
performance on downstream biomedical NLP tasks, especially ones which involve
biomedical terms directly such as named entity recognition (NER) and entity
linking. Surprisingly, we find that pre-training a biomedical LM using a more
accurate biomedical tokenizer does not improve the entity representation
quality of a language model as measured by several intrinsic and extrinsic
measures such as masked language modeling prediction (MLM) accuracy as well as
NER and entity linking performance. These quantitative findings, along with a
case study which explores entity representation quality more directly, suggest
that the biomedical pre-training process is quite robust to instances of
sub-optimal tokenization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01370">Multilingual Language Models are not Multicultural: A Case Study in Emotion. (arXiv:2307.01370v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1">Shreya Havaldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rai_S/0/1/0/all/0/1">Sunny Rai</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_B/0/1/0/all/0/1">Bhumika Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Langchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guntuku_S/0/1/0/all/0/1">Sharath Chandra Guntuku</a>, <a href="http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1">Lyle Ungar</a></p>
<p>Emotions are experienced and expressed differently across the world. In order
to use Large Language Models (LMs) for multilingual tasks that require
emotional sensitivity, LMs must reflect this cultural variation in emotion. In
this study, we investigate whether the widely-used multilingual LMs in 2023
reflect differences in emotional expressions across cultures and languages. We
find that embeddings obtained from LMs (e.g., XLM-RoBERTa) are Anglocentric,
and generative LMs (e.g., ChatGPT) reflect Western norms, even when responding
to prompts in other languages. Our results show that multilingual LMs do not
successfully learn the culturally appropriate nuances of emotion and we
highlight possible research directions towards correcting this.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02863">ValiTex -- a unified validation framework for computational text-based measures of social science constructs. (arXiv:2307.02863v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Birkenmaier_L/0/1/0/all/0/1">Lukas Birkenmaier</a>, <a href="http://arxiv.org/find/cs/1/au:+Lechner_C/0/1/0/all/0/1">Clemens Lechner</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1">Claudia Wagner</a></p>
<p>Guidance on how to validate computational text-based measures of social
science constructs is fragmented. Whereas scholars are generally acknowledging
the importance of validating their text-based measures, they often lack common
terminology and a unified framework to do so. This paper introduces a new
validation framework called ValiTex, designed to assist scholars to measure
social science constructs based on textual data. The framework draws on a
long-established tradition within psychometrics while extending the framework
for the purpose of computational text analysis. ValiTex consists of two
components, a conceptual model, and a dynamic checklist. Whereas the conceptual
model provides a general structure along distinct phases on how to approach
validation, the dynamic checklist defines specific validation steps and
provides guidance on which steps might be considered recommendable (i.e.,
providing relevant and necessary validation evidence) or optional (i.e., useful
for providing additional supporting validation evidence. The utility of the
framework is demonstrated by applying it to a use case of detecting sexism from
social media data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03131">BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training. (arXiv:2307.03131v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yiming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chengqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shujian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiajun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a></p>
<p>Automatic metrics play a crucial role in machine translation. Despite the
widespread use of n-gram-based metrics, there has been a recent surge in the
development of pre-trained model-based metrics that focus on measuring sentence
semantics. However, these neural metrics, while achieving higher correlations
with human evaluations, are often considered to be black boxes with potential
biases that are difficult to detect. In this study, we systematically analyze
and compare various mainstream and cutting-edge automatic metrics from the
perspective of their guidance for training machine translation systems. Through
Minimum Risk Training (MRT), we find that certain metrics exhibit robustness
defects, such as the presence of universal adversarial translations in BLEURT
and BARTScore. In-depth analysis suggests two main causes of these robustness
deficits: distribution biases in the training datasets, and the tendency of the
metric paradigm. By incorporating token-level constraints, we enhance the
robustness of evaluation metrics, which in turn leads to an improvement in the
performance of machine translation systems. Codes are available at
\url{https://github.com/powerpuffpomelo/fairseq_mrt}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03667">Testing the Predictions of Surprisal Theory in 11 Languages. (arXiv:2307.03667v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wilcox_E/0/1/0/all/0/1">Ethan Gotlieb Wilcox</a>, <a href="http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1">Tiago Pimentel</a>, <a href="http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1">Clara Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1">Roger P. Levy</a></p>
<p>A fundamental result in psycholinguistics is that less predictable words take
a longer time to process. One theoretical explanation for this finding is
Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's
predictability as its surprisal, i.e. its negative log-probability given a
context. While evidence supporting the predictions of Surprisal Theory have
been replicated widely, most have focused on a very narrow slice of data:
native English speakers reading English texts. Indeed, no comprehensive
multilingual analysis exists. We address this gap in the current literature by
investigating the relationship between surprisal and reading times in eleven
different languages, distributed across five language families. Deriving
estimates from language models trained on monolingual and multilingual corpora,
we test three predictions associated with surprisal theory: (i) whether
surprisal is predictive of reading times; (ii) whether expected surprisal, i.e.
contextual entropy, is predictive of reading times; (iii) and whether the
linking function between surprisal and reading times is linear. We find that
all three predictions are borne out crosslinguistically. By focusing on a more
diverse set of languages, we argue that these results offer the most robust
link to-date between information theory and incremental language processing
across languages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00457">GenRec: Large Language Model for Generative Recommendation. (arXiv:2307.00457v2 [cs.IR] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jianchao Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zelong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wenyue Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yingqiang Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Juntao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a></p>
<p>In recent years, large language models (LLM) have emerged as powerful tools
for diverse natural language processing tasks. However, their potential for
recommender systems under the generative recommendation paradigm remains
relatively unexplored. This paper presents an innovative approach to
recommendation systems using large language models (LLMs) based on text data.
In this paper, we present a novel LLM for generative recommendation (GenRec)
that utilized the expressive power of LLM to directly generate the target item
to recommend, rather than calculating ranking score for each candidate item one
by one as in traditional discriminative recommendation. GenRec uses LLM's
understanding ability to interpret context, learn user preferences, and
generate relevant recommendation. Our proposed approach leverages the vast
knowledge encoded in large language models to accomplish recommendation tasks.
We first we formulate specialized prompts to enhance the ability of LLM to
comprehend recommendation tasks. Subsequently, we use these prompts to
fine-tune the LLaMA backbone LLM on a dataset of user-item interactions,
represented by textual data, to capture user preferences and item
characteristics. Our research underscores the potential of LLM-based generative
recommendation in revolutionizing the domain of recommendation systems and
offers a foundational framework for future explorations in this field. We
conduct extensive experiments on benchmark datasets, and the experiments shows
that our GenRec has significant better results on large dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01226">vONTSS: vMF based semi-supervised neural topic modeling with optimal transport. (arXiv:2307.01226v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weijie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoyu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengamedu_S/0/1/0/all/0/1">Srinivasan H. Sengamedu</a>, <a href="http://arxiv.org/find/cs/1/au:+Iannacci_F/0/1/0/all/0/1">Francis Iannacci</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jinjin Zhao</a></p>
<p>Recently, Neural Topic Models (NTM), inspired by variational autoencoders,
have attracted a lot of research interest; however, these methods have limited
applications in the real world due to the challenge of incorporating human
knowledge. This work presents a semi-supervised neural topic modeling method,
vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and
optimal transport. When a few keywords per topic are provided, vONTSS in the
semi-supervised setting generates potential topics and optimizes topic-keyword
quality and topic classification. Experiments show that vONTSS outperforms
existing semi-supervised topic modeling methods in classification accuracy and
diversity. vONTSS also supports unsupervised topic modeling. Quantitative and
qualitative experiments show that vONTSS in the unsupervised setting
outperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered
and coherent topics on benchmark datasets. It is also much faster than the
state-of-the-art weakly supervised text classification method while achieving
similar classification performance. We further prove the equivalence of optimal
transport loss and cross-entropy loss at the global minimum.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03056">Generalizing Backpropagation for Gradient-Based Interpretability. (arXiv:2307.03056v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Du_K/0/1/0/all/0/1">Kevin Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennigen_L/0/1/0/all/0/1">Lucas Torroba Hennigen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoehr_N/0/1/0/all/0/1">Niklas Stoehr</a>, <a href="http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1">Alexander Warstadt</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a></p>
<p>Many popular feature-attribution methods for interpreting deep neural
networks rely on computing the gradients of a model's output with respect to
its inputs. While these methods can indicate which input features may be
important for the model's prediction, they reveal little about the inner
workings of the model itself. In this paper, we observe that the gradient
computation of a model is a special case of a more general formulation using
semirings. This observation allows us to generalize the backpropagation
algorithm to efficiently compute other interpretable statistics about the
gradient graph of a neural network, such as the highest-weighted path and
entropy. We implement this generalized algorithm, evaluate it on synthetic
datasets to better understand the statistics it computes, and apply it to study
BERT's behavior on the subject-verb number agreement task (SVA). With this
method, we (a) validate that the amount of gradient flow through a component of
a model reflects its importance to a prediction and (b) for SVA, identify which
pathways of the self-attention mechanism are most important.
</p>
</p>
</div>

    </div>
    </body>
    