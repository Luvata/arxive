<!DOCTYPE html>
<html>
<head>
<title>2024-01-03-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.00003">Generative Inverse Design of Metamaterials with Functional Responses by Interpretable Learning. (arXiv:2401.00003v1 [physics.optics])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Chen_W/0/1/0/all/0/1">Wei &quot;Wayne&quot; Chen</a>, <a href="http://arxiv.org/find/physics/1/au:+Sun_R/0/1/0/all/0/1">Rachel Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Lee_D/0/1/0/all/0/1">Doksoo Lee</a>, <a href="http://arxiv.org/find/physics/1/au:+Portela_C/0/1/0/all/0/1">Carlos M. Portela</a>, <a href="http://arxiv.org/find/physics/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a></p>
<p>Metamaterials with functional responses, such as wave-based responses or
deformation-induced property variation under external stimuli, can exhibit
varying properties or functionalities under different conditions. Herein, we
aim at rapid inverse design of these metamaterials to meet target qualitative
functional behaviors. This inverse problem is challenging due to its
intractability and the existence of non-unique solutions. Past works mainly
focus on deep-learning-based methods that are data-demanding, require
time-consuming training and hyperparameter tuning, and are non-interpretable.
To overcome these limitations, we propose the Random-forest-based Interpretable
Generative Inverse Design (RIGID), a single-shot inverse design method to
achieve the fast generation of metamaterial designs with on-demand functional
behaviors. Unlike most existing methods, by exploiting the interpretability of
the random forest, we eliminate the need to train an inverse model mapping
responses to designs. Based on the likelihood of target satisfaction derived
from the trained forward model, one can sample design solutions using Markov
chain Monte Carlo methods. The RIGID method therefore functions as a generative
model that captures the conditional distribution of satisfying solutions given
a design target. We demonstrate the effectiveness and efficiency of RIGID on
both acoustic and optical metamaterial design problems where only small
datasets (less than 250 training samples) are available. Synthetic design
problems are created to further illustrate and validate the mechanism of
likelihood estimation in RIGID. This work offers a new perspective on solving
on-demand inverse design problems, showcasing the potential for incorporating
interpretable machine learning into generative design and eliminating its large
data requirement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00010">Professional Network Matters: Connections Empower Person-Job Fit. (arXiv:2401.00010v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Lun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yuxuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Qiang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yanbin Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Guangming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zi Li</a></p>
<p>Online recruitment platforms typically employ Person-Job Fit models in the
core service that automatically match suitable job seekers with appropriate job
positions. While existing works leverage historical or contextual information,
they often disregard a crucial aspect: job seekers' social relationships in
professional networks. This paper emphasizes the importance of incorporating
professional networks into the Person-Job Fit model. Our innovative approach
consists of two stages: (1) defining a Workplace Heterogeneous Information
Network (WHIN) to capture heterogeneous knowledge, including professional
connections and pre-training representations of various entities using a
heterogeneous graph neural network; (2) designing a Contextual Social Attention
Graph Neural Network (CSAGNN) that supplements users' missing information with
professional connections' contextual information. We introduce a job-specific
attention mechanism in CSAGNN to handle noisy professional networks, leveraging
pre-trained entity representations from WHIN. We demonstrate the effectiveness
of our approach through experimental evaluations conducted across three
real-world recruitment datasets from LinkedIn, showing superior performance
compared to baseline models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00011">Learning of networked spreading models from noisy and incomplete data. (arXiv:2401.00011v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wilinski_M/0/1/0/all/0/1">Mateusz Wilinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lokhov_A/0/1/0/all/0/1">Andrey Y. Lokhov</a></p>
<p>Recent years have seen a lot of progress in algorithms for learning
parameters of spreading dynamics from both full and partial data. Some of the
remaining challenges include model selection under the scenarios of unknown
network structure, noisy data, missing observations in time, as well as an
efficient incorporation of prior information to minimize the number of samples
required for an accurate learning. Here, we introduce a universal learning
method based on scalable dynamic message-passing technique that addresses these
challenges often encountered in real data. The algorithm leverages available
prior knowledge on the model and on the data, and reconstructs both network
structure and parameters of a spreading model. We show that a linear
computational complexity of the method with the key model parameters makes the
algorithm scalable to large network instances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00013">HITSnDIFFs: From Truth Discovery to Ability Discovery by Recovering Matrices with the Consecutive Ones Property. (arXiv:2401.00013v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zixuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_S/0/1/0/all/0/1">Subhodeep Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_R/0/1/0/all/0/1">R Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatterbauer_W/0/1/0/all/0/1">Wolfgang Gatterbauer</a></p>
<p>We analyze a general problem in a crowd-sourced setting where one user asks a
question (also called item) and other users return answers (also called labels)
for this question. Different from existing crowd sourcing work which focuses on
finding the most appropriate label for the question (the "truth"), our problem
is to determine a ranking of the users based on their ability to answer
questions. We call this problem "ability discovery" to emphasize the connection
to and duality with the more well-studied problem of "truth discovery".
</p>
<p>To model items and their labels in a principled way, we draw upon Item
Response Theory (IRT) which is the widely accepted theory behind standardized
tests such as SAT and GRE. We start from an idealized setting where the
relative performance of users is consistent across items and better users
choose better fitting labels for each item. We posit that a principled
algorithmic solution to our more general problem should solve this ideal
setting correctly and observe that the response matrices in this setting obey
the Consecutive Ones Property (C1P). While C1P is well understood
algorithmically with various discrete algorithms, we devise a novel variant of
the HITS algorithm which we call "HITSNDIFFS" (or HND), and prove that it can
recover the ideal C1P-permutation in case it exists. Unlike fast combinatorial
algorithms for finding the consecutive ones permutation (if it exists), HND
also returns an ordering when such a permutation does not exist. Thus it
provides a principled heuristic for our problem that is guaranteed to return
the correct answer in the ideal setting. Our experiments show that HND produces
user rankings with robustly high accuracy compared to state-of-the-art truth
discovery methods. We also show that our novel variant of HITS scales better in
the number of users than ABH, the only prior spectral C1P reconstruction
algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00014">Resource-Limited Automated Ki67 Index Estimation in Breast Cancer. (arXiv:2401.00014v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Gliozzo_J/0/1/0/all/0/1">J. Gliozzo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marino_G/0/1/0/all/0/1">G. Marin&#xf2;</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bonometti_A/0/1/0/all/0/1">A. Bonometti</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Frasca_M/0/1/0/all/0/1">M. Frasca</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Malchiodi_D/0/1/0/all/0/1">D. Malchiodi</a></p>
<p>The prediction of tumor progression and chemotherapy response has been
recently tackled exploiting Tumor Infiltrating Lymphocytes (TILs) and the
nuclear protein Ki67 as prognostic factors. Recently, deep neural networks
(DNNs) have been shown to achieve top results in estimating Ki67 expression and
simultaneous determination of intratumoral TILs score in breast cancer cells.
However, in the last ten years the extraordinary progress induced by deep
models proliferated at least as much as their resource demand. The exorbitant
computational costs required to query (and in some cases also to store) a deep
model represent a strong limitation in resource-limited contexts, like that of
IoT-based applications to support healthcare personnel. To this end, we propose
a resource consumption-aware DNN for the effective estimate of the percentage
of Ki67-positive cells in breast cancer screenings. Our approach reduced up to
75% and 89% the usage of memory and disk space respectively, up to 1.5x the
energy consumption, and preserved or improved the overall accuracy of a
benchmark state-of-the-art solution. Encouraged by such positive results, we
developed and structured the adopted framework so as to allow its general
purpose usage, along with a public software repository to support its usage.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00015">Distributional Reinforcement Learning-based Energy Arbitrage Strategies in Imbalance Settlement Mechanism. (arXiv:2401.00015v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madahi_S/0/1/0/all/0/1">Seyed Soroush Karimi Madahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Claessens_B/0/1/0/all/0/1">Bert Claessens</a>, <a href="http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1">Chris Develder</a></p>
<p>Growth in the penetration of renewable energy sources makes supply more
uncertain and leads to an increase in the system imbalance. This trend,
together with the single imbalance pricing, opens an opportunity for balance
responsible parties (BRPs) to perform energy arbitrage in the imbalance
settlement mechanism. To this end, we propose a battery control framework based
on distributional reinforcement learning (DRL). Our proposed control framework
takes a risk-sensitive perspective, allowing BRPs to adjust their risk
preferences: we aim to optimize a weighted sum of the arbitrage profit and a
risk measure while constraining the daily number of cycles for the battery. We
assess the performance of our proposed control framework using the Belgian
imbalance prices of 2022 and compare two state-of-the-art RL methods, deep Q
learning and soft actor-critic. Results reveal that the distributional soft
actor-critic method can outperform other methods. Moreover, we note that our
fully risk-averse agent appropriately learns to hedge against the risk related
to the unknown imbalance price by (dis)charging the battery only when the agent
is more certain about the price.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00023">CycleGAN Models for MRI Image Translation. (arXiv:2401.00023v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Czobit_C/0/1/0/all/0/1">Cassandra Czobit</a>, <a href="http://arxiv.org/find/eess/1/au:+Samavi_R/0/1/0/all/0/1">Reza Samavi</a></p>
<p>Image-to-image translation has gained popularity in the medical field to
transform images from one domain to another. Medical image synthesis via domain
transformation is advantageous in its ability to augment an image dataset where
images for a given class is limited. From the learning perspective, this
process contributes to data-oriented robustness of the model by inherently
broadening the model's exposure to more diverse visual data and enabling it to
learn more generalized features. In the case of generating additional
neuroimages, it is advantageous to obtain unidentifiable medical data and
augment smaller annotated datasets. This study proposes the development of a
CycleGAN model for translating neuroimages from one field strength to another
(e.g., 3 Tesla to 1.5). This model was compared to a model based on DCGAN
architecture. CycleGAN was able to generate the synthetic and reconstructed
images with reasonable accuracy. The mapping function from the source (3 Tesla)
to target domain (1.5 Tesla) performed optimally with an average PSNR value of
25.69 $\pm$ 2.49 dB and an MAE value of 2106.27 +/- 1218.37.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00031">Self-supervised Pretraining for Decision Foundation Model: Formulation, Pipeline and Challenges. (arXiv:2401.00031v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoqian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1">Jianbin Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junge Zhang</a></p>
<p>Decision-making is a dynamic process requiring perception, memory, and
reasoning to make choices and find optimal policies. Traditional approaches to
decision-making suffer from sample efficiency and generalization, while
large-scale self-supervised pretraining has enabled fast adaptation with
fine-tuning or few-shot learning in language and vision. We thus argue to
integrate knowledge acquired from generic large-scale self-supervised
pretraining into downstream decision-making problems. We propose
Pretrain-Then-Adapt pipeline and survey recent work on data collection,
pretraining objectives and adaptation strategies for decision-making
pretraining and downstream inference. Finally, we identify critical challenges
and future directions for developing decision foundation model with the help of
generic and flexible self-supervised pretraining.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00033">Hybrid Modeling Design Patterns. (arXiv:2401.00033v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1">Maja Rudolph</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurz_S/0/1/0/all/0/1">Stefan Kurz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rakitsch_B/0/1/0/all/0/1">Barbara Rakitsch</a></p>
<p>Design patterns provide a systematic way to convey solutions to recurring
modeling challenges. This paper introduces design patterns for hybrid modeling,
an approach that combines modeling based on first principles with data-driven
modeling techniques. While both approaches have complementary advantages there
are often multiple ways to combine them into a hybrid model, and the
appropriate solution will depend on the problem at hand. In this paper, we
provide four base patterns that can serve as blueprints for combining
data-driven components with domain knowledge into a hybrid approach. In
addition, we also present two composition patterns that govern the combination
of the base patterns into more complex hybrid models. Each design pattern is
illustrated by typical use cases from application areas such as climate
modeling, engineering, and physics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00035">Learning About Structural Errors in Models of Complex Dynamical Systems. (arXiv:2401.00035v1 [physics.comp-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1">Jin-Long Wu</a>, <a href="http://arxiv.org/find/physics/1/au:+Levine_M/0/1/0/all/0/1">Matthew E. Levine</a>, <a href="http://arxiv.org/find/physics/1/au:+Schneider_T/0/1/0/all/0/1">Tapio Schneider</a>, <a href="http://arxiv.org/find/physics/1/au:+Stuart_A/0/1/0/all/0/1">Andrew Stuart</a></p>
<p>Complex dynamical systems are notoriously difficult to model because some
degrees of freedom (e.g., small scales) may be computationally unresolvable or
are incompletely understood, yet they are dynamically important. For example,
the small scales of cloud dynamics and droplet formation are crucial for
controlling climate, yet are unresolvable in global climate models.
Semi-empirical closure models for the effects of unresolved degrees of freedom
often exist and encode important domain-specific knowledge. Building on such
closure models and correcting them through learning the structural errors can
be an effective way of fusing data with domain knowledge. Here we describe a
general approach, principles, and algorithms for learning about structural
errors. Key to our approach is to include structural error models inside the
models of complex systems, for example, in closure models for unresolved
scales. The structural errors then map, usually nonlinearly, to observable
data. As a result, however, mismatches between model output and data are only
indirectly informative about structural errors, due to a lack of labeled pairs
of inputs and outputs of structural error models. Additionally, derivatives of
the model may not exist or be readily available. We discuss how structural
error models can be learned from indirect data with derivative-free Kalman
inversion algorithms and variants, how sparsity constraints enforce a "do no
harm" principle, and various ways of modeling structural errors. We also
discuss the merits of using non-local and/or stochastic error models. In
addition, we demonstrate how data assimilation techniques can assist the
learning about structural errors in non-ergodic systems. The concepts and
algorithms are illustrated in two numerical examples based on the Lorenz-96
system and a human glucose-insulin model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00036">Discrete Distribution Networks. (arXiv:2401.00036v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a></p>
<p>We introduce a novel generative model, the Discrete Distribution Networks
(DDN), that approximates data distribution using hierarchical discrete
distributions. We posit that since the features within a network inherently
contain distributional information, liberating the network from a single output
to concurrently generate multiple samples proves to be highly effective.
Therefore, DDN fits the target distribution, including continuous ones, by
generating multiple discrete sample points. To capture finer details of the
target data, DDN selects the output that is closest to the Ground Truth (GT)
from the coarse results generated in the first layer. This selected output is
then fed back into the network as a condition for the second layer, thereby
generating new outputs more similar to the GT. As the number of DDN layers
increases, the representational space of the outputs expands exponentially, and
the generated samples become increasingly similar to the GT. This hierarchical
output pattern of discrete distributions endows DDN with two intriguing
properties: highly compressed representation and more general zero-shot
conditional generation. We demonstrate the efficacy of DDN and these intriguing
properties through experiments on CIFAR-10 and FFHQ.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00037">Messenger and Non-Coding RNA Design via Expected Partition Function and Continuous Optimization. (arXiv:2401.00037v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Dai_N/0/1/0/all/0/1">Ning Dai</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tang_W/0/1/0/all/0/1">Wei Yu Tang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhou_T/0/1/0/all/0/1">Tianshuo Zhou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mathews_D/0/1/0/all/0/1">David H. Mathews</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_L/0/1/0/all/0/1">Liang Huang</a></p>
<p>The tasks of designing messenger RNAs and non-coding RNAs are discrete
optimization problems, and several versions of these problems are NP-hard. As
an alternative to commonly used local search methods, we formulate these
problems as continuous optimization and develop a general framework for this
optimization based on a new concept of "expected partition function". The basic
idea is to start with a distribution over all possible candidate sequences, and
extend the objective function from a sequence to a distribution. We then use
gradient descent-based optimization methods to improve the extended objective
function, and the distribution will gradually shrink towards a one-hot sequence
(i.e., a single sequence). We consider two important case studies within this
framework, the mRNA design problem optimizing for partition function (i.e.,
ensemble free energy) and the non-coding RNA design problem optimizing for
conditional (i.e., Boltzmann) probability. In both cases, our approach
demonstrate promising preliminary results. We make our code available at
https://github.com/KuNyaa/RNA_Design_codebase.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00055">Online Algorithmic Recourse by Collective Action. (arXiv:2401.00055v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1">Elliot Creager</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a></p>
<p>Research on algorithmic recourse typically considers how an individual can
reasonably change an unfavorable automated decision when interacting with a
fixed decision-making system. This paper focuses instead on the online setting,
where system parameters are updated dynamically according to interactions with
data subjects. Beyond the typical individual-level recourse, the online setting
opens up new ways for groups to shape system decisions by leveraging the
parameter update rule. We show empirically that recourse can be improved when
users coordinate by jointly computing their feature perturbations, underscoring
the importance of collective action in mitigating adverse automated decisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00057">Generalization properties of contrastive world models. (arXiv:2401.00057v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_K/0/1/0/all/0/1">Kandan Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotton_R/0/1/0/all/0/1">R. James Cotton</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitkow_X/0/1/0/all/0/1">Xaq Pitkow</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolias_A/0/1/0/all/0/1">Andreas S. Tolias</a></p>
<p>Recent work on object-centric world models aim to factorize representations
in terms of objects in a completely unsupervised or self-supervised manner.
Such world models are hypothesized to be a key component to address the
generalization problem. While self-supervision has shown improved performance
however, OOD generalization has not been systematically and explicitly tested.
In this paper, we conduct an extensive study on the generalization properties
of contrastive world model. We systematically test the model under a number of
different OOD generalization scenarios such as extrapolation to new object
attributes, introducing new conjunctions or new attributes. Our experiments
show that the contrastive world model fails to generalize under the different
OOD tests and the drop in performance depends on the extent to which the
samples are OOD. When visualizing the transition updates and convolutional
feature maps, we observe that any changes in object attributes (such as
previously unseen colors, shapes, or conjunctions of color and shape) breaks
down the factorization of object representations. Overall, our work highlights
the importance of object-centric representations for generalization and current
models are limited in their capacity to learn such representations required for
human-level generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00065">Accelerating Process Development for 3D Printing of New Metal Alloys. (arXiv:2401.00065v1 [cond-mat.mtrl-sci])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Guirguis_D/0/1/0/all/0/1">David Guirguis</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Tucker_C/0/1/0/all/0/1">Conrad Tucker</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Beuth_J/0/1/0/all/0/1">Jack Beuth</a></p>
<p>Addressing the uncertainty and variability in the quality of 3D printed
metals can further the wide spread use of this technology. Process mapping for
new alloys is crucial for determining optimal process parameters that
consistently produce acceptable printing quality. Process mapping is typically
performed by conventional methods and is used for the design of experiments and
ex situ characterization of printed parts. On the other hand, in situ
approaches are limited because their observable features are limited and they
require complex high-cost setups to obtain temperature measurements to boost
accuracy. Our method relaxes these limitations by incorporating the temporal
features of molten metal dynamics during laser-metal interactions using video
vision transformers and high-speed imaging. Our approach can be used in
existing commercial machines and can provide in situ process maps for efficient
defect and variability quantification. The generalizability of the approach is
demonstrated by performing cross-dataset evaluations on alloys with different
compositions and intrinsic thermofluid properties.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00072">Machine-learned models for magnetic materials. (arXiv:2401.00072v1 [cond-mat.mtrl-sci])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Leszczynski_P/0/1/0/all/0/1">Pawe&#x142; Leszczy&#x144;ski</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kutorasinski_K/0/1/0/all/0/1">Kamil Kutorasi&#x144;ski</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Szewczyk_M/0/1/0/all/0/1">Marcin Szewczyk</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Pawlowski_J/0/1/0/all/0/1">Jaros&#x142;aw Paw&#x142;owski</a></p>
<p>We present a general framework for modeling materials using deep neural
networks. Material represented by multidimensional characteristics (that mimic
measurements) is used to train the neural autoencoder model in an unsupervised
manner. The encoder is trying to predict the material parameters of a
theoretical model, which is then used in a decoder part. The decoder, using the
predicted parameters, reconstructs the input characteristics. The neural model
is trained to capture a synthetically generated set of characteristics that can
cover a broad range of material behaviors, leading to a model that can
generalize on the underlying physics rather than just optimize the model
parameters for a single measurement. After setting up the model we prove its
usefulness in the complex problem of modeling magnetic materials in the
frequency and current (out-of-linear range) domains simultaneously.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00073">Nonasymptotic Regret Analysis of Adaptive Linear Quadratic Control with Model Misspecification. (arXiv:2401.00073v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Lee_B/0/1/0/all/0/1">Bruce D. Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Rantzer_A/0/1/0/all/0/1">Anders Rantzer</a>, <a href="http://arxiv.org/find/eess/1/au:+Matni_N/0/1/0/all/0/1">Nikolai Matni</a></p>
<p>The strategy of pre-training a large model on a diverse dataset, then
fine-tuning for a particular application has yielded impressive results in
computer vision, natural language processing, and robotic control. This
strategy has vast potential in adaptive control, where it is necessary to
rapidly adapt to changing conditions with limited data. Toward concretely
understanding the benefit of pre-training for adaptive control, we study the
adaptive linear quadratic control problem in the setting where the learner has
prior knowledge of a collection of basis matrices for the dynamics. This basis
is misspecified in the sense that it cannot perfectly represent the dynamics of
the underlying data generating process. We propose an algorithm that uses this
prior knowledge, and prove upper bounds on the expected regret after $T$
interactions with the system. In the regime where $T$ is small, the upper
bounds are dominated by a term scales with either $\texttt{poly}(\log T)$ or
$\sqrt{T}$, depending on the prior knowledge available to the learner. When $T$
is large, the regret is dominated by a term that grows with $\delta T$, where
$\delta$ quantifies the level of misspecification. This linear term arises due
to the inability to perfectly estimate the underlying dynamics using the
misspecified basis, and is therefore unavoidable unless the basis matrices are
also adapted online. However, it only dominates for large $T$, after the
sublinear terms arising due to the error in estimating the weights for the
basis matrices become negligible. We provide simulations that validate our
analysis. Our simulations also show that offline data from a collection of
related systems can be used as part of a pre-training stage to estimate a
misspecified dynamics basis, which is in turn used by our adaptive controller.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00081">Synthetic Data Applications in Finance. (arXiv:2401.00081v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Potluru_V/0/1/0/all/0/1">Vamsi K. Potluru</a>, <a href="http://arxiv.org/find/cs/1/au:+Borrajo_D/0/1/0/all/0/1">Daniel Borrajo</a>, <a href="http://arxiv.org/find/cs/1/au:+Coletta_A/0/1/0/all/0/1">Andrea Coletta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalmasso_N/0/1/0/all/0/1">Niccol&#xf2; Dalmasso</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Laham_Y/0/1/0/all/0/1">Yousef El-Laham</a>, <a href="http://arxiv.org/find/cs/1/au:+Fons_E/0/1/0/all/0/1">Elizabeth Fons</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1">Mohsen Ghassemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1">Sriram Gopalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gosai_V/0/1/0/all/0/1">Vikesh Gosai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreacic_E/0/1/0/all/0/1">Eleonora Krea&#x10d;i&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Mani_G/0/1/0/all/0/1">Ganapathy Mani</a>, <a href="http://arxiv.org/find/cs/1/au:+Obitayo_S/0/1/0/all/0/1">Saheed Obitayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Paramanand_D/0/1/0/all/0/1">Deepak Paramanand</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_N/0/1/0/all/0/1">Natraj Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Solonin_M/0/1/0/all/0/1">Mikhail Solonin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_S/0/1/0/all/0/1">Srijan Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Vyetrenko_S/0/1/0/all/0/1">Svitlana Vyetrenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Haibei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1">Manuela Veloso</a>, <a href="http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1">Tucker Balch</a></p>
<p>Synthetic data has made tremendous strides in various commercial settings
including finance, healthcare, and virtual reality. We present a broad overview
of prototypical applications of synthetic data in the financial sector and in
particular provide richer details for a few select ones. These cover a wide
variety of data modalities including tabular, time-series, event-series, and
unstructured arising from both markets and retail financial applications. Since
finance is a highly regulated industry, synthetic data is a potential approach
for dealing with issues related to privacy, fairness, and explainability.
Various metrics are utilized in evaluating the quality and effectiveness of our
approaches in these applications. We conclude with open directions in synthetic
data in the context of the financial domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00086">Quantifying Policy Administration Cost in an Active Learning Framework. (arXiv:2401.00086v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Si Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fong_P/0/1/0/all/0/1">Philip W. L. Fong</a></p>
<p>This paper proposes a computational model for policy administration. As an
organization evolves, new users and resources are gradually placed under the
mediation of the access control model. Each time such new entities are added,
the policy administrator must deliberate on how the access control policy shall
be revised to reflect the new reality. A well-designed access control model
must anticipate such changes so that the administration cost does not become
prohibitive when the organization scales up. Unfortunately, past Access Control
research does not offer a formal way to quantify the cost of policy
administration. In this work, we propose to model ongoing policy administration
in an active learning framework. Administration cost can be quantified in terms
of query complexity. We demonstrate the utility of this approach by applying it
to the evolution of protection domains. We also modelled different policy
administration strategies in our framework. This allowed us to formally
demonstrate that domain-based policies have a cost advantage over access
control matrices because of the use of heuristic reasoning when the policy
evolves. To the best of our knowledge, this is the first work to employ an
active learning framework to study the cost of policy deliberation and
demonstrate the cost advantage of heuristic policy administration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00093">Fairness-Enhancing Vehicle Rebalancing in the Ride-hailing System. (arXiv:2401.00093v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaotong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hanyong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_D/0/1/0/all/0/1">Dingyi Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yunhan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jinhua Zhao</a></p>
<p>The rapid growth of the ride-hailing industry has revolutionized urban
transportation worldwide. Despite its benefits, equity concerns arise as
underserved communities face limited accessibility to affordable ride-hailing
services. A key issue in this context is the vehicle rebalancing problem, where
idle vehicles are moved to areas with anticipated demand. Without equitable
approaches in demand forecasting and rebalancing strategies, these practices
can further deepen existing inequities. In the realm of ride-hailing, three
main facets of fairness are recognized: algorithmic fairness, fairness to
drivers, and fairness to riders. This paper focuses on enhancing both
algorithmic and rider fairness through a novel vehicle rebalancing method. We
introduce an approach that combines a Socio-Aware Spatial-Temporal Graph
Convolutional Network (SA-STGCN) for refined demand prediction and a
fairness-integrated Matching-Integrated Vehicle Rebalancing (MIVR) model for
subsequent vehicle rebalancing. Our methodology is designed to reduce
prediction discrepancies and ensure equitable service provision across diverse
regions. The effectiveness of our system is evaluated using simulations based
on real-world ride-hailing data. The results suggest that our proposed method
enhances both accuracy and fairness in forecasting ride-hailing demand,
ultimately resulting in more equitable vehicle rebalancing in subsequent
operations. Specifically, the algorithm developed in this study effectively
reduces the standard deviation and average customer wait times by 6.48% and
0.49%, respectively. This achievement signifies a beneficial outcome for
ride-hailing platforms, striking a balance between operational efficiency and
fairness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00104">Causal State Distillation for Explainable Reinforcement Learning. (arXiv:2401.00104v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wenhao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xufeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fryen_T/0/1/0/all/0/1">Thilo Fryen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae Hee Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mengdi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Magg_S/0/1/0/all/0/1">Sven Magg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1">Stefan Wermter</a></p>
<p>Reinforcement learning (RL) is a powerful technique for training intelligent
agents, but understanding why these agents make specific decisions can be quite
challenging. This lack of transparency in RL models has been a long-standing
problem, making it difficult for users to grasp the reasons behind an agent's
behaviour. Various approaches have been explored to address this problem, with
one promising avenue being reward decomposition (RD). RD is appealing as it
sidesteps some of the concerns associated with other methods that attempt to
rationalize an agent's behaviour in a post-hoc manner. RD works by exposing
various facets of the rewards that contribute to the agent's objectives during
training. However, RD alone has limitations as it primarily offers insights
based on sub-rewards and does not delve into the intricate cause-and-effect
relationships that occur within an RL agent's neural model. In this paper, we
present an extension of RD that goes beyond sub-rewards to provide more
informative explanations. Our approach is centred on a causal learning
framework that leverages information-theoretic measures for explanation
objectives that encourage three crucial properties of causal factors:
\emph{causal sufficiency}, \emph{sparseness}, and \emph{orthogonality}. These
properties help us distill the cause-and-effect relationships between the
agent's states and actions or rewards, allowing for a deeper understanding of
its decision-making processes. Our framework is designed to generate local
explanations and can be applied to a wide range of RL tasks with multiple
reward channels. Through a series of experiments, we demonstrate that our
approach offers more meaningful and insightful explanations for the agent's
action selections.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00110">Diffusion Model with Perceptual Loss. (arXiv:2401.00110v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shanchuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a></p>
<p>Diffusion models trained with mean squared error loss tend to generate
unrealistic samples. Current state-of-the-art models rely on classifier-free
guidance to improve sample quality, yet its surprising effectiveness is not
fully understood. In this paper, We show that the effectiveness of
classifier-free guidance partly originates from it being a form of implicit
perceptual guidance. As a result, we can directly incorporate perceptual loss
in diffusion training to improve sample quality. Since the score matching
objective used in diffusion training strongly resembles the denoising
autoencoder objective used in unsupervised training of perceptual networks, the
diffusion model itself is a perceptual network and can be used to generate
meaningful perceptual loss. We propose a novel self-perceptual objective that
results in diffusion models capable of generating more realistic samples. For
conditional generation, our method only improves sample quality without
entanglement with the conditional input and therefore does not sacrifice sample
diversity. Our method can also improve sample quality for unconditional
generation, which was not possible with classifier-free guidance before.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00112">Enabling Smart Retrofitting and Performance Anomaly Detection for a Sensorized Vessel: A Maritime Industry Experience. (arXiv:2401.00112v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moghadam_M/0/1/0/all/0/1">Mahshid Helali Moghadam</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzymowski_M/0/1/0/all/0/1">Mateusz Rzymowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulas_L/0/1/0/all/0/1">Lukasz Kulas</a></p>
<p>The integration of sensorized vessels, enabling real-time data collection and
machine learning-driven data analysis marks a pivotal advancement in the
maritime industry. This transformative technology not only can enhance safety,
efficiency, and sustainability but also usher in a new era of cost-effective
and smart maritime transportation in our increasingly interconnected world.
This study presents a deep learning-driven anomaly detection system augmented
with interpretable machine learning models for identifying performance
anomalies in an industrial sensorized vessel, called TUCANA. We Leverage a
human-in-the-loop unsupervised process that involves utilizing standard and
Long Short-Term Memory (LSTM) autoencoders augmented with interpretable
surrogate models, i.e., random forest and decision tree, to add transparency
and interpretability to the results provided by the deep learning models. The
interpretable models also enable automated rule generation for translating the
inference into human-readable rules. Additionally, the process also includes
providing a projection of the results using t-distributed stochastic neighbor
embedding (t-SNE), which helps with a better understanding of the structure and
relationships within the data and assessment of the identified anomalies. We
empirically evaluate the system using real data acquired from the vessel TUCANA
and the results involve achieving over 80% precision and 90% recall with the
LSTM model used in the process. The interpretable models also provide logical
rules aligned with expert thinking, and the t-SNE-based projection enhances
interpretability. Our system demonstrates that the proposed approach can be
used effectively in real-world scenarios, offering transparency and precision
in performance anomaly detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00122">SALSA: Sequential Approximate Leverage-Score Algorithm with Application in Analyzing Big Time Series Data. (arXiv:2401.00122v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Eshragh_A/0/1/0/all/0/1">Ali Eshragh</a>, <a href="http://arxiv.org/find/stat/1/au:+Yerbury_L/0/1/0/all/0/1">Luke Yerbury</a>, <a href="http://arxiv.org/find/stat/1/au:+Nazari_A/0/1/0/all/0/1">Asef Nazari</a>, <a href="http://arxiv.org/find/stat/1/au:+Roosta_F/0/1/0/all/0/1">Fred Roosta</a>, <a href="http://arxiv.org/find/stat/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a></p>
<p>We develop a new efficient sequential approximate leverage score algorithm,
SALSA, using methods from randomized numerical linear algebra (RandNLA) for
large matrices. We demonstrate that, with high probability, the accuracy of
SALSA's approximations is within $(1 + O({\varepsilon}))$ of the true leverage
scores. In addition, we show that the theoretical computational complexity and
numerical accuracy of SALSA surpass existing approximations. These theoretical
results are subsequently utilized to develop an efficient algorithm, named
LSARMA, for fitting an appropriate ARMA model to large-scale time series data.
Our proposed algorithm is, with high probability, guaranteed to find the
maximum likelihood estimates of the parameters for the true underlying ARMA
model. Furthermore, it has a worst-case running time that significantly
improves those of the state-of-the-art alternatives in big data regimes.
Empirical results on large-scale data strongly support these theoretical
results and underscore the efficacy of our new approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00128">Quantifying intra-tumoral genetic heterogeneity of glioblastoma toward precision medicine using MRI and a data-inclusive machine learning algorithm. (arXiv:2401.00128v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lujia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hairong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+DAngelo_F/0/1/0/all/0/1">Fulvio D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Curtin_L/0/1/0/all/0/1">Lee Curtin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sereduk_C/0/1/0/all/0/1">Christopher P. Sereduk</a>, <a href="http://arxiv.org/find/cs/1/au:+Leon_G/0/1/0/all/0/1">Gustavo De Leon</a>, <a href="http://arxiv.org/find/cs/1/au:+Singleton_K/0/1/0/all/0/1">Kyle W. Singleton</a>, <a href="http://arxiv.org/find/cs/1/au:+Urcuyo_J/0/1/0/all/0/1">Javier Urcuyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawkins_Daarud_A/0/1/0/all/0/1">Andrea Hawkins-Daarud</a>, <a href="http://arxiv.org/find/cs/1/au:+Jackson_P/0/1/0/all/0/1">Pamela R. Jackson</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_C/0/1/0/all/0/1">Chandan Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmerman_R/0/1/0/all/0/1">Richard S. Zimmerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Patra_D/0/1/0/all/0/1">Devi P. Patra</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendok_B/0/1/0/all/0/1">Bernard R. Bendok</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kris A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakaji_P/0/1/0/all/0/1">Peter Nakaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Donev_K/0/1/0/all/0/1">Kliment Donev</a>, <a href="http://arxiv.org/find/cs/1/au:+Baxter_L/0/1/0/all/0/1">Leslie C. Baxter</a>, <a href="http://arxiv.org/find/cs/1/au:+Mrugala_M/0/1/0/all/0/1">Maciej M. Mruga&#x142;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceccarelli_M/0/1/0/all/0/1">Michele Ceccarelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Iavarone_A/0/1/0/all/0/1">Antonio Iavarone</a>, <a href="http://arxiv.org/find/cs/1/au:+Swanson_K/0/1/0/all/0/1">Kristin R. Swanson</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1">Nhan L. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Leland S. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a></p>
<p>Glioblastoma (GBM) is one of the most aggressive and lethal human cancers.
Intra-tumoral genetic heterogeneity poses a significant challenge for
treatment. Biopsy is invasive, which motivates the development of non-invasive,
MRI-based machine learning (ML) models to quantify intra-tumoral genetic
heterogeneity for each patient. This capability holds great promise for
enabling better therapeutic selection to improve patient outcomes. We proposed
a novel Weakly Supervised Ordinal Support Vector Machine (WSO-SVM) to predict
regional genetic alteration status within each GBM tumor using MRI. WSO-SVM was
applied to a unique dataset of 318 image-localized biopsies with spatially
matched multiparametric MRI from 74 GBM patients. The model was trained to
predict the regional genetic alteration of three GBM driver genes (EGFR,
PDGFRA, and PTEN) based on features extracted from the corresponding region of
five MRI contrast images. For comparison, a variety of existing ML algorithms
were also applied. The classification accuracy of each gene was compared
between the different algorithms. The SHapley Additive exPlanations (SHAP)
method was further applied to compute contribution scores of different contrast
images. Finally, the trained WSO-SVM was used to generate prediction maps
within the tumoral area of each patient to help visualize the intra-tumoral
genetic heterogeneity. This study demonstrated the feasibility of using MRI and
WSO-SVM to enable non-invasive prediction of intra-tumoral regional genetic
alteration for each GBM patient, which can inform future adaptive therapies for
individualized oncology.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00139">Is Knowledge All Large Language Models Needed for Causal Reasoning?. (arXiv:2401.00139v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hengrui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shengjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Rui Song</a></p>
<p>This paper explores the causal reasoning of large language models (LLMs) to
enhance their interpretability and reliability in advancing artificial
intelligence. Despite the proficiency of LLMs in a range of tasks, their
potential for understanding causality requires further exploration. We propose
a novel causal attribution model that utilizes "do-operators" for constructing
counterfactual scenarios, allowing us to systematically quantify the influence
of input numerical data and LLMs' pre-existing knowledge on their causal
reasoning processes. Our newly developed experimental setup assesses LLMs'
reliance on contextual information and inherent knowledge across various
domains. Our evaluation reveals that LLMs' causal reasoning ability depends on
the context and domain-specific knowledge provided, and supports the argument
that "knowledge is, indeed, what LLMs principally require for sound causal
reasoning". On the contrary, in the absence of knowledge, LLMs still maintain a
degree of causal reasoning using the available numerical data, albeit with
limitations in the calculations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00161">DiffHybrid-UQ: Uncertainty Quantification for Differentiable Hybrid Neural Modeling. (arXiv:2401.00161v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akhare_D/0/1/0/all/0/1">Deepak Akhare</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tengfei Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian-Xun Wang</a></p>
<p>The hybrid neural differentiable models mark a significant advancement in the
field of scientific machine learning. These models, integrating numerical
representations of known physics into deep neural networks, offer enhanced
predictive capabilities and show great potential for data-driven modeling of
complex physical systems. However, a critical and yet unaddressed challenge
lies in the quantification of inherent uncertainties stemming from multiple
sources. Addressing this gap, we introduce a novel method, DiffHybrid-UQ, for
effective and efficient uncertainty propagation and estimation in hybrid neural
differentiable models, leveraging the strengths of deep ensemble Bayesian
learning and nonlinear transformations. Specifically, our approach effectively
discerns and quantifies both aleatoric uncertainties, arising from data noise,
and epistemic uncertainties, resulting from model-form discrepancies and data
sparsity. This is achieved within a Bayesian model averaging framework, where
aleatoric uncertainties are modeled through hybrid neural models. The unscented
transformation plays a pivotal role in enabling the flow of these uncertainties
through the nonlinear functions within the hybrid model. In contrast, epistemic
uncertainties are estimated using an ensemble of stochastic gradient descent
(SGD) trajectories. This approach offers a practical approximation to the
posterior distribution of both the network parameters and the physical
parameters. Notably, the DiffHybrid-UQ framework is designed for simplicity in
implementation and high scalability, making it suitable for parallel computing
environments. The merits of the proposed method have been demonstrated through
problems governed by both ordinary and partial differentiable equations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00162">Policy Optimization with Smooth Guidance Rewards Learned from Sparse-Reward Demonstrations. (arXiv:2401.00162v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guojian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Faguo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianyuan Chen</a></p>
<p>The sparsity of reward feedback remains a challenging problem in online deep
reinforcement learning (DRL). Previous approaches have utilized temporal credit
assignment (CA) to achieve impressive results in multiple hard tasks. However,
many CA methods relied on complex architectures or introduced sensitive
hyperparameters to estimate the impact of state-action pairs. Meanwhile, the
premise of the feasibility of CA methods is to obtain trajectories with sparse
rewards, which can be troublesome in sparse-reward environments with large
state spaces. To tackle these problems, we propose a simple and efficient
algorithm called Policy Optimization with Smooth Guidance (POSG) that leverages
a small set of sparse-reward demonstrations to make reliable and effective
long-term credit assignments while efficiently facilitating exploration. The
key idea is that the relative impact of state-action pairs can be indirectly
estimated using offline demonstrations rather than directly leveraging the
sparse reward trajectories generated by the agent. Specifically, we first
obtain the trajectory importance by considering both the trajectory-level
distance to demonstrations and the returns of the relevant trajectories. Then,
the guidance reward is calculated for each state-action pair by smoothly
averaging the importance of the trajectories through it, merging the
demonstration's distribution and reward information. We theoretically analyze
the performance improvement bound caused by smooth guidance rewards and derive
a new worst-case lower bound on the performance improvement. Extensive results
demonstrate POSG's significant advantages in control performance and
convergence speed compared to benchmark DRL algorithms. Notably, the specific
metrics and quantifiable results are investigated to demonstrate the
superiority of POSG.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00163">A clean-label graph backdoor attack method in node classification task. (arXiv:2401.00163v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1">Xiaogang Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Ming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yujing Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Dongdong Yang</a></p>
<p>Backdoor attacks in the traditional graph neural networks (GNNs) field are
easily detectable due to the dilemma of confusing labels. To explore the
backdoor vulnerability of GNNs and create a more stealthy backdoor attack
method, a clean-label graph backdoor attack method(CGBA) in the node
classification task is proposed in this paper. Differently from existing
backdoor attack methods, CGBA requires neither modification of node labels nor
graph structure. Specifically, to solve the problem of inconsistency between
the contents and labels of the samples, CGBA selects poisoning samples in a
specific target class and uses the label of sample as the target label (i.e.,
clean-label) after injecting triggers into the target samples. To guarantee the
similarity of neighboring nodes, the raw features of the nodes are elaborately
picked as triggers to further improve the concealment of the triggers.
Extensive experiments results show the effectiveness of our method. When the
poisoning rate is 0.04, CGBA can achieve an average attack success rate of
87.8%, 98.9%, 89.1%, and 98.5%, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00170">L3Cube-MahaSocialNER: A Social Media based Marathi NER Dataset and BERT models. (arXiv:2401.00170v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chaudhari_H/0/1/0/all/0/1">Harsh Chaudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1">Anuja Patil</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavekar_D/0/1/0/all/0/1">Dhanashree Lavekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Khairnar_P/0/1/0/all/0/1">Pranav Khairnar</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Raviraj Joshi</a></p>
<p>This work introduces the L3Cube-MahaSocialNER dataset, the first and largest
social media dataset specifically designed for Named Entity Recognition (NER)
in the Marathi language. The dataset comprises 18,000 manually labeled
sentences covering eight entity classes, addressing challenges posed by social
media data, including non-standard language and informal idioms. Deep learning
models, including CNN, LSTM, BiLSTM, and Transformer models, are evaluated on
the individual dataset with IOB and non-IOB notations. The results demonstrate
the effectiveness of these models in accurately recognizing named entities in
Marathi informal text. The L3Cube-MahaSocialNER dataset offers user-centric
information extraction and supports real-time applications, providing a
valuable resource for public opinion analysis, news, and marketing on social
media platforms. We also show that the zero-shot results of the regular NER
model are poor on the social NER test set thus highlighting the need for more
social NER datasets. The datasets and models are publicly available at
https://github.com/l3cube-pune/MarathiNLP
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00186">A Novel Explanation Against Linear Neural Networks. (arXiv:2401.00186v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lakkapragada_A/0/1/0/all/0/1">Anish Lakkapragada</a></p>
<p>Linear Regression and neural networks are widely used to model data. Neural
networks distinguish themselves from linear regression with their use of
activation functions that enable modeling nonlinear functions. The standard
argument for these activation functions is that without them, neural networks
only can model a line. However, a novel explanation we propose in this paper
for the impracticality of neural networks without activation functions, or
linear neural networks, is that they actually reduce both training and testing
performance. Having more parameters makes LNNs harder to optimize, and thus
they require more training iterations than linear regression to even
potentially converge to the optimal solution. We prove this hypothesis through
an analysis of the optimization of an LNN and rigorous testing comparing the
performance between both LNNs and linear regression on synthethic, noisy
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00193">KAXAI: An Integrated Environment for Knowledge Analysis and Explainable AI. (arXiv:2401.00193v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barua_S/0/1/0/all/0/1">Saikat Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Momen_D/0/1/0/all/0/1">Dr. Sifat Momen</a></p>
<p>In order to fully harness the potential of machine learning, it is crucial to
establish a system that renders the field more accessible and less daunting for
individuals who may not possess a comprehensive understanding of its
intricacies. The paper describes the design of a system that integrates AutoML,
XAI, and synthetic data generation to provide a great UX design for users. The
system allows users to navigate and harness the power of machine learning while
abstracting its complexities and providing high usability. The paper proposes
two novel classifiers, Logistic Regression Forest and Support Vector Tree, for
enhanced model performance, achieving 96\% accuracy on a diabetes dataset and
93\% on a survey dataset. The paper also introduces a model-dependent local
interpreter called MEDLEY and evaluates its interpretation against LIME,
Greedy, and Parzen. Additionally, the paper introduces LLM-based synthetic data
generation, library-based data generation, and enhancing the original dataset
with GAN. The findings on synthetic data suggest that enhancing the original
dataset with GAN is the most reliable way to generate synthetic data, as
evidenced by KS tests, standard deviation, and feature importance. The authors
also found that GAN works best for quantitative datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00230">Transformer Multivariate Forecasting: Less is More?. (arXiv:2401.00230v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Caesar Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan-Fang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouvry_P/0/1/0/all/0/1">Pascal Bouvry</a></p>
<p>In the domain of multivariate forecasting, transformer models stand out as
powerful apparatus, displaying exceptional capabilities in handling messy
datasets from real-world contexts. However, the inherent complexity of these
datasets, characterized by numerous variables and lengthy temporal sequences,
poses challenges, including increased noise and extended model runtime. This
paper focuses on reducing redundant information to elevate forecasting accuracy
while optimizing runtime efficiency. We propose a novel transformer forecasting
framework enhanced by Principal Component Analysis (PCA) to tackle this
challenge. The framework is evaluated by five state-of-the-art (SOTA) models
and four diverse real-world datasets. Our experimental results demonstrate the
framework's ability to minimize prediction errors across all models and
datasets while significantly reducing runtime. From the model perspective, one
of the PCA-enhanced models: PCA+Crossformer, reduces mean square errors (MSE)
by 33.3% and decreases runtime by 49.2% on average. From the dataset
perspective, the framework delivers 14.3% MSE and 76.6% runtime reduction on
Electricity datasets, as well as 4.8% MSE and 86.9% runtime reduction on
Traffic datasets. This study aims to advance various SOTA models and enhance
transformer-based time series forecasting for intricate data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00242">Laboratory Experiments of Model-based Reinforcement Learning for Adaptive Optics Control. (arXiv:2401.00242v1 [astro-ph.IM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+Nousiainen_J/0/1/0/all/0/1">Jalo Nousiainen</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Engler_B/0/1/0/all/0/1">Byron Engler</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Kasper_M/0/1/0/all/0/1">Markus Kasper</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Rajani_C/0/1/0/all/0/1">Chang Rajani</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Helin_T/0/1/0/all/0/1">Tapio Helin</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Heritier_C/0/1/0/all/0/1">C&#xe9;dric T. Heritier</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Quanz_S/0/1/0/all/0/1">Sascha P. Quanz</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Glauser_A/0/1/0/all/0/1">Adrian M. Glauser</a></p>
<p>Direct imaging of Earth-like exoplanets is one of the most prominent
scientific drivers of the next generation of ground-based telescopes.
Typically, Earth-like exoplanets are located at small angular separations from
their host stars, making their detection difficult. Consequently, the adaptive
optics (AO) system's control algorithm must be carefully designed to
distinguish the exoplanet from the residual light produced by the host star.
</p>
<p>A new promising avenue of research to improve AO control builds on
data-driven control methods such as Reinforcement Learning (RL). RL is an
active branch of the machine learning research field, where control of a system
is learned through interaction with the environment. Thus, RL can be seen as an
automated approach to AO control, where its usage is entirely a turnkey
operation. In particular, model-based reinforcement learning (MBRL) has been
shown to cope with both temporal and misregistration errors. Similarly, it has
been demonstrated to adapt to non-linear wavefront sensing while being
efficient in training and execution.
</p>
<p>In this work, we implement and adapt an RL method called Policy Optimization
for AO (PO4AO) to the GHOST test bench at ESO headquarters, where we
demonstrate a strong performance of the method in a laboratory environment. Our
implementation allows the training to be performed parallel to inference, which
is crucial for on-sky operation. In particular, we study the predictive and
self-calibrating aspects of the method. The new implementation on GHOST running
PyTorch introduces only around 700 microseconds in addition to hardware,
pipeline, and Python interface latency. We open-source well-documented code for
the implementation and specify the requirements for the RTC pipeline. We also
discuss the important hyperparameters of the method, the source of the latency,
and the possible paths for a lower latency implementation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00243">Uncertainty-Penalized Reinforcement Learning from Human Feedback with Diverse Reward LoRA Ensembles. (arXiv:2401.00243v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1">Yuanzhao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yu Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1">Dawei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1">Bo Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huaimin Wang</a></p>
<p>Reinforcement learning from human feedback (RLHF) emerges as a promising
paradigm for aligning large language models (LLMs). However, a notable
challenge in RLHF is overoptimization, where beyond a certain threshold, the
pursuit of higher rewards leads to a decline in human preferences. In this
paper, we observe the weakness of KL regularization which is commonly employed
in existing RLHF methods to address overoptimization. To mitigate this
limitation, we scrutinize the RLHF objective in the offline dataset and propose
uncertainty-penalized RLHF (UP-RLHF), which incorporates uncertainty
regularization during RL-finetuning. To enhance the uncertainty quantification
abilities for reward models, we first propose a diverse low-rank adaptation
(LoRA) ensemble by maximizing the nuclear norm of LoRA matrix concatenations.
Then we optimize policy models utilizing penalized rewards, determined by both
rewards and uncertainties provided by the diverse reward LoRA ensembles. Our
experimental results, based on two real human preference datasets, showcase the
effectiveness of diverse reward LoRA ensembles in quantifying reward
uncertainty. Additionally, uncertainty regularization in UP-RLHF proves to be
pivotal in mitigating overoptimization, thereby contributing to the overall
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00275">An $\ell^1$-Plug-and-Play Approach for Magnetic Particle Imaging Using a Zero Shot Denoiser with Validation on the 3D Open MPI Dataset. (arXiv:2401.00275v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Gapyak_V/0/1/0/all/0/1">Vladyslav Gapyak</a>, <a href="http://arxiv.org/find/eess/1/au:+Rentschler_C/0/1/0/all/0/1">Corinna Rentschler</a>, <a href="http://arxiv.org/find/eess/1/au:+Marz_T/0/1/0/all/0/1">Thomas M&#xe4;rz</a>, <a href="http://arxiv.org/find/eess/1/au:+Weinmann_A/0/1/0/all/0/1">Andreas Weinmann</a></p>
<p>Magnetic particle imaging (MPI) is an emerging medical imaging modality which
has gained increasing interest in recent years. Among the benefits of MPI are
its high temporal resolution, and that the technique does not expose the
specimen to any kind of ionizing radiation. It is based on the non-linear
response of magnetic nanoparticles to an applied magnetic field. From the
electric signal measured in receive coils, the particle concentration has to be
reconstructed. Due to the ill-posedness of the reconstruction problem, various
regularization methods have been proposed for reconstruction ranging from early
stopping methods, via classical Tikhonov regularization and iterative methods
to modern machine learning approaches. In this work, we contribute to the
latter class: we propose a plug-and-play approach based on a generic zero-shot
denoiser with an $\ell^1$-prior. Moreover, we develop parameter selection
strategies. Finally, we quantitatively and qualitatively evaluate the proposed
algorithmic scheme on the 3D Open MPI data set with different levels of
preprocessing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00276">Second-Order Uncertainty Quantification: Variance-Based Measures. (arXiv:2401.00276v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sale_Y/0/1/0/all/0/1">Yusuf Sale</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofman_P/0/1/0/all/0/1">Paul Hofman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wimmer_L/0/1/0/all/0/1">Lisa Wimmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagler_T/0/1/0/all/0/1">Thomas Nagler</a></p>
<p>Uncertainty quantification is a critical aspect of machine learning models,
providing important insights into the reliability of predictions and aiding the
decision-making process in real-world applications. This paper proposes a novel
way to use variance-based measures to quantify uncertainty on the basis of
second-order distributions in classification problems. A distinctive feature of
the measures is the ability to reason about uncertainties on a class-based
level, which is useful in situations where nuanced decision-making is required.
Recalling some properties from the literature, we highlight that the
variance-based measures satisfy important (axiomatic) properties. In addition
to this axiomatic approach, we present empirical results showing the measures
to be effective and competitive to commonly used entropy-based measures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00280">Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation. (arXiv:2401.00280v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fayyazi_R/0/1/0/all/0/1">Reza Fayyazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taghdimi_R/0/1/0/all/0/1">Rozhina Taghdimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shanchieh Jay Yang</a></p>
<p>Tactics, Techniques, and Procedures (TTPs) outline the methods attackers use
to exploit vulnerabilities. The interpretation of TTPs in the MITRE ATT&amp;CK
framework can be challenging for cybersecurity practitioners due to presumed
expertise, complex dependencies, and inherent ambiguity. Meanwhile,
advancements with Large Language Models (LLMs) have led to recent surge in
studies exploring its uses in cybersecurity operations. This leads us to
question how well encoder-only (e.g., RoBERTa) and decoder-only (e.g., GPT-3.5)
LLMs can comprehend and summarize TTPs to inform analysts of the intended
purposes (i.e., tactics) of a cyberattack procedure. The state-of-the-art LLMs
have shown to be prone to hallucination by providing inaccurate information,
which is problematic in critical domains like cybersecurity. Therefore, we
propose the use of Retrieval Augmented Generation (RAG) techniques to extract
relevant contexts for each cyberattack procedure for decoder-only LLMs (without
fine-tuning). We further contrast such approach against supervised fine-tuning
(SFT) of encoder-only LLMs. Our results reveal that both the direct-use of
decoder-only LLMs (i.e., its pre-trained knowledge) and the SFT of encoder-only
LLMs offer inaccurate interpretation of cyberattack procedures. Significant
improvements are shown when RAG is used for decoder-only LLMs, particularly
when directly relevant context is found. This study further sheds insights on
the limitations and capabilities of using RAG for LLMs in interpreting TTPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00282">Deep Generative Symbolic Regression. (arXiv:2401.00282v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Holt_S/0/1/0/all/0/1">Samuel Holt</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1">Zhaozhi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a></p>
<p>Symbolic regression (SR) aims to discover concise closed-form mathematical
equations from data, a task fundamental to scientific discovery. However, the
problem is highly challenging because closed-form equations lie in a complex
combinatorial search space. Existing methods, ranging from heuristic search to
reinforcement learning, fail to scale with the number of input variables. We
make the observation that closed-form equations often have structural
characteristics and invariances (e.g., the commutative law) that could be
further exploited to build more effective symbolic regression solutions.
Motivated by this observation, our key contribution is to leverage pre-trained
deep generative models to capture the intrinsic regularities of equations,
thereby providing a solid foundation for subsequent optimization steps. We show
that our novel formalism unifies several prominent approaches of symbolic
regression and offers a new perspective to justify and improve on the previous
ad hoc designs, such as the usage of cross-entropy loss during pre-training.
Specifically, we propose an instantiation of our framework, Deep Generative
Symbolic Regression (DGSR). In our experiments, we show that DGSR achieves a
higher recovery rate of true equations in the setting of a larger number of
input variables, and it is more computationally efficient at inference time
than state-of-the-art RL symbolic regression solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00297">A Novel Reinforcement Learning Routing Algorithm for Congestion Control in Complex Networks. (arXiv:2401.00297v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yajadda_S/0/1/0/all/0/1">Seyed Hassan Yajadda</a>, <a href="http://arxiv.org/find/cs/1/au:+Safaei_F/0/1/0/all/0/1">Farshad Safaei</a></p>
<p>Despite technological advancements, the significance of interdisciplinary
subjects like complex networks has grown. Exploring communication within these
networks is crucial, with traffic becoming a key concern due to the expanding
population and increased need for connections. Congestion tends to originate in
specific network areas but quickly proliferates throughout. Consequently,
understanding the transition from a flow-free state to a congested state is
vital. Numerous studies have delved into comprehending the emergence and
control of congestion in complex networks, falling into three general
categories: soft strategies, hard strategies, and resource allocation
strategies. This article introduces a routing algorithm leveraging
reinforcement learning to address two primary objectives: congestion control
and optimizing path length based on the shortest path algorithm, ultimately
enhancing network throughput compared to previous methods. Notably, the
proposed method proves effective not only in Barab\'asi-Albert scale-free
networks but also in other network models such as Watts-Strogatz (small-world)
and Erd\"os-R\'enyi (random network). Simulation experiment results demonstrate
that, across various traffic scenarios and network topologies, the proposed
method can enhance efficiency criteria by up to 30% while reducing maximum node
congestion by five times.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00313">Matching of Users and Creators in Two-Sided Markets with Departures. (arXiv:2401.00313v1 [cs.GT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huttenlocher_D/0/1/0/all/0/1">Daniel Huttenlocher</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hannah Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1">Liang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1">Asuman Ozdaglar</a>, <a href="http://arxiv.org/find/cs/1/au:+Siderius_J/0/1/0/all/0/1">James Siderius</a></p>
<p>Many online platforms of today, including social media sites, are two-sided
markets bridging content creators and users. Most of the existing literature on
platform recommendation algorithms largely focuses on user preferences and
decisions, and does not simultaneously address creator incentives. We propose a
model of content recommendation that explicitly focuses on the dynamics of
user-content matching, with the novel property that both users and creators may
leave the platform permanently if they do not experience sufficient engagement.
In our model, each player decides to participate at each time step based on
utilities derived from the current match: users based on alignment of the
recommended content with their preferences, and creators based on their
audience size. We show that a user-centric greedy algorithm that does not
consider creator departures can result in arbitrarily poor total engagement,
relative to an algorithm that maximizes total engagement while accounting for
two-sided departures. Moreover, in stark contrast to the case where only users
or only creators leave the platform, we prove that with two-sided departures,
approximating maximum total engagement within any constant factor is NP-hard.
We present two practical algorithms, one with performance guarantees under mild
assumptions on user preferences, and another that tends to outperform
algorithms that ignore two-sided departures in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00314">GAN-GA: A Generative Model based on Genetic Algorithm for Medical Image Generation. (arXiv:2401.00314v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+AbdulRazek_M/0/1/0/all/0/1">M. AbdulRazek</a>, <a href="http://arxiv.org/find/eess/1/au:+Khoriba_G/0/1/0/all/0/1">G. Khoriba</a>, <a href="http://arxiv.org/find/eess/1/au:+Belal_M/0/1/0/all/0/1">M. Belal</a></p>
<p>Medical imaging is an essential tool for diagnosing and treating diseases.
However, lacking medical images can lead to inaccurate diagnoses and
ineffective treatments. Generative models offer a promising solution for
addressing medical image shortage problems due to their ability to generate new
data from existing datasets and detect anomalies in this data. Data
augmentation with position augmentation methods like scaling, cropping,
flipping, padding, rotation, and translation could lead to more overfitting in
domains with little data, such as medical image data. This paper proposes the
GAN-GA, a generative model optimized by embedding a genetic algorithm. The
proposed model enhances image fidelity and diversity while preserving
distinctive features. The proposed medical image synthesis approach improves
the quality and fidelity of medical images, an essential aspect of image
interpretation. To evaluate synthesized images: Frechet Inception Distance
(FID) is used. The proposed GAN-GA model is tested by generating Acute
lymphoblastic leukemia (ALL) medical images, an image dataset, and is the first
time to be used in generative models. Our results were compared to those of
InfoGAN as a baseline model. The experimental results show that the proposed
optimized GAN-GA enhances FID scores by about 6.8\%, especially in earlier
training epochs. The source code and dataset will be available at:
https://github.com/Mustafa-AbdulRazek/InfoGAN-GA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00320">DXAI: Explaining Classification by Image Decomposition. (arXiv:2401.00320v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kadar_E/0/1/0/all/0/1">Elnatan Kadar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilboa_G/0/1/0/all/0/1">Guy Gilboa</a></p>
<p>We propose a new way to explain and to visualize neural network
classification through a decomposition-based explainable AI (DXAI). Instead of
providing an explanation heatmap, our method yields a decomposition of the
image into class-agnostic and class-distinct parts, with respect to the data
and chosen classifier. Following a fundamental signal processing paradigm of
analysis and synthesis, the original image is the sum of the decomposed parts.
We thus obtain a radically different way of explaining classification. The
class-agnostic part ideally is composed of all image features which do not
posses class information, where the class-distinct part is its complementary.
This new visualization can be more helpful and informative in certain
scenarios, especially when the attributes are dense, global and additive in
nature, for instance, when colors or textures are essential for class
distinction. Code is available at https://github.com/dxai2024/dxai.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00329">On the Burstiness of Distributed Machine Learning Traffic. (arXiv:2401.00329v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luangsomboon_N/0/1/0/all/0/1">Natchanon Luangsomboon</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazel_F/0/1/0/all/0/1">Fahimeh Fazel</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebeherr_J/0/1/0/all/0/1">J&#xf6;rg Liebeherr</a>, <a href="http://arxiv.org/find/cs/1/au:+Sobhani_A/0/1/0/all/0/1">Ashkan Sobhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1">Shichao Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xingjun Chu</a></p>
<p>Traffic from distributed training of machine learning (ML) models makes up a
large and growing fraction of the traffic mix in enterprise data centers. While
work on distributed ML abounds, the network traffic generated by distributed ML
has received little attention. Using measurements on a testbed network, we
investigate the traffic characteristics generated by the training of the
ResNet-50 neural network with an emphasis on studying its short-term
burstiness. For the latter we propose metrics that quantify traffic burstiness
at different time scales. Our analysis reveals that distributed ML traffic
exhibits a very high degree of burstiness on short time scales, exceeding a
60:1 peak-to-mean ratio on time intervals as long as 5~ms. We observe that
training software orchestrates transmissions in such a way that burst
transmissions from different sources within the same application do not result
in congestion and packet losses. An extrapolation of the measurement data to
multiple applications underscores the challenges of distributed ML traffic for
congestion and flow control algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00330">Efficient Two-Phase Offline Deep Reinforcement Learning from Preference Feedback. (arXiv:2401.00330v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinglun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a></p>
<p>In this work, we consider the offline preference-based reinforcement learning
problem. We focus on the two-phase learning approach that is prevalent in
previous reinforcement learning from human preference works. We find a
challenge in applying two-phase learning in the offline PBRL setting that the
learned utility model can be too hard for the learning agent to optimize during
the second learning phase. To overcome the challenge, we propose a two-phasing
learning approach under behavior regularization through action clipping. The
insight is that the state-actions which are poorly covered by the dataset can
only provide limited information and increase the complexity of the problem in
the second learning phase. Our method ignores such state-actions during the
second learning phase to achieve higher learning efficiency. We empirically
verify that our method has high learning efficiency on a variety of datasets in
robotic control environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00334">Explainability-Driven Leaf Disease Classification using Adversarial Training and Knowledge Distillation. (arXiv:2401.00334v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Echim_S/0/1/0/all/0/1">Sebastian-Vasile Echim</a>, <a href="http://arxiv.org/find/cs/1/au:+Taiatu_I/0/1/0/all/0/1">Iulian-Marius T&#x103;iatu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1">Dumitru-Clementin Cercel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pop_F/0/1/0/all/0/1">Florin Pop</a></p>
<p>This work focuses on plant leaf disease classification and explores three
crucial aspects: adversarial training, model explainability, and model
compression. The models' robustness against adversarial attacks is enhanced
through adversarial training, ensuring accurate classification even in the
presence of threats. Leveraging explainability techniques, we gain insights
into the model's decision-making process, improving trust and transparency.
Additionally, we explore model compression techniques to optimize computational
efficiency while maintaining classification performance. Through our
experiments, we determine that on a benchmark dataset, the robustness can be
the price of the classification accuracy with performance reductions of 3%-20%
for regular tests and gains of 50%-70% for adversarial attack tests. We also
demonstrate that a student model can be 15-25 times more computationally
efficient for a slight performance reduction, distilling the knowledge of more
complex models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00364">Tight Finite Time Bounds of Two-Time-Scale Linear Stochastic Approximation with Markovian Noise. (arXiv:2401.00364v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Haque_S/0/1/0/all/0/1">Shaan Ul Haque</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1">Sajad Khodadadian</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1">Siva Theja Maguluri</a></p>
<p>Stochastic approximation (SA) is an iterative algorithm to find the fixed
point of an operator given noisy samples of this operator. SA appears in many
areas such as optimization and Reinforcement Learning (RL). When implemented in
practice, the noise that appears in the update of RL algorithms is naturally
Markovian. Furthermore, in some settings, such as gradient TD, SA is employed
in a two-time-scale manner. The mix of Markovian noise along with the
two-time-scale structure results in an algorithm which is complex to analyze
theoretically. In this paper, we characterize a tight convergence bound for the
iterations of linear two-time-scale SA with Markovian noise. Our results show
the convergence behavior of this algorithm given various choices of step sizes.
Applying our result to the well-known TDC algorithm, we show the first
$O(1/\epsilon)$ sample complexity for the convergence of this algorithm,
outperforming all the previous work. Similarly, our results can be applied to
establish the convergence behavior of a variety of RL algorithms, such as
TD-learning with Polyak averaging, GTD, and GTD2.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00365">HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes. (arXiv:2401.00365v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Takida_Y/0/1/0/all/0/1">Yuhta Takida</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikemiya_Y/0/1/0/all/0/1">Yukara Ikemiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Shibuya_T/0/1/0/all/0/1">Takashi Shibuya</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimada_K/0/1/0/all/0/1">Kazuki Shimada</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_W/0/1/0/all/0/1">Woosung Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chieh-Hsin Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Murata_N/0/1/0/all/0/1">Naoki Murata</a>, <a href="http://arxiv.org/find/cs/1/au:+Uesaka_T/0/1/0/all/0/1">Toshimitsu Uesaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_K/0/1/0/all/0/1">Kengo Uchida</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wei-Hsiang Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1">Yuki Mitsufuji</a></p>
<p>Vector quantization (VQ) is a technique to deterministically learn features
with discrete codebook representations. It is commonly performed with a
variational autoencoding model, VQ-VAE, which can be further extended to
hierarchical structures for making high-fidelity reconstructions. However, such
hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse
issue, where the codebook is not efficiently used to express the data, and
hence degrades reconstruction accuracy. To mitigate this problem, we propose a
novel unified framework to stochastically learn hierarchical discrete
representation on the basis of the variational Bayes framework, called
hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally
generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and
residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training
scheme. Our comprehensive experiments on image datasets show that HQ-VAE
enhances codebook usage and improves reconstruction performance. We also
validated HQ-VAE in terms of its applicability to a different modality with an
audio dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00383">Predicting Evoked Emotions in Conversations. (arXiv:2401.00383v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Altarawneh_E/0/1/0/all/0/1">Enas Altarawneh</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ameeta Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenkin_M/0/1/0/all/0/1">Michael Jenkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Papagelis_M/0/1/0/all/0/1">Manos Papagelis</a></p>
<p>Understanding and predicting the emotional trajectory in multi-party
multi-turn conversations is of great significance. Such information can be
used, for example, to generate empathetic response in human-machine interaction
or to inform models of pre-emptive toxicity detection. In this work, we
introduce the novel problem of Predicting Emotions in Conversations (PEC) for
the next turn (n+1), given combinations of textual and/or emotion input up to
turn n. We systematically approach the problem by modeling three dimensions
inherently connected to evoked emotions in dialogues, including (i) sequence
modeling, (ii) self-dependency modeling, and (iii) recency modeling. These
modeling dimensions are then incorporated into two deep neural network
architectures, a sequence model and a graph convolutional network model. The
former is designed to capture the sequence of utterances in a dialogue, while
the latter captures the sequence of utterances and the network formation of
multi-party dialogues. We perform a comprehensive empirical evaluation of the
various proposed models for addressing the PEC problem. The results indicate
(i) the importance of the self-dependency and recency model dimensions for the
prediction task, (ii) the quality of simpler sequence models in short
dialogues, (iii) the importance of the graph neural models in improving the
predictions in long dialogues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00390">Horizontal Federated Computer Vision. (arXiv:2401.00390v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mandal_P/0/1/0/all/0/1">Paul K. Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Leo_C/0/1/0/all/0/1">Cole Leo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hurley_C/0/1/0/all/0/1">Connor Hurley</a></p>
<p>In the modern world, the amount of visual data recorded has been rapidly
increasing. In many cases, data is stored in geographically distinct locations
and thus requires a large amount of time and space to consolidate. Sometimes,
there are also regulations for privacy protection which prevent data
consolidation. In this work, we present federated implementations for object
detection and recognition using a federated Faster R-CNN (FRCNN) and image
segmentation using a federated Fully Convolutional Network (FCN). Our FRCNN was
trained on 5000 examples of the COCO2017 dataset while our FCN was trained on
the entire train set of the CamVid dataset. The proposed federated models
address the challenges posed by the increasing volume and decentralized nature
of visual data, offering efficient solutions in compliance with privacy
regulations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00391">Controllable Safety-Critical Closed-loop Traffic Simulation via Guided Diffusion. (arXiv:2401.00391v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1">Wei-Jer Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pittaluga_F/0/1/0/all/0/1">Francesco Pittaluga</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1">Masayoshi Tomizuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1">Wei Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandraker_M/0/1/0/all/0/1">Manmohan Chandraker</a></p>
<p>Evaluating the performance of autonomous vehicle planning algorithms
necessitates simulating long-tail traffic scenarios. Traditional methods for
generating safety-critical scenarios often fall short in realism and
controllability. Furthermore, these techniques generally neglect the dynamics
of agent interactions. To mitigate these limitations, we introduce a novel
closed-loop simulation framework rooted in guided diffusion models. Our
approach yields two distinct advantages: 1) the generation of realistic
long-tail scenarios that closely emulate real-world conditions, and 2) enhanced
controllability, enabling more comprehensive and interactive evaluations. We
achieve this through novel guidance objectives that enhance road progress while
lowering collision and off-road rates. We develop a novel approach to simulate
safety-critical scenarios through an adversarial term in the denoising process,
which allows the adversarial agent to challenge a planner with plausible
maneuvers, while all agents in the scene exhibit reactive and realistic
behaviors. We validate our framework empirically using the NuScenes dataset,
demonstrating improvements in both realism and controllability. These findings
affirm that guided diffusion models provide a robust and versatile foundation
for safety-critical, interactive traffic simulation, extending their utility
across the broader landscape of autonomous driving. For additional resources
and demonstrations, visit our project page at https://safe-sim.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00393">Generative Model-Driven Synthetic Training Image Generation: An Approach to Cognition in Rail Defect Detection. (arXiv:2401.00393v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ferdousi_R/0/1/0/all/0/1">Rahatara Ferdousi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chunsheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">M. Anwar Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Laamarti_F/0/1/0/all/0/1">Fedwa Laamarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">M. Shamim Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Saddik_A/0/1/0/all/0/1">Abdulmotaleb El Saddik</a></p>
<p>Recent advancements in cognitive computing, with the integration of deep
learning techniques, have facilitated the development of intelligent cognitive
systems (ICS). This is particularly beneficial in the context of rail defect
detection, where the ICS would emulate human-like analysis of image data for
defect patterns. Despite the success of Convolutional Neural Networks (CNN) in
visual defect classification, the scarcity of large datasets for rail defect
detection remains a challenge due to infrequent accident events that would
result in defective parts and images. Contemporary researchers have addressed
this data scarcity challenge by exploring rule-based and generative data
augmentation models. Among these, Variational Autoencoder (VAE) models can
generate realistic data without extensive baseline datasets for noise modeling.
This study proposes a VAE-based synthetic image generation technique for rail
defects, incorporating weight decay regularization and image reconstruction
loss to prevent overfitting. The proposed method is applied to create a
synthetic dataset for the Canadian Pacific Railway (CPR) with just 50 real
samples across five classes. Remarkably, 500 synthetic samples are generated
with a minimal reconstruction loss of 0.021. A Visual Transformer (ViT) model
underwent fine-tuning using this synthetic CPR dataset, achieving high accuracy
rates (98%-99%) in classifying the five defect classes. This research offers a
promising solution to the data scarcity challenge in rail defect detection,
showcasing the potential for robust ICS development in this domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00403">Client-wise Modality Selection for Balanced Multi-modal Federated Learning. (arXiv:2401.00403v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yunfeng Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenchao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haozhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_P/0/1/0/all/0/1">Penghui Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Song Guo</a></p>
<p>Selecting proper clients to participate in the iterative federated learning
(FL) rounds is critical to effectively harness a broad range of distributed
datasets. Existing client selection methods simply consider the variability
among FL clients with uni-modal data, however, have yet to consider clients
with multi-modalities. We reveal that traditional client selection scheme in
MFL may suffer from a severe modality-level bias, which impedes the
collaborative exploitation of multi-modal data, leading to insufficient local
data exploration and global aggregation. To tackle this challenge, we propose a
Client-wise Modality Selection scheme for MFL (CMSFed) that can comprehensively
utilize information from each modality via avoiding such client selection bias
caused by modality imbalance. Specifically, in each MFL round, the local data
from different modalities are selectively employed to participate in local
training and aggregation to mitigate potential modality imbalance of the global
model. To approximate the fully aggregated model update in a balanced way, we
introduce a novel local training loss function to enhance the weak modality and
align the divergent feature spaces caused by inconsistent modality adoption
strategies for different clients simultaneously. Then, a modality-level
gradient decoupling method is designed to derive respective submodular
functions to maintain the gradient diversity during the selection progress and
balance MFL according to local modality imbalance in each iteration. Our
extensive experiments showcase the superiority of CMSFed over baselines and its
effectiveness in multi-modal data exploitation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00413">Real-Time FJ/MAC PDE Solvers via Tensorized, Back-Propagation-Free Optical PINN Training. (arXiv:2401.00413v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yequan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xian_X/0/1/0/all/0/1">Xian Xian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xinling Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhixiong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurczveil_G/0/1/0/all/0/1">Geza Kurczveil</a>, <a href="http://arxiv.org/find/cs/1/au:+Beausoleil_R/0/1/0/all/0/1">Raymond G. Beausoleil</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a></p>
<p>Solving partial differential equations (PDEs) numerically often requires huge
computing time, energy cost, and hardware resources in practical applications.
This has limited their applications in many scenarios (e.g., autonomous
systems, supersonic flows) that have a limited energy budget and require near
real-time response. Leveraging optical computing, this paper develops an
on-chip training framework for physics-informed neural networks (PINNs), aiming
to solve high-dimensional PDEs with fJ/MAC photonic power consumption and
ultra-low latency. Despite the ultra-high speed of optical neural networks,
training a PINN on an optical chip is hard due to (1) the large size of
photonic devices, and (2) the lack of scalable optical memory devices to store
the intermediate results of back-propagation (BP). To enable realistic optical
PINN training, this paper presents a scalable method to avoid the BP process.
We also employ a tensor-compressed approach to improve the convergence and
scalability of our optical PINN training. This training framework is designed
with tensorized optical neural networks (TONN) for scalable inference
acceleration and MZI phase-domain tuning for \textit{in-situ} optimization. Our
simulation results of a 20-dim HJB PDE show that our photonic accelerator can
reduce the number of MZIs by a factor of $1.17\times 10^3$, with only $1.36$ J
and $1.15$ s to solve this equation. This is the first real-size optical PINN
training framework that can be applied to solve high-dimensional PDEs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00422">Interpreting the Curse of Dimensionality from Distance Concentration and Manifold Effect. (arXiv:2401.00422v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Dehua Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_Z/0/1/0/all/0/1">Zhipeng Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huayi Wu</a></p>
<p>The characteristics and interpretability of data become more abstract and
complex as the dimensionality increases. Common patterns and relationships that
hold in in low-dimensional space may fail to hold in higher-dimensional space.
This phenomenon leads to a decreasing performance for the regression,
classification or clustering models or algorithms, which is known as curse of
dimensionality. Curse of dimensionality can be attributed to many causes. In
this paper, we first summarize five challenges associated with manipulating
high-dimensional data, and explains the potential causes for the failure of
regression, classification or clustering tasks. Subsequently, we delve into two
major causes of the curse of dimensionality, distance concentration and
manifold effect, by performing theoretical and empirical analyses. The results
demonstrate that nearest neighbor search (NNS) using three typical distance
measurements, Minkowski distance, Chebyshev distance, and cosine distance,
becomes meaningless as the dimensionality increases. Meanwhile, the data
incorporates more redundant features, and the variance contribution of
principal component analysis (PCA) is skewed towards a few dimensions. By
interpreting the causes of the curse of dimensionality, we can better
understand the limitations of current models and algorithms, and drive to
improve the performance of data analysis and machine learning tasks in
high-dimensional space.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00423">MSGNet: Learning Multi-Scale Inter-Series Correlations for Multivariate Time Series Forecasting. (arXiv:2401.00423v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Wanlin Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yuxuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianggen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianshuai Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuankai Wu</a></p>
<p>Multivariate time series forecasting poses an ongoing challenge across
various disciplines. Time series data often exhibit diverse intra-series and
inter-series correlations, contributing to intricate and interwoven
dependencies that have been the focus of numerous studies. Nevertheless, a
significant research gap remains in comprehending the varying inter-series
correlations across different time scales among multiple time series, an area
that has received limited attention in the literature. To bridge this gap, this
paper introduces MSGNet, an advanced deep learning model designed to capture
the varying inter-series correlations across multiple time scales using
frequency domain analysis and adaptive graph convolution. By leveraging
frequency domain analysis, MSGNet effectively extracts salient periodic
patterns and decomposes the time series into distinct time scales. The model
incorporates a self-attention mechanism to capture intra-series dependencies,
while introducing an adaptive mixhop graph convolution layer to autonomously
learn diverse inter-series correlations within each time scale. Extensive
experiments are conducted on several real-world datasets to showcase the
effectiveness of MSGNet. Furthermore, MSGNet possesses the ability to
automatically learn explainable multi-scale inter-series correlations,
exhibiting strong generalization capabilities even when applied to
out-of-distribution samples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00428">Training towards significance with the decorrelated event classifier transformer neural network. (arXiv:2401.00428v1 [hep-ex])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/hep-ex/1/au:+Kim_J/0/1/0/all/0/1">Jaebak Kim</a></p>
<p>Experimental particle physics uses machine learning for many of tasks, where
one application is to classify signal and background events. The classification
can be used to bin an analysis region to enhance the expected significance for
a mass resonance search. In natural language processing, one of the leading
neural network architectures is the transformer. In this work, an event
classifier transformer is proposed to bin an analysis region, in which the
network is trained with special techniques. The techniques developed here can
enhance the significance and reduce the correlation between the network's
output and the reconstructed mass. It is found that this trained network can
perform better than boosted decision trees and feed-forward networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00443">Data-driven Energy Efficiency Modelling in Large-scale Networks: An Expert Knowledge and ML-based Approach. (arXiv:2401.00443v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Lopez_Perez_D/0/1/0/all/0/1">D L&#xf3;pez-P&#xe9;rez</a>, <a href="http://arxiv.org/find/eess/1/au:+Domenico_A/0/1/0/all/0/1">A De Domenico</a>, <a href="http://arxiv.org/find/eess/1/au:+Piovesan_N/0/1/0/all/0/1">N Piovesan</a>, <a href="http://arxiv.org/find/eess/1/au:+Debbah_M/0/1/0/all/0/1">M . Debbah</a></p>
<p>The energy consumption of mobile networks poses a critical challenge.
Mitigating this concern necessitates the deployment and optimization of network
energy-saving solutions, such as carrier shutdown, to dynamically manage
network resources. Traditional optimization approaches encounter complexity due
to factors like the large number of cells, stochastic traffic, channel
variations, and intricate trade-offs. This paper introduces the simulated
reality of communication networks (SRCON) framework, a novel, data-driven
modeling paradigm that harnesses live network data and employs a blend of
machine learning (ML)- and expert-based models. These mix of models accurately
characterizes the functioning of network components, and predicts network
energy efficiency and user equipment (UE) quality of service for any energy
carrier shutdown configuration in a specific network. Distinguishing itself
from existing methods, SRCON eliminates the reliance on expensive expert
knowledge, drive testing, or incomplete maps for predicting network
performance. This paper details the pipeline employed by SRCON to decompose the
large network energy efficiency modeling problem into ML and expert-based
submodels. It demonstrates how, by embracing stochasticity, and carefully
crafting the relationship between such submodels, the overall computational
complexity can be reduced and prediction accuracy enhanced. Results derived
from real network data underscore the paradigm shift introduced by SRCON,
showcasing significant gains over a state-of-the art method used by a operator
for network energy efficiency modeling. The reliability of this local,
data-driven modeling of the network proves to be a key asset for network
energy-saving optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00445">Energy-Efficient Power Control for Multiple-Task Split Inference in UAVs: A Tiny Learning-Based Approach. (arXiv:2401.00445v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chenxi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_M/0/1/0/all/0/1">Min Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1">Tianshu Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiandong Li</a></p>
<p>The limited energy and computing resources of unmanned aerial vehicles (UAVs)
hinder the application of aerial artificial intelligence. The utilization of
split inference in UAVs garners significant attention due to its effectiveness
in mitigating computing and energy requirements. However, achieving
energy-efficient split inference in UAVs remains complex considering of various
crucial parameters such as energy level and delay constraints, especially
involving multiple tasks. In this paper, we present a two-timescale approach
for energy minimization in split inference, where discrete and continuous
variables are segregated into two timescales to reduce the size of action space
and computational complexity. This segregation enables the utilization of tiny
reinforcement learning (TRL) for selecting discrete transmission modes for
sequential tasks. Moreover, optimization programming (OP) is embedded between
TRL's output and reward function to optimize the continuous transmit power.
Specifically, we replace the optimization of transmit power with that of
transmission time to decrease the computational complexity of OP since we
reveal that energy consumption monotonically decreases with increasing
transmission time. The replacement significantly reduces the feasible region
and enables a fast solution according to the closed-form expression for optimal
transmit power. Simulation results show that the proposed algorithm can achieve
a higher probability of successful task completion with lower energy
consumption.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00448">Beyond Chinchilla-Optimal: Accounting for Inference in Language Model Scaling Laws. (arXiv:2401.00448v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sardana_N/0/1/0/all/0/1">Nikhil Sardana</a>, <a href="http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1">Jonathan Frankle</a></p>
<p>Large language model (LLM) scaling laws are empirical formulas that estimate
changes in model quality as a result of increasing parameter count and training
data. However, these formulas, including the popular DeepMind Chinchilla
scaling laws, neglect to include the cost of inference. We modify the
Chinchilla scaling laws to calculate the optimal LLM parameter count and
pre-training data size to train and deploy a model of a given quality and
inference demand. We conduct our analysis both in terms of a compute budget and
real-world costs and find that LLM researchers expecting reasonably large
inference demand (~1B requests) should train models smaller and longer than
Chinchilla-optimal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00466">Online Symbolic Music Alignment with Offline Reinforcement Learning. (arXiv:2401.00466v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peter_S/0/1/0/all/0/1">Silvan David Peter</a></p>
<p>Symbolic Music Alignment is the process of matching performed MIDI notes to
corresponding score notes. In this paper, we introduce a reinforcement learning
(RL)-based online symbolic music alignment technique. The RL agent - an
attention-based neural network - iteratively estimates the current score
position from local score and performance contexts. For this symbolic alignment
task, environment states can be sampled exhaustively and the reward is dense,
rendering a formulation as a simplified offline RL problem straightforward. We
evaluate the trained agent in three ways. First, in its capacity to identify
correct score positions for sampled test contexts; second, as the core
technique of a complete algorithm for symbolic online note-wise alignment; and
finally, as a real-time symbolic score follower. We further investigate the
pitch-based score and performance representations used as the agent's inputs.
To this end, we develop a second model, a two-step Dynamic Time Warping
(DTW)-based offline alignment algorithm leveraging the same input
representation. The proposed model outperforms a state-of-the-art reference
model of offline symbolic music alignment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00490">Kernel Density Estimation for Multiclass Quantification. (arXiv:2401.00490v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_P/0/1/0/all/0/1">Pablo Gonz&#xe1;lez</a>, <a href="http://arxiv.org/find/cs/1/au:+Coz_J/0/1/0/all/0/1">Juan Jos&#xe9; del Coz</a></p>
<p>Several disciplines, like the social sciences, epidemiology, sentiment
analysis, or market research, are interested in knowing the distribution of the
classes in a population rather than the individual labels of the members
thereof. Quantification is the supervised machine learning task concerned with
obtaining accurate predictors of class prevalence, and to do so particularly in
the presence of label shift. The distribution-matching (DM) approaches
represent one of the most important families among the quantification methods
that have been proposed in the literature so far. Current DM approaches model
the involved populations by means of histograms of posterior probabilities. In
this paper, we argue that their application to the multiclass setting is
suboptimal since the histograms become class-specific, thus missing the
opportunity to model inter-class information that may exist in the data. We
propose a new representation mechanism based on multivariate densities that we
model via kernel density estimation (KDE). The experiments we have carried out
show our method, dubbed KDEy, yields superior quantification performance with
respect to previous DM approaches. We also investigate the KDE-based
representation within the maximum likelihood framework and show KDEy often
shows superior performance with respect to the expectation-maximization method
for quantification, arguably the strongest contender in the quantification
arena to date.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00496">SAR-RARP50: Segmentation of surgical instrumentation and Action Recognition on Robot-Assisted Radical Prostatectomy Challenge. (arXiv:2401.00496v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Psychogyios_D/0/1/0/all/0/1">Dimitrios Psychogyios</a>, <a href="http://arxiv.org/find/cs/1/au:+Colleoni_E/0/1/0/all/0/1">Emanuele Colleoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Amsterdam_B/0/1/0/all/0/1">Beatrice Van Amsterdam</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chih-Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shu-Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuchong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1">Fucang Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_B/0/1/0/all/0/1">Baosheng Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guotai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Boels_M/0/1/0/all/0/1">Maxence Boels</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1">Jiayu Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sparks_R/0/1/0/all/0/1">Rachel Sparks</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_P/0/1/0/all/0/1">Prokar Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Granados_A/0/1/0/all/0/1">Alejandro Granados</a>, <a href="http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengya Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">An Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yanan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Long Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Hongliang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamada_A/0/1/0/all/0/1">Atsushi Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Harai_Y/0/1/0/all/0/1">Yuriko Harai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_Y/0/1/0/all/0/1">Yuto Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1">Kazuyuki Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Simoens_J/0/1/0/all/0/1">Jente Simoens</a>, <a href="http://arxiv.org/find/cs/1/au:+DeBacker_P/0/1/0/all/0/1">Pieter DeBacker</a>, <a href="http://arxiv.org/find/cs/1/au:+Cisternino_F/0/1/0/all/0/1">Francesco Cisternino</a>, <a href="http://arxiv.org/find/cs/1/au:+Furnari_G/0/1/0/all/0/1">Gabriele Furnari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mottrie_A/0/1/0/all/0/1">Alex Mottrie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraguti_F/0/1/0/all/0/1">Federica Ferraguti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondo_S/0/1/0/all/0/1">Satoshi Kondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasai_S/0/1/0/all/0/1">Satoshi Kasai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirasawa_K/0/1/0/all/0/1">Kousuke Hirasawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soohee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seung Hyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyu Eun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_H/0/1/0/all/0/1">Hyoun-Joong Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1">Kui Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1">Shan An</a>, <a href="http://arxiv.org/find/cs/1/au:+Krell_S/0/1/0/all/0/1">Stefanie Krell</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodenstedt_S/0/1/0/all/0/1">Sebastian Bodenstedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayobi_N/0/1/0/all/0/1">Nicolas Ayobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1">Alejandra Perez</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1">Santiago Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Puentes_J/0/1/0/all/0/1">Juanita Puentes</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohareri_O/0/1/0/all/0/1">Omid Mohareri</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a></p>
<p>Surgical tool segmentation and action recognition are fundamental building
blocks in many computer-assisted intervention applications, ranging from
surgical skills assessment to decision support systems. Nowadays,
learning-based action recognition and segmentation approaches outperform
classical methods, relying, however, on large, annotated datasets. Furthermore,
action recognition and tool segmentation algorithms are often trained and make
predictions in isolation from each other, without exploiting potential
cross-task relationships. With the EndoVis 2022 SAR-RARP50 challenge, we
release the first multimodal, publicly available, in-vivo, dataset for surgical
action recognition and semantic instrumentation segmentation, containing 50
suturing video segments of Robotic Assisted Radical Prostatectomy (RARP). The
aim of the challenge is twofold. First, to enable researchers to leverage the
scale of the provided dataset and develop robust and highly accurate
single-task action recognition and tool segmentation approaches in the surgical
domain. Second, to further explore the potential of multitask-based learning
approaches and determine their comparative advantage against their single-task
counterparts. A total of 12 teams participated in the challenge, contributing 7
action recognition methods, 9 instrument segmentation techniques, and 4
multitask approaches that integrated both action recognition and instrument
segmentation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00503">Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI. (arXiv:2401.00503v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1">Dipankar Sarkar</a></p>
<p>This paper aims to introduce and analyze the Viz system in a comprehensive
way, a novel system architecture that integrates Quantized Low-Rank Adapters
(QLoRA) to fine-tune large language models (LLM) within a legally compliant and
resource efficient marketplace. Viz represents a significant contribution to
the field of artificial intelligence, particularly in addressing the challenges
of computational efficiency, legal compliance, and economic sustainability in
the utilization and monetization of LLMs. The paper delineates the scholarly
discourse and developments that have informed the creation of Viz, focusing
primarily on the advancements in LLM models, copyright issues in AI training
(NYT case, 2023), and the evolution of model fine-tuning techniques,
particularly low-rank adapters and quantized low-rank adapters, to create a
sustainable and economically compliant framework for LLM utilization. The
economic model it proposes benefits content creators, AI developers, and
end-users, delineating a harmonious integration of technology, economy, and
law, offering a comprehensive solution to the complex challenges of today's AI
landscape.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00521">Multi-spatial Multi-temporal Air Quality Forecasting with Integrated Monitoring and Reanalysis Data. (arXiv:2401.00521v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuxiao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiaodan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jinyue Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuntian Chen</a></p>
<p>Accurate air quality forecasting is crucial for public health, environmental
monitoring and protection, and urban planning. However, existing methods fail
to effectively utilize multi-scale information, both spatially and temporally.
Spatially, there is a lack of integration between individual monitoring
stations and city-wide scales. Temporally, the periodic nature of air quality
variations is often overlooked or inadequately considered. To address these
limitations, we present a novel Multi-spatial Multi-temporal air quality
forecasting method based on Graph Convolutional Networks and Gated Recurrent
Units (M2G2), bridging the gap in air quality forecasting across spatial and
temporal scales. The proposed framework consists of two modules: Multi-scale
Spatial GCN (MS-GCN) for spatial information fusion and Multi-scale Temporal
GRU(MT-GRU) for temporal information integration. In the spatial dimension, the
MS-GCN module employs a bidirectional learnable structure and a residual
structure, enabling comprehensive information exchange between individual
monitoring stations and the city-scale graph. Regarding the temporal dimension,
the MT-GRU module adaptively combines information from different temporal
scales through parallel hidden states. Leveraging meteorological indicators and
four air quality indicators, we present comprehensive comparative analyses and
ablation experiments, showcasing the higher accuracy of M2G2 in comparison to
nine currently available advanced approaches across all aspects. The
improvements of M2G2 over the second-best method on RMSE of the 24h/48h/72h are
as follows: PM2.5: (7.72%, 6.67%, 10.45%); PM10: (6.43%, 5.68%, 7.73%); NO2:
(5.07%, 7.76%, 16.60%); O3: (6.46%, 6.86%, 9.79%). Furthermore, we demonstrate
the effectiveness of each module of M2G2 by ablation study.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00524">Effect of Optimizer, Initializer, and Architecture of Hypernetworks on Continual Learning from Demonstration. (arXiv:2401.00524v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Auddy_S/0/1/0/all/0/1">Sayantan Auddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergner_S/0/1/0/all/0/1">Sebastian Bergner</a>, <a href="http://arxiv.org/find/cs/1/au:+Piater_J/0/1/0/all/0/1">Justus Piater</a></p>
<p>In continual learning from demonstration (CLfD), a robot learns a sequence of
real-world motion skills continually from human demonstrations. Recently,
hypernetworks have been successful in solving this problem. In this paper, we
perform an exploratory study of the effects of different optimizers,
initializers, and network architectures on the continual learning performance
of hypernetworks for CLfD. Our results show that adaptive learning rate
optimizers work well, but initializers specially designed for hypernetworks
offer no advantages for CLfD. We also show that hypernetworks that are capable
of stable trajectory predictions are robust to different network architectures.
Our open-source code is available at
https://github.com/sebastianbergner/ExploringCLFD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00529">GraphGPT: Graph Learning with Generative Pre-trained Transformers. (arXiv:2401.00529v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qifang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1">Weidong Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaoxiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hong Liu</a></p>
<p>We introduce \textit{GraphGPT}, a novel model for Graph learning by
self-supervised Generative Pre-training Transformers. Our model transforms each
graph or sampled subgraph into a sequence of tokens representing the node, edge
and attributes reversibly using the Eulerian path first. Then we feed the
tokens into a standard transformer decoder and pre-train it with the
next-token-prediction (NTP) task. Lastly, we fine-tune the GraphGPT model with
the supervised tasks. This intuitive, yet effective model achieves superior or
close results to the state-of-the-art methods for the graph-, edge- and
node-level tasks on the large scale molecular dataset PCQM4Mv2, the
protein-protein association dataset ogbl-ppa and the ogbn-proteins dataset from
the Open Graph Benchmark (OGB). Furthermore, the generative pre-training
enables us to train GraphGPT up to 400M+ parameters with consistently
increasing performance, which is beyond the capability of GNNs and previous
graph transformers. The source code and pre-trained checkpoints will be
released soon\footnote{\url{https://github.com/alibaba/graph-gpt}} to pave the
way for the graph foundation model research, and also to assist the scientific
discovery in pharmaceutical, chemistry, material and bio-informatics domains,
etc.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00532">On the Necessity of Metalearning: Learning Suitable Parameterizations for Learning Processes. (arXiv:2401.00532v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hamidi_M/0/1/0/all/0/1">Massinissa Hamidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Osmani_A/0/1/0/all/0/1">Aomar Osmani</a></p>
<p>In this paper we will discuss metalearning and how we can go beyond the
current classical learning paradigm. We will first address the importance of
inductive biases in the learning process and what is at stake: the quantities
of data necessary to learn. We will subsequently see the importance of choosing
suitable parameterizations to end up with well-defined learning processes.
Especially since in the context of real-world applications, we face numerous
biases due, e.g., to the specificities of sensors, the heterogeneity of data
sources, the multiplicity of points of view, etc. This will lead us to the idea
of exploiting the structuring of the concepts to be learned in order to
organize the learning process that we published previously. We conclude by
discussing the perspectives around parameter-tying schemes and the emergence of
universal aspects in the models thus learned.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00534">Financial Time-Series Forecasting: Towards Synergizing Performance And Interpretability Within a Hybrid Machine Learning Approach. (arXiv:2401.00534v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kexin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Chufeng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Bin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1">Danqing Ma</a></p>
<p>In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered
substantial attention due to its potential impact on financial markets and
investment strategies. This paper propose a comparative study on hybrid machine
learning algorithms and leverage on enhancing model interpretability.
Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM),
decision tree regressors are introduced. Through the grounded experiments, we
observe linear regressor achieves the best performance among candidate models.
For the interpretability, we carry out a systematic overview on the
preprocessing techniques of time-series statistics, including decomposition,
auto-correlational function, exponential triple forecasting, which aim to
excavate latent relations and complex patterns appeared in the financial
time-series forecasting. We believe this work may derive more attention and
inspire more researches in the realm of time-series analysis and its realistic
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00544">A Reliable Knowledge Processing Framework for Combustion Science using Foundation Models. (arXiv:2401.00544v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1">Vansh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_V/0/1/0/all/0/1">Venkat Raman</a></p>
<p>This research explores the integration of large language models (LLMs) into
scientific data assimilation, focusing on combustion science as a case study.
Leveraging foundational models integrated with Retrieval-Augmented Generation
(RAG) framework, the study introduces an approach to process diverse combustion
research data, spanning experimental studies, simulations, and literature. The
multifaceted nature of combustion research emphasizes the critical role of
knowledge processing in navigating and extracting valuable information from a
vast and diverse pool of sources. The developed approach minimizes
computational and economic expenses while optimizing data privacy and accuracy.
It incorporates prompt engineering and offline open-source LLMs, offering user
autonomy in selecting base models. The study provides a thorough examination of
text segmentation strategies, conducts comparative studies between LLMs, and
explores various optimized prompts to demonstrate the effectiveness of the
framework. By incorporating an external database, the framework outperforms a
conventional LLM in generating accurate responses and constructing robust
arguments. Additionally, the study delves into the investigation of optimized
prompt templates for the purpose of efficient extraction of scientific
literature. The research addresses concerns related to hallucinations and false
research articles by introducing a custom workflow developed with a detection
algorithm to filter out inaccuracies. Despite identified areas for improvement,
the framework consistently delivers accurate domain-specific responses with
minimal human oversight. The prompt-agnostic approach introduced holds promise
for future deliberations. The study underscores the significance of integrating
LLMs and knowledge processing techniques in scientific research, providing a
foundation for advancements in data assimilation and utilization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00546">AllSpark: a multimodal spatiotemporal general model. (arXiv:2401.00546v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1">Run Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiujun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">YanSheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dapeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shizhong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haifeng Li</a></p>
<p>For a long time, due to the high heterogeneity in structure and semantics
among various spatiotemporal modal data, the joint interpretation of multimodal
spatiotemporal data has been an extremely challenging problem. The primary
challenge resides in striking a trade-off between the cohesion and autonomy of
diverse modalities, and this trade-off exhibits a progressively nonlinear
nature as the number of modalities expands. We introduce the Language as
Reference Framework (LaRF), a fundamental principle for constructing a
multimodal unified model, aiming to strike a trade-off between the cohesion and
autonomy among different modalities. We propose a multimodal spatiotemporal
general artificial intelligence model, called AllSpark. Our model integrates
thirteen different modalities into a unified framework, including 1D (text,
code), 2D (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs,
trajectory, oblique photography), and 3D (point clouds, videos) modalities. To
achieve modal cohesion, AllSpark uniformly maps diverse modal features to the
language modality. In addition, we design modality-specific prompts to guide
multi-modal large language models in accurately perceiving multimodal data. To
maintain modality autonomy, AllSpark introduces modality-specific encoders to
extract the tokens of various spatiotemporal modalities. And modal bridge is
employed to achieve dimensional projection from each modality to the language
modality. Finally, observing a gap between the model's interpretation and
downstream tasks, we designed task heads to enhance the model's generalization
capability on specific downstream tasks. Experiments indicate that AllSpark
achieves competitive accuracy in modalities such as RGB and trajectory compared
to state-of-the-art models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00547">On Learning for Ambiguous Chance Constrained Problems. (arXiv:2401.00547v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madhusudanarao_A/0/1/0/all/0/1">A Ch Madhusudanarao</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rahul Singh</a></p>
<p>We study chance constrained optimization problems $\min_x f(x)$ s.t.
$P(\left\{ \theta: g(x,\theta)\le 0 \right\})\ge 1-\epsilon$ where $\epsilon\in
(0,1)$ is the violation probability, when the distribution $P$ is not known to
the decision maker (DM). When the DM has access to a set of distributions
$\mathcal{U}$ such that $P$ is contained in $\mathcal{U}$, then the problem is
known as the ambiguous chance-constrained problem \cite{erdougan2006ambiguous}.
We study ambiguous chance-constrained problem for the case when $\mathcal{U}$
is of the form $\left\{\mu:\frac{\mu (y)}{\nu(y)}\leq C, \forall y\in\Theta,
\mu(y)\ge 0\right\}$, where $\nu$ is a ``reference distribution.'' We show that
in this case the original problem can be ``well-approximated'' by a sampled
problem in which $N$ i.i.d. samples of $\theta$ are drawn from $\nu$, and the
original constraint is replaced with $g(x,\theta_i)\le 0,~i=1,2,\ldots,N$. We
also derive the sample complexity associated with this approximation, i.e., for
$\epsilon,\delta&gt;0$ the number of samples which must be drawn from $\nu$ so
that with a probability greater than $1-\delta$ (over the randomness of $\nu$),
the solution obtained by solving the sampled program yields an
$\epsilon$-feasible solution for the original chance constrained problem.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00579">Exploring the Effectiveness of Instruction Tuning in Biomedical Language Processing. (arXiv:2401.00579v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rohanian_O/0/1/0/all/0/1">Omid Rohanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nouriborji_M/0/1/0/all/0/1">Mohammadmahdi Nouriborji</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1">David A. Clifton</a></p>
<p>Large Language Models (LLMs), particularly those similar to ChatGPT, have
significantly influenced the field of Natural Language Processing (NLP). While
these models excel in general language tasks, their performance in
domain-specific downstream tasks such as biomedical and clinical Named Entity
Recognition (NER), Relation Extraction (RE), and Medical Natural Language
Inference (NLI) is still evolving. In this context, our study investigates the
potential of instruction tuning for biomedical language processing, applying
this technique to two general LLMs of substantial scale. We present a
comprehensive, instruction-based model trained on a dataset that consists of
approximately $200,000$ instruction-focused samples. This dataset represents a
carefully curated compilation of existing data, meticulously adapted and
reformatted to align with the specific requirements of our instruction-based
tasks. This initiative represents an important step in utilising such models to
achieve results on par with specialised encoder-only models like BioBERT and
BioClinicalBERT for various classical biomedical NLP tasks. Our work includes
an analysis of the dataset's composition and its impact on model performance,
providing insights into the intricacies of instruction tuning. By sharing our
codes, models, and the distinctively assembled instruction-based dataset, we
seek to encourage ongoing research and development in this area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00582">An Analysis of Embedding Layers and Similarity Scores using Siamese Neural Networks. (arXiv:2401.00582v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bingi_Y/0/1/0/all/0/1">Yash Bingi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yiqiao Yin</a></p>
<p>Large Lanugage Models (LLMs) are gaining increasing popularity in a variety
of use cases, from language understanding and writing to assistance in
application development. One of the most important aspects for optimal
funcionality of LLMs is embedding layers. Word embeddings are distributed
representations of words in a continuous vector space. In the context of LLMs,
words or tokens from the input text are transformed into high-dimensional
vectors using unique algorithms specific to the model. Our research examines
the embedding algorithms from leading companies in the industry, such as
OpenAI, Google's PaLM, and BERT. Using medical data, we have analyzed
similarity scores of each embedding layer, observing differences in performance
among each algorithm. To enhance each model and provide an additional encoding
layer, we also implemented Siamese Neural Networks. After observing changes in
performance with the addition of the model, we measured the carbon footage per
epoch of training. The carbon footprint associated with large language models
(LLMs) is a significant concern, and should be taken into consideration when
selecting algorithms for a variety of use cases. Overall, our research compared
the accuracy different, leading embedding algorithms and their carbon footage,
allowing for a holistic review of each embedding algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00583">Improving the Privacy and Practicality of Objective Perturbation for Differentially Private Linear Learners. (arXiv:2401.00583v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Redberg_R/0/1/0/all/0/1">Rachel Redberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Koskela_A/0/1/0/all/0/1">Antti Koskela</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Xiang Wang</a></p>
<p>In the arena of privacy-preserving machine learning, differentially private
stochastic gradient descent (DP-SGD) has outstripped the objective perturbation
mechanism in popularity and interest. Though unrivaled in versatility, DP-SGD
requires a non-trivial privacy overhead (for privately tuning the model's
hyperparameters) and a computational complexity which might be extravagant for
simple models such as linear and logistic regression. This paper revamps the
objective perturbation mechanism with tighter privacy analyses and new
computational tools that boost it to perform competitively with DP-SGD on
unconstrained convex generalized linear problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00588">Fairness in Serving Large Language Models. (arXiv:2401.00588v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sheng_Y/0/1/0/all/0/1">Ying Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Shiyi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dacheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Banghua Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhuohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_D/0/1/0/all/0/1">Danyang Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a></p>
<p>High-demand LLM inference services (e.g., ChatGPT and BARD) support a wide
range of requests from short chat conversations to long document reading. To
ensure that all client requests are processed fairly, most major LLM inference
services have request rate limits, to ensure that no client can dominate the
request queue. However, this rudimentary notion of fairness also results in
under-utilization of the resources and poor client experience when there is
spare capacity. While there is a rich literature on fair scheduling, serving
LLMs presents new challenges due to their unpredictable request lengths and
their unique batching characteristics on parallel accelerators. This paper
introduces the definition of LLM serving fairness based on a cost function that
accounts for the number of input and output tokens processed. To achieve
fairness in serving, we propose a novel scheduling algorithm, the Virtual Token
Counter (VTC), a fair scheduler based on the continuous batching mechanism. We
prove a 2x tight upper bound on the service difference between two backlogged
clients, adhering to the requirement of work-conserving. Through extensive
experiments, we demonstrate the superior performance of VTC in ensuring
fairness, especially in contrast to other baseline methods, which exhibit
shortcomings under various conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00599">Sub-sampling of NMR Correlation and Exchange Experiments. (arXiv:2401.00599v1 [physics.chem-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Beckmann_J/0/1/0/all/0/1">Julian B. B. Beckmann</a>, <a href="http://arxiv.org/find/physics/1/au:+Mantle_M/0/1/0/all/0/1">Mick D. Mantle</a>, <a href="http://arxiv.org/find/physics/1/au:+Sederman_A/0/1/0/all/0/1">Andrew J. Sederman</a>, <a href="http://arxiv.org/find/physics/1/au:+Gladden_L/0/1/0/all/0/1">Lynn F. Gladden</a></p>
<p>Sub-sampling is applied to simulated $T_1$-$D$ NMR signals and its influence
on inversion performance is evaluated. For this different levels of
sub-sampling were employed ranging from the fully sampled signal down to only
less than two percent of the original data points. This was combined with
multiple sample schemes including fully random sampling, truncation and a
combination of both. To compare the performance of different inversion
algorithms, the so-generated sub-sampled signals were inverted using Tikhonov
regularization, modified total generalized variation (MTGV) regularization,
deep learning and a combination of deep learning and Tikhonov regularization.
Further, the influence of the chosen cost function on the relative inversion
performance was investigated. Overall, it could be shown that for a vast
majority of instances, deep learning clearly outperforms regularization based
inversion methods, if the signal is fully or close to fully sampled. However,
in the case of significantly sub-sampled signals regularization yields better
inversion performance than its deep learning counterpart with MTGV clearly
prevailing over Tikhonov. Additionally, fully random sampling could be
identified as the best overall sampling scheme independent of the inversion
method. Finally, it could also be shown that the choice of cost function does
vastly influence the relative rankings of the tested inversion algorithms
highlighting the importance of choosing the cost function accordingly to
experimental intentions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00611">A Compact Representation for Bayesian Neural Networks By Removing Permutation Symmetry. (arXiv:2401.00611v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Xiao_T/0/1/0/all/0/1">Tim Z. Xiao</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Bamler_R/0/1/0/all/0/1">Robert Bamler</a></p>
<p>Bayesian neural networks (BNNs) are a principled approach to modeling
predictive uncertainties in deep learning, which are important in
safety-critical applications. Since exact Bayesian inference over the weights
in a BNN is intractable, various approximate inference methods exist, among
which sampling methods such as Hamiltonian Monte Carlo (HMC) are often
considered the gold standard. While HMC provides high-quality samples, it lacks
interpretable summary statistics because its sample mean and variance is
meaningless in neural networks due to permutation symmetry. In this paper, we
first show that the role of permutations can be meaningfully quantified by a
number of transpositions metric. We then show that the recently proposed
rebasin method allows us to summarize HMC samples into a compact representation
that provides a meaningful explicit uncertainty estimate for each weight in a
neural network, thus unifying sampling methods with variational inference. We
show that this compact representation allows us to compare trained BNNs
directly in weight space across sampling methods and variational inference, and
to efficiently prune neural networks trained without explicit Bayesian
frameworks by exploiting uncertainty estimates from HMC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00622">Federated Class-Incremental Learning with New-Class Augmented Self-Distillation. (arXiv:2401.00622v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tianliu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Sheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Min Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1">Bo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xuefeng Jiang</a></p>
<p>Federated Learning (FL) enables collaborative model training among
participants while guaranteeing the privacy of raw data. Mainstream FL
methodologies overlook the dynamic nature of real-world data, particularly its
tendency to grow in volume and diversify in classes over time. This oversight
results in FL methods suffering from catastrophic forgetting, where models
inadvertently discard previously learned information upon assimilating new
data. In response to this challenge, we propose a novel Federated
Class-Incremental Learning (FCIL) method, named FCIL with New-Class Augmented
Self-Distillation (FedNASD). FedNASD combines new class scores, which are
inferred from current models, with historical models' predictions. Based on the
combined past and present knowledge, it incorporates self-distillation over
models on clients, aiming to achieve effective knowledge transfer from
historical models to current models. Theoretical analysis demonstrates that
FedNASD is equivalent to modeling old class scores as conditional probabilities
in the absence of new classes. Additionally, it reconciles the predictions of
new classes with current models to refine the conditional probabilities of
historical scores where new classes do not exist. Empirical experiments
demonstrate the superiority of FedNASD over four baseline algorithms in
reducing the average forgetting rate and boosting global accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00625">Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models. (arXiv:2401.00625v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_G/0/1/0/all/0/1">Guangji Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1">Zheng Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1">Chen Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiaying Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Nan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Tingwei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Ziyang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mengdan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yue Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a></p>
<p>The burgeoning field of Large Language Models (LLMs), exemplified by
sophisticated models like OpenAI's ChatGPT, represents a significant
advancement in artificial intelligence. These models, however, bring forth
substantial challenges in the high consumption of computational, memory,
energy, and financial resources, especially in environments with limited
resource capabilities. This survey aims to systematically address these
challenges by reviewing a broad spectrum of techniques designed to enhance the
resource efficiency of LLMs. We categorize methods based on their optimization
focus: computational, memory, energy, financial, and network resources and
their applicability across various stages of an LLM's lifecycle, including
architecture design, pretraining, finetuning, and system design. Additionally,
the survey introduces a nuanced categorization of resource efficiency
techniques by their specific resource types, which uncovers the intricate
relationships and mappings between various resources and corresponding
optimization techniques. A standardized set of evaluation metrics and datasets
is also presented to facilitate consistent and fair comparisons across
different models and techniques. By offering a comprehensive overview of the
current sota and identifying open research avenues, this survey serves as a
foundational reference for researchers and practitioners, aiding them in
developing more sustainable and efficient LLMs in a rapidly evolving landscape.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00629">Adversarially Trained Actor Critic for offline CMDPs. (arXiv:2401.00629v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Honghao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xiyue Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Arnob Ghosh</a></p>
<p>We propose a Safe Adversarial Trained Actor Critic (SATAC) algorithm for
offline reinforcement learning (RL) with general function approximation in the
presence of limited data coverage. SATAC operates as a two-player Stackelberg
game featuring a refined objective function. The actor (leader player)
optimizes the policy against two adversarially trained value critics (follower
players), who focus on scenarios where the actor's performance is inferior to
the behavior policy. Our framework provides both theoretical guarantees and a
robust deep-RL implementation. Theoretically, we demonstrate that when the
actor employs a no-regret optimization oracle, SATAC achieves two guarantees:
(i) For the first time in the offline RL setting, we establish that SATAC can
produce a policy that outperforms the behavior policy while maintaining the
same level of safety, which is critical to designing an algorithm for offline
RL. (ii) We demonstrate that the algorithm guarantees policy improvement across
a broad range of hyperparameters, indicating its practical robustness.
Additionally, we offer a practical version of SATAC and compare it with
existing state-of-the-art offline safe-RL algorithms in continuous control
environments. SATAC outperforms all baselines across a range of tasks, thus
validating the theoretical performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00633">On Discprecncies between Perturbation Evaluations of Graph Neural Network Attributions. (arXiv:2401.00633v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rezaei_R/0/1/0/all/0/1">Razieh Rezaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dizaji_A/0/1/0/all/0/1">Alireza Dizaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Khakzar_A/0/1/0/all/0/1">Ashkan Khakzar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazi_A/0/1/0/all/0/1">Anees Kazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a></p>
<p>Neural networks are increasingly finding their way into the realm of graphs
and modeling relationships between features. Concurrently graph neural network
explanation approaches are being invented to uncover relationships between the
nodes of the graphs. However, there is a disparity between the existing
attribution methods, and it is unclear which attribution to trust. Therefore
research has introduced evaluation experiments that assess them from different
perspectives. In this work, we assess attribution methods from a perspective
not previously explored in the graph domain: retraining. The core idea is to
retrain the network on important (or not important) relationships as identified
by the attributions and evaluate how networks can generalize based on these
relationships. We reformulate the retraining framework to sidestep issues
lurking in the previous formulation and propose guidelines for correct
analysis. We run our analysis on four state-of-the-art GNN attribution methods
and five synthetic and real-world graph classification datasets. The analysis
reveals that attributions perform variably depending on the dataset and the
network. Most importantly, we observe that the famous GNNExplainer performs
similarly to an arbitrary designation of edge importance. The study concludes
that the retraining evaluation cannot be used as a generalized benchmark and
recommends it as a toolset to evaluate attributions on a specifically addressed
network, dataset, and sparsity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00658">Point Cloud in the Air. (arXiv:2401.00658v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1">Yulin Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_C/0/1/0/all/0/1">Chenghong Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Li Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qianqian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhaoyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz Gunduz</a></p>
<p>Acquisition and processing of point clouds (PCs) is a crucial enabler for
many emerging applications reliant on 3D spatial data, such as robot
navigation, autonomous vehicles, and augmented reality. In most scenarios, PCs
acquired by remote sensors must be transmitted to an edge server for fusion,
segmentation, or inference. Wireless transmission of PCs not only puts on
increased burden on the already congested wireless spectrum, but also confronts
a unique set of challenges arising from the irregular and unstructured nature
of PCs. In this paper, we meticulously delineate these challenges and offer a
comprehensive examination of existing solutions while candidly acknowledging
their inherent limitations. In response to these intricacies, we proffer four
pragmatic solution frameworks, spanning advanced techniques, hybrid schemes,
and distributed data aggregation approaches. In doing so, our goal is to chart
a path toward efficient, reliable, and low-latency wireless PC transmission.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00664">New Sample Complexity Bounds for (Regularized) Sample Average Approximation in Several Heavy-Tailed, Non-Lipschitzian, and High-Dimensional Cases. (arXiv:2401.00664v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Liu_H/0/1/0/all/0/1">Hongcheng Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Tong_J/0/1/0/all/0/1">Jindong Tong</a></p>
<p>We study the sample complexity of sample average approximation (SAA) and its
simple variations, referred to as the regularized SAA (RSAA), in solving convex
and strongly convex stochastic programming (SP) problems under
heavy-tailed-ness, non-Lipschitz-ness, and/or high dimensionality. The presence
of such irregularities underscores critical vacua in the literature. In
response, this paper presents three sets of results: First, we show that the
(R)SAA is effective even if the objective function is not necessarily Lipschitz
and the underlying distribution admits some bounded central moments only at
(near-)optimal solutions. Second, when the SP's objective function is the sum
of a smooth term and a Lipschitz term, we prove that the (R)SAA's sample
complexity is completely independent from any complexity measures (e.g., the
covering number) of the feasible region. Third, we explicate the (R)SAA's
sample complexities with regard to the dependence on dimensionality $d$: When
some $p$th ($p\geq 2$) central moment of the underlying distribution is
bounded, we show that the required sample size grows at a rate no worse than
$\mathcal O\left(p d^{2/p}\right)$ under any one of the three structural
assumptions: (i) strong convexity w.r.t. the $q$-norm ($q\geq 1$); (ii) the
combination of restricted strong convexity and sparsity; and (iii) a
dimension-insensitive $q$-norm of an optimal solution. In both cases of (i) and
(iii), it is further required that $p\leq q/(q-1)$. As a direct implication,
the (R)SAA's complexity becomes (poly-)logarithmic in $d$, whenever $p\geq
c\cdot \ln d$ is admissible for some constant $c&gt;0$. These new results deviate
from the SAA's typical sample complexities that grow polynomially with $d$.
Part of our proof is based on the average-replace-one (RO) stability, which
appears to be novel for the (R)SAA's analyses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00676">Digger: Detecting Copyright Content Mis-usage in Large Language Model Training. (arXiv:2401.00676v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haodong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_G/0/1/0/all/0/1">Gelei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kailong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuekang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guoai Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guosheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a></p>
<p>Pre-training, which utilizes extensive and varied datasets, is a critical
factor in the success of Large Language Models (LLMs) across numerous
applications. However, the detailed makeup of these datasets is often not
disclosed, leading to concerns about data security and potential misuse. This
is particularly relevant when copyrighted material, still under legal
protection, is used inappropriately, either intentionally or unintentionally,
infringing on the rights of the authors.
</p>
<p>In this paper, we introduce a detailed framework designed to detect and
assess the presence of content from potentially copyrighted books within the
training datasets of LLMs. This framework also provides a confidence estimation
for the likelihood of each content sample's inclusion. To validate our
approach, we conduct a series of simulated experiments, the results of which
affirm the framework's effectiveness in identifying and addressing instances of
content misuse in LLM training processes. Furthermore, we investigate the
presence of recognizable quotes from famous literary works within these
datasets. The outcomes of our study have significant implications for ensuring
the ethical use of copyrighted materials in the development of LLMs,
highlighting the need for more transparent and responsible data management
practices in this field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00678">General-purpose foundation models for increased autonomy in robot-assisted surgery. (arXiv:2401.00678v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schmidgall_S/0/1/0/all/0/1">Samuel Schmidgall</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Ji Woong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuntz_A/0/1/0/all/0/1">Alan Kuntz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghazi_A/0/1/0/all/0/1">Ahmed Ezzat Ghazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Krieger_A/0/1/0/all/0/1">Axel Krieger</a></p>
<p>The dominant paradigm for end-to-end robot learning focuses on optimizing
task-specific objectives that solve a single robotic problem such as picking up
an object or reaching a target position. However, recent work on high-capacity
models in robotics has shown promise toward being trained on large collections
of diverse and task-agnostic datasets of video demonstrations. These models
have shown impressive levels of generalization to unseen circumstances,
especially as the amount of data and the model complexity scale. Surgical robot
systems that learn from data have struggled to advance as quickly as other
fields of robot learning for a few reasons: (1) there is a lack of existing
large-scale open-source data to train models, (2) it is challenging to model
the soft-body deformations that these robots work with during surgery because
simulation cannot match the physical and visual complexity of biological
tissue, and (3) surgical robots risk harming patients when tested in clinical
trials and require more extensive safety measures. This perspective article
aims to provide a path toward increasing robot autonomy in robot-assisted
surgery through the development of a multi-modal, multi-task,
vision-language-action model for surgical robots. Ultimately, we argue that
surgical robots are uniquely positioned to benefit from general-purpose models
and provide three guiding actions toward increased autonomy in robot-assisted
surgery.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00684">A Temporal Filter to Extract Doped Conducting Polymer Information Features from an Electronic Nose. (arXiv:2401.00684v1 [cond-mat.mtrl-sci])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Ammar_W/0/1/0/all/0/1">Wiem Haj Ammar</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Boujnah_A/0/1/0/all/0/1">Aicha Boujnah</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Baron_A/0/1/0/all/0/1">Antoine Baron</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Boubaker_A/0/1/0/all/0/1">Aimen Boubaker</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kalboussi_A/0/1/0/all/0/1">Adel Kalboussi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lmimouni_K/0/1/0/all/0/1">Kamal Lmimouni</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Pecqueur_S/0/1/0/all/0/1">Sebastien Pecqueur</a></p>
<p>Identifying relevant machine-learning features for multi-sensing platforms is
both an applicative limitation to recognize environments and a necessity to
interpret the physical relevance of transducers' complementarity in their
information processing. Particularly for long acquisitions, feature extraction
must be fully automatized without human intervention and resilient to
perturbations without increasing significantly the computational cost of a
classifier. In this study, we investigate on the relative resistance and
current modulation of a 24-dimensional conductimetric electronic nose, which
uses the exponential moving average as a floating reference in a low-cost
information descriptor for environment recognition. In particular, we
identified that depending on the structure of a linear classifier, the 'modema'
descriptor is optimized for different material sensing elements' contributions
to classify information patterns. The low-pass filtering optimization leads to
opposite behaviors between unsupervised and supervised learning: the latter one
favors longer integration of the reference, allowing to recognize five
different classes over 90%, while the first one prefers using the latest events
as its reference to clusterize patterns by environment nature. Its electronic
implementation shall greatly diminish the computational requirements of
conductimetric electronic noses for on-board environment recognition without
human supervision.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00685">Communication-Efficient Federated Learning for LEO Constellations Integrated with HAPs Using Hybrid NOMA-OFDM. (arXiv:2401.00685v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Elmahallawy_M/0/1/0/all/0/1">Mohamed Elmahallawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramadan_K/0/1/0/all/0/1">Khaled Ramadan</a></p>
<p>Space AI has become increasingly important and sometimes even necessary for
government, businesses, and society. An active research topic under this
mission is integrating federated learning (FL) with satellite communications
(SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively
train a machine learning model. However, the special communication environment
of SatCom leads to a very slow FL training process up to days and weeks. This
paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO
satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed
parameter servers (PS) to enhance satellite visibility, and (2) introduces
non-orthogonal multiple access (NOMA) into LEO to enable fast and
bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a
new communication topology that exploits HAPs to bridge satellites among
different orbits to mitigate the Doppler shift, and (4) a new FL model
aggregation scheme that optimally balances models between different orbits and
shells. Moreover, we (5) derive a closed-form expression of the outage
probability for satellites in near and far shells, as well as for the entire
system. Our extensive simulations have validated the mathematical analysis and
demonstrated the superior performance of NomaFedHAP in achieving fast and
efficient FL model convergence with high accuracy as compared to the
state-of-the-art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00688">Inferring community structure in attributed hypergraphs using stochastic block models. (arXiv:2401.00688v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1">Kazuki Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Uno_T/0/1/0/all/0/1">Takeaki Uno</a></p>
<p>Hypergraphs are a representation of complex systems involving interactions
among more than two entities and allow to investigation of higher-order
structure and dynamics in real-world complex systems. Community structure is a
common property observed in empirical networks in various domains. Stochastic
block models have been employed to investigate community structure in networks.
Node attribute data, often accompanying network data, has been found to
potentially enhance the learning of community structure in dyadic networks. In
this study, we develop a statistical framework that incorporates node attribute
data into the learning of community structure in a hypergraph, employing a
stochastic block model. We demonstrate that our model, which we refer to as
HyperNEO, enhances the learning of community structure in synthetic and
empirical hypergraphs when node attributes are sufficiently associated with the
communities. Furthermore, we found that applying a dimensionality reduction
method, UMAP, to the learned representations obtained using stochastic block
models, including our model, maps nodes into a two-dimensional vector space
while largely preserving community structure in empirical hypergraphs. We
expect that our framework will broaden the investigation and understanding of
higher-order community structure in real-world complex systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00691">Stochastic Gradient Descent for Additive Nonparametric Regression. (arXiv:2401.00691v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1">Xin Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Klusowski_J/0/1/0/all/0/1">Jason M. Klusowski</a></p>
<p>This paper introduces an iterative algorithm designed to train additive
models with favorable memory storage and computational requirements. The
algorithm can be viewed as the functional counterpart of stochastic gradient
descent, applied to the coefficients of a truncated basis expansion of the
component functions. We show that the resulting estimator satisfies an oracle
inequality that allows for model mispecification. In the well-specified
setting, by choosing the learning rate carefully across three distinct stages
of training, we prove that its risk is minimax optimal in terms of the
dependence on the dimensionality of the data and the size of the training
sample.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00692">Self-supervised learning for skin cancer diagnosis with limited training data. (arXiv:2401.00692v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Haggerty_H/0/1/0/all/0/1">Hamish Haggerty</a>, <a href="http://arxiv.org/find/eess/1/au:+Chandra_R/0/1/0/all/0/1">Rohitash Chandra</a></p>
<p>Cancer diagnosis is a well-studied problem in machine learning since early
detection of cancer is often the determining factor in prognosis. Supervised
deep learning achieves excellent results in cancer image classification,
usually through transfer learning. However, these models require large amounts
of labelled data and for several types of cancer, large labelled datasets do
not exist. In this paper, we demonstrate that a model pre-trained using a
self-supervised learning algorithm known as Barlow Twins can outperform the
conventional supervised transfer learning pipeline. We juxtapose two base
models: i) pretrained in a supervised fashion on ImageNet; ii) pretrained in a
self-supervised fashion on ImageNet. Both are subsequently fine tuned on a
small labelled skin lesion dataset and evaluated on a large test set. We
achieve a mean test accuracy of 70\% for self-supervised transfer in comparison
to 66\% for supervised transfer. Interestingly, boosting performance further is
possible by self-supervised pretraining a second time (on unlabelled skin
lesion images) before subsequent fine tuning. This hints at an alternative path
to collecting more labelled data in settings where this is challenging - namely
just collecting more unlabelled images. Our framework is applicable to cancer
image classification models in the low-labelled data regime.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00698">Large Language Models aren&#x27;t all that you need. (arXiv:2401.00698v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Holla_K/0/1/0/all/0/1">Kiran Voderhobli Holla</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_C/0/1/0/all/0/1">Chaithanya Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Aryan Singh</a></p>
<p>This paper describes the architecture and systems built towards solving the
SemEval 2023 Task 2: MultiCoNER II (Multilingual Complex Named Entity
Recognition) [1]. We evaluate two approaches (a) a traditional Conditional
Random Fields model and (b) a Large Language Model (LLM) fine-tuned with a
customized head and compare the two approaches. The novel ideas explored are:
1) Decaying auxiliary loss (with residual) - where we train the model on an
auxiliary task of Coarse-Grained NER and include this task as a part of the
loss function 2) Triplet token blending - where we explore ways of blending the
embeddings of neighboring tokens in the final NER layer prior to prediction 3)
Task-optimal heads - where we explore a variety of custom heads and learning
rates for the final layer of the LLM. We also explore multiple LLMs including
GPT-3 and experiment with a variety of dropout and other hyperparameter
settings before arriving at our final model which achieves micro &amp; macro f1 of
0.85/0.84 (on dev) and 0.67/0.61 on the test data . We show that while
pre-trained LLMs, by themselves, bring about a large improvement in scores as
compared to traditional models, we also demonstrate that tangible improvements
to the Macro-F1 score can be made by augmenting the LLM with additional
feature/loss/model engineering techniques described above.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00700">An attempt to generate new bridge types from latent space of generative adversarial network. (arXiv:2401.00700v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongjun Zhang</a></p>
<p>Try to generate new bridge types using generative artificial intelligence
technology. Symmetric structured image dataset of three-span beam bridge, arch
bridge, cable-stayed bridge and suspension bridge are used . Based on Python
programming language, TensorFlow and Keras deep learning platform framework ,
as well as Wasserstein loss function and Lipschitz constraints, generative
adversarial network is constructed and trained. From the obtained low
dimensional bridge-type latent space sampling, new bridge types with asymmetric
structures can be generated. Generative adversarial network can create new
bridge types by organically combining different structural components on the
basis of human original bridge types. It has a certain degree of human original
ability. Generative artificial intelligence technology can open up imagination
space and inspire humanity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00713">A Survey on Graph Neural Networks in Intelligent Transportation Systems. (arXiv:2401.00713v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hourun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yusheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1">Zhengyang Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">YiFang Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Zhiping Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiaqi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yiyang Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1">Wei Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Ming Zhao</a></p>
<p>Intelligent Transportation System (ITS) is vital in improving traffic
congestion, reducing traffic accidents, optimizing urban planning, etc.
However, due to the complexity of the traffic network, traditional machine
learning and statistical methods are relegated to the background. With the
advent of the artificial intelligence era, many deep learning frameworks have
made remarkable progress in various fields and are now considered effective
methods in many areas. As a deep learning method, Graph Neural Networks (GNNs)
have emerged as a highly competitive method in the ITS field since 2019 due to
their strong ability to model graph-related problems. As a result, more and
more scholars pay attention to the applications of GNNs in transportation
domains, which have shown excellent performance. However, most of the research
in this area is still concentrated on traffic forecasting, while other ITS
domains, such as autonomous vehicles and urban planning, still require more
attention. This paper aims to review the applications of GNNs in six
representative and emerging ITS domains: traffic forecasting, autonomous
vehicles, traffic signal control, transportation safety, demand prediction, and
parking management. We have reviewed extensive graph-related studies from 2018
to 2023, summarized their methods, features, and contributions, and presented
them in informative tables or lists. Finally, we have identified the challenges
of applying GNNs to ITS and suggested potential future directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00728">MultiFusionNet: Multilayer Multimodal Fusion of Deep Neural Networks for Chest X-Ray Image Classification. (arXiv:2401.00728v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1">Saurabh Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Arya_K/0/1/0/all/0/1">K. V. Arya</a>, <a href="http://arxiv.org/find/eess/1/au:+Meena_Y/0/1/0/all/0/1">Yogesh Kumar Meena</a></p>
<p>Chest X-ray imaging is a critical diagnostic tool for identifying pulmonary
diseases. However, manual interpretation of these images is time-consuming and
error-prone. Automated systems utilizing convolutional neural networks (CNNs)
have shown promise in improving the accuracy and efficiency of chest X-ray
image classification. While previous work has mainly focused on using feature
maps from the final convolution layer, there is a need to explore the benefits
of leveraging additional layers for improved disease classification. Extracting
robust features from limited medical image datasets remains a critical
challenge. In this paper, we propose a novel deep learning-based multilayer
multimodal fusion model that emphasizes extracting features from different
layers and fusing them. Our disease detection model considers the
discriminatory information captured by each layer. Furthermore, we propose the
fusion of different-sized feature maps (FDSFM) module to effectively merge
feature maps from diverse layers. The proposed model achieves a significantly
higher accuracy of 97.21% and 99.60% for both three-class and two-class
classifications, respectively. The proposed multilayer multimodal fusion model,
along with the FDSFM module, holds promise for accurate disease classification
and can also be extended to other disease classifications in chest X-ray
images.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00736">Diffusion Models, Image Super-Resolution And Everything: A Survey. (arXiv:2401.00736v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moser_B/0/1/0/all/0/1">Brian B. Moser</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanbhag_A/0/1/0/all/0/1">Arundhati S. Shanbhag</a>, <a href="http://arxiv.org/find/cs/1/au:+Raue_F/0/1/0/all/0/1">Federico Raue</a>, <a href="http://arxiv.org/find/cs/1/au:+Frolov_S/0/1/0/all/0/1">Stanislav Frolov</a>, <a href="http://arxiv.org/find/cs/1/au:+Palacio_S/0/1/0/all/0/1">Sebastian Palacio</a>, <a href="http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1">Andreas Dengel</a></p>
<p>Diffusion Models (DMs) represent a significant advancement in image
Super-Resolution (SR), aligning technical image quality more closely with human
preferences and expanding SR applications. DMs address critical limitations of
previous methods, enhancing overall realism and details in SR images. However,
DMs suffer from color-shifting issues, and their high computational costs call
for efficient sampling alternatives, underscoring the challenge of balancing
computational efficiency and image quality. This survey gives an overview of
DMs applied to image SR and offers a detailed analysis that underscores the
unique characteristics and methodologies within this domain, distinct from
broader existing reviews in the field. It presents a unified view of DM
fundamentals and explores research directions, including alternative input
domains, conditioning strategies, guidance, corruption spaces, and zero-shot
methods. This survey provides insights into the evolution of image SR with DMs,
addressing current trends, challenges, and future directions in this rapidly
evolving field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00737">Searching, fast and slow, through product catalogs. (arXiv:2401.00737v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1">Dayananda Ubrangala</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_J/0/1/0/all/0/1">Juhi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rangappa_S/0/1/0/all/0/1">Sharath Kumar Rangappa</a>, <a href="http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1">Kiran R</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1">Ravi Prasad Kondapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1">Laurent Bou&#xe9;</a></p>
<p>String matching algorithms in the presence of abbreviations, such as in Stock
Keeping Unit (SKU) product catalogs, remains a relatively unexplored topic. In
this paper, we present a unified architecture for SKU search that provides both
a real-time suggestion system (based on a Trie data structure) as well as a
lower latency search system (making use of character level TF-IDF in
combination with language model vector embeddings) where users initiate the
search process explicitly. We carry out ablation studies that justify designing
a complex search system composed of multiple components to address the delicate
trade-off between speed and accuracy. Using SKU search in the Dynamics CRM as
an example, we show how our system vastly outperforms, in all aspects, the
results provided by the default search engine. Finally, we show how SKU
descriptions may be enhanced via generative text models (using gpt-3.5-turbo)
so that the consumers of the search results may get more context and a
generally better experience when presented with the results of their SKU
search.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00744">Harmonizing Covariance and Expressiveness for Deep Hamiltonian Regression in Crystalline Material Research: a Hybrid Cascaded Regression Framework. (arXiv:2401.00744v1 [physics.comp-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Yin_S/0/1/0/all/0/1">Shi Yin</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhu_X/0/1/0/all/0/1">Xudong Zhu</a>, <a href="http://arxiv.org/find/physics/1/au:+Gao_T/0/1/0/all/0/1">Tianyu Gao</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhang_H/0/1/0/all/0/1">Haochong Zhang</a>, <a href="http://arxiv.org/find/physics/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>, <a href="http://arxiv.org/find/physics/1/au:+He_L/0/1/0/all/0/1">Lixin He</a></p>
<p>Deep learning for Hamiltonian regression of quantum systems in material
research necessitates satisfying the covariance laws, among which achieving
SO(3)-equivariance without sacrificing the expressiveness of networks remains
an elusive challenge due to the restriction to non-linear mappings on
guaranteeing theoretical equivariance. To alleviate the
covariance-expressiveness dilemma, we propose a hybrid framework with two
cascaded regression stages. The first stage, with a theoretically-guaranteed
covariant neural network modeling symmetry properties of 3D atom systems,
yields theoretically covariant features and baseline Hamiltonian predictions,
assisting the second stage in learning covariance. Meanwhile, the second stage,
powered by a non-linear 3D graph Transformer network we propose for structural
modeling of 3D atomic systems, refines the first stage's output as a
fine-grained prediction of Hamiltonians with better expressiveness capability.
The combination of a theoretically covariant yet inevitably less expressive
model with a highly expressive non-linear network enables precise,
generalizable predictions while maintaining robust covariance under coordinate
transformations. Our method achieves state-of-the-art performance in
Hamiltonian prediction for electronic structure calculations, confirmed through
experiments on five crystalline material databases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00755">Saliency-Aware Regularized Graph Neural Network. (arXiv:2401.00755v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pei_W/0/1/0/all/0/1">Wenjie Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weina Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zongze Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weichao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinfan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Guangming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiangrong Wang</a></p>
<p>The crux of graph classification lies in the effective representation
learning for the entire graph. Typical graph neural networks focus on modeling
the local dependencies when aggregating features of neighboring nodes, and
obtain the representation for the entire graph by aggregating node features.
Such methods have two potential limitations: 1) the global node saliency w.r.t.
graph classification is not explicitly modeled, which is crucial since
different nodes may have different semantic relevance to graph classification;
2) the graph representation directly aggregated from node features may have
limited effectiveness to reflect graph-level information. In this work, we
propose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph
classification, which consists of two core modules: 1) a traditional graph
neural network serving as the backbone for learning node features and 2) the
Graph Neural Memory designed to distill a compact graph representation from
node features of the backbone. We first estimate the global node saliency by
measuring the semantic similarity between the compact graph representation and
node features. Then the learned saliency distribution is leveraged to
regularize the neighborhood aggregation of the backbone, which facilitates the
message passing of features for salient nodes and suppresses the less relevant
nodes. Thus, our model can learn more effective graph representation. We
demonstrate the merits of SAR-GNN by extensive experiments on seven datasets
across various types of graph data. Code will be released.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00756">MPRE: Multi-perspective Patient Representation Extractor for Disease Prediction. (arXiv:2401.00756v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Ziyue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiayi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Wuman Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tse_R/0/1/0/all/0/1">Rita Tse</a>, <a href="http://arxiv.org/find/cs/1/au:+Pau_G/0/1/0/all/0/1">Giovanni Pau</a></p>
<p>Patient representation learning based on electronic health records (EHR) is a
critical task for disease prediction. This task aims to effectively extract
useful information on dynamic features. Although various existing works have
achieved remarkable progress, the model performance can be further improved by
fully extracting the trends, variations, and the correlation between the trends
and variations in dynamic features. In addition, sparse visit records limit the
performance of deep learning models. To address these issues, we propose the
Multi-perspective Patient Representation Extractor (MPRE) for disease
prediction. Specifically, we propose Frequency Transformation Module (FTM) to
extract the trend and variation information of dynamic features in the
time-frequency domain, which can enhance the feature representation. In the 2D
Multi-Extraction Network (2D MEN), we form the 2D temporal tensor based on
trend and variation. Then, the correlations between trend and variation are
captured by the proposed dilated operation. Moreover, we propose the
First-Order Difference Attention Mechanism (FODAM) to calculate the
contributions of differences in adjacent variations to the disease diagnosis
adaptively. To evaluate the performance of MPRE and baseline methods, we
conduct extensive experiments on two real-world public datasets. The experiment
results show that MPRE outperforms state-of-the-art baseline methods in terms
of AUROC and AUPRC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00773">Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures. (arXiv:2401.00773v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwook Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Juyeon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hee Cheol Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1">Seonghyun Jeong</a></p>
<p>Probabilistic mixture models are acknowledged as a valuable tool for
unsupervised outlier detection owing to their interpretability and intuitive
grounding in statistical principles. Within this framework, Dirichlet process
mixture models emerge as a compelling alternative to conventional finite
mixture models for both clustering and outlier detection tasks. However,
despite their evident advantages, the widespread adoption of Dirichlet process
mixture models in unsupervised outlier detection has been hampered by
challenges related to computational inefficiency and sensitivity to outliers
during the construction of detectors. To tackle these challenges, we propose a
novel outlier detection method based on ensembles of Dirichlet process Gaussian
mixtures. The proposed method is a fully unsupervised algorithm that
capitalizes on random subspace and subsampling ensembles, not only ensuring
efficient computation but also enhancing the robustness of the resulting
outlier detector. Moreover, the proposed method leverages variational inference
for Dirichlet process mixtures to ensure efficient and fast computation.
Empirical studies with benchmark datasets demonstrate that our method
outperforms existing approaches for unsupervised outlier detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00776">Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study in the Autism Spectrum Disorder Therapy. (arXiv:2401.00776v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qin Yang</a></p>
<p>In recent years, edge computing has served as a paradigm that enables many
future technologies like AI, Robotics, IoT, and high-speed wireless sensor
networks (like 5G) by connecting cloud computing facilities and services to the
end users. Especially in medical and healthcare applications, it provides
remote patient monitoring and increases voluminous multimedia. From the
robotics angle, robot-assisted therapy (RAT) is an active-assistive robotic
technology in rehabilitation robotics, attracting many researchers to study and
benefit people with disability like autism spectrum disorder (ASD) children.
However, the main challenge of RAT is that the model capable of detecting the
affective states of ASD people exists and can recall individual preferences.
Moreover, involving expert diagnosis and recommendations to guide robots in
updating the therapy approach to adapt to different statuses and scenarios is a
crucial part of the ASD therapy process. This paper proposes the architecture
of edge cognitive computing by combining human experts and assisted robots
collaborating in the same framework to help ASD patients with long-term
support. By integrating the real-time computing and analysis of a new cognitive
robotic model for ASD therapy, the proposed architecture can achieve a seamless
remote diagnosis, round-the-clock symptom monitoring, emergency warning,
therapy alteration, and advanced assistance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00781">Inferring Heterogeneous Treatment Effects of Crashes on Highway Traffic: A Doubly Robust Causal Machine Learning Approach. (arXiv:2401.00781v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_Z/0/1/0/all/0/1">Ziyuan Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhiyong Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghyeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiucheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngoduy_D/0/1/0/all/0/1">Dong Ngoduy</a></p>
<p>Highway traffic crashes exert a considerable impact on both transportation
systems and the economy. In this context, accurate and dependable emergency
responses are crucial for effective traffic management. However, the influence
of crashes on traffic status varies across diverse factors and may be biased
due to selection bias. Therefore, there arises a necessity to accurately
estimate the heterogeneous causal effects of crashes, thereby providing
essential insights to facilitate individual-level emergency decision-making.
This paper proposes a novel causal machine learning framework to estimate the
causal effect of different types of crashes on highway speed. The Neyman-Rubin
Causal Model (RCM) is employed to formulate this problem from a causal
perspective. The Conditional Shapley Value Index (CSVI) is proposed based on
causal graph theory to filter adverse variables, and the Structural Causal
Model (SCM) is then adopted to define the statistical estimand for causal
effects. The treatment effects are estimated by Doubly Robust Learning (DRL)
methods, which combine doubly robust causal inference with classification and
regression machine learning models. Experimental results from 4815 crashes on
Highway Interstate 5 in Washington State reveal the heterogeneous treatment
effects of crashes at varying distances and durations. The rear-end crashes
cause more severe congestion and longer durations than other types of crashes,
and the sideswipe crashes have the longest delayed impact. Additionally, the
findings show that rear-end crashes affect traffic greater at night, while
crash to objects has the most significant influence during peak hours.
Statistical hypothesis tests, error metrics based on matched "counterfactual
outcomes", and sensitive analyses are employed for assessment, and the results
validate the accuracy and effectiveness of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00793">SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models. (arXiv:2401.00793v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jinglong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yehong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_X/0/1/0/all/0/1">Xin Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a></p>
<p>With the growing use of large language models hosted on cloud platforms to
offer inference services, privacy concerns are escalating, especially
concerning sensitive data like investment plans and bank account details.
Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect
the privacy of inference data and model parameters. However, the application of
SMPC in Privacy-Preserving Inference (PPI) for large language models,
particularly those based on the Transformer architecture, often leads to
considerable slowdowns or declines in performance. This is largely due to the
multitude of nonlinear operations in the Transformer architecture, which are
not well-suited to SMPC and are difficult to circumvent or optimize
effectively. To address this concern, we introduce an advanced optimization
framework called SecFormer, designed to strike an optimal balance between
performance and efficiency in PPI for Transformer models. By implementing
knowledge distillation techniques, we successfully eliminate the high-cost
exponential and maximum operations in PPI without sacrificing model
performance. Additionally, we have developed a suite of efficient SMPC
protocols that utilize segmented polynomials and Goldschmidt's method to handle
other complex nonlinear functions within PPI, such as GeLU, LayerNorm, and
Softmax. Our extensive experiments reveal that SecFormer outperforms MPCFormer
in performance, showing improvements of $5.6\%$ and $24.2\%$ for
BERT$_{\text{BASE}}$ and BERT$_{\text{LARGE}}$, respectively. In terms of
efficiency, SecFormer is 3.4 and 3.2 times faster than Puma, demonstrating its
effectiveness and speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00809">A review on different techniques used to combat the non-IID and heterogeneous nature of data in FL. (arXiv:2401.00809v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Iyer_V/0/1/0/all/0/1">Venkataraman Natarajan Iyer</a></p>
<p>Federated Learning (FL) is a machine-learning approach enabling collaborative
model training across multiple decentralized edge devices that hold local data
samples, all without exchanging these samples. This collaborative process
occurs under the supervision of a central server orchestrating the training or
via a peer-to-peer network. The significance of FL is particularly pronounced
in industries such as healthcare and finance, where data privacy holds
paramount importance. However, training a model under the Federated learning
setting brings forth several challenges, with one of the most prominent being
the heterogeneity of data distribution among the edge devices. The data is
typically non-independently and non-identically distributed (non-IID), thereby
presenting challenges to model convergence. This report delves into the issues
arising from non-IID and heterogeneous data and explores current algorithms
designed to address these challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00816">GLIMPSE: Generalized Local Imaging with MLPs. (arXiv:2401.00816v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khorashadizadeh_A/0/1/0/all/0/1">AmirEhsan Khorashadizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Debarnot_V/0/1/0/all/0/1">Valentin Debarnot</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dokmanic_I/0/1/0/all/0/1">Ivan Dokmani&#x107;</a></p>
<p>Deep learning is the current de facto state of the art in tomographic
imaging. A common approach is to feed the result of a simple inversion, for
example the backprojection, to a convolutional neural network (CNN) which then
computes the reconstruction. Despite strong results on 'in-distribution' test
data similar to the training data, backprojection from sparse-view data
delocalizes singularities, so these approaches require a large receptive field
to perform well. As a consequence, they overfit to certain global structures
which leads to poor generalization on out-of-distribution (OOD) samples.
Moreover, their memory complexity and training time scale unfavorably with
image resolution, making them impractical for application at realistic clinical
resolutions, especially in 3D: a standard U-Net requires a substantial 140GB of
memory and 2600 seconds per epoch on a research-grade GPU when training on
1024x1024 images. In this paper, we introduce GLIMPSE, a local processing
neural network for computed tomography which reconstructs a pixel value by
feeding only the measurements associated with the neighborhood of the pixel to
a simple MLP. While achieving comparable or better performance with successful
CNNs like the U-Net on in-distribution test data, GLIMPSE significantly
outperforms them on OOD samples while maintaining a memory footprint almost
independent of image resolution; 5GB memory suffices to train on 1024x1024
images. Further, we built GLIMPSE to be fully differentiable, which enables
feats such as recovery of accurate projection angles if they are out of
calibration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00824">Graph-Convolutional Autoencoder Ensembles for the Humanities, Illustrated with a Study of the American Slave Trade. (arXiv:2401.00824v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lippincott_T/0/1/0/all/0/1">Tom Lippincott</a></p>
<p>We introduce a graph-aware autoencoder ensemble framework, with associated
formalisms and tooling, designed to facilitate deep learning for scholarship in
the humanities. By composing sub-architectures to produce a model isomorphic to
a humanistic domain we maintain interpretability while providing function
signatures for each sub-architectural choice, allowing both traditional and
computational researchers to collaborate without disrupting established
practices. We illustrate a practical application of our approach to a
historical study of the American post-Atlantic slave trade, and make several
specific technical contributions: a novel hybrid graph-convolutional
autoencoder mechanism, batching policies for common graph topologies, and
masking techniques for particular use-cases. The effectiveness of the framework
for broadening participation of diverse domains is demonstrated by a growing
suite of two dozen studies, both collaborations with humanists and established
tasks from machine learning literature, spanning a variety of fields and data
modalities. We make performance comparisons of several different architectural
choices and conclude with an ambitious list of imminent next steps for this
research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00828">Multi-Lattice Sampling of Quantum Field Theories via Neural Operators. (arXiv:2401.00828v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mate_B/0/1/0/all/0/1">B&#xe1;lint M&#xe1;t&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleuret_F/0/1/0/all/0/1">Fran&#xe7;ois Fleuret</a></p>
<p>We consider the problem of sampling discrete field configurations $\phi$ from
the Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is the
lattice-discretization of the continuous Euclidean action $\mathcal S$ of some
quantum field theory. Since such densities arise as the approximation of the
underlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcal
S[\phi(x)]}$, we frame the task as an instance of operator learning. In
particular, we propose to approximate a time-dependent operator $\mathcal V_t$
whose time integral provides a mapping between the functional distributions of
the free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcal
S_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcal
Z^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, the
operator $\mathcal V_t$ can be discretized to a finite dimensional,
time-dependent vector field $V_t$ which in turn induces a continuous
normalizing flow between finite dimensional distributions over the chosen
lattice. This flow can then be trained to be a diffeormorphism between the
discretized free and target theories $[d\phi] Z_0^{-1} e^{-S_{0}[\phi]}$,
$[d\phi] Z^{-1}e^{-S[\phi]}$. We run experiments on the $\phi^4$-theory to
explore to what extent such operator-based flow architectures generalize to
lattice sizes they were not trained on and show that pretraining on smaller
lattices can lead to speedup over training only a target lattice size.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2007.05690">A Unified Linear Speedup Analysis of Federated Averaging and Nesterov FedAvg. (arXiv:2007.05690v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qu_Z/0/1/0/all/0/1">Zhaonan Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kaixiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhaojian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiayu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a></p>
<p>Federated learning (FL) learns a model jointly from a set of participating
devices without sharing each other's privately held data. The characteristics
of non-i.i.d. data across the network, low device participation, high
communication costs, and the mandate that data remain private bring challenges
in understanding the convergence of FL algorithms, particularly regarding how
convergence scales with the number of participating devices. In this paper, we
focus on Federated Averaging (FedAvg), one of the most popular and effective FL
algorithms in use today, as well as its Nesterov accelerated variant, and
conduct a systematic study of how their convergence scale with the number of
participating devices under non-i.i.d. data and partial participation in convex
settings. We provide a unified analysis that establishes convergence guarantees
for FedAvg under strongly convex, convex, and overparameterized strongly convex
problems. We show that FedAvg enjoys linear speedup in each case, although with
different convergence rates and communication efficiencies. For strongly convex
and convex problems, we also characterize the corresponding convergence rates
for the Nesterov accelerated FedAvg algorithm, which are the first linear
speedup guarantees for momentum variants of FedAvg in convex settings.
Empirical studies of the algorithms in various settings have supported our
theoretical results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2103.02543">On the geometric and Riemannian structure of the spaces of group equivariant non-expansive operators. (arXiv:2103.02543v2 [math.DG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Cascarano_P/0/1/0/all/0/1">Pasquale Cascarano</a>, <a href="http://arxiv.org/find/math/1/au:+Frosini_P/0/1/0/all/0/1">Patrizio Frosini</a>, <a href="http://arxiv.org/find/math/1/au:+Quercioli_N/0/1/0/all/0/1">Nicola Quercioli</a>, <a href="http://arxiv.org/find/math/1/au:+Saki_A/0/1/0/all/0/1">Amir Saki</a></p>
<p>Group equivariant non-expansive operators have been recently proposed as
basic components in topological data analysis and deep learning. In this paper
we study some geometric properties of the spaces of group equivariant operators
and show how a space $\mathcal{F}$ of group equivariant non-expansive operators
can be endowed with the structure of a Riemannian manifold, so making available
the use of gradient descent methods for the minimization of cost functions on
$\mathcal{F}$. As an application of this approach, we also describe a procedure
to select a finite set of representative group equivariant non-expansive
operators in the considered manifold.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2111.05530">Nearly Optimal Linear Convergence of Stochastic Primal-Dual Methods for Linear Programming. (arXiv:2111.05530v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lu_H/0/1/0/all/0/1">Haihao Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1">Jinwen Yang</a></p>
<p>There is a recent interest on first-order methods for linear programming
(LP). In this paper,we propose a stochastic algorithm using variance reduction
and restarts for solving sharp primal-dual problems such as LP. We show that
the proposed stochastic method exhibits a linear convergence rate for solving
sharp instances with a high probability. In addition, we propose an efficient
coordinate-based stochastic oracle for unconstrained bilinear problems, which
has $\mathcal O(1)$ per iteration cost and improves the complexity of the
existing deterministic and stochastic algorithms. Finally, we show that the
obtained linear convergence rate is nearly optimal (upto $\log$ terms) for a
wide class of stochastic primal dual methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.08364">Data Valuation for Vertical Federated Learning: A Model-free and Privacy-preserving Method. (arXiv:2112.08364v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Leye Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Junjie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xiao Fang</a></p>
<p>Vertical Federated learning (VFL) is a promising paradigm for predictive
analytics, empowering an organization (i.e., task party) to enhance its
predictive models through collaborations with multiple data suppliers (i.e.,
data parties) in a decentralized and privacy-preserving way. Despite the
fast-growing interest in VFL, the lack of effective and secure tools for
assessing the value of data owned by data parties hinders the application of
VFL in business contexts. In response, we propose FedValue, a
privacy-preserving, task-specific but model-free data valuation method for VFL,
which consists of a data valuation metric and a federated computation method.
Specifically, we first introduce a novel data valuation metric, namely
MShapley-CMI. The metric evaluates a data party's contribution to a predictive
analytics task without the need of executing a machine learning model, making
it well-suited for real-world applications of VFL. Next, we develop an
innovative federated computation method that calculates the MShapley-CMI value
for each data party in a privacy-preserving manner. Extensive experiments
conducted on six public datasets validate the efficacy of FedValue for data
valuation in the context of VFL. In addition, we illustrate the practical
utility of FedValue with a case study involving federated movie
recommendations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.07794">A Non-Expert&#x27;s Introduction to Data Ethics for Mathematicians. (arXiv:2201.07794v2 [math.HO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Porter_M/0/1/0/all/0/1">Mason A. Porter</a></p>
<p>I give a short introduction to data ethics. I begin with some background
information and societal context for data ethics. I then discuss data ethics in
mathematical-science education and indicate some available course material. I
briefly highlight a few efforts -- at my home institution and elsewhere -- on
data ethics, society, and social good. I then discuss open data in research,
research replicability and some other ethical issues in research, and the
tension between privacy and open data and code, and a few controversial studies
and reactions to studies. I then discuss ethical principles, institutional
review boards, and a few other considerations in the scientific use of human
data. Finally, I briefly survey a variety of research and lay articles that are
relevant to data ethics and data privacy. I conclude with a brief summary.
</p>
<p>My focal audience is mathematicians, but I hope that this chapter will also
be useful to others. I am not an expert about data ethics, and this chapter
provides only a starting point on this wide-ranging topic. I encourage you to
examine the resources that I discuss and to reflect carefully on data ethics,
its role in mathematics education, and the societal implications of data and
data analysis. As data and technology continue to evolve, I hope that such
careful reflection will continue throughout your life.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.00362">A Simple and General Duality Proof for Wasserstein Distributionally Robust Optimization. (arXiv:2205.00362v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1">Luhao Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1">Jincheng Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Gao_R/0/1/0/all/0/1">Rui Gao</a></p>
<p>We present an elementary yet general proof of duality for Wasserstein
distributionally robust optimization. The duality holds for any arbitrary
Kantorovich transport cost, measurable loss function, and nominal probability
distribution, provided that an interchangeability principle holds, which is
equivalent to certain measurability conditions. To illustrate the broader
applicability of our approach, we provide a rigorous treatment of duality
results in distributionally robust Markov decision processes and
distributionally robust multistage stochastic programming. Furthermore, we
extend the result to other problems including infinity-Wasserstein
distributionally robust optimization, risk-averse optimization, and globalized
distributionally robust counterpart.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.00605">Cluster-based Regression using Variational Inference and Applications in Financial Forecasting. (arXiv:2205.00605v3 [q-fin.ST] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Nagpal_U/0/1/0/all/0/1">Udai Nagpal</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Nagpal_K/0/1/0/all/0/1">Krishan Nagpal</a></p>
<p>This paper describes an approach to simultaneously identify clusters and
estimate cluster-specific regression parameters from the given data. Such an
approach can be useful in learning the relationship between input and output
when the regression parameters for estimating output are different in different
regions of the input space. Variational Inference (VI), a machine learning
approach to obtain posterior probability densities using optimization
techniques, is used to identify clusters of explanatory variables and
regression parameters for each cluster. From these results, one can obtain both
the expected value and the full distribution of predicted output. Other
advantages of the proposed approach include the elegant theoretical solution
and clear interpretability of results. The proposed approach is well-suited for
financial forecasting where markets have different regimes (or clusters) with
different patterns and correlations of market changes in each regime. In
financial applications, knowledge about such clusters can provide useful
insights about portfolio performance and identify the relative importance of
variables in different market regimes. An illustrative example of predicting
one-day S&amp;P change is considered to illustrate the approach and compare the
performance of the proposed approach with standard regression without clusters.
Due to the broad applicability of the problem, its elegant theoretical
solution, and the computational efficiency of the proposed algorithm, the
approach may be useful in a number of areas extending beyond the financial
domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.04151">Learning effective dynamics from data-driven stochastic systems. (arXiv:2205.04151v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1">Lingyu Feng</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1">Ting Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Dai_M/0/1/0/all/0/1">Min Dai</a>, <a href="http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1">Jinqiao Duan</a></p>
<p>Multiscale stochastic dynamical systems have been widely adopted to a variety
of scientific and engineering problems due to their capability of depicting
complex phenomena in many real world applications. This work is devoted to
investigating the effective dynamics for slow-fast stochastic dynamical
systems. Given observation data on a short-term period satisfying some unknown
slow-fast stochastic systems, we propose a novel algorithm including a neural
network called Auto-SDE to learn invariant slow manifold. Our approach captures
the evolutionary nature of a series of time-dependent autoencoder neural
networks with the loss constructed from a discretized stochastic differential
equation. Our algorithm is also validated to be accurate, stable and effective
through numerical experiments under various evaluation metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.12987">FlowX: Towards Explainable Graph Neural Networks via Message Flows. (arXiv:2206.12987v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gui_S/0/1/0/all/0/1">Shurui Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lao_Q/0/1/0/all/0/1">Qicheng Lao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a></p>
<p>We investigate the explainability of graph neural networks (GNNs) as a step
toward elucidating their working mechanisms. While most current methods focus
on explaining graph nodes, edges, or features, we argue that, as the inherent
functional mechanism of GNNs, message flows are more natural for performing
explainability. To this end, we propose a novel method here, known as FlowX, to
explain GNNs by identifying important message flows. To quantify the importance
of flows, we propose to follow the philosophy of Shapley values from
cooperative game theory. To tackle the complexity of computing all coalitions'
marginal contributions, we propose a flow sampling scheme to compute Shapley
value approximations as initial assessments of further training. We then
propose an information-controlled learning algorithm to train flow scores
toward diverse explanation targets: necessary or sufficient explanations.
Experimental studies on both synthetic and real-world datasets demonstrate that
our proposed FlowX and its variants lead to improved explainability of GNNs.
The code is available at https://github.com/divelab/DIG.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.04173">Stochastic Approximation with Decision-Dependent Distributions: Asymptotic Normality and Optimality. (arXiv:2207.04173v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Cutler_J/0/1/0/all/0/1">Joshua Cutler</a>, <a href="http://arxiv.org/find/math/1/au:+Diaz_M/0/1/0/all/0/1">Mateo D&#xed;az</a>, <a href="http://arxiv.org/find/math/1/au:+Drusvyatskiy_D/0/1/0/all/0/1">Dmitriy Drusvyatskiy</a></p>
<p>We analyze a stochastic approximation algorithm for decision-dependent
problems, wherein the data distribution used by the algorithm evolves along the
iterate sequence. The primary examples of such problems appear in performative
prediction and its multiplayer extensions. We show that under mild assumptions,
the deviation between the average iterate of the algorithm and the solution is
asymptotically normal, with a covariance that clearly decouples the effects of
the gradient noise and the distributional shift. Moreover, building on the work
of H\'ajek and Le Cam, we show that the asymptotic performance of the algorithm
with averaging is locally minimax optimal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.10226">Improving Privacy-Preserving Vertical Federated Learning by Efficient Communication with ADMM. (arXiv:2207.10226v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chulin Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nourian_A/0/1/0/all/0/1">Arash Nourian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a></p>
<p>Federated learning (FL) enables distributed resource-constrained devices to
jointly train shared models while keeping the training data local for privacy
purposes. Vertical FL (VFL), which allows each client to collect partial
features, has attracted intensive research efforts recently. We identified the
main challenges that existing VFL frameworks are facing: the server needs to
communicate gradients with the clients for each training step, incurring high
communication cost that leads to rapid consumption of privacy budgets. To
address these challenges, in this paper, we introduce a VFL framework with
multiple heads (VIM), which takes the separate contribution of each client into
account, and enables an efficient decomposition of the VFL optimization
objective to sub-objectives that can be iteratively tackled by the server and
the clients on their own. In particular, we propose an Alternating Direction
Method of Multipliers (ADMM)-based method to solve our optimization problem,
which allows clients to conduct multiple local updates before communication,
and thus reduces the communication cost and leads to better performance under
differential privacy (DP). We provide the user-level DP mechanism for our
framework to protect user privacy. Moreover, we show that a byproduct of VIM is
that the weights of learned heads reflect the importance of local clients. We
conduct extensive evaluations and show that on four vertical FL datasets, VIM
achieves significantly higher performance and faster convergence compared with
the state-of-the-art. We also explicitly evaluate the importance of local
clients and show that VIM enables functionalities such as client-level
explanation and client denoising. We hope this work will shed light on a new
way of effective VFL training and understanding.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.10308">UniFed: All-In-One Federated Learning Platform to Unify Open-Source Frameworks. (arXiv:2207.10308v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Tianneng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chulin Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kangping Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Haoyu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaojun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_Le_T/0/1/0/all/0/1">The-Anh Vu-Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nourian_A/0/1/0/all/0/1">Arash Nourian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a></p>
<p>Federated Learning (FL) has become a practical and widely adopted distributed
learning paradigm. However, the lack of a comprehensive and standardized
solution covering diverse use cases makes it challenging to use in practice. In
addition, selecting an appropriate FL framework for a specific use case can be
a daunting task. In this work, we present UniFed, the first unified platform
for standardizing existing open-source FL frameworks. The platform streamlines
the end-to-end workflow for distributed experimentation and deployment,
encompassing 11 popular open-source FL frameworks. In particular, to address
the substantial variations in workflows and data formats, UniFed introduces a
configuration-based schema-enforced task specification, offering 20 editable
fields. UniFed also provides functionalities such as distributed execution
management, logging, and data analysis.
</p>
<p>With UniFed, we evaluate and compare 11 popular FL frameworks from the
perspectives of functionality, privacy protection, and performance, through
conducting developer surveys and code-level investigation. We collect 15
diverse FL scenario setups (e.g., horizontal and vertical settings) for FL
framework evaluation. This comprehensive evaluation allows us to analyze both
model and system performance, providing detailed comparisons and offering
recommendations for framework selection. UniFed simplifies the process of
selecting and utilizing the appropriate FL framework for specific use cases,
while enabling standardized distributed experimentation and deployment. Our
results and analysis based on experiments with up to 178 distributed nodes
provide valuable system design and deployment insights, aiming to empower
practitioners in their pursuit of effective FL solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.14653">Ensemble forecasts in reproducing kernel Hilbert space family. (arXiv:2207.14653v4 [math-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math-ph/1/au:+Dufee_B/0/1/0/all/0/1">Benjamin Duf&#xe9;e</a>, <a href="http://arxiv.org/find/math-ph/1/au:+Hug_B/0/1/0/all/0/1">B&#xe9;renger Hug</a>, <a href="http://arxiv.org/find/math-ph/1/au:+Memin_E/0/1/0/all/0/1">Etienne M&#xe9;min</a>, <a href="http://arxiv.org/find/math-ph/1/au:+Tissot_G/0/1/0/all/0/1">Gilles Tissot</a></p>
<p>A methodological framework for ensemble-based estimation and simulation of
high dimensional dynamical systems such as the oceanic or atmospheric flows is
proposed. To that end, the dynamical system is embedded in a family of
reproducing kernel Hilbert spaces (RKHS) with kernel functions driven by the
dynamics. In the RKHS family, the Koopman and Perron-Frobenius operators are
unitary and uniformly continuous. This property warrants they can be expressed
in exponential series of diagonalizable bounded evolution operators defined
from their infinitesimal generators. Access to Lyapunov exponents and to exact
ensemble based expressions of the tangent linear dynamics are directly
available as well. The RKHS family enables us the devise of strikingly simple
ensemble data assimilation methods for trajectory reconstructions in terms of
constant-in-time linear combinations of trajectory samples. Such an
embarrassingly simple strategy is made possible through a fully justified
superposition principle ensuing from several fundamental theorems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.09894">Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning. (arXiv:2208.09894v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ozfatura_K/0/1/0/all/0/1">Kerem Ozfatura</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozfatura_E/0/1/0/all/0/1">Emre Ozfatura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kupcu_A/0/1/0/all/0/1">Alptekin Kupcu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz Gunduz</a></p>
<p>The increasing popularity of the federated learning (FL) framework due to its
success in a wide range of collaborative learning tasks also induces certain
security concerns. Among many vulnerabilities, the risk of Byzantine attacks is
of particular concern, which refers to the possibility of malicious clients
participating in the learning process. Hence, a crucial objective in FL is to
neutralize the potential impact of Byzantine attacks and to ensure that the
final model is trustable. It has been observed that the higher the variance
among the clients' models/updates, the more space there is for Byzantine
attacks to be hidden. As a consequence, by utilizing momentum, and thus,
reducing the variance, it is possible to weaken the strength of known Byzantine
attacks. The centered clipping (CC) framework has further shown that the
momentum term from the previous iteration, besides reducing the variance, can
be used as a reference point to neutralize Byzantine attacks better. In this
work, we first expose vulnerabilities of the CC framework, and introduce a
novel attack strategy that can circumvent the defences of CC and other robust
aggregators and reduce their test accuracy up to %33 on best-case scenarios in
image classification tasks. Then, we propose a new robust and fast defence
mechanism that is effective against the proposed and other existing Byzantine
attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.06950">Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v7 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1">Stephan Mandt</a></p>
<p>This paper outlines an end-to-end optimized lossy image compression framework
using diffusion generative models. The approach relies on the transform coding
paradigm, where an image is mapped into a latent space for entropy coding and,
from there, mapped back to the data space for reconstruction. In contrast to
VAE-based neural compression, where the (mean) decoder is a deterministic
neural network, our decoder is a conditional diffusion model. Our approach thus
introduces an additional ``content'' latent variable on which the reverse
diffusion process is conditioned and uses this variable to store information
about the image. The remaining ``texture'' variables characterizing the
diffusion process are synthesized at decoding time. We show that the model's
performance can be tuned toward perceptual metrics of interest. Our extensive
experiments involving multiple datasets and image quality assessment metrics
show that our approach yields stronger reported FID scores than the GAN-based
model, while also yielding competitive performance with VAE-based models in
several distortion metrics. Furthermore, training the diffusion with
$\mathcal{X}$-parameterization enables high-quality reconstructions in only a
handful of decoding steps, greatly affecting the model's practicality. Our code
is available at: \url{https://github.com/buggyyang/CDC_compression}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.06971">Shot-frugal and Robust quantum kernel classifiers. (arXiv:2210.06971v3 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Shastry_A/0/1/0/all/0/1">Abhay Shastry</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Jayakumar_A/0/1/0/all/0/1">Abhijith Jayakumar</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Patel_A/0/1/0/all/0/1">Apoorva Patel</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bhattacharyya_C/0/1/0/all/0/1">Chiranjib Bhattacharyya</a></p>
<p>Quantum kernel methods are a candidate for quantum speed-ups in supervised
machine learning. The number of quantum measurements N required for a
reasonable kernel estimate is a critical resource, both from complexity
considerations and because of the constraints of near-term quantum hardware. We
emphasize that for classification tasks, the aim is reliable classification and
not precise kernel evaluation, and demonstrate that the former is far more
resource efficient. Furthermore, it is shown that the accuracy of
classification is not a suitable performance metric in the presence of noise
and we motivate a new metric that characterizes the reliability of
classification. We then obtain a bound for N which ensures, with high
probability, that classification errors over a dataset are bounded by the
margin errors of an idealized quantum kernel classifier. Using chance
constraint programming and the subgaussian bounds of quantum kernel
distributions, we derive several Shot-frugal and Robust (ShofaR) programs
starting from the primal formulation of the Support Vector Machine. This
significantly reduces the number of quantum measurements needed and is robust
to noise by construction. Our strategy is applicable to uncertainty in quantum
kernels arising from any source of unbiased noise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.09929">Differentially Private Diffusion Models. (arXiv:2210.09929v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Dockhorn_T/0/1/0/all/0/1">Tim Dockhorn</a>, <a href="http://arxiv.org/find/stat/1/au:+Cao_T/0/1/0/all/0/1">Tianshi Cao</a>, <a href="http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1">Arash Vahdat</a>, <a href="http://arxiv.org/find/stat/1/au:+Kreis_K/0/1/0/all/0/1">Karsten Kreis</a></p>
<p>While modern machine learning models rely on increasingly large training
datasets, data is often limited in privacy-sensitive domains. Generative models
trained with differential privacy (DP) on sensitive data can sidestep this
challenge, providing access to synthetic data instead. We build on the recent
success of diffusion models (DMs) and introduce Differentially Private
Diffusion Models (DPDMs), which enforce privacy using differentially private
stochastic gradient descent (DP-SGD). We investigate the DM parameterization
and the sampling algorithm, which turn out to be crucial ingredients in DPDMs,
and propose noise multiplicity, a powerful modification of DP-SGD tailored to
the training of DMs. We validate our novel DPDMs on image generation benchmarks
and achieve state-of-the-art performance in all experiments. Moreover, on
standard benchmarks, classifiers trained on DPDM-generated synthetic data
perform on par with task-specific DP-SGD-trained classifiers, which has not
been demonstrated before for DP generative models. Project page and code:
https://nv-tlabs.github.io/DPDM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.14416">Residual Back Projection With Untrained Neural Networks. (arXiv:2210.14416v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Shu_Z/0/1/0/all/0/1">Ziyu Shu</a>, <a href="http://arxiv.org/find/eess/1/au:+Entezari_A/0/1/0/all/0/1">Alireza Entezari</a></p>
<p>Background and Objective: The success of neural networks in a number of image
processing tasks has motivated their application in image reconstruction
problems in computed tomography (CT). While progress has been made in this
area, the lack of stability and theoretical guarantees for accuracy, together
with the scarcity of high-quality training data for specific imaging domains
pose challenges for many CT applications. In this paper, we present a framework
for iterative reconstruction (IR) in CT that leverages the hierarchical
structure of neural networks, without the need for training. Our framework
incorporates this structural information as a deep image prior (DIP), and uses
a novel residual back projection (RBP) connection that forms the basis for our
iterations.
</p>
<p>Methods: We propose using an untrained U-net in conjunction with a novel
residual back projection to minimize an objective function and achieve
high-accuracy reconstruction. In each iteration, the weights of the untrained
U-net are optimized, and the output of the U-net in the current iteration is
used to update the input of the U-net in the next iteration through the
aforementioned RBP connection.
</p>
<p>Results: Experimental results demonstrate that the RBP-DIP framework offers
improvements over other state-of-the-art conventional IR methods, as well as
pre-trained and untrained models with similar network structures under multiple
conditions. These improvements are particularly significant in the few-view,
limited-angle, and low-dose imaging configurations.
</p>
<p>Conclusions: Applying to both parallel and fan beam X-ray imaging, our
framework shows significant improvement under multiple conditions. Furthermore,
the proposed framework requires no training data and can be adjusted on-demand
to adapt to different conditions (e.g. noise level, geometry, and imaged
object).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.03749">Markovian Sliced Wasserstein Distances: Beyond Independent Projections. (arXiv:2301.03749v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1">Khai Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1">Tongzheng Ren</a>, <a href="http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1">Nhat Ho</a></p>
<p>Sliced Wasserstein (SW) distance suffers from redundant projections due to
independent uniform random projecting directions. To partially overcome the
issue, max K sliced Wasserstein (Max-K-SW) distance ($K\geq 1$), seeks the best
discriminative orthogonal projecting directions. Despite being able to reduce
the number of projections, the metricity of Max-K-SW cannot be guaranteed in
practice due to the non-optimality of the optimization. Moreover, the
orthogonality constraint is also computationally expensive and might not be
effective. To address the problem, we introduce a new family of SW distances,
named Markovian sliced Wasserstein (MSW) distance, which imposes a first-order
Markov structure on projecting directions. We discuss various members of MSW by
specifying the Markov structure including the prior distribution, the
transition distribution, and the burning and thinning technique. Moreover, we
investigate the theoretical properties of MSW including topological properties
(metricity, weak convergence, and connection to other distances), statistical
properties (sample complexity, and Monte Carlo estimation error), and
computational properties (computational complexity and memory complexity).
Finally, we compare MSW distances with previous SW variants in various
applications such as gradient flows, color transfer, and deep generative
modeling to demonstrate the favorable performance of MSW.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.07390">Relativistic Digital Twin: Bringing the IoT to the Future. (arXiv:2301.07390v3 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sciullo_L/0/1/0/all/0/1">Luca Sciullo</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchi_A/0/1/0/all/0/1">Alberto De Marchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Trotta_A/0/1/0/all/0/1">Angelo Trotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Montori_F/0/1/0/all/0/1">Federico Montori</a>, <a href="http://arxiv.org/find/cs/1/au:+Bononi_L/0/1/0/all/0/1">Luciano Bononi</a>, <a href="http://arxiv.org/find/cs/1/au:+Felice_M/0/1/0/all/0/1">Marco Di Felice</a></p>
<p>Complex IoT ecosystems often require the usage of Digital Twins (DTs) of
their physical assets in order to perform predictive analytics and simulate
what-if scenarios. DTs are able to replicate IoT devices and adapt over time to
their behavioral changes. However, DTs in IoT are typically tailored to a
specific use case, without the possibility to seamlessly adapt to different
scenarios. Further, the fragmentation of IoT poses additional challenges on how
to deploy DTs in heterogeneous scenarios characterized by the usage of multiple
data formats and IoT network protocols. In this paper, we propose the
Relativistic Digital Twin (RDT) framework, through which we automatically
generate general-purpose DTs of IoT entities and tune their behavioral models
over time by constantly observing their real counterparts. The framework relies
on the object representation via the Web of Things (WoT), to offer a
standardized interface to each of the IoT devices as well as to their DTs. To
this purpose, we extended the W3C WoT standard in order to encompass the
concept of behavioral model and define it in the Thing Description (TD) through
a new vocabulary. Finally, we evaluated the RDT framework over two disjoint use
cases to assess its correctness and learning performance, i.e., the DT of a
simulated smart home scenario with the capability of forecasting the indoor
temperature, and the DT of a real-world drone with the capability of
forecasting its trajectory in an outdoor scenario. Experiments show that the
generated DT can estimate the behavior of its real counterpart after an
observation stage, regardless of the considered scenario.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00293">A Survey of Methods, Challenges and Perspectives in Causality. (arXiv:2302.00293v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1">Ga&#xeb;l Gendron</a>, <a href="http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1">Michael Witbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobbie_G/0/1/0/all/0/1">Gillian Dobbie</a></p>
<p>Deep Learning models have shown success in a large variety of tasks by
extracting correlation patterns from high-dimensional data but still struggle
when generalizing out of their initial distribution. As causal engines aim to
learn mechanisms independent from a data distribution, combining Deep Learning
with Causality can have a great impact on the two fields. In this paper, we
further motivate this assumption. We perform an extensive overview of the
theories and methods for Causality from different perspectives, with an
emphasis on Deep Learning and the challenges met by the two domains. We show
early attempts to bring the fields together and the possible perspectives for
the future. We finish by providing a large variety of applications for
techniques from Causality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.04062">Machine Learning for Synthetic Data Generation: A Review. (arXiv:2302.04062v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yingzhou Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1">Minjie Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huazheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rechem_C/0/1/0/all/0/1">Capucine van Rechem</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wenqi Wei</a></p>
<p>Machine learning heavily relies on data, but real-world applications often
encounter various data-related issues. These include data of poor quality,
insufficient data points leading to under-fitting of machine learning models,
and difficulties in data access due to concerns surrounding privacy, safety,
and regulations. In light of these challenges, the concept of synthetic data
generation emerges as a promising alternative that allows for data sharing and
utilization in ways that real-world data cannot facilitate. This paper presents
a comprehensive systematic review of existing studies that employ machine
learning models for the purpose of generating synthetic data. The review
encompasses various perspectives, starting with the applications of synthetic
data generation, spanning computer vision, speech, natural language processing,
healthcare, and business domains. Additionally, it explores different machine
learning methods, with particular emphasis on neural network architectures and
deep generative models. The paper also addresses the crucial aspects of privacy
and fairness concerns related to synthetic data generation. Furthermore, this
study identifies the challenges and opportunities prevalent in this emerging
field, shedding light on the potential avenues for future research. By delving
into the intricacies of synthetic data generation, this paper aims to
contribute to the advancement of knowledge and inspire further exploration in
synthetic data generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.05765">Adversarial Online Collaborative Filtering. (arXiv:2302.05765v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pasteris_S/0/1/0/all/0/1">Stephen Pasteris</a>, <a href="http://arxiv.org/find/cs/1/au:+Vitale_F/0/1/0/all/0/1">Fabio Vitale</a>, <a href="http://arxiv.org/find/cs/1/au:+Herbster_M/0/1/0/all/0/1">Mark Herbster</a>, <a href="http://arxiv.org/find/cs/1/au:+Gentile_C/0/1/0/all/0/1">Claudio Gentile</a>, <a href="http://arxiv.org/find/cs/1/au:+Panisson_A/0/1/0/all/0/1">Andre&#x27; Panisson</a></p>
<p>We investigate the problem of online collaborative filtering under
no-repetition constraints, whereby users need to be served content in an online
fashion and a given user cannot be recommended the same content item more than
once. We start by designing and analyzing an algorithm that works under
biclustering assumptions on the user-item preference matrix, and show that this
algorithm exhibits an optimal regret guarantee, while being fully adaptive, in
that it is oblivious to any prior knowledge about the sequence of users, the
universe of items, as well as the biclustering parameters of the preference
matrix. We then propose a more robust version of this algorithm which operates
with general matrices. Also this algorithm is parameter free, and we prove
regret guarantees that scale with the amount by which the preference matrix
deviates from a biclustered structure. To our knowledge, these are the first
results on online collaborative filtering that hold at this level of generality
and adaptivity under no-repetition constraints. Finally, we complement our
theoretical findings with simple experiments on real-world datasets aimed at
both validating the theory and empirically comparing to standard baselines.
This comparison shows the competitive advantage of our approach over these
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.14770">Completeness of Atomic Structure Representations. (arXiv:2302.14770v3 [physics.chem-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Nigam_J/0/1/0/all/0/1">Jigyasa Nigam</a>, <a href="http://arxiv.org/find/physics/1/au:+Pozdnyakov_S/0/1/0/all/0/1">Sergey N. Pozdnyakov</a>, <a href="http://arxiv.org/find/physics/1/au:+Huguenin_Dumittan_K/0/1/0/all/0/1">Kevin K. Huguenin-Dumittan</a>, <a href="http://arxiv.org/find/physics/1/au:+Ceriotti_M/0/1/0/all/0/1">Michele Ceriotti</a></p>
<p>In this paper, we address the challenge of obtaining a comprehensive and
symmetric representation of point particle groups, such as atoms in a molecule,
which is crucial in physics and theoretical chemistry. The problem has become
even more important with the widespread adoption of machine-learning techniques
in science, as it underpins the capacity of models to accurately reproduce
physical relationships while being consistent with fundamental symmetries and
conservation laws. However, some of the descriptors that are commonly used to
represent point clouds -- most notably those based on discretized correlations
of the neighbor density, that underpin most of the existing ML models of matter
at the atomic scale -- are unable to distinguish between special arrangements
of particles in three dimensions. This makes it impossible to machine learn
their properties. Atom-density correlations are provably complete in the limit
in which they simultaneously describe the mutual relationship between all
atoms, which is impractical. We present a novel approach to construct
descriptors of \emph{finite} correlations based on the relative arrangement of
particle triplets, which can be employed to create symmetry-adapted models with
universal approximation capabilities, which have the resolution of the neighbor
discretization as the sole convergence parameter. Our strategy is demonstrated
on a class of atomic arrangements that are specifically built to defy a broad
class of conventional symmetric descriptors, showcasing its potential for
addressing their limitations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16212">A Multi-objective Complex Network Pruning Framework Based on Divide-and-conquer and Global Performance Impairment Ranking. (arXiv:2303.16212v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shang_R/0/1/0/all/0/1">Ronghua Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Songling Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yinan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weitong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songhua Xu</a></p>
<p>Model compression plays a vital role in the practical deployment of deep
neural networks (DNNs), and evolutionary multi-objective (EMO) pruning is an
essential tool in balancing the compression rate and performance of the DNNs.
However, due to its population-based nature, EMO pruning suffers from the
complex optimization space and the resource-intensive structure verification
process, especially in complex networks. To this end, a multi-objective complex
network pruning framework based on divide-and-conquer and global performance
impairment ranking (EMO-DIR) is proposed in this paper. Firstly, a
divide-and-conquer EMO network pruning method is proposed, which decomposes the
complex task of EMO pruning on the entire network into easier sub-tasks on
multiple sub-networks. On the one hand, this decomposition narrows the pruning
optimization space and decreases the optimization difficulty; on the other
hand, the smaller network structure converges faster, so the proposed algorithm
consumes lower computational resources. Secondly, a sub-network training method
based on cross-network constraints is designed, which could bridge independent
EMO pruning sub-tasks, allowing them to collaborate better and improving the
overall performance of the pruned network. Finally, a multiple sub-networks
joint pruning method based on EMO is proposed. This method combines the Pareto
Fronts from EMO pruning results on multiple sub-networks through global
performance impairment ranking to design a joint pruning scheme. The rich
experiments on CIFAR-10/100 and ImageNet-100/1k are conducted. The proposed
algorithm achieves a comparable performance with the state-of-the-art pruning
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.03365">Decision-Focused Model-based Reinforcement Learning for Reward Transfer. (arXiv:2304.03365v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Abhishek Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Parbhoo_S/0/1/0/all/0/1">Sonali Parbhoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottesman_O/0/1/0/all/0/1">Omer Gottesman</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1">Finale Doshi-Velez</a></p>
<p>Decision-focused (DF) model-based reinforcement learning has recently been
introduced as a powerful algorithm that can focus on learning the MDP dynamics
that are most relevant for obtaining high returns. While this approach
increases the agent's performance by directly optimizing the reward, it does so
by learning less accurate dynamics from a maximum likelihood perspective. We
demonstrate that when the reward function is defined by preferences over
multiple objectives, the DF model may be sensitive to changes in the objective
preferences.In this work, we develop the robust decision-focused (RDF)
algorithm, which leverages the non-identifiability of DF solutions to learn
models that maximize expected returns while simultaneously learning models that
transfer to changes in the preference over multiple objectives. We demonstrate
the effectiveness of RDF on two synthetic domains and two healthcare
simulators, showing that it significantly improves the robustness of DF model
learning to changes in the reward function without compromising training-time
return.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.08842">UDTIRI: An Online Open-Source Intelligent Road Inspection Benchmark Suite. (arXiv:2304.08842v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Sicen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiahang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dacheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Denghuang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1">Shuai Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingyi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qijun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1">Rui Fan</a></p>
<p>In the nascent domain of urban digital twins (UDT), the prospects for
leveraging cutting-edge deep learning techniques are vast and compelling.
Particularly within the specialized area of intelligent road inspection (IRI),
a noticeable gap exists, underscored by the current dearth of dedicated
research efforts and the lack of large-scale well-annotated datasets. To foster
advancements in this burgeoning field, we have launched an online open-source
benchmark suite, referred to as UDTIRI. Along with this article, we introduce
the road pothole detection task, the first online competition published within
this benchmark suite. This task provides a well-annotated dataset, comprising
1,000 RGB images and their pixel/instance-level ground-truth annotations,
captured in diverse real-world scenarios under different illumination and
weather conditions. Our benchmark provides a systematic and thorough evaluation
of state-of-the-art object detection, semantic segmentation, and instance
segmentation networks, developed based on either convolutional neural networks
or Transformers. We anticipate that our benchmark will serve as a catalyst for
the integration of advanced UDT techniques into IRI. By providing algorithms
with a more comprehensive understanding of diverse road conditions, we seek to
unlock their untapped potential and foster innovation in this critical domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.13586">Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1">Khai Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1">Nhat Ho</a></p>
<p>The sliced Wasserstein (SW) distance has been widely recognized as a
statistically effective and computationally efficient metric between two
probability measures. A key component of the SW distance is the slicing
distribution. There are two existing approaches for choosing this distribution.
The first approach is using a fixed prior distribution. The second approach is
optimizing for the best distribution which belongs to a parametric family of
distributions and can maximize the expected distance. However, both approaches
have their limitations. A fixed prior distribution is non-informative in terms
of highlighting projecting directions that can discriminate two general
probability measures. Doing optimization for the best distribution is often
expensive and unstable. Moreover, designing the parametric family of the
candidate distribution could be easily misspecified. To address the issues, we
propose to design the slicing distribution as an energy-based distribution that
is parameter-free and has the density proportional to an energy function of the
projected one-dimensional Wasserstein distance. We then derive a novel sliced
Wasserstein metric, energy-based sliced Waserstein (EBSW) distance, and
investigate its topological, statistical, and computational properties via
importance sampling, sampling importance resampling, and Markov Chain methods.
Finally, we conduct experiments on point-cloud gradient flow, color transfer,
and point-cloud reconstruction to show the favorable performance of the EBSW.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.13710">Hopfield model with planted patterns: a teacher-student self-supervised learning model. (arXiv:2304.13710v3 [cond-mat.dis-nn] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Alemanno_F/0/1/0/all/0/1">Francesco Alemanno</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Camanzi_L/0/1/0/all/0/1">Luca Camanzi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Manzan_G/0/1/0/all/0/1">Gianluca Manzan</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Tantari_D/0/1/0/all/0/1">Daniele Tantari</a></p>
<p>While Hopfield networks are known as paradigmatic models for memory storage
and retrieval, modern artificial intelligence systems mainly stand on the
machine learning paradigm. We show that it is possible to formulate a
teacher-student self-supervised learning problem with Boltzmann machines in
terms of a suitable generalization of the Hopfield model with structured
patterns, where the spin variables are the machine weights and patterns
correspond to the training set's examples. We analyze the learning performance
by studying the phase diagram in terms of the training set size, the dataset
noise and the inference temperature (i.e. the weight regularization). With a
small but informative dataset the machine can learn by memorization. With a
noisy dataset, an extensive number of examples above a critical threshold is
needed. In this regime the memory storage limits of the system becomes an
opportunity for the occurrence of a learning regime in which the system can
generalize.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.14870">Using a Deep Learning Model to Simulate Human Stock Trader&#x27;s Methods of Chart Analysis. (arXiv:2304.14870v2 [q-fin.ST] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Kang_S/0/1/0/all/0/1">Sungwoo Kang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Kim_J/0/1/0/all/0/1">Jong-Kook Kim</a></p>
<p>Despite the efficient market hypothesis, many studies suggest the existence
of inefficiencies in the stock market leading to the development of techniques
to gain above-market returns. Systematic trading has undergone significant
advances in recent decades with deep learning schemes emerging as a powerful
tool for analyzing and predicting market behavior. In this paper, a method is
proposed that is inspired by how professional technical analysts trade. This
scheme looks at stock prices of the previous 600 days and predicts whether the
stock price will rise or fall 10% or 20% within the next D days. Plus, the
proposed method uses the Resnet's (a deep learning model) skip connections and
logits to increase the probability of the prediction. The model was trained and
tested using historical data from both the Korean and US stock markets. We show
that using the period label of 5 gives the best result. On Korea market it
achieved a profit more than 39% above the market return, and a profit more than
40% above the market return on the US market.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.09126">Transfer Learning for Causal Effect Estimation. (arXiv:2305.09126v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Song Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1">Ronald Moore</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamaleswaran_R/0/1/0/all/0/1">Rishikesan Kamaleswaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yao Xie</a></p>
<p>We present a Transfer Causal Learning (TCL) framework when target and source
domains share the same covariate/feature spaces, aiming to improve causal
effect estimation accuracy in limited data. Limited data is very common in
medical applications, where some rare medical conditions, such as sepsis, are
of interest. Our proposed method, named \texttt{$\ell_1$-TCL}, incorporates
$\ell_1$ regularized TL for nuisance models (e.g., propensity score model); the
TL estimator of the nuisance parameters is plugged into downstream average
causal/treatment effect estimators (e.g., inverse probability weighted
estimator). We establish non-asymptotic recovery guarantees for the
\texttt{$\ell_1$-TCL} with generalized linear model (GLM) under the sparsity
assumption in the high-dimensional setting, and demonstrate the empirical
benefits of \texttt{$\ell_1$-TCL} through extensive numerical simulation for
GLM and recent neural network nuisance models. Our method is subsequently
extended to real data and generates meaningful insights consistent with medical
literature, a case where all baseline methods fail.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16943">DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models. (arXiv:2305.16943v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1">Sohyun An</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1">Jaehyeong Jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seanie Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a></p>
<p>Existing NAS methods suffer from either an excessive amount of time for
repetitive sampling and training of many task-irrelevant architectures. To
tackle such limitations of existing NAS methods, we propose a paradigm shift
from NAS to a novel conditional Neural Architecture Generation (NAG) framework
based on diffusion models, dubbed DiffusionNAG. Specifically, we consider the
neural architectures as directed graphs and propose a graph diffusion model for
generating them. Moreover, with the guidance of parameterized predictors,
DiffusionNAG can flexibly generate task-optimal architectures with the desired
properties for diverse tasks, by sampling from a region that is more likely to
satisfy the properties. This conditional NAG scheme is significantly more
efficient than previous NAS schemes which sample the architectures and filter
them using the property predictors. We validate the effectiveness of
DiffusionNAG through extensive experiments in two predictor-based NAS
scenarios: Transferable NAS and Bayesian Optimization (BO)-based NAS.
DiffusionNAG achieves superior performance with speedups of up to 20 times when
compared to the baselines on Transferable NAS benchmarks. Furthermore, when
integrated into a BO-based algorithm, DiffusionNAG outperforms existing
BO-based NAS approaches, particularly in the large MobileNetV3 search space on
the ImageNet 1K dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.17282">Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. II. (arXiv:2305.17282v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1">Sushma Kumari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pestov_V/0/1/0/all/0/1">Vladimir G. Pestov</a></p>
<p>We continue to investigate the $k$ nearest neighbour learning rule in
separable metric spaces. Thanks to the results of C\'erou and Guyader (2006)
and Preiss (1983), this rule is known to be universally consistent in every
metric space $X$ that is sigma-finite dimensional in the sense of Nagata. Here
we show that the rule is strongly universally consistent in such spaces in the
absence of ties. Under the tie-breaking strategy applied by Devroye,
Gy\"{o}rfi, Krzy\.{z}ak, and Lugosi (1994) in the Euclidean setting, we manage
to show the strong universal consistency in non-Archimedian metric spaces (that
is, those of Nagata dimension zero). Combining the theorem of C\'erou and
Guyader with results of Assouad and Quentin de Gromard (2006), one deduces that
the $k$-NN rule is universally consistent in metric spaces having finite
dimension in the sense of de Groot. In particular, the $k$-NN rule is
universally consistent in the Heisenberg group which is not sigma-finite
dimensional in the sense of Nagata as follows from an example independently
constructed by Kor\'anyi and Reimann (1995) and Sawyer and Wheeden (1992).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00354">Addressing Negative Transfer in Diffusion Models. (arXiv:2306.00354v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Go_H/0/1/0/all/0/1">Hyojun Go</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">JinYoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yunsung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Shinhyeok Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_H/0/1/0/all/0/1">Hyeongdon Moon</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Seungtaek Choi</a></p>
<p>Diffusion-based generative models have achieved remarkable success in various
domains. It trains a shared model on denoising tasks that encompass different
noise levels simultaneously, representing a form of multi-task learning (MTL).
However, analyzing and improving diffusion models from an MTL perspective
remains under-explored. In particular, MTL can sometimes lead to the well-known
phenomenon of negative transfer, which results in the performance degradation
of certain tasks due to conflicts between tasks. In this paper, we first aim to
analyze diffusion training from an MTL standpoint, presenting two key
observations: (O1) the task affinity between denoising tasks diminishes as the
gap between noise levels widens, and (O2) negative transfer can arise even in
diffusion training. Building upon these observations, we aim to enhance
diffusion training by mitigating negative transfer. To achieve this, we propose
leveraging existing MTL methods, but the presence of a huge number of denoising
tasks makes this computationally expensive to calculate the necessary per-task
loss or gradient. To address this challenge, we propose clustering the
denoising tasks into small task clusters and applying MTL methods to them.
Specifically, based on (O2), we employ interval clustering to enforce temporal
proximity among denoising tasks within clusters. We show that interval
clustering can be solved using dynamic programming, utilizing signal-to-noise
ratio, timestep, and task affinity for clustering objectives. Through this, our
approach addresses the issue of negative transfer in diffusion models by
allowing for efficient computation of MTL methods. We validate the efficacy of
proposed clustering and its integration with MTL methods through various
experiments, demonstrating 1) improved generation quality and 2) faster
training convergence of diffusion models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05836">Can Large Language Models Infer Causation from Correlation?. (arXiv:2306.05836v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhijing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiarui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1">Zhiheng Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Poff_S/0/1/0/all/0/1">Spencer Poff</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>, <a href="http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1">Mona Diab</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a></p>
<p>Causal inference is one of the hallmarks of human intelligence. While the
field of CausalNLP has attracted much interest in the recent years, existing
causal inference datasets in NLP primarily rely on discovering causality from
empirical knowledge (e.g., commonsense knowledge). In this work, we propose the
first benchmark dataset to test the pure causal inference skills of large
language models (LLMs). Specifically, we formulate a novel task Corr2Cause,
which takes a set of correlational statements and determines the causal
relationship between the variables. We curate a large-scale dataset of more
than 200K samples, on which we evaluate seventeen existing LLMs. Through our
experiments, we identify a key shortcoming of LLMs in terms of their causal
inference skills, and show that these models achieve almost close to random
performance on the task. This shortcoming is somewhat mitigated when we try to
re-purpose LLMs for this skill via finetuning, but we find that these models
still fail to generalize -- they can only perform causal inference in
in-distribution settings when variable names and textual expressions used in
the queries are similar to those in the training set, but fail in
out-of-distribution settings generated by perturbing these queries. Corr2Cause
is a challenging task for LLMs, and would be helpful in guiding future research
on improving LLMs' pure reasoning skills and generalizability. Our data is at
https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at
https://github.com/causalNLP/corr2cause.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11250">InRank: Incremental Low-Rank Learning. (arXiv:2306.11250v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiawei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Beidi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schafer_F/0/1/0/all/0/1">Florian Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a></p>
<p>The theory of greedy low-rank learning (GLRL) aims to explain the impressive
generalization capabilities of deep learning. It proves that stochastic
gradient-based training implicitly regularizes neural networks towards low-rank
solutions through a gradual increase of the rank during training. However,
there is a gap between theory and practice since GLRL requires an infinitesimal
initialization of the weights, which is not practical due to the fact that it
is a saddle point. In this work, we remove the assumption of infinitesimal
initialization by focusing on cumulative weight updates. We prove the
cumulative weight updates follow an incremental low-rank trajectory for
arbitrary orthogonal initialization of weights in a three-layer linear network.
Empirically, we demonstrate that our theory holds on a broad range of neural
networks (e.g., transformers) and standard training algorithms (e.g., SGD,
Adam). However, existing training algorithms do not exploit the low-rank
property to improve computational efficiency as the networks are not
parameterized in low-rank. To remedy this, we design a new training algorithm
Incremental Low-Rank Learning (InRank), which explicitly expresses cumulative
weight updates as low-rank matrices while incrementally augmenting their ranks
during training. We evaluate InRank on GPT-2, and our results indicate that
InRank achieves comparable prediction performance as the full-rank counterpart
while requiring at most 33% of the total ranks throughout training. We also
propose an efficient version of InRank that achieves a reduction of 37% in
total training time and 36% in model size when training GPT-medium on
WikiText-103 from scratch.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.13746">Revisiting inference after prediction. (arXiv:2306.13746v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Motwani_K/0/1/0/all/0/1">Keshav Motwani</a>, <a href="http://arxiv.org/find/stat/1/au:+Witten_D/0/1/0/all/0/1">Daniela Witten</a></p>
<p>Recent work has focused on the very common practice of prediction-based
inference: that is, (i) using a pre-trained machine learning model to predict
an unobserved response variable, and then (ii) conducting inference on the
association between that predicted response and some covariates. As pointed out
by Wang et al. (2020), applying a standard inferential approach in (ii) does
not accurately quantify the association between the unobserved (as opposed to
the predicted) response and the covariates. In recent work, Wang et al. (2020)
and Angelopoulos et al. (2023) propose corrections to step (ii) in order to
enable valid inference on the association between the unobserved response and
the covariates. Here, we show that the method proposed by Angelopoulos et al.
(2023) successfully controls the type 1 error rate and provides confidence
intervals with correct nominal coverage, regardless of the quality of the
pre-trained machine learning model used to predict the unobserved response.
However, the method proposed by Wang et al. (2020) provides valid inference
only under very strong conditions that rarely hold in practice: for instance,
if the machine learning model perfectly estimates the true regression function
in the study population of interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.14872">Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yuwei Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayati_M/0/1/0/all/0/1">Mohsen Bayati</a></p>
<p>This paper is motivated by recent research in the $d$-dimensional stochastic
linear bandit literature, which has revealed an unsettling discrepancy:
algorithms like Thompson sampling and Greedy demonstrate promising empirical
performance, yet this contrasts with their pessimistic theoretical regret
bounds. The challenge arises from the fact that while these algorithms may
perform poorly in certain problem instances, they generally excel in typical
instances. To address this, we propose a new data-driven technique that tracks
the geometric properties of the uncertainty ellipsoid around the main problem
parameter. This methodology enables us to formulate an instance-dependent
frequentist regret bound, which incorporates the geometric information, for a
broad class of base algorithms, including Greedy, OFUL, and Thompson sampling.
This result allows us to identify and ``course-correct" problem instances in
which the base algorithms perform poorly. The course-corrected algorithms
achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$
for a $T$-period decision-making scenario, effectively maintaining the
desirable attributes of the base algorithms, including their empirical
efficacy. We present simulation results to validate our findings using
synthetic and real data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15546">When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions. (arXiv:2306.15546v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1">Lingjuan Lyu</a></p>
<p>The intersection of the Foundation Model (FM) and Federated Learning (FL)
provides mutual benefits, presents a unique opportunity to unlock new
possibilities in AI research, and address critical challenges in AI and
real-world applications. FL expands the availability of data for FMs and
enables computation sharing, distributing the training process and reducing the
burden on FL participants. It promotes collaborative FM development,
democratizing the process and fostering inclusivity and innovation. On the
other hand, FM, with its enormous size, pre-trained knowledge, and exceptional
performance, serves as a robust starting point for FL, facilitating faster
convergence and better performance under non-iid data. Additionally, leveraging
FM to generate synthetic data enriches data diversity, reduces overfitting, and
preserves privacy. By examining the interplay between FL and FM, this paper
aims to deepen the understanding of their synergistic relationship,
highlighting the motivations, challenges, and future directions. Through an
exploration of the challenges faced by FL and FM individually and their
interconnections, we aim to inspire future research directions that can further
enhance both fields, driving advancements and propelling the development of
privacy-preserving and scalable AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12083">Active Control of Flow over Rotating Cylinder by Multiple Jets using Deep Reinforcement Learning. (arXiv:2307.12083v3 [physics.flu-dyn] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Dobakhti_K/0/1/0/all/0/1">Kamyar Dobakhti</a>, <a href="http://arxiv.org/find/physics/1/au:+Ghazanfarian_J/0/1/0/all/0/1">Jafar Ghazanfarian</a></p>
<p>The real power of artificial intelligence appears in reinforcement learning,
which is computationally and physically more sophisticated due to its dynamic
nature. Rotation and injection are some of the proven ways in active flow
control for drag reduction on blunt bodies. In this paper, rotation will be
added to the cylinder alongside the deep reinforcement learning (DRL)
algorithm, which uses multiple controlled jets to reach the maximum possible
drag suppression. Characteristics of the DRL code, including controlling
parameters, their limitations, and optimization of the DRL network for use with
rotation will be presented. This work will focus on optimizing the number and
positions of the jets, the sensors location, and the maximum allowed flow rate
to jets in the form of the maximum allowed flow rate of each actuation and the
total number of them per episode. It is found that combining the rotation and
DRL is promising since it suppresses the vortex shedding, stabilizes the Karman
vortex street, and reduces the drag coefficient by up to 49.75%. Also, it will
be shown that having more sensors at more locations is not always a good choice
and the sensor number and location should be determined based on the need of
the user and corresponding configuration. Also, allowing the agent to have
access to higher flow rates, mostly reduces the performance, except when the
cylinder rotates. In all cases, the agent can keep the lift coefficient at a
value near zero, or stabilize it at a smaller number.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13535">Do algorithms and barriers for sparse principal component analysis extend to other structured settings?. (arXiv:2307.13535v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wang_G/0/1/0/all/0/1">Guanyi Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lou_M/0/1/0/all/0/1">Mengqi Lou</a>, <a href="http://arxiv.org/find/stat/1/au:+Pananjady_A/0/1/0/all/0/1">Ashwin Pananjady</a></p>
<p>We study a principal component analysis problem under the spiked Wishart
model in which the structure in the signal is captured by a class of
union-of-subspace models. This general class includes vanilla sparse PCA as
well as its variants with graph sparsity. With the goal of studying these
problems under a unified statistical and computational lens, we establish
fundamental limits that depend on the geometry of the problem instance, and
show that a natural projected power method exhibits local convergence to the
statistically near-optimal neighborhood of the solution. We complement these
results with end-to-end analyses of two important special cases given by path
and tree sparsity in a general basis, showing initialization methods and
matching evidence of computational hardness. Overall, our results indicate that
several of the phenomena observed for vanilla sparse PCA extend in a natural
fashion to its structured counterparts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04102">Asynchronous Evolution of Deep Neural Network Architectures. (arXiv:2308.04102v3 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jason Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahrzad_H/0/1/0/all/0/1">Hormoz Shahrzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1">Risto Miikkulainen</a></p>
<p>Many evolutionary algorithms (EAs) take advantage of parallel evaluation of
candidates. However, if evaluation times vary significantly, many worker nodes
(i.e.,\ compute clients) are idle much of the time, waiting for the next
generation to be created. Evolutionary neural architecture search (ENAS), a
class of EAs that optimizes the architecture and hyperparameters of deep neural
networks, is particularly vulnerable to this issue. This paper proposes a
generic asynchronous evaluation strategy (AES) that is then adapted to work
with ENAS. AES increases throughput by maintaining a queue of up to $K$
individuals ready to be sent to the workers for evaluation and proceeding to
the next generation as soon as $M&lt;&lt;K$ individuals have been evaluated. A
suitable value for $M$ is determined experimentally, balancing diversity and
efficiency. To showcase the generality and power of AES, it was first evaluated
in eight-line sorting network design (a single-population optimization task
with limited evaluation-time variability), achieving an over two-fold speedup.
Next, it was evaluated in 11-bit multiplexer design (a single-population
discovery task with extended variability), where a 14-fold speedup was
observed. It was then scaled up to ENAS for image captioning (a
multi-population open-ended-optimization task), resulting in an over two-fold
speedup. In all problems, a multifold performance improvement was observed,
suggesting that AES is a promising method for parallelizing the evolution of
complex systems with long and variable evaluation times, such as those in ENAS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.06382">Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion. (arXiv:2308.06382v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Siyuan Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Amartya Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliva_J/0/1/0/all/0/1">Junier B. Oliva</a></p>
<p>Voice conversion (VC) aims at altering a person's voice to make it sound
similar to the voice of another person while preserving linguistic content.
Existing methods suffer from a dilemma between content intelligibility and
speaker similarity; i.e., methods with higher intelligibility usually have a
lower speaker similarity, while methods with higher speaker similarity usually
require plenty of target speaker voice data to achieve high intelligibility. In
this work, we propose a novel method \textit{Phoneme Hallucinator} that
achieves the best of both worlds. Phoneme Hallucinator is a one-shot VC model;
it adopts a novel model to hallucinate diversified and high-fidelity target
speaker phonemes based just on a short target speaker voice (e.g. 3 seconds).
The hallucinated phonemes are then exploited to perform neighbor-based voice
conversion. Our model is a text-free, any-to-any VC model that requires no text
annotations and supports conversion to any unseen speaker. Objective and
subjective evaluations show that \textit{Phoneme Hallucinator} outperforms
existing VC methods for both intelligibility and speaker similarity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.07931">Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation. (arXiv:2308.07931v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">William Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Ge Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1">Alan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1">Jansen Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1">Leslie Pack Kaelbling</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a></p>
<p>Self-supervised and language-supervised image models contain rich knowledge
of the world that is important for generalization. Many robotic tasks, however,
require a detailed understanding of 3D geometry, which is often lacking in 2D
image features. This work bridges this 2D-to-3D gap for robotic manipulation by
leveraging distilled feature fields to combine accurate 3D geometry with rich
semantics from 2D foundation models. We present a few-shot learning method for
6-DOF grasping and placing that harnesses these strong spatial and semantic
priors to achieve in-the-wild generalization to unseen objects. Using features
distilled from a vision-language model, CLIP, we present a way to designate
novel objects for manipulation via free-text natural language, and demonstrate
its ability to generalize to unseen expressions and novel categories of
objects.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.10273">Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks. (arXiv:2308.10273v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zuheng Xu</a></p>
<p>Continuous Conditional Generative Adversarial Networks (CcGANs) enable
generative modeling conditional on continuous scalar variables (termed
regression labels). However, they can produce subpar fake images due to limited
training data. Although Negative Data Augmentation (NDA) effectively enhances
unconditional and class-conditional GANs by introducing anomalies into real
training images, guiding the GANs away from low-quality outputs, its impact on
CcGANs is limited, as it fails to replicate negative samples that may occur
during the CcGAN sampling. We present a novel NDA approach called Dual-NDA
specifically tailored for CcGANs to address this problem. Dual-NDA employs two
types of negative samples: visually unrealistic images generated from a
pre-trained CcGAN and label-inconsistent images created by manipulating real
images' labels. Leveraging these negative samples, we introduce a novel
discriminator objective alongside a modified CcGAN training algorithm.
Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA
consistently enhances the visual fidelity and label consistency of fake images
generated by CcGANs, exhibiting a substantial performance gain over the vanilla
NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable
advancement beyond the capabilities of state-of-the-art conditional GANs and
diffusion models, establishing a new pinnacle of performance. Our codes can be
found at https://github.com/UBCDingXin/Dual-NDA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12210">ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy. (arXiv:2308.12210v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kato_F/0/1/0/all/0/1">Fumiyuki Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Takagi_S/0/1/0/all/0/1">Shun Takagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1">Masatoshi Yoshikawa</a></p>
<p>Differentially Private Federated Learning (DP-FL) has garnered attention as a
collaborative machine learning approach that ensures formal privacy. Most DP-FL
approaches ensure DP at the record-level within each silo for cross-silo FL.
However, a single user's data may extend across multiple silos, and the desired
user-level DP guarantee for such a setting remains unknown. In this study, we
present Uldp-FL, a novel FL framework designed to guarantee user-level DP in
cross-silo FL where a single user's data may belong to multiple silos. Our
proposed algorithm directly ensures user-level DP through per-user weighted
clipping, departing from group-privacy approaches. We provide a theoretical
analysis of the algorithm's privacy and utility. Additionally, we enhance the
utility of the proposed algorithm with an enhanced weighting strategy based on
user record distribution and design a novel private protocol that ensures no
additional information is revealed to the silos and the server. Experiments on
real-world datasets show substantial improvements in our methods in
privacy-utility trade-offs under user-level DP compared to baseline methods. To
the best of our knowledge, our work is the first FL framework that effectively
provides user-level DP in the general cross-silo FL setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.15821">Federated Two Stage Decoupling With Adaptive Personalization Layers. (arXiv:2308.15821v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hangyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yuxiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhenping Xie</a></p>
<p>Federated learning has gained significant attention due to its groundbreaking
ability to enable distributed learning while maintaining privacy constraints.
However, as a consequence of data heterogeneity among decentralized devices, it
inherently experiences significant learning degradation and slow convergence
speed. Therefore, it is natural to employ the concept of clustering homogeneous
clients into the same group, allowing only the model weights within each group
to be aggregated. While most existing clustered federated learning methods
employ either model gradients or inference outputs as metrics for client
partitioning, with the goal of grouping similar devices together, may still
have heterogeneity within each cluster. Moreover, there is a scarcity of
research exploring the underlying reasons for determining the appropriate
timing for clustering, resulting in the common practice of assigning each
client to its own individual cluster, particularly in the context of highly non
independent and identically distributed (Non-IID) data. In this paper, we
introduce a two-stage decoupling federated learning algorithm with adaptive
personalization layers named FedTSDP, where client clustering is performed
twice according to inference outputs and model weights, respectively. Hopkins
amended sampling is adopted to determine the appropriate timing for clustering
and the sampling weight of public unlabeled data. In addition, a simple yet
effective approach is developed to adaptively adjust the personalization layers
based on varying degrees of data skew. Experimental results show that our
proposed method has reliable performance on both IID and non-IID scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.00993">A Boosted Machine Learning Framework for the Improvement of Phase and Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and Configurational Parameters. (arXiv:2309.00993v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1">Debsundar Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Suchandan Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1">Anik Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Santanu Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Raul_C/0/1/0/all/0/1">Chandan Kumar Raul</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1">Arghya Chatterjee</a></p>
<p>The reason behind the remarkable properties of High-Entropy Alloys (HEAs) is
rooted in the diverse phases and the crystal structures they contain. In the
realm of material informatics, employing machine learning (ML) techniques to
classify phases and crystal structures of HEAs has gained considerable
significance. In this study, we assembled a new collection of 1345 HEAs with
varying compositions to predict phases. Within this collection, there were 705
sets of data that were utilized to predict the crystal structures with the help
of thermodynamics and electronic configuration. Our study introduces a
methodical framework i.e., the Pearson correlation coefficient that helps in
selecting the strongly co-related features to increase the prediction accuracy.
This study employed five distinct boosting algorithms to predict phases and
crystal structures, offering an enhanced guideline for improving the accuracy
of these predictions. Among all these algorithms, XGBoost gives the highest
accuracy of prediction (94.05%) for phases and LightGBM gives the highest
accuracy of prediction of crystal structure of the phases (90.07%). The
quantification of the influence exerted by parameters on the model's accuracy
was conducted and a new approach was made to elucidate the contribution of
individual parameters in the process of phase prediction and crystal structure
prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.01030">Online Adaptive Mahalanobis Distance Estimation. (arXiv:2309.01030v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1">Lianke Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1">Aravind Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a></p>
<p>Mahalanobis metrics are widely used in machine learning in conjunction with
methods like $k$-nearest neighbors, $k$-means clustering, and $k$-medians
clustering. Despite their importance, there has not been any prior work on
applying sketching techniques to speed up algorithms for Mahalanobis metrics.
In this paper, we initiate the study of dimension reduction for Mahalanobis
metrics. In particular, we provide efficient data structures for solving the
Approximate Distance Estimation (ADE) problem for Mahalanobis distances. We
first provide a randomized Monte Carlo data structure. Then, we show how we can
adapt it to provide our main data structure which can handle sequences of
\textit{adaptive} queries and also online updates to both the Mahalanobis
metric matrix and the data points, making it amenable to be used in conjunction
with prior algorithms for online learning of Mahalanobis metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.02332">Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations. (arXiv:2309.02332v2 [q-bio.NC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Nilsson_M/0/1/0/all/0/1">Martin N. P. Nilsson</a></p>
<p>In the intricate architecture of the mammalian central nervous system,
neurons form populations. Axonal bundles communicate between these clusters
using spike trains. However, these neuron populations' precise encoding and
operations have yet to be discovered. In our analysis, the starting point is a
state-of-the-art mechanistic model of a generic neuron endowed with plasticity.
From this simple framework emerges a subtle mathematical construct: The
representation and manipulation of information can be precisely characterized
by an algebra of convex cones. Furthermore, these neuron populations are not
merely passive transmitters. They act as operators within this algebraic
structure, mirroring the functionality of a low-level programming language.
When these populations interconnect, they embody succinct yet potent algebraic
expressions. These networks allow them to implement many operations, such as
specialization, generalization, novelty detection, dimensionality reduction,
inverse modeling, prediction, and associative memory. In broader terms, this
work illuminates the potential of matrix embeddings in advancing our
understanding in fields like cognitive science and AI. These embeddings enhance
the capacity for concept processing and hierarchical description over their
vector counterparts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03537">Data-Adaptive Graph Framelets with Generalized Vanishing Moments for Graph Signal Processing. (arXiv:2309.03537v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Zheng_R/0/1/0/all/0/1">Ruigang Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhuang_X/0/1/0/all/0/1">Xiaosheng Zhuang</a></p>
<p>In this paper, we propose a novel and general framework to construct tight
framelet systems on graphs with localized supports based on hierarchical
partitions. Our construction provides parametrized graph framelet systems with
great generality based on partition trees, by which we are able to find the
size of a low-dimensional subspace that best fits the low-rank structure of a
family of signals. The orthogonal decomposition of subspaces provides a key
ingredient for the definition of "generalized vanishing moments" for graph
framelets. In a data-adaptive setting, the graph framelet systems can be
learned by solving an optimization problem on Stiefel manifolds with respect to
our parameterization. Moreover, such graph framelet systems can be further
improved by solving a subsequent optimization problem on Stiefel manifolds,
aiming at providing the utmost sparsity for a given family of graph signals.
Experimental results show that our learned graph framelet systems perform
superiorly in non-linear approximation and denoising tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03842">Early warning indicators via latent stochastic dynamical systems. (arXiv:2309.03842v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1">Lingyu Feng</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1">Ting Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Xiao_W/0/1/0/all/0/1">Wang Xiao</a>, <a href="http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1">Jinqiao Duan</a></p>
<p>Detecting early warning indicators for abrupt dynamical transitions in
complex systems or high-dimensional observation data is essential in many
real-world applications, such as brain diseases, natural disasters, financial
crises, and engineering reliability. To this end, we develop a novel approach:
the directed anisotropic diffusion map that captures the latent evolutionary
dynamics in the low-dimensional manifold. Then three effective warning signals
(Onsager-Machlup Indicator, Sample Entropy Indicator, and Transition
Probability Indicator) are derived through the latent coordinates and the
latent stochastic dynamical systems. To validate our framework, we apply this
methodology to authentic electroencephalogram (EEG) data. We find that our
early warning indicators are capable of detecting the tipping point during
state transition. This framework not only bridges the latent dynamics with
real-world data but also shows the potential ability for automatic labeling on
complex high-dimensional time series.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.11766">Dictionary Attack on IMU-based Gait Authentication. (arXiv:2309.11766v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Rajesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Isik_C/0/1/0/all/0/1">Can Isik</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_C/0/1/0/all/0/1">Chilukuri K. Mohan</a></p>
<p>We present a novel adversarial model for authentication systems that use gait
patterns recorded by the inertial measurement unit (IMU) built into
smartphones. The attack idea is inspired by and named after the concept of a
dictionary attack on knowledge (PIN or password) based authentication systems.
In particular, this work investigates whether it is possible to build a
dictionary of IMUGait patterns and use it to launch an attack or find an
imitator who can actively reproduce IMUGait patterns that match the target's
IMUGait pattern. Nine physically and demographically diverse individuals walked
at various levels of four predefined controllable and adaptable gait factors
(speed, step length, step width, and thigh-lift), producing 178 unique IMUGait
patterns. Each pattern attacked a wide variety of user authentication models.
The deeper analysis of error rates (before and after the attack) challenges the
belief that authentication systems based on IMUGait patterns are the most
difficult to spoof; further research is needed on adversarial models and
associated countermeasures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.15366">Density Estimation via Measure Transport: Outlook for Applications in the Biological Sciences. (arXiv:2309.15366v2 [q-bio.QM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Lopez_Marrero_V/0/1/0/all/0/1">Vanessa Lopez-Marrero</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Johnstone_P/0/1/0/all/0/1">Patrick R. Johnstone</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Park_G/0/1/0/all/0/1">Gilchan Park</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Luo_X/0/1/0/all/0/1">Xihaier Luo</a></p>
<p>One among several advantages of measure transport methods is that they allow
for a unified framework for processing and analysis of data distributed
according to a wide class of probability measures. Within this context, we
present results from computational studies aimed at assessing the potential of
measure transport techniques, specifically, the use of triangular transport
maps, as part of a workflow intended to support research in the biological
sciences. Scarce data scenarios, which are common in domains such as radiation
biology, are of particular interest. We find that when data is scarce, sparse
transport maps are advantageous. In particular, statistics gathered from
computing series of (sparse) adaptive transport maps, trained on a series of
randomly chosen subsets of the set of available data samples, leads to
uncovering information hidden in the data. As a result, in the radiation
biology application considered here, this approach provides a tool for
generating hypotheses about gene relationships and their dynamics under
radiation exposure.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07220">COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL. (arXiv:2310.07220v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiyao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Ruijie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yanchao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ruonan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wongkamjan_W/0/1/0/all/0/1">Wichayaporn Wongkamjan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a></p>
<p>Dyna-style model-based reinforcement learning contains two phases: model
rollouts to generate sample for policy learning and real environment
exploration using current policy for dynamics model learning. However, due to
the complex real-world environment, it is inevitable to learn an imperfect
dynamics model with model prediction error, which can further mislead policy
learning and result in sub-optimal solutions. In this paper, we propose
$\texttt{COPlanner}$, a planning-driven framework for model-based methods to
address the inaccurately learned dynamics model problem with conservative model
rollouts and optimistic environment exploration. $\texttt{COPlanner}$ leverages
an uncertainty-aware policy-guided model predictive control (UP-MPC) component
to plan for multi-step uncertainty estimation. This estimated uncertainty then
serves as a penalty during model rollouts and as a bonus during real
environment exploration respectively, to choose actions. Consequently,
$\texttt{COPlanner}$ can avoid model uncertain regions through conservative
model rollouts, thereby alleviating the influence of model error.
Simultaneously, it explores high-reward model uncertain regions to reduce model
error actively through optimistic real environment exploration.
$\texttt{COPlanner}$ is a plug-and-play framework that can be applied to any
dyna-style model-based methods. Experimental results on a series of
proprioceptive and visual continuous control tasks demonstrate that both sample
efficiency and asymptotic performance of strong model-based methods are
significantly improved combined with $\texttt{COPlanner}$.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09877">Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE). (arXiv:2310.09877v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Okoli_C/0/1/0/all/0/1">Chitu Okoli</a></p>
<p>Accumulated Local Effects (ALE) is a model-agnostic approach for global
explanations of the results of black-box machine learning (ML) algorithms.
There are at least three challenges with conducting statistical inference based
on ALE: ensuring the reliability of ALE analyses, especially in the context of
small datasets; intuitively characterizing a variable's overall effect in ML;
and making robust inferences from ML data analysis. In response, we introduce
innovative tools and techniques for statistical inference using ALE,
establishing bootstrapped confidence intervals tailored to dataset size and
introducing ALE effect size measures that intuitively indicate effects on both
the outcome variable scale and a normalized scale. Furthermore, we demonstrate
how to use these tools to draw reliable statistical inferences, reflecting the
flexible patterns ALE adeptly highlights, with implementations available in the
'ale' package in R. This work propels the discourse on ALE and its
applicability in ML and statistical analysis forward, offering practical
solutions to prevailing challenges in the field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10483">Passive Inference Attacks on Split Learning via Adversarial Regularization. (arXiv:2310.10483v3 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaochen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xinjian Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuncheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yangfan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xiaokui Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ooi_B/0/1/0/all/0/1">Beng Chin Ooi</a></p>
<p>Split Learning (SL) has emerged as a practical and efficient alternative to
traditional federated learning. While previous attempts to attack SL have often
relied on overly strong assumptions or targeted easily exploitable models, we
seek to develop more practical attacks. We introduce SDAR, a novel attack
framework against SL with an honest-but-curious server. SDAR leverages
auxiliary data and adversarial regularization to learn a decodable simulator of
the client's private model, which can effectively infer the client's private
features under the vanilla SL, and both features and labels under the U-shaped
SL. We perform extensive experiments in both configurations to validate the
effectiveness of our proposed attacks. Notably, in challenging but practical
scenarios where existing passive attacks struggle to reconstruct the client's
private data effectively, SDAR consistently achieves attack performance
comparable to active attacks. On CIFAR-10, at the deep split level of 7, SDAR
achieves private feature reconstruction with less than 0.025 mean squared error
in both the vanilla and the U-shaped SL, and attains a label inference accuracy
of over 98% in the U-shaped setting, while existing attacks fail to produce
non-trivial results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10835">Provable Probabilistic Imaging using Score-Based Generative Priors. (arXiv:2310.10835v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Sun_Y/0/1/0/all/0/1">Yu Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_Z/0/1/0/all/0/1">Zihui Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yifan Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Feng_B/0/1/0/all/0/1">Berthy T. Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Bouman_K/0/1/0/all/0/1">Katherine L. Bouman</a></p>
<p>Estimating high-quality images while also quantifying their uncertainty are
two desired features in an image reconstruction algorithm for solving ill-posed
inverse problems. In this paper, we propose plug-and-play Monte Carlo (PMC) as
a principled framework for characterizing the space of possible solutions to a
general inverse problem. PMC is able to incorporate expressive score-based
generative priors for high-quality image reconstruction while also performing
uncertainty quantification via posterior sampling. In particular, we introduce
two PMC algorithms which can be viewed as the sampling analogues of the
traditional plug-and-play priors (PnP) and regularization by denoising (RED)
algorithms. We also establish a theoretical analysis for characterizing the
convergence of the PMC algorithms. Our analysis provides non-asymptotic
stationarity guarantees for both algorithms, even in the presence of
non-log-concave likelihoods and imperfect score networks. We demonstrate the
performance of the PMC algorithms on multiple representative inverse problems
with both linear and nonlinear forward models. Experimental results show that
PMC significantly improves reconstruction quality and enables high-fidelity
uncertainty quantification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12781">Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Xiong_Y/0/1/0/all/0/1">Yifei Xiong</a>, <a href="http://arxiv.org/find/stat/1/au:+Ju_N/0/1/0/all/0/1">Nianqiao P. Ju</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1">Sanguo Zhang</a></p>
<p>Many modern statistical analysis and machine learning applications require
training models on sensitive user data. Differential privacy provides a formal
guarantee that individual-level information about users does not leak. In this
framework, randomized algorithms inject calibrated noise into the confidential
data, resulting in privacy-protected datasets or queries. However, restricting
access to only privatized data during statistical analysis makes it
computationally challenging to make valid inferences on the parameters
underlying the confidential data. In this work, we propose simulation-based
inference methods from privacy-protected datasets. In addition to sequential
Monte Carlo approximate Bayesian computation, we use neural conditional density
estimators as a flexible family of distributions to approximate the posterior
distribution of model parameters given the observed private query results. We
illustrate our methods on discrete time-series data under an infectious disease
model and with ordinary linear regression models. Illustrating the
privacy-utility trade-off, our experiments and analysis demonstrate the
necessity and feasibility of designing valid statistical inference procedures
to correct for biases introduced by the privacy-protection mechanisms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.03380">An attempt to generate new bridge types from latent space of variational autoencoder. (arXiv:2311.03380v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongjun Zhang</a></p>
<p>Try to generate new bridge types using generative artificial intelligence
technology. The grayscale images of the bridge facade with the change of
component width was rendered by 3dsMax animation software, and then the OpenCV
module performed an appropriate amount of geometric transformation (rotation,
horizontal scale, vertical scale) to obtain the image dataset of three-span
beam bridge, arch bridge, cable-stayed bridge and suspension bridge. Based on
Python programming language, TensorFlow and Keras deep learning platform
framework, variational autoencoder was constructed and trained, and
low-dimensional bridge-type latent space that is convenient for vector
operations was obtained. Variational autoencoder can combine two bridge types
on the basis of the original of human into one that is a new bridge type.
Generative artificial intelligence technology can assist bridge designers in
bridge-type innovation, and can be used as copilot.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13091">Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise. (arXiv:2311.13091v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaidi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a></p>
<p>The open source of large amounts of image data promotes the development of
deep learning techniques. Along with this comes the privacy risk of these
open-source image datasets being exploited by unauthorized third parties to
train deep learning models for commercial or illegal purposes. To avoid the
abuse of public data, a poisoning-based technique, the unlearnable example, is
proposed to significantly degrade the generalization performance of models by
adding a kind of imperceptible noise to the data. To further enhance its
robustness against adversarial training, existing works leverage iterative
adversarial training on both the defensive noise and the surrogate model.
However, it still remains unknown whether the robustness of unlearnable
examples primarily comes from the effect of enhancement in the surrogate model
or the defensive noise. Observing that simply removing the adversarial noise on
the training process of the defensive noise can improve the performance of
robust unlearnable examples, we identify that solely the surrogate model's
robustness contributes to the performance. Furthermore, we found a negative
correlation exists between the robustness of defensive noise and the protection
performance, indicating defensive noise's instability issue. Motivated by this,
to further boost the robust unlearnable example, we introduce stable
error-minimizing noise (SEM), which trains the defensive noise against random
perturbation instead of the time-consuming adversarial perturbation to improve
the stability of defensive noise. Through extensive experiments, we demonstrate
that SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,
and ImageNet Subset in terms of both effectiveness and efficiency. The code is
available at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.15218">Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis. (arXiv:2311.15218v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bathini_S/0/1/0/all/0/1">Sai Akash Bathini</a>, <a href="http://arxiv.org/find/cs/1/au:+Cihan_D/0/1/0/all/0/1">Dagli Cihan</a></p>
<p>The application of Machine learning to finance has become a familiar
approach, even more so in stock market forecasting. The stock market is highly
volatile, and huge amounts of data are generated every minute globally. The
extraction of effective intelligence from this data is of critical importance.
However, a collaboration of numerical stock data with qualitative text data can
be a challenging task. In this work, we accomplish this by providing an
unprecedented, publicly available dataset with technical and fundamental data
and sentiment that we gathered from news archives, TV news captions, radio
transcripts, tweets, daily financial newspapers, etc. The text data entries
used for sentiment extraction total more than 1.4 Million. The dataset consists
of daily entries from January 2018 to December 2022 for eight companies
representing diverse industrial sectors and the Dow Jones Industrial Average
(DJIA) as a whole. Holistic Fundamental and Technical data is provided training
ready for Model learning and deployment. Most importantly, the data generated
could be used for incremental online learning with real-time data points
retrieved daily since no stagnant data was utilized. All the data was retired
from APIs or self-designed robust information retrieval technologies. These
adaptable technologies facilitate data extraction for any stock. Moreover, the
utilization of Spearman's rank correlation over real-time data, linking stock
returns with sentiment analysis has produced noteworthy results for the DJIA,
achieving accuracy levels surpassing 60\%. The dataset is made available at
https://github.com/batking24/Huge-Stock-Dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.15487">Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning. (arXiv:2311.15487v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Thomas Chen</a></p>
<p>We consider the gradient descent flow widely used for the minimization of the
$\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two
modified versions; one adapted for the overparametrized setting, and the other
for the underparametrized setting. Both have a clear and natural invariant
geometric meaning, taking into account the pullback vector bundle structure in
the overparametrized, and the pushforward vector bundle structure in the
underparametrized setting. In the overparametrized case, we prove that,
provided that a rank condition holds, all orbits of the modified gradient
descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform
exponential convergence rate; one thereby obtains an a priori stopping time for
any prescribed proximity to the global minimum. We point out relations of the
latter to sub-Riemannian geometry.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.15654">Event Detection in Time Series: Universal Deep Learning Approach. (arXiv:2311.15654v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Azib_M/0/1/0/all/0/1">Menouar Azib</a>, <a href="http://arxiv.org/find/stat/1/au:+Renard_B/0/1/0/all/0/1">Benjamin Renard</a>, <a href="http://arxiv.org/find/stat/1/au:+Garnier_P/0/1/0/all/0/1">Philippe Garnier</a>, <a href="http://arxiv.org/find/stat/1/au:+Genot_V/0/1/0/all/0/1">Vincent G&#xe9;not</a>, <a href="http://arxiv.org/find/stat/1/au:+Andre_N/0/1/0/all/0/1">Nicolas Andr&#xe9;</a></p>
<p>Event detection in time series is a challenging task due to the prevalence of
imbalanced datasets, rare events, and time interval-defined events. Traditional
supervised deep learning methods primarily employ binary classification, where
each time step is assigned a binary label indicating the presence or absence of
an event. However, these methods struggle to handle these specific scenarios
effectively. To address these limitations, we propose a novel supervised
regression-based deep learning approach that offers several advantages over
classification-based methods. Our approach, with a limited number of
parameters, can effectively handle various types of events within a unified
framework, including rare events and imbalanced datasets. We provide
theoretical justifications for its universality and precision and demonstrate
its superior performance across diverse domains, particularly for rare events
and imbalanced datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00209">On the Interplay Between Stepsize Tuning and Progressive Sharpening. (arXiv:2312.00209v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roulet_V/0/1/0/all/0/1">Vincent Roulet</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwala_A/0/1/0/all/0/1">Atish Agarwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1">Fabian Pedregosa</a></p>
<p>Recent empirical work has revealed an intriguing property of deep learning
models by which the sharpness (largest eigenvalue of the Hessian) increases
throughout optimization until it stabilizes around a critical value at which
the optimizer operates at the edge of stability, given a fixed stepsize (Cohen
et al, 2022). We investigate empirically how the sharpness evolves when using
stepsize-tuners, the Armijo linesearch and Polyak stepsizes, that adapt the
stepsize along the iterations to local quantities such as, implicitly, the
sharpness itself. We find that the surprisingly poor performance of a classical
Armijo linesearch in the deterministic setting may be well explained by its
tendency to ever-increase the sharpness of the objective. On the other hand, we
observe that Polyak stepsizes operate generally at the edge of stability or
even slightly beyond, outperforming its Armijo and constant stepsizes
counterparts in the deterministic setting. We conclude with an analysis that
suggests unlocking stepsize tuners requires an understanding of the joint
dynamics of the step size and the sharpness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01324">MABViT -- Modified Attention Block Enhances Vision Transformers. (arXiv:2312.01324v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramesh_M/0/1/0/all/0/1">Mahesh Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramkumar_A/0/1/0/all/0/1">Aswinkumar Ramkumar</a></p>
<p>Recent studies have demonstrated the effectiveness of Gated Linear Units
(GLU) in enhancing transformer models, particularly in Large Language Models
(LLMs). Additionally, utilizing a parallel configuration within each
Transformer block rather than the conventional serialized method has been
revealed to accelerate the training of LLMs without significantly impacting
performance. However, when the MLP and attention block were run in parallel for
the image classification task, we observed a noticeable decline in performance.
We propose a novel transformer variant that integrates non-linearity within the
attention block to tackle this problem. We implemented the GLU-based activation
function on the Value tensor, and this new technique surpasses the current
state-of-the-art S/16 variant of Vision Transformers by 0.6% on the ImageNet-1K
dataset while utilizing fewer parameters. It also supersedes the B/16 variant
while using only half the parameters. Furthermore, we provide results with the
GELU activation function variant to confirm our assertions. Lastly, we showcase
that the MABViT variants exhibit greater potential when utilized in deep
transformers compared to the standard architecture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04501">Graph Metanetworks for Processing Diverse Neural Architectures. (arXiv:2312.04501v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1">Derek Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Maron_H/0/1/0/all/0/1">Haggai Maron</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1">Marc T. Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Lorraine_J/0/1/0/all/0/1">Jonathan Lorraine</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucas_J/0/1/0/all/0/1">James Lucas</a></p>
<p>Neural networks efficiently encode learned information within their
parameters. Consequently, many tasks can be unified by treating neural networks
themselves as input data. When doing so, recent studies demonstrated the
importance of accounting for the symmetries and geometry of parameter spaces.
However, those works developed architectures tailored to specific networks such
as MLPs and CNNs without normalization layers, and generalizing such
architectures to other types of networks can be challenging. In this work, we
overcome these challenges by building new metanetworks - neural networks that
take weights from other neural networks as input. Put simply, we carefully
build graphs representing the input neural networks and process the graphs
using graph neural networks. Our approach, Graph Metanetworks (GMNs),
generalizes to neural architectures where competing methods struggle, such as
multi-head attention layers, normalization layers, convolutional layers, ResNet
blocks, and group-equivariant linear layers. We prove that GMNs are expressive
and equivariant to parameter permutation symmetries that leave the input neural
network functions unchanged. We validate the effectiveness of our method on
several metanetwork tasks over diverse neural network architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07586">Characteristic Guidance: Non-linear Correction for Diffusion Model at Large Guidance Scale. (arXiv:2312.07586v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Candi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yuan Lan</a></p>
<p>Popular guidance for denoising diffusion probabilistic model (DDPM) linearly
combines distinct conditional models together to provide enhanced control over
samples. However, this approach overlooks nonlinear effects that become
significant when guidance scale is large. To address this issue, we propose
characteristic guidance, a sampling method that provides first-principle
non-linear correction for classifier-free guided DDPMs. Such correction forces
the guided DDPMs to respect the Fokker-Planck equation of their underlying
diffusion process, in a way that is training-free, derivative-free, and
compatible with existing sampling methods. Experiments show that characteristic
guidance enhances control and reduces color and exposure issues in image
generation, proving effective in diverse applications ranging from latent space
sampling to solving physics problems like magnet phase transitions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08793">Forbidden Facts: An Investigation of Competing Objectives in Llama-2. (arXiv:2312.08793v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tony T. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Miles Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hariharan_K/0/1/0/all/0/1">Kaivalya Hariharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shavit_N/0/1/0/all/0/1">Nir Shavit</a></p>
<p>LLMs often face competing pressures (for example helpfulness vs.
harmlessness). To understand how models resolve such conflicts, we study
Llama-2-chat models on the forbidden fact task. Specifically, we instruct
Llama-2 to truthfully complete a factual recall statement while forbidding it
from saying the correct answer. This often makes the model give incorrect
answers. We decompose Llama-2 into 1000+ components, and rank each one with
respect to how useful it is for forbidding the correct answer. We find that in
aggregate, around 35 components are enough to reliably implement the full
suppression behavior. However, these components are fairly heterogeneous and
many operate using faulty heuristics. We discover that one of these heuristics
can be exploited via a manually designed adversarial attack which we call The
California Attack. Our results highlight some roadblocks standing in the way of
being able to successfully interpret advanced ML systems. Project website
available at https://forbiddenfacts.github.io .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09086">COMBHelper: A Neural Approach to Reduce Search Space for Graph Combinatorial Problems. (arXiv:2312.09086v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1">Hao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Medya_S/0/1/0/all/0/1">Sourav Medya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1">Wei Ye</a></p>
<p>Combinatorial Optimization (CO) problems over graphs appear routinely in many
applications such as in optimizing traffic, viral marketing in social networks,
and matching for job allocation. Due to their combinatorial nature, these
problems are often NP-hard. Existing approximation algorithms and heuristics
rely on the search space to find the solutions and become time-consuming when
this space is large. In this paper, we design a neural method called COMBHelper
to reduce this space and thus improve the efficiency of the traditional CO
algorithms based on node selection. Specifically, it employs a Graph Neural
Network (GNN) to identify promising nodes for the solution set. This pruned
search space is then fed to the traditional CO algorithms. COMBHelper also uses
a Knowledge Distillation (KD) module and a problem-specific boosting module to
bring further efficiency and efficacy. Our extensive experiments show that the
traditional CO algorithms with COMBHelper are at least 2 times faster than
their original versions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09168">DiffusionLight: Light Probes for Free by Painting a Chrome Ball. (arXiv:2312.09168v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Phongthawee_P/0/1/0/all/0/1">Pakkapon Phongthawee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chinchuthakun_W/0/1/0/all/0/1">Worameth Chinchuthakun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinsunthithet_N/0/1/0/all/0/1">Nontaphat Sinsunthithet</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_A/0/1/0/all/0/1">Amit Raj</a>, <a href="http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1">Varun Jampani</a>, <a href="http://arxiv.org/find/cs/1/au:+Khungurn_P/0/1/0/all/0/1">Pramook Khungurn</a>, <a href="http://arxiv.org/find/cs/1/au:+Suwajanakorn_S/0/1/0/all/0/1">Supasorn Suwajanakorn</a></p>
<p>We present a simple yet effective technique to estimate lighting in a single
input image. Current techniques rely heavily on HDR panorama datasets to train
neural networks to regress an input with limited field-of-view to a full
environment map. However, these approaches often struggle with real-world,
uncontrolled settings due to the limited diversity and size of their datasets.
To address this problem, we leverage diffusion models trained on billions of
standard images to render a chrome ball into the input image. Despite its
simplicity, this task remains challenging: the diffusion models often insert
incorrect or inconsistent objects and cannot readily generate images in HDR
format. Our research uncovers a surprising relationship between the appearance
of chrome balls and the initial diffusion noise map, which we utilize to
consistently generate high-quality chrome balls. We further fine-tune an LDR
difusion model (Stable Diffusion XL) with LoRA, enabling it to perform exposure
bracketing for HDR light estimation. Our method produces convincing light
estimates across diverse settings and demonstrates superior generalization to
in-the-wild scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10324">Federated Learning with Instance-Dependent Noisy Labels. (arXiv:2312.10324v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jieming Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a></p>
<p>Federated learning (FL) with noisy labels poses a significant challenge.
Existing methods designed for handling noisy labels in centralized learning
tend to lose their effectiveness in the FL setting, mainly due to the small
dataset size and the heterogeneity of client data. While some attempts have
been made to tackle FL with noisy labels, they primarily focused on scenarios
involving class-conditional noise. In this paper, we study the more challenging
and practical issue of instance-dependent noise (IDN) in FL. We introduce a
novel algorithm called FedBeat (Federated Learning with Bayesian
Ensemble-Assisted Transition Matrix Estimation). FedBeat aims to build a global
statistically consistent classifier using the IDN transition matrix (IDNTM),
which encompasses three synergistic steps: (1) A federated data extraction step
that constructs a weak global model and extracts high-confidence data using a
Bayesian model ensemble method. (2) A federated transition matrix estimation
step in which clients collaboratively train an IDNTM estimation network based
on the extracted data. (3) A federated classifier correction step that enhances
the global model's performance by training it using a loss function tailored
for noisy labels, leveraging the IDNTM. Experiments conducted on CIFAR-10 and
SVHN verify that the proposed method significantly outperforms state-of-the-art
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10472">Analyzing Generalization in Policy Networks: A Case Study with the Double-Integrator System. (arXiv:2312.10472v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruining Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Haoran Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_M/0/1/0/all/0/1">Maolong Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qisong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jian Cheng</a></p>
<p>Extensive utilization of deep reinforcement learning (DRL) policy networks in
diverse continuous control tasks has raised questions regarding performance
degradation in expansive state spaces where the input state norm is larger than
that in the training environment. This paper aims to uncover the underlying
factors contributing to such performance deterioration when dealing with
expanded state spaces, using a novel analysis technique known as state
division. In contrast to prior approaches that employ state division merely as
a post-hoc explanatory tool, our methodology delves into the intrinsic
characteristics of DRL policy networks. Specifically, we demonstrate that the
expansion of state space induces the activation function $\tanh$ to exhibit
saturability, resulting in the transformation of the state division boundary
from nonlinear to linear. Our analysis centers on the paradigm of the
double-integrator system, revealing that this gradual shift towards linearity
imparts a control behavior reminiscent of bang-bang control. However, the
inherent linearity of the division boundary prevents the attainment of an ideal
bang-bang control, thereby introducing unavoidable overshooting. Our
experimental investigations, employing diverse RL algorithms, establish that
this performance phenomenon stems from inherent attributes of the DRL policy
network, remaining consistent across various optimization algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10841">Online Boosting Adaptive Learning under Concept Drift for Multistream Classification. (arXiv:2312.10841v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_E/0/1/0/all/0/1">En Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangquan Zhang</a></p>
<p>Multistream classification poses significant challenges due to the necessity
for rapid adaptation in dynamic streaming processes with concept drift. Despite
the growing research outcomes in this area, there has been a notable oversight
regarding the temporal dynamic relationships between these streams, leading to
the issue of negative transfer arising from irrelevant data. In this paper, we
propose a novel Online Boosting Adaptive Learning (OBAL) method that
effectively addresses this limitation by adaptively learning the dynamic
correlation among different streams. Specifically, OBAL operates in a
dual-phase mechanism, in the first of which we design an Adaptive COvariate
Shift Adaptation (AdaCOSA) algorithm to construct an initialized ensemble model
using archived data from various source streams, thus mitigating the covariate
shift while learning the dynamic correlations via an adaptive re-weighting
strategy. During the online process, we employ a Gaussian Mixture Model-based
weighting mechanism, which is seamlessly integrated with the acquired
correlations via AdaCOSA to effectively handle asynchronous drift. This
approach significantly improves the predictive performance and stability of the
target stream. We conduct comprehensive experiments on several synthetic and
real-world data streams, encompassing various drifting scenarios and types. The
results clearly demonstrate that OBAL achieves remarkable advancements in
addressing multistream classification problems by effectively leveraging
positive knowledge derived from multiple sources.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13110">Pre-training of Molecular GNNs as Conditional Boltzmann Generator. (arXiv:2312.13110v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koge_D/0/1/0/all/0/1">Daiki Koge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ono_N/0/1/0/all/0/1">Naoaki Ono</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanaya_S/0/1/0/all/0/1">Shigehiko Kanaya</a></p>
<p>Learning representations of molecular structures using deep learning is a
fundamental problem in molecular property prediction tasks. Molecules
inherently exist in the real world as three-dimensional structures;
furthermore, they are not static but in continuous motion in the 3D Euclidean
space, forming a potential energy surface. Therefore, it is desirable to
generate multiple conformations in advance and extract molecular
representations using a 4D-QSAR model that incorporates multiple conformations.
However, this approach is impractical for drug and material discovery tasks
because of the computational cost of obtaining multiple conformations. To
address this issue, we propose a pre-training method for molecular GNNs using
an existing dataset of molecular conformations to generate a latent vector
universal to multiple conformations from a 2D molecular graph. Our method,
called Boltzmann GNN, is formulated by maximizing the conditional marginal
likelihood of a conditional generative model for conformations generation. We
show that our model has a better prediction performance for molecular
properties than existing pre-training methods using molecular graphs and
three-dimensional molecular structures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13584">Wave Physics-informed Matrix Factorizations. (arXiv:2312.13584v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tetali_H/0/1/0/all/0/1">Harsha Vardhan Tetali</a>, <a href="http://arxiv.org/find/cs/1/au:+Harley_J/0/1/0/all/0/1">Joel B. Harley</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1">Benjamin D. Haeffele</a></p>
<p>With the recent success of representation learning methods, which includes
deep learning as a special case, there has been considerable interest in
developing techniques that incorporate known physical constraints into the
learned representation. As one example, in many applications that involve a
signal propagating through physical media (e.g., optics, acoustics, fluid
dynamics, etc), it is known that the dynamics of the signal must satisfy
constraints imposed by the wave equation. Here we propose a matrix
factorization technique that decomposes such signals into a sum of components,
where each component is regularized to ensure that it {nearly} satisfies wave
equation constraints. Although our proposed formulation is non-convex, we prove
that our model can be efficiently solved to global optimality. Through this
line of work we establish theoretical connections between wave-informed
learning and filtering theory in signal processing. We further demonstrate the
application of this work on modal analysis problems commonly arising in
structural diagnostics and prognostics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.15112">Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation. (arXiv:2312.15112v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Chengming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haolun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chen Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xue Liu</a></p>
<p>Knowledge distillation aims to train a compact student network using soft
supervision from a larger teacher network and hard supervision from ground
truths. However, determining an optimal knowledge fusion ratio that balances
these supervisory signals remains challenging. Prior methods generally resort
to a constant or heuristic-based fusion ratio, which often falls short of a
proper balance. In this study, we introduce a novel adaptive method for
learning a sample-wise knowledge fusion ratio, exploiting both the correctness
of teacher and student, as well as how well the student mimics the teacher on
each sample. Our method naturally leads to the intra-sample trilateral
geometric relations among the student prediction ($S$), teacher prediction
($T$), and ground truth ($G$). To counterbalance the impact of outliers, we
further extend to the inter-sample relations, incorporating the teacher's
global average prediction $\bar{T}$ for samples within the same class. A simple
neural network then learns the implicit mapping from the intra- and
inter-sample relations to an adaptive, sample-wise knowledge fusion ratio in a
bilevel-optimization manner. Our approach provides a simple, practical, and
adaptable solution for knowledge distillation that can be employed across
various architectures and model sizes. Extensive experiments demonstrate
consistent improvements over other loss re-weighting methods on image
classification, attack detection, and click-through rate prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.16430">Preference as Reward, Maximum Preference Optimization with Importance Sampling. (arXiv:2312.16430v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zaifan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chao Wei</a></p>
<p>Preference learning is a key technology for aligning language models with
human values. Reinforcement Learning from Human Feedback (RLHF) is a model
based algorithm to optimize preference learning, which first fitting a reward
model for preference score, and then optimizing generating policy with
on-policy PPO algorithm to maximize the reward. The processing of RLHF is
complex, time-consuming and unstable. Direct Preference Optimization (DPO)
algorithm using off-policy algorithm to direct optimize generating policy and
eliminating the need for reward model, which is data efficient and stable. DPO
use Bradley-Terry model and log-loss which leads to over-fitting to the
preference data at the expense of ignoring KL-regularization term when
preference is deterministic. IPO uses a root-finding MSE loss to solve the
ignoring KL-regularization problem. In this paper, we'll figure out, although
IPO fix the problem when preference is deterministic, but both DPO and IPO
fails the KL-regularization term because the support of preference distribution
not equal to reference distribution. Then, we design a simple and intuitive
off-policy preference optimization algorithm from an importance sampling view,
which we call Maximum Preference Optimization (MPO), and add off-policy
KL-regularization terms which makes KL-regularization truly effective. The
objective of MPO bears resemblance to RLHF's objective, and likes IPO, MPO is
off-policy. So, MPO attains the best of both worlds. To simplify the learning
process and save memory usage, MPO eliminates the needs for both reward model
and reference policy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.16471">A Survey on Super Resolution for video Enhancement Using GAN. (arXiv:2312.16471v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Maity_A/0/1/0/all/0/1">Ankush Maity</a>, <a href="http://arxiv.org/find/eess/1/au:+Pious_R/0/1/0/all/0/1">Roshan Pious</a>, <a href="http://arxiv.org/find/eess/1/au:+Lenka_S/0/1/0/all/0/1">Sourabh Kumar Lenka</a>, <a href="http://arxiv.org/find/eess/1/au:+Choudhary_V/0/1/0/all/0/1">Vishal Choudhary</a>, <a href="http://arxiv.org/find/eess/1/au:+Lokhande_P/0/1/0/all/0/1">Prof. Sharayu Lokhande</a></p>
<p>This compilation of various research paper highlights provides a
comprehensive overview of recent developments in super-resolution image and
video using deep learning algorithms such as Generative Adversarial Networks.
The studies covered in these summaries provide fresh techniques to addressing
the issues of improving image and video quality, such as recursive learning for
video super-resolution, novel loss functions, frame-rate enhancement, and
attention model integration. These approaches are frequently evaluated using
criteria such as PSNR, SSIM, and perceptual indices. These advancements, which
aim to increase the visual clarity and quality of low-resolution video, have
tremendous potential in a variety of sectors ranging from surveillance
technology to medical imaging. In addition, this collection delves into the
wider field of Generative Adversarial Networks, exploring their principles,
training approaches, and applications across a broad range of domains, while
also emphasizing the challenges and opportunities for future research in this
rapidly advancing and changing field of artificial intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.17194">Resilient Constrained Reinforcement Learning. (arXiv:2312.17194v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Ding_D/0/1/0/all/0/1">Dongsheng Ding</a>, <a href="http://arxiv.org/find/math/1/au:+Huan_Z/0/1/0/all/0/1">Zhengyan Huan</a>, <a href="http://arxiv.org/find/math/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a></p>
<p>We study a class of constrained reinforcement learning (RL) problems in which
multiple constraint specifications are not identified before training. It is
challenging to identify appropriate constraint specifications due to the
undefined trade-off between the reward maximization objective and the
constraint satisfaction, which is ubiquitous in constrained decision-making. To
tackle this issue, we propose a new constrained RL approach that searches for
policy and constraint specifications together. This method features the
adaptation of relaxing the constraint according to a relaxation cost introduced
in the learning objective. Since this feature mimics how ecological systems
adapt to disruptions by altering operation, our approach is termed as resilient
constrained RL. Specifically, we provide a set of sufficient conditions that
balance the constraint satisfaction and the reward maximization in notion of
resilient equilibrium, propose a tractable formulation of resilient constrained
policy optimization that takes this equilibrium as an optimal solution, and
advocate two resilient constrained policy search algorithms with non-asymptotic
convergence guarantees on the optimality gap and constraint satisfaction.
Furthermore, we demonstrate the merits and the effectiveness of our approach in
computational experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.04430">Breaking Through the Haze: An Advanced Non-Homogeneous Dehazing Method based on Fast Fourier Convolution and ConvNeXt. (arXiv:2305.04430v1 [cs.CV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Han Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Wei Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jun Chen</a></p>
<p>Haze usually leads to deteriorated images with low contrast, color shift and
structural distortion. We observe that many deep learning based models exhibit
exceptional performance on removing homogeneous haze, but they usually fail to
address the challenge of non-homogeneous dehazing. Two main factors account for
this situation. Firstly, due to the intricate and non uniform distribution of
dense haze, the recovery of structural and chromatic features with high
fidelity is challenging, particularly in regions with heavy haze. Secondly, the
existing small scale datasets for non-homogeneous dehazing are inadequate to
support reliable learning of feature mappings between hazy images and their
corresponding haze-free counterparts by convolutional neural network
(CNN)-based models. To tackle these two challenges, we propose a novel two
branch network that leverages 2D discrete wavelete transform (DWT), fast
Fourier convolution (FFC) residual block and a pretrained ConvNeXt model.
Specifically, in the DWT-FFC frequency branch, our model exploits DWT to
capture more high-frequency features. Moreover, by taking advantage of the
large receptive field provided by FFC residual blocks, our model is able to
effectively explore global contextual information and produce images with
better perceptual quality. In the prior knowledge branch, an ImageNet
pretrained ConvNeXt as opposed to Res2Net is adopted. This enables our model to
learn more supplementary information and acquire a stronger generalization
ability. The feasibility and effectiveness of the proposed method is
demonstrated via extensive experiments and ablation studies. The code is
available at https://github.com/zhouh115/DWT-FFC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00983">Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">MD Shafikul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1">Azmine Toushik Wasi</a></p>
<p>Inventory Routing Problem (IRP) is a crucial challenge in supply chain
management as it involves optimizing efficient route selection while
considering the uncertainty of inventory demand planning. To solve IRPs,
usually a two-stage approach is employed, where demand is predicted using
machine learning techniques first, and then an optimization algorithm is used
to minimize routing costs. Our experiment shows machine learning models fall
short of achieving perfect accuracy because inventory levels are influenced by
the dynamic business environment, which, in turn, affects the optimization
problem in the next stage, resulting in sub-optimal decisions. In this paper,
we formulate and propose a decision-focused learning-based approach to solving
real-world IRPs. This approach directly integrates inventory prediction and
routing optimization within an end-to-end system potentially ensuring a robust
supply chain strategy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.04916">Explainable Identification of Hate Speech towards Islam using Graph Neural Networks. (arXiv:2311.04916v2 [cs.CL] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1">Azmine Toushik Wasi</a></p>
<p>Islamophobic language is a prevalent challenge on online social interaction
platforms. Identifying and eliminating such hatred is a crucial step towards a
future of harmony and peace. This study presents a novel paradigm for
identifying and explaining hate speech towards Islam using graph neural
networks. Utilizing the intrinsic ability of graph neural networks to find,
extract, and use relationships across disparate data points, our model
consistently achieves outstanding performance while offering explanations for
the underlying correlations and causation.
</p>
</p>
</div>

    </div>
    </body>
    