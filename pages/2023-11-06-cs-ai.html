<!DOCTYPE html>
<html>
<head>
<title>2023-11-06-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2311.00706">Can AI Mitigate Human Perceptual Biases? A Pilot Study. (arXiv:2311.00706v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Geuy_R/0/1/0/all/0/1">Ross Geuy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rising_N/0/1/0/all/0/1">Nate Rising</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Tiancheng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_M/0/1/0/all/0/1">Meng Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jian Chen</a></p>
<p>We present results from a pilot experiment to measure if machine
recommendations can debias human perceptual biases in visualization tasks. We
specifically studied the ``pull-down'' effect, i.e., people underestimate the
average position of lines, for the task of estimating the ensemble average of
data points in line charts. These line charts can show for example temperature
or precipitation in 12 months. Six participants estimated ensemble averages
with or without an AI assistant. The assistant, when available, responded at
three different speeds to assemble the conditions of a human collaborator who
may delay his or her responses. Our pilot study showed that participants were
faster with AI assistance in ensemble tasks, compared to the baseline without
AI assistance. Although ``pull-down'' biases were reduced, the effect of AI
assistance was not statistically significant. Also, delaying AI responses had
no significant impact on human decision accuracy. We discuss the implications
of these preliminary results for subsequent studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00710">AI Alignment in the Design of Interactive AI: Specification Alignment, Process Alignment, and Evaluation Support. (arXiv:2311.00710v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Terry_M/0/1/0/all/0/1">Michael Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_C/0/1/0/all/0/1">Chinmay Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wattenberg_M/0/1/0/all/0/1">Martin Wattenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_L/0/1/0/all/0/1">Lucas Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_M/0/1/0/all/0/1">Meredith Ringel Morris</a></p>
<p>AI alignment considers the overall problem of ensuring an AI produces desired
outcomes, without undesirable side effects. While often considered from the
perspectives of safety and human values, AI alignment can also be considered in
the context of designing and evaluating interfaces for interactive AI systems.
This paper maps concepts from AI alignment onto a basic, three step interaction
cycle, yielding a corresponding set of alignment objectives: 1) specification
alignment: ensuring the user can efficiently and reliably communicate
objectives to the AI, 2) process alignment: providing the ability to verify and
optionally control the AI's execution process, and 3) evaluation support:
ensuring the user can verify and understand the AI's output. We also introduce
the concepts of a surrogate process, defined as a simplified, separately
derived, but controllable representation of the AI's actual process; and the
notion of a Process Gulf, which highlights how differences between human and AI
processes can lead to challenges in AI control. To illustrate the value of this
framework, we describe commercial and research systems along each of the three
alignment dimensions, and show how interfaces that provide interactive
alignment mechanisms can lead to qualitatively different and improved user
experiences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00724">Fraud Analytics Using Machine-learning &amp; Engineering on Big Data (FAME) for Telecom. (arXiv:2311.00724v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pratihar_S/0/1/0/all/0/1">Sudarson Roy Pratihar</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Subhadip Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Dash_P/0/1/0/all/0/1">Pranab Kumar Dash</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Amartya Kumar Das</a></p>
<p>Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining
and machine learning techniques (apart from rules oriented approach) have been
used in past, but efficiency has been low as fraud pattern changes very
rapidly. This paper presents an industrialized solution approach with self
adaptive data mining technique and application of big data technologies to
detect fraud and discover novel fraud patterns in accurate, efficient and cost
effective manner. Solution has been successfully demonstrated to detect
International Revenue Share Fraud with &lt;5% false positive. More than 1 Terra
Bytes of Call Detail Record from a reputed wholesale carrier and overseas
telecom transit carrier has been used to conduct this study.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00727">Investigating Relative Performance of Transfer and Meta Learning. (arXiv:2311.00727v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alwis_B/0/1/0/all/0/1">Benji Alwis</a></p>
<p>Over the past decade, the field of machine learning has experienced
remarkable advancements. While image recognition systems have achieved
impressive levels of accuracy, they continue to rely on extensive training
datasets. Additionally, a significant challenge has emerged in the form of poor
out-of-distribution performance, which necessitates retraining neural networks
when they encounter conditions that deviate from their training data. This
limitation has notably contributed to the slow progress in self-driving car
technology. These pressing issues have sparked considerable interest in methods
that enable neural networks to learn effectively from limited data. This paper
presents the outcomes of an extensive investigation designed to compare two
distinct approaches, transfer learning and meta learning, as potential
solutions to this problem. The overarching objective was to establish a robust
criterion for selecting the most suitable method in diverse machine learning
scenarios. Building upon prior research, I expanded the comparative analysis by
introducing a new meta learning method into the investigation. Subsequently, I
assessed whether the findings remained consistent under varying conditions.
Finally, I delved into the impact of altering the size of the training dataset
on the relative performance of these methods. This comprehensive exploration
has yielded insights into the conditions favoring each approach, thereby
facilitating the development of a criterion for selecting the most appropriate
method in any given situation
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00729">ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection. (arXiv:2311.00729v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Phan_T/0/1/0/all/0/1">Thinh Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_K/0/1/0/all/0/1">Khoa Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1">Duy Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1">Gianfranco Doretto</a>, <a href="http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1">Donald Adjeroh</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a></p>
<p>Temporal action detection (TAD) involves the localization and classification
of action instances within untrimmed videos. While standard TAD follows fully
supervised learning with closed-set setting on large training data, recent
zero-shot TAD methods showcase the promising of open-set setting by leveraging
large-scale contrastive visual-language (ViL) pretrained models. However,
existing zero-shot TAD methods have limitations on how to properly construct
the strong relationships between two interdependent tasks of localization and
classification and adapt ViL model to video understanding. In this work, we
present ZEETAD, featuring two modules: dual-localization and zero-shot proposal
classification. The former is a Transformer-based module that detects action
events while selectively collecting crucial semantic embeddings for later
recognition. The latter one, CLIP-based module, generates semantic embeddings
from text and frame inputs for each temporal unit. Additionally, we enhance
discriminative capability on unseen classes by minimally updating the frozen
CLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and
ActivityNet-1.3 datasets demonstrate our approach's superior performance in
zero-shot TAD and effective knowledge transfer from ViL models to unseen action
categories.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00732">tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis. (arXiv:2311.00732v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Glazkova_A/0/1/0/all/0/1">Anna Glazkova</a></p>
<p>The paper describes a system developed for Task 1 at SMM4H 2023. The goal of
the task is to automatically distinguish tweets that self-report a COVID-19
diagnosis (for example, a positive test, clinical diagnosis, or
hospitalization) from those that do not. We investigate the use of different
techniques for preprocessing tweets using four transformer-based models. The
ensemble of fine-tuned language models obtained an F1-score of 84.5%, which is
4.1% higher than the average value.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00738">Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?. (arXiv:2311.00738v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1">Yuwei Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Keunwoo Peter Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Storks_S/0/1/0/all/0/1">Shane Storks</a>, <a href="http://arxiv.org/find/cs/1/au:+Bar_Yossef_I/0/1/0/all/0/1">Itamar Bar-Yossef</a>, <a href="http://arxiv.org/find/cs/1/au:+Iglesia_A/0/1/0/all/0/1">Alexander De La Iglesia</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_M/0/1/0/all/0/1">Megan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiao Lin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1">Joyce Chai</a></p>
<p>Despite tremendous advances in AI, it remains a significant challenge to
develop interactive task guidance systems that can offer situated, personalized
guidance and assist humans in various tasks. These systems need to have a
sophisticated understanding of the user as well as the environment, and make
timely accurate decisions on when and what to say. To address this issue, we
created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based
on natural interaction between a human user and a human instructor. We further
proposed two tasks: User and Environment Understanding, and Instructor Decision
Making. We leveraged several foundation models to study to what extent these
models can be quickly adapted to perceptually enabled task guidance. Our
quantitative, qualitative, and human evaluation results show that these models
can demonstrate fair performances in some cases with no task-specific training,
but a fast and reliable adaptation remains a significant challenge. Our
benchmark and baselines will provide a stepping stone for future work on
situated task guidance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00750">Are These the Same Apple? Comparing Images Based on Object Intrinsics. (arXiv:2311.00750v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kotar_K/0/1/0/all/0/1">Klemen Kotar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Stephen Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hong-Xing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1">Daniel L.K. Yamins</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a></p>
<p>The human visual system can effortlessly recognize an object under different
extrinsic factors such as lighting, object poses, and background, yet current
computer vision systems often struggle with these variations. An important step
to understanding and improving artificial vision systems is to measure image
similarity purely based on intrinsic object properties that define object
identity. This problem has been studied in the computer vision literature as
re-identification, though mostly restricted to specific object categories such
as people and cars. We propose to extend it to general object categories,
exploring an image similarity metric based on object intrinsics. To benchmark
such measurements, we collect the Common paired objects Under differenT
Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different
extrinsic factors such as lighting, poses, and imaging conditions. While
existing methods such as LPIPS and CLIP scores do not measure object intrinsics
well, we find that combining deep features learned from contrastive
self-supervised learning with foreground filtering is a simple yet effective
approach to approximating the similarity. We conduct an extensive survey of
pre-trained features and foreground extraction methods to arrive at a strong
baseline that best measures intrinsic object-centric image similarity among
current methods. Finally, we demonstrate that our approach can aid in
downstream applications such as acting as an analog for human subjects and
improving generalizable re-identification. Please see our project website at
https://s-tian.github.io/projects/cute/ for visualizations of the data and
demos of our metric.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00754">Learning to Design and Use Tools for Robotic Manipulation. (arXiv:2311.00754v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Stephen Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Michelle Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">C. Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a></p>
<p>When limited by their own morphologies, humans and some species of animals
have the remarkable ability to use objects from the environment toward
accomplishing otherwise impossible tasks. Robots might similarly unlock a range
of additional capabilities through tool use. Recent techniques for jointly
optimizing morphology and control via deep learning are effective at designing
locomotion agents. But while outputting a single morphology makes sense for
locomotion, manipulation involves a variety of strategies depending on the task
goals at hand. A manipulation agent must be capable of rapidly prototyping
specialized tools for different goals. Therefore, we propose learning a
designer policy, rather than a single design. A designer policy is conditioned
on task information and outputs a tool design that helps solve the task. A
design-conditioned controller policy can then perform manipulation using these
tools. In this work, we take a step towards this goal by introducing a
reinforcement learning framework for jointly learning these policies. Through
simulated manipulation tasks, we show that this framework is more sample
efficient than prior methods in multi-goal or multi-variant settings, can
perform zero-shot interpolation or fine-tuning to tackle previously unseen
goals, and allows tradeoffs between the complexity of design and control
policies under practical constraints. Finally, we deploy our learned policies
onto a real robot. Please see our supplementary video and website at
https://robotic-tool-design.github.io/ for visualizations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00767">Hand Gesture Classification on Praxis Dataset: Trading Accuracy for Expense. (arXiv:2311.00767v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Islam_R/0/1/0/all/0/1">Rahat Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_K/0/1/0/all/0/1">Kenneth Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yanushkevich_S/0/1/0/all/0/1">Svetlana Yanushkevich</a></p>
<p>In this paper, we investigate hand gesture classifiers that rely upon the
abstracted 'skeletal' data recorded using the RGB-Depth sensor. We focus on
'skeletal' data represented by the body joint coordinates, from the Praxis
dataset. The PRAXIS dataset contains recordings of patients with cortical
pathologies such as Alzheimer's disease, performing a Praxis test under the
direction of a clinician. In this paper, we propose hand gesture classifiers
that are more effective with the PRAXIS dataset than previously proposed
models. Body joint data offers a compressed form of data that can be analyzed
specifically for hand gesture recognition. Using a combination of windowing
techniques with deep learning architecture such as a Recurrent Neural Network
(RNN), we achieved an overall accuracy of 70.8% using only body joint data. In
addition, we investigated a long-short-term-memory (LSTM) to extract and
analyze the movement of the joints through time to recognize the hand gestures
being performed and achieved a gesture recognition rate of 74.3% and 67.3% for
static and dynamic gestures, respectively. The proposed approach contributed to
the task of developing an automated, accurate, and inexpensive approach to
diagnosing cortical pathologies for multiple healthcare applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00772">SAGE: Smart home Agent with Grounded Execution. (arXiv:2311.00772v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rivkin_D/0/1/0/all/0/1">Dmitriy Rivkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogan_F/0/1/0/all/0/1">Francois Hogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feriani_A/0/1/0/all/0/1">Amal Feriani</a>, <a href="http://arxiv.org/find/cs/1/au:+Konar_A/0/1/0/all/0/1">Abhisek Konar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigal_A/0/1/0/all/0/1">Adam Sigal</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Steve Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Greg Dudek</a></p>
<p>This article introduces SAGE (Smart home Agent with Grounded Execution), a
framework designed to maximize the flexibility of smart home assistants by
replacing manually-defined inference logic with an LLM-powered autonomous agent
system. SAGE integrates information about user preferences, device states, and
external factors (such as weather and TV schedules) through the orchestration
of a collection of tools. SAGE's capabilities include learning user preferences
from natural-language utterances, interacting with devices by reading their API
documentation, writing code to continuously monitor devices, and understanding
natural device references. To evaluate SAGE, we develop a benchmark of 43
highly challenging smart home tasks, where SAGE successfully achieves 23 tasks,
significantly outperforming existing LLM-enabled baselines (5/43).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00797">Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling. (arXiv:2311.00797v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Evangelou_N/0/1/0/all/0/1">Nikolaos Evangelou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_T/0/1/0/all/0/1">Tianqi Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Bello_Rivas_J/0/1/0/all/0/1">Juan M. Bello-Rivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Makeev_A/0/1/0/all/0/1">Alexei Makeev</a>, <a href="http://arxiv.org/find/cs/1/au:+Kevrekidis_I/0/1/0/all/0/1">Ioannis G. Kevrekidis</a></p>
<p>We study the tipping point collective dynamics of an adaptive
susceptible-infected-susceptible (SIS) epidemiological network in a
data-driven, machine learning-assisted manner. We identify a
parameter-dependent effective stochastic differential equation (eSDE) in terms
of physically meaningful coarse mean-field variables through a deep-learning
ResNet architecture inspired by numerical stochastic integrators. We construct
an approximate effective bifurcation diagram based on the identified drift term
of the eSDE and contrast it with the mean-field SIS model bifurcation diagram.
We observe a subcritical Hopf bifurcation in the evolving network's effective
SIS dynamics, that causes the tipping point behavior; this takes the form of
large amplitude collective oscillations that spontaneously -- yet rarely --
arise from the neighborhood of a (noisy) stationary state. We study the
statistics of these rare events both through repeated brute force simulations
and by using established mathematical/computational tools exploiting the
right-hand-side of the identified SDE. We demonstrate that such a collective
SDE can also be identified (and the rare events computations also performed) in
terms of data-driven coarse observables, obtained here via manifold learning
techniques, in particular Diffusion Maps. The workflow of our study is
straightforwardly applicable to other complex dynamics problems exhibiting
tipping point dynamics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00800">Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks. (arXiv:2311.00800v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fadaei_A/0/1/0/all/0/1">AmirHosein Fadaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehaqani_M/0/1/0/all/0/1">Mohammad-Reza A. Dehaqani</a></p>
<p>A defining characteristic of natural vision is its ability to withstand a
variety of input alterations, resulting in the creation of an invariant
representation of the surroundings. While convolutional neural networks exhibit
resilience to certain forms of spatial input variation, modifications in the
spatial and temporal aspects can significantly affect the representations of
video content in deep neural networks. Inspired by the resilience of natural
vision to input variations, we employ a simple multi-stream model to explore
its potential to address spatiotemporal changes by including temporal features.
Our primary goal is to introduce a video-trained model and evaluate its
robustness to diverse image and video inputs, with a particular focus on
exploring the role of temporal features in invariant recognition. Results show
that including videos and the temporal stream during training mitigates the
decline in accuracy and mAP in image and video understanding tasks by 1.36% and
3.14%, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00837">Constant-time Motion Planning with Anytime Refinement for Manipulation. (arXiv:2311.00837v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mishani_I/0/1/0/all/0/1">Itamar Mishani</a>, <a href="http://arxiv.org/find/cs/1/au:+Feddock_H/0/1/0/all/0/1">Hayden Feddock</a>, <a href="http://arxiv.org/find/cs/1/au:+Likhachev_M/0/1/0/all/0/1">Maxim Likhachev</a></p>
<p>Robotic manipulators are essential for future autonomous systems, yet limited
trust in their autonomy has confined them to rigid, task-specific systems. The
intricate configuration space of manipulators, coupled with the challenges of
obstacle avoidance and constraint satisfaction, often makes motion planning the
bottleneck for achieving reliable and adaptable autonomy. Recently, a class of
constant-time motion planners (CTMP) was introduced. These planners employ a
preprocessing phase to compute data structures that enable online planning
provably guarantee the ability to generate motion plans, potentially
sub-optimal, within a user defined time bound. This framework has been
demonstrated to be effective in a number of time-critical tasks. However,
robotic systems often have more time allotted for planning than the online
portion of CTMP requires, time that can be used to improve the solution. To
this end, we propose an anytime refinement approach that works in combination
with CTMP algorithms. Our proposed framework, as it operates as a constant time
algorithm, rapidly generates an initial solution within a user-defined time
threshold. Furthermore, functioning as an anytime algorithm, it iteratively
refines the solution's quality within the allocated time budget. This enables
our approach to strike a balance between guaranteed fast plan generation and
the pursuit of optimization over time. We support our approach by elucidating
its analytical properties, showing the convergence of the anytime component
towards optimal solutions. Additionally, we provide empirical validation
through simulation and real-world demonstrations on a 6 degree-of-freedom robot
manipulator, applied to an assembly domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00842">healthAIChain: Improving security and safety using Blockchain Technology applications in AI-based healthcare systems. (arXiv:2311.00842v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kshetri_N/0/1/0/all/0/1">Naresh Kshetri</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutson_J/0/1/0/all/0/1">James Hutson</a>, <a href="http://arxiv.org/find/cs/1/au:+G_R/0/1/0/all/0/1">Revathy G</a></p>
<p>Blockchain as a digital ledger for keeping records of digital transactions
and other information, it is secure and decentralized technology. The globally
growing number of digital population every day possesses a significant threat
to online data including the medical and patients data. After bitcoin,
blockchain technology has emerged into a general-purpose technology with
applications in medical industries and healthcare. Blockchain can promote
highly configurable openness while retaining the highest security standards for
critical data of medical patients. Referred to as distributed record keeping
for healthcare systems which makes digital assets unalterable and transparent
via a cryptographic hash and decentralized network. The study delves into the
security and safety improvement associated with implementing blockchain in
AI-based healthcare systems. Blockchain-enabled AI tackles the existing issues
related to security, performance efficiencies, and safety in healthcare
systems. We have also examined the Artificial Intelligence in healthcare and
medical industry, potential areas, open questions concerning the blockchain in
healthcare systems. Finally, the article proposed an AI-based healthcare
blockchain model (healthAIChain) to improve patients data and security.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00855">A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan. (arXiv:2311.00855v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1">Dinesh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Ankit Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalappa_C/0/1/0/all/0/1">Chaitra Gopalappa</a></p>
<p>Human immunodeficiency virus (HIV) is a major public health concern in the
United States, with about 1.2 million people living with HIV and 35,000 newly
infected each year. There are considerable geographical disparities in HIV
burden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE)
initiative aims to reduce new infections by 90% by 2030, by improving coverage
of diagnoses, treatment, and prevention interventions and prioritizing
jurisdictions with high HIV prevalence. Identifying optimal scale-up of
intervention combinations will help inform resource allocation. Existing HIV
decision analytic models either evaluate specific cities or the overall
national population, thus overlooking jurisdictional interactions or
differences. In this paper, we propose a multi-agent reinforcement learning
(MARL) model, that enables jurisdiction-specific decision analyses but in an
environment with cross-jurisdictional epidemiological interactions. In
experimental analyses, conducted on jurisdictions within California and
Florida, optimal policies from MARL were significantly different than those
generated from single-agent RL, highlighting the influence of jurisdictional
variations and interactions. By using comprehensive modeling of HIV and
formulations of state space, action space, and reward functions, this work
helps demonstrate the strengths and applicability of MARL for informing public
health policies, and provides a framework for expanding to the national-level
to inform the EHE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00859">Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems. (arXiv:2311.00859v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Ziqing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guanlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1">Lifeng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weiyu Xu</a></p>
<p>Finding optimal adversarial attack strategies is an important topic in
reinforcement learning and the Markov decision process. Previous studies
usually assume one all-knowing coordinator (attacker) for whom attacking
different recipient (victim) agents incurs uniform costs. However, in reality,
instead of using one limitless central attacker, the attacks often need to be
performed by distributed attack agents. We formulate the problem of performing
optimal adversarial agent-to-agent attacks using distributed attack agents, in
which we impose distinct cost constraints on each different attacker-victim
pair. We propose an optimal method integrating within-step static constrained
attack-resource allocation optimization and between-step dynamic programming to
achieve the optimal adversarial attack in a multi-agent system. Our numerical
results show that the proposed attacks can significantly reduce the rewards
received by the attacked agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00860">Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leng_K/0/1/0/all/0/1">Kuangdai Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_M/0/1/0/all/0/1">Mallikarjun Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiyagalingam_J/0/1/0/all/0/1">Jeyan Thiyagalingam</a></p>
<p>Automatic differentiation (AD) is a critical step in physics-informed machine
learning, required for computing the high-order derivatives of network output
w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm
to conduct such AD for physics-informed operator learning, as we call the trick
of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf
variables, ZCS introduces only one scalar-valued leaf variable for each spatial
or temporal dimension, leading to a game-changing performance leap by
simplifying the wanted derivatives from "many-roots-many-leaves" to
"one-root-many-leaves". ZCS is easy to implement with current deep learning
libraries; our own implementation is by extending the DeepXDE package. We carry
out a comprehensive benchmark analysis and several case studies, training
physics-informed DeepONets to solve partial differential equations (PDEs)
without data. The results show that ZCS has persistently brought down GPU
memory consumption and wall time for training by an order of magnitude, with
the savings increasing with problem scale (i.e., number of functions, number of
points and order of PDE). As a low-level optimisation, ZCS entails no
restrictions on data, physics (PDEs) or network architecture and does not
compromise training results from any aspect.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00863">Training Dynamics of Contextual N-Grams in Language Models. (arXiv:2311.00863v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Quirke_L/0/1/0/all/0/1">Lucia Quirke</a>, <a href="http://arxiv.org/find/cs/1/au:+Heindrich_L/0/1/0/all/0/1">Lovis Heindrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurnee_W/0/1/0/all/0/1">Wes Gurnee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1">Neel Nanda</a></p>
<p>Prior work has shown the existence of contextual neurons in language models,
including a neuron that activates on German text. We show that this neuron
exists within a broader contextual n-gram circuit: we find late layer neurons
which recognize and continue n-grams common in German text, but which only
activate if the German neuron is active. We investigate the formation of this
circuit throughout training and find that it is an example of what we call a
second-order circuit. In particular, both the constituent n-gram circuits and
the German detection circuit which culminates in the German neuron form with
independent functions early in training - the German detection circuit
partially through modeling German unigram statistics, and the n-grams by
boosting appropriate completions. Only after both circuits have already formed
do they fit together into a second-order circuit. Contrary to the hypotheses
presented in prior work, we find that the contextual n-gram circuit forms
gradually rather than in a sudden phase transition. We further present a range
of anomalous observations such as a simultaneous phase transition in many tasks
coinciding with the learning rate warm-up, and evidence that many context
neurons form simultaneously early in training but are later unlearned.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00865">Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning. (arXiv:2311.00865v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gerstgrasser_M/0/1/0/all/0/1">Matthias Gerstgrasser</a>, <a href="http://arxiv.org/find/cs/1/au:+Danino_T/0/1/0/all/0/1">Tom Danino</a>, <a href="http://arxiv.org/find/cs/1/au:+Keren_S/0/1/0/all/0/1">Sarah Keren</a></p>
<p>We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized
Experience Relay, in which agents share with other agents a limited number of
transitions they observe during training. The intuition behind this is that
even a small number of relevant experiences from other agents could help each
agent learn. Unlike many other multi-agent RL algorithms, this approach allows
for largely decentralized training, requiring only a limited communication
channel between agents. We show that our approach outperforms baseline
no-sharing decentralized training and state-of-the art multi-agent RL
algorithms. Further, sharing only a small number of highly relevant experiences
outperforms sharing all experiences between agents, and the performance uplift
from selective experience sharing is robust across a range of hyperparameters
and DQN variants. A reference implementation of our algorithm is available at
https://github.com/mgerstgrasser/super.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00880">SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization. (arXiv:2311.00880v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mhamed_J/0/1/0/all/0/1">Jaafar Mhamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shangding Gu</a></p>
<p>Incorporating safety is an essential prerequisite for broadening the
practical applications of reinforcement learning in real-world scenarios. To
tackle this challenge, Constrained Markov Decision Processes (CMDPs) are
leveraged, which introduce a distinct cost function representing safety
violations. In CMDPs' settings, Lagrangian relaxation technique has been
employed in previous algorithms to convert constrained optimization problems
into unconstrained dual problems. However, these algorithms may inaccurately
predict unsafe behavior, resulting in instability while learning the Lagrange
multiplier. This study introduces a novel safe reinforcement learning
algorithm, Safety Critic Policy Optimization (SCPO). In this study, we define
the safety critic, a mechanism that nullifies rewards obtained through
violating safety constraints. Furthermore, our theoretical analysis indicates
that the proposed algorithm can automatically balance the trade-off between
adhering to safety constraints and maximizing rewards. The effectiveness of the
SCPO algorithm is empirically validated by benchmarking it against strong
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00889">Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code. (arXiv:2311.00889v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Siddiq_M/0/1/0/all/0/1">Mohammed Latif Siddiq</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Joanna C. S. Santos</a></p>
<p>With the growing popularity of Large Language Models (e.g. GitHub Copilot,
ChatGPT, etc.) in software engineers' daily practices, it is important to
ensure that the code generated by these tools is not only functionally correct
but also free of vulnerabilities. Although LLMs can help developers to be more
productive, prior empirical studies have shown that LLMs can generate insecure
code. There are two contributing factors to the insecure code generation.
First, existing datasets used to evaluate Large Language Models (LLMs) do not
adequately represent genuine software engineering tasks sensitive to security.
Instead, they are often based on competitive programming challenges or
classroom-type coding tasks. In real-world applications, the code produced is
integrated into larger codebases, introducing potential security risks. There's
a clear absence of benchmarks that focus on evaluating the security of the
generated code. Second, existing evaluation metrics primarily focus on the
functional correctness of the generated code while ignoring security
considerations. Metrics such as pass@k gauge the probability of obtaining the
correct code in the top k suggestions. Other popular metrics like BLEU,
CodeBLEU, ROUGE, and METEOR similarly emphasize functional accuracy, neglecting
security implications. In light of these research gaps, in this paper, we
described SALLM, a framework to benchmark LLMs' abilities to generate secure
code systematically. This framework has three major components: a novel dataset
of security-centric Python prompts, an evaluation environment to test the
generated code, and novel metrics to evaluate the models' performance from the
perspective of secure code generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00903">Artificial Intelligence Ethics Education in Cybersecurity: Challenges and Opportunities: a focus group report. (arXiv:2311.00903v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jackson_D/0/1/0/all/0/1">Diane Jackson</a>, <a href="http://arxiv.org/find/cs/1/au:+Matei_S/0/1/0/all/0/1">Sorin Adam Matei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertino_E/0/1/0/all/0/1">Elisa Bertino</a></p>
<p>The emergence of AI tools in cybersecurity creates many opportunities and
uncertainties. A focus group with advanced graduate students in cybersecurity
revealed the potential depth and breadth of the challenges and opportunities.
The salient issues are access to open source or free tools, documentation,
curricular diversity, and clear articulation of ethical principles for AI
cybersecurity education. Confronting the "black box" mentality in AI
cybersecurity work is also of the greatest importance, doubled by deeper and
prior education in foundational AI work. Systems thinking and effective
communication were considered relevant areas of educational improvement. Future
AI educators and practitioners need to address these issues by implementing
rigorous technical training curricula, clear documentation, and frameworks for
ethically monitoring AI combined with critical and system's thinking and
communication skills.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00924">The Power of the Senses: Generalizable Manipulation from Vision and Touch through Masked Multimodal Learning. (arXiv:2311.00924v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sferrazza_C/0/1/0/all/0/1">Carmelo Sferrazza</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1">Younggyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Youngwoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a></p>
<p>Humans rely on the synergy of their senses for most essential tasks. For
tasks requiring object manipulation, we seamlessly and effectively exploit the
complementarity of our senses of vision and touch. This paper draws inspiration
from such capabilities and aims to find a systematic approach to fuse visual
and tactile information in a reinforcement learning setting. We propose Masked
Multimodal Learning (M3L), which jointly learns a policy and visual-tactile
representations based on masked autoencoding. The representations jointly
learned from vision and touch improve sample efficiency, and unlock
generalization capabilities beyond those achievable through each of the senses
separately. Remarkably, representations learned in a multimodal setting also
benefit vision-only policies at test time. We evaluate M3L on three simulated
environments with both visual and tactile observations: robotic insertion, door
opening, and dexterous in-hand manipulation, demonstrating the benefits of
learning a multimodal policy. Code and videos of the experiments are available
at https://sferrazza.cc/m3l_site.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00926">M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place. (arXiv:2311.00926v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Wentao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Murali_A/0/1/0/all/0/1">Adithyavairavan Murali</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1">Arsalan Mousavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a></p>
<p>With the advent of large language models and large-scale robotic datasets,
there has been tremendous progress in high-level decision-making for object
manipulation. These generic models are able to interpret complex tasks using
language commands, but they often have difficulties generalizing to
out-of-distribution objects due to the inability of low-level action
primitives. In contrast, existing task-specific models excel in low-level
manipulation of unknown objects, but only work for a single type of action. To
bridge this gap, we present M2T2, a single model that supplies different types
of low-level actions that work robustly on arbitrary objects in cluttered
scenes. M2T2 is a transformer model which reasons about contact points and
predicts valid gripper poses for different action modes given a raw point cloud
of the scene. Trained on a large-scale synthetic dataset with 128K scenes, M2T2
achieves zero-shot sim2real transfer on the real robot, outperforming the
baseline system with state-of-the-art task-specific models by about 19% in
overall performance and 37.5% in challenging scenes where the object needs to
be re-oriented for collision-free placement. M2T2 also achieves
state-of-the-art results on a subset of language conditioned tasks in RLBench.
Videos of robot experiments on unseen objects in both real world and simulation
are available on our project website https://m2-t2.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00927">Scalable Counterfactual Distribution Estimation in Multivariate Causal Models. (arXiv:2311.00927v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1">Thong Pham</a>, <a href="http://arxiv.org/find/stat/1/au:+Shimizu_S/0/1/0/all/0/1">Shohei Shimizu</a>, <a href="http://arxiv.org/find/stat/1/au:+Hino_H/0/1/0/all/0/1">Hideitsu Hino</a>, <a href="http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1">Tam Le</a></p>
<p>We consider the problem of estimating the counterfactual joint distribution
of multiple quantities of interests (e.g., outcomes) in a multivariate causal
model extended from the classical difference-in-difference design. Existing
methods for this task either ignore the correlation structures among dimensions
of the multivariate outcome by considering univariate causal models on each
dimension separately and hence produce incorrect counterfactual distributions,
or poorly scale even for moderate-size datasets when directly dealing with such
multivariate causal model. We propose a method that alleviates both issues
simultaneously by leveraging a robust latent one-dimensional subspace of the
original high-dimension space and exploiting the efficient estimation from the
univariate causal model on such space. Since the construction of the
one-dimensional subspace uses information from all the dimensions, our method
can capture the correlation structures and produce good estimates of the
counterfactual distribution. We demonstrate the advantages of our approach over
existing methods on both synthetic and real-world data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00938">Bridging the Gap: Addressing Discrepancies in Diffusion Model Training for Classifier-Free Guidance. (arXiv:2311.00938v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1">Niket Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Salamanca_L/0/1/0/all/0/1">Luis Salamanca</a>, <a href="http://arxiv.org/find/cs/1/au:+Barba_L/0/1/0/all/0/1">Luis Barba</a></p>
<p>Diffusion models have emerged as a pivotal advancement in generative models,
setting new standards to the quality of the generated instances. In the current
paper we aim to underscore a discrepancy between conventional training methods
and the desired conditional sampling behavior of these models. While the
prevalent classifier-free guidance technique works well, it's not without
flaws. At higher values for the guidance scale parameter $w$, we often get out
of distribution samples and mode collapse, whereas at lower values for $w$ we
may not get the desired specificity. To address these challenges, we introduce
an updated loss function that better aligns training objectives with sampling
behaviors. Experimental validation with FID scores on CIFAR-10 elucidates our
method's ability to produce higher quality samples with fewer sampling
timesteps, and be more robust to the choice of guidance scale $w$. We also
experiment with fine-tuning Stable Diffusion on the proposed loss, to provide
early evidence that large diffusion models may also benefit from this refined
loss function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00941">Gaussian Mixture Solvers for Diffusion Models. (arXiv:2311.00941v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hanzhong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1">Fan Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shuicheng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1">Chao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chongxuan Li</a></p>
<p>Recently, diffusion models have achieved great success in generative tasks.
Sampling from diffusion models is equivalent to solving the reverse diffusion
stochastic differential equations (SDEs) or the corresponding probability flow
ordinary differential equations (ODEs). In comparison, SDE-based solvers can
generate samples of higher quality and are suited for image translation tasks
like stroke-based synthesis. During inference, however, existing SDE-based
solvers are severely constrained by the efficiency-effectiveness dilemma. Our
investigation suggests that this is because the Gaussian assumption in the
reverse transition kernel is frequently violated (even in the case of simple
mixture data) given a limited number of discretization steps. To overcome this
limitation, we introduce a novel class of SDE-based solvers called
\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver
estimates the first three-order moments and optimizes the parameters of a
Gaussian mixture transition kernel using generalized methods of moments in each
step during sampling. Empirically, our solver outperforms numerous SDE-based
solvers in terms of sample quality in image generation and stroke-based
synthesis in various diffusion models, which validates the motivation and
effectiveness of GMS. Our code is available at
https://github.com/Guohanzhong/GMS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00958">IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End Task-Oriented Dialogue Systems. (arXiv:2311.00958v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kautsar_M/0/1/0/all/0/1">Muhammad Dehan Al Kautsar</a>, <a href="http://arxiv.org/find/cs/1/au:+Nurdini_R/0/1/0/all/0/1">Rahmah Khoirussyifa&#x27; Nurdini</a>, <a href="http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1">Samuel Cahyawijaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1">Genta Indra Winata</a>, <a href="http://arxiv.org/find/cs/1/au:+Purwarianti_A/0/1/0/all/0/1">Ayu Purwarianti</a></p>
<p>Task-oriented dialogue (ToD) systems have been mostly created for
high-resource languages, such as English and Chinese. However, there is a need
to develop ToD systems for other regional or local languages to broaden their
ability to comprehend the dialogue contexts in various languages. This paper
introduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We
extend two English ToD datasets to Indonesian, comprising four different
domains by delexicalization to efficiently reduce the size of annotations. To
ensure a high-quality data collection, we hire native speakers to manually
translate the dialogues. Along with the original English datasets, these new
Indonesian datasets serve as an effective benchmark for evaluating Indonesian
and English ToD systems as well as exploring the potential benefits of
cross-lingual and bilingual transfer learning approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00967">Vision-Language Interpreter for Robot Task Planning. (arXiv:2311.00967v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shirai_K/0/1/0/all/0/1">Keisuke Shirai</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltran_Hernandez_C/0/1/0/all/0/1">Cristian C. Beltran-Hernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamaya_M/0/1/0/all/0/1">Masashi Hamaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_A/0/1/0/all/0/1">Atsushi Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_S/0/1/0/all/0/1">Shohei Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawaharazuka_K/0/1/0/all/0/1">Kento Kawaharazuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_K/0/1/0/all/0/1">Kazutoshi Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1">Yoshitaka Ushiku</a>, <a href="http://arxiv.org/find/cs/1/au:+Mori_S/0/1/0/all/0/1">Shinsuke Mori</a></p>
<p>Large language models (LLMs) are accelerating the development of
language-guided robot planners. Meanwhile, symbolic planners offer the
advantage of interpretability. This paper proposes a new task that bridges
these two trends, namely, multimodal planning problem specification. The aim is
to generate a problem description (PD), a machine-readable file used by the
planners to find a plan. By generating PDs from language instruction and scene
observation, we can drive symbolic planners in a language-guided framework. We
propose a Vision-Language Interpreter (ViLaIn), a new framework that generates
PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine
generated PDs via error message feedback from the symbolic planner. Our aim is
to answer the question: How accurately can ViLaIn and the symbolic planner
generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset
called the problem description generation (ProDG) dataset. The framework is
evaluated with four new evaluation metrics. Experimental results show that
ViLaIn can generate syntactically correct problems with more than 99% accuracy
and valid plans with more than 58% accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00968">Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model. (arXiv:2311.00968v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jaeyong Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>, <a href="http://arxiv.org/find/cs/1/au:+Herremans_D/0/1/0/all/0/1">Dorien Herremans</a></p>
<p>Numerous studies in the field of music generation have demonstrated
impressive performance, yet virtually no models are able to directly generate
music to match accompanying videos. In this work, we develop a generative music
AI framework, Video2Music, that can match a provided video. We first curated a
unique collection of music videos. Then, we analysed the music videos to obtain
semantic, scene offset, motion, and emotion features. These distinct features
are then employed as guiding input to our music generation model. We transcribe
the audio files into MIDI and chords, and extract features such as note density
and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on
which we train a novel Affective Multimodal Transformer (AMT) model to generate
music given a video. This model includes a novel mechanism to enforce affective
similarity between video and music. Finally, post-processing is performed based
on a biGRU-based regression model to estimate note density and loudness based
on the video features. This ensures a dynamic rendering of the generated chords
with varying rhythm and volume. In a thorough experiment, we show that our
proposed framework can generate music that matches the video content in terms
of emotion. The musical quality, along with the quality of music-video matching
is confirmed in a user study. The proposed AMT model, along with the new
MuVi-Sync dataset, presents a promising step for the new task of music
generation for videos.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00971">An Integrated Framework Integrating Monte Carlo Tree Search and Supervised Learning for Train Timetabling Problem. (arXiv:2311.00971v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Feiyu Yang</a></p>
<p>The single-track railway train timetabling problem (TTP) is an important and
complex problem. This article proposes an integrated Monte Carlo Tree Search
(MCTS) computing framework that combines heuristic methods, unsupervised
learning methods, and supervised learning methods for solving TTP in discrete
action spaces. This article first describes the mathematical model and
simulation system dynamics of TTP, analyzes the characteristics of the solution
from the perspective of MCTS, and proposes some heuristic methods to improve
MCTS. This article considers these methods as planners in the proposed
framework. Secondly, this article utilizes deep convolutional neural networks
to approximate the value of nodes and further applies them to the MCTS search
process, referred to as learners. The experiment shows that the proposed
heuristic MCTS method is beneficial for solving TTP; The algorithm framework
that integrates planners and learners can improve the data efficiency of
solving TTP; The proposed method provides a new paradigm for solving TTP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00983">Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">MD Shafikul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1">Azmine Toushik Wasi</a></p>
<p>Inventory Routing Problem (IRP) is a crucial challenge in supply chain
management as it involves optimizing efficient route selection while
considering the uncertainty of inventory demand planning. To solve IRPs,
usually a two-stage approach is employed, where demand is predicted using
machine learning techniques first, and then an optimization algorithm is used
to minimize routing costs. Our experiment shows machine learning models fall
short of achieving perfect accuracy because inventory levels are influenced by
the dynamic business environment, which, in turn, affects the optimization
problem in the next stage, resulting in sub-optimal decisions. In this paper,
we formulate and propose a decision-focused learning-based approach to solving
real-world IRPs. This approach directly integrates inventory prediction and
routing optimization within an end-to-end system potentially ensuring a robust
supply chain strategy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00998">Replicable Benchmarking of Neural Machine Translation (NMT) on Low-Resource Local Languages in Indonesia. (arXiv:2311.00998v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Susanto_L/0/1/0/all/0/1">Lucky Susanto</a>, <a href="http://arxiv.org/find/cs/1/au:+Diandaru_R/0/1/0/all/0/1">Ryandito Diandaru</a>, <a href="http://arxiv.org/find/cs/1/au:+Krisnadhi_A/0/1/0/all/0/1">Adila Krisnadhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Purwarianti_A/0/1/0/all/0/1">Ayu Purwarianti</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijaya_D/0/1/0/all/0/1">Derry Wijaya</a></p>
<p>Neural machine translation (NMT) for low-resource local languages in
Indonesia faces significant challenges, including the need for a representative
benchmark and limited data availability. This work addresses these challenges
by comprehensively analyzing training NMT systems for four low-resource local
languages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our
study encompasses various training approaches, paradigms, data sizes, and a
preliminary study into using large language models for synthetic low-resource
languages parallel data generation. We reveal specific trends and insights into
practical strategies for low-resource language translation. Our research
demonstrates that despite limited computational resources and textual data,
several of our NMT systems achieve competitive performances, rivaling the
translation quality of zero-shot gpt-3.5-turbo. These findings significantly
advance NMT for low-resource languages, offering valuable guidance for
researchers in similar contexts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01001">Fully Quantized Always-on Face Detector Considering Mobile Image Sensors. (arXiv:2311.01001v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Haechang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1">Wongi Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_D/0/1/0/all/0/1">Dongil Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Je_H/0/1/0/all/0/1">Hyunwoo Je</a>, <a href="http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1">Albert No</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kijeong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Se Young Chun</a></p>
<p>Despite significant research on lightweight deep neural networks (DNNs)
designed for edge devices, the current face detectors do not fully meet the
requirements for "intelligent" CMOS image sensors (iCISs) integrated with
embedded DNNs. These sensors are essential in various practical applications,
such as energy-efficient mobile phones and surveillance systems with always-on
capabilities. One noteworthy limitation is the absence of suitable face
detectors for the always-on scenario, a crucial aspect of image sensor-level
applications. These detectors must operate directly with sensor RAW data before
the image signal processor (ISP) takes over. This gap poses a significant
challenge in achieving optimal performance in such scenarios. Further research
and development are necessary to bridge this gap and fully leverage the
potential of iCIS applications. In this study, we aim to bridge the gap by
exploring extremely low-bit lightweight face detectors, focusing on the
always-on face detection scenario for mobile image sensor applications. To
achieve this, our proposed model utilizes sensor-aware synthetic RAW inputs,
simulating always-on face detection processed "before" the ISP chain. Our
approach employs ternary (-1, 0, 1) weights for potential implementations in
image sensors, resulting in a relatively simple network architecture with
shallow layers and extremely low-bitwidth. Our method demonstrates reasonable
face detection performance and excellent efficiency in simulation studies,
offering promising possibilities for practical always-on face detectors in
real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01002">Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy. (arXiv:2311.01002v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dongmin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Seola Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Doyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hwanjun Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae-Gil Lee</a></p>
<p>Data pruning, which aims to downsize a large training set into a small
informative subset, is crucial for reducing the enormous computational costs of
modern deep learning. Though large-scale data collections invariably contain
annotation noise and numerous robust learning methods have been developed, data
pruning for the noise-robust learning scenario has received little attention.
With state-of-the-art Re-labeling methods that self-correct erroneous labels
while training, it is challenging to identify which subset induces the most
accurate re-labeling of erroneous labels in the entire training set. In this
paper, we formalize the problem of data pruning with re-labeling. We first show
that the likelihood of a training example being correctly re-labeled is
proportional to the prediction confidence of its neighborhood in the subset.
Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a
subset maximizing the total neighborhood confidence of all training examples,
thereby maximizing the re-labeling accuracy and generalization performance.
Extensive experiments on four real and one synthetic noisy datasets show that
\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as
well as those with a standard model by up to 21.6%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01004">Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning. (arXiv:2311.01004v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gaoang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Benlu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1">Weijie Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yizhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xuechen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shiyan Li</a></p>
<p>With the development of multimodality and large language models, the deep
learning-based technique for medical image captioning holds the potential to
offer valuable diagnostic recommendations. However, current generic text and
image pre-trained models do not yield satisfactory results when it comes to
describing intricate details within medical images. In this paper, we present a
novel medical image captioning method guided by the segment anything model
(SAM) to enable enhanced encoding with both general and detailed feature
extraction. In addition, our approach employs a distinctive pre-training
strategy with mixed semantic learning to simultaneously capture both the
overall information and finer details within medical images. We demonstrate the
effectiveness of this approach, as it outperforms the pre-trained BLIP2 model
on various evaluation metrics for generating descriptions of medical images.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01007">Effective Human-AI Teams via Learned Natural Language Rules and Onboarding. (arXiv:2311.01007v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mozannar_H/0/1/0/all/0/1">Hussein Mozannar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jimin J Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1">Dennis Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1">Prasanna Sattigeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Subhro Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1">David Sontag</a></p>
<p>People are relying on AI agents to assist them with various tasks. The human
must know when to rely on the agent, collaborate with the agent, or ignore its
suggestions. In this work, we propose to learn rules grounded in data regions
and described in natural language that illustrate how the human should
collaborate with the AI. Our novel region discovery algorithm finds local
regions in the data as neighborhoods in an embedding space that corrects the
human prior. Each region is then described using an iterative and contrastive
procedure where a large language model describes the region. We then teach
these rules to the human via an onboarding stage. Through user studies on
object detection and question-answering tasks, we show that our method can lead
to more accurate human-AI teams. We also evaluate our region discovery and
description algorithms separately.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01009">Revamping AI Models in Dermatology: Overcoming Critical Challenges for Enhanced Skin Lesion Diagnosis. (arXiv:2311.01009v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1">Deval Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Betz_Stablein_B/0/1/0/all/0/1">Brigid Betz-Stablein</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Toan D Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yaniv Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowling_A/0/1/0/all/0/1">Adrian Bowling</a>, <a href="http://arxiv.org/find/cs/1/au:+Haskett_M/0/1/0/all/0/1">Martin Haskett</a>, <a href="http://arxiv.org/find/cs/1/au:+Sashindranath_M/0/1/0/all/0/1">Maithili Sashindranath</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonnington_P/0/1/0/all/0/1">Paul Bonnington</a>, <a href="http://arxiv.org/find/cs/1/au:+Mar_V/0/1/0/all/0/1">Victoria Mar</a>, <a href="http://arxiv.org/find/cs/1/au:+Soyer_H/0/1/0/all/0/1">H Peter Soyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a></p>
<p>The surge in developing deep learning models for diagnosing skin lesions
through image analysis is notable, yet their clinical black faces challenges.
Current dermatology AI models have limitations: limited number of possible
diagnostic outputs, lack of real-world testing on uncommon skin lesions,
inability to detect out-of-distribution images, and over-reliance on
dermoscopic images. To address these, we present an All-In-One
\textbf{H}ierarchical-\textbf{O}ut of Distribution-\textbf{C}linical Triage
(HOT) model. For a clinical image, our model generates three outputs: a
hierarchical prediction, an alert for out-of-distribution images, and a
recommendation for dermoscopy if clinical image alone is insufficient for
diagnosis. When the recommendation is pursued, it integrates both clinical and
dermoscopic images to deliver final diagnosis. Extensive experiments on a
representative cutaneous lesion dataset demonstrate the effectiveness and
synergy of each component within our framework. Our versatile model provides
valuable decision support for lesion diagnosis and sets a promising precedent
for medical AI applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01017">Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion. (arXiv:2311.01017v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lunjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuwen Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ze Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Casas_S/0/1/0/all/0/1">Sergio Casas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Rui Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1">Raquel Urtasun</a></p>
<p>Learning world models can teach an agent how the world works in an
unsupervised manner. Even though it can be viewed as a special case of sequence
modeling, progress for scaling world models on robotic applications such as
autonomous driving has been somewhat less rapid than scaling language models
with Generative Pre-trained Transformers (GPT). We identify two reasons as
major bottlenecks: dealing with complex and unstructured observation space, and
having a scalable generative model. Consequently, we propose a novel world
modeling approach that first tokenizes sensor observations with VQVAE, then
predicts the future via discrete diffusion. To efficiently decode and denoise
tokens in parallel, we recast Masked Generative Image Transformer into the
discrete diffusion framework with a few simple changes, resulting in notable
improvement. When applied to learning world models on point cloud observations,
our model reduces prior SOTA Chamfer distance by more than 65% for 1s
prediction, and more than 50% for 3s prediction, across NuScenes, KITTI
Odometry, and Argoverse2 datasets. Our results demonstrate that discrete
diffusion on tokenized agent experience can unlock the power of GPT-like
unsupervised learning for robotic agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01022">NeuroWrite: Predictive Handwritten Digit Classification using Deep Neural Networks. (arXiv:2311.01022v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Asish_K/0/1/0/all/0/1">Kottakota Asish</a>, <a href="http://arxiv.org/find/cs/1/au:+Teja_P/0/1/0/all/0/1">P. Sarath Teja</a>, <a href="http://arxiv.org/find/cs/1/au:+Chander_R/0/1/0/all/0/1">R. Kishan Chander</a>, <a href="http://arxiv.org/find/cs/1/au:+Hema_D/0/1/0/all/0/1">Dr. D. Deva Hema</a></p>
<p>The rapid evolution of deep neural networks has revolutionized the field of
machine learning, enabling remarkable advancements in various domains. In this
article, we introduce NeuroWrite, a unique method for predicting the
categorization of handwritten digits using deep neural networks. Our model
exhibits outstanding accuracy in identifying and categorising handwritten
digits by utilising the strength of convolutional neural networks (CNNs) and
recurrent neural networks (RNNs).In this article, we give a thorough
examination of the data preparation methods, network design, and training
methods used in NeuroWrite. By implementing state-of-the-art techniques, we
showcase how NeuroWrite can achieve high classification accuracy and robust
generalization on handwritten digit datasets, such as MNIST. Furthermore, we
explore the model's potential for real-world applications, including digit
recognition in digitized documents, signature verification, and automated
postal code recognition. NeuroWrite is a useful tool for computer vision and
pattern recognition because of its performance and adaptability.The
architecture, training procedure, and evaluation metrics of NeuroWrite are
covered in detail in this study, illustrating how it can improve a number of
applications that call for handwritten digit classification. The outcomes show
that NeuroWrite is a promising method for raising the bar for deep neural
network-based handwritten digit recognition.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01023">Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview Learning for Medical Image Segmentation. (arXiv:2311.01023v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yanming Guo</a></p>
<p>The utilisation of deep learning segmentation algorithms that learn complex
organs and tissue patterns and extract essential regions of interest from the
noisy background to improve the visual ability for medical image diagnosis has
achieved impressive results in Medical Image Computing (MIC). This thesis
focuses on retinal blood vessel segmentation tasks, providing an extensive
literature review of deep learning-based medical image segmentation approaches
while comparing the methodologies and empirical performances. The work also
examines the limitations of current state-of-the-art methods by pointing out
the two significant existing limitations: data size constraints and the
dependency on high computational resources. To address such problems, this work
proposes a novel efficient, simple multiview learning framework that
contrastively learns invariant vessel feature representation by comparing with
multiple augmented views by various transformations to overcome data shortage
and improve generalisation ability. Moreover, the hybrid network architecture
integrates the attention mechanism into a Convolutional Neural Network to
further capture complex continuous curvilinear vessel structures. The result
demonstrates the proposed method validated on the CHASE-DB1 dataset, attaining
the highest F1 score of 83.46% and the highest Intersection over Union (IOU)
score of 71.62% with UNet structure, surpassing existing benchmark UNet-based
methods by 1.95% and 2.8%, respectively. The combination of the metrics
indicates the model detects the vessel object accurately with a highly
coincidental location with the ground truth. Moreover, the proposed approach
could be trained within 30 minutes by consuming less than 3 GB GPU RAM, and
such characteristics support the efficient implementation for real-world
applications and deployments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01024">Distance-Based Propagation for Efficient Knowledge Graph Reasoning. (arXiv:2311.01024v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shomer_H/0/1/0/all/0/1">Harry Shomer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juanhui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu C. Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a></p>
<p>Knowledge graph completion (KGC) aims to predict unseen edges in knowledge
graphs (KGs), resulting in the discovery of new facts. A new class of methods
have been proposed to tackle this problem by aggregating path information.
These methods have shown tremendous ability in the task of KGC. However they
are plagued by efficiency issues. Though there are a few recent attempts to
address this through learnable path pruning, they often sacrifice the
performance to gain efficiency. In this work, we identify two intrinsic
limitations of these methods that affect the efficiency and representation
quality. To address the limitations, we introduce a new method, TAGNet, which
is able to efficiently propagate information. This is achieved by only
aggregating paths in a fixed window for each source-target pair. We demonstrate
that the complexity of TAGNet is independent of the number of layers. Extensive
experiments demonstrate that TAGNet can cut down on the number of propagated
messages by as much as 90% while achieving competitive performance on multiple
KG datasets. The code is available at https://github.com/HarryShomer/TAGNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01030">Joint Learning of Local and Global Features for Aspect-based Sentiment Classification. (arXiv:2311.01030v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Niu_H/0/1/0/all/0/1">Hao Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaosu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a></p>
<p>Aspect-based sentiment classification (ASC) aims to judge the sentiment
polarity conveyed by the given aspect term in a sentence. The sentiment
polarity is not only determined by the local context but also related to the
words far away from the given aspect term. Most recent efforts related to the
attention-based models can not sufficiently distinguish which words they should
pay more attention to in some cases. Meanwhile, graph-based models are coming
into ASC to encode syntactic dependency tree information. But these models do
not fully leverage syntactic dependency trees as they neglect to incorporate
dependency relation tag information into representation learning effectively.
In this paper, we address these problems by effectively modeling the local and
global features. Firstly, we design a local encoder containing: a Gaussian mask
layer and a covariance self-attention layer. The Gaussian mask layer tends to
adjust the receptive field around aspect terms adaptively to deemphasize the
effects of unrelated words and pay more attention to local information. The
covariance self-attention layer can distinguish the attention weights of
different words more obviously. Furthermore, we propose a dual-level graph
attention network as a global encoder by fully employing dependency tag
information to capture long-distance information effectively. Our model
achieves state-of-the-art performance on both SemEval 2014 and Twitter
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01033">Non-Autoregressive Diffusion-based Temporal Point Processes for Continuous-Time Long-Term Event Prediction. (arXiv:2311.01033v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wang-Tao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Ling Tian</a></p>
<p>Continuous-time long-term event prediction plays an important role in many
application scenarios. Most existing works rely on autoregressive frameworks to
predict event sequences, which suffer from error accumulation, thus
compromising prediction quality. Inspired by the success of denoising diffusion
probabilistic models, we propose a diffusion-based non-autoregressive temporal
point process model for long-term event prediction in continuous time. Instead
of generating events one at a time in an autoregressive way, our model predicts
the future event sequence entirely as a whole. In order to perform diffusion
processes on event sequences, we develop a bidirectional map between target
event sequences and the Euclidean vector space. Furthermore, we design a novel
denoising network to capture both sequential and contextual features for better
sample quality. Extensive experiments are conducted to prove the superiority of
our proposed model over state-of-the-art methods on long-term event prediction
in continuous time. To the best of our knowledge, this is the first work to
apply diffusion methods to long-term event prediction problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01036">ATHENA: Mathematical Reasoning with Thought Expansion. (arXiv:2311.01036v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">JB. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hazel Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_J/0/1/0/all/0/1">Joonghyuk Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yo-Sub Han</a></p>
<p>Solving math word problems depends on how to articulate the problems, the
lens through which models view human linguistic expressions. Real-world
settings count on such a method even more due to the diverse practices of the
same mathematical operations. Earlier works constrain available thinking
processes by limited prediction strategies without considering their
significance in acquiring mathematical knowledge. We introduce Attention-based
THought Expansion Network Architecture (ATHENA) to tackle the challenges of
real-world practices by mimicking human thought expansion mechanisms in the
form of neural network propagation. A thought expansion recurrently generates
the candidates carrying the thoughts of possible math expressions driven from
the previous step and yields reasonable thoughts by selecting the valid
pathways to the goal. Our experiments show that ATHENA achieves a new
state-of-the-art stage toward the ideal model that is compelling in variant
questions even when the informativeness in training examples is restricted.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01041">Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism. (arXiv:2311.01041v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Lang Cao</a></p>
<p>Large language models (LLMs) have demonstrated impressive language
understanding and generation capabilities, enabling them to answer a wide range
of questions across various domains. However, these models are not flawless and
often produce responses that contain errors or misinformation. These
inaccuracies, commonly referred to as hallucinations, render LLMs unreliable
and even unusable in many scenarios. In this paper, our focus is on mitigating
the issue of hallucination in LLMs, particularly in the context of
question-answering. Instead of attempting to answer all questions, we explore a
refusal mechanism that instructs LLMs to refuse to answer challenging questions
in order to avoid errors. We then propose a simple yet effective solution
called Learn to Refuse (L2R), which incorporates the refusal mechanism to
enable LLMs to recognize and refuse to answer questions that they find
difficult to address. To achieve this, we utilize a structured knowledge base
to represent all the LLM's understanding of the world, enabling it to provide
traceable gold knowledge. This knowledge base is separate from the LLM and
initially empty, and it is progressively expanded with validated knowledge.
When an LLM encounters questions outside its domain, the system recognizes its
knowledge scope and determines whether it can answer the question
independently. Additionally, we introduce a method for automatically and
efficiently expanding the knowledge base of LLMs. Through qualitative and
quantitative analysis, we demonstrate that our approach enhances the
controllability and reliability of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01043">A Survey of Large Language Models for Autonomous Driving. (arXiv:2311.01043v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhenjie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaosong Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a></p>
<p>Autonomous driving technology, a catalyst for revolutionizing transportation
and urban mobility, has the tend to transition from rule-based systems to
data-driven strategies. Traditional module-based systems are constrained by
cumulative errors among cascaded modules and inflexible pre-set rules. In
contrast, end-to-end autonomous driving systems have the potential to avoid
error accumulation due to their fully data-driven training process, although
they often lack transparency due to their ``black box" nature, complicating the
validation and traceability of decisions. Recently, large language models
(LLMs) have demonstrated abilities including understanding context, logical
reasoning, and generating answers. A natural thought is to utilize these
abilities to empower autonomous driving. By combining LLM with foundation
vision models, it could open the door to open-world understanding, reasoning,
and few-shot learning, which current autonomous driving systems are lacking. In
this paper, we systematically review a research line about \textit{Large
Language Models for Autonomous Driving (LLM4AD)}. This study evaluates the
current state of technological advancements, distinctly outlining the principal
challenges and prospective directions for the field. For the convenience of
researchers in academia and industry, we provide real-time updates on the
latest advances in the field as well as relevant open-source resources via the
designated link: https://github.com/Thinklab-SJTU/Awesome-LLM4AD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01048">AI-assisted Learning for Electronic Engineering Courses in High Education. (arXiv:2311.01048v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ngoc_T/0/1/0/all/0/1">Thanh Nguyen Ngoc</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_Q/0/1/0/all/0/1">Quang Nhat Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_A/0/1/0/all/0/1">Arthur Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bao Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thuy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Thanh Pham</a></p>
<p>This study evaluates the efficacy of ChatGPT as an AI teaching and learning
support tool in an integrated circuit systems course at a higher education
institution in an Asian country. Various question types were completed, and
ChatGPT responses were assessed to gain valuable insights for further
investigation. The objective is to assess ChatGPT's ability to provide
insights, personalized support, and interactive learning experiences in
engineering education. The study includes the evaluation and reflection of
different stakeholders: students, lecturers, and engineers. The findings of
this study shed light on the benefits and limitations of ChatGPT as an AI tool,
paving the way for innovative learning approaches in technical disciplines.
Furthermore, the study contributes to our understanding of how digital
transformation is likely to unfold in the education sector.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01049">Multi-dimensional data refining strategy for effective fine-tuning LLMs. (arXiv:2311.01049v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ngoc_T/0/1/0/all/0/1">Thanh Nguyen Ngoc</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_Q/0/1/0/all/0/1">Quang Nhat Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_A/0/1/0/all/0/1">Arthur Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bao Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thuy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Thanh Pham</a></p>
<p>Data is a cornerstone for fine-tuning large language models, yet acquiring
suitable data remains challenging. Challenges encompassed data scarcity,
linguistic diversity, and domain-specific content. This paper presents lessons
learned while crawling and refining data tailored for fine-tuning Vietnamese
language models. Crafting such a dataset, while accounting for linguistic
intricacies and striking a balance between inclusivity and accuracy, demands
meticulous planning. Our paper presents a multidimensional strategy including
leveraging existing datasets in the English language and developing customized
data-crawling scripts with the assistance of generative AI tools. A fine-tuned
LLM model for the Vietnamese language, which was produced using resultant
datasets, demonstrated good performance while generating Vietnamese news
articles from prompts. The study offers practical solutions and guidance for
future fine-tuning models in languages like Vietnamese.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01057">Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO. (arXiv:2311.01057v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moosmann_J/0/1/0/all/0/1">Julian Moosmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonazzi_P/0/1/0/all/0/1">Pietro Bonazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yawei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_S/0/1/0/all/0/1">Sizhen Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayer_P/0/1/0/all/0/1">Philipp Mayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1">Luca Benini</a>, <a href="http://arxiv.org/find/cs/1/au:+Magno_M/0/1/0/all/0/1">Michele Magno</a></p>
<p>Smart glasses are rapidly gaining advanced functionality thanks to
cutting-edge computing technologies, accelerated hardware architectures, and
tiny AI algorithms. Integrating AI into smart glasses featuring a small form
factor and limited battery capacity is still challenging when targeting
full-day usage for a satisfactory user experience. This paper illustrates the
design and implementation of tiny machine-learning algorithms exploiting novel
low-power processors to enable prolonged continuous operation in smart glasses.
We explore the energy- and latency-efficient of smart glasses in the case of
real-time object detection. To this goal, we designed a smart glasses prototype
as a research platform featuring two microcontrollers, including a novel
milliwatt-power RISC-V parallel processor with a hardware accelerator for
visual AI, and a Bluetooth low-power module for communication. The smart
glasses integrate power cycling mechanisms, including image and audio sensing
interfaces. Furthermore, we developed a family of novel tiny deep-learning
models based on YOLO with sub-million parameters customized for
microcontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming
at benchmarking object detection with smart glasses for energy and latency.
Evaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's
17ms inference latency and 1.59mJ energy consumption per inference while
ensuring acceptable detection accuracy. Further evaluation reveals an
end-to-end latency from image capturing to the algorithm's prediction of 56ms
or equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to
a 9.3 hours of continuous run time on a 154mAh battery. These results
outperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image
classification) at just 7.3 fps per second.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01107">GREEMA: Proposal and Experimental Verification of Growing Robot by Eating Environmental MAterial for Landslide Disaster. (arXiv:2311.01107v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsunoda_Y/0/1/0/all/0/1">Yusuke Tsunoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1">Yuya Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Osuka_K/0/1/0/all/0/1">Koichi Osuka</a></p>
<p>In areas that are inaccessible to humans, such as the lunar surface and
landslide sites, there is a need for multiple autonomous mobile robot systems
that can replace human workers. In particular, at landslide sites such as river
channel blockages, robots are required to remove water and sediment from the
site as soon as possible. Conventionally, several construction machines have
been deployed to the site for civil engineering work. However, because of the
large size and weight of conventional construction equipment, it is difficult
to move multiple units of construction equipment to the site, resulting in
significant transportation costs and time. To solve such problems, this study
proposes a novel growing robot by eating environmental material called GREEMA,
which is lightweight and compact during transportation, but can function by
eating on environmental materials once it arrives at the site. GREEMA actively
takes in environmental materials such as water and sediment, uses them as its
structure, and removes them by moving itself. In this paper, we developed and
experimentally verified two types of GREEMAs. First, we developed a fin-type
swimming robot that passively takes water into its body using a water-absorbing
polymer and forms a body to express its swimming function. Second, we
constructed an arm-type robot that eats soil to increase the rigidity of its
body. We discuss the results of these two experiments from the viewpoint of
Explicit-Implicit control and describe the design theory of GREEMA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01150">Revisiting the Knowledge Injection Frameworks. (arXiv:2311.01150v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1">Peng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haobo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Weikang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Junbo Zhao</a></p>
<p>In recent years, large language models (LLMs), such as GPTs, have attained
great impact worldwide. However, how to adapt these LLMs to better suit the
vertical domain-specific tasks by utilizing external knowledge remains not
completely solved. Indeed, there have emerged a few works on this line where
most of them rely on an alignment heuristic that is built to inject the
corresponding knowledge tuple into the associated text sample.
</p>
<p>However, despite the promise, we identify a pivotal problem in this work
ubiquitously. Simply put, we find that injecting unaligned (i.e., random)
knowledge tuple into the LLMs achieves comparable (and sometimes better)
results than the aligned knowledge being injected. We therefore take a thorough
investigation of this frustrating finding on a variety of related prior work
and further provide a chain of potential interpretations for the phenomenon.
Based on all that, we offer a simple remediated technique. Briefly, the core of
this technique is rooted in an ideological emphasis on the pruning and
purification of the external knowledge base to be injected into LLMs. At last,
we show that by integrating this technique into most (if not all) knowledge
injection frameworks and recent LLMs, it manages to overcome the aforementioned
sanity problem and further pushes the boundary of the performance of the
domain-adaptive LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01154">A Review of Digital Twins and their Application in Cybersecurity based on Artificial Intelligence. (arXiv:2311.01154v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Homaei_M/0/1/0/all/0/1">MohammadHossein Homaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_O/0/1/0/all/0/1">Oscar Mogollon Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunez_J/0/1/0/all/0/1">Jose Carlos Sancho Nunez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegas_M/0/1/0/all/0/1">Mar Avila Vegas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindo_A/0/1/0/all/0/1">Andres Caro Lindo</a></p>
<p>The potential of digital twin technology is yet to be fully realized due to
its diversity and untapped potential. Digital twins enable systems' analysis,
design, optimization, and evolution to be performed digitally or in conjunction
with a cyber-physical approach to improve speed, accuracy, and efficiency over
traditional engineering methods. Industry 4.0, factories of the future, and
digital twins continue to benefit from the technology and provide enhanced
efficiency within existing systems. Due to the lack of information and security
standards associated with the transition to cyber digitization, cybercriminals
have been able to take advantage of the situation. Access to a digital twin of
a product or service is equivalent to threatening the entire collection. There
is a robust interaction between digital twins and artificial intelligence
tools, which leads to strong interaction between these technologies, so it can
be used to improve the cybersecurity of these digital platforms based on their
integration with these technologies. This study aims to investigate the role of
artificial intelligence in providing cybersecurity for digital twin versions of
various industries, as well as the risks associated with these versions. In
addition, this research serves as a road map for researchers and others
interested in cybersecurity and digital security.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01161">Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering. (arXiv:2311.01161v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kang-il Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Segwang Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1">Kyomin Jung</a></p>
<p>The problem of spurious programs is a longstanding challenge when training a
semantic parser from weak supervision. To eliminate such programs that have
wrong semantics but correct denotation, existing methods focus on exploiting
similarities between examples based on domain-specific knowledge. In this
paper, we propose a domain-agnostic filtering mechanism based on program
execution results. Specifically, for each program obtained through the search
process, we first construct a representation that captures the program's
semantics as execution results under various inputs. Then, we run a majority
vote on these representations to identify and filter out programs with
significantly different semantics from the other programs. In particular, our
method is orthogonal to the program search process so that it can easily
augment any of the existing weakly supervised semantic parsing frameworks.
Empirical evaluations on the Natural Language Visual Reasoning and
WikiTableQuestions demonstrate that applying our method to the existing
semantic parsers induces significantly improved performances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01166">Generative Input: Towards Next-Generation Input Methods Paradigm. (arXiv:2311.01166v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Keyu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongcan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zihang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhenzhen Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shijin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Cong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a></p>
<p>Since the release of ChatGPT, generative models have achieved tremendous
success and become the de facto approach for various NLP tasks. However, its
application in the field of input methods remains under-explored. Many neural
network approaches have been applied to the construction of Chinese input
method engines(IMEs).Previous research often assumed that the input pinyin was
correct and focused on Pinyin-to-character(P2C) task, which significantly falls
short of meeting users' demands. Moreover, previous research could not leverage
user feedback to optimize the model and provide personalized results. In this
study, we propose a novel Generative Input paradigm named GeneInput. It uses
prompts to handle all input scenarios and other intelligent auxiliary input
functions, optimizing the model with user feedback to deliver personalized
results. The results demonstrate that we have achieved state-of-the-art
performance for the first time in the Full-mode Key-sequence to
Characters(FK2C) task. We propose a novel reward model training method that
eliminates the need for additional manual annotations and the performance
surpasses GPT-4 in tasks involving intelligent association and conversational
assistance. Compared to traditional paradigms, GeneInput not only demonstrates
superior performance but also exhibits enhanced robustness, scalability, and
online learning capabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01185">Revolutionizing Healthcare Image Analysis in Pandemic-Based Fog-Cloud Computing Architectures. (arXiv:2311.01185v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Elsayed_A/0/1/0/all/0/1">Al Zahraa Elsayed</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_K/0/1/0/all/0/1">Khalil Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Harb_H/0/1/0/all/0/1">Hany Harb</a></p>
<p>The emergence of pandemics has significantly emphasized the need for
effective solutions in healthcare data analysis. One particular challenge in
this domain is the manual examination of medical images, such as X-rays and CT
scans. This process is time-consuming and involves the logistical complexities
of transferring these images to centralized cloud computing servers.
Additionally, the speed and accuracy of image analysis are vital for efficient
healthcare image management. This research paper introduces an innovative
healthcare architecture that tackles the challenges of analysis efficiency and
accuracy by harnessing the capabilities of Artificial Intelligence (AI).
Specifically, the proposed architecture utilizes fog computing and presents a
modified Convolutional Neural Network (CNN) designed specifically for image
analysis. Different architectures of CNN layers are thoroughly explored and
evaluated to optimize overall performance. To demonstrate the effectiveness of
the proposed approach, a dataset of X-ray images is utilized for analysis and
evaluation. Comparative assessments are conducted against recent models such as
VGG16, VGG19, MobileNet, and related research papers. Notably, the proposed
approach achieves an exceptional accuracy rate of 99.88% in classifying normal
cases, accompanied by a validation rate of 96.5%, precision and recall rates of
100%, and an F1 score of 100%. These results highlight the immense potential of
fog computing and modified CNNs in revolutionizing healthcare image analysis
and diagnosis, not only during pandemics but also in the future. By leveraging
these technologies, healthcare professionals can enhance the efficiency and
accuracy of medical image analysis, leading to improved patient care and
outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01191">VIGraph: Self-supervised Learning for Class-Imbalanced Node Classification. (arXiv:2311.01191v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yulan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1">Sheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhirui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a></p>
<p>Class imbalance in graph data poses significant challenges for node
classification. Existing methods, represented by SMOTE-based approaches,
partially alleviate this issue but still exhibit limitations during imbalanced
scenario construction. Self-supervised learning (SSL) offers a promising
solution by synthesizing minority nodes from the data itself, yet its potential
remains unexplored. In this paper, we analyze the limitations of SMOTE-based
approaches and introduce VIGraph, a novel SSL model based on the
self-supervised Variational Graph Auto-Encoder (VGAE) that leverages
Variational Inference (VI) to generate minority nodes. Specifically, VIGraph
strictly adheres to the concept of imbalance when constructing imbalanced
graphs and utilizes the generative VGAE to generate minority nodes. Moreover,
VIGraph introduces a novel Siamese contrastive strategy at the decoding phase
to improve the overall quality of generated nodes. VIGraph can generate
high-quality nodes without reintegrating them into the original graph,
eliminating the "Generating, Reintegrating, and Retraining" process found in
SMOTE-based methods. Experiments on multiple real-world datasets demonstrate
that VIGraph achieves promising results for class-imbalanced node
classification tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01193">Contextual Confidence and Generative AI. (arXiv:2311.01193v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shrey Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Hitzig_Z/0/1/0/all/0/1">Zo&#xeb; Hitzig</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishkin_P/0/1/0/all/0/1">Pamela Mishkin</a></p>
<p>Generative AI models perturb the foundations of effective human
communication. They present new challenges to contextual confidence, disrupting
participants' ability to identify the authentic context of communication and
their ability to protect communication from reuse and recombination outside its
intended context. In this paper, we describe strategies--tools, technologies
and policies--that aim to stabilize communication in the face of these
challenges. The strategies we discuss fall into two broad categories.
Containment strategies aim to reassert context in environments where it is
currently threatened--a reaction to the context-free expectations and norms
established by the internet. Mobilization strategies, by contrast, view the
rise of generative AI as an opportunity to proactively set new and higher
expectations around privacy and authenticity in mediated communication.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01195">Batch Bayesian Optimization for Replicable Experimental Design. (arXiv:2311.01195v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zhongxiang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quoc Phong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tay_S/0/1/0/all/0/1">Sebastian Shenghong Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Urano_D/0/1/0/all/0/1">Daisuke Urano</a>, <a href="http://arxiv.org/find/cs/1/au:+Leong_R/0/1/0/all/0/1">Richalynn Leong</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1">Bryan Kian Hsiang Low</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1">Patrick Jaillet</a></p>
<p>Many real-world experimental design problems (a) evaluate multiple
experimental conditions in parallel and (b) replicate each condition multiple
times due to large and heteroscedastic observation noise. Given a fixed total
budget, this naturally induces a trade-off between evaluating more unique
conditions while replicating each of them fewer times vs. evaluating fewer
unique conditions and replicating each more times. Moreover, in these problems,
practitioners may be risk-averse and hence prefer an input with both good
average performance and small variability. To tackle both challenges, we
propose the Batch Thompson Sampling for Replicable Experimental Design
(BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and
BTS-RED-Unknown algorithms, for, respectively, known and unknown noise
variance, choose the number of replications adaptively rather than
deterministically such that an input with a larger noise variance is replicated
more times. As a result, despite the noise heteroscedasticity, both algorithms
enjoy a theoretical guarantee and are asymptotically no-regret. Our
Mean-Var-BTS-RED algorithm aims at risk-averse optimization and is also
asymptotically no-regret. We also show the effectiveness of our algorithms in
two practical real-world applications: precision agriculture and AutoML.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01197">AiluRus: A Scalable ViT Framework for Dense Prediction. (arXiv:2311.01197v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaoming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaopeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Bowen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Dongsheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wenrui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hongkai Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a></p>
<p>Vision transformers (ViTs) have emerged as a prevalent architecture for
vision tasks owing to their impressive performance. However, when it comes to
handling long token sequences, especially in dense prediction tasks that
require high-resolution input, the complexity of ViTs increases significantly.
Notably, dense prediction tasks, such as semantic segmentation or object
detection, emphasize more on the contours or shapes of objects, while the
texture inside objects is less informative. Motivated by this observation, we
propose to apply adaptive resolution for different regions in the image
according to their importance. Specifically, at the intermediate layer of the
ViT, we utilize a spatial-aware density-based clustering algorithm to select
representative tokens from the token sequence. Once the representative tokens
are determined, we proceed to merge other tokens into their closest
representative token. Consequently, semantic similar tokens are merged together
to form low-resolution regions, while semantic irrelevant tokens are preserved
independently as high-resolution regions. This strategy effectively reduces the
number of tokens, allowing subsequent layers to handle a reduced token sequence
and achieve acceleration. We evaluate our proposed method on three different
datasets and observe promising performance. For example, the "Segmenter ViT-L"
model can be accelerated by 48% FPS without fine-tuning, while maintaining the
performance. Additionally, our method can be applied to accelerate fine-tuning
as well. Experimental results demonstrate that we can save 52% training time
while accelerating 2.46 times FPS with only a 0.09% performance drop. The code
is available at https://github.com/caddyless/ailurus/tree/main.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01201">Federated Learning on Edge Sensing Devices: A Review. (arXiv:2311.01201v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saylam_B/0/1/0/all/0/1">Berrenur Saylam</a>, <a href="http://arxiv.org/find/cs/1/au:+Incel_O/0/1/0/all/0/1">&#xd6;zlem Durmaz &#x130;ncel</a></p>
<p>The ability to monitor ambient characteristics, interact with them, and
derive information about the surroundings has been made possible by the rapid
proliferation of edge sensing devices like IoT, mobile, and wearable devices
and their measuring capabilities with integrated sensors. Even though these
devices are small and have less capacity for data storage and processing, they
produce vast amounts of data. Some example application areas where sensor data
is collected and processed include healthcare, environmental (including air
quality and pollution levels), automotive, industrial, aerospace, and
agricultural applications. These enormous volumes of sensing data collected
from the edge devices are analyzed using a variety of Machine Learning (ML) and
Deep Learning (DL) approaches. However, analyzing them on the cloud or a server
presents challenges related to privacy, hardware, and connectivity limitations.
Federated Learning (FL) is emerging as a solution to these problems while
preserving privacy by jointly training a model without sharing raw data. In
this paper, we review the FL strategies from the perspective of edge sensing
devices to get over the limitations of conventional machine learning
techniques. We focus on the key FL principles, software frameworks, and
testbeds. We also explore the current sensor technologies, properties of the
sensing devices and sensing applications where FL is utilized. We conclude with
a discussion on open issues and future research directions on FL for further
studies
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01202">Cross-Modal Information-Guided Network using Contrastive Learning for Point Cloud Registration. (arXiv:2311.01202v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yifan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jihua Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shiqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1">Pengcheng Shi</a></p>
<p>The majority of point cloud registration methods currently rely on extracting
features from points. However, these methods are limited by their dependence on
information obtained from a single modality of points, which can result in
deficiencies such as inadequate perception of global features and a lack of
texture information. Actually, humans can employ visual information learned
from 2D images to comprehend the 3D world. Based on this fact, we present a
novel Cross-Modal Information-Guided Network (CMIGNet), which obtains global
shape perception through cross-modal information to achieve precise and robust
point cloud registration. Specifically, we first incorporate the projected
images from the point clouds and fuse the cross-modal features using the
attention mechanism. Furthermore, we employ two contrastive learning
strategies, namely overlapping contrastive learning and cross-modal contrastive
learning. The former focuses on features in overlapping regions, while the
latter emphasizes the correspondences between 2D and 3D features. Finally, we
propose a mask prediction module to identify keypoints in the point clouds.
Extensive experiments on several benchmark datasets demonstrate that our
network achieves superior registration performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01205">Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent. (arXiv:2311.01205v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kummer_L/0/1/0/all/0/1">Lorenz Kummer</a>, <a href="http://arxiv.org/find/cs/1/au:+Moustafa_S/0/1/0/all/0/1">Samir Moustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1">Nils N. Kriege</a>, <a href="http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1">Wilfried N. Gansterer</a></p>
<p>Prior attacks on graph neural networks have mostly focused on graph poisoning
and evasion, neglecting the network's weights and biases. Traditional
weight-based fault injection attacks, such as bit flip attacks used for
convolutional neural networks, do not consider the unique properties of graph
neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip
attack designed specifically for graph neural networks. Our attack targets the
learnable neighborhood aggregation functions in quantized message passing
neural networks, degrading their ability to distinguish graph structures and
losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest
that exploiting mathematical properties specific to certain graph neural
network architectures can significantly increase their vulnerability to bit
flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive
Graph Isomorphism Networks trained on various graph property prediction
datasets to random output by flipping only a small fraction of the network's
bits, demonstrating its higher destructive power compared to a bit flip attack
transferred from convolutional neural networks. Our attack is transparent and
motivated by theoretical insights which are confirmed by extensive empirical
results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01212">Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral Image Classification. (arXiv:2311.01212v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Longwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhigang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianzhong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Junyong Yu</a></p>
<p>Cross-domain few-shot hyperspectral image classification focuses on learning
prior knowledge from a large number of labeled samples from source domain and
then transferring the knowledge to the tasks which contain only few labeled
samples in target domains. Following the metric-based manner, many current
methods first extract the features of the query and support samples, and then
directly predict the classes of query samples according to their distance to
the support samples or prototypes. The relations between samples have not been
fully explored and utilized. Different from current works, this paper proposes
to learn sample relations from different views and take them into the model
learning process, to improve the cross-domain few-shot hyperspectral image
classification. Building on current DCFSL method which adopts a domain
discriminator to deal with domain-level distribution difference, the proposed
method applys contrastive learning to learn the class-level sample relations to
obtain more discriminable sample features. In addition, it adopts a transformer
based cross-attention learning module to learn the set-level sample relations
and acquire the attentions from query samples to support samples. Our
experimental results have demonstrated the contribution of the multi-view
relation learning mechanism for few-shot hyperspectral image classification
when compared with the state of the art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01223">Diffusion Models for Reinforcement Learning: A Survey. (arXiv:2311.01223v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhengbang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hanye Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Haoran He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yichao Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shenyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a></p>
<p>Diffusion models have emerged as a prominent class of generative models,
surpassing previous methods regarding sample quality and training stability.
Recent works have shown the advantages of diffusion models in improving
reinforcement learning (RL) solutions, including as trajectory planners,
expressive policy classes, data synthesizers, etc. This survey aims to provide
an overview of the advancements in this emerging field and hopes to inspire new
avenues of research. First, we examine several challenges encountered by
current RL algorithms. Then, we present a taxonomy of existing methods based on
the roles played by diffusion models in RL and explore how the existing
challenges are addressed. We further outline successful applications of
diffusion models in various RL-related tasks while discussing the limitations
of current approaches. Finally, we conclude the survey and offer insights into
future research directions, focusing on enhancing model performance and
applying diffusion models to broader tasks. We are actively maintaining a
GitHub repository for papers and other related resources in applying diffusion
models in RL: https://github.com/apexrl/Diff4RLSurvey .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01230">Multi-Operational Mathematical Derivations in Latent Space. (arXiv:2311.01230v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1">Marco Valentino</a>, <a href="http://arxiv.org/find/cs/1/au:+Meadows_J/0/1/0/all/0/1">Jordan Meadows</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1">Andr&#xe9; Freitas</a></p>
<p>This paper investigates the possibility of approximating multiple
mathematical operations in latent space for expression derivation. To this end,
we introduce different multi-operational representation paradigms, modelling
mathematical operations as explicit geometric transformations. By leveraging a
symbolic engine, we construct a large-scale dataset comprising 1.7M derivation
steps stemming from 61K premises and 6 operators, analysing the properties of
each paradigm when instantiated with state-of-the-art neural encoders.
Specifically, we investigate how different encoding mechanisms can approximate
equational reasoning in latent space, exploring the trade-off between learning
different operators and specialising within single operations, as well as the
ability to support multi-step derivations and out-of-distribution
generalisation. Our empirical analysis reveals that the multi-operational
paradigm is crucial for disentangling different operators, while discriminating
the conclusions for a single operation is achievable in the original expression
encoder. Moreover, we show that architectural choices can heavily affect the
training dynamics, structural organisation, and generalisation of the latent
space, resulting in significant variations across paradigms and classes of
encoders.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01233">Long Story Short: a Summarize-then-Search Method for Long Video Question Answering. (arXiv:2311.01233v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jiwan Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a></p>
<p>Large language models such as GPT-3 have demonstrated an impressive
capability to adapt to new tasks without requiring task-specific training data.
This capability has been particularly effective in settings such as narrative
question answering, where the diversity of tasks is immense, but the available
supervision data is small. In this work, we investigate if such language models
can extend their zero-shot reasoning abilities to long multimodal narratives in
multimedia content such as drama, movies, and animation, where the story plays
an essential role. We propose Long Story Short, a framework for narrative video
QA that first summarizes the narrative of the video to a short plot and then
searches parts of the video relevant to the question. We also propose to
enhance visual matching with CLIPCheck. Our model outperforms state-of-the-art
supervised models by a large margin, highlighting the potential of zero-shot QA
for long videos.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01235">Navigating Complex Search Tasks with AI Copilots. (arXiv:2311.01235v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+White_R/0/1/0/all/0/1">Ryen W. White</a></p>
<p>As many of us in the information retrieval (IR) research community know and
appreciate, search is far from being a solved problem. Millions of people
struggle with tasks on search engines every day. Often, their struggles relate
to the intrinsic complexity of their task and the failure of search systems to
fully understand the task and serve relevant results. The task motivates the
search, creating the gap/problematic situation that searchers attempt to
bridge/resolve and drives search behavior as they work through different task
facets. Complex search tasks require more than support for rudimentary fact
finding or re-finding. Research on methods to support complex tasks includes
work on generating query and website suggestions, personalizing and
contextualizing search, and developing new search experiences, including those
that span time and space. The recent emergence of generative artificial
intelligence (AI) and the arrival of assistive agents, or copilots, based on
this technology, has the potential to offer further assistance to searchers,
especially those engaged in complex tasks. There are profound implications from
these advances for the design of intelligent systems and for the future of
search itself. This article, based on a keynote by the author at the 2023 ACM
SIGIR Conference, explores these issues and charts a course toward new horizons
in information access guided by AI copilots.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01240">FacadeNet: Conditional Facade Synthesis via Selective Editing. (arXiv:2311.01240v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Georgiou_Y/0/1/0/all/0/1">Yiangos Georgiou</a>, <a href="http://arxiv.org/find/cs/1/au:+Loizou_M/0/1/0/all/0/1">Marios Loizou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1">Tom Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Averkiou_M/0/1/0/all/0/1">Melinos Averkiou</a></p>
<p>We introduce FacadeNet, a deep learning approach for synthesizing building
facade images from diverse viewpoints. Our method employs a conditional GAN,
taking a single view of a facade along with the desired viewpoint information
and generates an image of the facade from the distinct viewpoint. To precisely
modify view-dependent elements like windows and doors while preserving the
structure of view-independent components such as walls, we introduce a
selective editing module. This module leverages image embeddings extracted from
a pre-trained vision transformer. Our experiments demonstrated state-of-the-art
performance on building facade generation, surpassing alternative methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01248">Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ablett_T/0/1/0/all/0/1">Trevor Ablett</a>, <a href="http://arxiv.org/find/cs/1/au:+Limoyo_O/0/1/0/all/0/1">Oliver Limoyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigal_A/0/1/0/all/0/1">Adam Sigal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jilani_A/0/1/0/all/0/1">Affan Jilani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1">Jonathan Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddiqi_K/0/1/0/all/0/1">Kaleem Siddiqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogan_F/0/1/0/all/0/1">Francois Hogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Gregory Dudek</a></p>
<p>Optical tactile sensors have emerged as an effective means to acquire dense
contact information during robotic manipulation. A recently-introduced
`see-through-your-skin' (STS) variant of this type of sensor has both visual
and tactile modes, enabled by leveraging a semi-transparent surface and
controllable lighting. In this work, we investigate the benefits of pairing
visuotactile sensing with imitation learning for contact-rich manipulation
tasks. First, we use tactile force measurements and a novel algorithm during
kinesthetic teaching to yield a force profile that better matches that of the
human demonstrator. Second, we add visual/tactile STS mode switching as a
control policy output, simplifying the application of the sensor. Finally, we
study multiple observation configurations to compare and contrast the value of
visual/tactile data (both with and without mode switching) with visual data
from a wrist-mounted eye-in-hand camera. We perform an extensive series of
experiments on a real robotic manipulator with door-opening and closing tasks,
including over 3,000 real test episodes. Our results highlight the importance
of tactile sensing for imitation learning, both for data collection to allow
force matching, and for policy execution to allow accurate task feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01256">An energy-based comparative analysis of common approaches to text classification in the Legal domain. (arXiv:2311.01256v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gultekin_S/0/1/0/all/0/1">Sinan Gultekin</a>, <a href="http://arxiv.org/find/cs/1/au:+Globo_A/0/1/0/all/0/1">Achille Globo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zugarini_A/0/1/0/all/0/1">Andrea Zugarini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernandes_M/0/1/0/all/0/1">Marco Ernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigutini_L/0/1/0/all/0/1">Leonardo Rigutini</a></p>
<p>Most Machine Learning research evaluates the best solutions in terms of
performance. However, in the race for the best performing model, many important
aspects are often overlooked when, on the contrary, they should be carefully
considered. In fact, sometimes the gaps in performance between different
approaches are neglectable, whereas factors such as production costs, energy
consumption, and carbon footprint must take into consideration. Large Language
Models (LLMs) are extensively adopted to address NLP problems in academia and
industry. In this work, we present a detailed quantitative comparison of LLM
and traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes
into account both performance (standard indices) and alternative metrics such
as timing, power consumption and cost, in a word: the carbon-footprint. In our
analysis, we considered the prototyping phase (model selection by
training-validation-test iterations) and in-production phases separately, since
they follow different implementation procedures and also require different
resources. The results indicate that very often, the simplest algorithms
achieve performance very close to that of large LLMs but with very low power
consumption and lower resource demands. The results obtained could suggest
companies to include additional evaluations in the choice of Machine Learning
(ML) solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01258">Formal Methods for Autonomous Systems. (arXiv:2311.01258v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wongpiromsarn_T/0/1/0/all/0/1">Tichakorn Wongpiromsarn</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghasemi_M/0/1/0/all/0/1">Mahsa Ghasemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cubuktepe_M/0/1/0/all/0/1">Murat Cubuktepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakirtzis_G/0/1/0/all/0/1">Georgios Bakirtzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Carr_S/0/1/0/all/0/1">Steven Carr</a>, <a href="http://arxiv.org/find/cs/1/au:+Karabag_M/0/1/0/all/0/1">Mustafa O. Karabag</a>, <a href="http://arxiv.org/find/cs/1/au:+Neary_C/0/1/0/all/0/1">Cyrus Neary</a>, <a href="http://arxiv.org/find/cs/1/au:+Gohari_P/0/1/0/all/0/1">Parham Gohari</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a></p>
<p>Formal methods refer to rigorous, mathematical approaches to system
development and have played a key role in establishing the correctness of
safety-critical systems. The main building blocks of formal methods are models
and specifications, which are analogous to behaviors and requirements in system
design and give us the means to verify and synthesize system behaviors with
formal guarantees.
</p>
<p>This monograph provides a survey of the current state of the art on
applications of formal methods in the autonomous systems domain. We consider
correct-by-construction synthesis under various formulations, including closed
systems, reactive, and probabilistic settings. Beyond synthesizing systems in
known environments, we address the concept of uncertainty and bound the
behavior of systems that employ learning using formal methods. Further, we
examine the synthesis of systems with monitoring, a mitigation technique for
ensuring that once a system deviates from expected behavior, it knows a way of
returning to normalcy. We also show how to overcome some limitations of formal
methods themselves with learning. We conclude with future directions for formal
methods in reinforcement learning, uncertainty, privacy, explainability of
formal methods, and regulation and certification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01260">Expressive TTS Driven by Natural Language Prompts Using Few Human Annotations. (arXiv:2311.01260v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1">Hanglei Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1">Yiwei Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1">Sen Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xie Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_K/0/1/0/all/0/1">Kai Yu</a></p>
<p>Expressive text-to-speech (TTS) aims to synthesize speeches with human-like
tones, moods, or even artistic attributes. Recent advancements in expressive
TTS empower users with the ability to directly control synthesis style through
natural language prompts. However, these methods often require excessive
training with a significant amount of style-annotated data, which can be
challenging to acquire. Moreover, they may have limited adaptability due to
fixed style annotations. In this work, we present FreeStyleTTS (FS-TTS), a
controllable expressive TTS model with minimal human annotations. Our approach
utilizes a large language model (LLM) to transform expressive TTS into a style
retrieval task. The LLM selects the best-matching style references from
annotated utterances based on external style prompts, which can be raw input
text or natural language style descriptions. The selected reference guides the
TTS pipeline to synthesize speeches with the intended style. This innovative
approach provides flexible, versatile, and precise style control with minimal
human workload. Experiments on a Mandarin storytelling corpus demonstrate
FS-TTS's proficiency in leveraging LLM's semantic inference ability to retrieve
desired styles from either input text or user-defined descriptions. This
results in synthetic speeches that are closely aligned with the specified
styles.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01267">UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding. (arXiv:2311.01267v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Han Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yutong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenqiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huanyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Dongzhe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cewu Lu</a></p>
<p>This paper explores the development of UniFolding, a sample-efficient,
scalable, and generalizable robotic system for unfolding and folding various
garments. UniFolding employs the proposed UFONet neural network to integrate
unfolding and folding decisions into a single policy model that is adaptable to
different garment types and states. The design of UniFolding is based on a
garment's partial point cloud, which aids in generalization and reduces
sensitivity to variations in texture and shape. The training pipeline
prioritizes low-cost, sample-efficient data collection. Training data is
collected via a human-centric process with offline and online stages. The
offline stage involves human unfolding and folding actions via Virtual Reality,
while the online stage utilizes human-in-the-loop learning to fine-tune the
model in a real-world setting. The system is tested on two garment types:
long-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with
significant variations in textures, shapes, and materials. More experiments and
videos can be found in the supplementary materials and on the website:
https://unifolding.robotflow.ai
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01301">TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence Generation with Biomedical Language Models. (arXiv:2311.01301v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Javier Gonz&#xe1;lez</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1">Cliff Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gero_Z/0/1/0/all/0/1">Zelalem Gero</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagga_J/0/1/0/all/0/1">Jass Bagga</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueno_R/0/1/0/all/0/1">Risa Ueno</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_I/0/1/0/all/0/1">Isabel Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Orakvin_E/0/1/0/all/0/1">Eduard Orakvin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiciman_E/0/1/0/all/0/1">Emre Kiciman</a>, <a href="http://arxiv.org/find/cs/1/au:+Nori_A/0/1/0/all/0/1">Aditya Nori</a>, <a href="http://arxiv.org/find/cs/1/au:+Weerasinghe_R/0/1/0/all/0/1">Roshanthi Weerasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Leidner_R/0/1/0/all/0/1">Rom S. Leidner</a>, <a href="http://arxiv.org/find/cs/1/au:+Piening_B/0/1/0/all/0/1">Brian Piening</a>, <a href="http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1">Tristan Naumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bifulco_C/0/1/0/all/0/1">Carlo Bifulco</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1">Hoifung Poon</a></p>
<p>The rapid digitization of real-world data offers an unprecedented opportunity
for optimizing healthcare delivery and accelerating biomedical discovery. In
practice, however, such data is most abundantly available in unstructured
forms, such as clinical notes in electronic medical records (EMRs), and it is
generally plagued by confounders. In this paper, we present TRIALSCOPE, a
unifying framework for distilling real-world evidence from population-level
observational data. TRIALSCOPE leverages biomedical language models to
structure clinical text at scale, employs advanced probabilistic modeling for
denoising and imputation, and incorporates state-of-the-art causal inference
techniques to combat common confounders. Using clinical trial specification as
generic representation, TRIALSCOPE provides a turn-key solution to generate and
reason with clinical hypotheses using observational data. In extensive
experiments and analyses on a large-scale real-world dataset with over one
million cancer patients from a large US healthcare network, we show that
TRIALSCOPE can produce high-quality structuring of real-world data and
generates comparable results to marquee cancer trials. In addition to
facilitating in-silicon clinical trial design and optimization, TRIALSCOPE may
be used to empower synthetic controls, pragmatic trials, post-market
surveillance, as well as support fine-grained patient-like-me reasoning in
precision diagnosis and treatment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01305">AWEQ: Post-Training Quantization with Activation-Weight Equalization for Large Language Models. (arXiv:2311.01305v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baisong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingwang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haixiao Xu</a></p>
<p>Large language models(LLMs) exhibit excellent performance across a variety of
tasks, but they come with significant computational and storage costs.
Quantizing these models is an effective way to alleviate this issue. However,
existing methods struggle to strike a balance between model accuracy and
hardware efficiency. This is where we introduce AWEQ, a post-training method
that requires no additional training overhead. AWEQ excels in both
ultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.
There is an observation that weight quantization is less challenging than
activation quantization. AWEQ transfers the difficulty of activation
quantization to weights using channel equalization, achieving a balance between
the quantization difficulties of both, and thereby maximizing performance. We
have further refined the equalization method to mitigate quantization bias
error, ensuring the robustness of the model. Extensive experiments on popular
models such as LLaMA and OPT demonstrate that AWEQ outperforms all existing
post-training quantization methods for large models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01310">Scattering Vision Transformer: Spectral Mixing Matters. (arXiv:2311.01310v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1">Badri N. Patro</a>, <a href="http://arxiv.org/find/cs/1/au:+Agneeswaran_V/0/1/0/all/0/1">Vijay Srinivas Agneeswaran</a></p>
<p>Vision transformers have gained significant attention and achieved
state-of-the-art performance in various computer vision tasks, including image
classification, instance segmentation, and object detection. However,
challenges remain in addressing attention complexity and effectively capturing
fine-grained information within images. Existing solutions often resort to
down-sampling operations, such as pooling, to reduce computational cost.
Unfortunately, such operations are non-invertible and can result in information
loss. In this paper, we present a novel approach called Scattering Vision
Transformer (SVT) to tackle these challenges. SVT incorporates a spectrally
scattering network that enables the capture of intricate image details. SVT
overcomes the invertibility issue associated with down-sampling operations by
separating low-frequency and high-frequency components. Furthermore, SVT
introduces a unique spectral gating network utilizing Einstein multiplication
for token and channel mixing, effectively reducing complexity. We show that SVT
achieves state-of-the-art performance on the ImageNet dataset with a
significant reduction in a number of parameters and FLOPS. SVT shows 2\%
improvement over LiTv2 and iFormer. SVT-H-S reaches 84.2\% top-1 accuracy,
while SVT-H-B reaches 85.2\% (state-of-art for base versions) and SVT-H-L
reaches 85.7\% (again state-of-art for large versions). SVT also shows
comparable results in other vision tasks such as instance segmentation. SVT
also outperforms other transformers in transfer learning on standard datasets
such as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The
project page is available on this
webpage.\url{https://badripatro.github.io/svt/}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01326">Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information. (arXiv:2311.01326v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chepurova_A/0/1/0/all/0/1">Alla Chepurova</a>, <a href="http://arxiv.org/find/cs/1/au:+Bulatov_A/0/1/0/all/0/1">Aydar Bulatov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuratov_Y/0/1/0/all/0/1">Yuri Kuratov</a>, <a href="http://arxiv.org/find/cs/1/au:+Burtsev_M/0/1/0/all/0/1">Mikhail Burtsev</a></p>
<p>Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which
limits their potential performance. Knowledge Graph Completion (KGC) techniques
aim to address this issue. However, traditional KGC methods are computationally
intensive and impractical for large-scale KGs, necessitating the learning of
dense node embeddings and computing pairwise distances. Generative
transformer-based language models (e.g., T5 and recent KGT5) offer a promising
solution as they can predict the tail nodes directly. In this study, we propose
to include node neighborhoods as additional information to improve KGC methods
based on language models. We examine the effects of this imputation and show
that, on both inductive and transductive Wikidata subsets, our method
outperforms KGT5 and conventional KGC approaches. We also provide an extensive
analysis of the impact of neighborhood on model prediction and show its
importance. Furthermore, we point the way to significantly improve KGC through
more effective neighborhood selection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01329">A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories. (arXiv:2311.01329v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Kai Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1">Alexander G. Schwing</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Xiong Wang</a></p>
<p>Offline imitation from observations aims to solve MDPs where only
task-specific expert states and task-agnostic non-expert state-action pairs are
available. Offline imitation is useful in real-world scenarios where arbitrary
interactions are costly and expert actions are unavailable. The
state-of-the-art "DIstribution Correction Estimation" (DICE) methods minimize
divergence of state occupancy between expert and learner policies and retrieve
a policy with weighted behavior cloning; however, their results are unstable
when learning from incomplete trajectories, due to a non-robust optimization in
the dual domain. To address the issue, in this paper, we propose
Trajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a
discounted sum along the future trajectory as the weight for weighted behavior
cloning. The terms for the sum are scaled by the output of a discriminator,
which aims to identify expert states. Despite simplicity, TAILO works well if
there exist trajectories or segments of expert behavior in the task-agnostic
data, a common assumption in prior work. In experiments across multiple
testbeds, we find TAILO to be more robust and effective, particularly with
incomplete trajectories.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01331">Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching. (arXiv:2311.01331v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Kai Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1">Alexander G. Schwing</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-xiong Wang</a></p>
<p>In real-world scenarios, arbitrary interactions with the environment can
often be costly, and actions of expert demonstrations are not always available.
To reduce the need for both, Offline Learning from Observations (LfO) is
extensively studied, where the agent learns to solve a task with only expert
states and \textit{task-agnostic} non-expert state-action pairs. The
state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the
state occupancy divergence between the learner and expert policies. However,
they are limited to either $f$-divergences (KL and $\chi^2$) or Wasserstein
distance with Rubinstein duality, the latter of which constrains the underlying
distance metric crucial to the performance of Wasserstein-based solutions. To
address this problem, we propose Primal Wasserstein DICE (PW-DICE), which
minimizes the primal Wasserstein distance between the expert and learner state
occupancies with a pessimistic regularizer and leverages a contrastively
learned distance as the underlying metric for the Wasserstein distance.
Theoretically, we prove that our framework is a generalization of the
state-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein
minimization. Empirically, we find that PW-DICE improves upon several
state-of-the-art methods on multiple testbeds.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01344">Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers. (arXiv:2311.01344v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Joud_R/0/1/0/all/0/1">Raphael Joud</a>, <a href="http://arxiv.org/find/cs/1/au:+Moellic_P/0/1/0/all/0/1">Pierre-Alain Moellic</a>, <a href="http://arxiv.org/find/cs/1/au:+Pontie_S/0/1/0/all/0/1">Simon Pontie</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigaud_J/0/1/0/all/0/1">Jean-Baptiste Rigaud</a></p>
<p>Model extraction is a growing concern for the security of AI systems. For
deep neural network models, the architecture is the most important information
an adversary aims to recover. Being a sequence of repeated computation blocks,
neural network models deployed on edge-devices will generate distinctive
side-channel leakages. The latter can be exploited to extract critical
information when targeted platforms are physically accessible. By combining
theoretical knowledge about deep learning practices and analysis of a
widespread implementation library (ARM CMSIS-NN), our purpose is to answer this
critical question: how far can we extract architecture information by simply
examining an EM side-channel trace? For the first time, we propose an
extraction methodology for traditional MLP and CNN models running on a high-end
32-bit microcontroller (Cortex-M7) that relies only on simple pattern
recognition analysis. Despite few challenging cases, we claim that, contrary to
parameters extraction, the complexity of the attack is relatively low and we
highlight the urgent need for practicable protections that could fit the strong
memory and latency requirements of such platforms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01351">Simplicial Models for the Epistemic Logic of Faulty Agents. (arXiv:2311.01351v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goubault_E/0/1/0/all/0/1">Eric Goubault</a>, <a href="http://arxiv.org/find/cs/1/au:+Kniazev_R/0/1/0/all/0/1">Roman Kniazev</a>, <a href="http://arxiv.org/find/cs/1/au:+Ledent_J/0/1/0/all/0/1">Jeremy Ledent</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajsbaum_S/0/1/0/all/0/1">Sergio Rajsbaum</a></p>
<p>In recent years, several authors have been investigating simplicial models, a
model of epistemic logic based on higher-dimensional structures called
simplicial complexes. In the original formulation, simplicial models were
always assumed to be pure, meaning that all worlds have the same dimension.
This is equivalent to the standard S5n semantics of epistemic logic, based on
Kripke models. By removing the assumption that models must be pure, we can go
beyond the usual Kripke semantics and study epistemic logics where the number
of agents participating in a world can vary. This approach has been developed
in a number of papers, with applications in fault-tolerant distributed
computing where processes may crash during the execution of a system. A
difficulty that arises is that subtle design choices in the definition of
impure simplicial models can result in different axioms of the resulting logic.
In this paper, we classify those design choices systematically, and axiomatize
the corresponding logics. We illustrate them via distributed computing examples
of synchronous systems where processes may crash.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01373">Recognize Any Regions. (arXiv:2311.01373v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haosen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chuofan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1">Bin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zehuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a></p>
<p>Understanding the semantics of individual regions or patches within
unconstrained images, such as in open-world object detection, represents a
critical yet challenging task in computer vision. Building on the success of
powerful image-level vision-language (ViL) foundation models like CLIP, recent
efforts have sought to harness their capabilities by either training a
contrastive model from scratch with an extensive collection of region-label
pairs or aligning the outputs of a detection model with image-level
representations of region proposals. Despite notable progress, these approaches
are plagued by computationally intensive training requirements, susceptibility
to data noise, and deficiency in contextual information. To address these
limitations, we explore the synergistic potential of off-the-shelf foundation
models, leveraging their respective strengths in localization and semantics. We
introduce a novel, generic, and efficient region recognition architecture,
named RegionSpot, designed to integrate position-aware localization knowledge
from a localization foundation model (e.g., SAM) with semantic information
extracted from a ViL model (e.g., CLIP). To fully exploit pretrained knowledge
while minimizing training overhead, we keep both foundation models frozen,
focusing optimization efforts solely on a lightweight attention-based knowledge
integration module. Through extensive experiments in the context of open-world
object recognition, our RegionSpot demonstrates significant performance
improvements over prior alternatives, while also providing substantial
computational savings. For instance, training our model with 3 million data in
a single day using 8 V100 GPUs. Our model outperforms GLIP by 6.5 % in mean
average precision (mAP), with an even larger margin by 14.8 % for more
challenging and rare categories.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01378">Vision-Language Foundation Models as Effective Robot Imitators. (arXiv:2311.01378v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinghang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minghuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cunjun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongtao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheang_C/0/1/0/all/0/1">Chilam Cheang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_Y/0/1/0/all/0/1">Ya Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huaping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1">Tao Kong</a></p>
<p>Recent progress in vision language foundation models has shown their ability
to understand multimodal data and resolve complicated vision language tasks,
including robotics manipulation. We seek a straightforward way of making use of
existing vision-language models (VLMs) with simple fine-tuning on robotics
data. To this end, we derive a simple and novel vision-language manipulation
framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.
Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step
vision-language comprehension, models sequential history information with an
explicit policy head, and is slightly fine-tuned by imitation learning only on
language-conditioned manipulation datasets. Such a decomposition provides
RoboFlamingo the flexibility for open-loop control and deployment on
low-performance platforms. By exceeding the state-of-the-art performance with a
large margin on the tested benchmark, we show RoboFlamingo can be an effective
and competitive alternative to adapt VLMs to robot control. Our extensive
experimental results also reveal several interesting conclusions regarding the
behavior of different pre-trained VLMs on manipulation tasks. We believe
RoboFlamingo has the potential to be a cost-effective and easy-to-use solution
for robotics manipulation, empowering everyone with the ability to fine-tune
their own robotics policy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01406">Analysis of Information Propagation in Ethereum Network Using Combined Graph Attention Network and Reinforcement Learning to Optimize Network Efficiency and Scalability. (arXiv:2311.01406v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Behfar_S/0/1/0/all/0/1">Stefan Kambiz Behfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Crowcroft_J/0/1/0/all/0/1">Jon Crowcroft</a></p>
<p>Blockchain technology has revolutionized the way information is propagated in
decentralized networks. Ethereum plays a pivotal role in facilitating smart
contracts and decentralized applications. Understanding information propagation
dynamics in Ethereum is crucial for ensuring network efficiency, security, and
scalability. In this study, we propose an innovative approach that utilizes
Graph Convolutional Networks (GCNs) to analyze the information propagation
patterns in the Ethereum network. The first phase of our research involves data
collection from the Ethereum blockchain, consisting of blocks, transactions,
and node degrees. We construct a transaction graph representation using
adjacency matrices to capture the node embeddings; while our major contribution
is to develop a combined Graph Attention Network (GAT) and Reinforcement
Learning (RL) model to optimize the network efficiency and scalability. It
learns the best actions to take in various network states, ultimately leading
to improved network efficiency, throughput, and optimize gas limits for block
processing. In the experimental evaluation, we analyze the performance of our
model on a large-scale Ethereum dataset. We investigate effectively aggregating
information from neighboring nodes capturing graph structure and updating node
embeddings using GCN with the objective of transaction pattern prediction,
accounting for varying network loads and number of blocks. Not only we design a
gas limit optimization model and provide the algorithm, but also to address
scalability, we demonstrate the use and implementation of sparse matrices in
GraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL
model achieves superior results compared to other GCN models in terms of
performance. It effectively propagates information across the network,
optimizing gas limits for block processing and improving network efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01412">Castor: Causal Temporal Regime Structure Learning. (arXiv:2311.01412v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1">Abdellah Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1">Pascal Frossard</a></p>
<p>The task of uncovering causal relationships among multivariate time series
data stands as an essential and challenging objective that cuts across a broad
array of disciplines ranging from climate science to healthcare. Such data
entails linear or non-linear relationships, and usually follow multiple a
priori unknown regimes. Existing causal discovery methods can infer summary
causal graphs from heterogeneous data with known regimes, but they fall short
in comprehensively learning both regimes and the corresponding causal graph. In
this paper, we introduce CASTOR, a novel framework designed to learn causal
relationships in heterogeneous time series data composed of various regimes,
each governed by a distinct causal graph. Through the maximization of a score
function via the EM algorithm, CASTOR infers the number of regimes and learns
linear or non-linear causal relationships in each regime. We demonstrate the
robust convergence properties of CASTOR, specifically highlighting its
proficiency in accurately identifying unique regimes. Empirical evidence,
garnered from exhaustive synthetic experiments and two real-world benchmarks,
confirm CASTOR's superior performance in causal discovery compared to baseline
methods. By learning a full temporal causal graph for each regime, CASTOR
establishes itself as a distinctly interpretable method for causal discovery in
heterogeneous time series.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01434">Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bouniot_Q/0/1/0/all/0/1">Quentin Bouniot</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1">Pavlo Mozharovskyi</a>, <a href="http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1">Florence d&#x27;Alch&#xe9;-Buc</a></p>
<p>Data augmentation is an essential building block for learning efficient deep
learning models. Among all augmentation techniques proposed so far, linear
interpolation of training data points, also called mixup, has found to be
effective for a large panel of applications. While the majority of works have
focused on selecting the right points to mix, or applying complex non-linear
interpolation, we are interested in mixing similar points more frequently and
strongly than less similar ones. To this end, we propose to dynamically change
the underlying distribution of interpolation coefficients through warping
functions, depending on the similarity between data points to combine. We
define an efficient and flexible framework to do so without losing in
diversity. We provide extensive experiments for classification and regression
tasks, showing that our proposed method improves both performance and
calibration of models. Code available in
https://github.com/ENSTA-U2IS/torch-uncertainty
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01441">Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models. (arXiv:2311.01441v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1">Andy Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Xiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haohan Wang</a></p>
<p>We propose a conceptually simple and lightweight framework for improving the
robustness of vision models through the combination of knowledge distillation
and data augmentation. We address the conjecture that larger models do not make
for better teachers by showing strong gains in out-of-distribution robustness
when distilling from pretrained foundation models. Following this finding, we
propose Discrete Adversarial Distillation (DAD), which leverages a robust
teacher to generate adversarial examples and a VQGAN to discretize them,
creating more informative samples than standard data augmentation techniques.
We provide a theoretical framework for the use of a robust teacher in the
knowledge distillation with data augmentation setting and demonstrate strong
gains in out-of-distribution robustness and clean accuracy across different
student architectures. Notably, our method adds minor computational overhead
compared to similar techniques and can be easily combined with other data
augmentations for further improvements.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2005.05098">Positional Games and QBF: A Polished Encoding. (arXiv:2005.05098v2 [cs.LO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mayer_Eichberger_V/0/1/0/all/0/1">Valentin Mayer-Eichberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Saffidine_A/0/1/0/all/0/1">Abdallah Saffidine</a></p>
<p>Positional games are a mathematical class of two-player games comprising
Tic-tac-toe and its generalizations. We propose a novel encoding of these games
into Quantified Boolean Formulas (QBFs) such that a game instance admits a
winning strategy for the first player if and only if the corresponding formula
is true. Our approach improves over previous QBF encodings of games in multiple
ways. First, it is generic and lets us encode other positional games, such as
Hex. Second, the structural properties of positional games, together with
careful treatment of illegal moves, let us generate more compact instances that
can be solved faster by state-of-the-art QBF solvers. We establish the latter
fact through extensive experiments. Finally, the compactness of our new
encoding makes it feasible to translate realistic game problems. We identify a
few such problems of historical significance and put them forward to the QBF
community as milestones of increasing difficulty.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2103.05147">Model-free Policy Learning with Reward Gradients. (arXiv:2103.05147v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lan_Q/0/1/0/all/0/1">Qingfeng Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1">Samuele Tosatto</a>, <a href="http://arxiv.org/find/cs/1/au:+Farrahi_H/0/1/0/all/0/1">Homayoon Farrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">A. Rupam Mahmood</a></p>
<p>Despite the increasing popularity of policy gradient methods, they are yet to
be widely utilized in sample-scarce applications, such as robotics. The sample
efficiency could be improved by making best usage of available information. As
a key component in reinforcement learning, the reward function is usually
devised carefully to guide the agent. Hence, the reward function is usually
known, allowing access to not only scalar reward signals but also reward
gradients. To benefit from reward gradients, previous works require the
knowledge of environment dynamics, which are hard to obtain. In this work, we
develop the \textit{Reward Policy Gradient} estimator, a novel approach that
integrates reward gradients without learning a model. Bypassing the model
dynamics allows our estimator to achieve a better bias-variance trade-off,
which results in a higher sample efficiency, as shown in the empirical
analysis. Our method also boosts the performance of Proximal Policy
Optimization on different MuJoCo control tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2105.10381">Entropy-based Discovery of Summary Causal Graphs in Time Series. (arXiv:2105.10381v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Assaad_C/0/1/0/all/0/1">Charles K. Assaad</a>, <a href="http://arxiv.org/find/cs/1/au:+Devijver_E/0/1/0/all/0/1">Emilie Devijver</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaussier_E/0/1/0/all/0/1">Eric Gaussier</a></p>
<p>This study addresses the problem of learning a summary causal graph on time
series with potentially different sampling rates. To do so, we first propose a
new causal temporal mutual information measure for time series. We then show
how this measure relates to an entropy reduction principle that can be seen as
a special case of the probability raising principle. We finally combine these
two ingredients in PC-like and FCI-like algorithms to construct the summary
causal graph. There algorithm are evaluated on several datasets, which shows
both their efficacy and efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.11104">Combining Optimal Path Search With Task-Dependent Learning in a Neural Network. (arXiv:2201.11104v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kulvicius_T/0/1/0/all/0/1">Tomas Kulvicius</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamosiunaite_M/0/1/0/all/0/1">Minija Tamosiunaite</a>, <a href="http://arxiv.org/find/cs/1/au:+Worgotter_F/0/1/0/all/0/1">Florentin W&#xf6;rg&#xf6;tter</a></p>
<p>Finding optimal paths in connected graphs requires determining the smallest
total cost for traveling along the graph's edges. This problem can be solved by
several classical algorithms where, usually, costs are predefined for all
edges. Conventional planning methods can, thus, normally not be used when
wanting to change costs in an adaptive way following the requirements of some
task. Here we show that one can define a neural network representation of path
finding problems by transforming cost values into synaptic weights, which
allows for online weight adaptation using network learning mechanisms. When
starting with an initial activity value of one, activity propagation in this
network will lead to solutions, which are identical to those found by the
Bellman-Ford algorithm. The neural network has the same algorithmic complexity
as Bellman-Ford and, in addition, we can show that network learning mechanisms
(such as Hebbian learning) can adapt the weights in the network augmenting the
resulting paths according to some task at hand. We demonstrate this by learning
to navigate in an environment with obstacles as well as by learning to follow
certain sequences of path nodes. Hence, the here-presented novel algorithm may
open up a different regime of applications where path-augmentation (by
learning) is directly coupled with path finding in a natural way.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.08879">SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault Diagnosis in Chemical Processes. (arXiv:2208.08879v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Golyadkin_M/0/1/0/all/0/1">Maksim Golyadkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pozdnyakov_V/0/1/0/all/0/1">Vitaliy Pozdnyakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhukov_L/0/1/0/all/0/1">Leonid Zhukov</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarov_I/0/1/0/all/0/1">Ilya Makarov</a></p>
<p>Modern industrial facilities generate large volumes of raw sensor data during
the production process. This data is used to monitor and control the processes
and can be analyzed to detect and predict process abnormalities. Typically, the
data has to be annotated by experts in order to be used in predictive modeling.
However, manual annotation of large amounts of data can be difficult in
industrial settings.
</p>
<p>In this paper, we propose SensorSCAN, a novel method for unsupervised fault
detection and diagnosis, designed for industrial chemical process monitoring.
We demonstrate our model's performance on two publicly available datasets of
the Tennessee Eastman Process with various faults. The results show that our
method significantly outperforms existing approaches (+0.2-0.3 TPR for a fixed
FPR) and effectively detects most of the process faults without expert
annotation. Moreover, we show that the model fine-tuned on a small fraction of
labeled data nearly reaches the performance of a SOTA model trained on the full
dataset. We also demonstrate that our method is suitable for real-world
applications where the number of faults is not known in advance. The code is
available at https://github.com/AIRI-Institute/sensorscan.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.14741">Failed Goal Aware Hindsight Experience Replay. (arXiv:2208.14741v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taeyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Har_D/0/1/0/all/0/1">Dongsoo Har</a></p>
<p>In multi-goal reinforcement learning for a given environment, agents learn
policies to achieve multiple goals by using experiences gained from
interactions with the environment. One of the key challenges in this setting is
training agents using sparse binary rewards, which can be difficult due to a
lack of successful experiences. To address this challenge, hindsight experience
replay (HER) generates successful experiences from unsuccessful experiences.
However, the process of generating successful experiences from uniformly
sampled ones can be inefficient. In this paper, a novel approach called Failed
goal Aware HER (FAHER) is proposed to enhance the sampling efficiency. The
approach exploits the property of achieved goals in relation to failed goals
that are defined as the original goals not achieved. The proposed method
involves clustering episodes with different achieved goals using a cluster
model and subsequently sampling experiences in the manner of HER. The cluster
model is generated by applying a clustering algorithm to failed goals. The
proposed method is validated by experiments with three robotic control tasks of
the OpenAI gym. The results of experiments demonstrate that the proposed method
is more sample efficient and achieves improved performance over baseline
approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.04366">KP-RNN: A Deep Learning Pipeline for Human Motion Prediction and Synthesis of Performance Art. (arXiv:2210.04366v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Perrine_P/0/1/0/all/0/1">Patrick Perrine</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirkby_T/0/1/0/all/0/1">Trevor Kirkby</a></p>
<p>Digitally synthesizing human motion is an inherently complex process, which
can create obstacles in application areas such as virtual reality. We offer a
new approach for predicting human motion, KP-RNN, a neural network which can
integrate easily with existing image processing and generation pipelines. We
utilize a new human motion dataset of performance art, Take The Lead, as well
as the motion generation pipeline, the Everybody Dance Now system, to
demonstrate the effectiveness of KP-RNN's motion predictions. We have found
that our neural network can predict human dance movements effectively, which
serves as a baseline result for future works using the Take The Lead dataset.
Since KP-RNN can work alongside a system such as Everybody Dance Now, we argue
that our approach could inspire new methods for rendering human avatar
animation. This work also serves to benefit the visualization of performance
art in digital platforms by utilizing accessible neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.15092">Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting. (arXiv:2211.15092v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jati_A/0/1/0/all/0/1">Arindam Jati</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekambaram_V/0/1/0/all/0/1">Vijay Ekambaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1">Shaonli Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1">Brian Quanz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gifford_W/0/1/0/all/0/1">Wesley M. Gifford</a>, <a href="http://arxiv.org/find/cs/1/au:+Harsha_P/0/1/0/all/0/1">Pavithra Harsha</a>, <a href="http://arxiv.org/find/cs/1/au:+Siegel_S/0/1/0/all/0/1">Stuart Siegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Sumanta Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanaswami_C/0/1/0/all/0/1">Chandra Narayanaswami</a></p>
<p>Selecting the right set of hyperparameters is crucial in time series
forecasting. The classical temporal cross-validation framework for
hyperparameter optimization (HPO) often leads to poor test performance because
of a possible mismatch between validation and test periods. To address this
test-validation mismatch, we propose a novel technique, H-Pro to drive HPO via
test proxies by exploiting data hierarchies often associated with time series
datasets. Since higher-level aggregated time series often show less
irregularity and better predictability as compared to the lowest-level time
series which can be sparse and intermittent, we optimize the hyperparameters of
the lowest-level base-forecaster by leveraging the proxy forecasts for the test
period generated from the forecasters at higher levels. H-Pro can be applied on
any off-the-shelf machine learning model to perform HPO. We validate the
efficacy of our technique with extensive empirical evaluation on five publicly
available hierarchical forecasting datasets. Our approach outperforms existing
state-of-the-art methods in Tourism, Wiki, and Traffic datasets, and achieves
competitive result in Tourism-L dataset, without any model-specific
enhancements. Moreover, our method outperforms the winning method of the M5
forecast accuracy competition.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.10649">Inversion of Bayesian Networks. (arXiv:2212.10649v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oostrum_J/0/1/0/all/0/1">Jesse van Oostrum</a>, <a href="http://arxiv.org/find/cs/1/au:+Hintum_P/0/1/0/all/0/1">Peter van Hintum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ay_N/0/1/0/all/0/1">Nihat Ay</a></p>
<p>Variational autoencoders and Helmholtz machines use a recognition network
(encoder) to approximate the posterior distribution of a generative model
(decoder). In this paper we study the necessary and sufficient properties of a
recognition network so that it can model the true posterior distribution
exactly. These results are derived in the general context of probabilistic
graphical modelling / Bayesian networks, for which the network represents a set
of conditional independence statements. We derive both global conditions, in
terms of d-separation, and local conditions for the recognition network to have
the desired qualities. It turns out that for the local conditions the property
perfectness (for every node, all parents are joined) plays an important role.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.08317">Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain. (arXiv:2301.08317v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vece_C/0/1/0/all/0/1">Chiara Di Vece</a>, <a href="http://arxiv.org/find/cs/1/au:+Lous_M/0/1/0/all/0/1">Maela Le Lous</a>, <a href="http://arxiv.org/find/cs/1/au:+Dromey_B/0/1/0/all/0/1">Brian Dromey</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1">Francisco Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1">Anna L David</a>, <a href="http://arxiv.org/find/cs/1/au:+Peebles_D/0/1/0/all/0/1">Donald Peebles</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a></p>
<p>In obstetric ultrasound (US) scanning, the learner's ability to mentally
build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US
image represents a significant challenge in skill acquisition. We aim to build
a US plane localization system for 3D visualization, training, and guidance
without integrating additional sensors. This work builds on top of our previous
work, which predicts the six-dimensional (6D) pose of arbitrarily oriented US
planes slicing the fetal brain with respect to a normalized reference frame
using a convolutional neural network (CNN) regression network. Here, we analyze
in detail the assumptions of the normalized fetal brain reference frame and
quantify its accuracy with respect to the acquisition of transventricular (TV)
standard plane (SP) for fetal biometry. We investigate the impact of
registration quality in the training and testing data and its subsequent effect
on trained models. Finally, we introduce data augmentations and larger training
sets that improve the results of our previous work, achieving median errors of
2.97 mm and 6.63 degrees for translation and rotation, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10180">Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning. (arXiv:2303.10180v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1">Xiuding Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yaoyao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Beimin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yu Yao</a></p>
<p>Automated anesthesia promises to enable more precise and personalized
anesthetic administration and free anesthesiologists from repetitive tasks,
allowing them to focus on the most critical aspects of a patient's surgical
care. Current research has typically focused on creating simulated environments
from which agents can learn. These approaches have demonstrated good
experimental results, but are still far from clinical application. In this
paper, Policy Constraint Q-Learning (PCQL), a data-driven reinforcement
learning algorithm for solving the problem of learning anesthesia strategies on
real clinical datasets, is proposed. Conservative Q-Learning was first
introduced to alleviate the problem of Q function overestimation in an offline
context. A policy constraint term is added to agent training to keep the policy
distribution of the agent and the anesthesiologist consistent to ensure safer
decisions made by the agent in anesthesia scenarios. The effectiveness of PCQL
was validated by extensive experiments on a real clinical anesthesia dataset.
Experimental results show that PCQL is predicted to achieve higher gains than
the baseline approach while maintaining good agreement with the reference dose
given by the anesthesiologist, using less total dose, and being more responsive
to the patient's vital signs. In addition, the confidence intervals of the
agent were investigated, which were able to cover most of the clinical
decisions of the anesthesiologist. Finally, an interpretable method, SHAP, was
used to analyze the contributing components of the model predictions to
increase the transparency of the model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.12783">Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Auer_A/0/1/0/all/0/1">Andreas Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gauch_M/0/1/0/all/0/1">Martin Gauch</a>, <a href="http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1">Daniel Klotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1">Sepp Hochreiter</a></p>
<p>To quantify uncertainty, conformal prediction methods are gaining
continuously more interest and have already been successfully applied to
various domains. However, they are difficult to apply to time series as the
autocorrelative structure of time series violates basic assumptions required by
conformal prediction. We propose HopCPT, a novel conformal prediction approach
for time series that not only copes with temporal structures but leverages
them. We show that our approach is theoretically well justified for time series
where temporal dependencies are present. In experiments, we demonstrate that
our new approach outperforms state-of-the-art conformal prediction methods on
multiple real-world time series datasets from four different domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17760">CAMEL: Communicative Agents for &quot;Mind&quot; Exploration of Large Language Model Society. (arXiv:2303.17760v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guohao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammoud_H/0/1/0/all/0/1">Hasan Abed Al Kader Hammoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Itani_H/0/1/0/all/0/1">Hani Itani</a>, <a href="http://arxiv.org/find/cs/1/au:+Khizbullin_D/0/1/0/all/0/1">Dmitrii Khizbullin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a></p>
<p>The rapid advancement of chat-based language models has led to remarkable
progress in complex task-solving. However, their success heavily relies on
human input to guide the conversation, which can be challenging and
time-consuming. This paper explores the potential of building scalable
techniques to facilitate autonomous cooperation among communicative agents, and
provides insight into their "cognitive" processes. To address the challenges of
achieving autonomous cooperation, we propose a novel communicative agent
framework named role-playing. Our approach involves using inception prompting
to guide chat agents toward task completion while maintaining consistency with
human intentions. We showcase how role-playing can be used to generate
conversational data for studying the behaviors and capabilities of a society of
agents, providing a valuable resource for investigating conversational language
models. In particular, we conduct comprehensive studies on
instruction-following cooperation in multi-agent settings. Our contributions
include introducing a novel communicative agent framework, offering a scalable
approach for studying the cooperative behaviors and capabilities of multi-agent
systems, and open-sourcing our library to support research on communicative
agents and beyond: https://github.com/camel-ai/camel.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.00586">How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v5 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1">Michael Hanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1">Ollie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Variengien_A/0/1/0/all/0/1">Alexandre Variengien</a></p>
<p>Pre-trained language models can be surprisingly adept at tasks they were not
explicitly trained on, but how they implement these capabilities is poorly
understood. In this paper, we investigate the basic mathematical abilities
often acquired by pre-trained language models. Concretely, we use mechanistic
interpretability techniques to explain the (limited) mathematical abilities of
GPT-2 small. As a case study, we examine its ability to take in sentences such
as "The war lasted from the year 1732 to the year 17", and predict valid
two-digit end years (years &gt; 32). We first identify a circuit, a small subset
of GPT-2 small's computational graph that computes this task's output. Then, we
explain the role of each circuit component, showing that GPT-2 small's final
multi-layer perceptrons boost the probability of end years greater than the
start year. Finally, we find related tasks that activate our circuit. Our
results suggest that GPT-2 small computes greater-than using a complex but
general mechanism that activates across diverse contexts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02305">Calibrated Explanations: with Uncertainty Information and Counterfactuals. (arXiv:2305.02305v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lofstrom_H/0/1/0/all/0/1">Helena Lofstrom</a>, <a href="http://arxiv.org/find/cs/1/au:+Lofstrom_T/0/1/0/all/0/1">Tuwe Lofstrom</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansson_U/0/1/0/all/0/1">Ulf Johansson</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonstrod_C/0/1/0/all/0/1">Cecilia Sonstrod</a></p>
<p>While local explanations for AI models can offer insights into individual
predictions, such as feature importance, they are plagued by issues like
instability. The unreliability of feature weights, often skewed due to poorly
calibrated ML models, deepens these challenges. Moreover, the critical aspect
of feature importance uncertainty remains mostly unaddressed in Explainable AI
(XAI). The novel feature importance explanation method presented in this paper,
called Calibrated Explanations (CE), is designed to tackle these issues
head-on. Built on the foundation of Venn-Abers, CE not only calibrates the
underlying model but also delivers reliable feature importance explanations
with an exact definition of the feature weights. CE goes beyond conventional
solutions by addressing output uncertainty. It accomplishes this by providing
uncertainty quantification for both feature weights and the model's probability
estimates. Additionally, CE is model-agnostic, featuring easily comprehensible
conditional rules and the ability to generate counterfactual explanations with
embedded uncertainty quantification. Results from an evaluation with 25
benchmark datasets underscore the efficacy of CE, making it stand as a fast,
reliable, stable, and robust solution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11147">UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild. (arXiv:2305.11147v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Can Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Ning Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yihao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xinyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yingbo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1">Juan Carlos Niebles</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yun Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ran Xu</a></p>
<p>Achieving machine autonomy and human control often represent divergent
objectives in the design of interactive AI systems. Visual generative
foundation models such as Stable Diffusion show promise in navigating these
goals, especially when prompted with arbitrary languages. However, they often
fall short in generating images with spatial, structural, or geometric
controls. The integration of such controls, which can accommodate various
visual conditions in a single unified model, remains an unaddressed challenge.
In response, we introduce UniControl, a new generative foundation model that
consolidates a wide array of controllable condition-to-image (C2I) tasks within
a singular framework, while still allowing for arbitrary language prompts.
UniControl enables pixel-level-precise image generation, where visual
conditions primarily influence the generated structures and language prompts
guide the style and context. To equip UniControl with the capacity to handle
diverse visual conditions, we augment pretrained text-to-image diffusion models
and introduce a task-aware HyperNet to modulate the diffusion models, enabling
the adaptation to different C2I tasks simultaneously. Trained on nine unique
C2I tasks, UniControl demonstrates impressive zero-shot generation abilities
with unseen visual conditions. Experimental results show that UniControl often
surpasses the performance of single-task-controlled methods of comparable model
sizes. This control versatility positions UniControl as a significant
advancement in the realm of controllable visual generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14909">Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning. (arXiv:2305.14909v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guan_L/0/1/0/all/0/1">Lin Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Valmeekam_K/0/1/0/all/0/1">Karthik Valmeekam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreedharan_S/0/1/0/all/0/1">Sarath Sreedharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1">Subbarao Kambhampati</a></p>
<p>There is a growing interest in applying pre-trained large language models
(LLMs) to planning problems. However, methods that use LLMs directly as
planners are currently impractical due to several factors, including limited
correctness of plans, strong reliance on feedback from interactions with
simulators or even the actual environment, and the inefficiency in utilizing
human feedback. In this work, we introduce a novel alternative paradigm that
constructs an explicit world (domain) model in planning domain definition
language (PDDL) and then uses it to plan with sound domain-independent
planners. To address the fact that LLMs may not generate a fully functional
PDDL model initially, we employ LLMs as an interface between PDDL and sources
of corrective feedback, such as PDDL validators and humans. For users who lack
a background in PDDL, we show that LLMs can translate PDDL into natural
language and effectively encode corrective feedback back to the underlying
domain model. Our framework not only enjoys the correctness guarantee offered
by the external planners but also reduces human involvement by allowing users
to correct domain models at the beginning, rather than inspecting and
correcting (through interactive prompting) every generated plan as in previous
work. On two IPC domains and a Household domain that is more complicated than
commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be
leveraged to produce high-quality PDDL models for over 40 actions, and the
corrected PDDL models are then used to successfully solve 48 challenging
planning tasks. Resources, including the source code, are released at:
https://guansuns.github.io/pages/llm-dm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18333">Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics. (arXiv:2305.18333v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1">Guy Tennenholtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mladenov_M/0/1/0/all/0/1">Martin Mladenov</a>, <a href="http://arxiv.org/find/cs/1/au:+Merlis_N/0/1/0/all/0/1">Nadav Merlis</a>, <a href="http://arxiv.org/find/cs/1/au:+Axtell_R/0/1/0/all/0/1">Robert L. Axtell</a>, <a href="http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1">Craig Boutilier</a></p>
<p>While popularity bias is recognized to play a crucial role in recommmender
(and other ranking-based) systems, detailed analysis of its impact on
collective user welfare has largely been lacking. We propose and theoretically
analyze a general mechanism, rooted in many of the models proposed in the
literature, by which item popularity, item quality, and position bias jointly
impact user choice. We focus on a standard setting in which user utility is
largely driven by item quality, and a recommender attempts to estimate it given
user behavior. Formulating the problem as a non-stationary contextual bandit,
we study the ability of a recommender policy to maximize user welfare under
this model. We highlight the importance of exploration, not to eliminate
popularity bias, but to mitigate its negative impact on welfare. We first show
that naive popularity-biased recommenders induce linear regret by conflating
item quality and popularity. More generally, we show that, even in linear
settings, identifiability of item quality may not be possible due to the
confounding effects of popularity bias. However, under sufficient variability
assumptions, we develop an efficient optimistic algorithm and prove efficient
regret guarantees w.r.t. user welfare. We complement our analysis with several
simulation studies, which demonstrate the negative impact of popularity bias on
the performance of several natural recommender policies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07962">Parting with Misconceptions about Learning-based Vehicle Motion Planning. (arXiv:2306.07962v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dauner_D/0/1/0/all/0/1">Daniel Dauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Hallgarten_M/0/1/0/all/0/1">Marcel Hallgarten</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Andreas Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitta_K/0/1/0/all/0/1">Kashyap Chitta</a></p>
<p>The release of nuPlan marks a new era in vehicle motion planning research,
offering the first large-scale real-world dataset and evaluation schemes
requiring both precise short-term planning and long-horizon ego-forecasting.
Existing systems struggle to simultaneously meet both requirements. Indeed, we
find that these tasks are fundamentally misaligned and should be addressed
independently. We further assess the current state of closed-loop planning in
the field, revealing the limitations of learning-based methods in complex
real-world scenarios and the value of simple rule-based priors such as
centerline selection through lane graph search algorithms. More surprisingly,
for the open-loop sub-task, we observe that the best results are achieved when
using only this centerline as scene context (i.e., ignoring all information
regarding the map and other agents). Combining these insights, we propose an
extremely simple and efficient planner which outperforms an extensive set of
competitors, winning the nuPlan planning challenge 2023.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.08129">AVIS: Autonomous Visual Information Seeking with Large Language Model Agent. (arXiv:2306.08129v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Ziniu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Iscen_A/0/1/0/all/0/1">Ahmet Iscen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yizhou Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1">David A Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathi_A/0/1/0/all/0/1">Alireza Fathi</a></p>
<p>In this paper, we propose an autonomous information seeking visual question
answering framework, AVIS. Our method leverages a Large Language Model (LLM) to
dynamically strategize the utilization of external tools and to investigate
their outputs, thereby acquiring the indispensable knowledge needed to provide
answers to the posed questions. Responding to visual questions that necessitate
external knowledge, such as "What event is commemorated by the building
depicted in this image?", is a complex task. This task presents a combinatorial
search space that demands a sequence of actions, including invoking APIs,
analyzing their responses, and making informed decisions. We conduct a user
study to collect a variety of instances of human decision-making when faced
with this task. This data is then used to design a system comprised of three
components: an LLM-powered planner that dynamically determines which tool to
use next, an LLM-powered reasoner that analyzes and extracts key information
from the tool outputs, and a working memory component that retains the acquired
information throughout the process. The collected user behavior serves as a
guide for our system in two key ways. First, we create a transition graph by
analyzing the sequence of decisions made by users. This graph delineates
distinct states and confines the set of actions available at each state.
Second, we use examples of user decision-making to provide our LLM-powered
planner and reasoner with relevant contextual instances, enhancing their
capacity to make informed decisions. We show that AVIS achieves
state-of-the-art results on knowledge-intensive visual question answering
benchmarks such as Infoseek and OK-VQA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09750">Fedstellar: A Platform for Decentralized Federated Learning. (arXiv:2306.09750v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Beltran_E/0/1/0/all/0/1">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">&#xc1;ngel Luis Perales G&#xf3;mez</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1">Chao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernal_S/0/1/0/all/0/1">Sergio L&#xf3;pez Bernal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bovet_G/0/1/0/all/0/1">G&#xe9;r&#xf4;me Bovet</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1">Manuel Gil P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1">Gregorio Mart&#xed;nez P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Celdran_A/0/1/0/all/0/1">Alberto Huertas Celdr&#xe1;n</a></p>
<p>In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train
Machine Learning (ML) models across the participants of a federation while
preserving data privacy. Since its birth, Centralized FL (CFL) has been the
most used approach, where a central entity aggregates participants' models to
create a global one. However, CFL presents limitations such as communication
bottlenecks, single point of failure, and reliance on a central server.
Decentralized Federated Learning (DFL) addresses these issues by enabling
decentralized model aggregation and minimizing dependency on a central entity.
Despite these advances, current platforms training DFL models struggle with key
issues such as managing heterogeneous federation network topologies. To
overcome these challenges, this paper presents Fedstellar, a novel platform
designed to train FL models in a decentralized, semi-decentralized, and
centralized fashion across diverse federations of physical or virtualized
devices. The Fedstellar implementation encompasses a web application with an
interactive graphical interface, a controller for deploying federations of
nodes using physical or virtual devices, and a core deployed on each device
which provides the logic needed to train, aggregate, and communicate in the
network. The effectiveness of the platform has been demonstrated in two
scenarios: a physical deployment involving single-board devices such as
Raspberry Pis for detecting cyberattacks, and a virtualized deployment
comparing various FL approaches in a controlled environment using MNIST and
CIFAR-10 datasets. In both scenarios, Fedstellar demonstrated consistent
performance and adaptability, achieving F1 scores of 91%, 98%, and 91.2% using
DFL for detecting cyberattacks and classifying MNIST and CIFAR-10,
respectively, reducing training time by 32% compared to centralized approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15668">Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties. (arXiv:2306.15668v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tung_H/0/1/0/all/0/1">Hsiao-Yu Tung</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Mingyu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenfang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bear_D/0/1/0/all/0/1">Daniel Bear</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1">Daniel LK Yamins</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Judith E Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kevin A. Smith</a></p>
<p>General physical scene understanding requires more than simply localizing and
recognizing objects -- it requires knowledge that objects can have different
latent properties (e.g., mass or elasticity), and that those properties affect
the outcome of physical events. While there has been great progress in physical
and video prediction models in recent years, benchmarks to test their
performance typically do not require an understanding that objects have
individual physical properties, or at best test only those properties that are
directly observable (e.g., size or color). This work proposes a novel dataset
and benchmark, termed Physion++, that rigorously evaluates visual physical
prediction in artificial systems under circumstances where those predictions
rely on accurate estimates of the latent physical properties of objects in the
scene. Specifically, we test scenarios where accurate prediction relies on
estimates of properties such as mass, friction, elasticity, and deformability,
and where the values of those properties can only be inferred by observing how
objects move and interact with other objects or fluids. We evaluate the
performance of a number of state-of-the-art prediction models that span a
variety of levels of learning vs. built-in knowledge, and compare that
performance to a set of human predictions. We find that models that have been
trained using standard regimes and datasets do not spontaneously learn to make
inferences about latent properties, but also that models that encode objectness
and physical states tend to make better predictions. However, there is still a
huge gap between all models and human performance, and all models' predictions
correlate poorly with those made by humans, suggesting that no state-of-the-art
model is learning to make physical predictions in a human-like way. Project
page: https://dingmyu.github.io/physion_v2/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02028">EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models. (arXiv:2307.02028v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wornow_M/0/1/0/all/0/1">Michael Wornow</a>, <a href="http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1">Rahul Thapa</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinberg_E/0/1/0/all/0/1">Ethan Steinberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Fries_J/0/1/0/all/0/1">Jason A. Fries</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nigam H. Shah</a></p>
<p>While the general machine learning (ML) community has benefited from public
datasets, tasks, and models, the progress of ML in healthcare has been hampered
by a lack of such shared assets. The success of foundation models creates new
challenges for healthcare ML by requiring access to shared pretrained models to
validate performance benefits. We help address these challenges through three
contributions. First, we publish a new dataset, EHRSHOT, which contains
deidentified structured data from the electronic health records (EHRs) of 6,739
patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR
datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.
Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical
foundation model pretrained on the structured EHR data of 2.57M patients. We
are one of the first to fully release such a model for coded EHR data; in
contrast, most prior models released for clinical data (e.g. GatorTron,
ClinicalBERT) only work with unstructured text and cannot process the rich,
structured data within an EHR. We provide an end-to-end pipeline for the
community to validate and build upon its performance. Third, we define 15
few-shot clinical prediction tasks, enabling evaluation of foundation models on
benefits such as sample efficiency and task adaptation. Our model and dataset
are available via a research data use agreement from the Stanford AIMI Center.
Code to reproduce our results are available at our Github repo:
https://github.com/som-shahlab/ehrshot-benchmark
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03486">Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning. (arXiv:2307.03486v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1">Seungyong Moon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1">Junyoung Yeom</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1">Bumsoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hyun Oh Song</a></p>
<p>Discovering achievements with a hierarchical structure in procedurally
generated environments presents a significant challenge. This requires an agent
to possess a broad range of abilities, including generalization and long-term
reasoning. Many prior methods have been built upon model-based or hierarchical
approaches, with the belief that an explicit module for long-term planning
would be advantageous for learning hierarchical dependencies. However, these
methods demand an excessive number of environment interactions or large model
sizes, limiting their practicality. In this work, we demonstrate that proximal
policy optimization (PPO), a simple yet versatile model-free algorithm,
outperforms previous methods when optimized with recent implementation
practices. Moreover, we find that the PPO agent can predict the next
achievement to be unlocked to some extent, albeit with limited confidence.
Based on this observation, we introduce a novel contrastive learning method,
called achievement distillation, which strengthens the agent's ability to
predict the next achievement. Our method exhibits a strong capacity for
discovering hierarchical achievements and shows state-of-the-art performance on
the challenging Crafter environment in a sample-efficient manner while
utilizing fewer model parameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05973">VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models. (arXiv:2307.05973v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenlong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunzhu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a></p>
<p>Large language models (LLMs) are shown to possess a wealth of actionable
knowledge that can be extracted for robot manipulation in the form of reasoning
and planning. Despite the progress, most still rely on pre-defined motion
primitives to carry out the physical interactions with the environment, which
remains a major bottleneck. In this work, we aim to synthesize robot
trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a
large variety of manipulation tasks given an open-set of instructions and an
open-set of objects. We achieve this by first observing that LLMs excel at
inferring affordances and constraints given a free-form language instruction.
More importantly, by leveraging their code-writing capabilities, they can
interact with a vision-language model (VLM) to compose 3D value maps to ground
the knowledge into the observation space of the agent. The composed value maps
are then used in a model-based planning framework to zero-shot synthesize
closed-loop robot trajectories with robustness to dynamic perturbations. We
further demonstrate how the proposed framework can benefit from online
experiences by efficiently learning a dynamics model for scenes that involve
contact-rich interactions. We present a large-scale study of the proposed
method in both simulated and real-robot environments, showcasing the ability to
perform a large variety of everyday manipulation tasks specified in free-form
natural language. Videos and code at https://voxposer.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10943">Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery. (arXiv:2307.10943v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyungmin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_S/0/1/0/all/0/1">Sungho Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Daehwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_D/0/1/0/all/0/1">Daun Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Hansang Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Junmo Kim</a></p>
<p>Recent advances in deep learning have significantly improved the performance
of various computer vision applications. However, discovering novel categories
in an incremental learning scenario remains a challenging problem due to the
lack of prior knowledge about the number and nature of new categories. Existing
methods for novel category discovery are limited by their reliance on labeled
datasets and prior knowledge about the number of novel categories and the
proportion of novel samples in the batch. To address the limitations and more
accurately reflect real-world scenarios, in this paper, we propose a novel
unsupervised class incremental learning approach for discovering novel
categories on unlabeled sets without prior knowledge. The proposed method
fine-tunes the feature extractor and proxy anchors on labeled sets, then splits
samples into old and novel categories and clusters on the unlabeled dataset.
Furthermore, the proxy anchors-based exemplar generates representative category
vectors to mitigate catastrophic forgetting. Experimental results demonstrate
that our proposed approach outperforms the state-of-the-art methods on
fine-grained datasets under real-world scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12776">Predict-AI-bility of how humans balance self-interest with the interest of others. (arXiv:2307.12776v2 [econ.GN] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Capraro_V/0/1/0/all/0/1">Valerio Capraro</a>, <a href="http://arxiv.org/find/econ/1/au:+Paolo_R/0/1/0/all/0/1">Roberto Di Paolo</a>, <a href="http://arxiv.org/find/econ/1/au:+Pizziol_V/0/1/0/all/0/1">Veronica Pizziol</a></p>
<p>Generative artificial intelligence holds enormous potential to revolutionize
decision-making processes, from everyday to high-stake scenarios. However, as
many decisions carry social implications, for AI to be a reliable assistant for
decision-making it is crucial that it is able to capture the balance between
self-interest and the interest of others. We investigate the ability of three
of the most advanced chatbots to predict dictator game decisions across 108
experiments with human participants from 12 countries. We find that only GPT-4
(not Bard nor Bing) correctly captures qualitative behavioral patterns,
identifying three major classes of behavior: self-interested, inequity-averse,
and fully altruistic. Nonetheless, GPT-4 consistently underestimates
self-interest and inequity-aversion, while overestimating altruistic behavior.
This bias has significant implications for AI developers and users.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.06534">Self-Supervised Pre-Training with Contrastive and Masked Autoencoder Methods for Dealing with Small Datasets in Deep Learning for Medical Imaging. (arXiv:2308.06534v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1">Daniel Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Payer_T/0/1/0/all/0/1">Tristan Payer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1">Catharina Silvia Lisson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1">Christoph Gerhard Lisson</a>, <a href="http://arxiv.org/find/cs/1/au:+Beer_M/0/1/0/all/0/1">Meinrad Beer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gotz_M/0/1/0/all/0/1">Michael G&#xf6;tz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1">Timo Ropinski</a></p>
<p>Deep learning in medical imaging has the potential to minimize the risk of
diagnostic errors, reduce radiologist workload, and accelerate diagnosis.
Training such deep learning models requires large and accurate datasets, with
annotations for all training samples. However, in the medical imaging domain,
annotated datasets for specific tasks are often small due to the high
complexity of annotations, limited access, or the rarity of diseases. To
address this challenge, deep learning models can be pre-trained on large image
datasets without annotations using methods from the field of self-supervised
learning. After pre-training, small annotated datasets are sufficient to
fine-tune the models for a specific task. The most popular self-supervised
pre-training approaches in medical imaging are based on contrastive learning.
However, recent studies in natural image processing indicate a strong potential
for masked autoencoder approaches. Our work compares state-of-the-art
contrastive learning methods with the recently introduced masked autoencoder
approach "SparK" for convolutional neural networks (CNNs) on medical images.
Therefore we pre-train on a large unannotated CT image dataset and fine-tune on
several CT classification tasks. Due to the challenge of obtaining sufficient
annotated training data in medical imaging, it is of particular interest to
evaluate how the self-supervised pre-training methods perform when fine-tuning
on small datasets. By experimenting with gradually reducing the training
dataset size for fine-tuning, we find that the reduction has different effects
depending on the type of pre-training chosen. The SparK pre-training method is
more robust to the training dataset size than the contrastive methods. Based on
our results, we propose the SparK pre-training for medical imaging tasks with
only small annotated datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.11809">Expressive probabilistic sampling in recurrent neural networks. (arXiv:2308.11809v2 [q-bio.NC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1">Shirui Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jiang_L/0/1/0/all/0/1">Linxin Preston Jiang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Rao_R/0/1/0/all/0/1">Rajesh P. N. Rao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shea_Brown_E/0/1/0/all/0/1">Eric Shea-Brown</a></p>
<p>In sampling-based Bayesian models of brain function, neural activities are
assumed to be samples from probability distributions that the brain uses for
probabilistic computation. However, a comprehensive understanding of how
mechanistic models of neural dynamics can sample from arbitrary distributions
is still lacking. We use tools from functional analysis and stochastic
differential equations to explore the minimum architectural requirements for
$\textit{recurrent}$ neural circuits to sample from complex distributions. We
first consider the traditional sampling model consisting of a network of
neurons whose outputs directly represent the samples (sampler-only network). We
argue that synaptic current and firing-rate dynamics in the traditional model
have limited capacity to sample from a complex probability distribution. We
show that the firing rate dynamics of a recurrent neural circuit with a
separate set of output units can sample from an arbitrary probability
distribution. We call such circuits reservoir-sampler networks (RSNs). We
propose an efficient training procedure based on denoising score matching that
finds recurrent and output weights such that the RSN implements Langevin
sampling. We empirically demonstrate our model's ability to sample from several
complex data distributions using the proposed neural dynamics and discuss its
applicability to developing the next generation of sampling-based brain models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.16741">Socratis: Are large multimodal models emotionally aware?. (arXiv:2308.16741v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Katherine Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1">Arijit Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_R/0/1/0/all/0/1">Reuben Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabriel_S/0/1/0/all/0/1">Saadia Gabriel</a>, <a href="http://arxiv.org/find/cs/1/au:+Plummer_B/0/1/0/all/0/1">Bryan A. Plummer</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a></p>
<p>Existing emotion prediction benchmarks contain coarse emotion labels which do
not consider the diversity of emotions that an image and text can elicit in
humans due to various reasons. Learning diverse reactions to multimodal content
is important as intelligent machines take a central role in generating and
delivering content to society. To address this gap, we propose Socratis, a
societal reactions benchmark, where each image-caption (IC) pair is annotated
with multiple emotions and the reasons for feeling them. Socratis contains 18K
free-form reactions for 980 emotions on 2075 image-caption pairs from 5
widely-read news and image-caption (IC) datasets. We benchmark the capability
of state-of-the-art multimodal large language models to generate the reasons
for feeling an emotion given an IC pair. Based on a preliminary human study, we
observe that humans prefer human-written reasons over 2 times more often than
machine-generated ones. This shows our task is harder than standard generation
tasks because it starkly contrasts recent findings where humans cannot tell
apart machine vs human-written news articles, for instance. We further see that
current captioning metrics based on large vision-language models also fail to
correlate with human preferences. We hope that these findings and our benchmark
will inspire further research on training emotionally aware models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.01267">Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy. (arXiv:2309.01267v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Haimin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zixu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakamura_K/0/1/0/all/0/1">Kensuke Nakamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bajcsy_A/0/1/0/all/0/1">Andrea Bajcsy</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisac_J/0/1/0/all/0/1">Jaime F. Fisac</a></p>
<p>An outstanding challenge for the widespread deployment of robotic systems
like autonomous vehicles is ensuring safe interaction with humans without
sacrificing performance. Existing safety methods often neglect the robot's
ability to learn and adapt at runtime, leading to overly conservative behavior.
This paper proposes a new closed-loop paradigm for synthesizing safe control
policies that explicitly account for the robot's evolving uncertainty and its
ability to quickly respond to future scenarios as they arise, by jointly
considering the physical dynamics and the robot's learning algorithm. We
leverage adversarial reinforcement learning for tractable safety analysis under
high-dimensional learning dynamics and demonstrate our framework's ability to
work with both Bayesian belief propagation and implicit learning through large
pre-trained neural trajectory predictors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.04316">Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models. (arXiv:2309.04316v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barmann_L/0/1/0/all/0/1">Leonard B&#xe4;rmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kartmann_R/0/1/0/all/0/1">Rainer Kartmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Peller_Konrad_F/0/1/0/all/0/1">Fabian Peller-Konrad</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alex Waibel</a>, <a href="http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1">Tamim Asfour</a></p>
<p>Natural-language dialog is key for intuitive human-robot interaction. It can
be used not only to express humans' intents, but also to communicate
instructions for improvement if a robot does not understand a command
correctly. Of great importance is to endow robots with the ability to learn
from such interaction experience in an incremental way to allow them to improve
their behaviors or avoid mistakes in the future. In this paper, we propose a
system to achieve incremental learning of complex behavior from natural
interaction, and demonstrate its implementation on a humanoid robot. Building
on recent advances, we present a system that deploys Large Language Models
(LLMs) for high-level orchestration of the robot's behavior, based on the idea
of enabling the LLM to generate Python statements in an interactive console to
invoke both robot perception and action. The interaction loop is closed by
feeding back human instructions, environment observations, and execution
results to the LLM, thus informing the generation of the next statement.
Specifically, we introduce incremental prompt learning, which enables the
system to interactively learn from its mistakes. For that purpose, the LLM can
call another LLM responsible for code-level improvements of the current
interaction based on human feedback. The improved interaction is then saved in
the robot's memory, and thus retrieved on similar requests. We integrate the
system in the robot cognitive architecture of the humanoid robot ARMAR-6 and
evaluate our methods both quantitatively (in simulation) and qualitatively (in
simulation and real-world) by demonstrating generalized incrementally-learned
knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05183">Data Summarization beyond Monotonicity: Non-monotone Two-Stage Submodular Maximization. (arXiv:2309.05183v2 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a></p>
<p>The objective of a two-stage submodular maximization problem is to reduce the
ground set using provided training functions that are submodular, with the aim
of ensuring that optimizing new objective functions over the reduced ground set
yields results comparable to those obtained over the original ground set. This
problem has applications in various domains including data summarization.
Existing studies often assume the monotonicity of the objective function,
whereas our work pioneers the extension of this research to accommodate
non-monotone submodular functions. We have introduced the first constant-factor
approximation algorithms for this more general case.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12177">Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey. (arXiv:2309.12177v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyelere_S/0/1/0/all/0/1">Solomon Sunday Oyelere</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1">Sadiq Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Calixto_R/0/1/0/all/0/1">Rene Ripardo Calixto</a>, <a href="http://arxiv.org/find/cs/1/au:+Albuquerque_V/0/1/0/all/0/1">Victor Hugo C. de Albuquerque</a>, <a href="http://arxiv.org/find/cs/1/au:+Roshanzamir_M/0/1/0/all/0/1">Mohamad Roshanzamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahouti_M/0/1/0/all/0/1">Mohamed Rahouti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagatheesaperumal_S/0/1/0/all/0/1">Senthil Kumar Jagatheesaperumal</a></p>
<p>The field of drug discovery has experienced a remarkable transformation with
the advent of artificial intelligence (AI) and machine learning (ML)
technologies. However, as these AI and ML models are becoming more complex,
there is a growing need for transparency and interpretability of the models.
Explainable Artificial Intelligence (XAI) is a novel approach that addresses
this issue and provides a more interpretable understanding of the predictions
made by machine learning models. In recent years, there has been an increasing
interest in the application of XAI techniques to drug discovery. This review
article provides a comprehensive overview of the current state-of-the-art in
XAI for drug discovery, including various XAI methods, their application in
drug discovery, and the challenges and limitations of XAI techniques in drug
discovery. The article also covers the application of XAI in drug discovery,
including target identification, compound design, and toxicity prediction.
Furthermore, the article suggests potential future research directions for the
application of XAI in drug discovery. The aim of this review article is to
provide a comprehensive understanding of the current state of XAI in drug
discovery and its potential to transform the field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13744">A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly. (arXiv:2309.13744v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Salunkhe_O/0/1/0/all/0/1">Omkar Salunkhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Quadrini_W/0/1/0/all/0/1">Walter Quadrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansson_B/0/1/0/all/0/1">Bj&#xf6;rn Johansson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamkull_D/0/1/0/all/0/1">Dan L&#xe4;mkull</a>, <a href="http://arxiv.org/find/cs/1/au:+Ore_F/0/1/0/all/0/1">Fredrik Ore</a>, <a href="http://arxiv.org/find/cs/1/au:+Despeisse_M/0/1/0/all/0/1">M&#xe9;lanie Despeisse</a>, <a href="http://arxiv.org/find/cs/1/au:+Fumagalli_L/0/1/0/all/0/1">Luca Fumagalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Stahre_J/0/1/0/all/0/1">Johan Stahre</a></p>
<p>This article presents a systematic literature review on computer vision
applications that have been proposed for robotized wire harness assembly,
derives challenges from existing studies, and identifies opportunities for
future research to promote a more practical robotized assembly of wire
harnesses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13745">Computer Vision Technology for Robotized Wire Harness Assembly. (arXiv:2309.13745v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Salunkhe_O/0/1/0/all/0/1">Omkar Salunkhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Quadrini_W/0/1/0/all/0/1">Walter Quadrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamkull_D/0/1/0/all/0/1">Dan L&#xe4;mkull</a>, <a href="http://arxiv.org/find/cs/1/au:+Ore_F/0/1/0/all/0/1">Fredrik Ore</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansson_B/0/1/0/all/0/1">Bj&#xf6;rn Johansson</a>, <a href="http://arxiv.org/find/cs/1/au:+Stahre_J/0/1/0/all/0/1">Johan Stahre</a></p>
<p>Wire harnesses are essential hardware for electronic systems in modern
automotive vehicles. With a shift in the automotive industry towards
electrification and autonomous driving, more and more automotive electronics
are responsible for energy transmission and safety-critical functions such as
maneuvering, driver assistance, and safety system. This paradigm shift places
more demand on automotive wiring harnesses from the safety perspective and
stresses the greater importance of high-quality wire harness assembly in
vehicles. However, most of the current operations of wire harness assembly are
still performed manually by skilled workers, and some of the manual processes
are problematic from different perspectives, such as quality control and
ergonomics. There is also a persistent demand in the industry to increase
competitiveness and gain market share. Hence, assuring assembly quality while
improving ergonomics and optimizing labor costs is desired. Robotized assembly,
accomplished by robots or in human-robot collaboration, is a key enabler for
fulfilling the increasingly demanding quality and safety as it enables more
replicable, transparent, and comprehensible processes than completely manual
operations. However, robotized assembly of wire harnesses is challenging in
real environments due to the flexibility of the deformable objects, though many
preliminary automation solutions have been proposed under simplified industrial
configurations. Previous research efforts have proposed the use of computer
vision technology to facilitate robotized automation of wire harness assembly,
enabling the robots to better perceive and manipulate the flexible wire
harness. This article presents an overview on computer vision technology
proposed for robotized wire harness assembly and derives research gaps that
require further study to facilitate a more practical robotized assembly of wire
harness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02230">Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks. (arXiv:2310.02230v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Scimeca_L/0/1/0/all/0/1">Luca Scimeca</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_A/0/1/0/all/0/1">Alexander Rubinstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolicioiu_A/0/1/0/all/0/1">Armand Mihai Nicolicioiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a></p>
<p>Spurious correlations in the data, where multiple cues are predictive of the
target labels, often lead to shortcut learning phenomena, where a model may
rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this
work, we propose an ensemble diversification framework exploiting the
generation of synthetic counterfactuals using Diffusion Probabilistic Models
(DPMs). We discover that DPMs have the inherent capability to represent
multiple visual cues independently, even when they are largely correlated in
the training data. We leverage this characteristic to encourage model diversity
and empirically show the efficacy of the approach with respect to several
diversification objectives. We show that diffusion-guided diversification can
lead models to avert attention from shortcut cues, achieving ensemble diversity
performance comparable to previous methods requiring additional data
collection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.13018">Getting aligned on representational alignment. (arXiv:2310.13018v2 [q-bio.NC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Sucholutsky_I/0/1/0/all/0/1">Ilia Sucholutsky</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Muttenthaler_L/0/1/0/all/0/1">Lukas Muttenthaler</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Peng_A/0/1/0/all/0/1">Andi Peng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bobu_A/0/1/0/all/0/1">Andreea Bobu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kim_B/0/1/0/all/0/1">Been Kim</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Love_B/0/1/0/all/0/1">Bradley C. Love</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Grant_E/0/1/0/all/0/1">Erin Grant</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Groen_I/0/1/0/all/0/1">Iris Groen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Achterberg_J/0/1/0/all/0/1">Jascha Achterberg</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Collins_K/0/1/0/all/0/1">Katherine M. Collins</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hermann_K/0/1/0/all/0/1">Katherine L. Hermann</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Oktar_K/0/1/0/all/0/1">Kerem Oktar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Greff_K/0/1/0/all/0/1">Klaus Greff</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hebart_M/0/1/0/all/0/1">Martin N. Hebart</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jacoby_N/0/1/0/all/0/1">Nori Jacoby</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_Q/0/1/0/all/0/1">Qiuyi Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marjieh_R/0/1/0/all/0/1">Raja Marjieh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Geirhos_R/0/1/0/all/0/1">Robert Geirhos</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1">Sherol Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kornblith_S/0/1/0/all/0/1">Simon Kornblith</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Rane_S/0/1/0/all/0/1">Sunayana Rane</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Konkle_T/0/1/0/all/0/1">Talia Konkle</a>, <a href="http://arxiv.org/find/q-bio/1/au:+OConnell_T/0/1/0/all/0/1">Thomas P. O&#x27;Connell</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Unterthiner_T/0/1/0/all/0/1">Thomas Unterthiner</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lampinen_A/0/1/0/all/0/1">Andrew K. Lampinen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Muller_K/0/1/0/all/0/1">Klaus-Robert M&#xfc;ller</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Toneva_M/0/1/0/all/0/1">Mariya Toneva</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a></p>
<p>Biological and artificial information processing systems form representations
that they can use to categorize, reason, plan, navigate, and make decisions.
How can we measure the extent to which the representations formed by these
diverse systems agree? Do similarities in representations then translate into
similar behavior? How can a system's representations be modified to better
match those of another system? These questions pertaining to the study of
representational alignment are at the heart of some of the most active research
areas in cognitive science, neuroscience, and machine learning. For example,
cognitive scientists measure the representational alignment of multiple
individuals to identify shared cognitive priors, neuroscientists align fMRI
responses from multiple individuals into a shared representational space for
group-level analyses, and ML researchers distill knowledge from teacher models
into student models by increasing their alignment. Unfortunately, there is
limited knowledge transfer between research communities interested in
representational alignment, so progress in one field often ends up being
rediscovered independently in another. Thus, greater cross-field communication
would be advantageous. To improve communication between these fields, we
propose a unifying framework that can serve as a common language between
researchers studying representational alignment. We survey the literature from
all three fields and demonstrate how prior work fits into this framework.
Finally, we lay out open problems in representational alignment where progress
can benefit all three of these fields. We hope that our work can catalyze
cross-disciplinary collaboration and accelerate progress for all communities
studying and developing information processing systems. We note that this is a
working paper and encourage readers to reach out with their suggestions for
future revisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.17490">Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering. (arXiv:2310.17490v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Sukmin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1">Jeongyeon Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1">Soyeong Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jong C. Park</a></p>
<p>Large language models (LLMs) enable zero-shot approaches in open-domain
question answering (ODQA), yet with limited advancements as the reader is
compared to the retriever. This study aims at the feasibility of a zero-shot
reader that addresses the challenges of computational cost and the need for
labeled data. We find that LLMs are distracted due to irrelevant documents in
the retrieved set and the overconfidence of the generated answers when they are
exploited as zero-shot readers. To tackle these problems, we mitigate the
impact of such documents via Distraction-aware Answer Selection (DAS) with a
negation-based instruction and score adjustment for proper answer selection.
Experimental results show that our approach successfully handles distraction
across diverse scenarios, enhancing the performance of zero-shot readers.
Furthermore, unlike supervised readers struggling with unseen data, zero-shot
readers demonstrate outstanding transferability without any training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18301">Interactive Motion Planning for Autonomous Vehicles with Joint Optimization. (arXiv:2310.18301v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Veer_S/0/1/0/all/0/1">Sushant Veer</a>, <a href="http://arxiv.org/find/cs/1/au:+Karkus_P/0/1/0/all/0/1">Peter Karkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a></p>
<p>In highly interactive driving scenarios, the actions of one agent greatly
influences those of its neighbors. Planning safe motions for autonomous
vehicles in such interactive environments, therefore, requires reasoning about
the impact of the ego's intended motion plan on nearby agents' behavior.
Deep-learning-based models have recently achieved great success in trajectory
prediction and many models in the literature allow for ego-conditioned
prediction. However, leveraging ego-conditioned prediction remains challenging
in downstream planning due to the complex nature of neural networks, limiting
the planner structure to simple ones, e.g., sampling-based planner. Despite
their ability to generate fine-grained high-quality motion plans, it is
difficult for gradient-based planning algorithms, such as model predictive
control (MPC), to leverage ego-conditioned prediction due to their iterative
nature and need for gradient. We present Interactive Joint Planning (IJP) that
bridges MPC with learned prediction models in a computationally scalable manner
to provide us the best of both the worlds. In particular, IJP jointly optimizes
over the behavior of the ego and the surrounding agents and leverages
deep-learned prediction models as prediction priors that the join trajectory
optimization tries to stay close to. Furthermore, by leveraging homotopy
classes, our joint optimizer searches over diverse motion plans to avoid
getting stuck at local minima. Closed-loop simulation result shows that IJP
significantly outperforms the baselines that are either without joint
optimization or running sampling-based planning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18348">Meaning Representations from Trajectories in Autoregressive Models. (arXiv:2310.18348v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tian Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Trager_M/0/1/0/all/0/1">Matthew Trager</a>, <a href="http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1">Alessandro Achille</a>, <a href="http://arxiv.org/find/cs/1/au:+Perera_P/0/1/0/all/0/1">Pramuditha Perera</a>, <a href="http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1">Luca Zancato</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a></p>
<p>We propose to extract meaning representations from autoregressive language
models by considering the distribution of all possible trajectories extending
an input text. This strategy is prompt-free, does not require fine-tuning, and
is applicable to any pre-trained autoregressive model. Moreover, unlike
vector-based representations, distribution-based representations can also model
asymmetric relations (e.g., direction of logical entailment, hypernym/hyponym
relations) by using algebraic operations between likelihood functions. These
ideas are grounded in distributional perspectives on semantics and are
connected to standard constructions in automata theory, but to our knowledge
they have not been applied to modern language models. We empirically show that
the representations obtained from large models align well with human
annotations, outperform other zero-shot and prompt-free methods on semantic
similarity tasks, and can be used to solve more complex entailment and
containment tasks that standard embeddings cannot handle. Finally, we extend
our method to represent data from different modalities (e.g., image and text)
using multimodal autoregressive models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.20280">AutoMixer for Improved Multivariate Time-Series Forecasting on Business and IT Observability Data. (arXiv:2310.20280v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Palaskar_S/0/1/0/all/0/1">Santosh Palaskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekambaram_V/0/1/0/all/0/1">Vijay Ekambaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Jati_A/0/1/0/all/0/1">Arindam Jati</a>, <a href="http://arxiv.org/find/cs/1/au:+Gantayat_N/0/1/0/all/0/1">Neelamadhav Gantayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1">Avirup Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagar_S/0/1/0/all/0/1">Seema Nagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Nam H. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dayama_P/0/1/0/all/0/1">Pankaj Dayama</a>, <a href="http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1">Renuka Sindhgatta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohapatra_P/0/1/0/all/0/1">Prateeti Mohapatra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_H/0/1/0/all/0/1">Harshit Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalagnanam_J/0/1/0/all/0/1">Jayant Kalagnanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemachandra_N/0/1/0/all/0/1">Nandyala Hemachandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Rangaraj_N/0/1/0/all/0/1">Narayan Rangaraj</a></p>
<p>The efficiency of business processes relies on business key performance
indicators (Biz-KPIs), that can be negatively impacted by IT failures. Business
and IT Observability (BizITObs) data fuses both Biz-KPIs and IT event channels
together as multivariate time series data. Forecasting Biz-KPIs in advance can
enhance efficiency and revenue through proactive corrective measures. However,
BizITObs data generally exhibit both useful and noisy inter-channel
interactions between Biz-KPIs and IT events that need to be effectively
decoupled. This leads to suboptimal forecasting performance when existing
multivariate forecasting models are employed. To address this, we introduce
AutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel
technique of channel-compressed pretrain and finetune workflows. AutoMixer
leverages an AutoEncoder for channel-compressed pretraining and integrates it
with the advanced TSMixer model for multivariate time series forecasting. This
fusion greatly enhances the potency of TSMixer for accurate forecasts and also
generalizes well across several downstream tasks. Through detailed experiments
and dashboard analytics, we show AutoMixer's capability to consistently improve
the Biz-KPI's forecasting accuracy (by 11-15\%) which directly translates to
actionable business insights.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00286">JADE: A Linguistics-based Safety Evaluation Platform for LLM. (arXiv:2311.00286v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xudong Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Min Yang</a></p>
<p>In this paper, we present JADE, a targeted linguistic fuzzing platform which
strengthens the linguistic complexity of seed questions to simultaneously and
consistently break a wide range of widely-used LLMs categorized in three
groups: eight open-sourced Chinese, six commercial Chinese and four commercial
English LLMs. JADE generates three safety benchmarks for the three groups of
LLMs, which contain unsafe questions that are highly threatening: the questions
simultaneously trigger harmful generation of multiple LLMs, with an average
unsafe generation ratio of $70\%$ (please see the table below), while are still
natural questions, fluent and preserving the core unsafe semantics. We release
the benchmark demos generated for commercial English LLMs and open-sourced
English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For
readers who are interested in evaluating on more questions generated by JADE,
please contact us.
</p>
<p>JADE is based on Noam Chomsky's seminal theory of transformational-generative
grammar. Given a seed question with unsafe intention, JADE invokes a sequence
of generative and transformational rules to increment the complexity of the
syntactic structure of the original question, until the safety guardrail is
broken. Our key insight is: Due to the complexity of human language, most of
the current best LLMs can hardly recognize the invariant evil from the infinite
number of different syntactic structures which form an unbound example space
that can never be fully covered. Technically, the generative/transformative
rules are constructed by native speakers of the languages, and, once developed,
can be used to automatically grow and transform the parse tree of a given
question, until the guardrail is broken. For more evaluation results and demo,
please check our website: https://whitzard-ai.github.io/jade.html.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00344">A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents. (arXiv:2311.00344v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sigaud_O/0/1/0/all/0/1">Olivier Sigaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldassarre_G/0/1/0/all/0/1">Gianluca Baldassarre</a>, <a href="http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1">Cedric Colas</a>, <a href="http://arxiv.org/find/cs/1/au:+Doncieux_S/0/1/0/all/0/1">Stephane Doncieux</a>, <a href="http://arxiv.org/find/cs/1/au:+Duro_R/0/1/0/all/0/1">Richard Duro</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrin_Gilbert_N/0/1/0/all/0/1">Nicolas Perrin-Gilbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Santucci_V/0/1/0/all/0/1">Vieri Giuliano Santucci</a></p>
<p>A lot of recent machine learning research papers have "Open-ended learning"
in their title. But very few of them attempt to define what they mean when
using the term. Even worse, when looking more closely there seems to be no
consensus on what distinguishes open-ended learning from related concepts such
as continual learning, lifelong learning or autotelic learning. In this paper,
we contribute to fixing this situation. After illustrating the genealogy of the
concept and more recent perspectives about what it truly means, we outline that
open-ended learning is generally conceived as a composite notion encompassing a
set of diverse properties. In contrast with these previous approaches, we
propose to isolate a key elementary property of open-ended processes, which is
to always produce novel elements from time to time over an infinite horizon.
From there, we build the notion of open-ended learning problems and focus in
particular on the subset of open-ended goal-conditioned reinforcement learning
problems, as this framework facilitates the definition of learning a growing
repertoire of skills. Finally, we highlight the work that remains to be
performed to fill the gap between our elementary definition and the more
involved notions of open-ended learning that developmental AI researchers may
have in mind.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00462">Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design. (arXiv:2311.00462v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Heng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a></p>
<p>Multi-cellular robot design aims to create robots comprised of numerous cells
that can be efficiently controlled to perform diverse tasks. Previous research
has demonstrated the ability to generate robots for various tasks, but these
approaches often optimize robots directly in the vast design space, resulting
in robots with complicated morphologies that are hard to control. In response,
this paper presents a novel coarse-to-fine method for designing multi-cellular
robots. Initially, this strategy seeks optimal coarse-grained robots and
progressively refines them. To mitigate the challenge of determining the
precise refinement juncture during the coarse-to-fine transition, we introduce
the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies
robots of various granularity within a shared hyperbolic space and leverages a
refined Cross-Entropy Method for optimization. This framework enables our
method to autonomously identify areas of exploration in hyperbolic space and
concentrate on regions demonstrating promise. Finally, the extensive empirical
studies on various challenging tasks sourced from EvoGym show our approach's
superior efficiency and generalization capability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00582">Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value. (arXiv:2311.00582v2 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Young Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+McMahan_J/0/1/0/all/0/1">Jeremy McMahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiding Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yudong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaojin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1">Qiaomin Xie</a></p>
<p>We study the game modification problem, where a benevolent game designer or a
malevolent adversary modifies the reward function of a zero-sum Markov game so
that a target deterministic or stochastic policy profile becomes the unique
Markov perfect Nash equilibrium and has a value within a target range, in a way
that minimizes the modification cost. We characterize the set of policy
profiles that can be installed as the unique equilibrium of some game, and
establish sufficient and necessary conditions for successful installation. We
propose an efficient algorithm, which solves a convex optimization problem with
linear constraints and then performs random perturbation, to obtain a
modification plan with a near-optimal cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00651">Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning. (arXiv:2311.00651v2 [cs.MA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bornemann_R/0/1/0/all/0/1">Richard Bornemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamon_G/0/1/0/all/0/1">Gautier Hamon</a>, <a href="http://arxiv.org/find/cs/1/au:+Nisioti_E/0/1/0/all/0/1">Eleni Nisioti</a>, <a href="http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1">Cl&#xe9;ment Moulin-Frier</a></p>
<p>Recent works have proven that intricate cooperative behaviors can emerge in
agents trained using meta reinforcement learning on open ended task
distributions using self-play. While the results are impressive, we argue that
self-play and other centralized training techniques do not accurately reflect
how general collective exploration strategies emerge in the natural world:
through decentralized training and over an open-ended distribution of tasks. In
this work we therefore investigate the emergence of collective exploration
strategies, where several agents meta-learn independent recurrent policies on
an open ended distribution of tasks. To this end we introduce a novel
environment with an open ended procedurally generated task space which
dynamically combines multiple subtasks sampled from five diverse task types to
form a vast distribution of task trees. We show that decentralized agents
trained in our environment exhibit strong generalization abilities when
confronted with novel objects at test time. Additionally, despite never being
forced to cooperate during training the agents learn collective exploration
strategies which allow them to solve novel tasks never encountered during
training. We further find that the agents learned collective exploration
strategies extend to an open ended task setting, allowing them to solve task
trees of twice the depth compared to the ones seen during training. Our open
source code as well as videos of the agents can be found on our companion
website.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.14691">Identifiability of total effects from abstractions of time series causal graphs. (arXiv:2310.14691v2 [math.ST] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Assaad_C/0/1/0/all/0/1">Charles K. Assaad</a>, <a href="http://arxiv.org/find/math/1/au:+Devijver_E/0/1/0/all/0/1">Emilie Devijver</a> (LIG, UGA), <a href="http://arxiv.org/find/math/1/au:+Gaussier_E/0/1/0/all/0/1">Eric Gaussier</a> (LIG, UGA), <a href="http://arxiv.org/find/math/1/au:+Gossler_G/0/1/0/all/0/1">Gregor G&#xf6;ssler</a> (LIG, SPADES), <a href="http://arxiv.org/find/math/1/au:+Meynaoui_A/0/1/0/all/0/1">Anouar Meynaoui</a> (IRMAR, UR2)</p>
<p>We study the problem of identifiability of the total effect of an
intervention from observational time series only given an abstraction of the
causal graph of the system. Specifically, we consider two types of
abstractions: the extended summary causal graph which conflates all lagged
causal relations but distinguishes between lagged and instantaneous relations;
and the summary causal graph which does not give any indication about the lag
between causal relations. We show that the total effect is always identifiable
in extended summary causal graphs and we provide necessary and sufficient
graphical conditions for identifiability in summary causal graphs. Furthermore,
we provide adjustment sets allowing to estimate the total effect whenever it is
identifiable.
</p>
</p>
</div>

    </div>
    </body>
    