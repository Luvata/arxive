<!DOCTYPE html>
<html>
<head>
<title>2024-01-12-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.04810">Translate-Distill: Learning Cross-Language Dense Retrieval by Translation and Distillation. (arXiv:2401.04810v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eugene Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawrie_D/0/1/0/all/0/1">Dawn Lawrie</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayfield_J/0/1/0/all/0/1">James Mayfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1">Douglas W. Oard</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_S/0/1/0/all/0/1">Scott Miller</a></p>
<p>Prior work on English monolingual retrieval has shown that a cross-encoder
trained using a large number of relevance judgments for query-document pairs
can be used as a teacher to train more efficient, but similarly effective,
dual-encoder student models. Applying a similar knowledge distillation approach
to training an efficient dual-encoder model for Cross-Language Information
Retrieval (CLIR), where queries and documents are in different languages, is
challenging due to the lack of a sufficiently large training collection when
the query and document languages differ. The state of the art for CLIR thus
relies on translating queries, documents, or both from the large English MS
MARCO training set, an approach called Translate-Train. This paper proposes an
alternative, Translate-Distill, in which knowledge distillation from either a
monolingual cross-encoder or a CLIR cross-encoder is used to train a
dual-encoder CLIR student model. This richer design space enables the teacher
model to perform inference in an optimized setting, while training the student
model directly for CLIR. Trained models and artifacts are publicly available on
Huggingface.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04821">MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer. (arXiv:2401.04821v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Haotian Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yihong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chunlan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a></p>
<p>Transformer-based pre-trained language models (PLMs) have achieved remarkable
performance in various natural language processing (NLP) tasks. However,
pre-training such models can take considerable resources that are almost only
available to high-resource languages. On the contrary, static word embeddings
are easier to train in terms of computing resources and the amount of data
required. In this paper, we introduce MoSECroT Model Stitching with Static Word
Embeddings for Crosslingual Zero-shot Transfer), a novel and challenging task
that is especially relevant to low-resource languages for which static word
embeddings are available. To tackle the task, we present the first framework
that leverages relative representations to construct a common space for the
embeddings of a source language PLM and the static word embeddings of a target
language. In this way, we can train the PLM on source-language training data
and perform zero-shot transfer to the target language by simply swapping the
embedding layer. However, through extensive experiments on two classification
datasets, we show that although our proposed framework is competitive with weak
baselines when addressing MoSECroT, it fails to achieve competitive results
compared with some strong baselines. In this paper, we attempt to explain this
negative result and provide several thoughts on possible improvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04848">Arabic Text Diacritization In The Age Of Transfer Learning: Token Classification Is All You Need. (arXiv:2401.04848v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Skiredj_A/0/1/0/all/0/1">Abderrahman Skiredj</a>, <a href="http://arxiv.org/find/cs/1/au:+Berrada_I/0/1/0/all/0/1">Ismail Berrada</a></p>
<p>Automatic diacritization of Arabic text involves adding diacritical marks
(diacritics) to the text. This task poses a significant challenge with
noteworthy implications for computational processing and comprehension. In this
paper, we introduce PTCAD (Pre-FineTuned Token Classification for Arabic
Diacritization, a novel two-phase approach for the Arabic Text Diacritization
task. PTCAD comprises a pre-finetuning phase and a finetuning phase, treating
Arabic Text Diacritization as a token classification task for pre-trained
models. The effectiveness of PTCAD is demonstrated through evaluations on two
benchmark datasets derived from the Tashkeela dataset, where it achieves
state-of-the-art results, including a 20\% reduction in Word Error Rate (WER)
compared to existing benchmarks and superior performance over GPT-4 in ATD
tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04853">Entity Recognition from Colloquial Text. (arXiv:2401.04853v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Babaian_T/0/1/0/all/0/1">Tamara Babaian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jennifer Xu</a></p>
<p>Extraction of concepts and entities of interest from non-formal texts such as
social media posts and informal communication is an important capability for
decision support systems in many domains, including healthcare, customer
relationship management, and others. Despite the recent advances in training
large language models for a variety of natural language processing tasks, the
developed models and techniques have mainly focused on formal texts and do not
perform as well on colloquial data, which is characterized by a number of
distinct challenges. In our research, we focus on the healthcare domain and
investigate the problem of symptom recognition from colloquial texts by
designing and evaluating several training strategies for BERT-based model
fine-tuning. These strategies are distinguished by the choice of the base
model, the training corpora, and application of term perturbations in the
training data. The best-performing models trained using these strategies
outperform the state-of-the-art specialized symptom recognizer by a large
margin. Through a series of experiments, we have found specific patterns of
model behavior associated with the training strategies we designed. We present
design principles for training strategies for effective entity recognition in
colloquial texts based on our findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04854">Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs. (arXiv:2401.04854v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lederman_H/0/1/0/all/0/1">Harvey Lederman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1">Kyle Mahowald</a></p>
<p>Are LLMs cultural technologies like photocopiers or printing presses, which
transmit information but cannot create new content? A challenge for this idea,
which we call bibliotechnism, is that LLMs often do generate entirely novel
text. We begin by defending bibliotechnism against this challenge, showing how
novel text may be meaningful only in a derivative sense, so that the content of
this generated text depends in an important sense on the content of original
human text. We go on to present a different, novel challenge for
bibliotechnism, stemming from examples in which LLMs generate "novel
reference", using novel names to refer to novel entities. Such examples could
be smoothly explained if LLMs were not cultural technologies but possessed a
limited form of agency (beliefs, desires, and intentions). According to
interpretationism in the philosophy of mind, a system has beliefs, desires and
intentions if and only if its behavior is well-explained by the hypothesis that
it has such states. In line with this view, we argue that cases of novel
reference provide evidence that LLMs do in fact have beliefs, desires, and
intentions, and thus have a limited form of agency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04858">User Embedding Model for Personalized Language Prompting. (arXiv:2401.04858v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1">Sumanth Doddapaneni</a>, <a href="http://arxiv.org/find/cs/1/au:+Sayana_K/0/1/0/all/0/1">Krishna Sayana</a>, <a href="http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1">Ambarish Jash</a>, <a href="http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1">Sukhdeep Sodhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1">Dima Kuzmin</a></p>
<p>Modeling long histories plays a pivotal role in enhancing recommendation
systems, allowing to capture user's evolving preferences, resulting in more
precise and personalized recommendations. In this study we tackle the
challenges of modeling long user histories for preference understanding in
natural language. Specifically, we introduce a new User Embedding Module (UEM)
that efficiently processes user history in free-form text by compressing and
representing them as embeddings, to use them as soft prompts to a LM. Our
experiments demonstrate the superior capability of this approach in handling
significantly longer histories compared to conventional text based prompting
methods, yielding substantial improvements in predictive performance. The main
contribution of this research is to demonstrate the ability to bias language
models with user signals represented as embeddings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04867">An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems. (arXiv:2401.04867v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Koji Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Lala_D/0/1/0/all/0/1">Divesh Lala</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochi_K/0/1/0/all/0/1">Keiko Ochi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1">Tatsuya Kawahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Skantze_G/0/1/0/all/0/1">Gabriel Skantze</a></p>
<p>Establishing evaluation schemes for spoken dialogue systems is important, but
it can also be challenging. While subjective evaluations are commonly used in
user experiments, objective evaluations are necessary for research comparison
and reproducibility. To address this issue, we propose a framework for
indirectly but objectively evaluating systems based on users' behaviours. In
this paper, to this end, we investigate the relationship between user
behaviours and subjective evaluation scores in social dialogue tasks: attentive
listening, job interview, and first-meeting conversation. The results reveal
that in dialogue tasks where user utterances are primary, such as attentive
listening and job interview, indicators like the number of utterances and words
play a significant role in evaluation. Observing disfluency also can indicate
the effectiveness of formal tasks, such as job interview. On the other hand, in
dialogue tasks with high interactivity, such as first-meeting conversation,
behaviours related to turn-taking, like average switch pause length, become
more important. These findings suggest that selecting appropriate user
behaviours can provide valuable insights for objective evaluation in each
social dialogue task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04868">Real-time and Continuous Turn-taking Prediction Using Voice Activity Projection. (arXiv:2401.04868v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Koji Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bing&#x27;er Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekstedt_E/0/1/0/all/0/1">Erik Ekstedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1">Tatsuya Kawahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Skantze_G/0/1/0/all/0/1">Gabriel Skantze</a></p>
<p>A demonstration of a real-time and continuous turn-taking prediction system
is presented. The system is based on a voice activity projection (VAP) model,
which directly maps dialogue stereo audio to future voice activities. The VAP
model includes contrastive predictive coding (CPC) and self-attention
transformers, followed by a cross-attention transformer. We examine the effect
of the input context audio length and demonstrate that the proposed system can
operate in real-time with CPU settings, with minimal performance degradation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04881">Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing. (arXiv:2401.04881v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_N/0/1/0/all/0/1">Nan Hua</a></p>
<p>As LLMs have become capable of processing more complex types of inputs,
researchers have recently studied how to efficiently and affordably process
possibly arbitrarily long sequences. One effective approach is to use a FIFO
memory to store keys and values of an attention sublayer from past chunks to
allow subsequent queries to attend. However, this approach requires a large
memory and/or takes into the consideration the specific LM architecture.
Moreover, due to the causal nature between the key-values in prior context and
the queries at present, this approach cannot be extended to bidirectional
attention such as in an encoder-decoder or PrefixLM decoder-only architecture.
In this paper, we propose to use eviction policies, such as LRA and LFA, to
reduce the memory size and adapt to various architectures, and we also propose
the Attendre layer, a wait-to-attend mechanism by retrieving the key-value
memory (K/V memory) with evicted queries in the query memory (Q memory). As a
first step, we evaluate this method in the context length extension setup using
the TriviaQA reading comprehension task, and show the effectiveness of the
approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04883">Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate Group Conversations. (arXiv:2401.04883v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mao_M/0/1/0/all/0/1">Manqing Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_P/0/1/0/all/0/1">Paishun Ting</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yijian Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Julia Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jianzhe Lin</a></p>
<p>Recent advancements in large language models (LLMs) have provided a new
avenue for chatbot development, while most existing research has primarily
centered on single-user chatbots that focus on deciding "What" to answer after
user inputs. In this paper, we identified that multi-user chatbots have more
complex 3W design dimensions -- "What" to say, "When" to respond, and "Who" to
answer. Additionally, we proposed Multi-User Chat Assistant (MUCA), which is an
LLM-based framework for chatbots specifically designed for group discussions.
MUCA consists of three main modules: Sub-topic Generator, Dialog Analyzer, and
Utterance Strategies Arbitrator. These modules jointly determine suitable
response contents, timings, and the appropriate recipients. To make the
optimizing process for MUCA easier, we further propose an LLM-based Multi-User
Simulator (MUS) that can mimic real user behavior. This enables faster
simulation of a conversation between the chatbot and simulated users, making
the early development of the chatbot framework much more efficient. MUCA
demonstrates effectiveness, including appropriate chime-in timing, relevant
content, and positive user engagement, in goal-oriented conversations with a
small to medium number of participants, as evidenced by case studies and
experimental results from user studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04898">ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain. (arXiv:2401.04898v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bingchao Wang</a></p>
<p>Recently, various Large Language Models (LLMs) evaluation datasets have
emerged, but most of them have issues with distorted rankings and difficulty in
model capabilities analysis. Addressing these concerns, this paper introduces
ANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes
\textit{Keypoint} categorization standard for the first time, each question in
ANGO can correspond to multiple keypoints, effectively enhancing
interpretability of evaluation results. Base on performance of real humans, we
build a quantifiable question difficulty standard and divide ANGO questions
into 9 difficulty levels, which provide more precise guidance for model
training. To minimize data leakage impact and fully leverage ANGO's innovative
features, we have engineered exclusive sampling strategies and a new evaluation
framework that support swift testset iteration. Our experiments demonstrate
that ANGO poses a stronger challenge to models and reveals more details in
evaluation result compared to existing benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04925">The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Mingyu Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qinkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+shu_D/0/1/0/all/0/1">Dong shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haiyan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wenyue Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yanda Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Mengnan Du</a></p>
<p>Chain of Thought (CoT) is significant in improving the reasoning abilities of
large language models (LLMs). However, the correlation between the
effectiveness of CoT and the length of reasoning steps in prompts remains
largely unknown. To shed light on this, we have conducted several empirical
experiments to explore the relations. Specifically, we design experiments that
expand and compress the rationale reasoning steps within CoT demonstrations,
while keeping all other factors constant. We have the following key findings.
First, the results indicate that lengthening the reasoning steps in prompts,
even without adding new information into the prompt, considerably enhances
LLMs' reasoning abilities across multiple datasets. Alternatively, shortening
the reasoning steps, even while preserving the key information, significantly
diminishes the reasoning abilities of models. This finding highlights the
importance of the number of steps in CoT prompts and provides practical
guidance to make better use of LLMs' potential in complex problem-solving
scenarios. Second, we also investigated the relationship between the
performance of CoT and the rationales used in demonstrations. Surprisingly, the
result shows that even incorrect rationales can yield favorable outcomes if
they maintain the requisite length of inference. Third, we observed that the
advantages of increasing reasoning steps are task-dependent: simpler tasks
require fewer steps, whereas complex tasks gain significantly from longer
inference sequences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04935">Learning Audio Concepts from Counterfactual Natural Language. (arXiv:2401.04935v1 [cs.MM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vosoughi_A/0/1/0/all/0/1">Ali Vosoughi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bondi_L/0/1/0/all/0/1">Luca Bondi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Ho-Hsiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenliang Xu</a></p>
<p>Conventional audio classification relied on predefined classes, lacking the
ability to learn from free-form text. Recent methods unlock learning joint
audio-text embeddings from raw audio-text pairs describing audio in natural
language. Despite recent advancements, there is little exploration of
systematic methods to train models for recognizing sound events and sources in
alternative scenarios, such as distinguishing fireworks from gunshots at
outdoor events in similar situations. This study introduces causal reasoning
and counterfactual analysis in the audio domain. We use counterfactual
instances and include them in our model across different aspects. Our model
considers acoustic characteristics and sound source information from
human-annotated reference texts. To validate the effectiveness of our model, we
conducted pre-training utilizing multiple audio captioning datasets. We then
evaluate with several common downstream tasks, demonstrating the merits of the
proposed method as one of the first works leveraging counterfactual information
in audio domain. Specifically, the top-1 accuracy in open-ended language-based
audio retrieval task increased by more than 43%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04952">Can AI Write Classical Chinese Poetry like Humans? An Empirical Study Inspired by Turing Test. (arXiv:2401.04952v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zekun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a></p>
<p>Some argue that the essence of humanity, such as creativity and sentiment,
can never be mimicked by machines. This paper casts doubt on this belief by
studying a vital question: Can AI compose poetry as well as humans? To answer
the question, we propose ProFTAP, a novel evaluation framework inspired by
Turing test to assess AI's poetry writing capability. We apply it on current
large language models (LLMs) and find that recent LLMs do indeed possess the
ability to write classical Chinese poems nearly indistinguishable from those of
humans. We also reveal that various open-source LLMs can outperform GPT-4 on
this task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04972">Whose wife is it anyway? Assessing bias against same-gender relationships in machine translation. (arXiv:2401.04972v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stewart_I/0/1/0/all/0/1">Ian Stewart</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a></p>
<p>Machine translation often suffers from biased data and algorithms that can
lead to unacceptable errors in system output. While bias in gender norms has
been investigated, less is known about whether MT systems encode bias about
social relationships, e.g. sentences such as "the lawyer kissed her wife." We
investigate the degree of bias against same-gender relationships in MT systems,
using generated template sentences drawn from several noun-gender languages
(e.g. Spanish). We find that three popular MT services consistently fail to
accurately translate sentences concerning relationships between nouns of the
same gender. The error rate varies considerably based on the context, e.g.
same-gender sentences referencing high female-representation occupations are
translated with lower accuracy. We provide this work as a case study in the
evaluation of intrinsic bias in NLP systems, with respect to social
relationships.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05033">Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk. (arXiv:2401.05033v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1">Dennis Ulmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansimov_E/0/1/0/all/0/1">Elman Mansimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kaixiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Justin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xibin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a></p>
<p>Large language models (LLMs) are powerful dialogue agents, but specializing
them towards fulfilling a specific function can be challenging. Instructing
tuning, i.e. tuning models on instruction and sample responses generated by
humans (Ouyang et al., 2022), has proven as an effective method to do so, yet
requires a number of data samples that a) might not be available or b) costly
to generate. Furthermore, this cost increases when the goal is to make the LLM
follow a specific workflow within a dialogue instead of single instructions.
Inspired by the self-play technique in reinforcement learning and the use of
LLMs to simulate human agents, we propose a more effective method for data
collection through LLMs engaging in a conversation in various roles. This
approach generates a training data via "self-talk" of LLMs that can be refined
and utilized for supervised fine-tuning. We introduce an automated way to
measure the (partial) success of a dialogue. This metric is used to filter the
generated conversational data that is fed back in LLM for training. Based on
our automated and human evaluations of conversation quality, we demonstrate
that such self-talk data improves results. In addition, we examine the various
characteristics that showcase the quality of generated dialogues and how they
can be connected to their potential utility as training data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05054">Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding. (arXiv:2401.05054v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jinnai_Y/0/1/0/all/0/1">Yuu Jinnai</a>, <a href="http://arxiv.org/find/cs/1/au:+Honda_U/0/1/0/all/0/1">Ukyo Honda</a>, <a href="http://arxiv.org/find/cs/1/au:+Morimura_T/0/1/0/all/0/1">Tetsuro Morimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peinan Zhang</a></p>
<p>One of the most important challenges in text generation systems is to produce
outputs that are not only correct but also diverse. Recently, Minimum
Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the
highest quality among the decoding algorithms. However, existing algorithms
proposed for generating diverse outputs are predominantly based on beam search
or random sampling, thus their output quality is capped by these underlying
methods. In this paper, we investigate an alternative approach -- we develop
diversity-promoting decoding algorithms by enforcing diversity objectives to
MBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and
$k$-medoids MBR (KMBR), methods to generate a set of sentences with high
quality and diversity. We evaluate DMBR and KMBR on a variety of directed text
generation tasks using encoder-decoder models and a large language model with
prompting. The experimental results show that the proposed method achieves a
better trade-off than the diverse beam search and sampling algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05060">MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector. (arXiv:2401.05060v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1">Marta R. Costa-juss&#xe0;</a>, <a href="http://arxiv.org/find/cs/1/au:+Meglioli_M/0/1/0/all/0/1">Mariano Coria Meglioli</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrews_P/0/1/0/all/0/1">Pierre Andrews</a>, <a href="http://arxiv.org/find/cs/1/au:+Dale_D/0/1/0/all/0/1">David Dale</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansanti_P/0/1/0/all/0/1">Prangthip Hansanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalbassi_E/0/1/0/all/0/1">Elahe Kalbassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mourachko_A/0/1/0/all/0/1">Alex Mourachko</a>, <a href="http://arxiv.org/find/cs/1/au:+Ropers_C/0/1/0/all/0/1">Christophe Ropers</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_C/0/1/0/all/0/1">Carleigh Wood</a></p>
<p>Research in toxicity detection in natural language processing for the speech
modality (audio-based) is quite limited, particularly for languages other than
English. To address these limitations and lay the groundwork for truly
multilingual audio-based toxicity detection, we introduce MuTox, the first
highly multilingual audio-based dataset with toxicity labels. The dataset
comprises 20,000 audio utterances for English and Spanish, and 4,000 for the
other 19 languages. To demonstrate the quality of this dataset, we trained the
MuTox audio-based toxicity classifier, which enables zero-shot toxicity
detection across a wide range of languages. This classifier outperforms
existing text-based trainable classifiers by more than 1% AUC, while expanding
the language coverage more than tenfold. When compared to a wordlist-based
classifier that covers a similar number of languages, MuTox improves precision
and recall by approximately 2.5 times. This significant improvement underscores
the potential of MuTox in advancing the field of audio-based toxicity
detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05072">Aligning Translation-Specific Understanding to General Understanding in Large Language Models. (arXiv:2401.05072v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yichong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xiaocheng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baohang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chengpeng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_W/0/1/0/all/0/1">Wenshuai Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a></p>
<p>Although large language models (LLMs) have shown surprising language
understanding and generation capabilities, they have yet to gain a
revolutionary advancement in the field of machine translation. One potential
cause of the limited performance is the misalignment between the
translation-specific understanding and general understanding inside LLMs. To
align the translation-specific understanding to the general one, we propose a
novel translation process xIoD (Cross-Lingual Interpretation of Difficult
words), explicitly incorporating the general understanding on the content
incurring inconsistent understanding to guide the translation. Specifically,
xIoD performs the cross-lingual interpretation for the difficult-to-translate
words and enhances the translation with the generated interpretations.
Furthermore, we reframe the external tools of QE to tackle the challenges of
xIoD in the detection of difficult words and the generation of helpful
interpretations. We conduct experiments on the self-constructed benchmark
ChallengeMT, which includes cases in which multiple SOTA translation systems
consistently underperform. Experimental results show the effectiveness of our
xIoD, which improves up to +3.85 COMET.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05073">Hierarchical Classification of Transversal Skills in Job Ads Based on Sentence Embeddings. (arXiv:2401.05073v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leon_F/0/1/0/all/0/1">Florin Leon</a>, <a href="http://arxiv.org/find/cs/1/au:+Gavrilescu_M/0/1/0/all/0/1">Marius Gavrilescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Floria_S/0/1/0/all/0/1">Sabina-Adriana Floria</a>, <a href="http://arxiv.org/find/cs/1/au:+Minea_A/0/1/0/all/0/1">Alina-Adriana Minea</a></p>
<p>This paper proposes a classification framework aimed at identifying
correlations between job ad requirements and transversal skill sets, with a
focus on predicting the necessary skills for individual job descriptions using
a deep learning model. The approach involves data collection, preprocessing,
and labeling using ESCO (European Skills, Competences, and Occupations)
taxonomy. Hierarchical classification and multi-label strategies are used for
skill identification, while augmentation techniques address data imbalance,
enhancing model robustness. A comparison between results obtained with
English-specific and multi-language sentence embedding models reveals close
accuracy. The experimental case studies detail neural network configurations,
hyperparameters, and cross-validation results, highlighting the efficacy of the
hierarchical approach and the suitability of the multi-language model for the
diverse European job market. Thus, a new approach is proposed for the
hierarchical classification of transversal skills from job ads.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05111">Noise-robust zero-shot text-to-speech synthesis conditioned on self-supervised speech-representation model with adapters. (arXiv:2401.05111v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fujita_K/0/1/0/all/0/1">Kenichi Fujita</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_H/0/1/0/all/0/1">Hiroshi Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashihara_T/0/1/0/all/0/1">Takanori Ashihara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanagawa_H/0/1/0/all/0/1">Hiroki Kanagawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Delcroix_M/0/1/0/all/0/1">Marc Delcroix</a>, <a href="http://arxiv.org/find/cs/1/au:+Moriya_T/0/1/0/all/0/1">Takafumi Moriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ijima_Y/0/1/0/all/0/1">Yusuke Ijima</a></p>
<p>The zero-shot text-to-speech (TTS) method, based on speaker embeddings
extracted from reference speech using self-supervised learning (SSL) speech
representations, can reproduce speaker characteristics very accurately.
However, this approach suffers from degradation in speech synthesis quality
when the reference speech contains noise. In this paper, we propose a
noise-robust zero-shot TTS method. We incorporated adapters into the SSL model,
which we fine-tuned with the TTS model using noisy reference speech. In
addition, to further improve performance, we adopted a speech enhancement (SE)
front-end. With these improvements, our proposed SSL-based zero-shot TTS
achieved high-quality speech synthesis with noisy reference speech. Through the
objective and subjective evaluations, we confirmed that the proposed method is
highly robust to noise in reference speech, and effectively works in
combination with SE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05125">BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation. (arXiv:2401.05125v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garda_S/0/1/0/all/0/1">Samuele Garda</a>, <a href="http://arxiv.org/find/cs/1/au:+Leser_U/0/1/0/all/0/1">Ulf Leser</a></p>
<p>Biomedical entity linking (BEL) is the task of grounding entity mentions to a
knowledge base (KB). A popular approach to the task are name-based methods,
i.e. those identifying the most appropriate name in the KB for a given mention,
either via dense retrieval or autoregressive modeling. However, as these
methods directly return KB names, they cannot cope with homonyms, i.e.
different KB entities sharing the exact same name. This significantly affects
their performance, especially for KBs where homonyms account for a large amount
of entity mentions (e.g. UMLS and NCBI Gene). We therefore present BELHD
(Biomedical Entity Linking with Homonym Disambiguation), a new name-based
method that copes with this challenge. Specifically, BELHD builds upon the
BioSyn (Sung et al.,2020) model introducing two crucial extensions. First, it
performs a preprocessing of the KB in which it expands homonyms with an
automatically chosen disambiguating string, thus enforcing unique linking
decisions. Second, we introduce candidate sharing, a novel strategy to select
candidates for contrastive learning that enhances the overall training signal.
Experiments with 10 corpora and five entity types show that BELHD improves upon
state-of-the-art approaches, achieving the best results in 6 out 10 corpora
with an average improvement of 4.55pp recall@1. Furthermore, the KB
preprocessing is orthogonal to the core prediction model and thus can also
improve other methods, which we exemplify for GenBioEL (Yuan et al, 2022), a
generative name-based BEL approach. Code is available at: link added upon
publication.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05134">Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation. (arXiv:2401.05134v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1">Abhisek Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Bera_S/0/1/0/all/0/1">Shreyangshu Bera</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sriparna Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Pushpak Bhattacharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Samrat Ghosh</a></p>
<p>Over the past few years, the use of the Internet for healthcare-related tasks
has grown by leaps and bounds, posing a challenge in effectively managing and
processing information to ensure its efficient utilization. During moments of
emotional turmoil and psychological challenges, we frequently turn to the
internet as our initial source of support, choosing this over discussing our
feelings with others due to the associated social stigma. In this paper, we
propose a new task of multi-modal medical concern summary (MMCS) generation,
which provides a short and precise summary of patients' major concerns brought
up during the consultation. Nonverbal cues, such as patients' gestures and
facial expressions, aid in accurately identifying patients' concerns. Doctors
also consider patients' personal information, such as age and gender, in order
to describe the medical condition appropriately. Motivated by the potential
efficacy of patients' personal context and visual gestures, we propose a
transformer-based multi-task, multi-modal intent-recognition, and medical
concern summary generation (IR-MMCSG) system. Furthermore, we propose a
multitasking framework for intent recognition and medical concern summary
generation for doctor-patient consultations. We construct the first multi-modal
medical concern summary generation (MM-MediConSummation) corpus, which includes
patient-doctor consultations annotated with medical concern summaries, intents,
patient personal information, doctor's recommendations, and keywords. Our
experiments and analysis demonstrate (a) the significant role of patients'
expressions/gestures and their personal information in intent identification
and medical concern summary generation, and (b) the strong correlation between
intent recognition and patients' medical concern summary generation
</p>
<p>The dataset and source code are available at https://github.com/NLP-RL/MMCSG.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05176">Can ChatGPT Rival Neural Machine Translation? A Comparative Study. (arXiv:2401.05176v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhaokun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziyin Zhang</a></p>
<p>Inspired by the increasing interest in leveraging large language models for
translation, this paper evaluates the capabilities of large language models
(LLMs) represented by ChatGPT in comparison to the mainstream neural machine
translation (NMT) engines in translating Chinese diplomatic texts into English.
Specifically, we examine the translation quality of ChatGPT and NMT engines as
measured by four automated metrics and human evaluation based on an
error-typology and six analytic rubrics. Our findings show that automated
metrics yield similar results for ChatGPT under different prompts and NMT
systems, while human annotators tend to assign noticeably higher scores to
ChatGPT when it is provided an example or contextual information about the
translation task. Pairwise correlation between automated metrics and dimensions
of human evaluation produces weak and non-significant results, suggesting the
divergence between the two methods of translation quality assessment. These
findings provide valuable insights into the potential of ChatGPT as a capable
machine translator, and the influence of prompt engineering on its performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05190">Divide and Conquer for Large Language Models Reasoning. (arXiv:2401.05190v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1">Zijie Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhaopeng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gaoang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zuozhu Liu</a></p>
<p>Large language models (LLMs) have shown impressive performance in various
reasoning benchmarks with the emergence of Chain-of-Thought (CoT) and its
derivative methods, particularly in tasks involving multi-choice questions
(MCQs). However, current works all process data uniformly without considering
the problem-solving difficulty, which means an excessive focus on simple
questions while insufficient to intricate ones. To address this challenge, we
inspired by humans using heuristic strategies to categorize tasks and handle
them individually, propose to apply the Divide and Conquer to LLMs reasoning.
First, we divide questions into different subsets based on the statistical
confidence score ($\mathcal{CS}$), then fix nearly resolved sets and conquer
demanding nuanced process ones with elaborately designed methods, including
Prior Knowledge based Reasoning (PKR) and Filter Choices based Reasoning (FCR),
as well as their integration variants. Our experiments demonstrate that this
proposed strategy significantly boosts the models' reasoning abilities across
nine datasets involving arithmetic, commonsense, and logic tasks. For instance,
compared to baseline, we make a striking improvement on low confidence subsets
of 8.72\% for AQuA, 15.07\% for ARC Challenge and 7.71\% for RiddleSense. In
addition, through extensive analysis on length of rationale and number of
options, we verify that longer reasoning paths in PKR could prevent models from
referring infer-harmful shortcuts, and also find that removing irrelevant
choices in FCR would substantially avoid models' confusion. The code is at
\url{https://github.com/AiMijie/Divide-and-Conquer}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05199">Monte Carlo Tree Search for Recipe Generation using GPT-2. (arXiv:2401.05199v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Taneja_K/0/1/0/all/0/1">Karan Taneja</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_R/0/1/0/all/0/1">Richard Segal</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodwin_R/0/1/0/all/0/1">Richard Goodwin</a></p>
<p>Automatic food recipe generation methods provide a creative tool for chefs to
explore and to create new, and interesting culinary delights. Given the recent
success of large language models (LLMs), they have the potential to create new
recipes that can meet individual preferences, dietary constraints, and adapt to
what is in your refrigerator. Existing research on using LLMs to generate
recipes has shown that LLMs can be finetuned to generate realistic-sounding
recipes. However, on close examination, these generated recipes often fail to
meet basic requirements like including chicken as an ingredient in chicken
dishes. In this paper, we propose RecipeMC, a text generation method using
GPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to
define reward functions to put soft constraints on text generation and thus
improve the credibility of the generated recipes. Our results show that human
evaluators prefer recipes generated with RecipeMC more often than recipes
generated with other baseline methods when compared with real recipes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05204">A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer. (arXiv:2401.05204v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Senlin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_Y/0/1/0/all/0/1">Yu-Ming Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengjun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a></p>
<p>The verbalizer, which serves to map label words to class labels, is an
essential component of prompt-tuning. In this paper, we present a novel
approach to constructing verbalizers. While existing methods for verbalizer
construction mainly rely on augmenting and refining sets of synonyms or related
words based on class names, this paradigm suffers from a narrow perspective and
lack of abstraction, resulting in limited coverage and high bias in the
label-word space. To address this issue, we propose a label-word construction
process that incorporates scenario-specific concepts. Specifically, we extract
rich concepts from task-specific scenarios as label-word candidates and then
develop a novel cascade calibration module to refine the candidates into a set
of label words for each class. We evaluate the effectiveness of our proposed
approach through extensive experiments on {five} widely used datasets for
zero-shot text classification. The results demonstrate that our method
outperforms existing methods and achieves state-of-the-art results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05215">Pre-trained Large Language Models for Financial Sentiment Analysis. (arXiv:2401.05215v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Wei Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_D/0/1/0/all/0/1">Dihong Gong</a></p>
<p>Financial sentiment analysis refers to classifying financial text contents
into sentiment categories (e.g. positive, negative, and neutral). In this
paper, we focus on the classification of financial news title, which is a
challenging task due to a lack of large amount of training samples. To overcome
this difficulty, we propose to adapt the pretrained large language models
(LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge
amount of text corpora,have an advantage in text understanding and can be
effectively adapted to domain-specific task while requiring very few amount of
training samples. In particular, we adapt the open-source Llama2-7B model
(2023) with the supervised fine-tuning (SFT) technique [4]. Experimental
evaluation shows that even with the 7B model (which is relatively small for
LLMs), our approach significantly outperforms the previous state-of-the-art
algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05224">Do Vision and Language Encoders Represent the World Similarly?. (arXiv:2401.05224v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maniparambil_M/0/1/0/all/0/1">Mayug Maniparambil</a>, <a href="http://arxiv.org/find/cs/1/au:+Akshulakov_R/0/1/0/all/0/1">Raiymbek Akshulakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Djilali_Y/0/1/0/all/0/1">Yasser Abdelaziz Dahou Djilali</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1">Sanath Narayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Seddik_M/0/1/0/all/0/1">Mohamed El Amine Seddik</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1">Karttikeya Mangalam</a>, <a href="http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1">Noel E. O&#x27;Connor</a></p>
<p>Aligned text-image encoders such as CLIP have become the de facto model for
vision-language tasks. Furthermore, modality-specific encoders achieve
impressive performances in their respective domains. This raises a central
question: does an alignment exist between uni-modal vision and language
encoders since they fundamentally represent the same physical world? Analyzing
the latent spaces structure of vision and language models on image-caption
benchmarks using the Centered Kernel Alignment (CKA), we find that the
representation spaces of unaligned and aligned encoders are semantically
similar. In the absence of statistical similarity in aligned encoders like
CLIP, we show that a possible matching of unaligned encoders exists without any
training. We frame this as a seeded graph-matching problem exploiting the
semantic similarity between graphs and propose two methods - a Fast Quadratic
Assignment Problem optimization, and a novel localized CKA metric-based
matching/retrieval. We demonstrate the effectiveness of this on several
downstream tasks including cross-lingual, cross-domain caption matching and
image classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05249">CASA: Causality-driven Argument Sufficiency Assessment. (arXiv:2401.05249v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yansong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a></p>
<p>The argument sufficiency assessment task aims to determine if the premises of
a given argument support its conclusion. To tackle this task, existing works
often train a classifier on data annotated by humans. However, annotating data
is laborious, and annotations are often inconsistent due to subjective
criteria. Motivated by the probability of sufficiency (PS) definition in the
causal literature, we propose CASA, a zero-shot causality-driven argument
sufficiency assessment framework. PS measures how likely introducing the
premise event would lead to the conclusion, when both the premise and
conclusion events are absent. To estimate this probability, we propose to use
large language models (LLMs) to generate contexts that are inconsistent with
the premise and conclusion, and revise them by injecting the premise event.
Experiments on two logical fallacy detection datasets demonstrate that CASA
accurately identifies insufficient arguments. We further deploy CASA in a
writing assistance application, and find that suggestions generated by CASA
enhance the sufficiency of student-written arguments. Code and data are
available at https://github.com/xxxiaol/CASA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05254">Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination. (arXiv:2401.05254v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1">Young-Min Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_D/0/1/0/all/0/1">Dandan Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Thapa_S/0/1/0/all/0/1">Stuti Thapa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sherman_G/0/1/0/all/0/1">Garrick Sherman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1">Lyle Ungar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1">Louis Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Guntuku_S/0/1/0/all/0/1">Sharath Chandra Guntuku</a></p>
<p>Although affective expressions of individuals have been extensively studied
using social media, research has primarily focused on the Western context.
There are substantial differences among cultures that contribute to their
affective expressions. This paper examines the differences between Twitter (X)
in the United States and Sina Weibo posts in China on two primary dimensions of
affect - valence and arousal. We study the difference in the functional
relationship between arousal and valence (so-called V-shaped) among individuals
in the US and China and explore the associated content differences.
Furthermore, we correlate word usage and topics in both platforms to interpret
their differences. We observe that for Twitter users, the variation in
emotional intensity is less distinct between negative and positive emotions
compared to Weibo users, and there is a sharper escalation in arousal
corresponding with heightened emotions. From language features, we discover
that affective expressions are associated with personal life and feelings on
Twitter, while on Weibo such discussions are about socio-political topics in
the society. These results suggest a West-East difference in the V-shaped
relationship between valence and arousal of affective expressions on social
media influenced by content differences. Our findings have implications for
applications and theories related to cultural differences in affective
expressions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05268">AUTOACT: Automatic Agent Learning from Scratch via Self-Planning. (arXiv:2401.05268v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1">Shuofei Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_R/0/1/0/all/0/1">Runnan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yujie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuchen Eleanor Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1">Chengfei Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a></p>
<p>Language agents have achieved considerable performance on various complex
tasks. Despite the incessant exploration in this field, existing language agent
systems still struggle with costly, non-reproducible data reliance and face the
challenge of compelling a single model for multiple functions. To this end, we
introduce AutoAct, an automatic agent learning framework that does not rely on
large-scale annotated data and synthetic trajectories from closed-source models
(e.g., GPT-4). Given limited data with a tool library, AutoAct first
automatically synthesizes planning trajectories without any assistance from
humans or strong closed-source models. Then, AutoAct leverages a
division-of-labor strategy to automatically differentiate based on the target
task information and synthesized trajectories, producing a sub-agent group to
complete the task. We conduct comprehensive experiments with different LLMs,
which demonstrates that AutoAct yields better or parallel performance compared
to various strong baselines. We even notice that AutoAct, when using the
Llama-2-13b model, can achieve performance comparable to that of the
GPT-3.5-Turbo agent. Code will be available at
https://github.com/zjunlp/AutoAct.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05273">INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges. (arXiv:2401.05273v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pereira_J/0/1/0/all/0/1">Jayr Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Assumpcao_A/0/1/0/all/0/1">Andre Assumpcao</a>, <a href="http://arxiv.org/find/cs/1/au:+Trecenti_J/0/1/0/all/0/1">Julio Trecenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Airosa_L/0/1/0/all/0/1">Luiz Airosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lente_C/0/1/0/all/0/1">Caio Lente</a>, <a href="http://arxiv.org/find/cs/1/au:+Cleto_J/0/1/0/all/0/1">Jhonatan Cl&#xe9;to</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobins_G/0/1/0/all/0/1">Guilherme Dobins</a>, <a href="http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1">Rodrigo Nogueira</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_L/0/1/0/all/0/1">Luis Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotufo_R/0/1/0/all/0/1">Roberto Lotufo</a></p>
<p>This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia
Artificial), a groundbreaking system designed to integrate Large Language
Models (LLMs) into the operational framework of Brazilian Federal Court of
Accounts (TCU). The system automates various stages of case analysis, including
basic information extraction, admissibility examination, Periculum in mora and
Fumus boni iuris analyses, and recommendations generation. Through a series of
experiments, we demonstrate INACIA's potential in extracting relevant
information from case documents, evaluating its legal plausibility, and
generating judicial recommendations. Utilizing a validation dataset alongside
LLMs, our evaluation methodology presents an innovative approach to assessing
system performance, correlating highly with human judgment. The results
highlight INACIA's proficiency in handling complex legal tasks, indicating its
suitability for augmenting efficiency and judicial fairness within legal
systems. The paper also discusses potential enhancements and future
applications, positioning INACIA as a model for worldwide AI integration in
legal domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05300">I am a Strange Dataset: Metalinguistic Tests for Language Models. (arXiv:2401.05300v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1">Tristan Thrush</a>, <a href="http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1">Jared Moore</a>, <a href="http://arxiv.org/find/cs/1/au:+Monares_M/0/1/0/all/0/1">Miguel Monares</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a></p>
<p>Statements involving metalinguistic self-reference ("This paper has six
sections.") are prevalent in many domains. Can large language models (LLMs)
handle such language? In this paper, we present "I am a Strange Dataset", a new
dataset for addressing this question. There are two subtasks: generation and
verification. In generation, models continue statements like "The penultimate
word in this sentence is" (where a correct continuation is "is"). In
verification, models judge the truth of statements like "The penultimate word
in this sentence is sentence." (false). We also provide minimally different
metalinguistic non-self-reference examples to complement the main dataset by
probing for whether models can handle metalinguistic language at all. The
dataset is hand-crafted by experts and validated by non-expert annotators. We
test a variety of open-source LLMs (7B to 70B parameters) as well as
closed-source LLMs through APIs. All models perform close to chance across both
subtasks and even on the non-self-referential metalinguistic control data,
though we find some steady improvement with model scale. GPT 4 is the only
model to consistently do significantly better than chance, and it is still only
in the 60% range, while our untrained human annotators score well in the 89-93%
range. The dataset and evaluation toolkit are available at
https://github.com/TristanThrush/i-am-a-strange-dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05314">ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video. (arXiv:2401.05314v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Cai_K/0/1/0/all/0/1">Kevin Cai</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1">Chonghua Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_D/0/1/0/all/0/1">David M. Chan</a></p>
<p>The Internet's wealth of content, with up to 60% published in English,
starkly contrasts the global population, where only 18.8% are English speakers,
and just 5.1% consider it their native language, leading to disparities in
online information access. Unfortunately, automated processes for dubbing of
video - replacing the audio track of a video with a translated alternative -
remains a complex and challenging task due to pipelines, necessitating precise
timing, facial movement synchronization, and prosody matching. While end-to-end
dubbing offers a solution, data scarcity continues to impede the progress of
both end-to-end and pipeline-based methods. In this work, we introduce
Anim-400K, a comprehensive dataset of over 425K aligned animated video segments
in Japanese and English supporting various video-related tasks, including
automated dubbing, simultaneous translation, guided video summarization, and
genre/theme/style classification. Our dataset is made publicly available for
research purposes at https://github.com/davidmchan/Anim400K.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05319">Leveraging Print Debugging to Improve Code Generation in Large Language Models. (arXiv:2401.05319v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xueyu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1">Kun Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiankai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a></p>
<p>Large language models (LLMs) have made significant progress in code
generation tasks, but their performance in tackling programming problems with
complex data structures and algorithms remains suboptimal. To address this
issue, we propose an in-context learning approach that guides LLMs to debug by
using a "print debugging" method, which involves inserting print statements to
trace and analysing logs for fixing the bug. We collect a Leetcode problem
dataset and evaluate our method using the Leetcode online judging system.
Experiments with GPT-4 demonstrate the effectiveness of our approach,
outperforming rubber duck debugging in easy and medium-level Leetcode problems
by 1.5% and 17.9%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.10668">BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing. (arXiv:2206.10668v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhro Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomson_S/0/1/0/all/0/1">Sam Thomson</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tongfei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_R/0/1/0/all/0/1">Richard Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauls_A/0/1/0/all/0/1">Adam Pauls</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1">Jason Eisner</a>, <a href="http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1">Benjamin Van Durme</a></p>
<p>Recent work has shown that generation from a prompted or fine-tuned language
model can perform well at semantic parsing when the output is constrained to be
a valid semantic representation. We introduce BenchCLAMP, a Benchmark to
evaluate Constrained LAnguage Model Parsing, that includes context-free
grammars for seven semantic parsing datasets and two syntactic parsing datasets
with varied output representations, as well as a constrained decoding interface
to generate only valid outputs covered by these grammars. We provide low,
medium, and high resource splits for each dataset, allowing accurate comparison
of various language models under different data regimes. Our benchmark supports
evaluation of language models using prompt-based learning as well as
fine-tuning. We benchmark eight language models, including two GPT-3 variants
available only through an API. Our experiments show that encoder-decoder
pretrained language models can achieve similar performance or surpass
state-of-the-art methods for syntactic and semantic parsing when the model
output is constrained to be valid.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.15088">Personalized Dialogue Generation with Persona-Adaptive Attention. (arXiv:2210.15088v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiushi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1">Tom Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xubo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenwu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Lilian Tang</a></p>
<p>Persona-based dialogue systems aim to generate consistent responses based on
historical context and predefined persona. Unlike conventional dialogue
generation, the persona-based dialogue needs to consider both dialogue context
and persona, posing a challenge for coherent training. Specifically, this
requires a delicate weight balance between context and persona. To achieve
that, in this paper, we propose an effective framework with Persona-Adaptive
Attention (PAA), which adaptively integrates the weights from the persona and
context information via our designed attention. In addition, a dynamic masking
mechanism is applied to the PAA to not only drop redundant information in
context and persona but also serve as a regularization mechanism to avoid
overfitting. Experimental results demonstrate the superiority of the proposed
PAA framework compared to the strong baselines in both automatic and human
evaluation. Moreover, the proposed PAA approach can perform equivalently well
in a low-resource regime compared to models trained in a full-data setting,
which achieve a similar result with only 20% to 30% of data compared to the
larger models trained in the full-data setting. To fully exploit the
effectiveness of our design, we designed several variants for handling the
weighted information in different ways, showing the necessity and sufficiency
of our weighting and masking designs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.11406">LaMP: When Large Language Models Meet Personalization. (arXiv:2304.11406v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Salemi_A/0/1/0/all/0/1">Alireza Salemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1">Sheshera Mysore</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1">Michael Bendersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1">Hamed Zamani</a></p>
<p>This paper highlights the importance of personalization in large language
models and introduces the LaMP benchmark -- a novel benchmark for training and
evaluating language models for producing personalized outputs. LaMP offers a
comprehensive evaluation framework with diverse language tasks and multiple
entries for each user profile. It consists of seven personalized tasks,
spanning three text classification and four text generation tasks. We
additionally propose two retrieval augmentation approaches that retrieve
personal items from each user profile for personalizing language model outputs.
To this aim, we study various retrieval models, including term matching,
semantic matching, and time-aware methods. Extensive experiments on LaMP for
zero-shot and fine-tuned language models demonstrate the efficacy of the
proposed retrieval augmentation approach and highlight the impact of
personalization in various natural language tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11731">Persian Typographical Error Type Detection Using Deep Neural Networks on Algorithmically-Generated Misspellings. (arXiv:2305.11731v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1">Mohammad Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Faili_H/0/1/0/all/0/1">Heshaam Faili</a></p>
<p>Spelling correction is a remarkable challenge in the field of natural
language processing. The objective of spelling correction tasks is to recognize
and rectify spelling errors automatically. The development of applications that
can effectually diagnose and correct Persian spelling and grammatical errors
has become more important in order to improve the quality of Persian text. The
Typographical Error Type Detection in Persian is a relatively understudied
area. Therefore, this paper presents a compelling approach for detecting
typographical errors in Persian texts. Our work includes the presentation of a
publicly available dataset called FarsTypo, which comprises 3.4 million words
arranged in chronological order and tagged with their corresponding
part-of-speech. These words cover a wide range of topics and linguistic styles.
We develop an algorithm designed to apply Persian-specific errors to a scalable
portion of these words, resulting in a parallel dataset of correct and
incorrect words. By leveraging FarsTypo, we establish a strong foundation and
conduct a thorough comparison of various methodologies employing different
architectures. Additionally, we introduce a groundbreaking Deep Sequential
Neural Network that utilizes both word and character embeddings, along with
bidirectional LSTM layers, for token classification aimed at detecting
typographical errors across 51 distinct classes. Our approach is contrasted
with highly advanced industrial systems that, unlike this study, have been
developed using a diverse range of resources. The outcomes of our final method
proved to be highly competitive, achieving an accuracy of 97.62%, precision of
98.83%, recall of 98.61%, and surpassing others in terms of speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.17100">BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. (arXiv:2305.17100v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Adhikarla_E/0/1/0/all/0/1">Eashan Adhikarla</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Rong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhiling Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Davison_B/0/1/0/all/0/1">Brian Davison</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Hui Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1">Sunyang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Quanzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongfang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a></p>
<p>Conventional task- and modality-specific artificial intelligence (AI) models
are inflexible in real-world deployment and maintenance for biomedicine. At the
same time, the growing availability of biomedical data, coupled with the
advancements in modern multi-modal multi-task AI techniques, has paved the way
for the emergence of generalist biomedical AI solutions. These solutions hold
the potential to interpret different medical modalities and produce expressive
outputs such as free-text reports or disease diagnosis. Here, we propose
BiomedGPT, the first open-source and generalist visual language AI for diverse
biomedical tasks. BiomedGPT achieved 16 state-of-the-art results across five
clinically significant tasks on 26 datasets. Notably, it outperformed OpenAI's
GPT-4 with vision (GPT-4V) in radiology human evaluation and surpassed Google's
Med-PaLM M (12B) in breast cancer diagnosis and medical visual question
answering. Moreover, BiomedGPT facilitates zero-shot transfer learning, greatly
enhancing its utility as a biomedical assistant, similar to ChatGPT. Our method
demonstrates effective training with diverse datasets can lead to more
practical biomedical AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09996">Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering. (arXiv:2306.09996v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Awal_R/0/1/0/all/0/1">Rabiul Awal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Le Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Aishwarya Agrawal</a></p>
<p>In this paper, we explore effective prompting techniques to enhance zero- and
few-shot Visual Question Answering (VQA) performance in contemporary
Vision-Language Models (VLMs). Central to our investigation is the role of
question templates in guiding VLMs to generate accurate answers. We identify
that specific templates significantly influence VQA outcomes, underscoring the
need for strategic template selection. Another pivotal aspect of our study is
augmenting VLMs with image captions, providing them with additional visual cues
alongside direct image features in VQA tasks. Surprisingly, this augmentation
significantly improves the VLMs' performance in many cases, even though VLMs
"see" the image directly! We explore chain-of-thought (CoT) reasoning and find
that while standard CoT reasoning causes drops in performance, advanced methods
like self-consistency can help recover it. Furthermore, we find that text-only
few-shot examples enhance VLMs' alignment with the task format, particularly
benefiting models prone to verbose zero-shot answers. Lastly, to mitigate the
challenges associated with evaluating free-form open-ended VQA responses using
string-matching based VQA metrics, we introduce a straightforward LLM-guided
pre-processing technique to adapt the model responses to the expected
ground-truth answer distribution. In summary, our research sheds light on the
intricacies of prompting strategies in VLMs for VQA, emphasizing the
synergistic use of captions, templates, and pre-processing to enhance model
efficacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12245">Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking. (arXiv:2306.12245v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yinghui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xingyu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yangning Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pengjun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Ying Shen</a></p>
<p>Entity Linking (EL) is a fundamental task for Information Extraction and
Knowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first
find mentions in the given input document and then link the mentions to
corresponding entities in a specific knowledge base. Recently, the paradigm of
retriever-reader promotes the progress of end-to-end EL, benefiting from the
advantages of dense entity retrieval and machine reading comprehension.
However, the existing study only trains the retriever and the reader separately
in a pipeline manner, which ignores the benefit that the interaction between
the retriever and the reader can bring to the task. To advance the
retriever-reader paradigm to perform more perfectly on end-to-end EL, we
propose BEER$^2$, a Bidirectional End-to-End training framework for Retriever
and Reader. Through our designed bidirectional end-to-end training, BEER$^2$
guides the retriever and the reader to learn from each other, make progress
together, and ultimately improve EL performance. Extensive experiments on
benchmarks of multiple domains demonstrate the effectiveness of our proposed
BEER$^2$.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00319">LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack. (arXiv:2308.00319v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hai Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaoqing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_W/0/1/0/all/0/1">Weiwei Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuren Wu</a></p>
<p>Natural language processing models are vulnerable to adversarial examples.
Previous textual adversarial attacks adopt gradients or confidence scores to
calculate word importance ranking and generate adversarial examples. However,
this information is unavailable in the real world. Therefore, we focus on a
more realistic and challenging setting, named hard-label attack, in which the
attacker can only query the model and obtain a discrete prediction label.
Existing hard-label attack algorithms tend to initialize adversarial examples
by random substitution and then utilize complex heuristic algorithms to
optimize the adversarial perturbation. These methods require a lot of model
queries and the attack success rate is restricted by adversary initialization.
In this paper, we propose a novel hard-label attack algorithm named LimeAttack,
which leverages a local explainable method to approximate word importance
ranking, and then adopts beam search to find the optimal solution. Extensive
experiments show that LimeAttack achieves the better attacking performance
compared with existing hard-label attack under the same query budget. In
addition, we evaluate the effectiveness of LimeAttack on large language models,
and results indicate that adversarial examples remain a significant threat to
large language models. The adversarial examples crafted by LimeAttack are
highly transferable and effectively improve model robustness in adversarial
training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05281">Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zihui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemphill_L/0/1/0/all/0/1">Libby Hemphill</a>, <a href="http://arxiv.org/find/cs/1/au:+Baecher_G/0/1/0/all/0/1">Gregory B. Baecher</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yubai Yuan</a></p>
<p>Effective disaster response is critical for affected communities. Responders
and decision-makers would benefit from reliable, timely measures of the issues
impacting their communities during a disaster, and social media offers a
potentially rich data source. Social media can reflect public concerns and
demands during a disaster, offering valuable insights for decision-makers to
understand evolving situations and optimize resource allocation. We used
Bidirectional Encoder Representations from Transformers (BERT) topic modeling
to cluster topics from Twitter data. Then, we conducted a temporal-spatial
analysis to examine the distribution of these topics across different regions
during the 2020 western U.S. wildfire season. Our results show that Twitter
users mainly focused on three topics:"health impact," "damage," and
"evacuation." We used the Susceptible-Infected-Recovered (SIR) theory to
explore the magnitude and velocity of topic diffusion on Twitter. The results
displayed a clear relationship between topic trends and wildfire propagation
patterns. The estimated parameters obtained from the SIR model in selected
cities revealed that residents exhibited a high level of several concerns
during the wildfire. Our study details how the SIR model and topic modeling
using social media data can provide decision-makers with a quantitative
approach to measure disaster response and support their decision-making
processes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10744">Evaluating large language models&#x27; ability to understand metaphor and sarcasm using a screening test for Asperger syndrome. (arXiv:2309.10744v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yakura_H/0/1/0/all/0/1">Hiromu Yakura</a></p>
<p>Metaphors and sarcasm are precious fruits of our highly-evolved social
communication skills. However, children with Asperger syndrome are known to
have difficulties in comprehending sarcasm, even if they possess a certain
level of verbal IQ sufficient for understanding metaphors. Given that, a
screening test that scores the ability to understand metaphor and sarcasm has
been used to differentiate Asperger syndrome from other symptoms exhibiting
akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This
study uses the standardized test to examine the capability of recent large
language models (LLMs) in understanding human nuanced communication. The
results divulged that, whereas their ability to comprehend metaphors has been
improved with the increase of the number of model parameters, the improvement
in sarcasm understanding was not observed. This implies that an alternative
approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which
has been associated with the amygdala, a pivotal cerebral region for emotional
learning, in the case of humans.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02567">Improving Automatic VQA Evaluation Using Large Language Models. (arXiv:2310.02567v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manas_O/0/1/0/all/0/1">Oscar Ma&#xf1;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Krojer_B/0/1/0/all/0/1">Benno Krojer</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Aishwarya Agrawal</a></p>
<p>8 years after the visual question answering (VQA) task was proposed, accuracy
remains the primary metric for automatic evaluation. VQA Accuracy has been
effective so far in the IID evaluation setting. However, our community is
undergoing a shift towards open-ended generative models and OOD evaluation. In
this new paradigm, the existing VQA Accuracy metric is overly stringent and
underestimates the performance of VQA systems. Thus, there is a need to develop
more robust automatic VQA metrics that serve as a proxy for human judgment. In
this work, we propose to leverage the in-context learning capabilities of
instruction-tuned large language models (LLMs) to build a better VQA metric. We
formulate VQA evaluation as an answer-rating task where the LLM is instructed
to score the accuracy of a candidate answer given a set of reference answers.
We demonstrate the proposed metric better correlates with human judgment
compared to existing metrics across several VQA models and benchmarks. We hope
wide adoption of our metric will contribute to better estimating the research
progress on the VQA task. We plan to release the evaluation code and collected
human judgments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.04666">Pre-training LLMs using human-like development data corpus. (arXiv:2311.04666v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhardwaj_K/0/1/0/all/0/1">Khushi Bhardwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Raj Sanjay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Varma_S/0/1/0/all/0/1">Sashank Varma</a></p>
<p>Pre-trained Large Language Models (LLMs) have shown success in a diverse set
of language inference and understanding tasks. The pre-training stage of LLMs
looks at a large corpus of raw textual data. The BabyLM shared task compares
LLM pre-training to human language acquisition, where the number of tokens seen
by 13-year-old kids is magnitudes smaller than the number of tokens seen by
LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn
contextual word representations using roughly the same number of tokens as seen
by children. We provide a strong set of baselines; with different
architectures, evaluation of changes in performance across epochs, and reported
pre-training metrics for the strict small and strict tracks of the task. We
also try to loosely replicate the RoBERTa baseline given by the task organizers
to observe the training robustness to hyperparameter selection and
replicability. We provide the submission details to the strict and strict-small
tracks in this report.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14115">A density estimation perspective on learning from pairwise human preferences. (arXiv:2311.14115v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel D. Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Dauphin_Y/0/1/0/all/0/1">Yann Dauphin</a></p>
<p>Learning from human feedback (LHF) -- and in particular learning from
pairwise preferences -- has recently become a crucial ingredient in training
large language models (LLMs), and has been the subject of much research. Most
recent works frame it as a reinforcement learning problem, where a reward
function is learned from pairwise preference data and the LLM is treated as a
policy which is adapted to maximize the rewards, often under additional
regularization constraints. We propose an alternative interpretation which
centers on the generative process for pairwise preferences and treats LHF as a
density estimation problem. We provide theoretical and empirical results
showing that for a family of generative processes defined via preference
behavior distribution equations, training a reward function on pairwise
preferences effectively models an annotator's implicit preference distribution.
Finally, we discuss and present findings on "annotator misspecification" --
failure cases where wrong modeling assumptions are made about annotator
behavior, resulting in poorly-adapted models -- suggesting that approaches that
learn from pairwise human preferences could have trouble learning from a
population of annotators with diverse viewpoints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.14836">Custom Data Augmentation for low resource ASR using Bark and Retrieval-Based Voice Conversion. (arXiv:2311.14836v3 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kamble_A/0/1/0/all/0/1">Anand Kamble</a>, <a href="http://arxiv.org/find/cs/1/au:+Tathe_A/0/1/0/all/0/1">Aniket Tathe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumbharkar_S/0/1/0/all/0/1">Suyash Kumbharkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandare_A/0/1/0/all/0/1">Atharva Bhandare</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1">Anirban C. Mitra</a></p>
<p>This paper proposes two innovative methodologies to construct customized
Common Voice datasets for low-resource languages like Hindi. The first
methodology leverages Bark, a transformer-based text-to-audio model developed
by Suno, and incorporates Meta's enCodec and a pre-trained HuBert model to
enhance Bark's performance. The second methodology employs Retrieval-Based
Voice Conversion (RVC) and uses the Ozen toolkit for data preparation. Both
methodologies contribute to the advancement of ASR technology and offer
valuable insights into addressing the challenges of constructing customized
Common Voice datasets for under-resourced languages. Furthermore, they provide
a pathway to achieving high-quality, personalized voice generation for a range
of applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04889">KwaiAgents: Generalized Information-seeking Agent System with Large Language Models. (arXiv:2312.04889v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Haojie Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_Z/0/1/0/all/0/1">Zepeng Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yaojia Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1">Ruiji Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a></p>
<p>Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user's query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system's performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10638">HyperPIE: Hyperparameter Information Extraction from Scientific Publications. (arXiv:2312.10638v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saier_T/0/1/0/all/0/1">Tarek Saier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohta_M/0/1/0/all/0/1">Mayumi Ohta</a>, <a href="http://arxiv.org/find/cs/1/au:+Asakura_T/0/1/0/all/0/1">Takuto Asakura</a>, <a href="http://arxiv.org/find/cs/1/au:+Farber_M/0/1/0/all/0/1">Michael F&#xe4;rber</a></p>
<p>Automatic extraction of information from publications is key to making
scientific knowledge machine readable at a large scale. The extracted
information can, for example, facilitate academic search, decision making, and
knowledge graph construction. An important type of information not covered by
existing approaches is hyperparameters. In this paper, we formalize and tackle
hyperparameter information extraction (HyperPIE) as an entity recognition and
relation extraction task. We create a labeled data set covering publications
from a variety of computer science disciplines. Using this data set, we train
and evaluate BERT-based fine-tuned models as well as five large language
models: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tuned
models, we develop a relation extraction approach that achieves an improvement
of 29% F1 over a state-of-the-art baseline. For large language models, we
develop an approach leveraging YAML output for structured data extraction,
which achieves an average improvement of 5.5% F1 in entity recognition over
using JSON. With our best performing model we extract hyperparameter
information from a large number of unannotated papers, and analyze patterns
across disciplines. All our data and source code is publicly available at
https://github.com/IllDepence/hyperpie
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.15156">Large Language Models as Zero-Shot Keyphrase Extractors: A Preliminary Empirical Study. (arXiv:2312.15156v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingyang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xuelian Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1">Songfang Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shilong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1">Liping Jing</a></p>
<p>Zero-shot keyphrase extraction aims to build a keyphrase extractor without
training by human-annotated data, which is challenging due to the limited human
intervention involved. Challenging but worthwhile, zero-shot setting
efficiently reduces the time and effort that data labeling takes. Recent
efforts on pre-trained large language models (e.g., ChatGPT and ChatGLM) show
promising performance on zero-shot settings, thus inspiring us to explore
prompt-based methods. In this paper, we ask whether strong keyphrase extraction
models can be constructed by directly prompting the large language model
ChatGPT. Through experimental results, it is found that ChatGPT still has a lot
of room for improvement in the keyphrase extraction task compared to existing
state-of-the-art unsupervised and supervised models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.01053">Cheetah: Natural Language Generation for 517 African Languages. (arXiv:2401.01053v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Adebara_I/0/1/0/all/0/1">Ife Adebara</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1">AbdelRahim Elmadany</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a></p>
<p>Low-resource African languages pose unique challenges for natural language
processing (NLP) tasks, including natural language generation (NLG). In this
paper, we develop Cheetah, a massively multilingual NLG language model for
African languages. Cheetah supports 517 African languages and language
varieties, allowing us to address the scarcity of NLG resources and provide a
solution to foster linguistic diversity. We demonstrate the effectiveness of
Cheetah through comprehensive evaluations across six generation downstream
tasks. In five of the six tasks, Cheetah significantly outperforms other
models, showcasing its remarkable performance for generating coherent and
contextually appropriate text in a wide range of African languages. We
additionally conduct a detailed human evaluation to delve deeper into the
linguistic capabilities of Cheetah. The introduction of Cheetah has
far-reaching benefits for linguistic diversity. By leveraging pretrained models
and adapting them to specific languages, our approach facilitates the
development of practical NLG applications for African communities. The findings
of this study contribute to advancing NLP research in low-resource settings,
enabling greater accessibility and inclusion for African languages in a rapidly
expanding digital landscape. We publicly release our models for research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.02987">Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aboagye_P/0/1/0/all/0/1">Prince Aboagye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junpeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Saini_U/0/1/0/all/0/1">Uday Singh Saini</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xin Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_M/0/1/0/all/0/1">Michael Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yujie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zhongfang Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shubham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a></p>
<p>The emergence of pretrained models has significantly impacted Natural
Language Processing (NLP) and Computer Vision to relational datasets.
Traditionally, these models are assessed through fine-tuned downstream tasks.
However, this raises the question of how to evaluate these models more
efficiently and more effectively. In this study, we explore a novel approach
where we leverage the meta features associated with each entity as a source of
worldly knowledge and employ entity representations from the models. We propose
using the consistency between these representations and the meta features as a
metric for evaluating pretrained models. Our method's effectiveness is
demonstrated across various domains, including models with relational datasets,
large language models and image models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03385">Grimoire is All You Need for Enhancing Large Language Models. (arXiv:2401.03385v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Ding Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shichao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qingchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenjin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_F/0/1/0/all/0/1">Feiyu Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1">Bo Tang</a></p>
<p>In-context Learning (ICL) is one of the key methods for enhancing the
performance of large language models on specific tasks by providing a set of
few-shot examples. However, the ICL capability of different types of models
shows significant variation due to factors such as model architecture, volume
of learning data, and the size of parameters. Generally, the larger the model's
parameter size and the more extensive the learning data, the stronger its ICL
capability. In this paper, we propose a method SLEICL that involves learning
from examples using strong language models and then summarizing and
transferring these learned skills to weak language models for inference and
application. This ensures the stability and effectiveness of ICL. Compared to
directly enabling weak language models to learn from prompt examples, SLEICL
reduces the difficulty of ICL for these models. Our experiments, conducted on
up to eight datasets with five language models, demonstrate that weak language
models achieve consistent improvement over their own zero-shot or few-shot
capabilities using the SLEICL method. Some weak language models even surpass
the performance of GPT4-1106-preview (zero-shot) with the aid of SLEICL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04620">Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shimin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tianxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a></p>
<p>Agents based on Large Language Models (LLMs) are increasingly permeating
various domains of human production and life, highlighting the importance of
aligning them with human values. The current alignment of AI systems primarily
focuses on passively aligning LLMs through human intervention. However, agents
possess characteristics like receiving environmental feedback and
self-evolution, rendering the LLM alignment methods inadequate. In response, we
propose an evolutionary framework for agent evolution and alignment, named
EvolutionaryAgent, which transforms agent alignment into a process of evolution
and selection under the principle of survival of the fittest. In an environment
where social norms continuously evolve, agents better adapted to the current
social norms will have a higher probability of survival and proliferation,
while those inadequately aligned dwindle over time. Experimental results
assessing the agents from multiple perspectives in aligning with social norms
demonstrate that EvolutionaryAgent possesses the capability to align
progressively better with the evolving social norms while maintaining its
proficiency in general tasks. Effectiveness tests conducted on various open and
closed-source LLMs as the foundation for agents also prove the applicability of
our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04679">RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nikdan_M/0/1/0/all/0/1">Mahdi Nikdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabesh_S/0/1/0/all/0/1">Soroush Tabesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a></p>
<p>We investigate parameter-efficient fine-tuning (PEFT) methods that can
provide good accuracy under limited computational and memory budgets in the
context of large language models (LLMs). We present a new PEFT method called
Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA)
that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components
on top of a set of fixed pretrained weights to efficiently approximate the
performance of a full-fine-tuning (FFT) solution. Across a series of
challenging generative tasks such as grade-school math and SQL query
generation, which require fine-tuning for good performance, we show that RoSA
outperforms both LoRA and pure sparse fine-tuning, at the same parameter
budget. We provide system support for RoSA to complement the training
algorithm, specifically in the form of sparse GPU kernels which enable memory-
and computationally-efficient training. Our code will be made available at
https://github.com/IST-DASLab/RoSA}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03991">Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark. (arXiv:2401.03991v1 [cs.AI] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fangjun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogg_D/0/1/0/all/0/1">David C. Hogg</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1">Anthony G. Cohn</a></p>
<p>Artificial intelligence (AI) has made remarkable progress across various
domains, with large language models like ChatGPT gaining substantial attention
for their human-like text-generation capabilities. Despite these achievements,
spatial reasoning remains a significant challenge for these models. Benchmarks
like StepGame evaluate AI spatial reasoning, where ChatGPT has shown
unsatisfactory performance. However, the presence of template errors in the
benchmark has an impact on the evaluation results. Thus there is potential for
ChatGPT to perform better if these template errors are addressed, leading to
more accurate assessments of its spatial reasoning capabilities. In this study,
we refine the StepGame benchmark, providing a more accurate dataset for model
evaluation. We analyze GPT's spatial reasoning performance on the rectified
benchmark, identifying proficiency in mapping natural language text to spatial
relations but limitations in multi-hop reasoning. We provide a flawless
solution to the benchmark by combining template-to-relation mapping with
logic-based reasoning. This combination demonstrates proficiency in performing
qualitative reasoning on StepGame without encountering any errors. We then
address the limitations of GPT models in spatial reasoning. We deploy
Chain-of-thought and Tree-of-thoughts prompting strategies, offering insights
into GPT's ``cognitive process", and achieving remarkable improvements in
accuracy. Our investigation not only sheds light on model deficiencies but also
proposes enhancements, contributing to the advancement of AI with more robust
spatial reasoning capabilities.
</p>
</p>
</div>

    </div>
    </body>
    