<!DOCTYPE html>
<html>
<head>
<title>2023-07-27-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.13699">EFL Students&#x27; Attitudes and Contradictions in a Machine-in-the-loop Activity System. (arXiv:2307.13699v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Woo_D/0/1/0/all/0/1">David James Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Susanto_H/0/1/0/all/0/1">Hengky Susanto</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1">Kai Guo</a></p>
<p>This study applies Activity Theory and investigates the attitudes and
contradictions of 67 English as a foreign language (EFL) students from four
Hong Kong secondary schools towards machine-in-the-loop writing, where
artificial intelligence (AI) suggests ideas during composition. Students
answered an open-ended question about their feelings on writing with AI.
Results revealed mostly positive attitudes, with some negative or mixed
feelings. From a thematic analysis, contradictions or points of tension between
students and AI stemmed from AI inadequacies, students' balancing enthusiasm
with preference, and their striving for language autonomy. The research
highlights the benefits and challenges of implementing machine-in-the-loop
writing in EFL classrooms, suggesting educators align activity goals with
students' values, language abilities, and AI capabilities to enhance students'
activity systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13702">Measuring Faithfulness in Chain-of-Thought Reasoning. (arXiv:2307.13702v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lanham_T/0/1/0/all/0/1">Tamera Lanham</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anna Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1">Ansh Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_B/0/1/0/all/0/1">Benoit Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Denison_C/0/1/0/all/0/1">Carson Denison</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_D/0/1/0/all/0/1">Danny Hernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dustin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1">Esin Durmus</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubinger_E/0/1/0/all/0/1">Evan Hubinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kernion_J/0/1/0/all/0/1">Jackson Kernion</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukosiute_K/0/1/0/all/0/1">Kamil&#x117; Luko&#x161;i&#x16b;t&#x117;</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Karina Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1">Newton Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_N/0/1/0/all/0/1">Nicholas Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1">Nicholas Schiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rausch_O/0/1/0/all/0/1">Oliver Rausch</a>, <a href="http://arxiv.org/find/cs/1/au:+Larson_R/0/1/0/all/0/1">Robin Larson</a>, <a href="http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1">Sam McCandlish</a>, <a href="http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1">Sandipan Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1">Saurav Kadavath</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shannon Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Henighan_T/0/1/0/all/0/1">Thomas Henighan</a>, <a href="http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1">Timothy Maxwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Telleen_Lawton_T/0/1/0/all/0/1">Timothy Telleen-Lawton</a>, <a href="http://arxiv.org/find/cs/1/au:+Hume_T/0/1/0/all/0/1">Tristan Hume</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatfield_Dodds_Z/0/1/0/all/0/1">Zac Hatfield-Dodds</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1">Jared Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1">Jan Brauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1">Samuel R. Bowman</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1">Ethan Perez</a></p>
<p>Large language models (LLMs) perform better when they produce step-by-step,
"Chain-of-Thought" (CoT) reasoning before answering a question, but it is
unclear if the stated reasoning is a faithful explanation of the model's actual
reasoning (i.e., its process for answering the question). We investigate
hypotheses for how CoT reasoning may be unfaithful, by examining how the model
predictions change when we intervene on the CoT (e.g., by adding mistakes or
paraphrasing it). Models show large variation across tasks in how strongly they
condition on the CoT when predicting their answer, sometimes relying heavily on
the CoT and other times primarily ignoring it. CoT's performance boost does not
seem to come from CoT's added test-time compute alone or from information
encoded via the particular phrasing of the CoT. As models become larger and
more capable, they produce less faithful reasoning on most tasks we study.
Overall, our results suggest that CoT can be faithful if the circumstances such
as the model size and task are carefully chosen.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13714">Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice. (arXiv:2307.13714v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Helm_P/0/1/0/all/0/1">Paula Helm</a>, <a href="http://arxiv.org/find/cs/1/au:+Bella_G/0/1/0/all/0/1">G&#xe1;bor Bella</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_G/0/1/0/all/0/1">Gertraud Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1">Fausto Giunchiglia</a></p>
<p>It is well known that AI-based language technology -- large language models,
machine translation systems, multilingual dictionaries, and corpora -- is
currently limited to 2 to 3 percent of the world's most widely spoken and/or
financially and politically best supported languages. In response, recent
research efforts have sought to extend the reach of AI technology to
``underserved languages.'' In this paper, we show that many of these attempts
produce flawed solutions that adhere to a hard-wired representational
preference for certain languages, which we call techno-linguistic bias.
Techno-linguistic bias is distinct from the well-established phenomenon of
linguistic bias as it does not concern the languages represented but rather the
design of the technologies. As we show through the paper, techno-linguistic
bias can result in systems that can only express concepts that are part of the
language and culture of dominant powers, unable to correctly represent concepts
from other communities. We argue that at the root of this problem lies a
systematic tendency of technology developer communities to apply a simplistic
understanding of diversity which does not do justice to the more profound
differences that languages, and ultimately the communities that speak them,
embody. Drawing on the concept of epistemic injustice, we point to the broader
sociopolitical consequences of the bias we identify and show how it can lead
not only to a disregard for valuable aspects of diversity but also to an
under-representation of the needs and diverse worldviews of marginalized
language communities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13776">Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations. (arXiv:2307.13776v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Berend_G/0/1/0/all/0/1">G&#xe1;bor Berend</a></p>
<p>In this paper, we advocate for using large pre-trained monolingual language
models in cross lingual zero-shot word sense disambiguation (WSD) coupled with
a contextualized mapping mechanism. We also report rigorous experiments that
illustrate the effectiveness of employing sparse contextualized word
representations obtained via a dictionary learning procedure. Our experimental
results demonstrate that the above modifications yield a significant
improvement of nearly 6.5 points of increase in the average F-score (from 62.0
to 68.5) over a collection of 17 typologically diverse set of target languages.
We release our source code for replicating our experiments at
https://github.com/begab/sparsity_makes_sense.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13779">Is GPT a Computational Model of Emotion? Detailed Analysis. (arXiv:2307.13779v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tak_A/0/1/0/all/0/1">Ala N. Tak</a>, <a href="http://arxiv.org/find/cs/1/au:+Gratch_J/0/1/0/all/0/1">Jonathan Gratch</a></p>
<p>This paper investigates the emotional reasoning abilities of the GPT family
of large language models via a component perspective. The paper first examines
how the model reasons about autobiographical memories. Second, it
systematically varies aspects of situations to impact emotion intensity and
coping tendencies. Even without the use of prompt engineering, it is shown that
GPT's predictions align significantly with human-provided appraisals and
emotional labels. However, GPT faces difficulties predicting emotion intensity
and coping responses. GPT-4 showed the highest performance in the initial study
but fell short in the second, despite providing superior results after minor
prompt engineering. This assessment brings up questions on how to effectively
employ the strong points and address the weak areas of these models,
particularly concerning response variability. These studies underscore the
merits of evaluating models from a componential perspective.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13808">Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy. (arXiv:2307.13808v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1">Deyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yue Dong</a></p>
<p>To mitigate potential risks associated with language models, recent AI
detection research proposes incorporating watermarks into machine-generated
text through random vocabulary restrictions and utilizing this information for
detection. While these watermarks only induce a slight deterioration in
perplexity, our empirical investigation reveals a significant detriment to the
performance of conditional text generation. To address this issue, we introduce
a simple yet effective semantic-aware watermarking algorithm that considers the
characteristics of conditional text generation and the input context.
Experimental results demonstrate that our proposed method yields substantial
improvements across various text generation models, including BART and Flan-T5,
in tasks such as summarization and data-to-text generation while maintaining
detection ability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13829">ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal Methods Boosted by Ensemble Learning, Syntactical and Entity Features. (arXiv:2307.13829v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sahin_U/0/1/0/all/0/1">Umitcan Sahin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kucukkaya_I/0/1/0/all/0/1">Izzet Emre Kucukkaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozcelik_O/0/1/0/all/0/1">Oguzhan Ozcelik</a>, <a href="http://arxiv.org/find/cs/1/au:+Toraman_C/0/1/0/all/0/1">Cagri Toraman</a></p>
<p>Text-embedded images can serve as a means of spreading hate speech,
propaganda, and extremist beliefs. Throughout the Russia-Ukraine war, both
opposing factions heavily relied on text-embedded images as a vehicle for
spreading propaganda and hate speech. Ensuring the effective detection of hate
speech and propaganda is of utmost importance to mitigate the negative effect
of hate speech dissemination. In this paper, we outline our methodologies for
two subtasks of Multimodal Hate Speech Event Detection 2023. For the first
subtask, hate speech detection, we utilize multimodal deep learning models
boosted by ensemble learning and syntactical text attributes. For the second
subtask, target detection, we employ multimodal deep learning models boosted by
named entity features. Through experimentation, we demonstrate the superior
performance of our models compared to all textual, visual, and text-visual
baselines employed in multimodal hate speech detection. Furthermore, our models
achieve the first place in both subtasks on the final leaderboard of the shared
task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13854">WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuyan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Frank F. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xuhui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1">Robert Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1">Abishek Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xianyi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a>, <a href="http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1">Daniel Fried</a>, <a href="http://arxiv.org/find/cs/1/au:+Alon_U/0/1/0/all/0/1">Uri Alon</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a></p>
<p>With generative AI advances, the exciting potential for autonomous agents to
manage daily tasks via natural language commands has emerged. However, cur rent
agents are primarily created and tested in simplified synthetic environments,
substantially limiting real-world scenario representation. In this paper, we
build an environment for agent command and control that is highly realistic and
reproducible. Specifically, we focus on agents that perform tasks on websites,
and we create an environment with fully functional websites from four common
domains: e-commerce, social forum discussions, collaborative software
development, and content management. Our environment is enriched with tools
(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage
human-like task-solving. Building upon our environment, we release a set of
benchmark tasks focusing on evaluating the functional correctness of task
completions. The tasks in our benchmark are diverse, long-horizon, and are
designed to emulate tasks that humans routinely perform on the internet. We
design and implement several autonomous agents, integrating recent techniques
such as reasoning before acting. The results demonstrate that solving complex
tasks is challenging: our best GPT-4-based agent only achieves an end-to-end
task success rate of 10.59%. These results highlight the need for further
development of robust agents, that current state-of-the-art LMs are far from
perfect performance in these real-life tasks, and that WebArena can be used to
measure such progress. Our code, data, environment reproduction resources, and
video demonstrations are publicly available at https://webarena.dev/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13900">FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction. (arXiv:2307.13900v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ok_H/0/1/0/all/0/1">Hyunjong Ok</a></p>
<p>We present FinTree, Financial Dataset Pretrain Transformer Encoder for
Relation Extraction. Utilizing an encoder language model, we further pretrain
FinTree on the financial dataset, adapting the model in financial domain tasks.
FinTree stands out with its novel structure that predicts a masked token
instead of the conventional [CLS] token, inspired by the Pattern Exploiting
Training methodology. This structure allows for more accurate relation
predictions between two given entities. The model is trained with a unique
input pattern to provide contextual and positional information about the
entities of interest, and a post-processing step ensures accurate predictions
in line with the entity types. Our experiments demonstrate that FinTree
outperforms on the REFinD, a large-scale financial relation extraction dataset.
The code and pretrained models are available at
https://github.com/HJ-Ok/FinTree.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13923">GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning. (arXiv:2307.13923v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yaxin Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1">Feng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haizhou Li</a></p>
<p>Grammatical error correction aims to correct ungrammatical sentences
automatically. Recently, some work has demonstrated the excellent capabilities
of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical
error correction. However, the potential of open-source LLMs remains
unexplored. In this paper, we introduced GrammarGPT, an open-source LLM, to
preliminary explore its potential for native Chinese grammatical error
correction. The core recipe of GrammarGPT is to leverage the hybrid dataset of
ChatGPT-generated and human-annotated. For grammatical errors with clues, we
proposed a heuristic method to guide ChatGPT to generate ungrammatical
sentences by providing those clues. For grammatical errors without clues, we
collected ungrammatical sentences from publicly available websites and manually
corrected them. In addition, we employed an error-invariant augmentation method
to enhance the ability of the model to correct native Chinese grammatical
errors. We ultimately constructed about 1k parallel data and utilized these
data to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese
University of Hong Kong, Shenzhen) with instruction tuning. The experimental
results show that GrammarGPT outperforms the existing SOTA system
significantly. Although model parameters are 20x larger than the SOTA baseline,
the required amount of data for instruction tuning is 1200x smaller,
illustrating the potential of open-source LLMs on native CGEC. Our GrammarGPT
ranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's
effectiveness. The code and data are available at
\url{https://github.com/FreedomIntelligence/GrammarGPT}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13949">How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?. (arXiv:2307.13949v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huazheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1">Daixuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haifeng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1">Jianxin Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Cong Liu</a></p>
<p>Transformer-based pretrained language models (PLMs) have achieved great
success in modern NLP. An important advantage of PLMs is good
out-of-distribution (OOD) robustness. Recently, diffusion models have attracted
a lot of work to apply diffusion to PLMs. It remains under-explored how
diffusion influences PLMs on OOD data. The core of diffusion models is a
forward diffusion process which gradually applies Gaussian noise to inputs, and
a reverse denoising process which removes noise. The noised input
reconstruction is a fundamental ability of diffusion models. We directly
analyze OOD robustness by measuring the reconstruction loss, including testing
the abilities to reconstruct OOD data, and to detect OOD samples. Experiments
are conducted by analyzing different training parameters and data statistical
features on eight datasets. It shows that finetuning PLMs with diffusion
degrades the reconstruction ability on OOD data. The comparison also shows that
diffusion models can effectively detect OOD samples, achieving state-of-the-art
performance in most of the datasets with an absolute accuracy improvement up to
18%. These results indicate that diffusion reduces OOD robustness of PLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13989">This is not correct! Negation-aware Evaluation of Language Generation Systems. (arXiv:2307.13989v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anschutz_M/0/1/0/all/0/1">Miriam Ansch&#xfc;tz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozano_D/0/1/0/all/0/1">Diego Miguel Lozano</a>, <a href="http://arxiv.org/find/cs/1/au:+Groh_G/0/1/0/all/0/1">Georg Groh</a></p>
<p>Large language models underestimate the impact of negations on how much they
change the meaning of a sentence. Therefore, learned evaluation metrics based
on these models are insensitive to negations. In this paper, we propose
NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that,
we designed a rule-based sentence negation tool and used it to create the
CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a
sentence transformer and an evaluation metric to improve their negation
sensitivity. Evaluating these models on existing benchmarks shows that our
fine-tuned models outperform existing metrics on the negated sentences by far
while preserving their base models' performances on other perturbations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14004">Affective Natural Language Generation of Event Descriptions through Fine-grained Appraisal Conditions. (arXiv:2307.14004v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Resendiz_Y/0/1/0/all/0/1">Yarik Menchaca Resendiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1">Roman Klinger</a></p>
<p>Models for affective text generation have shown a remarkable progress, but
they commonly rely only on basic emotion theories or valance/arousal values as
conditions. This is appropriate when the goal is to create explicit emotion
statements ("The kid is happy."). Emotions are, however, commonly communicated
implicitly. For instance, the emotional interpretation of an event ("Their dog
died.") does often not require an explicit emotion statement. In psychology,
appraisal theories explain the link between a cognitive evaluation of an event
and the potentially developed emotion. They put the assessment of the situation
on the spot, for instance regarding the own control or the responsibility for
what happens. We hypothesize and subsequently show that including appraisal
variables as conditions in a generation framework comes with two advantages.
(1) The generation model is informed in greater detail about what makes a
specific emotion and what properties it has. This leads to text generation that
better fulfills the condition. (2) The variables of appraisal allow a user to
perform a more fine-grained control of the generated text, by stating
properties of a situation instead of only providing the emotion category. Our
Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt,
Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control,
Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals
during training improves the accurateness of the generated texts by 10 pp in
F1. Further, (2) the texts with appraisal variables are longer and contain more
details. This exemplifies the greater control for users.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14005">Unsupervised extraction of local and global keywords from a single text. (arXiv:2307.14005v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aleksanyan_L/0/1/0/all/0/1">Lida Aleksanyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Allahverdyan_A/0/1/0/all/0/1">Armen E. Allahverdyan</a></p>
<p>We propose an unsupervised, corpus-independent method to extract keywords
from a single text. It is based on the spatial distribution of words and the
response of this distribution to a random permutation of words. As compared to
existing methods (such as e.g. YAKE) our method has three advantages. First, it
is significantly more effective at extracting keywords from long texts. Second,
it allows inference of two types of keywords: local and global. Third, it
uncovers basic themes in texts. Additionally, our method is
language-independent and applies to short texts. The results are obtained via
human annotators with previous knowledge of texts from our database of
classical literary works (the agreement between annotators is from moderate to
substantial). Our results are supported via human-independent arguments based
on the average length of extracted content words and on the average number of
nouns in extracted words. We discuss relations of keywords with higher-order
textual features and reveal a connection between keywords and chapter
divisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14031">Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems. (arXiv:2307.14031v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songbo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Han Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hergul_M/0/1/0/all/0/1">Mete Hergul</a>, <a href="http://arxiv.org/find/cs/1/au:+Gritta_M/0/1/0/all/0/1">Milan Gritta</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guchun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Iacobacci_I/0/1/0/all/0/1">Ignacio Iacobacci</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a></p>
<p>Creating high-quality annotated data for task-oriented dialog (ToD) is known
to be notoriously difficult, and the challenges are amplified when the goal is
to create equitable, culturally adapted, and large-scale ToD datasets for
multiple languages. Therefore, the current datasets are still very scarce and
suffer from limitations such as translation-based non-native dialogs with
translation artefacts, small scale, or lack of cultural adaptation, among
others. In this work, we first take stock of the current landscape of
multilingual ToD datasets, offering a systematic overview of their properties
and limitations. Aiming to reduce all the detected limitations, we then
introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD
dataset. It is large-scale and offers culturally adapted dialogs in 4 languages
to enable training and evaluation of multilingual and cross-lingual ToD
systems. We describe a complex bottom-up data collection process that yielded
the final dataset, and offer the first sets of baseline scores across different
ToD-related tasks for future reference, also highlighting its challenging
nature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14107">Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions. (arXiv:2307.14107v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sohail_S/0/1/0/all/0/1">Shahab Saquib Sohail</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhat_F/0/1/0/all/0/1">Faiza Farhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Himeur_Y/0/1/0/all/0/1">Yassine Himeur</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_M/0/1/0/all/0/1">Mohammad Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Madsen_D/0/1/0/all/0/1">Dag &#xd8;ivind Madsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_Y/0/1/0/all/0/1">Yashbir Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Atalla_S/0/1/0/all/0/1">Shadi Atalla</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansoor_W/0/1/0/all/0/1">Wathiq Mansoor</a></p>
<p>Chat Generative Pre-trained Transformer (ChatGPT) has gained significant
interest and attention since its launch in November 2022. It has shown
impressive performance in various domains, including passing exams and creative
writing. However, challenges and concerns related to biases and trust persist.
In this work, we present a comprehensive review of over 100 Scopus-indexed
publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and
explore its applications. We critically analyze the existing literature,
identifying common approaches employed in the studies. Additionally, we
investigate diverse application areas where ChatGPT has found utility, such as
healthcare, marketing and financial services, software engineering, academic
and scientific writing, research and education, environmental science, and
natural language processing. Through examining these applications, we gain
valuable insights into the potential of ChatGPT in addressing real-world
challenges. We also discuss crucial issues related to ChatGPT, including biases
and trustworthiness, emphasizing the need for further research and development
in these areas. Furthermore, we identify potential future directions for
ChatGPT research, proposing solutions to current challenges and speculating on
expected advancements. By fully leveraging the capabilities of ChatGPT, we can
unlock its potential across various domains, leading to advancements in
conversational AI and transformative impacts in society.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14117">Leveraging Implicit Feedback from Deployment Data in Dialogue. (arXiv:2307.14117v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Richard Yuanzhe Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a></p>
<p>We study improving social conversational agents by learning from natural
dialogue between users and a deployed model, without extra annotations. To
implicitly measure the quality of a machine-generated utterance, we leverage
signals like user response length, sentiment and reaction of the future human
utterances in the collected dialogue episodes. Our experiments use the publicly
released deployment data from BlenderBot (Xu et al., 2023). Human evaluation
indicates improvements in our new models over baseline responses; however, we
find that some proxy signals can lead to more generations with undesirable
properties as well. For example, optimizing for conversation length can lead to
more controversial or unfriendly generations compared to the baseline, whereas
optimizing for positive sentiment or reaction can decrease these behaviors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14132">Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition. (arXiv:2307.14132v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tian-Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dinghao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhon_G/0/1/0/all/0/1">Guiping Zhon</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baoxiang Li</a></p>
<p>RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve
length alignment between input audio and target sequence. However, the
implementation complexity and the alignment-based optimization target of RNN-T
loss lead to computational redundancy and a reduced role for predictor network,
respectively. In this paper, we propose a novel model named CIF-Transducer
(CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism
with the RNN-T model to achieve efficient alignment. In this way, the RNN-T
loss is abandoned, thus bringing a computational reduction and allowing the
predictor network a more significant role. We also introduce Funnel-CIF,
Context Blocks, Unified Gating and Bilinear Pooling joint network, and
auxiliary training strategy to further improve performance. Experiments on the
178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves
state-of-the-art results with lower computational overhead compared to RNN-T
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14134">Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models. (arXiv:2307.14134v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kesgin_H/0/1/0/all/0/1">Himmet Toprak Kesgin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuce_M/0/1/0/all/0/1">Muzaffer Kaan Yuce</a>, <a href="http://arxiv.org/find/cs/1/au:+Amasyali_M/0/1/0/all/0/1">Mehmet Fatih Amasyali</a></p>
<p>This study introduces and evaluates tiny, mini, small, and medium-sized
uncased Turkish BERT models, aiming to bridge the research gap in
less-resourced languages. We trained these models on a diverse dataset
encompassing over 75GB of text from multiple sources and tested them on several
tasks, including mask prediction, sentiment analysis, news classification, and,
zero-shot classification. Despite their smaller size, our models exhibited
robust performance, including zero-shot task, while ensuring computational
efficiency and faster execution times. Our findings provide valuable insights
into the development and application of smaller language models, especially in
the context of the Turkish language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14142">LOIS: Looking Out of Instance Semantics for Visual Question Answering. (arXiv:2307.14142v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Siyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yeming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yaoru Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haibo Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoran Wang</a></p>
<p>Visual question answering (VQA) has been intensively studied as a multimodal
task that requires effort in bridging vision and language to infer answers
correctly. Recent attempts have developed various attention-based modules for
solving VQA tasks. However, the performance of model inference is largely
bottlenecked by visual processing for semantics understanding. Most existing
detection methods rely on bounding boxes, remaining a serious challenge for VQA
models to understand the causal nexus of object semantics in images and
correctly infer contextual information. To this end, we propose a finer model
framework without bounding boxes in this work, termed Looking Out of Instance
Semantics (LOIS) to tackle this important issue. LOIS enables more fine-grained
feature descriptions to produce visual facts. Furthermore, to overcome the
label ambiguity caused by instance masks, two types of relation attention
modules: 1) intra-modality and 2) inter-modality, are devised to infer the
correct answers from the different multi-view features. Specifically, we
implement a mutual relation attention module to model sophisticated and deeper
visual semantic relations between instance objects and background information.
In addition, our proposed attention model can further analyze salient image
regions by focusing on important word-related questions. Experimental results
on four benchmark VQA datasets prove that our proposed method has favorable
performance in improving visual reasoning capability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14236">UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text. (arXiv:2307.14236v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ningrum_P/0/1/0/all/0/1">Panggih Kusuma Ningrum</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayr_P/0/1/0/all/0/1">Philipp Mayr</a>, <a href="http://arxiv.org/find/cs/1/au:+Atanassova_I/0/1/0/all/0/1">Iana Atanassova</a></p>
<p>This demo paper presents UnScientify, an interactive system designed to
detect scientific uncertainty in scholarly full text. The system utilizes a
weakly supervised technique that employs a fine-grained annotation scheme to
identify verbally formulated uncertainty at the sentence level in scientific
texts. The pipeline for the system includes a combination of pattern matching,
complex sentence checking, and authorial reference checking. Our approach
automates labeling and annotation tasks for scientific uncertainty
identification, taking into account different types of scientific uncertainty,
that can serve various applications such as information retrieval, text mining,
and scholarly document processing. Additionally, UnScientify provides
interpretable results, aiding in the comprehension of identified instances of
scientific uncertainty in text.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14291">Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects. (arXiv:2307.14291v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lazzizzera_I/0/1/0/all/0/1">I. Lazzizzera</a></p>
<p>We take as a case study the spread of Germanic syntactic features into
Romance dialects of North-Eastern Italy, which occurred after the immigration
of German people in the Tyrol during the High Middle Ages.
</p>
<p>An interactive map is produced using tools of what is called Geographic Data
Science. A smooth two-dimensional surface $\mathcal{G}$ expresses locally which
fraction of territory uses a given German language feature: it is obtained by
interpolating a discrete function that says if at any surveyed locality that
feature is used or not.\newline
</p>
<p>This surface $\mathcal{G}$ is thought of as the value at the present time of
a function describing a diffusion-convection phenomenon in two dimensions (here
said \emph{tidal} mode), which is subjected in a very natural way to the same
equation, suitably contextualized, used in physics for a number of
phenomenological facts like the heat diffusion. It is shown that solutions of
this equation, evaluated at the present time, fit well with the data as
interpolated by $\mathcal{G}$, thus providing convincing pictures of
diffusion-convection of the linguistic features of the case study, albeit
simplifications and approximations.\newline
</p>
<p>Very importantly, it is shown that Schmidt's 'waves' can be counted among the
solutions of the diffusion equation: superimposing Schmidt 'waves' to a 'tidal
flooding' can reproduce complexities of real linguistic diffusion events.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14298">ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality. (arXiv:2307.14298v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Remountakis_M/0/1/0/all/0/1">Manolis Remountakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotis_K/0/1/0/all/0/1">Konstantinos Kotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kourtzis_B/0/1/0/all/0/1">Babis Kourtzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsekouras_G/0/1/0/all/0/1">George E. Tsekouras</a></p>
<p>Recommender systems have become indispensable tools in the hotel hospitality
industry, enabling personalized and tailored experiences for guests. Recent
advancements in large language models (LLMs), such as ChatGPT, and persuasive
technologies, have opened new avenues for enhancing the effectiveness of those
systems. This paper explores the potential of integrating ChatGPT and
persuasive technologies for automating and improving hotel hospitality
recommender systems. First, we delve into the capabilities of ChatGPT, which
can understand and generate human-like text, enabling more accurate and
context-aware recommendations. We discuss the integration of ChatGPT into
recommender systems, highlighting the ability to analyze user preferences,
extract valuable insights from online reviews, and generate personalized
recommendations based on guest profiles. Second, we investigate the role of
persuasive technology in influencing user behavior and enhancing the persuasive
impact of hotel recommendations. By incorporating persuasive techniques, such
as social proof, scarcity and personalization, recommender systems can
effectively influence user decision-making and encourage desired actions, such
as booking a specific hotel or upgrading their room. To investigate the
efficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment
with a case study involving a hotel recommender system. We aim to study the
impact of integrating ChatGPT and persua-sive techniques on user engagement,
satisfaction, and conversion rates. The preliminary results demonstrate the
potential of these technologies in enhancing the overall guest experience and
business performance. Overall, this paper contributes to the field of hotel
hospitality by exploring the synergistic relationship between LLMs and
persuasive technology in recommender systems, ultimately influencing guest
satisfaction and hotel revenue.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14305">Automatically Evaluating Opinion Prevalence in Opinion Summarization. (arXiv:2307.14305v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malon_C/0/1/0/all/0/1">Christopher Malon</a></p>
<p>When faced with a large number of product reviews, it is not clear that a
human can remember all of them and weight opinions representatively to write a
good reference summary. We propose an automatic metric to test the prevalence
of the opinions that a summary expresses, based on counting the number of
reviews that are consistent with each statement in the summary, while
discrediting trivial or redundant statements. To formulate this opinion
prevalence metric, we consider several existing methods to score the factual
consistency of a summary statement with respect to each individual source
review. On a corpus of Amazon product reviews, we gather multiple human
judgments of the opinion consistency, to determine which automatic metric best
expresses consistency in product reviews. Using the resulting opinion
prevalence metric, we show that a human authored summary has only slightly
better opinion prevalence than randomly selected extracts from the source
reviews, and previous extractive and abstractive unsupervised opinion
summarization methods perform worse than humans. We demonstrate room for
improvement with a greedy construction of extractive summaries with twice the
opinion prevalence achieved by humans. Finally, we show that preprocessing
source reviews by simplification can raise the opinion prevalence achieved by
existing abstractive opinion summarization systems to the level of human
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14311">Comparative Analysis of Libraries for the Sentimental Analysis. (arXiv:2307.14311v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ccoya_W/0/1/0/all/0/1">Wendy Ccoya</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_E/0/1/0/all/0/1">Edson Pinto</a></p>
<p>This study is main goal is to provide a comparative comparison of libraries
using machine learning methods. Experts in natural language processing (NLP)
are becoming more and more interested in sentiment analysis (SA) of text
changes. The objective of employing NLP text analysis techniques is to
recognize and categorize feelings related to twitter users utterances. In this
examination, issues with SA and the libraries utilized are also looked at.
provides a number of cooperative methods to classify emotional polarity. The
Naive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn
Classifier, Sklearn Classifier MultinomialNB, and other conjoint learning
algorithms, according to recent research, are very effective. In the project
will use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT
and BERT pretrained), and Tidytext will be used in the study to apply sentiment
analysis techniques. Four machine learning models Tree of Decisions (DT),
Support Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN)
will also be used. To evaluate how well libraries for SA operate in the social
network environment, comparative study was also carried out. The measures to
assess the best algorithms in this experiment, which used a single data set for
each method, were precision, recall, and F1 score. We conclude that the BERT
transformer method with an Accuracy: 0.973 is recommended for sentiment
analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14324">Evaluating the Moral Beliefs Encoded in LLMs. (arXiv:2307.14324v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Scherrer_N/0/1/0/all/0/1">Nino Scherrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Claudia Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1">David M. Blei</a></p>
<p>This paper presents a case study on the design, administration,
post-processing, and evaluation of surveys on large language models (LLMs). It
comprises two components: (1) A statistical method for eliciting beliefs
encoded in LLMs. We introduce statistical measures and evaluation metrics that
quantify the probability of an LLM "making a choice", the associated
uncertainty, and the consistency of that choice. (2) We apply this method to
study what moral beliefs are encoded in different LLMs, especially in ambiguous
cases where the right choice is not obvious. We design a large-scale survey
comprising 680 high-ambiguity moral scenarios (e.g., "Should I tell a white
lie?") and 687 low-ambiguity moral scenarios (e.g., "Should I stop for a
pedestrian on the road?"). Each scenario includes a description, two possible
actions, and auxiliary labels indicating violated rules (e.g., "do not kill").
We administer the survey to 28 open- and closed-source LLMs. We find that (a)
in unambiguous scenarios, most models "choose" actions that align with
commonsense. In ambiguous cases, most models express uncertainty. (b) Some
models are uncertain about choosing the commonsense action because their
responses are sensitive to the question-wording. (c) Some models reflect clear
preferences in ambiguous scenarios. Specifically, closed-source models tend to
agree with each other.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14334">Towards Generalist Biomedical AI. (arXiv:2307.14334v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tu_T/0/1/0/all/0/1">Tao Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Azizi_S/0/1/0/all/0/1">Shekoofeh Azizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Driess_D/0/1/0/all/0/1">Danny Driess</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaekermann_M/0/1/0/all/0/1">Mike Schaekermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1">Mohamed Amin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1">Pi-Chuan Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Carroll_A/0/1/0/all/0/1">Andrew Carroll</a>, <a href="http://arxiv.org/find/cs/1/au:+Lau_C/0/1/0/all/0/1">Chuck Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanno_R/0/1/0/all/0/1">Ryutaro Tanno</a>, <a href="http://arxiv.org/find/cs/1/au:+Ktena_I/0/1/0/all/0/1">Ira Ktena</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1">Basil Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1">Aakanksha Chowdhery</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1">Simon Kornblith</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansfield_P/0/1/0/all/0/1">Philip Mansfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1">Sushant Prakash</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1">Renee Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Virmani_S/0/1/0/all/0/1">Sunny Virmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Semturs_C/0/1/0/all/0/1">Christopher Semturs</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_S/0/1/0/all/0/1">S Sara Mahdavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Green_B/0/1/0/all/0/1">Bradley Green</a>, <a href="http://arxiv.org/find/cs/1/au:+Dominowska_E/0/1/0/all/0/1">Ewa Dominowska</a>, <a href="http://arxiv.org/find/cs/1/au:+Arcas_B/0/1/0/all/0/1">Blaise Aguera y Arcas</a>, <a href="http://arxiv.org/find/cs/1/au:+Barral_J/0/1/0/all/0/1">Joelle Barral</a>, <a href="http://arxiv.org/find/cs/1/au:+Webster_D/0/1/0/all/0/1">Dale Webster</a>, <a href="http://arxiv.org/find/cs/1/au:+Corrado_G/0/1/0/all/0/1">Greg S. Corrado</a>, <a href="http://arxiv.org/find/cs/1/au:+Matias_Y/0/1/0/all/0/1">Yossi Matias</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1">Karan Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1">Pete Florence</a>, <a href="http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1">Alan Karthikesalingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Natarajan_V/0/1/0/all/0/1">Vivek Natarajan</a></p>
<p>Medicine is inherently multimodal, with rich data modalities spanning text,
imaging, genomics, and more. Generalist biomedical artificial intelligence (AI)
systems that flexibly encode, integrate, and interpret this data at scale can
potentially enable impactful applications ranging from scientific discovery to
care delivery. To enable the development of these models, we first curate
MultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses
14 diverse tasks such as medical question answering, mammography and
dermatology image interpretation, radiology report generation and
summarization, and genomic variant calling. We then introduce Med-PaLM
Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI
system. Med-PaLM M is a large multimodal generative model that flexibly encodes
and interprets biomedical data including clinical language, imaging, and
genomics with the same set of model weights. Med-PaLM M reaches performance
competitive with or exceeding the state of the art on all MultiMedBench tasks,
often surpassing specialist models by a wide margin. We also report examples of
zero-shot generalization to novel medical concepts and tasks, positive transfer
learning across tasks, and emergent zero-shot medical reasoning. To further
probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist
evaluation of model-generated (and human) chest X-ray reports and observe
encouraging performance across model scales. In a side-by-side ranking on 246
retrospective chest X-rays, clinicians express a pairwise preference for
Med-PaLM M reports over those produced by radiologists in up to 40.50% of
cases, suggesting potential clinical utility. While considerable work is needed
to validate these models in real-world use cases, our results represent a
milestone towards the development of generalist biomedical AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.11483">A Comprehensive Comparison of Pre-training Language Models. (arXiv:2106.11483v9 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1">Tong Guo</a></p>
<p>Recently, the development of pre-trained language models has brought natural
language processing (NLP) tasks to the new state-of-the-art. In this paper we
explore the efficiency of various pre-trained language models. We pre-train a
list of transformer-based models with the same amount of text and the same
training steps. The experimental results shows that the most improvement upon
the origin BERT is adding the RNN-layer to capture more contextual information
for short text understanding. But the conclusion is: There are no remarkable
improvement for short text understanding for similar BERT structures.
Data-centric method[12] can achieve better performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.12645">Exploring Multi-Modal Representations for Ambiguity Detection &amp; Coreference Resolution in the SIMMC 2.0 Challenge. (arXiv:2202.12645v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chiyah_Garcia_J/0/1/0/all/0/1">Javier Chiyah-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Suglia_A/0/1/0/all/0/1">Alessandro Suglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopes_J/0/1/0/all/0/1">Jos&#xe9; Lopes</a>, <a href="http://arxiv.org/find/cs/1/au:+Eshghi_A/0/1/0/all/0/1">Arash Eshghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hastie_H/0/1/0/all/0/1">Helen Hastie</a></p>
<p>Anaphoric expressions, such as pronouns and referential descriptions, are
situated with respect to the linguistic context of prior turns, as well as, the
immediate visual environment. However, a speaker's referential descriptions do
not always uniquely identify the referent, leading to ambiguities in need of
resolution through subsequent clarificational exchanges. Thus, effective
Ambiguity Detection and Coreference Resolution are key to task success in
Conversational AI. In this paper, we present models for these two tasks as part
of the SIMMC 2.0 Challenge (Kottur et al. 2021). Specifically, we use TOD-BERT
and LXMERT based models, compare them to a number of baselines and provide
ablation experiments. Our results show that (1) language models are able to
exploit correlations in the data to detect ambiguity; and (2) unimodal
coreference resolution models can avoid the need for a vision component,
through the use of smart object representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.13192">Direct Speech Translation for Automatic Subtitling. (arXiv:2209.13192v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Papi_S/0/1/0/all/0/1">Sara Papi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaido_M/0/1/0/all/0/1">Marco Gaido</a>, <a href="http://arxiv.org/find/cs/1/au:+Karakanta_A/0/1/0/all/0/1">Alina Karakanta</a>, <a href="http://arxiv.org/find/cs/1/au:+Cettolo_M/0/1/0/all/0/1">Mauro Cettolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1">Matteo Negri</a>, <a href="http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1">Marco Turchi</a></p>
<p>Automatic subtitling is the task of automatically translating the speech of
audiovisual content into short pieces of timed text, i.e. subtitles and their
corresponding timestamps. The generated subtitles need to conform to space and
time requirements, while being synchronised with the speech and segmented in a
way that facilitates comprehension. Given its considerable complexity, the task
has so far been addressed through a pipeline of components that separately deal
with transcribing, translating, and segmenting text into subtitles, as well as
predicting timestamps. In this paper, we propose the first direct ST model for
automatic subtitling that generates subtitles in the target language along with
their timestamps with a single model. Our experiments on 7 language pairs show
that our approach outperforms a cascade system in the same data condition, also
being competitive with production tools on both in-domain and newly-released
out-domain benchmarks covering new scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.12247">Quantifying &amp; Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Paul Pu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1">Chun Kai Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1">Suzanne Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Richard Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zihao Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Allen_N/0/1/0/all/0/1">Nicholas Allen</a>, <a href="http://arxiv.org/find/cs/1/au:+Auerbach_R/0/1/0/all/0/1">Randy Auerbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1">Faisal Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1">Louis-Philippe Morency</a></p>
<p>The recent explosion of interest in multimodal applications has resulted in a
wide selection of datasets and methods for representing and integrating
information from different modalities. Despite these empirical advances, there
remain fundamental research questions: How can we quantify the interactions
that are necessary to solve a multimodal task? Subsequently, what are the most
suitable multimodal models to capture these interactions? To answer these
questions, we propose an information-theoretic approach to quantify the degree
of redundancy, uniqueness, and synergy relating input modalities with an output
task. We term these three measures as the PID statistics of a multimodal
distribution (or PID for short), and introduce two new estimators for these PID
statistics that scale to high-dimensional distributions. To validate PID
estimation, we conduct extensive experiments on both synthetic datasets where
the PID is known and on large-scale multimodal benchmarks where PID estimations
are compared with human annotations. Finally, we demonstrate their usefulness
in (1) quantifying interactions within multimodal datasets, (2) quantifying
interactions captured by multimodal models, (3) principled approaches for model
selection, and (4) three real-world case studies engaging with domain experts
in pathology, mood prediction, and robotic perception where our framework helps
to recommend strong multimodal models for each application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00017">Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saba_W/0/1/0/all/0/1">Walid S. Saba</a></p>
<p>Large language models (LLMs) have achieved a milestone that undenia-bly
changed many held beliefs in artificial intelligence (AI). However, there
remains many limitations of these LLMs when it comes to true language
understanding, limitations that are a byproduct of the under-lying architecture
of deep neural networks. Moreover, and due to their subsymbolic nature,
whatever knowledge these models acquire about how language works will always be
buried in billions of microfeatures (weights), none of which is meaningful on
its own, making such models hopelessly unexplainable. To address these
limitations, we suggest com-bining the strength of symbolic representations
with what we believe to be the key to the success of LLMs, namely a successful
bottom-up re-verse engineering of language at scale. As such we argue for a
bottom-up reverse engineering of language in a symbolic setting. Hints on what
this project amounts to have been suggested by several authors, and we discuss
in some detail here how this project could be accomplished.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02115">Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models. (arXiv:2306.02115v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kamigaito_H/0/1/0/all/0/1">Hidetaka Kamigaito</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1">Katsuhiko Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1">Taro Watanabe</a></p>
<p>In this paper, we propose a table and image generation task to verify how the
knowledge about entities acquired from natural language is retained in Vision &amp;
Language (V&amp;L) models. This task consists of two parts: the first is to
generate a table containing knowledge about an entity and its related image,
and the second is to generate an image from an entity with a caption and a
table containing related knowledge of the entity. In both tasks, the model must
know the entities used to perform the generation properly. We created the
Wikipedia Table and Image Generation (WikiTIG) dataset from about 200,000
infoboxes in English Wikipedia articles to perform the proposed tasks. We
evaluated the performance on the tasks with respect to the above research
question using the V&amp;L model OFA, which has achieved state-of-the-art results
in multiple tasks. Experimental results show that OFA forgets part of its
entity knowledge by pre-training as a complement to improve the performance of
image related tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02377">&quot;Are you telling me to put glasses on the dog?&#x27;&#x27; Content-Grounded Annotation of Instruction Clarification Requests in the CoDraw Dataset. (arXiv:2306.02377v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madureira_B/0/1/0/all/0/1">Brielen Madureira</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlangen_D/0/1/0/all/0/1">David Schlangen</a></p>
<p>Instruction Clarification Requests are a mechanism to solve communication
problems, which is very functional in instruction-following interactions.
Recent work has argued that the CoDraw dataset is a valuable source of
naturally occurring iCRs. Beyond identifying when iCRs should be made, dialogue
models should also be able to generate them with suitable form and content. In
this work, we introduce CoDraw-iCR (v2), extending the existing iCR identifiers
with fine-grained information grounded in the underlying dialogue game items
and possible actions. Our annotation can serve to model and evaluate repair
capabilities of dialogue agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03506">Derivative Free Weight-space Ensembling. (arXiv:2307.03506v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ninalga_D/0/1/0/all/0/1">Dean Ninalga</a></p>
<p>Recent work suggests that interpolating between the weights of two
specialized language models can transfer knowledge between tasks in a way that
multi-task learning cannot. However, very few have explored interpolation
between more than two models, where each has a distinct knowledge base. In this
paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new
few-sample task transfer approach for open-domain dialogue. Our framework
creates a set of diverse expert language models trained using a predefined set
of source tasks. Next, we finetune each of the expert models on the target
task, approaching the target task from several distinct knowledge bases.
Finally, we linearly interpolate between the model weights using a
gradient-free-optimization algorithm, to efficiently find a good interpolation
weighting. We demonstrate the effectiveness of the method on FETA-Friends
outperforming the standard pretrain-finetune approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04192">SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering. (arXiv:2307.04192v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1">Min-Yen Kan</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a></p>
<p>Video question--answering is a fundamental task in the field of video
understanding. Although current vision--language models (VLMs) equipped with
Video Transformers have enabled temporal modeling and yielded superior results,
they are at the cost of huge computational power and thus too expensive to
deploy in real-time application scenarios. An economical workaround only
samples a small portion of frames to represent the main content of that video
and tune an image--text model on these sampled frames. Recent video
understanding models usually randomly sample a set of frames or clips,
regardless of internal correlations between their visual contents, nor their
relevance to the problem. We argue that such kinds of aimless sampling may omit
the key frames from which the correct answer can be deduced, and the situation
gets worse when the sampling sparsity increases, which always happens as the
video lengths increase. To mitigate this issue, we propose two frame sampling
strategies, namely the most domain frames (MDF) and most implied frames (MIF),
to maximally preserve those frames that are most likely vital to the given
questions. MDF passively minimizes the risk of key frame omission in a
bootstrap manner, while MIS actively searches key frames customized for each
video--question pair with the assistance of auxiliary models. The experimental
results on three public datasets from three advanced VLMs (CLIP, GIT and
All-in-one) demonstrate that our proposed strategies can boost the performance
for image--text pretrained models. The source codes pertaining to the method
proposed in this paper are publicly available at
https://github.com/declare-lab/sas-vqa.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06281">MMBench: Is Your Multi-modal Model an All-around Player?. (arXiv:2307.06281v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_H/0/1/0/all/0/1">Haodong Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuanhan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wangbo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yike Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Conghui He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a></p>
<p>Large vision-language models have recently achieved remarkable progress,
exhibiting great perception and reasoning abilities concerning visual
information. However, how to effectively evaluate these large vision-language
models remains a major obstacle, hindering future model development.
Traditional benchmarks like VQAv2 or COCO Caption provide quantitative
performance measurements but suffer from a lack of fine-grained ability
assessment and non-robust evaluation metrics. Recent subjective benchmarks,
such as OwlEval, offer comprehensive evaluations of a model's abilities by
incorporating human labor, but they are not scalable and display significant
bias. In response to these challenges, we propose MMBench, a novel
multi-modality benchmark. MMBench methodically develops a comprehensive
evaluation pipeline, primarily comprised of two elements. The first element is
a meticulously curated dataset that surpasses existing similar benchmarks in
terms of the number and variety of evaluation questions and abilities. The
second element introduces a novel CircularEval strategy and incorporates the
use of ChatGPT. This implementation is designed to convert free-form
predictions into pre-defined choices, thereby facilitating a more robust
evaluation of the model's predictions. MMBench is a systematically-designed
objective benchmark for robustly evaluating the various abilities of
vision-language models. We hope MMBench will assist the research community in
better evaluating their models and encourage future advancements in this
domain. Project page: https://opencompass.org.cn/mmbench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06440">No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1">Jean Kaddour</a>, <a href="http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1">Oscar Key</a>, <a href="http://arxiv.org/find/cs/1/au:+Nawrot_P/0/1/0/all/0/1">Piotr Nawrot</a>, <a href="http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1">Pasquale Minervini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a></p>
<p>The computation necessary for training Transformer-based language models has
skyrocketed in recent years. This trend has motivated research on efficient
training algorithms designed to improve training, validation, and downstream
performance faster than standard training. In this work, we revisit three
categories of such algorithms: dynamic architectures (layer stacking, layer
dropping), batch selection (selective backprop, RHO loss), and efficient
optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed
computation budget using such methods, we find that their training, validation,
and downstream gains vanish compared to a baseline with a fully-decayed
learning rate. We define an evaluation protocol that enables computation to be
done on arbitrary machines by mapping all computation time to a reference
machine which we call reference system time. We discuss the limitations of our
proposed protocol and release our code to encourage rigorous research in
efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08072">Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study. (arXiv:2307.08072v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peiyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zikang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Ze-Feng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1">Dawei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1">Bolin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a></p>
<p>Despite the superior performance, Large Language Models~(LLMs) require
significant computational resources for deployment and use. To overcome this
issue, quantization methods have been widely applied to reduce the memory
footprint of LLMs as well as increasing the inference rate. However, a major
challenge is that low-bit quantization methods often lead to performance
degradation. It is important to understand how quantization impacts the
capacity of LLMs. Different from previous studies focused on overall
performance, this work aims to investigate the impact of quantization on
\emph{emergent abilities}, which are important characteristics that distinguish
LLMs from small language models. Specially, we examine the abilities of
in-context learning, chain-of-thought reasoning, and instruction-following in
quantized LLMs. Our empirical experiments show that these emergent abilities
still exist in 4-bit quantization models, while 2-bit models encounter severe
performance degradation on the test of these abilities. To improve the
performance of low-bit models, we conduct two special experiments: (1)
fine-gained impact analysis that studies which components (or substructures)
are more sensitive to quantization, and (2) performance compensation through
model fine-tuning. Our work derives a series of important findings to
understand the impact of quantization on emergent abilities, and sheds lights
on the possibilities of extremely low-bit quantization for LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10930">MediaGPT : A Large Language Model For Chinese Media. (arXiv:2307.10930v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhonghao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zijia Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1">Bo Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1">Haiying Deng</a></p>
<p>Large language models (LLMs) have shown remarkable capabilities in generating
high-quality text and making predictions based on large amounts of data,
including the media domain. However, in practical applications, the differences
between the media's use cases and the general-purpose applications of LLMs have
become increasingly apparent, especially Chinese. This paper examines the
unique characteristics of media-domain-specific LLMs compared to general LLMs,
designed a diverse set of task instruction types to cater the specific
requirements of the domain and constructed unique datasets that are tailored to
the media domain. Based on these, we proposed MediaGPT, a domain-specific LLM
for the Chinese media domain, training by domain-specific data and experts SFT
data. By performing human experts evaluation and strong model evaluation on a
validation set, this paper demonstrated that MediaGPT outperforms mainstream
models on various Chinese media domain tasks and verifies the importance of
domain data and domain-defined prompt types for building an effective
domain-specific LLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13528">FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios. (arXiv:2307.13528v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chern_I/0/1/0/all/0/1">I-Chun Chern</a>, <a href="http://arxiv.org/find/cs/1/au:+Chern_S/0/1/0/all/0/1">Steffi Chern</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shiqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_K/0/1/0/all/0/1">Kehua Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chunting Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Junxian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a></p>
<p>The emergence of generative pre-trained models has facilitated the synthesis
of high-quality text, but it has also posed challenges in identifying factual
errors in the generated text. In particular: (1) A wider range of tasks now
face an increasing risk of containing factual errors when handled by generative
models. (2) Generated texts tend to be lengthy and lack a clearly defined
granularity for individual facts. (3) There is a scarcity of explicit evidence
available during the process of fact checking. With the above challenges in
mind, in this paper, we propose FacTool, a task and domain agnostic framework
for detecting factual errors of texts generated by large language models (e.g.,
ChatGPT). Experiments on four different tasks (knowledge-based QA, code
generation, mathematical reasoning, and scientific literature review) show the
efficacy of the proposed method. We release the code of FacTool associated with
ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13617">GPT-3 Models are Few-Shot Financial Reasoners. (arXiv:2307.13617v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Padua_R/0/1/0/all/0/1">Raul Salles de Padua</a>, <a href="http://arxiv.org/find/cs/1/au:+Qureshi_I/0/1/0/all/0/1">Imran Qureshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Karakaplan_M/0/1/0/all/0/1">Mustafa U. Karakaplan</a></p>
<p>Financial analysis is an important tool for evaluating company performance.
Practitioners work to answer financial questions to make profitable investment
decisions, and use advanced quantitative analyses to do so. As a result,
Financial Question Answering (QA) is a question answering task that requires
deep reasoning about numbers. Furthermore, it is unknown how well pre-trained
language models can reason in the financial domain. The current
state-of-the-art requires a retriever to collect relevant facts about the
financial question from the text and a generator to produce a valid financial
program and a final answer. However, recently large language models like GPT-3
have achieved state-of-the-art performance on wide variety of tasks with just a
few shot examples. We run several experiments with GPT-3 and find that a
separate retrieval model and logic engine continue to be essential components
to achieving SOTA performance in this task, particularly due to the precise
nature of financial questions and the complex information stored in financial
documents. With this understanding, our refined prompt-engineering approach on
GPT-3 achieves near SOTA accuracy without any fine-tuning.
</p>
</p>
</div>

    </div>
    </body>
    