<!DOCTYPE html>
<html>
<head>
<title>2023-08-10-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2308.04436">The Two Faces of AI in Green Mobile Computing: A Literature Review. (arXiv:2308.04436v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Siemers_W/0/1/0/all/0/1">Wander Siemers</a>, <a href="http://arxiv.org/find/cs/1/au:+Sallou_J/0/1/0/all/0/1">June Sallou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1">Lu&#xed;s Cruz</a></p>
<p>Artificial intelligence is bringing ever new functionalities to the realm of
mobile devices that are now considered essential (e.g., camera and voice
assistants, recommender systems). Yet, operating artificial intelligence takes
up a substantial amount of energy. However, artificial intelligence is also
being used to enable more energy-efficient solutions for mobile systems. Hence,
artificial intelligence has two faces in that regard, it is both a key enabler
of desired (efficient) mobile functionalities and a major power draw on these
devices, playing a part in both the solution and the problem. In this paper, we
present a review of the literature of the past decade on the usage of
artificial intelligence within the realm of green mobile computing. From the
analysis of 34 papers, we highlight the emerging patterns and map the field
into 13 main topics that are summarized in details.
</p>
<p>Our results showcase that the field is slowly increasing in the past years,
more specifically, since 2019. Regarding the double impact AI has on the mobile
energy consumption, the energy consumption of AI-based mobile systems is
under-studied in comparison to the usage of AI for energy-efficient mobile
computing, and we argue for more exploratory studies in that direction. We
observe that although most studies are framed as solution papers (94%), the
large majority do not make those solutions publicly available to the community.
Moreover, we also show that most contributions are purely academic (28 out of
34 papers) and that we need to promote the involvement of the mobile software
industry in this field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04440">Nature and the Machines. (arXiv:2308.04440v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Price_H/0/1/0/all/0/1">Huw Price</a>, <a href="http://arxiv.org/find/cs/1/au:+Connolly_M/0/1/0/all/0/1">Matthew Connolly</a></p>
<p>Does artificial intelligence (AI) pose existential risks to humanity? Some
critics feel this question is getting too much attention, and want to push it
aside in favour of conversations about the immediate risks of AI. These critics
now include the journal Nature, where a recent editorial urges us to 'stop
talking about tomorrow's AI doomsday when AI poses risks today.' We argue that
this is a serious failure of judgement, on Nature's part. In science, as in
everyday life, we expect influential actors to consider the consequences of
error. As the world's leading scientific journal, Nature is certainly an
influential actor, especially so in the absence of robust global regulation of
AI. Yet it has manifestly failed to consider the cost of error in this case.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04442">Blockchain-based Optimized Client Selection and Privacy Preserved Framework for Federated Learning. (arXiv:2308.04442v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qammar_A/0/1/0/all/0/1">Attia Qammar</a>, <a href="http://arxiv.org/find/cs/1/au:+Naouri_A/0/1/0/all/0/1">Abdenacer Naouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jianguo Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_H/0/1/0/all/0/1">Huansheng Ning</a></p>
<p>Federated learning is a distributed mechanism that trained large-scale neural
network models with the participation of multiple clients and data remains on
their devices, only sharing the local model updates. With this feature,
federated learning is considered a secure solution for data privacy issues.
However, the typical FL structure relies on the client-server, which leads to
the single-point-of-failure (SPoF) attack, and the random selection of clients
for model training compromised the model accuracy. Furthermore, adversaries try
for inference attacks i.e., attack on privacy leads to gradient leakage
attacks. We proposed the blockchain-based optimized client selection and
privacy-preserved framework in this context. We designed the three kinds of
smart contracts such as 1) registration of clients 2) forward bidding to select
optimized clients for FL model training 3) payment settlement and reward smart
contracts. Moreover, fully homomorphic encryption with Cheon, Kim, Kim, and
Song (CKKS) method is implemented before transmitting the local model updates
to the server. Finally, we evaluated our proposed method on the benchmark
dataset and compared it with state-of-the-art studies. Consequently, we
achieved a higher accuracy rate and privacy-preserved FL framework with
decentralized nature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04445">Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc. (arXiv:2308.04445v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lenat_D/0/1/0/all/0/1">Doug Lenat</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcus_G/0/1/0/all/0/1">Gary Marcus</a></p>
<p>Generative AI, the most popular current approach to AI, consists of large
language models (LLMs) that are trained to produce outputs that are plausible,
but not necessarily correct. Although their abilities are often uncanny, they
are lacking in aspects of reasoning, leading LLMs to be less than completely
trustworthy. Furthermore, their results tend to be both unpredictable and
uninterpretable.
</p>
<p>We lay out 16 desiderata for future AI, and discuss an alternative approach
to AI which could theoretically address many of the limitations associated with
current approaches: AI educated with curated pieces of explicit knowledge and
rules of thumb, enabling an inference engine to automatically deduce the
logical entailments of all that knowledge. Even long arguments produced this
way can be both trustworthy and interpretable, since the full step-by-step line
of reasoning is always available, and for each step the provenance of the
knowledge used can be documented and audited. There is however a catch: if the
logical language is expressive enough to fully represent the meaning of
anything we can say in English, then the inference engine runs much too slowly.
That's why symbolic AI systems typically settle for some fast but much less
expressive logic, such as knowledge graphs. We describe how one AI system, Cyc,
has developed ways to overcome that tradeoff and is able to reason in higher
order logic in real time.
</p>
<p>We suggest that any trustworthy general AI will need to hybridize the
approaches, the LLM approach and more formal approach, and lay out a path to
realizing that dream.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04448">Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI. (arXiv:2308.04448v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Avijit Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshmi_D/0/1/0/all/0/1">Dhanya Lakshmi</a></p>
<p>Generative Artificial Intelligence (AI) has seen mainstream adoption lately,
especially in the form of consumer-facing, open-ended, text and image
generating models. However, the use of such systems raises significant ethical
and safety concerns, including privacy violations, misinformation and
intellectual property theft. The potential for generative AI to displace human
creativity and livelihoods has also been under intense scrutiny. To mitigate
these risks, there is an urgent need of policies and regulations responsible
and ethical development in the field of generative AI. Existing and proposed
centralized regulations by governments to rein in AI face criticisms such as
not having sufficient clarity or uniformity, lack of interoperability across
lines of jurisdictions, restricting innovation, and hindering free market
competition. Decentralized protections via crowdsourced safety tools and
mechanisms are a potential alternative. However, they have clear deficiencies
in terms of lack of adequacy of oversight and difficulty of enforcement of
ethical and safety standards, and are thus not enough by themselves as a
regulation mechanism. We propose a marriage of these two strategies via a
framework we call Dual Governance. This framework proposes a cooperative
synergy between centralized government regulations in a U.S. specific context
and safety mechanisms developed by the community to protect stakeholders from
the harms of generative AI. By implementing the Dual Governance framework, we
posit that innovation and creativity can be promoted while ensuring safe and
ethical deployment of generative AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04451">Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks. (arXiv:2308.04451v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cotroneo_D/0/1/0/all/0/1">Domenico Cotroneo</a>, <a href="http://arxiv.org/find/cs/1/au:+Improta_C/0/1/0/all/0/1">Cristina Improta</a>, <a href="http://arxiv.org/find/cs/1/au:+Liguori_P/0/1/0/all/0/1">Pietro Liguori</a>, <a href="http://arxiv.org/find/cs/1/au:+Natella_R/0/1/0/all/0/1">Roberto Natella</a></p>
<p>In this work, we assess the security of AI code generators via data
poisoning, i.e., an attack that injects malicious samples into the training
data to generate vulnerable code. We poison the training data by injecting
increasing amounts of code containing security vulnerabilities and assess the
attack's success on different state-of-the-art models for code generation. Our
analysis shows that AI code generators are vulnerable to even a small amount of
data poisoning. Moreover, the attack does not impact the correctness of code
generated by pre-trained models, making it hard to detect.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04455">Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques. (arXiv:2308.04455v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Champion_P/0/1/0/all/0/1">Pierre Champion</a></p>
<p>The growing use of voice user interfaces has led to a surge in the collection
and storage of speech data. While data collection allows for the development of
efficient tools powering most speech services, it also poses serious privacy
issues for users as centralized storage makes private personal speech data
vulnerable to cyber threats. With the increasing use of voice-based digital
assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the
increasing ease with which personal speech data can be collected, the risk of
malicious use of voice-cloning and speaker/gender/pathological/etc. recognition
has increased.
</p>
<p>This thesis proposes solutions for anonymizing speech and evaluating the
degree of the anonymization. In this work, anonymization refers to making
personal speech data unlinkable to an identity while maintaining the usefulness
(utility) of the speech signal (e.g., access to linguistic content). We start
by identifying several challenges that evaluation protocols need to consider to
evaluate the degree of privacy protection properly. We clarify how
anonymization systems must be configured for evaluation purposes and highlight
that many practical deployment configurations do not permit privacy evaluation.
Furthermore, we study and examine the most common voice conversion-based
anonymization system and identify its weak points before suggesting new methods
to overcome some limitations. We isolate all components of the anonymization
system to evaluate the degree of speaker PPI associated with each of them.
Then, we propose several transformation methods for each component to reduce as
much as possible speaker PPI while maintaining utility. We promote
anonymization algorithms based on quantization-based transformation as an
alternative to the most-used and well-known noise-based approach. Finally, we
endeavor a new attack method to invert anonymization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04469">Correlating Medi- Claim Service by Deep Learning Neural Networks. (arXiv:2308.04469v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vajiram_J/0/1/0/all/0/1">Jayanthi Vajiram</a>, <a href="http://arxiv.org/find/cs/1/au:+Senthil_N/0/1/0/all/0/1">Negha Senthil</a>, <a href="http://arxiv.org/find/cs/1/au:+P_N/0/1/0/all/0/1">Nean Adhith.P</a></p>
<p>Medical insurance claims are of organized crimes related to patients,
physicians, diagnostic centers, and insurance providers, forming a chain
reaction that must be monitored constantly. These kinds of frauds affect the
financial growth of both insured people and health insurance companies. The
Convolution Neural Network architecture is used to detect fraudulent claims
through a correlation study of regression models, which helps to detect money
laundering on different claims given by different providers. Supervised and
unsupervised classifiers are used to detect fraud and non-fraud claims.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04477">A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages. (arXiv:2308.04477v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Buscemi_A/0/1/0/all/0/1">Alessio Buscemi</a></p>
<p>Large Language Models (LLMs) are advanced Artificial Intelligence (AI)
systems that have undergone extensive training using large datasets in order to
understand and produce language that closely resembles that of humans. These
models have reached a level of proficiency where they are capable of
successfully completing university exams across several disciplines and
generating functional code to handle novel problems. This research investigates
the coding proficiency of ChatGPT 3.5, a LLM released by OpenAI in November
2022, which has gained significant recognition for its impressive text
generating and code creation capabilities. The skill of the model in creating
code snippets is evaluated across 10 various programming languages and 4
different software domains. Based on the findings derived from this research,
major unexpected behaviors and limitations of the model have been identified.
This study aims to identify potential areas for development and examine the
ramifications of automated code generation on the evolution of programming
languages and on the tech industry.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04492">ChatGPT for Arabic Grammatical Error Correction. (arXiv:2308.04492v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1">Sang Yun Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_G/0/1/0/all/0/1">Gagan Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagoud_E/0/1/0/all/0/1">El Moatez Billah Nagoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a></p>
<p>Recently, large language models (LLMs) fine-tuned to follow human instruction
have exhibited significant capabilities in various English NLP tasks. However,
their performance in grammatical error correction (GEC) tasks, particularly in
non-English languages, remains significantly unexplored. In this paper, we
delve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task made
complex due to Arabic's rich morphology. Our findings suggest that various
prompting methods, coupled with (in-context) few-shot learning, demonstrate
considerable effectiveness, with GPT-4 achieving up to $65.49$
F\textsubscript{1} score under expert prompting (approximately $5$ points
higher than our established baseline). This highlights the potential of LLMs in
low-resource settings, offering a viable approach for generating useful
synthetic data for model training. Despite these positive results, we find that
instruction fine-tuned models, regardless of their size, significantly
underperform compared to fully fine-tuned models of significantly smaller
sizes. This disparity highlights a substantial room for improvements for LLMs.
Inspired by methods from low-resource machine translation, we also develop a
method exploiting synthetic data that significantly outperforms previous models
on two standard Arabic benchmarks. Our work sets new SoTA for Arabic GEC, with
$72.19\%$ and $73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04511">MT-IceNet -- A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting. (arXiv:2308.04511v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Ali_S/0/1/0/all/0/1">Sahara Ali</a>, <a href="http://arxiv.org/find/physics/1/au:+Wang_J/0/1/0/all/0/1">Jianwu Wang</a></p>
<p>Arctic amplification has altered the climate patterns both regionally and
globally, resulting in more frequent and more intense extreme weather events in
the past few decades. The essential part of Arctic amplification is the
unprecedented sea ice loss as demonstrated by satellite observations.
Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has
been a major research question with fundamental challenges at play. In addition
to physics-based Earth system models, researchers have been applying multiple
statistical and machine learning models for sea ice forecasting. Looking at the
potential of data-driven approaches to study sea ice variations, we propose
MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model
for forecasting Arctic sea ice concentration (SIC). The model uses an
encoder-decoder architecture with skip connections and processes multi-temporal
input streams to regenerate spatial maps at future timesteps. Using bi-monthly
and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric
and oceanic variables from ERA5 reanalysis product during 1979-2021, we show
that our proposed model provides promising predictive performance for per-pixel
SIC forecasting with up to 60% decrease in prediction error for a lead time of
6 months as compared to its state-of-the-art counterparts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04519">DisCoCat for Donkey Sentences. (arXiv:2308.04519v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McPheat_L/0/1/0/all/0/1">Lachlan McPheat</a> (University College London), <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Daphne Wang</a> (University College London)</p>
<p>We demonstrate how to parse Geach's Donkey sentences in a compositional
distributional model of meaning. We build on previous work on the DisCoCat
(Distributional Compositional Categorical) framework, including extensions that
model discourse, determiners, and relative pronouns. We present a type-logical
syntax for parsing donkey sentences, for which we define both relational and
vector space semantics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04522">Deep Learning for Diverse Data Types Steganalysis: A Review. (arXiv:2308.04522v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kheddar_H/0/1/0/all/0/1">Hamza Kheddar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemis_M/0/1/0/all/0/1">Mustapha Hemis</a>, <a href="http://arxiv.org/find/cs/1/au:+Himeur_Y/0/1/0/all/0/1">Yassine Himeur</a>, <a href="http://arxiv.org/find/cs/1/au:+Megias_D/0/1/0/all/0/1">David Meg&#xed;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1">Abbes Amira</a></p>
<p>Steganography and steganalysis are two interrelated aspects of the field of
information security. Steganography seeks to conceal communications, whereas
steganalysis is aimed to either find them or even, if possible, recover the
data they contain. Steganography and steganalysis have attracted a great deal
of interest, particularly from law enforcement. Steganography is often used by
cybercriminals and even terrorists to avoid being captured while in possession
of incriminating evidence, even encrypted, since cryptography is prohibited or
restricted in many countries. Therefore, knowledge of cutting-edge techniques
to uncover concealed information is crucial in exposing illegal acts. Over the
last few years, a number of strong and reliable steganography and steganalysis
techniques have been introduced in the literature. This review paper provides a
comprehensive overview of deep learning-based steganalysis techniques used to
detect hidden information within digital media. The paper covers all types of
cover in steganalysis, including image, audio, and video, and discusses the
most commonly used deep learning techniques. In addition, the paper explores
the use of more advanced deep learning techniques, such as deep transfer
learning (DTL) and deep reinforcement learning (DRL), to enhance the
performance of steganalysis systems. The paper provides a systematic review of
recent research in the field, including data sets and evaluation metrics used
in recent studies. It also presents a detailed analysis of DTL-based
steganalysis approaches and their performance on different data sets. The
review concludes with a discussion on the current state of deep learning-based
steganalysis, challenges, and future research directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04529">Generating Modern Persian Carpet Map by Style-transfer. (arXiv:2308.04529v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rahmatian_D/0/1/0/all/0/1">Dorsa Rahmatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshavash_M/0/1/0/all/0/1">Monireh Moshavash</a>, <a href="http://arxiv.org/find/cs/1/au:+Eftekhari_M/0/1/0/all/0/1">Mahdi Eftekhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoseinkhani_K/0/1/0/all/0/1">Kamran Hoseinkhani</a></p>
<p>Today, the great performance of Deep Neural Networks(DNN) has been proven in
various fields. One of its most attractive applications is to produce artistic
designs. A carpet that is known as a piece of art is one of the most important
items in a house, which has many enthusiasts all over the world. The first
stage of producing a carpet is to prepare its map, which is a difficult,
time-consuming, and expensive task. In this research work, our purpose is to
use DNN for generating a Modern Persian Carpet Map. To reach this aim, three
different DNN style transfer methods are proposed and compared against each
other. In the proposed methods, the Style-Swap method is utilized to create the
initial carpet map, and in the following, to generate more diverse designs,
methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition,
some methods are examined and introduced for coloring the produced carpet maps.
The designed maps are evaluated via the results of filled questionnaires where
the outcomes of user evaluations confirm the popularity of generated carpet
maps. Eventually, for the first time, intelligent methods are used in producing
carpet maps, and it reduces human intervention. The proposed methods can
successfully produce diverse carpet designs, and at a higher speed than
traditional ways.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04539">Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures. (arXiv:2308.04539v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madireddy_S/0/1/0/all/0/1">Sandeep Madireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Yanguas_Gil_A/0/1/0/all/0/1">Angel Yanguas-Gil</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaprakash_P/0/1/0/all/0/1">Prasanna Balaprakash</a></p>
<p>The ability to learn continuously from an incoming data stream without
catastrophic forgetting is critical to designing intelligent systems. Many
approaches to continual learning rely on stochastic gradient descent and its
variants that employ global error updates, and hence need to adopt strategies
such as memory buffers or replay to circumvent its stability, greed, and
short-term memory limitations. To address this limitation, we have developed a
biologically inspired lightweight neural network architecture that incorporates
synaptic plasticity mechanisms and neuromodulation and hence learns through
local error signals to enable online continual learning without stochastic
gradient descent.
</p>
<p>Our approach leads to superior online continual learning performance on
Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other
memory-constrained learning approaches and matches that of the state-of-the-art
memory-intensive replay-based approaches. We further demonstrate the
effectiveness of our approach by integrating key design concepts into other
backpropagation-based continual learning algorithms, significantly improving
their accuracy. Our results provide compelling evidence for the importance of
incorporating biological principles into machine learning models and offer
insights into how we can leverage them to design more efficient and robust
systems for online continual learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04586">Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stefik_M/0/1/0/all/0/1">Mark Stefik</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_R/0/1/0/all/0/1">Robert Price</a></p>
<p>Although some current AIs surpass human abilities especially in closed worlds
such as board games, their performance in the messy real world is limited. They
make strange mistakes and do not notice them. They cannot be instructed easily,
fail to use common sense, and lack curiosity. They do not make good
collaborators. Neither systems built using the traditional manually-constructed
symbolic AI approach nor systems built using generative and deep learning AI
approaches including large language models (LLMs) can meet the challenges. They
are not well suited for creating robust and trustworthy AIs. Although it is
outside of mainstream AI approaches, developmental bootstrapping shows promise.
In developmental bootstrapping, AIs develop competences like human children do.
They start with innate competences. Like humans, they interact with the
environment and learn from their interactions. They incrementally extend their
innate competences with self-developed competences. They interact and learn
from people and establish perceptual, cognitive, and common grounding.
Following a bootstrapping process, they acquire the competences that they need.
However, developmental robotics has not yet produced AIs with robust
adult-level competences. Projects have typically stopped at the Toddler Barrier
corresponding to human infant development at about two years of age, before
speech is fluent. They also do not bridge the Reading Barrier, where they can
skillfully and skeptically tap into the vast socially developed recorded
information resources that power LLMs. The next competences in human cognitive
development involve intrinsic motivation, imitation learning, imagination,
coordination, and communication. This paper lays out the logic, prospects,
gaps, and challenges for extending the practice of developmental bootstrapping
to create robust and resilient AIs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04589">Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction. (arXiv:2308.04589v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Teeti_I/0/1/0/all/0/1">Izzeddin Teeti</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhargav_R/0/1/0/all/0/1">Rongali Sai Bhargav</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1">Vivek Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bradley_A/0/1/0/all/0/1">Andrew Bradley</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Biplab Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuzzolin_F/0/1/0/all/0/1">Fabio Cuzzolin</a></p>
<p>The emerging field of action prediction plays a vital role in various
computer vision applications such as autonomous driving, activity analysis and
human-computer interaction. Despite significant advancements, accurately
predicting future actions remains a challenging problem due to high
dimensionality, complex dynamics and uncertainties inherent in video data.
Traditional supervised approaches require large amounts of labelled data, which
is expensive and time-consuming to obtain. This paper introduces a novel
self-supervised video strategy for enhancing action prediction inspired by DINO
(self-distillation with no labels). The Temporal-DINO approach employs two
models; a 'student' processing past frames; and a 'teacher' processing both
past and future frames, enabling a broader temporal context. During training,
the teacher guides the student to learn future context by only observing past
frames. The strategy is evaluated on ROAD dataset for the action prediction
downstream task using 3D-ResNet, Transformer, and LSTM architectures. The
experimental results showcase significant improvements in prediction
performance across these architectures, with our method achieving an average
enhancement of 9.9% Precision Points (PP), highlighting its effectiveness in
enhancing the backbones' capabilities of capturing long-term dependencies.
Furthermore, our approach demonstrates efficiency regarding the pretraining
dataset size and the number of epochs required. This method overcomes
limitations present in other approaches, including considering various backbone
architectures, addressing multiple prediction horizons, reducing reliance on
hand-crafted augmentations, and streamlining the pretraining process into a
single stage. These findings highlight the potential of our approach in diverse
video-based tasks such as activity recognition, motion planning, and scene
understanding.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04592">Shepherd: A Critic for Language Model Generation. (arXiv:2308.04592v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianlu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Ping Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiaoqing Ellen Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+OBrien_S/0/1/0/all/0/1">Sean O&#x27;Brien</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1">Ramakanth Pasunuru</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwivedi_Yu_J/0/1/0/all/0/1">Jane Dwivedi-Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovneva_O/0/1/0/all/0/1">Olga Golovneva</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazel_Zarandi_M/0/1/0/all/0/1">Maryam Fazel-Zarandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1">Asli Celikyilmaz</a></p>
<p>As large language models improve, there is increasing interest in techniques
that leverage these models' capabilities to refine their own outputs. In this
work, we introduce Shepherd, a language model specifically tuned to critique
responses and suggest refinements, extending beyond the capabilities of an
untuned model to identify diverse errors and provide suggestions to remedy
them. At the core of our approach is a high quality feedback dataset, which we
curate from community feedback and human annotations. Even though Shepherd is
small (7B parameters), its critiques are either equivalent or preferred to
those from established models including ChatGPT. Using GPT-4 for evaluation,
Shepherd reaches an average win-rate of 53-87% compared to competitive
alternatives. In human evaluation, Shepherd strictly outperforms other models
and on average closely ties with ChatGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04600">Model of models -- Part 1. (arXiv:2308.04600v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Komarovsky_S/0/1/0/all/0/1">Shimon Komarovsky</a></p>
<p>This paper proposes a new cognitive model, acting as the main component of an
AGI agent. The model is introduced in its mature intelligence state, and as an
extension of previous models, DENN, and especially AKREM, by including
operational models (frames/classes) and will. This model's core assumption is
that cognition is about operating on accumulated knowledge, with the guidance
of an appropriate will. Also, we assume that the actions, part of knowledge,
are learning to be aligned with will, during the evolution phase that precedes
the mature intelligence state. In addition, this model is mainly based on the
duality principle in every known intelligent aspect, such as exhibiting both
top-down and bottom-up model learning, generalization verse specialization, and
more. Furthermore, a holistic approach is advocated for AGI designing, and
cognition under constraints or efficiency is proposed, in the form of
reusability and simplicity. Finally, reaching this mature state is described
via a cognitive evolution from infancy to adulthood, utilizing a consolidation
principle. The final product of this cognitive model is a dynamic operational
memory of models and instances. Lastly, some examples and preliminary ideas for
the evolution phase to reach the mature state are presented.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04623">Accelerating LLM Inference with Staged Speculative Decoding. (arXiv:2308.04623v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Spector_B/0/1/0/all/0/1">Benjamin Spector</a>, <a href="http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1">Chris Re</a></p>
<p>Recent advances with large language models (LLM) illustrate their diverse
capabilities. We propose a novel algorithm, staged speculative decoding, to
accelerate LLM inference in small-batch, on-device scenarios. We address the
low arithmetic intensity of small-batch inference by improving upon previous
work in speculative decoding. First, we restructure the speculative batch as a
tree, which reduces generation costs and increases the expected tokens per
batch. Second, we add a second stage of speculative decoding. Taken together,
we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-L
model while perfectly preserving output quality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04624">Benchmarking LLM powered Chatbots: Methods and Metrics. (arXiv:2308.04624v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1">Debarag Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Pooja Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Avadhanam_A/0/1/0/all/0/1">Arjun Avadhanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Saksham Srivastava</a></p>
<p>Autonomous conversational agents, i.e. chatbots, are becoming an increasingly
common mechanism for enterprises to provide support to customers and partners.
In order to rate chatbots, especially ones powered by Generative AI tools like
Large Language Models (LLMs) we need to be able to accurately assess their
performance. This is where chatbot benchmarking becomes important. In this
paper, we propose the use of a novel benchmark that we call the E2E (End to
End) benchmark, and show how the E2E benchmark can be used to evaluate accuracy
and usefulness of the answers provided by chatbots, especially ones powered by
LLMs. We evaluate an example chatbot at different levels of sophistication
based on both our E2E benchmark, as well as other available metrics commonly
used in the state of art, and observe that the proposed benchmark show better
results compared to others. In addition, while some metrics proved to be
unpredictable, the metric associated with the E2E benchmark, which uses cosine
similarity performed well in evaluating chatbots. The performance of our best
models shows that there are several benefits of using the cosine similarity
score as a metric in the E2E benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04625">A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation. (arXiv:2308.04625v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mistry_D/0/1/0/all/0/1">Deven M. Mistry</a>, <a href="http://arxiv.org/find/cs/1/au:+Minai_A/0/1/0/all/0/1">Ali A. Minai</a></p>
<p>Analyzing the pattern of semantic variation in long real-world texts such as
books or transcripts is interesting from the stylistic, cognitive, and
linguistic perspectives. It is also useful for applications such as text
segmentation, document summarization, and detection of semantic novelty. The
recent emergence of several vector-space methods for sentence embedding has
made such analysis feasible. However, this raises the issue of how consistent
and meaningful the semantic representations produced by various methods are in
themselves. In this paper, we compare several recent sentence embedding methods
via time-series of semantic similarity between successive sentences and
matrices of pairwise sentence similarity for multiple books of literature. In
contrast to previous work using target tasks and curated datasets to compare
sentence embedding methods, our approach provides an evaluation of the methods
'in the wild'. We find that most of the sentence embedding methods considered
do infer highly correlated patterns of semantic similarity in a given document,
but show interesting differences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04635">Where&#x27;s the Liability in Harmful AI Speech?. (arXiv:2308.04635v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Peter Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1">Tatsunori Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemley_M/0/1/0/all/0/1">Mark Lemley</a></p>
<p>Generative AI, in particular text-based "foundation models" (large models
trained on a huge variety of information including the internet), can generate
speech that could be problematic under a wide range of liability regimes.
Machine learning practitioners regularly "red team" models to identify and
mitigate such problematic speech: from "hallucinations" falsely accusing people
of serious misconduct to recipes for constructing an atomic bomb. A key
question is whether these red-teamed behaviors actually present any liability
risk for model creators and deployers under U.S. law, incentivizing investments
in safety mechanisms. We examine three liability regimes, tying them to common
examples of red-teamed model behaviors: defamation, speech integral to criminal
conduct, and wrongful death. We find that any Section 230 immunity analysis or
downstream liability analysis is intimately wrapped up in the technical details
of algorithm design. And there are many roadblocks to truly finding models (and
their associated parties) liable for generated speech. We argue that AI should
not be categorically immune from liability in these scenarios and that as
courts grapple with the already fine-grained complexities of platform
algorithms, the technical details of generative AI loom above with thornier
questions. Courts and policymakers should think carefully about what technical
design incentives they create as they evaluate these issues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04637">Sparse Binary Transformers for Multivariate Time Series Modeling. (arXiv:2308.04637v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorbett_M/0/1/0/all/0/1">Matt Gorbett</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirazi_H/0/1/0/all/0/1">Hossein Shirazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_I/0/1/0/all/0/1">Indrakshi Ray</a></p>
<p>Compressed Neural Networks have the potential to enable deep learning across
new applications and smaller computational environments. However, understanding
the range of learning tasks in which such models can succeed is not well
studied. In this work, we apply sparse and binary-weighted Transformers to
multivariate time series problems, showing that the lightweight models achieve
accuracy comparable to that of dense floating-point Transformers of the same
structure. Our model achieves favorable results across three time series
learning tasks: classification, anomaly detection, and single-step forecasting.
Additionally, to reduce the computational complexity of the attention
mechanism, we apply two modifications, which show little to no decline in model
performance: 1) in the classification task, we apply a fixed mask to the query,
key, and value activations, and 2) for forecasting and anomaly detection, which
rely on predicting outputs at a single point in time, we propose an attention
mask to allow computation only at the current time step. Together, each
compression technique and attention modification substantially reduces the
number of non-zero operations necessary in the Transformer. We measure the
computational savings of our approach over a range of metrics including
parameter count, bit size, and floating point operation (FLOPs) count, showing
up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04639">A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem. (arXiv:2308.04639v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhang-Hua Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Sipeng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jintong Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tianshu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuanyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a></p>
<p>For prohibitively large-scale Travelling Salesman Problems (TSPs), existing
algorithms face big challenges in terms of both computational efficiency and
solution quality. To address this issue, we propose a hierarchical
destroy-and-repair (HDR) approach, which attempts to improve an initial
solution by applying a series of carefully designed destroy-and-repair
operations. A key innovative concept is the hierarchical search framework,
which recursively fixes partial edges and compresses the input instance into a
small-scale TSP under some equivalence guarantee. This neat search framework is
able to deliver highly competitive solutions within a reasonable time. Fair
comparisons based on nineteen famous large-scale instances (with 10,000 to
10,000,000 cities) show that HDR is highly competitive against existing
state-of-the-art TSP algorithms, in terms of both efficiency and solution
quality. Notably, on two large instances with 3,162,278 and 10,000,000 cities,
HDR breaks the world records (i.e., best-known results regardless of
computation time), which were previously achieved by LKH and its variants,
while HDR is completely independent of LKH. Finally, ablation studies are
performed to certify the importance and validity of the hierarchical search
framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04672">Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks. (arXiv:2308.04672v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jue Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Huan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jianchao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chengru Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Di Zhang</a></p>
<p>Brain-inspired Spiking Neural Networks (SNNs) have the characteristics of
event-driven and high energy-efficient, which are different from traditional
Artificial Neural Networks (ANNs) when deployed on edge devices such as
neuromorphic chips. Most previous work focuses on SNNs training strategies to
improve model performance and brings larger and deeper network architectures.
It is difficult to deploy these complex networks on resource-limited edge
devices directly. To meet such demand, people compress SNNs very cautiously to
balance the performance and the computation efficiency. Existing compression
methods either iteratively pruned SNNs using weights norm magnitude or
formulated the problem as a sparse learning optimization. We propose an
improved end-to-end Minimax optimization method for this sparse learning
problem to better balance the model performance and the computation efficiency.
We also demonstrate that jointly applying compression and finetuning on SNNs is
better than sequentially, especially for extreme compression ratios. The
compressed SNN models achieved state-of-the-art (SOTA) performance on various
benchmark datasets and architectures. Our code is available at
https://github.com/chenjallen/Resource-Constrained-Compression-on-SNN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04673">SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning. (arXiv:2308.04673v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaobei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Changchun Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Liming Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Run Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chenhao Lin</a></p>
<p>Self-supervised learning (SSL) which leverages unlabeled datasets for
pre-training powerful encoders has achieved significant success in recent
years. These encoders are commonly used as feature extractors for various
downstream tasks, requiring substantial data and computing resources for their
training process. With the deployment of pre-trained encoders in commercial
use, protecting the intellectual property of model owners and ensuring the
trustworthiness of the models becomes crucial. Recent research has shown that
encoders are threatened by backdoor attacks, adversarial attacks, etc.
Therefore, a scheme to verify the integrity of pre-trained encoders is needed
to protect users. In this paper, we propose SSL-Auth, the first fragile
watermarking scheme for verifying the integrity of encoders without
compromising model performance. Our method utilizes selected key samples as
watermark information and trains a verification network to reconstruct the
watermark information, thereby verifying the integrity of the encoder. By
comparing the reconstruction results of the key samples, malicious
modifications can be effectively detected, as altered models should not exhibit
similar reconstruction performance as the original models. Extensive
evaluations on various models and diverse datasets demonstrate the
effectiveness and fragility of our proposed SSL-Auth.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04674">Addressing Racial Bias in Facial Emotion Recognition. (arXiv:2308.04674v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1">Alex Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xingshuo Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1">Peter Washington</a></p>
<p>Fairness in deep learning models trained with high-dimensional inputs and
subjective labels remains a complex and understudied area. Facial emotion
recognition, a domain where datasets are often racially imbalanced, can lead to
models that yield disparate outcomes across racial groups. This study focuses
on analyzing racial bias by sub-sampling training sets with varied racial
distributions and assessing test performance across these simulations. Our
findings indicate that smaller datasets with posed faces improve on both
fairness and performance metrics as the simulations approach racial balance.
Notably, the F1-score increases by $27.2\%$ points, and demographic parity
increases by $15.7\%$ points on average across the simulations. However, in
larger datasets with greater facial variation, fairness metrics generally
remain constant, suggesting that racial balance by itself is insufficient to
achieve parity in test performance across different racial groups.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04679">Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA. (arXiv:2308.04679v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yuhan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haiqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Chenyou Fan</a></p>
<p>Large Language Models (LLMs) have shown outstanding performance across wide
range of downstream tasks. This competency is attributed to their substantial
parameter size and pre-training on extensive corpus. Moreover, LLMs have
exhibited enhanced reasoning capabilities in tackling complex reasoning tasks,
owing to the utilization of a method named ``Chain-of-Thought (CoT)
prompting''. This method is designed to generate intermediate reasoning steps
that guide the inference of the final answer. However, it is essential to
highlight that these advanced reasoning abilities appear to emerge in models
with a minimum of 10 billion parameters, thereby limiting its efficacy in
situations where computational resources are constrained. In this paper, we
investigate the possibility of transferring the reasoning capabilities of LLMs
to smaller models via knowledge distillation. Specifically, we propose Sci-CoT,
a two-stage framework that separates the processes of generating rationales and
inferring answers. This method enables a more efficient use of rationales
during the answer inference stage, leading to improved performance on
scientific question-answering tasks. Utilizing Sci-CoT, our 80-million
parameter model is able to exceed the performance of BLOOM-176B in the ARC-Easy
dataset under the few shot setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04687">Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization. (arXiv:2308.04687v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kushwaha_A/0/1/0/all/0/1">Abhishek Kushwaha</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Sarthak Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhanushali_A/0/1/0/all/0/1">Anish Bhanushali</a>, <a href="http://arxiv.org/find/cs/1/au:+Dastidar_T/0/1/0/all/0/1">Tathagato Rai Dastidar</a></p>
<p>While the use of artificial intelligence (AI) for medical image analysis is
gaining wide acceptance, the expertise, time and cost required to generate
annotated data in the medical field are significantly high, due to limited
availability of both data and expert annotation. Strongly supervised object
localization models require data that is exhaustively annotated, meaning all
objects of interest in an image are identified. This is difficult to achieve
and verify for medical images. We present a method for the transformation of
real data to train any Deep Neural Network to solve the above problems. We show
the efficacy of this approach on both a weakly supervised localization model
and a strongly supervised localization model. For the weakly supervised model,
we show that the localization accuracy increases significantly using the
generated data. For the strongly supervised model, this approach overcomes the
need for exhaustive annotation on real images. In the latter model, we show
that the accuracy, when trained with generated images, closely parallels the
accuracy when trained with exhaustively annotated real images. The results are
demonstrated on images of human urine samples obtained using microscopy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04689">web crawler strategies for web pages under robot.txt restriction. (arXiv:2308.04689v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vyas_P/0/1/0/all/0/1">Piyush Vyas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_A/0/1/0/all/0/1">Akhilesh Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandge_T/0/1/0/all/0/1">Tushar Mandge</a>, <a href="http://arxiv.org/find/cs/1/au:+Hardikar_S/0/1/0/all/0/1">Surbhi Hardikar</a></p>
<p>In the present time, all know about World Wide Web and work over the Internet
daily. In this paper, we introduce the search engines working for keywords that
are entered by users to find something. The search engine uses different search
algorithms for convenient results for providing to the net surfer. Net surfers
go with the top search results but how did the results of web pages get higher
ranks over search engines? how the search engine got that all the web pages in
the database? This paper gives the answers to all these kinds of basic
questions. Web crawlers working for search engines and robot exclusion protocol
rules for web crawlers are also addressed in this research paper. Webmaster
uses different restriction facts in robot.txt file to instruct web crawler,
some basic formats of robot.txt are also mentioned in this paper.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04690">Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1">Jae Yong Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Ko_S/0/1/0/all/0/1">Seungchan Ko</a>, <a href="http://arxiv.org/find/math/1/au:+Hong_Y/0/1/0/all/0/1">Youngjoon Hong</a></p>
<p>Partial differential equations (PDEs) underlie our understanding and
prediction of natural phenomena across numerous fields, including physics,
engineering, and finance. However, solving parametric PDEs is a complex task
that necessitates efficient numerical methods. In this paper, we propose a
novel approach for solving parametric PDEs using a Finite Element Operator
Network (FEONet). Our proposed method leverages the power of deep learning in
conjunction with traditional numerical methods, specifically the finite element
method, to solve parametric PDEs in the absence of any paired input-output
training data. We demonstrate the effectiveness of our approach on several
benchmark problems and show that it outperforms existing state-of-the-art
methods in terms of accuracy, generalization, and computational flexibility.
Our FEONet framework shows potential for application in various fields where
PDEs play a crucial role in modeling complex domains with diverse boundary
conditions and singular behavior. Furthermore, we provide theoretical
convergence analysis to support our approach, utilizing finite element
approximation in numerical analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04696">Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects. (arXiv:2308.04696v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amirian_S/0/1/0/all/0/1">Soheyla Amirian</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlson_L/0/1/0/all/0/1">Luke A. Carlson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Matthew F. Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lohse_I/0/1/0/all/0/1">Ines Lohse</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_K/0/1/0/all/0/1">Kurt R. Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Plate_J/0/1/0/all/0/1">Johannes F. Plate</a>, <a href="http://arxiv.org/find/cs/1/au:+Tafti_A/0/1/0/all/0/1">Ahmad P. Tafti</a></p>
<p>While artificial intelligence (AI) has made many successful applications in
various domains, its adoption in healthcare lags a little bit behind other
high-stakes settings. Several factors contribute to this slower uptake,
including regulatory frameworks, patient privacy concerns, and data
heterogeneity. However, one significant challenge that impedes the
implementation of AI in healthcare, particularly in orthopedics, is the lack of
explainability and interpretability around AI models. Addressing the challenge
of explainable AI (XAI) in orthopedics requires developing AI models and
algorithms that prioritize transparency and interpretability, allowing
clinicians, surgeons, and patients to understand the contributing factors
behind any AI-powered predictive or descriptive models. The current
contribution outlines several key challenges and opportunities that manifest in
XAI in orthopedic practice. This work emphasizes the need for interdisciplinary
collaborations between AI practitioners, orthopedic specialists, and regulatory
entities to establish standards and guidelines for the adoption of XAI in
orthopedics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04708">Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution. (arXiv:2308.04708v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ide_T/0/1/0/all/0/1">Tsuyoshi Id&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_N/0/1/0/all/0/1">Naoki Abe</a></p>
<p>We address the task of probabilistic anomaly attribution in the black-box
regression setting, where the goal is to compute the probability distribution
of the attribution score of each input variable, given an observed anomaly. The
training dataset is assumed to be unavailable. This task differs from the
standard XAI (explainable AI) scenario, since we wish to explain the anomalous
deviation from a black-box prediction rather than the black-box model itself.
</p>
<p>We begin by showing that mainstream model-agnostic explanation methods, such
as the Shapley values, are not suitable for this task because of their
``deviation-agnostic property.'' We then propose a novel framework for
probabilistic anomaly attribution that allows us to not only compute
attribution scores as the predictive mean but also quantify the uncertainty of
those scores. This is done by considering a generative process for
perturbations that counter-factually bring the observed anomalous observation
back to normalcy. We introduce a variational Bayes algorithm for deriving the
distributions of per variable attribution scores. To the best of our knowledge,
this is the first probabilistic anomaly attribution framework that is free from
being deviation-agnostic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04719">JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games. (arXiv:2308.04719v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_K/0/1/0/all/0/1">Kun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yingping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiangcheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mcaleer_S/0/1/0/all/0/1">Stephen Mcaleer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Wei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zonghong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a></p>
<p>This paper presents an empirical exploration of non-transitivity in
perfect-information games, specifically focusing on Xiangqi, a traditional
Chinese board game comparable in game-tree complexity to chess and shogi. By
analyzing over 10,000 records of human Xiangqi play, we highlight the existence
of both transitive and non-transitive elements within the game's strategic
structure. To address non-transitivity, we introduce the JiangJun algorithm, an
innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space
Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate
the algorithm empirically using a WeChat mini program and achieve a Master
level with a 99.41\% win rate against human players. The algorithm's
effectiveness in overcoming non-transitivity is confirmed by a plethora of
metrics, such as relative population performance and visualization results. Our
project site is available at
\url{https://sites.google.com/view/jiangjun-site/}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04729">JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models. (arXiv:2308.04729v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peike Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yikai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Allen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Alex Wang</a></p>
<p>Music generation has attracted growing interest with the advancement of deep
generative models. However, generating music conditioned on textual
descriptions, known as text-to-music, remains challenging due to the complexity
of musical structures and high sampling rate requirements. Despite the task's
significance, prevailing generative models exhibit limitations in music
quality, computational efficiency, and generalization. This paper introduces
JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a
diffusion model incorporating both autoregressive and non-autoregressive
training. Through in-context learning, JEN-1 performs various generation tasks
including text-guided music generation, music inpainting, and continuation.
Evaluations demonstrate JEN-1's superior performance over state-of-the-art
methods in text-music alignment and music quality while maintaining
computational efficiency. Our demos are available at
<a href="http://futureverse.com/research/jen/demos/jen1">this http URL</a>
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04736">Case Study: Using AI-Assisted Code Generation In Mobile Teams. (arXiv:2308.04736v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vasiliniuc_M/0/1/0/all/0/1">Mircea-Serban Vasiliniuc</a>, <a href="http://arxiv.org/find/cs/1/au:+Groza_A/0/1/0/all/0/1">Adrian Groza</a></p>
<p>The aim of this study is to evaluate the performance of AI-assisted
programming in actual mobile development teams that are focused on native
mobile languages like Kotlin and Swift. The extensive case study involves 16
participants and 2 technical reviewers, from a software development department
designed to understand the impact of using LLMs trained for code generation in
specific phases of the team, more specifically, technical onboarding and
technical stack switch. The study uses technical problems dedicated to each
phase and requests solutions from the participants with and without using
AI-Code generators. It measures time, correctness, and technical integration
using ReviewerScore, a metric specific to the paper and extracted from actual
industry standards, the code reviewers of merge requests. The output is
converted and analyzed together with feedback from the participants in an
attempt to determine if using AI-assisted programming tools will have an impact
on getting developers onboard in a project or helping them with a smooth
transition between the two native development environments of mobile
development, Android and iOS. The study was performed between May and June 2023
with members of the mobile department of a software development company based
in Cluj-Napoca, with Romanian ownership and management.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04749">Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks. (arXiv:2308.04749v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Feifei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Wenxuan Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1">Guobin Shen</a></p>
<p>Children possess the ability to learn multiple cognitive tasks sequentially,
which is a major challenge toward the long-term goal of artificial general
intelligence. Existing continual learning frameworks are usually applicable to
Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired,
energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning
mechanisms during child growth and development, we propose Dynamic Structure
Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive
continual learning. When learning a sequence of tasks, the DSD-SNN dynamically
assigns and grows new neurons to new tasks and prunes redundant neurons,
thereby increasing memory capacity and reducing computational overhead. In
addition, the overlapping shared structure helps to quickly leverage all
acquired knowledge to new tasks, empowering a single network capable of
supporting multiple incremental tasks (without the separate sub-network mask
for each task). We validate the effectiveness of the proposed model on multiple
class incremental learning and task incremental learning benchmarks. Extensive
experiments demonstrated that our model could significantly improve
performance, learning speed and memory capacity, and reduce computational
overhead. Besides, our DSD-SNN model achieves comparable performance with the
DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA)
performance for existing SNNs-based continual learning methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04758">Bird&#x27;s-Eye-View Scene Graph for Vision-Language Navigation. (arXiv:2308.04758v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaohan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a></p>
<p>Vision-language navigation (VLN), which entails an agent to navigate 3D
environments following human instructions, has shown great advances. However,
current agents are built upon panoramic observations, which hinders their
ability to perceive 3D scene geometry and easily leads to ambiguous selection
of panoramic view. To address these limitations, we present a BEV Scene Graph
(BSG), which leverages multi-step BEV representations to encode scene layouts
and geometric cues of indoor environment under the supervision of 3D detection.
During navigation, BSG builds a local BEV representation at each step and
maintains a BEV-based global scene map, which stores and organizes all the
online collected local BEV representations according to their topological
relations. Based on BSG, the agent predicts a local BEV grid-level decision
score and a global graph-level decision score, combined with a sub-view
selection score on panoramic views, for more accurate action prediction. Our
approach significantly outperforms state-of-the-art methods on REVERIE, R2R,
and R4R, showing the potential of BEV perception in VLN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04760">Automated Driving Without Ethics: Meaning, Design and Real-World Implementation. (arXiv:2308.04760v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Evans_K/0/1/0/all/0/1">Katherine Evans</a> (IRCAI), <a href="http://arxiv.org/find/cs/1/au:+Moura_N/0/1/0/all/0/1">Nelson de Moura</a> (ASTRA), <a href="http://arxiv.org/find/cs/1/au:+Chatila_R/0/1/0/all/0/1">Raja Chatila</a> (ISIR), <a href="http://arxiv.org/find/cs/1/au:+Chauvier_S/0/1/0/all/0/1">St&#xe9;phane Chauvier</a> (SND)</p>
<p>The ethics of automated vehicles (AV) has received a great amount of
attention in recent years, specifically in regard to their decisional policies
in accident situations in which human harm is a likely consequence. After a
discussion about the pertinence and cogency of the term 'artificial moral
agent' to describe AVs that would accomplish these sorts of decisions, and
starting from the assumption that human harm is unavoidable in some situations,
a strategy for AV decision making is proposed using only pre-defined parameters
to characterize the risk of possible accidents and also integrating the Ethical
Valence Theory, which paints AV decision-making as a type of claim mitigation,
into multiple possible decision rules to determine the most suitable action
given the specific environment and decision context. The goal of this approach
is not to define how moral theory requires vehicles to behave, but rather to
provide a computational approach that is flexible enough to accommodate a
number of human 'moral positions' concerning what morality demands and what
road users may expect, offering an evaluation tool for the social acceptability
of an automated vehicle's decision making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04761">Feature Matching Data Synthesis for Non-IID Federated Learning. (arXiv:2308.04761v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jiawei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuyi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jessie Hui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a></p>
<p>Federated learning (FL) has emerged as a privacy-preserving paradigm that
trains neural networks on edge devices without collecting data at a central
server. However, FL encounters an inherent challenge in dealing with
non-independent and identically distributed (non-IID) data among devices. To
address this challenge, this paper proposes a hard feature matching data
synthesis (HFMDS) method to share auxiliary data besides local models.
Specifically, synthetic data are generated by learning the essential
class-relevant features of real samples and discarding the redundant features,
which helps to effectively tackle the non-IID issue. For better privacy
preservation, we propose a hard feature augmentation method to transfer real
features towards the decision boundary, with which the synthetic data not only
improve the model generalization but also erase the information of real
features. By integrating the proposed HFMDS method with FL, we present a novel
FL framework with data augmentation to relieve data heterogeneity. The
theoretical analysis highlights the effectiveness of our proposed data
synthesis method in solving the non-IID challenge. Simulation results further
demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in
terms of accuracy, privacy preservation, and computational cost on various
benchmark datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04767">Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization. (arXiv:2308.04767v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Y/0/1/0/all/0/1">Yufei Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+You_T/0/1/0/all/0/1">Tao You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanning Zhang</a></p>
<p>Self-supervised sound source localization is usually challenged by the
modality inconsistency. In recent studies, contrastive learning based
strategies have shown promising to establish such a consistent correspondence
between audio and sound sources in visual scenarios. Unfortunately, the
insufficient attention to the heterogeneity influence in the different modality
features still limits this scheme to be further improved, which also becomes
the motivation of our work. In this study, an Induction Network is proposed to
bridge the modality gap more effectively. By decoupling the gradients of visual
and audio modalities, the discriminative visual representations of sound
sources can be learned with the designed Induction Vector in a bootstrap
manner, which also enables the audio modality to be aligned with the visual
modality consistently. In addition to a visual weighted contrastive loss, an
adaptive threshold selection strategy is introduced to enhance the robustness
of the Induction Network. Substantial experiments conducted on SoundNet-Flickr
and VGG-Sound Source datasets have demonstrated a superior performance compared
to other state-of-the-art works in different challenging scenarios. The code is
available at https://github.com/Tahy1/AVIN
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04774">E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles. (arXiv:2308.04774v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Suo_J/0/1/0/all/0/1">Jiashun Suo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xingzhou Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Weisong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a></p>
<p>Motivated by the advances in deep learning techniques, the application of
Unmanned Aerial Vehicle (UAV)-based object detection has proliferated across a
range of fields, including vehicle counting, fire detection, and city
monitoring. While most existing research studies only a subset of the
challenges inherent to UAV-based object detection, there are few studies that
balance various aspects to design a practical system for energy consumption
reduction. In response, we present the E3-UAV, an edge-based energy-efficient
object detection system for UAVs. The system is designed to dynamically support
various UAV devices, edge devices, and detection algorithms, with the aim of
minimizing energy consumption by deciding the most energy-efficient flight
parameters (including flight altitude, flight speed, detection algorithm, and
sampling rate) required to fulfill the detection requirements of the task. We
first present an effective evaluation metric for actual tasks and construct a
transparent energy consumption model based on hundreds of actual flight data to
formalize the relationship between energy consumption and flight parameters.
Then we present a lightweight energy-efficient priority decision algorithm
based on a large quantity of actual flight data to assist the system in
deciding flight parameters. Finally, we evaluate the performance of the system,
and our experimental results demonstrate that it can significantly decrease
energy consumption in real-world scenarios. Additionally, we provide four
insights that can assist researchers and engineers in their efforts to study
UAV-based object detection further.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04778">Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization. (arXiv:2308.04778v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khalafaoui_Y/0/1/0/all/0/1">Yasser Khalafaoui</a> (Alteca, ETIS - UMR 8051, CY), <a href="http://arxiv.org/find/cs/1/au:+Grozavu_N/0/1/0/all/0/1">Nistor Grozavu</a> (ETIS - UMR 8051, CY), <a href="http://arxiv.org/find/cs/1/au:+Matei_B/0/1/0/all/0/1">Basarab Matei</a> (LIPN), <a href="http://arxiv.org/find/cs/1/au:+Goix_L/0/1/0/all/0/1">Laurent-Walter Goix</a></p>
<p>By combining related objects, unsupervised machine learning techniques aim to
reveal the underlying patterns in a data set. Non-negative Matrix Factorization
(NMF) is a data mining technique that splits data matrices by imposing
restrictions on the elements' non-negativity into two matrices: one
representing the data partitions and the other to represent the cluster
prototypes of the data set. This method has attracted a lot of attention and is
used in a wide range of applications, including text mining, clustering,
language modeling, music transcription, and neuroscience (gene separation). The
interpretation of the generated matrices is made simpler by the absence of
negative values. In this article, we propose a study on multi-modal clustering
algorithms and present a novel method called multi-modal multi-view
non-negative matrix factorization, in which we analyze the collaboration of
several local NMF models. The experimental results show the value of the
proposed approach, which was evaluated using a variety of data sets, and the
obtained results are very promising compared to state of art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04779">Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR. (arXiv:2308.04779v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chunpeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_K/0/1/0/all/0/1">Kangjie Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haishuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1">Jiajun Bu</a></p>
<p>The application of 3D ground-penetrating radar (3D-GPR) for subgrade distress
detection has gained widespread popularity. To enhance the efficiency and
accuracy of detection, pioneering studies have attempted to adopt automatic
detection techniques, particularly deep learning. However, existing works
typically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of the
GPR, resulting in either insufficient spatial information or high computational
complexity. To address these challenges, we introduce a novel methodology for
the subgrade distress detection task by leveraging the multi-view information
from 3D-GPR data. Moreover, we construct a real multi-view image dataset
derived from the original 3D-GPR data for the detection task, which provides
richer spatial information compared to A-scan and B-scan data, while reducing
computational complexity compared to C-scan data. Subsequently, we develop a
novel \textbf{M}ulti-\textbf{V}iew \textbf{V}usion and \textbf{D}istillation
framework, \textbf{GPR-MVFD}, specifically designed to optimally utilize the
multi-view GPR dataset. This framework ingeniously incorporates multi-view
distillation and attention-based fusion to facilitate significant feature
extraction for subgrade distresses. In addition, a self-adaptive learning
mechanism is adopted to stabilize the model training and prevent performance
degeneration in each branch. Extensive experiments conducted on this new GPR
benchmark demonstrate the effectiveness and efficiency of our proposed
framework. Our framework outperforms not only the existing GPR baselines, but
also the state-of-the-art methods in the fields of multi-view learning,
multi-modal learning, and knowledge distillation. We will release the
constructed multi-view GPR dataset with expert-annotated labels and the source
codes of the proposed framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04792">A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers. (arXiv:2308.04792v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yiming Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1">Guanghu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zongwu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1">Baoshi Cao</a></p>
<p>Intelligent autonomous path planning is crucial to improve the exploration
efficiency of planetary rovers. In this paper, we propose a learning-based
method to quickly search for optimal paths in an elevation map, which is called
NNPP. The NNPP model learns semantic information about start and goal
locations, as well as map representations, from numerous pre-annotated optimal
path demonstrations, and produces a probabilistic distribution over each pixel
representing the likelihood of it belonging to an optimal path on the map. More
specifically, the paper computes the traversal cost for each grid cell from the
slope, roughness and elevation difference obtained from the DEM. Subsequently,
the start and goal locations are encoded using a Gaussian distribution and
different location encoding parameters are analyzed for their effect on model
performance. After training, the NNPP model is able to perform path planning on
novel maps. Experiments show that the guidance field generated by the NNPP
model can significantly reduce the search time for optimal paths under the same
hardware conditions, and the advantage of NNPP increases with the scale of the
map.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04814">Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges. (arXiv:2308.04814v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gunjan Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1">Sumit Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Mutharaju_R/0/1/0/all/0/1">Raghava Mutharaju</a></p>
<p>Ontologies are used in various domains, with RDF and OWL being prominent
standards for ontology development. RDF is favored for its simplicity and
flexibility, while OWL enables detailed domain knowledge representation.
However, as ontologies grow larger and more expressive, reasoning complexity
increases, and traditional reasoners struggle to perform efficiently. Despite
optimization efforts, scalability remains an issue. Additionally, advancements
in automated knowledge base construction have created large and expressive
ontologies that are often noisy and inconsistent, posing further challenges for
conventional reasoners. To address these challenges, researchers have explored
neuro-symbolic approaches that combine neural networks' learning capabilities
with symbolic systems' reasoning abilities. In this chapter,we provide an
overview of the existing literature in the field of neuro-symbolic deductive
reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL,
discussing the techniques employed, the tasks they address, and other relevant
efforts in this area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04844">Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning. (arXiv:2308.04844v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vanneste_A/0/1/0/all/0/1">Astrid Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Somers_T/0/1/0/all/0/1">Thomas Somers</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanneste_S/0/1/0/all/0/1">Simon Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Mets_K/0/1/0/all/0/1">Kevin Mets</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_T/0/1/0/all/0/1">Tom De Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercelis_S/0/1/0/all/0/1">Siegfried Mercelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellinckx_P/0/1/0/all/0/1">Peter Hellinckx</a></p>
<p>Many multi-agent systems require inter-agent communication to properly
achieve their goal. By learning the communication protocol alongside the action
protocol using multi-agent reinforcement learning techniques, the agents gain
the flexibility to determine which information should be shared. However, when
the number of agents increases we need to create an encoding of the information
contained in these messages. In this paper, we investigate the effect of
increasing the amount of information that should be contained in a message and
increasing the number of agents. We evaluate these effects on two different
message encoding methods, the mean message encoder and the attention message
encoder. We perform our experiments on a matrix environment. Surprisingly, our
results show that the mean message encoder consistently outperforms the
attention message encoder. Therefore, we analyse the communication protocol
used by the agents that use the mean message encoder and can conclude that the
agents use a combination of an exponential and a logarithmic function in their
communication policy to avoid the loss of important information after applying
the mean message encoder.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04867">Learning Type-Generalized Actions for Symbolic Planning. (arXiv:2308.04867v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tanneberg_D/0/1/0/all/0/1">Daniel Tanneberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gienger_M/0/1/0/all/0/1">Michael Gienger</a></p>
<p>Symbolic planning is a powerful technique to solve complex tasks that require
long sequences of actions and can equip an intelligent agent with complex
behavior. The downside of this approach is the necessity for suitable symbolic
representations describing the state of the environment as well as the actions
that can change it. Traditionally such representations are carefully
hand-designed by experts for distinct problem domains, which limits their
transferability to different problems and environment complexities. In this
paper, we propose a novel concept to generalize symbolic actions using a given
entity hierarchy and observed similar behavior. In a simulated grid-based
kitchen environment, we show that type-generalized actions can be learned from
few observations and generalize to novel situations. Incorporating an
additional on-the-fly generalization mechanism during planning, unseen task
combinations, involving longer sequences, novel entities and unexpected
environment behavior, can be solved.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04889">NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?. (arXiv:2308.04889v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>, <a href="http://arxiv.org/find/cs/1/au:+Leiter_C/0/1/0/all/0/1">Christoph Leiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Belouadi_J/0/1/0/all/0/1">Jonas Belouadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ran Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kostikova_A/0/1/0/all/0/1">Aida Kostikova</a>, <a href="http://arxiv.org/find/cs/1/au:+Larionov_D/0/1/0/all/0/1">Daniil Larionov</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fresen_V/0/1/0/all/0/1">Vivian Fresen</a></p>
<p>The rapid growth of information in the field of Generative Artificial
Intelligence (AI), particularly in the subfields of Natural Language Processing
(NLP) and Machine Learning (ML), presents a significant challenge for
researchers and practitioners to keep pace with the latest developments. To
address the problem of information overload, this report by the Natural
Language Learning Group at Bielefeld University focuses on identifying the most
popular papers on arXiv, with a specific emphasis on NLP and ML. The objective
is to offer a quick guide to the most relevant and widely discussed research,
aiding both newcomers and established researchers in staying abreast of current
trends. In particular, we compile a list of the 40 most popular papers based on
normalized citation counts from the first half of 2023. We observe the
dominance of papers related to Large Language Models (LLMs) and specifically
ChatGPT during the first half of 2023, with the latter showing signs of
declining popularity more recently, however. Further, NLP related papers are
the most influential (around 60\% of top papers) even though there are twice as
many ML related papers in our data. Core issues investigated in the most
heavily cited papers are: LLM efficiency, evaluation techniques, ethical
considerations, embodied agents, and problem-solving with LLMs. Additionally,
we examine the characteristics of top papers in comparison to others outside
the top-40 list (noticing the top paper's focus on LLM related issues and
higher number of co-authors) and analyze the citation distributions in our
dataset, among others.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04905">GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters. (arXiv:2308.04905v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bernardez_G/0/1/0/all/0/1">Guillermo Bern&#xe1;rdez</a>, <a href="http://arxiv.org/find/cs/1/au:+Suarez_Varela_J/0/1/0/all/0/1">Jos&#xe9; Su&#xe1;rez-Varela</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1">Shihan Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiangle Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Barlet_Ros_P/0/1/0/all/0/1">Pere Barlet-Ros</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabellos_Aparicio_A/0/1/0/all/0/1">Albert Cabellos-Aparicio</a></p>
<p>Congestion Control (CC) plays a fundamental role in optimizing traffic in
Data Center Networks (DCN). Currently, DCNs mainly implement two main CC
protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are
based on Explicit Congestion Notification (ECN), where intermediate switches
mark packets when they detect congestion. The ECN configuration is thus a
crucial aspect on the performance of CC protocols. Nowadays, network experts
set static ECN parameters carefully selected to optimize the average network
performance. However, today's high-speed DCNs experience quick and abrupt
changes that severely change the network state (e.g., dynamic traffic
workloads, incast events, failures). This leads to under-utilization and
sub-optimal performance. This paper presents GraphCC, a novel Machine
Learning-based framework for in-network CC optimization. Our distributed
solution relies on a novel combination of Multi-agent Reinforcement Learning
(MARL) and Graph Neural Networks (GNN), and it is compatible with widely
deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches
that communicate with their neighbors to cooperate and optimize the global ECN
configuration. In our evaluation, we test the performance of GraphCC under a
wide variety of scenarios, focusing on the capability of this solution to adapt
to new scenarios unseen during training (e.g., new traffic workloads, failures,
upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for
ECN tuning -- ACC -- and observe that our proposed solution outperforms the
state-of-the-art baseline in all of the evaluation scenarios, showing
improvements up to $20\%$ in Flow Completion Time as well as significant
reductions in buffer occupancy ($38.0-85.7\%$).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04909">Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks. (arXiv:2308.04909v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Borchjes_L/0/1/0/all/0/1">Luke Borchjes</a>, <a href="http://arxiv.org/find/cs/1/au:+Nyirenda_C/0/1/0/all/0/1">Clement Nyirenda</a>, <a href="http://arxiv.org/find/cs/1/au:+Leenen_L/0/1/0/all/0/1">Louise Leenen</a></p>
<p>This paper focuses on the impact of leveraging autonomous offensive
approaches in Deep Reinforcement Learning (DRL) to train more robust agents by
exploring the impact of applying adversarial learning to DRL for autonomous
security in Software Defined Networks (SDN). Two algorithms, Double Deep
Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or
N2D), are compared. NEC2DQN was proposed in 2018 and is a new member of the
deep q-network (DQN) family of algorithms. The attacker has full observability
of the environment and access to a causative attack that uses state
manipulation in an attempt to poison the learning process. The implementation
of the attack is done under a white-box setting, in which the attacker has
access to the defender's model and experiences. Two games are played; in the
first game, DDQN is a defender and N2D is an attacker, and in second game, the
roles are reversed. The games are played twice; first, without an active
causative attack and secondly, with an active causative attack. For execution,
three sets of game results are recorded in which a single set consists of 10
game runs. The before and after results are then compared in order to see if
there was actually an improvement or degradation. The results show that with
minute parameter changes made to the algorithms, there was growth in the
attacker's role, since it is able to win games. Implementation of the
adversarial learning by the introduction of the causative attack showed the
algorithms are still able to defend the network according to their strengths.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04911">SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation. (arXiv:2308.04911v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_F/0/1/0/all/0/1">Fan Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Ke Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiaoyu Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xinyu Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xiaoli Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yu Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Le Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_M/0/1/0/all/0/1">Max Q.-H. Meng</a></p>
<p>Medical image analysis using deep learning is often challenged by limited
labeled data and high annotation costs. Fine-tuning the entire network in
label-limited scenarios can lead to overfitting and suboptimal performance.
Recently, prompt tuning has emerged as a more promising technique that
introduces a few additional tunable parameters as prompts to a task-agnostic
pre-trained model, and updates only these parameters using supervision from
limited labeled data while keeping the pre-trained model unchanged. However,
previous work has overlooked the importance of selective labeling in downstream
tasks, which aims to select the most valuable downstream samples for annotation
to achieve the best performance with minimum annotation cost. To address this,
we propose a framework that combines selective labeling with prompt tuning
(SLPT) to boost performance in limited labels. Specifically, we introduce a
feature-aware prompt updater to guide prompt tuning and a TandEm Selective
LAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection and
supervised selection using prompt-based uncertainty. In addition, we propose a
diversified visual prompt tuning strategy to provide multi-prompt-based
discrepant predictions for TESLA. We evaluate our method on liver tumor
segmentation and achieve state-of-the-art performance, outperforming
traditional fine-tuning with only 6% of tunable parameters, also achieving 94%
of full-data performance by labeling only 5% of the data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04913">LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following. (arXiv:2308.04913v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Kaize Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xueyao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dingxian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yinlin Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guandong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a></p>
<p>E-commerce authoring involves creating attractive, abundant, and targeted
promotional content to drive product sales. The emergence of large language
models (LLMs) introduces an innovative paradigm, offering a unified solution to
address various authoring tasks within this scenario. However, mainstream LLMs
trained on general corpora with common sense knowledge reveal limitations in
fitting complex and personalized features unique to e-commerce products and
customers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility,
raising concerns about safeguarding voluminous customer privacy data during
transmission. This paper proposes the LLaMA-E, the unified and customized
instruction-following language models focusing on diverse e-commerce authoring
tasks. Specifically, the domain experts create the seed instruction set from
the tasks of ads generation, query-enhanced product title rewriting, product
classification, purchase intent speculation, and general Q&amp;A. These tasks
enable the models to comprehensively understand precise e-commerce authoring
knowledge by interleaving features covering typical service aspects of
customers, sellers, and platforms. The GPT-3.5 is introduced as a teacher
model, which expands the seed instructions to form a training set for the
LLaMA-E models with various scales. The experimental results show that the
proposed LLaMA-E models achieve state-of-the-art results in quantitative and
qualitative evaluations, also exhibiting the advantage in zero-shot scenes. To
the best of our knowledge, this study is the first to serve the LLMs to
specific e-commerce authoring scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04914">Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach. (arXiv:2308.04914v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xumin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jiawen Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1">Jiangtian Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1">Weifeng Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong In Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shengli Xie</a></p>
<p>Metaverse enables users to communicate, collaborate and socialize with each
other through their digital avatars. Due to the spatio-temporal
characteristics, co-located users are served well by performing their software
components in a collaborative manner such that a Metaverse service provider
(MSP) eliminates redundant data transmission and processing, ultimately
reducing the total energy consumption. The energyefficient service provision is
crucial for enabling the green and sustainable Metaverse. In this article, we
take an augmented reality (AR) application as an example to achieve this goal.
Moreover, we study an economic issue on how the users reserve offloading
services from the MSP and how the MSP determines an optimal charging price
since each user is rational to decide whether to accept the offloading service
by taking into account the monetary cost. A single-leader multi-follower
Stackelberg game is formulated between the MSP and users while each user
optimizes an offloading probability to minimize the weighted sum of time,
energy consumption and monetary cost. Numerical results show that our scheme
achieves energy savings and satisfies individual rationality simultaneously
compared with the conventional schemes. Finally, we identify and discuss open
directions on how several emerging technologies are combined with the
sustainable green Metaverse.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04938">An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning. (arXiv:2308.04938v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vanneste_A/0/1/0/all/0/1">Astrid Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanneste_S/0/1/0/all/0/1">Simon Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Mets_K/0/1/0/all/0/1">Kevin Mets</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_T/0/1/0/all/0/1">Tom De Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercelis_S/0/1/0/all/0/1">Siegfried Mercelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellinckx_P/0/1/0/all/0/1">Peter Hellinckx</a></p>
<p>Communication is crucial in multi-agent reinforcement learning when agents
are not able to observe the full state of the environment. The most common
approach to allow learned communication between agents is the use of a
differentiable communication channel that allows gradients to flow between
agents as a form of feedback. However, this is challenging when we want to use
discrete messages to reduce the message size, since gradients cannot flow
through a discrete communication channel. Previous work proposed methods to
deal with this problem. However, these methods are tested in different
communication learning architectures and environments, making it hard to
compare them. In this paper, we compare several state-of-the-art discretization
methods as well as a novel approach. We do this comparison in the context of
communication learning using gradients from other agents and perform tests on
several environments. In addition, we present COMA-DIAL, a communication
learning approach based on DIAL and COMA extended with learning rate scaling
and adapted exploration. Using COMA-DIAL allows us to perform experiments on
more complex environments. Our results show that the novel ST-DRU method,
proposed in this paper, achieves the best results out of all discretization
methods across the different environments. It achieves the best or close to the
best performance in each of the experiments and is the only method that does
not fail on any of the tested environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04942">Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation. (arXiv:2308.04942v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Hongyang Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jiawen Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zehui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong In Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xuemin/0/1/0/all/0/1">Xuemin</a> (Sherman) <a href="http://arxiv.org/find/cs/1/au:+Shen/0/1/0/all/0/1">Shen</a></p>
<p>Artificial Intelligence Generated Content (AIGC) Services have significant
potential in digital content creation. The distinctive abilities of AIGC, such
as content generation based on minimal input, hold huge potential, especially
when integrating with semantic communication (SemCom). In this paper, a novel
comprehensive conceptual model for the integration of AIGC and SemCom is
developed. Particularly, a content generation level is introduced on top of the
semantic level that provides a clear outline of how AIGC and SemCom interact
with each other to produce meaningful and effective content. Moreover, a novel
framework that employs AIGC technology is proposed as an encoder and decoder
for semantic information, considering the joint optimization of semantic
extraction and evaluation metrics tailored to AIGC services. The framework can
adapt to different types of content generated, the required quality, and the
semantic information utilized. By employing a Deep Q Network (DQN), a case
study is presented that provides useful insights into the feasibility of the
optimization problem and its convergence characteristics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04944">Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection. (arXiv:2308.04944v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gula_T/0/1/0/all/0/1">Tetiana Gula</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertoldo_J/0/1/0/all/0/1">Jo&#xe3;o P C Bertoldo</a></p>
<p>Anomaly detection (AD) in images, identifying significant deviations from
normality, is a critical issue in computer vision. This paper introduces a
novel approach to dimensionality reduction for AD using pre-trained
convolutional neural network (CNN) that incorporate EfficientNet models. We
investigate the importance of component selection and propose two types of tree
search approaches, both employing a greedy strategy, for optimal eigencomponent
selection. Our study conducts three main experiments to evaluate the
effectiveness of our approach. The first experiment explores the influence of
test set performance on component choice, the second experiment examines the
performance when we train on one anomaly type and evaluate on all other types,
and the third experiment investigates the impact of using a minimum number of
images for training and selecting them based on anomaly types. Our approach
aims to find the optimal subset of components that deliver the highest
performance score, instead of focusing solely on the proportion of variance
explained by each component and also understand the components behaviour in
different settings. Our results indicate that the proposed method surpasses
both Principal Component Analysis (PCA) and Negated Principal Component
Analysis (NPCA) in terms of detection accuracy, even when using fewer
components. Thus, our approach provides a promising alternative to conventional
dimensionality reduction techniques in AD, and holds potential to enhance the
efficiency and effectiveness of AD systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04945">LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking. (arXiv:2308.04945v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1">Fahim Dalvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasanain_M/0/1/0/all/0/1">Maram Hasanain</a>, <a href="http://arxiv.org/find/cs/1/au:+Boughorbel_S/0/1/0/all/0/1">Sabri Boughorbel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousi_B/0/1/0/all/0/1">Basel Mousi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdaljalil_S/0/1/0/all/0/1">Samir Abdaljalil</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazar_N/0/1/0/all/0/1">Nizi Nazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelali_A/0/1/0/all/0/1">Ahmed Abdelali</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Mubarak_H/0/1/0/all/0/1">Hamdy Mubarak</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawasly_M/0/1/0/all/0/1">Majd Hawasly</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1">Nadir Durrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a></p>
<p>The recent development and success of Large Language Models (LLMs)
necessitate an evaluation of their performance across diverse NLP tasks in
different languages. Although several frameworks have been developed and made
publicly available, their customization capabilities for specific tasks and
datasets are often complex for different users. In this study, we introduce the
LLMeBench framework. Initially developed to evaluate Arabic NLP tasks using
OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task
and model, regardless of language. The framework also features zero- and
few-shot learning settings. A new custom dataset can be added in less than 10
minutes, and users can use their own model API keys to evaluate the task at
hand. The developed framework has been already tested on 31 unique NLP tasks
using 53 publicly available datasets within 90 experimental setups, involving
approximately 296K data points. We plan to open-source the framework for the
community (https://github.com/qcri/LLMeBench/). A video demonstrating the
framework is available online (https://youtu.be/FkQn4UjYA0s).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04947">Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey. (arXiv:2308.04947v1 [q-fin.ST])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Wang_L/0/1/0/all/0/1">Liping Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Li_J/0/1/0/all/0/1">Jiawei Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhao_L/0/1/0/all/0/1">Lifan Zhao</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Kou_Z/0/1/0/all/0/1">Zhizhuo Kou</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_X/0/1/0/all/0/1">Xiaohan Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhu_X/0/1/0/all/0/1">Xinyi Zhu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Shen_Y/0/1/0/all/0/1">Yanyan Shen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a></p>
<p>Predicting stock prices presents a challenging research problem due to the
inherent volatility and non-linear nature of the stock market. In recent years,
knowledge-enhanced stock price prediction methods have shown groundbreaking
results by utilizing external knowledge to understand the stock market. Despite
the importance of these methods, there is a scarcity of scholarly works that
systematically synthesize previous studies from the perspective of external
knowledge types. Specifically, the external knowledge can be modeled in
different data structures, which we group into non-graph-based formats and
graph-based formats: 1) non-graph-based knowledge captures contextual
information and multimedia descriptions specifically associated with an
individual stock; 2) graph-based knowledge captures interconnected and
interdependent information in the stock market. This survey paper aims to
provide a systematic and comprehensive description of methods for acquiring
external knowledge from various unstructured data sources and then
incorporating it into stock price prediction models. We also explore fusion
methods for combining external knowledge with historical price features.
Moreover, this paper includes a compilation of relevant datasets and delves
into potential future research directions in this domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04952">Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation. (arXiv:2308.04952v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Feigege Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_Y/0/1/0/all/0/1">Ye Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yutao Gao</a></p>
<p>Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic
Segmentation (FSS) to simultaneously segment unseen classes and seen classes
during evaluation. Previous works leverage additional branch or prototypical
aggregation to eliminate the constrained setting of FSS. However,
representation division and embedding prejudice, which heavily results in poor
performance of GFSS, have not been synthetical considered. We address the
aforementioned problems by jointing the prototypical kernel learning and
open-set foreground perception. Specifically, a group of learnable kernels is
proposed to perform segmentation with each kernel in charge of a stuff class.
Then, we explore to merge the prototypical learning to the update of base-class
kernels, which is consistent with the prototype knowledge aggregation of
few-shot novel classes. In addition, a foreground contextual perception module
cooperating with conditional bias based inference is adopted to perform
class-agnostic as well as open-set foreground detection, thus to mitigate the
embedding prejudice and prevent novel targets from being misclassified as
background. Moreover, we also adjust our method to the Class Incremental
Few-shot Semantic Segmentation (CIFSS) which takes the knowledge of novel
classes in a incremental stream. Extensive experiments on PASCAL-5i and
COCO-20i datasets demonstrate that our method performs better than previous
state-of-the-art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04953">Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation. (arXiv:2308.04953v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Le_M/0/1/0/all/0/1">Mai Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1">Dinh Thai Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Diep N. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Won-Joo Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1">Quoc-Viet Pham</a></p>
<p>Federated learning (FL) has found many successes in wireless networks;
however, the implementation of FL has been hindered by the energy limitation of
mobile devices (MDs) and the availability of training data at MDs. How to
integrate wireless power transfer and mobile crowdsensing towards sustainable
FL solutions is a research topic entirely missing from the open literature.
This work for the first time investigates a resource allocation problem in
collaborative sensing-assisted sustainable FL (S2FL) networks with the goal of
minimizing the total completion time. We investigate a practical
harvesting-sensing-training-transmitting protocol in which energy-limited MDs
first harvest energy from RF signals, use it to gain a reward for user
participation, sense the training data from the environment, train the local
models at MDs, and transmit the model updates to the server. The total
completion time minimization problem of jointly optimizing power transfer,
transmit power allocation, data sensing, bandwidth allocation, local model
training, and data transmission is complicated due to the non-convex objective
function, highly non-convex constraints, and strongly coupled variables. We
propose a computationally-efficient path-following algorithm to obtain the
optimal solution via the decomposition technique. In particular, inner convex
approximations are developed for the resource allocation subproblem, and the
subproblems are performed alternatively in an iterative fashion. Simulation
results are provided to evaluate the effectiveness of the proposed S2FL
algorithm in reducing the completion time up to 21.45% in comparison with other
benchmark schemes. Further, we investigate an extension of our work from
frequency division multiple access (FDMA) to non-orthogonal multiple access
(NOMA) and show that NOMA can speed up the total completion time 8.36% on
average of the considered FL system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04958">Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks. (arXiv:2308.04958v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brittain_M/0/1/0/all/0/1">Marc W. Brittain</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_L/0/1/0/all/0/1">Luis E. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Breeden_K/0/1/0/all/0/1">Kara Breeden</a></p>
<p>Advanced Air Mobility (AAM) introduces a new, efficient mode of
transportation with the use of vehicle autonomy and electrified aircraft to
provide increasingly autonomous transportation between previously underserved
markets. Safe and efficient navigation of low altitude aircraft through highly
dense environments requires the integration of a multitude of complex
observations, such as surveillance, knowledge of vehicle dynamics, and weather.
The processing and reasoning on these observations pose challenges due to the
various sources of uncertainty in the information while ensuring cooperation
with a variable number of aircraft in the airspace. These challenges coupled
with the requirement to make safety-critical decisions in real-time rule out
the use of conventional separation assurance techniques. We present a
decentralized reinforcement learning framework to provide autonomous
self-separation capabilities within AAM corridors with the use of speed and
vertical maneuvers. The problem is formulated as a Markov Decision Process and
solved by developing a novel extension to the sample-efficient, off-policy soft
actor-critic (SAC) algorithm. We introduce the use of attention networks for
variable-length observation processing and a distributed computing architecture
to achieve high training sample throughput as compared to existing approaches.
A comprehensive numerical study shows that the proposed framework can ensure
safe and efficient separation of aircraft in high density, dynamic environments
with various sources of uncertainty.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04982">Exploring Multilingual Text Data Distillation. (arXiv:2308.04982v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sahni_S/0/1/0/all/0/1">Shivam Sahni</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_H/0/1/0/all/0/1">Harsh Patel</a></p>
<p>With the rise of deep learning, large datasets and complex models have become
common, requiring significant computing power. To address this, data
distillation has emerged as a technique to quickly train models with lower
memory and time requirements. However, data distillation on text-based datasets
hasn't been explored much because of the challenges rising due to its discrete
nature. Additionally, existing dataset distillation methods often struggle to
generalize to new architectures. In the paper, we propose several data
distillation techniques for multilingual text classification datasets using
language-model-based learning methods. We conduct experiments to analyze their
performance in terms of classification strength, and cross-architecture
generalization. Furthermore, we investigate the language-specific fairness of
the data summaries generated by these methods. Our approach builds upon
existing techniques, enhancing cross-architecture generalization in the text
data distillation domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04992">AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities. (arXiv:2308.04992v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingdan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaodan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhixu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yanghua Xiao</a></p>
<p>Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text
and image) for a comprehensive understanding of entities. Despite the recent
progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature
of entities, limiting the ability to comprehend entities from various
perspectives. In this paper, we construct AspectMMKG, the first MMKG with
aspect-related images by matching images to different entity aspects.
Specifically, we collect aspect-related images from a knowledge base, and
further extract aspect-related sentences from the knowledge base as queries to
retrieve a large number of aspect-related images via an online image search
engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and
645,383 aspect-related images. We demonstrate the usability of AspectMMKG in
entity aspect linking (EAL) downstream task and show that previous EAL models
achieve a new state-of-the-art performance with the help of AspectMMKG. To
facilitate the research on aspect-related MMKG, we further propose an
aspect-related image retrieval (AIR) model, that aims to correct and expand
aspect-related images in AspectMMKG. We train an AIR model to learn the
relationship between entity image and entity aspect-related images by
incorporating entity image, aspect, and aspect image information. Experimental
results indicate that the AIR model could retrieve suitable images for a given
entity w.r.t different aspects.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05012">MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model. (arXiv:2308.05012v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leong_M/0/1/0/all/0/1">Michael Leong</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelhalim_A/0/1/0/all/0/1">Awad Abdelhalim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1">Jude Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Patterson_D/0/1/0/all/0/1">Dianne Patterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Pincus_G/0/1/0/all/0/1">Gabriel L. Pincus</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_A/0/1/0/all/0/1">Anthony B. Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Eichler_M/0/1/0/all/0/1">Michael Eichler</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jinhua Zhao</a></p>
<p>Transit riders' feedback provided in ridership surveys, customer relationship
management (CRM) channels, and in more recent times, through social media is
key for transit agencies to better gauge the efficacy of their services and
initiatives. Getting a holistic understanding of riders' experience through the
feedback shared in those instruments is often challenging, mostly due to the
open-ended, unstructured nature of text feedback. In this paper, we propose
leveraging traditional transit CRM feedback to develop and deploy a
transit-topic-aware large language model (LLM) capable of classifying
open-ended text feedback to relevant transit-specific topics. First, we utilize
semi-supervised learning to engineer a training dataset of 11 broad transit
topics detected in a corpus of 6 years of customer feedback provided to the
Washington Metropolitan Area Transit Authority (WMATA). We then use this
dataset to train and thoroughly evaluate a language model based on the RoBERTa
architecture. We compare our LLM, MetRoBERTa, to classical machine learning
approaches utilizing keyword-based and lexicon representations. Our model
outperforms those methods across all evaluation metrics, providing an average
topic classification accuracy of 90%. Finally, we provide a value proposition
of this work demonstrating how the language model, alongside additional text
processing tools, can be applied to add structure to open-ended text sources of
feedback like Twitter. The framework and results we present provide a pathway
for an automated, generalizable approach for ingesting, visualizing, and
reporting transit riders' feedback at scale, enabling agencies to better
understand and improve customer experience.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05035">Expert load matters: operating networks at high accuracy and low manual effort. (arXiv:2308.05035v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sangalli_S/0/1/0/all/0/1">Sara Sangalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdil_E/0/1/0/all/0/1">Ertunc Erdil</a>, <a href="http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1">Ender Konukoglu</a></p>
<p>In human-AI collaboration systems for critical applications, in order to
ensure minimal error, users should set an operating point based on model
confidence to determine when the decision should be delegated to human experts.
Samples for which model confidence is lower than the operating point would be
manually analysed by experts to avoid mistakes. Such systems can become truly
useful only if they consider two aspects: models should be confident only for
samples for which they are accurate, and the number of samples delegated to
experts should be minimized. The latter aspect is especially crucial for
applications where available expert time is limited and expensive, such as
healthcare. The trade-off between the model accuracy and the number of samples
delegated to experts can be represented by a curve that is similar to an ROC
curve, which we refer to as confidence operating characteristic (COC) curve. In
this paper, we argue that deep neural networks should be trained by taking into
account both accuracy and expert load and, to that end, propose a new
complementary loss function for classification that maximizes the area under
this COC curve. This promotes simultaneously the increase in network accuracy
and the reduction in number of samples delegated to humans. We perform
experiments on multiple computer vision and medical image datasets for
classification. Our results demonstrate that the proposed loss improves
classification accuracy and delegates less number of decisions to experts,
achieves better out-of-distribution samples detection and on par calibration
performance compared to existing loss functions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05037">Separate Anything You Describe. (arXiv:2308.05037v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xubo Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kong_Q/0/1/0/all/0/1">Qiuqiang Kong</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yan Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_H/0/1/0/all/0/1">Haohe Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_Y/0/1/0/all/0/1">Yi Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yuzhuo Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xia_R/0/1/0/all/0/1">Rui Xia</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yuxuan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Plumbley_M/0/1/0/all/0/1">Mark D. Plumbley</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Wenwu Wang</a></p>
<p>Language-queried audio source separation (LASS) is a new paradigm for
computational auditory scene analysis (CASA). LASS aims to separate a target
sound from an audio mixture given a natural language query, which provides a
natural and scalable interface for digital audio applications. Recent works on
LASS, despite attaining promising separation performance on specific sources
(e.g., musical instruments, limited classes of audio events), are unable to
separate audio concepts in the open domain. In this work, we introduce
AudioSep, a foundation model for open-domain audio source separation with
natural language queries. We train AudioSep on large-scale multimodal datasets
and extensively evaluate its capabilities on numerous tasks including audio
event separation, musical instrument separation, and speech enhancement.
AudioSep demonstrates strong separation performance and impressive zero-shot
generalization ability using audio captions or text labels as queries,
substantially outperforming previous audio-queried and language-queried sound
separation models. For reproducibility of this work, we will release the source
code, evaluation benchmark and pre-trained model at:
https://github.com/Audio-AGI/AudioSep.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05062">Competitions in AI -- Robustly Ranking Solvers Using Statistical Resampling. (arXiv:2308.05062v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fawcett_C/0/1/0/all/0/1">Chris Fawcett</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallati_M/0/1/0/all/0/1">Mauro Vallati</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoos_H/0/1/0/all/0/1">Holger H. Hoos</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerevini_A/0/1/0/all/0/1">Alfonso E. Gerevini</a></p>
<p>Solver competitions play a prominent role in assessing and advancing the
state of the art for solving many problems in AI and beyond. Notably, in many
areas of AI, competitions have had substantial impact in guiding research and
applications for many years, and for a solver to be ranked highly in a
competition carries considerable weight. But to which extent can we expect
competition results to generalise to sets of problem instances different from
those used in a particular competition? This is the question we investigate
here, using statistical resampling techniques. We show that the rankings
resulting from the standard interpretation of competition results can be very
sensitive to even minor changes in the benchmark instance set used as the basis
for assessment and can therefore not be expected to carry over to other samples
from the same underlying instance distribution. To address this problem, we
introduce a novel approach to statistically meaningful analysis of competition
results based on resampling performance data. Our approach produces confidence
intervals of competition scores as well as statistically robust solver rankings
with bounded error. Applied to recent SAT, AI planning and computer vision
competitions, our analysis reveals frequent statistical ties in solver
performance as well as some inversions of ranks compared to the official
results based on simple scoring.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05074">Drones4Good: Supporting Disaster Relief Through Remote Sensing and AI. (arXiv:2308.05074v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Merkle_N/0/1/0/all/0/1">Nina Merkle</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahmanyar_R/0/1/0/all/0/1">Reza Bahmanyar</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_C/0/1/0/all/0/1">Corentin Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Azimi_S/0/1/0/all/0/1">Seyed Majid Azimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1">Xiangtian Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schopferer_S/0/1/0/all/0/1">Simon Schopferer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gstaiger_V/0/1/0/all/0/1">Veronika Gstaiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">Stefan Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneibel_A/0/1/0/all/0/1">Anne Schneibel</a>, <a href="http://arxiv.org/find/cs/1/au:+Wieland_M/0/1/0/all/0/1">Marc Wieland</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraft_T/0/1/0/all/0/1">Thomas Kraft</a></p>
<p>In order to respond effectively in the aftermath of a disaster, emergency
services and relief organizations rely on timely and accurate information about
the affected areas. Remote sensing has the potential to significantly reduce
the time and effort required to collect such information by enabling a rapid
survey of large areas. To achieve this, the main challenge is the automatic
extraction of relevant information from remotely sensed data. In this work, we
show how the combination of drone-based data with deep learning methods enables
automated and large-scale situation assessment. In addition, we demonstrate the
integration of onboard image processing techniques for the deployment of
autonomous drone-based aid delivery. The results show the feasibility of a
rapid and large-scale image analysis in the field, and that onboard image
processing can increase the safety of drone-based aid deliveries.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05085">Organizational Bulk Email Systems: Their Role and Performance in Remote Work. (arXiv:2308.05085v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kong_R/0/1/0/all/0/1">Ruoyan Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Haiyi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Konstan_J/0/1/0/all/0/1">Joseph A. Konstan</a></p>
<p>The COVID-19 pandemic has forced many employees to work from home.
Organizational bulk emails now play a critical role to reach employees with
central information in this work-from-home environment. However, we know from
our own recent work that organizational bulk email has problems: recipients
fail to retain the bulk messages they received from the organization;
recipients and senders have different opinions on which bulk messages were
important; and communicators lack technology support to better target and
design messages. In this position paper, first we review the prior work on
evaluating, designing, and prototyping organizational communication systems.
Second we review our recent findings and some research techniques we found
useful in studying organizational communication. Last we propose a research
agenda to study organizational communications in remote work environment and
suggest some key questions and potential study directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05095">LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation. (arXiv:2308.05095v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Leigang Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shengqiong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1">Hao Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Liqiang Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a></p>
<p>In the text-to-image generation field, recent remarkable progress in Stable
Diffusion makes it possible to generate rich kinds of novel photorealistic
images. However, current models still face misalignment issues (e.g.,
problematic spatial relation understanding and numeration failure) in complex
natural scenes, which impedes the high-faithfulness text-to-image generation.
Although recent efforts have been made to improve controllability by giving
fine-grained guidance (e.g., sketch and scribbles), this issue has not been
fundamentally tackled since users have to provide such guidance information
manually. In this work, we strive to synthesize high-fidelity images that are
semantically aligned with a given textual prompt without any guidance. Toward
this end, we propose a coarse-to-fine paradigm to achieve layout planning and
image generation. Concretely, we first generate the coarse-grained layout
conditioned on a given textual prompt via in-context learning based on Large
Language Models. Afterward, we propose a fine-grained object-interaction
diffusion method to synthesize high-faithfulness images conditioned on the
prompt and the automatically generated layout. Extensive experiments
demonstrate that our proposed method outperforms the state-of-the-art models in
terms of layout and image generation. Our code and settings are available at
\url{https://layoutllm-t2i.github.io}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05101">DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels. (arXiv:2308.05101v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Soumadeep Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Garain_U/0/1/0/all/0/1">Utpal Garain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ukil_A/0/1/0/all/0/1">Arijit Ukil</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1">Arpan Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_S/0/1/0/all/0/1">Sundeep Khandelwal</a></p>
<p>The enormous demand for annotated data brought forth by deep learning
techniques has been accompanied by the problem of annotation noise. Although
this issue has been widely discussed in machine learning literature, it has
been relatively unexplored in the context of "multi-label classification" (MLC)
tasks which feature more complicated kinds of noise. Additionally, when the
domain in question has certain logical constraints, noisy annotations often
exacerbate their violations, making such a system unacceptable to an expert.
This paper studies the effect of label noise on domain rule violation incidents
in the MLC task, and incorporates domain rules into our learning algorithm to
mitigate the effect of noise. We propose the Domain Obedient Self-supervised
Training (DOST) paradigm which not only makes deep learning models more aligned
to domain rules, but also improves learning performance in key metrics and
minimizes the effect of annotation noise. This novel approach uses domain
guidance to detect offending annotations and deter rule-violating predictions
in a self-supervised manner, thus making it more "data efficient" and domain
compliant. Empirical studies, performed over two large scale multi-label
classification datasets, demonstrate that our method results in improvement
across the board, and often entirely counteracts the effect of noise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.01937">BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification. (arXiv:2203.01937v5 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yuanhong Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1">Fengbei Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Hu Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chong Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Tian_Y/0/1/0/all/0/1">Yu Tian</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yuyuan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a></p>
<p>Deep learning methods have shown outstanding classification accuracy in
medical imaging problems, which is largely attributed to the availability of
large-scale datasets manually annotated with clean labels. However, given the
high cost of such manual annotation, new medical imaging classification
problems may need to rely on machine-generated noisy labels extracted from
radiology reports. Indeed, many Chest X-ray (CXR) classifiers have already been
modelled from datasets with noisy labels, but their training procedure is in
general not robust to noisy-label samples, leading to sub-optimal models.
Furthermore, CXR datasets are mostly multi-label, so current noisy-label
learning methods designed for multi-class problems cannot be easily adapted. In
this paper, we propose a new method designed for the noisy multi-label CXR
learning, which detects and smoothly re-labels samples from the dataset, which
is then used to train common multi-label classifiers. The proposed method
optimises a bag of multi-label descriptors (BoMD) to promote their similarity
with the semantic descriptors produced by BERT models from the multi-label
image annotation. Our experiments on diverse noisy multi-label training sets
and clean testing sets show that our model has state-of-the-art accuracy and
robustness in many CXR multi-label classification benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.02307">A first-order logic characterization of safety and co-safety languages. (arXiv:2209.02307v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cimatti_A/0/1/0/all/0/1">Alessandro Cimatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Geatti_L/0/1/0/all/0/1">Luca Geatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gigante_N/0/1/0/all/0/1">Nicola Gigante</a>, <a href="http://arxiv.org/find/cs/1/au:+Montanari_A/0/1/0/all/0/1">Angelo Montanari</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonetta_S/0/1/0/all/0/1">Stefano Tonetta</a></p>
<p>Linear Temporal Logic (LTL) is one of the most popular temporal logics, that
comes into play in a variety of branches of computer science. Among the various
reasons of its widespread use there are its strong foundational properties: LTL
is equivalent to counter-free omega-automata, to star-free omega-regular
expressions, and (by Kamp's theorem) to the First-Order Theory of Linear Orders
(FO-TLO). Safety and co-safety languages, where a finite prefix suffices to
establish whether a word does not belong or belongs to the language,
respectively, play a crucial role in lowering the complexity of problems like
model checking and reactive synthesis for LTL. SafetyLTL (resp., coSafetyLTL)
is a fragment of LTL where only universal (resp., existential) temporal
modalities are allowed, that recognises safety (resp., co-safety) languages
only. The main contribution of this paper is the introduction of a fragment of
FO-TLO, called SafetyFO, and of its dual coSafetyFO, which are expressively
complete with respect to the LTL-definable safety and co-safety languages. We
prove that they exactly characterize SafetyLTL and coSafetyLTL, respectively, a
result that joins Kamp's theorem, and provides a clearer view of the
characterization of (fragments of) LTL in terms of first-order languages. In
addition, it gives a direct, compact, and self-contained proof that any safety
language definable in LTL is definable in SafetyLTL as well. As a by-product,
we obtain some interesting results on the expressive power of the weak tomorrow
operator of SafetyLTL, interpreted over finite and infinite words. Moreover, we
prove that, when interpreted over finite words, SafetyLTL (resp. coSafetyLTL)
devoid of the tomorrow (resp., weak tomorrow) operator captures the safety
(resp., co-safety) fragment of LTL over finite words.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.12126">One-Shot Neural Fields for 3D Object Understanding. (arXiv:2210.12126v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Blukis_V/0/1/0/all/0/1">Valts Blukis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1">Taeyeop Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tremblay_J/0/1/0/all/0/1">Jonathan Tremblay</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1">Bowen Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kuk-Jin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Birchfield_S/0/1/0/all/0/1">Stan Birchfield</a></p>
<p>We present a unified and compact scene representation for robotics, where
each object in the scene is depicted by a latent code capturing geometry and
appearance. This representation can be decoded for various tasks such as novel
view rendering, 3D reconstruction (e.g. recovering depth, point clouds, or
voxel maps), collision checking, and stable grasp prediction. We build our
representation from a single RGB input image at test time by leveraging recent
advances in Neural Radiance Fields (NeRF) that learn category-level priors on
large multiview datasets, then fine-tune on novel objects from one or few
views. We expand the NeRF model for additional grasp outputs and explore ways
to leverage this representation for robotics. At test-time, we build the
representation from a single RGB input image observing the scene from only one
viewpoint. We find that the recovered representation allows rendering from
novel views, including of occluded object parts, and also for predicting
successful stable grasps. Grasp poses can be directly decoded from our latent
representation with an implicit grasp decoder. We experimented in both
simulation and real world and demonstrated the capability for robust robotic
grasping using such compact representation. Website:
https://nerfgrasp.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.02408">Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis. (arXiv:2211.02408v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1">Lukas Struppek</a>, <a href="http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1">Dominik Hintersdorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a></p>
<p>While text-to-image synthesis currently enjoys great popularity among
researchers and the general public, the security of these models has been
neglected so far. Many text-guided image generation models rely on pre-trained
text encoders from external sources, and their users trust that the retrieved
models will behave as promised. Unfortunately, this might not be the case. We
introduce backdoor attacks against text-guided generative models and
demonstrate that their text encoders pose a major tampering risk. Our attacks
only slightly alter an encoder so that no suspicious model behavior is apparent
for image generations with clean prompts. By then inserting a single character
trigger into the prompt, e.g., a non-Latin character or emoji, the adversary
can trigger the model to either generate images with pre-defined attributes or
images following a hidden, potentially malicious description. We empirically
demonstrate the high effectiveness of our attacks on Stable Diffusion and
highlight that the injection process of a single backdoor takes less than two
minutes. Besides phrasing our approach solely as an attack, it can also force
an encoder to forget phrases related to certain concepts, such as nudity or
violence, and help to make image generation safer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.06108">RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System. (arXiv:2211.06108v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yanlong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jianan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1">Qing-Long Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1">Gang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Bing Zhu</a></p>
<p>In autonomous driving systems, LiDAR and radar play important roles in the
perception of the surrounding environment. LiDAR provides accurate 3D spatial
sensing information but cannot work in adverse weather like fog. On the other
hand, the radar signal can be diffracted when encountering raindrops or mist
particles thanks to its wavelength, but it suffers from large noise. Recent
state-of-the-art works reveal that fusion of radar and LiDAR can lead to robust
detection in adverse weather. The existing works adopt convolutional neural
network architecture to extract features from each sensor data stream, then
align and aggregate the two branch features to predict object detection
results. However, these methods have low accuracy of bounding box estimations
due to a simple design of label assignment and fusion strategies. In this
paper, we propose a bird's-eye view fusion learning-based anchor box-free
object detection system, which fuses the feature derived from the radar
range-azimuth heatmap and the LiDAR point cloud to estimate the possible
objects. Different label assignment strategies have been designed to facilitate
the consistency between the classification of foreground or background anchor
points and the corresponding bounding box regressions. In addition, the
performance of the proposed object detector is further enhanced by employing a
novel interactive transformer module. The superior performance of the methods
proposed in this paper has been demonstrated using the recently published
Oxford Radar RobotCar dataset. Our system's average precision significantly
outperforms the best state-of-the-art method by 13.1% and 19.0% at IoU of 0.8
under 'Clear+Foggy' training conditions for 'Clear' and 'Foggy' testing,
respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.10445">Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization. (arXiv:2212.10445v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rame_A/0/1/0/all/0/1">Alexandre Ram&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1">Kartik Ahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1">L&#xe9;on Bottou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Paz_D/0/1/0/all/0/1">David Lopez-Paz</a></p>
<p>Foundation models are redefining how AI systems are built. Practitioners now
follow a standard procedure to build their machine learning solutions: from a
pre-trained foundation model, they fine-tune the weights on the target task of
interest. So, the Internet is swarmed by a handful of foundation models
fine-tuned on many diverse tasks: these individual fine-tunings exist in
isolation without benefiting from each other. In our opinion, this is a missed
opportunity, as these specialized models contain rich and diverse features. In
this paper, we thus propose model ratatouille, a new strategy to recycle the
multiple fine-tunings of the same foundation model on diverse auxiliary tasks.
Specifically, we repurpose these auxiliary weights as initializations for
multiple parallel fine-tunings on the target task; then, we average all
fine-tuned weights to obtain the final model. This recycling strategy aims at
maximizing the diversity in weights by leveraging the diversity in auxiliary
tasks. Empirically, it improves the state of the art on the reference DomainBed
benchmark for out-of-distribution generalization. Looking forward, this work
contributes to the emerging paradigm of updatable machine learning where, akin
to open-source software development, the community collaborates to reliably
update machine learning models. Our code is released:
https://github.com/facebookresearch/ModelRatatouille.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00722">A Survey of Deep Learning: From Activations to Transformers. (arXiv:2302.00722v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Johannes Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_M/0/1/0/all/0/1">Michalis Vlachos</a></p>
<p>The past decade has witnessed remarkable advancements in deep learning, owing
to the emergence of various architectures, layers, objectives, and optimization
techniques. These consist of a multitude of variations of attention,
normalization, skip connections, transformer, and self-supervised learning
methods, among others. Our goal is to furnish a comprehensive survey of
significant recent contributions in these domains to individuals with a
fundamental grasp of deep learning. Our aspiration is that an integrated and
comprehensive approach of influential recent works will facilitate the
formation of new connections between different areas of deep learning. In our
discussion, we discuss multiple patterns that summarize the key strategies for
many of the successful innovations over the last decade. We also include a
discussion on recent commercially built, closed-source models such as OpenAI's
GPT-4 and Google's PaLM 2.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.00595">A Universal Question-Answering Platform for Knowledge Graphs. (arXiv:2303.00595v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Omar_R/0/1/0/all/0/1">Reham Omar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhall_I/0/1/0/all/0/1">Ishika Dhall</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalnis_P/0/1/0/all/0/1">Panos Kalnis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_E/0/1/0/all/0/1">Essam Mansour</a></p>
<p>Knowledge from diverse application domains is organized as knowledge graphs
(KGs) that are stored in RDF engines accessible in the web via SPARQL
endpoints. Expressing a well-formed SPARQL query requires information about the
graph structure and the exact URIs of its components, which is impractical for
the average user. Question answering (QA) systems assist by translating natural
language questions to SPARQL. Existing QA systems are typically based on
application-specific human-curated rules, or require prior information,
expensive pre-processing and model adaptation for each targeted KG. Therefore,
they are hard to generalize to a broad set of applications and KGs.
</p>
<p>In this paper, we propose KGQAn, a universal QA system that does not need to
be tailored to each target KG. Instead of curated rules, KGQAn introduces a
novel formalization of question understanding as a text generation problem to
convert a question into an intermediate abstract representation via a neural
sequence-to-sequence model. We also develop a just-in-time linker that maps at
query time the abstract representation to a SPARQL query for a specific KG,
using only the publicly accessible APIs and the existing indices of the RDF
store, without requiring any pre-processing. Our experiments with several real
KGs demonstrate that KGQAn is easily deployed and outperforms by a large margin
the state-of-the-art in terms of quality of answers and processing time,
especially for arbitrary KGs, unseen during the training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.04673">Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Susan Xueqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed H. Awadallah</a></p>
<p>Large Language Models (LLMs) have sparked significant interest in their
generative capabilities, leading to the development of various commercial
applications. The high cost of using the models drives application builders to
maximize the value of generation under a limited inference budget. This paper
presents a study of optimizing inference hyperparameters such as the number of
responses, temperature and max tokens, which significantly affects the
utility/cost of text generation. We design a framework named EcoOptiGen which
leverages economical hyperparameter optimization and cost-based pruning.
Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its
effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML
library: \url{https://aka.ms/autogen}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.05689">Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity. (arXiv:2303.05689v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1">Tong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jim Davis</a></p>
<p>There is a recently discovered and intriguing phenomenon called Neural
Collapse: at the terminal phase of training a deep neural network for
classification, the within-class penultimate feature means and the associated
classifier vectors of all flat classes collapse to the vertices of a simplex
Equiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenon
by fixing the related classifier weights to a pre-computed ETF to induce neural
collapse and maximize the separation of the learned features when training with
imbalanced data. In this work, we propose to fix the linear classifier of a
deep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF,
and use a cosine similarity-based auxiliary loss to learn hierarchy-aware
penultimate features that collapse to the HAFrame. We demonstrate that our
approach reduces the mistake severity of the model's predictions while
maintaining its top-1 accuracy on several datasets of varying scales with
hierarchies of heights ranging from 3 to 12. Code:
https://github.com/ltong1130ztr/HAFrame
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.07122">Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference. (arXiv:2303.07122v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sahara Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Faruque_O/0/1/0/all/0/1">Omar Faruque</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gani_M/0/1/0/all/0/1">Md. Osman Gani</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1">Aneesh Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shchlegel_N/0/1/0/all/0/1">Nicole-Jienne Shchlegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianwu Wang</a></p>
<p>The warming of the Arctic, also known as Arctic amplification, is led by
several atmospheric and oceanic drivers. However, the details of its underlying
thermodynamic causes are still unknown. Inferring the causal effects of
atmospheric processes on sea ice melt using fixed treatment effect strategies
leads to unrealistic counterfactual estimations. Such models are also prone to
bias due to time-varying confoundedness. Further, the complex non-linearity in
Earth science data makes it infeasible to perform causal inference using
existing marginal structural techniques. In order to tackle these challenges,
we propose TCINet - time-series causal inference model to infer causation under
continuous treatment using recurrent neural networks and a novel probabilistic
balancing technique. Through experiments on synthetic and observational data,
we show how our research can substantially improve the ability to quantify
leading causes of Arctic sea ice melt, further paving paths for causal
inference in observational Earth science.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.00409">DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection. (arXiv:2304.00409v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yizheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhoujie Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Alowain_L/0/1/0/all/0/1">Lamya Alowain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1">David Wagner</a></p>
<p>We propose and release a new vulnerable source code dataset. We curate the
dataset by crawling security issue websites, extracting vulnerability-fixing
commits and source codes from the corresponding projects. Our new dataset
contains 18,945 vulnerable functions spanning 150 CWEs and 330,492
non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295
more projects than all previous datasets combined.
</p>
<p>Combining our new dataset with previous datasets, we present an analysis of
the challenges and promising research directions of using deep learning for
detecting software vulnerabilities. We study 11 model architectures belonging
to 4 families. Our results show that deep learning is still not ready for
vulnerability detection, due to high false positive rate, low F1 score, and
difficulty of detecting hard CWEs. In particular, we demonstrate an important
generalization challenge for the deployment of deep learning-based models. We
show that increasing the volume of training data may not further improve the
performance of deep learning models for vulnerability detection, but might be
useful to improve the generalization ability to unseen projects.
</p>
<p>We also identify hopeful future research directions. We demonstrate that
large language models (LLMs) are a promising research direction for ML-based
vulnerability detection, outperforming Graph Neural Networks (GNNs) with
code-structure features in our experiments. Moreover, developing source code
specific pre-training objectives is a promising research direction to improve
the vulnerability detection performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02396">Can Feature Engineering Help Quantum Machine Learning for Malware Detection?. (arXiv:2305.02396v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1">Maksim Eren</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1">Charles Nicholas</a></p>
<p>With the increasing number and sophistication of malware attacks, malware
detection systems based on machine learning (ML) grow in importance. At the
same time, many popular ML models used in malware classification are supervised
solutions. These supervised classifiers often do not generalize well to novel
malware. Therefore, they need to be re-trained frequently to detect new malware
specimens, which can be time-consuming. Our work addresses this problem in a
hybrid framework of theoretical Quantum ML, combined with feature selection
strategies to reduce the data size and malware classifier training time. The
preliminary results show that VQC with XGBoost selected features can get a
78.91% test accuracy on the simulator. The average accuracy for the model
trained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM
5 qubits machines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05144">Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval. (arXiv:2305.05144v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shiyin Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingrui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Nannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a></p>
<p>Zero-shot sketch-based image retrieval (ZS-SBIR) is challenging due to the
cross-domain nature of sketches and photos, as well as the semantic gap between
seen and unseen image distributions. Previous methods fine-tune pre-trained
models with various side information and learning strategies to learn a compact
feature space that is shared between the sketch and photo domains and bridges
seen and unseen classes. However, these efforts are inadequate in adapting
domains and transferring knowledge from seen to unseen classes. In this paper,
we present an effective ``Adapt and Align'' approach to address the key
challenges. Specifically, we insert simple and lightweight domain adapters to
learn new abstract concepts of the sketch domain and improve cross-domain
representation capabilities. Inspired by recent advances in image-text
foundation models (e.g., CLIP) on zero-shot scenarios, we explicitly align the
learned image embedding with a more semantic text embedding to achieve the
desired knowledge transfer from seen to unseen classes. Extensive experiments
on three benchmark datasets and two popular backbones demonstrate the
superiority of our method in terms of retrieval accuracy and flexibility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18701">Temporally Layered Architecture for Efficient Continuous Control. (arXiv:2305.18701v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Devdhar Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sejnowski_T/0/1/0/all/0/1">Terrence Sejnowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Siegelmann_H/0/1/0/all/0/1">Hava Siegelmann</a></p>
<p>We present a temporally layered architecture (TLA) for temporally adaptive
control with minimal energy expenditure. The TLA layers a fast and a slow
policy together to achieve temporal abstraction that allows each layer to focus
on a different time scale. Our design draws on the energy-saving mechanism of
the human brain, which executes actions at different timescales depending on
the environment's demands. We demonstrate that beyond energy saving, TLA
provides many additional advantages, including persistent exploration, fewer
required decisions, reduced jerk, and increased action repetition. We evaluate
our method on a suite of continuous control tasks and demonstrate the
significant advantages of TLA over existing methods when measured over multiple
important metrics. We also introduce a multi-objective score to qualitatively
assess continuous control policies and demonstrate a significantly better score
for TLA. Our training algorithm uses minimal communication between the slow and
fast layers to train both policies simultaneously, making it viable for future
applications in distributed control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09417">Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis. (arXiv:2306.09417v3 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mehta_S/0/1/0/all/0/1">Shivam Mehta</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Siyang Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Alexanderson_S/0/1/0/all/0/1">Simon Alexanderson</a>, <a href="http://arxiv.org/find/eess/1/au:+Beskow_J/0/1/0/all/0/1">Jonas Beskow</a>, <a href="http://arxiv.org/find/eess/1/au:+Szekely_E/0/1/0/all/0/1">&#xc9;va Sz&#xe9;kely</a>, <a href="http://arxiv.org/find/eess/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a></p>
<p>With read-aloud speech synthesis achieving high naturalness scores, there is
a growing research interest in synthesising spontaneous speech. However, human
spontaneous face-to-face conversation has both spoken and non-verbal aspects
(here, co-speech gestures). Only recently has research begun to explore the
benefits of jointly synthesising these two modalities in a single system. The
previous state of the art used non-probabilistic methods, which fail to capture
the variability of human speech and motion, and risk producing oversmoothing
artefacts and sub-optimal synthesis quality. We present the first
diffusion-based probabilistic model, called Diff-TTSG, that jointly learns to
synthesise speech and gestures together. Our method can be trained on small
datasets from scratch. Furthermore, we describe a set of careful uni- and
multi-modal subjective tests for evaluating integrated speech and gesture
synthesis systems, and use them to validate our proposed approach. Please see
https://shivammehta25.github.io/Diff-TTSG/ for video examples, data, and code.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09633">The False Dawn: Reevaluating Google&#x27;s Reinforcement Learning for Chip Macro Placement. (arXiv:2306.09633v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1">Igor L. Markov</a></p>
<p>Reinforcement learning (RL) for physical design of silicon chips in a Google
2021 Nature paper stirred controversy due to poorly documented claims that
raised eyebrows and attracted critical media coverage. The Nature paper
withheld most inputs needed to produce reported results and some critical steps
in the methodology. But two separate evaluations filled in the gaps and
demonstrated that Google RL lags behind human designers, behind a well-known
algorithm (Simulated Annealing), and also behind generally-available commercial
software, while taking longer to run. Crosschecked data show that the integrity
of the Nature paper is substantially undermined owing to errors in conduct,
analysis and reporting. Before publishing, Google rebuffed internal allegations
of fraud.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03759">A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection. (arXiv:2307.03759v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Ming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Koh_H/0/1/0/all/0/1">Huan Yee Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1">Qingsong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zambon_D/0/1/0/all/0/1">Daniele Zambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Alippi_C/0/1/0/all/0/1">Cesare Alippi</a>, <a href="http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1">Geoffrey I. Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a></p>
<p>Time series are the primary data type used to record dynamic system
measurements and generated in great volume by both physical sensors and online
processes (virtual sensors). Time series analytics is therefore crucial to
unlocking the wealth of information implicit in available data. With the recent
advancements in graph neural networks (GNNs), there has been a surge in
GNN-based approaches for time series analysis. These approaches can explicitly
model inter-temporal and inter-variable relationships, which traditional and
other deep neural network-based methods struggle to do. In this survey, we
provide a comprehensive review of graph neural networks for time series
analysis (GNN4TS), encompassing four fundamental dimensions: forecasting,
classification, anomaly detection, and imputation. Our aim is to guide
designers and practitioners to understand, build applications, and advance
research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy
of GNN4TS. Then, we present and discuss representative research works and
introduce mainstream applications of GNN4TS. A comprehensive discussion of
potential future research directions completes the survey. This survey, for the
first time, brings together a vast array of knowledge on GNN-based time series
research, highlighting foundations, practical applications, and opportunities
of graph neural networks for time series analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06775">A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feldman_J/0/1/0/all/0/1">Jonathan Feldman</a></p>
<p>Over the last decade, there has been a vast increase in eating disorder
diagnoses and eating disorder-attributed deaths, reaching their zenith during
the Covid-19 pandemic. This immense growth derived in part from the stressors
of the pandemic but also from increased exposure to social media, which is rife
with content that promotes eating disorders. This study aimed to create a
multimodal deep learning model that can determine if a given social media post
promotes eating disorders based on a combination of visual and textual data. A
labeled dataset of Tweets was collected from Twitter, upon which twelve deep
learning models were trained and tested. Based on model performance, the most
effective deep learning model was the multimodal fusion of the RoBERTa natural
language processing model and the MaxViT image classification model, attaining
accuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViT
fusion model, deployed to classify an unlabeled dataset of posts from the
social media sites Tumblr and Reddit, generated results akin to those of
previous research studies that did not employ artificial intelligence-based
techniques, indicating that deep learning models can develop insights congruent
to those of researchers. Additionally, the model was used to conduct a
timeseries analysis of yet unseen Tweets from eight Twitter hashtags,
uncovering that, since 2014, the relative abundance of content that promotes
eating disorders has decreased drastically within those communities. Despite
this reduction, by 2018, content that promotes eating disorders had either
stopped declining or increased in ampleness anew on these hashtags.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.07415">AutoHint: Automatic Prompt Optimization with Hint Generation. (arXiv:2307.07415v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinchuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Homma_Y/0/1/0/all/0/1">Youkow Homma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Min Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1">Jian Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Charles_D/0/1/0/all/0/1">Denis Charles</a></p>
<p>This paper presents AutoHint, a novel framework for automatic prompt
engineering and optimization for Large Language Models (LLM). While LLMs have
demonstrated remarkable ability in achieving high-quality annotation in various
tasks, the key to applying this ability to specific tasks lies in developing
high-quality prompts. Thus we propose a framework to inherit the merits of both
in-context learning and zero-shot learning by incorporating enriched
instructions derived from input-output demonstrations to optimize original
prompt. We refer to the enrichment as the hint and propose a framework to
automatically generate the hint from labeled data. More concretely, starting
from an initial prompt, our method first instructs a LLM to deduce new hints
for selected samples from incorrect predictions, and then summarizes from
per-sample hints and adds the results back to the initial prompt to form a new,
enriched instruction. The proposed method is evaluated on the BIG-Bench
Instruction Induction dataset for both zero-shot and few-short prompts, where
experiments demonstrate our method is able to significantly boost accuracy for
multiple tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08131">INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks. (arXiv:2307.08131v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tiukhova_E/0/1/0/all/0/1">Elena Tiukhova</a>, <a href="http://arxiv.org/find/cs/1/au:+Penaloza_E/0/1/0/all/0/1">Emiliano Penaloza</a>, <a href="http://arxiv.org/find/cs/1/au:+Oskarsdottir_M/0/1/0/all/0/1">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, <a href="http://arxiv.org/find/cs/1/au:+Baesens_B/0/1/0/all/0/1">Bart Baesens</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoeck_M/0/1/0/all/0/1">Monique Snoeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1">Cristi&#xe1;n Bravo</a></p>
<p>Leveraging network information for predictive modeling has become widespread
in many domains. Within the realm of referral and targeted marketing,
influencer detection stands out as an area that could greatly benefit from the
incorporation of dynamic network representation due to the ongoing development
of customer-brand relationships. To elaborate this idea, we introduce
INFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic Graph
Neural Networks that combines Graph Neural Networks (GNN) and Recurrent Neural
Networks (RNN) with weighted loss functions, the Synthetic Minority
Oversampling TEchnique (SMOTE) adapted for graph data, and a carefully crafted
rolling-window strategy. To evaluate predictive performance, we utilize a
unique corporate data set with networks of three cities and derive a
profit-driven evaluation methodology for influencer prediction. Our results
show how using RNN to encode temporal attributes alongside GNNs significantly
improves predictive performance. We compare the results of various models to
demonstrate the importance of capturing graph representation, temporal
dependencies, and using a profit-driven methodology for evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08873">An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yudong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guiliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1">Pascal Poupart</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yangchen Pan</a></p>
<p>Restricting the variance of a policy's return is a popular choice in
risk-averse Reinforcement Learning (RL) due to its clear mathematical
definition and easy interpretability. Traditional methods directly restrict the
total return variance. Recent methods restrict the per-step reward variance as
a proxy. We thoroughly examine the limitations of these variance-based methods,
such as sensitivity to numerical scale and hindering of policy learning, and
propose to use an alternative risk measure, Gini deviation, as a substitute. We
study various properties of this new risk measure and derive a policy gradient
algorithm to minimize it. Empirical evaluation in domains where risk-aversion
can be clearly defined, shows that our algorithm can mitigate the limitations
of variance-based risk measures and achieves high return with low risk in terms
of variance and Gini deviation when others fail to learn a reasonable policy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10224">RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization. (arXiv:2307.10224v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhecheng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sizhe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_P/0/1/0/all/0/1">Pu Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Can Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kaizhe Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a></p>
<p>Visual Reinforcement Learning (Visual RL), coupled with high-dimensional
observations, has consistently confronted the long-standing challenge of
out-of-distribution generalization. Despite the focus on algorithms aimed at
resolving visual generalization problems, we argue that the devil is in the
existing benchmarks as they are restricted to isolated tasks and generalization
categories, undermining a comprehensive evaluation of agents' visual
generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel
Reinforcement Learning Benchmark for Visual Generalization, which contains
diverse tasks and a wide spectrum of generalization types, thereby facilitating
the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates
the latest generalization visual RL algorithms into a unified framework, under
which the experiment results indicate that no single existing algorithm has
prevailed universally across tasks. Our aspiration is that RL-ViGen will serve
as a catalyst in this area, and lay a foundation for the future creation of
universal visual generalization RL agents suitable for real-world scenarios.
Access to our code and implemented algorithms is provided at
https://gemcollector.github.io/RL-ViGen/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10763">Actor-agnostic Multi-label Action Recognition with Multi-modal Query. (arXiv:2307.10763v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1">Anindya Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sauradip Nag</a>, <a href="http://arxiv.org/find/cs/1/au:+Prada_J/0/1/0/all/0/1">Joaquin M Prada</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1">Anjan Dutta</a></p>
<p>Existing action recognition methods are typically actor-specific due to the
intrinsic topological and apparent differences among the actors. This requires
actor-specific pose estimation (e.g., humans vs. animals), leading to
cumbersome model design complexity and high maintenance costs. Moreover, they
often focus on learning the visual modality alone and single-label
classification whilst neglecting other available information sources (e.g.,
class name text) and the concurrent occurrence of multiple actions. To overcome
these limitations, we propose a new approach called 'actor-agnostic multi-modal
multi-label action recognition,' which offers a unified solution for various
types of actors, including humans and animals. We further formulate a novel
Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object
detection framework (e.g., DETR), characterized by leveraging visual and
textual modalities to represent the action classes better. The elimination of
actor-specific model designs is a key advantage, as it removes the need for
actor pose estimation altogether. Extensive experiments on five publicly
available benchmarks show that our MSQNet consistently outperforms the prior
arts of actor-specific alternatives on human and animal single- and multi-label
action recognition tasks by up to 50%. Code will be released at
https://github.com/mondalanindya/MSQNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12267">Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zijie Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1">Lele Sha</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaixun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasevic_D/0/1/0/all/0/1">Dragan Ga&#x161;evi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guanliang Chen</a></p>
<p>The recent large language models (LLMs), e.g., ChatGPT, have been able to
generate human-like and fluent responses when provided with specific
instructions. While admitting the convenience brought by technological
advancement, educators also have concerns that students might leverage LLMs to
complete their writing assignments and pass them off as their original work.
Although many AI content detection studies have been conducted as a result of
such concerns, most of these prior studies modeled AI content detection as a
classification problem, assuming that a text is either entirely human-written
or entirely AI-generated. In this study, we investigated AI content detection
in a rarely explored yet realistic setting where the text to be detected is
collaboratively written by human and generative LLMs (i.e., hybrid text). We
first formalized the detection task as identifying the transition points
between human-written content and AI-generated content from a given hybrid text
(boundary detection). Then we proposed a two-step approach where we (1)
separated AI-generated content from human-written content during the encoder
training process; and (2) calculated the distances between every two adjacent
prototypes and assumed that the boundaries exist between the two adjacent
prototypes that have the furthest distance from each other. Through extensive
experiments, we observed the following main findings: (1) the proposed approach
consistently outperformed the baseline methods across different experiment
settings; (2) the encoder training process can significantly boost the
performance of the proposed approach; (3) when detecting boundaries for
single-boundary hybrid essays, the proposed approach could be enhanced by
adopting a relatively large prototype size, leading to a 22% improvement in the
In-Domain evaluation and an 18% improvement in the Out-of-Domain evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12306">Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zheyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shukla_K/0/1/0/all/0/1">Khemraj Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1">George Em Karniadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1">Kenji Kawaguchi</a></p>
<p>The curse-of-dimensionality (CoD) taxes computational resources heavily with
exponentially increasing computational cost as the dimension increases. This
poses great challenges in solving high-dimensional PDEs as Richard Bellman
first pointed out over 60 years ago. While there has been some recent success
in solving numerically partial differential equations (PDEs) in high
dimensions, such computations are prohibitively expensive, and true scaling of
general nonlinear PDEs to high dimensions has never been achieved. In this
paper, we develop a new method of scaling up physics-informed neural networks
(PINNs) to solve arbitrary high-dimensional PDEs. The new method, called
Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs
into pieces corresponding to different dimensions and samples randomly a subset
of these dimensional pieces in each iteration of training PINNs. We
theoretically prove the convergence guarantee and other desired properties of
the proposed method. We experimentally demonstrate that the proposed method
allows us to solve many notoriously hard high-dimensional PDEs, including the
Hamilton-Jacobi-Bellman (HJB) and the Schr\"{o}dinger equations in thousands of
dimensions very fast on a single GPU using the PINNs mesh-free approach. For
instance, we solve nontrivial nonlinear PDEs (one HJB equation and one
Black-Scholes equation) in 100,000 dimensions in 6 hours on a single GPU using
SDGD with PINNs. Since SDGD is a general training methodology of PINNs, SDGD
can be applied to any current and future variants of PINNs to scale them up for
arbitrary high-dimensional PDEs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.16186">ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning. (arXiv:2307.16186v2 [cs.MA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1">Rongye Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Pu Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yongkai Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenjun Wu</a></p>
<p>Multi-agent reinforcement learning (MARL) has achieved promising results in
recent years. However, most existing reinforcement learning methods require a
large amount of data for model training. In addition, data-efficient
reinforcement learning requires the construction of strong inductive biases,
which are ignored in the current MARL approaches. Inspired by the symmetry
phenomenon in multi-agent systems, this paper proposes a framework for
exploiting prior knowledge by integrating data augmentation and a well-designed
consistency loss into the existing MARL methods. In addition, the proposed
framework is model-agnostic and can be applied to most of the current MARL
algorithms. Experimental tests on multiple challenging tasks demonstrate the
effectiveness of the proposed framework. Moreover, the proposed framework is
applied to a physical multi-robot testbed to show its superiority.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01011">Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chunwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoxu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lijun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuankai Wu</a></p>
<p>Time series analysis is a fundamental task in various application domains,
and deep learning approaches have demonstrated remarkable performance in this
area. However, many real-world time series data exhibit significant periodic or
quasi-periodic dynamics that are often not adequately captured by existing deep
learning-based solutions. This results in an incomplete representation of the
underlying dynamic behaviors of interest. To address this gap, we propose an
unsupervised method called Floss that automatically regularizes learned
representations in the frequency domain. The Floss method first automatically
detects major periodicities from the time series. It then employs periodic
shift and spectral density similarity measures to learn meaningful
representations with periodic consistency. In addition, Floss can be easily
incorporated into both supervised, semi-supervised, and unsupervised learning
frameworks. We conduct extensive experiments on common time series
classification, forecasting, and anomaly detection tasks to demonstrate the
effectiveness of Floss. We incorporate Floss into several representative deep
learning solutions to justify our design choices and demonstrate that it is
capable of automatically discovering periodic dynamics and improving
state-of-the-art deep learning models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02182">AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v2 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malekghaini_N/0/1/0/all/0/1">Navid Malekghaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbari_E/0/1/0/all/0/1">Elham Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Salahuddin_M/0/1/0/all/0/1">Mohammad A. Salahuddin</a>, <a href="http://arxiv.org/find/cs/1/au:+Limam_N/0/1/0/all/0/1">Noura Limam</a>, <a href="http://arxiv.org/find/cs/1/au:+Boutaba_R/0/1/0/all/0/1">Raouf Boutaba</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_B/0/1/0/all/0/1">Bertrand Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moteau_S/0/1/0/all/0/1">Stephanie Moteau</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuffin_S/0/1/0/all/0/1">Stephane Tuffin</a></p>
<p>Deep learning (DL) has been successfully applied to encrypted network traffic
classification in experimental settings. However, in production use, it has
been shown that a DL classifier's performance inevitably decays over time.
Re-training the model on newer datasets has been shown to only partially
improve its performance. Manually re-tuning the model architecture to meet the
performance expectations on newer datasets is time-consuming and requires
domain expertise. We propose AutoML4ETC, a novel tool to automatically design
efficient and high-performing neural architectures for encrypted traffic
classification. We define a novel, powerful search space tailored specifically
for the near real-time classification of encrypted traffic using packet header
bytes. We show that with different search strategies over our search space,
AutoML4ETC generates neural architectures that outperform the state-of-the-art
encrypted traffic classifiers on several datasets, including public benchmark
datasets and real-world TLS and QUIC traffic collected from the Orange mobile
network. In addition to being more accurate, AutoML4ETC's architectures are
significantly more efficient and lighter in terms of the number of parameters.
Finally, we make AutoML4ETC publicly available for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02582">Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1">Aseem Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhaisaheb_S/0/1/0/all/0/1">Shabbirhussain Bhaisaheb</a>, <a href="http://arxiv.org/find/cs/1/au:+Nigam_H/0/1/0/all/0/1">Harshit Nigam</a>, <a href="http://arxiv.org/find/cs/1/au:+Patwardhan_M/0/1/0/all/0/1">Manasi Patwardhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1">Lovekesh Vig</a>, <a href="http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1">Gautam Shroff</a></p>
<p>Cross-domain and cross-compositional generalization of Text-to-SQL semantic
parsing is a challenging task. Existing Large Language Model (LLM) based
solutions rely on inference-time retrieval of few-shot exemplars from the
training set to synthesize a run-time prompt for each Natural Language (NL)
test query. In contrast, we devise an algorithm which performs offline sampling
of a minimal set-of few-shots from the training data, with complete coverage of
SQL clauses, operators and functions, and maximal domain coverage within the
allowed token length. This allows for synthesis of a fixed Generic Prompt (GP),
with a diverse set-of exemplars common across NL test queries, avoiding
expensive test time exemplar retrieval. We further auto-adapt the GP to the
target database domain (DA-GP), to better handle cross-domain generalization;
followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle
cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline
task, to be performed one-time per new database with minimal human
intervention. Our approach demonstrates superior performance on the KaggleDBQA
dataset, designed to evaluate generalizability for the Text-to-SQL task. We
further showcase consistent performance improvement of LTMP-DA-GP over GP,
across LLMs and databases of KaggleDBQA, highlighting the efficacy and model
agnostic benefits of our prompt based adapt and decompose approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02914">Anomaly Detection in Global Financial Markets with Graph Neural Networks and Nonextensive Entropy. (arXiv:2308.02914v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Costa_K/0/1/0/all/0/1">Kleyton da Costa</a></p>
<p>Anomaly detection is a challenging task, particularly in systems with many
variables. Anomalies are outliers that statistically differ from the analyzed
data and can arise from rare events, malfunctions, or system misuse. This study
investigated the ability to detect anomalies in global financial markets
through Graph Neural Networks (GNN) considering an uncertainty scenario
measured by a nonextensive entropy. The main findings show that the complex
structure of highly correlated assets decreases in a crisis, and the number of
anomalies is statistically different for nonextensive entropy parameters
considering before, during, and after crisis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03443">Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Shimizu_T/0/1/0/all/0/1">Tatsuhiro Shimizu</a>, <a href="http://arxiv.org/find/stat/1/au:+Forastiere_L/0/1/0/all/0/1">Laura Forastiere</a></p>
<p>We study Off-Policy Evaluation (OPE) in contextual bandit settings with large
action spaces. The benchmark estimators suffer from severe bias and variance
tradeoffs. Parametric approaches suffer from bias due to difficulty specifying
the correct model, whereas ones with importance weight suffer from variance. To
overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was
proposed to mitigate the estimator's variance via embeddings of an action. To
make the estimator more accurate, we propose the doubly robust estimator of
MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical
analysis shows that the proposed estimator is unbiased under weaker assumptions
than MIPS while maintaining variance reduction against IPS, which was the main
advantage of MIPS. The empirical experiment verifies the supremacy of MDR
against existing estimators.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03855">Mobile Supply: The Last Piece of Jigsaw of Recommender System. (arXiv:2308.03855v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhenhao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_B/0/1/0/all/0/1">Biao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1">Hao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jia Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_N/0/1/0/all/0/1">Ning Hu</a></p>
<p>Recommendation system is a fundamental functionality of online platforms.
With the development of computing power of mobile phones, some researchers have
deployed recommendation algorithms on users' mobile devices to address the
problems of data transmission delay and pagination trigger mechanism. However,
the existing edge-side mobile rankings cannot completely solve the problem of
pagination trigger mechanism. The mobile ranking can only sort the items on the
current page, and the fixed set of candidate items limits the performance of
the mobile ranking. Besides, after the user has viewed the items of interest to
the user on the current page, the user refresh to get a new page of items. This
will affect the user's immersive experience because the user is not satisfied
with the left items on the current page. In order to address the problem of
pagination trigger mechanism, we propose a completely new module in the
pipeline of recommender system named Mobile Supply. The pipeline of recommender
system is extended to "retrival-&gt;pre-ranking-&gt;ranking-&gt;re-ranking-&gt;Mobile
Supply-&gt;mobile ranking". Specifically, we introduce the concept of list value
and use point-wise paradigm to approximate list-wise estimation to calculate
the maximum revenue that can be achieved by mobile ranking for the current
page. We also design a new mobile ranking approach named device-aware mobile
ranking considering the differences of mobile devices tailored to the new
pipeline. Extensive offline and online experiments show the superiority of our
proposed method and prove that Mobile Supply can further improve the
performance of edge-side recommender system and user experience. Mobile Supply
has been deployed on the homepage of a large-scale online food platform and has
yielded considerable profits in our business.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03936">ALFA -- Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals. (arXiv:2308.03936v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sikaroudi_M/0/1/0/all/0/1">Milad Sikaroudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1">Maryam Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnamayan_S/0/1/0/all/0/1">Shahryar Rahnamayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1">H.R. Tizhoosh</a></p>
<p>We propose an exhaustive methodology that leverages all levels of feature
abstraction, targeting an enhancement in the generalizability of image
classification to unobserved hospitals. Our approach incorporates
augmentation-based self-supervision with common distribution shifts in
histopathology scenarios serving as the pretext task. This enables us to derive
invariant features from training images without relying on training labels,
thereby covering different abstraction levels. Moving onto the subsequent
abstraction level, we employ a domain alignment module to facilitate further
extraction of invariant features across varying training hospitals. To
represent the highly specific features of participating hospitals, an encoder
is trained to classify hospital labels, independent of their diagnostic labels.
The features from each of these encoders are subsequently disentangled to
minimize redundancy and segregate the features. This representation, which
spans a broad spectrum of semantic information, enables the development of a
model demonstrating increased robustness to unseen images from disparate
distributions. Experimental results from the PACS dataset (a domain
generalization benchmark), a synthetic dataset created by applying
histopathology-specific jitters to the MHIST dataset (defining different
domains with varied distribution shifts), and a Renal Cell Carcinoma dataset
derived from four image repositories from TCGA, collectively indicate that our
proposed model is adept at managing varying levels of image granularity. Thus,
it shows improved generalizability when faced with new, out-of-distribution
hospital images.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03999">Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dalal_A/0/1/0/all/0/1">Abhilekha Dalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_M/0/1/0/all/0/1">Md Kamruzzaman Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Barua_A/0/1/0/all/0/1">Adrita Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasserman_E/0/1/0/all/0/1">Eugene Vasserman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hitzler_P/0/1/0/all/0/1">Pascal Hitzler</a></p>
<p>A major challenge in Explainable AI is in correctly interpreting activations
of hidden neurons: accurate interpretations would provide insights into the
question of what a deep learning system has internally detected as relevant on
the input, demystifying the otherwise black-box character of deep learning
systems. The state of the art indicates that hidden node activations can, in
some cases, be interpretable in a way that makes sense to humans, but
systematic automated methods that would be able to hypothesize and verify
interpretations of hidden neuron activations are underexplored. In this paper,
we provide such a method and demonstrate that it provides meaningful
interpretations. Our approach is based on using large-scale background
knowledge approximately 2 million classes curated from the Wikipedia concept
hierarchy together with a symbolic reasoning approach called Concept Induction
based on description logics, originally developed for applications in the
Semantic Web field. Our results show that we can automatically attach
meaningful labels from the background knowledge to individual neurons in the
dense layer of a Convolutional Neural Network through a hypothesis and
verification process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04313">Apple Vision Pro for Healthcare: &quot;The Ultimate Display&quot;? -- Entering the Wonderland of Precision. (arXiv:2308.04313v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1">Jan Egger</a>, <a href="http://arxiv.org/find/cs/1/au:+Gsaxner_C/0/1/0/all/0/1">Christina Gsaxner</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaojun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1">Jens Kleesiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Puladi_B/0/1/0/all/0/1">Behrus Puladi</a></p>
<p>At the Worldwide Developers Conference (WWDC) in June 2023, Apple introduced
the Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, more
specifically it is a Virtual Reality (VR) device with an additional Video
See-Through (VST) capability. The VST capability turns the Vision Pro also into
an Augmented Reality (AR) device. The AR feature is enabled by streaming the
real world via cameras to the (VR) screens in front of the user's eyes. This is
of course not unique and similar to other devices, like the Varjo XR-3.
Nevertheless, the Vision Pro has some interesting features, like an inside-out
screen that can show the headset wearers' eyes to "outsiders" or a button on
the top, called "Digital Crown", that allows you to seamlessly blend digital
content with your physical space by turning it. In addition, it is untethered,
except for the cable to the battery, which makes the headset more agile,
compared to the Varjo XR-3. This could actually come closer to the "Ultimate
Display", which Ivan Sutherland had already sketched in 1965. Not available to
the public yet, like the Ultimate Display, we want to take a look into the
crystal ball in this perspective to see if it can overcome some clinical
challenges that - especially - AR still faces in the medical domain, but also
go beyond and discuss if the Vision Pro could support clinicians in essential
tasks to spend more time with their patients.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04371">Cumulative Reasoning with Large Language Models. (arXiv:2308.04371v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingqin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1">Andrew Chi-Chih Yao</a></p>
<p>While language models are powerful and versatile, they often fail to address
highly complex problems. This is because solving complex problems requires
deliberate thinking, which has been only minimally guided during training. In
this paper, we propose a new method called Cumulative Reasoning (CR), which
employs language models in a cumulative and iterative manner to emulate human
thought processes. By decomposing tasks into smaller components, CR streamlines
the problem-solving process, rendering it both more manageable and effective.
For logical inference tasks, CR consistently outperforms existing methods with
an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on
the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves
an accuracy of 94%, which signifies a substantial enhancement of 20% over the
previous state-of-the-art method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04396">Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining. (arXiv:2308.04396v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Blatt_J/0/1/0/all/0/1">Jonas Blatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Delfmann_P/0/1/0/all/0/1">Patrick Delfmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schubert_P/0/1/0/all/0/1">Petra Schubert</a></p>
<p>One aim of Process Mining (PM) is the discovery of process models from event
logs of information systems. PM has been successfully applied to
process-oriented enterprise systems but is less suited for communication- and
document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are
very fine-granular and PM applied to their logs results in spaghetti models. A
common solution for this is event abstraction, i.e., converting low-level logs
into more abstract high-level logs before running discovery algorithms. ECS
logs come with special characteristics that have so far not been fully
addressed by existing event abstraction approaches. We aim to close this gap
with a tailored ECS event abstraction (ECSEA) approach that trains a model by
comparing recorded actual user activities (high-level traces) with the
system-generated low-level traces (extracted from the ECS). The model allows us
to automatically convert future low-level traces into an abstracted high-level
log that can be used for PM. Our evaluation shows that the algorithm produces
accurate results. ECSEA is a preprocessing method that is essential for the
interpretation of collaborative work activity in ECS, which we call Social
Process Mining.
</p>
</p>
</div>

    </div>
    </body>
    