<!DOCTYPE html>
<html>
<head>
<title>2023-07-13-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.05492">GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study. (arXiv:2307.05492v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Robertson_Z/0/1/0/all/0/1">Zachary Robertson</a></p>
<p>In this pilot study, we investigate the use of GPT4 to assist in the
peer-review process. Our key hypothesis was that GPT-generated reviews could
achieve comparable helpfulness to human reviewers. By comparing reviews
generated by both human reviewers and GPT models for academic papers submitted
to a major machine learning conference, we provide initial evidence that
artificial intelligence can contribute effectively to the peer-review process.
We also perform robustness experiments with inserted errors to understand which
parts of the paper the model tends to focus on. Our findings open new avenues
for leveraging machine learning tools to address resource constraints in peer
review. The results also shed light on potential enhancements to the review
process and lay the groundwork for further research on scaling oversight in a
domain where human-feedback is increasingly a scarce resource.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05493">Cases of EFL Secondary Students&#x27; Prompt Engineering Pathways to Complete a Writing Task with ChatGPT. (arXiv:2307.05493v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Woo_D/0/1/0/all/0/1">David James Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1">Kai Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Susanto_H/0/1/0/all/0/1">Hengky Susanto</a></p>
<p>ChatGPT is a state-of-the-art (SOTA) chatbot. Although it has potential to
support English as a foreign language (EFL) students' writing, to effectively
collaborate with it, a student must learn to engineer prompts, that is, the
skill of crafting appropriate instructions so that ChatGPT produces desired
outputs. However, writing an appropriate prompt for ChatGPT is not
straightforward for non-technical users who suffer a trial-and-error process.
This paper examines the content of EFL students' ChatGPT prompts when
completing a writing task and explores patterns in the quality and quantity of
the prompts. The data come from iPad screen recordings of secondary school EFL
students who used ChatGPT and other SOTA chatbots for the first time to
complete the same writing task. The paper presents a case study of four
distinct pathways that illustrate the trial-and-error process and show
different combinations of prompt content and quantity. The cases contribute
evidence for the need to provide prompt engineering education in the context of
the EFL writing classroom, if students are to move beyond an individual
trial-and-error process, learning a greater variety of prompt content and more
sophisticated prompts to support their writing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05494">Towards Environmentally Equitable AI via Geographical Load Balancing. (arXiv:2307.05494v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pengfei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1">Adam Wierman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shaolei Ren</a></p>
<p>Fueled by the soaring popularity of large language and foundation models, the
accelerated growth of artificial intelligence (AI) models' enormous
environmental footprint has come under increased scrutiny. While many
approaches have been proposed to make AI more energy-efficient and
environmentally friendly, environmental inequity -- the fact that AI's
environmental footprint can be disproportionately higher in certain regions
than in others -- has emerged, raising social-ecological justice concerns. This
paper takes a first step toward addressing AI's environmental inequity by
balancing its regional negative environmental impact. Concretely, we focus on
the carbon and water footprints of AI model inference and propose equity-aware
geographical load balancing (GLB) to explicitly address AI's environmental
impacts on the most disadvantaged regions. We run trace-based simulations by
considering a set of 10 geographically-distributed data centers that serve
inference requests for a large language AI model. The results demonstrate that
existing GLB approaches may amplify environmental inequity while our proposed
equity-aware GLB can significantly reduce the regional disparity in terms of
carbon and water footprints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05508">Human in the AI loop via xAI and Active Learning for Visual Inspection. (arXiv:2307.05508v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rozanec_J/0/1/0/all/0/1">Jo&#x17e;e M. Ro&#x17e;anec</a>, <a href="http://arxiv.org/find/cs/1/au:+Montini_E/0/1/0/all/0/1">Elias Montini</a>, <a href="http://arxiv.org/find/cs/1/au:+Cutrona_V/0/1/0/all/0/1">Vincenzo Cutrona</a>, <a href="http://arxiv.org/find/cs/1/au:+Papamartzivanos_D/0/1/0/all/0/1">Dimitrios Papamartzivanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemencic_T/0/1/0/all/0/1">Timotej Klemen&#x10d;i&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortuna_B/0/1/0/all/0/1">Bla&#x17e; Fortuna</a>, <a href="http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1">Dunja Mladeni&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Veliou_E/0/1/0/all/0/1">Entso Veliou</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannetsos_T/0/1/0/all/0/1">Thanassis Giannetsos</a>, <a href="http://arxiv.org/find/cs/1/au:+Emmanouilidis_C/0/1/0/all/0/1">Christos Emmanouilidis</a></p>
<p>Industrial revolutions have historically disrupted manufacturing by
introducing automation into production. Increasing automation reshapes the role
of the human worker. Advances in robotics and artificial intelligence open new
frontiers of human-machine collaboration. In this chapter, we first describe
Industry 5.0, human-machine collaboration, and state-of-the-art regarding
quality inspection, emphasizing visual inspection. We then provide our
perspective on how human-machine collaboration could be realized and enhanced
in visual inspection. Finally, we share some of the results obtained in the EU
H2020 STAR project regarding visual inspection, considering artificial
intelligence, human digital twins, and cybersecurity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05512">The Effects of Interaction Conflicts, Levels of Automation, and Frequency of Automation on Human Automation Trust and Acceptance. (arXiv:2307.05512v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Halvachi_H/0/1/0/all/0/1">Hadi Halvachi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirehjini_A/0/1/0/all/0/1">Ali Asghar Nazari Shirehjini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakavand_Z/0/1/0/all/0/1">Zahra Kakavand</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_N/0/1/0/all/0/1">Niloofar Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirmohammadi_S/0/1/0/all/0/1">Shervin Shirmohammadi</a></p>
<p>In the presence of interaction conflicts, user trust in automation plays an
important role in accepting intelligent environments such as smart homes. In
this paper, a factorial research design is employed to investigate and compare
the single and joint effects of Level of Automation (LoA), Frequency of
Automated responses (FoA), and Conflict Intensity (CI) on human trust and
acceptance of automation in the context of smart homes. To study these effects,
we conducted web-based experiments to gather data from 324 online participants
who experienced the system through a 3D simulation of a smart home. The
findings show that the level and frequency of automation had an impact on user
trust in smart environments. Furthermore, the results demonstrate that the
users' acceptance of automated smart environments decreased in the presence of
automation failures and interaction conflicts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05513">UX Heuristics and Checklist for Deep Learning powered Mobile Applications with Image Classification. (arXiv:2307.05513v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wangenheim_C/0/1/0/all/0/1">Christiane Gresse von Wangenheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dirschnabel_G/0/1/0/all/0/1">Gustavo Dirschnabel</a></p>
<p>Advances in mobile applications providing image classification enabled by
Deep Learning require innovative User Experience solutions in order to assure
their adequate use by users. To aid the design process, usability heuristics
are typically customized for a specific kind of application. Therefore, based
on a literature review and analyzing existing mobile applications with image
classification, we propose an initial set of AIX heuristics for Deep Learning
powered mobile applications with image classification decomposed into a
checklist. In order to facilitate the usage of the checklist we also developed
an online course presenting the concepts and heuristics as well as a web-based
tool in order to support an evaluation using these heuristics. These results of
this research can be used to guide the design of the interfaces of such
applications as well as support the conduction of heuristic evaluations
supporting practitioners to develop image classification apps that people can
understand, trust, and can engage with effectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05518">Procedurally generating rules to adapt difficulty for narrative puzzle games. (arXiv:2307.05518v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Volden_T/0/1/0/all/0/1">Thomas Volden</a>, <a href="http://arxiv.org/find/cs/1/au:+Grbic_D/0/1/0/all/0/1">Djordje Grbic</a>, <a href="http://arxiv.org/find/cs/1/au:+Burelli_P/0/1/0/all/0/1">Paolo Burelli</a></p>
<p>This paper focuses on procedurally generating rules and communicating them to
players to adjust the difficulty. This is part of a larger project to collect
and adapt games in educational games for young children using a digital puzzle
game designed for kindergarten. A genetic algorithm is used together with a
difficulty measure to find a target number of solution sets and a large
language model is used to communicate the rules in a narrative context. During
testing the approach was able to find rules that approximate any given target
difficulty within two dozen generations on average. The approach was combined
with a large language model to create a narrative puzzle game where players
have to host a dinner for animals that can't get along. Future experiments will
try to improve evaluation, specialize the language model on children's
literature, and collect multi-modal data from players to guide adaptation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05519">Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis. (arXiv:2307.05519v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Ji_X/0/1/0/all/0/1">Xiaoyi Ji</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Salmon_R/0/1/0/all/0/1">Richard Salmon</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mulliqi_N/0/1/0/all/0/1">Nita Mulliqi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khan_U/0/1/0/all/0/1">Umair Khan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1">Yinxi Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Blilie_A/0/1/0/all/0/1">Anders Blilie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Olsson_H/0/1/0/all/0/1">Henrik Olsson</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pedersen_B/0/1/0/all/0/1">Bodil Ginnerup Pedersen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sorensen_K/0/1/0/all/0/1">Karina Dalsgaard S&#xf8;rensen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ulhoi_B/0/1/0/all/0/1">Benedicte Parm Ulh&#xf8;i</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kjosavik_S/0/1/0/all/0/1">Svein R Kjosavik</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Janssen_E/0/1/0/all/0/1">Emilius AM Janssen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Rantalainen_M/0/1/0/all/0/1">Mattias Rantalainen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Egevad_L/0/1/0/all/0/1">Lars Egevad</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ruusuvuori_P/0/1/0/all/0/1">Pekka Ruusuvuori</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Eklund_M/0/1/0/all/0/1">Martin Eklund</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kartasalo_K/0/1/0/all/0/1">Kimmo Kartasalo</a></p>
<p>The potential of artificial intelligence (AI) in digital pathology is limited
by technical inconsistencies in the production of whole slide images (WSIs),
leading to degraded AI performance and posing a challenge for widespread
clinical application as fine-tuning algorithms for each new site is
impractical. Changes in the imaging workflow can also lead to compromised
diagnoses and patient safety risks. We evaluated whether physical color
calibration of scanners can standardize WSI appearance and enable robust AI
performance. We employed a color calibration slide in four different
laboratories and evaluated its impact on the performance of an AI system for
prostate cancer diagnosis on 1,161 WSIs. Color standardization resulted in
consistently improved AI model calibration and significant improvements in
Gleason grading performance. The study demonstrates that physical color
calibration provides a potential solution to the variation introduced by
different scanners, making AI-based cancer diagnostics more reliable and
applicable in clinical settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05553">Review of feedback in Automated Essay Scoring. (arXiv:2307.05553v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jong_Y/0/1/0/all/0/1">You-Jin Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yong-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ri_O/0/1/0/all/0/1">Ok-Chol Ri</a></p>
<p>The first automated essay scoring system was developed 50 years ago.
Automated essay scoring systems are developing into systems with richer
functions than the previous simple scoring systems. Its purpose is not only to
score essays but also as a learning tool to improve the writing skill of users.
Feedback is the most important aspect of making an automated essay scoring
system useful in real life. The importance of feedback was already emphasized
in the first AES system. This paper reviews research on feedback including
different feedback types and essay traits on automated essay scoring. We also
reviewed the latest case studies of the automated essay scoring system that
provides feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05561">TransPose: A Transformer-based 6D Object Pose Estimation Network with Depth Refinement. (arXiv:2307.05561v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdulsalam_M/0/1/0/all/0/1">Mahmoud Abdulsalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Aouf_N/0/1/0/all/0/1">Nabil Aouf</a></p>
<p>As demand for robotics manipulation application increases, accurate
vision-based 6D pose estimation becomes essential for autonomous operations.
Convolutional Neural Networks (CNNs) based approaches for pose estimation have
been previously introduced. However, the quest for better performance still
persists especially for accurate robotics manipulation. This quest extends to
the Agri-robotics domain. In this paper, we propose TransPose, an improved
Transformer-based 6D pose estimation with a depth refinement module. The
architecture takes in only an RGB image as input with no additional
supplementing modalities such as depth or thermal images. The architecture
encompasses an innovative lighter depth estimation network that estimates depth
from an RGB image using feature pyramid with an up-sampling method. A
transformer-based detection network with additional prediction heads is
proposed to directly regress the object's centre and predict the 6D pose of the
target. A novel depth refinement module is then used alongside the predicted
centers, 6D poses and depth patches to refine the accuracy of the estimated 6D
pose. We extensively compared our results with other state-of-the-art methods
and analysed our results for fruit-picking applications. The results we
achieved show that our proposed technique outperforms the other methods
available in the literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05563">RidgeBase: A Cross-Sensor Multi-Finger Contactless Fingerprint Dataset. (arXiv:2307.05563v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jawade_B/0/1/0/all/0/1">Bhavin Jawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_D/0/1/0/all/0/1">Deen Dayal Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Setlur_S/0/1/0/all/0/1">Srirangaraj Setlur</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratha_N/0/1/0/all/0/1">Nalini Ratha</a>, <a href="http://arxiv.org/find/cs/1/au:+Govindaraju_V/0/1/0/all/0/1">Venu Govindaraju</a></p>
<p>Contactless fingerprint matching using smartphone cameras can alleviate major
challenges of traditional fingerprint systems including hygienic acquisition,
portability and presentation attacks. However, development of practical and
robust contactless fingerprint matching techniques is constrained by the
limited availability of large scale real-world datasets. To motivate further
advances in contactless fingerprint matching across sensors, we introduce the
RidgeBase benchmark dataset. RidgeBase consists of more than 15,000 contactless
and contact-based fingerprint image pairs acquired from 88 individuals under
different background and lighting conditions using two smartphone cameras and
one flatbed contact sensor. Unlike existing datasets, RidgeBase is designed to
promote research under different matching scenarios that include Single Finger
Matching and Multi-Finger Matching for both contactless- to-contactless (CL2CL)
and contact-to-contactless (C2CL) verification and identification. Furthermore,
due to the high intra-sample variance in contactless fingerprints belonging to
the same finger, we propose a set-based matching protocol inspired by the
advances in facial recognition datasets. This protocol is specifically designed
for pragmatic contactless fingerprint matching that can account for variances
in focus, polarity and finger-angles. We report qualitative and quantitative
baseline results for different protocols using a COTS fingerprint matcher
(Verifinger) and a Deep CNN based approach on the RidgeBase dataset. The
dataset can be downloaded here:
https://www.buffalo.edu/cubs/research/datasets/ridgebase-benchmark-dataset.html
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05574">Some Preliminary Steps Towards Metaverse Logic. (arXiv:2307.05574v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Furtado_A/0/1/0/all/0/1">Antonio L. Furtado</a>, <a href="http://arxiv.org/find/cs/1/au:+Casanova_M/0/1/0/all/0/1">Marco A. Casanova</a>, <a href="http://arxiv.org/find/cs/1/au:+Lima_E/0/1/0/all/0/1">Edirlei Soares de Lima</a></p>
<p>Assuming that the term 'metaverse' could be understood as a computer-based
implementation of multiverse applications, we started to look in the present
work for a logic that would be powerful enough to handle the situations arising
both in the real and in the fictional underlying application domains. Realizing
that first-order logic fails to account for the unstable behavior of even the
most simpleminded information system domains, we resorted to non-conventional
extensions, in an attempt to sketch a minimal composite logic strategy. The
discussion was kept at a rather informal level, always trying to convey the
intuition behind the theoretical notions in natural language terms, and
appealing to an AI agent, namely ChatGPT, in the hope that algorithmic and
common-sense approaches can be usefully combined.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05578">Hate Speech Detection via Dual Contrastive Learning. (arXiv:2307.05578v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Junyu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongfei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaokun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhaoqing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tongyue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_L/0/1/0/all/0/1">Linlin Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fenglong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Bo Xu</a></p>
<p>The fast spread of hate speech on social media impacts the Internet
environment and our society by increasing prejudice and hurting people.
Detecting hate speech has aroused broad attention in the field of natural
language processing. Although hate speech detection has been addressed in
recent work, this task still faces two inherent unsolved challenges. The first
challenge lies in the complex semantic information conveyed in hate speech,
particularly the interference of insulting words in hate speech detection. The
second challenge is the imbalanced distribution of hate speech and non-hate
speech, which may significantly deteriorate the performance of models. To
tackle these challenges, we propose a novel dual contrastive learning (DCL)
framework for hate speech detection. Our framework jointly optimizes the
self-supervised and the supervised contrastive learning loss for capturing
span-level information beyond the token-level emotional semantics used in
existing models, particularly detecting speech containing abusive and insulting
words. Moreover, we integrate the focal loss into the dual contrastive learning
framework to alleviate the problem of data imbalance. We conduct experiments on
two publicly available English datasets, and experimental results show that the
proposed model outperforms the state-of-the-art models and precisely detects
hate speeches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05582">DBFed: Debiasing Federated Learning Framework based on Domain-Independent. (arXiv:2307.05582v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiale Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhixin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a></p>
<p>As digital transformation continues, enterprises are generating, managing,
and storing vast amounts of data, while artificial intelligence technology is
rapidly advancing. However, it brings challenges in information security and
data security. Data security refers to the protection of digital information
from unauthorized access, damage, theft, etc. throughout its entire life cycle.
With the promulgation and implementation of data security laws and the emphasis
on data security and data privacy by organizations and users,
Privacy-preserving technology represented by federated learning has a wide
range of application scenarios. Federated learning is a distributed machine
learning computing framework that allows multiple subjects to train joint
models without sharing data to protect data privacy and solve the problem of
data islands. However, the data among multiple subjects are independent of each
other, and the data differences in quality may cause fairness issues in
federated learning modeling, such as data bias among multiple subjects,
resulting in biased and discriminatory models. Therefore, we propose DBFed, a
debiasing federated learning framework based on domain-independent, which
mitigates model bias by explicitly encoding sensitive attributes during
client-side training. This paper conducts experiments on three real datasets
and uses five evaluation metrics of accuracy and fairness to quantify the
effect of the model. Most metrics of DBFed exceed those of the other three
comparative methods, fully demonstrating the debiasing effect of DBFed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05584">Code Generation for Machine Learning using Model-Driven Engineering and SysML. (arXiv:2307.05584v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Raedler_S/0/1/0/all/0/1">Simon Raedler</a>, <a href="http://arxiv.org/find/cs/1/au:+Rupp_M/0/1/0/all/0/1">Matthias Rupp</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigger_E/0/1/0/all/0/1">Eugen Rigger</a>, <a href="http://arxiv.org/find/cs/1/au:+Rinderle_Ma_S/0/1/0/all/0/1">Stefanie Rinderle-Ma</a></p>
<p>Data-driven engineering refers to systematic data collection and processing
using machine learning to improve engineering systems. Currently, the
implementation of data-driven engineering relies on fundamental data science
and software engineering skills. At the same time, model-based engineering is
gaining relevance for the engineering of complex systems. In previous work, a
model-based engineering approach integrating the formalization of machine
learning tasks using the general-purpose modeling language SysML is presented.
However, formalized machine learning tasks still require the implementation in
a specialized programming languages like Python. Therefore, this work aims to
facilitate the implementation of data-driven engineering in practice by
extending the previous work of formalizing machine learning tasks by
integrating model transformation to generate executable code. The method
focuses on the modifiability and maintainability of the model transformation so
that extensions and changes to the code generation can be integrated without
requiring modifications to the code generator. The presented method is
evaluated for feasibility in a case study to predict weather forecasts. Based
thereon, quality attributes of model transformations are assessed and
discussed. Results demonstrate the flexibility and the simplicity of the method
reducing efforts for implementation. Further, the work builds a theoretical
basis for standardizing data-driven engineering implementation in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05587">Active Learning for Video Classification with Frame Level Queries. (arXiv:2307.05587v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goswami_D/0/1/0/all/0/1">Debanjan Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Shayok Chakraborty</a></p>
<p>Deep learning algorithms have pushed the boundaries of computer vision
research and have depicted commendable performance in a variety of
applications. However, training a robust deep neural network necessitates a
large amount of labeled training data, acquiring which involves significant
time and human effort. This problem is even more serious for an application
like video classification, where a human annotator has to watch an entire video
end-to-end to furnish a label. Active learning algorithms automatically
identify the most informative samples from large amounts of unlabeled data;
this tremendously reduces the human annotation effort in inducing a machine
learning model, as only the few samples that are identified by the algorithm,
need to be labeled manually. In this paper, we propose a novel active learning
framework for video classification, with the goal of further reducing the
labeling onus on the human annotators. Our framework identifies a batch of
exemplar videos, together with a set of informative frames for each video; the
human annotator needs to merely review the frames and provide a label for each
video. This involves much less manual work than watching the complete video to
come up with a label. We formulate a criterion based on uncertainty and
diversity to identify the informative videos and exploit representative
sampling techniques to extract a set of exemplar frames from each video. To the
best of our knowledge, this is the first research effort to develop an active
learning framework for video classification, where the annotators need to
inspect only a few frames to produce a label, rather than watching the
end-to-end video.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05610">Substance or Style: What Does Your Image Embedding Know?. (arXiv:2307.05610v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rashtchian_C/0/1/0/all/0/1">Cyrus Rashtchian</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrmann_C/0/1/0/all/0/1">Charles Herrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferng_C/0/1/0/all/0/1">Chun-Sung Ferng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Ayan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_D/0/1/0/all/0/1">Dilip Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1">Deqing Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Juan_D/0/1/0/all/0/1">Da-Cheng Juan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomkins_A/0/1/0/all/0/1">Andrew Tomkins</a></p>
<p>Probes are small networks that predict properties of underlying data from
embeddings, and they provide a targeted, effective way to illuminate the
information contained in embeddings. While analysis through the use of probes
has become standard in NLP, there has been much less exploration in vision.
Image foundation models have primarily been evaluated for semantic content.
Better understanding the non-semantic information in popular embeddings (e.g.,
MAE, SimCLR, or CLIP) will shed new light both on the training algorithms and
on the uses for these foundation models. We design a systematic transformation
prediction task and measure the visual content of embeddings along many axes,
including image style, quality, and a range of natural and artificial
transformations. Surprisingly, six embeddings (including SimCLR) encode enough
non-semantic information to identify dozens of transformations. We also
consider a generalization task, where we group similar transformations and hold
out several for testing. We find that image-text models (CLIP and ALIGN) are
better at recognizing new examples of style transfer than masking-based models
(CAN and MAE). Overall, our results suggest that the choice of pre-training
algorithm impacts the types of information in the embedding, and certain models
are better than others for non-semantic downstream tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05614">Impact of Feature Encoding on Malware Classification Explainability. (arXiv:2307.05614v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manai_E/0/1/0/all/0/1">Elyes Manai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mejri_M/0/1/0/all/0/1">Mohamed Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fattahi_J/0/1/0/all/0/1">Jaouhar Fattahi</a></p>
<p>This paper investigates the impact of feature encoding techniques on the
explainability of XAI (Explainable Artificial Intelligence) algorithms. Using a
malware classification dataset, we trained an XGBoost model and compared the
performance of two feature encoding methods: Label Encoding (LE) and One Hot
Encoding (OHE). Our findings reveal a marginal performance loss when using OHE
instead of LE. However, the more detailed explanations provided by OHE
compensated for this loss. We observed that OHE enables deeper exploration of
details in both global and local contexts, facilitating more comprehensive
answers. Additionally, we observed that using OHE resulted in smaller
explanation files and reduced analysis time for human analysts. These findings
emphasize the significance of considering feature encoding techniques in XAI
research and suggest potential for further exploration by incorporating
additional encoding methods and innovative visualization approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05623">A DeepLearning Framework for Dynamic Estimation of Origin-Destination Sequence. (arXiv:2307.05623v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zheli Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1">Defu Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiaomin Cheng</a></p>
<p>OD matrix estimation is a critical problem in the transportation domain. The
principle method uses the traffic sensor measured information such as traffic
counts to estimate the traffic demand represented by the OD matrix. The problem
is divided into two categories: static OD matrix estimation and dynamic OD
matrices sequence(OD sequence for short) estimation. The above two face the
underdetermination problem caused by abundant estimated parameters and
insufficient constraint information. In addition, OD sequence estimation also
faces the lag challenge: due to different traffic conditions such as
congestion, identical vehicle will appear on different road sections during the
same observation period, resulting in identical OD demands correspond to
different trips. To this end, this paper proposes an integrated method, which
uses deep learning methods to infer the structure of OD sequence and uses
structural constraints to guide traditional numerical optimization. Our
experiments show that the neural network(NN) can effectively infer the
structure of the OD sequence and provide practical constraints for numerical
optimization to obtain better results. Moreover, the experiments show that
provided structural information contains not only constraints on the spatial
structure of OD matrices but also provides constraints on the temporal
structure of OD sequence, which solve the effect of the lagging problem well.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05624">CILF:Causality Inspired Learning Framework for Out-of-Distribution Vehicle Trajectory Prediction. (arXiv:2307.05624v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shengyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Q/0/1/0/all/0/1">Qifan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yezhuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuanpeng Li</a></p>
<p>Trajectory prediction is critical for autonomous driving vehicles. Most
existing methods tend to model the correlation between history trajectory
(input) and future trajectory (output). Since correlation is just a superficial
description of reality, these methods rely heavily on the i.i.d. assumption and
evince a heightened susceptibility to out-of-distribution data. To address this
problem, we propose an Out-of- Distribution Causal Graph (OOD-CG), which
explicitly defines the underlying causal structure of the data with three
entangled latent features: 1) domain-invariant causal feature (IC), 2)
domain-variant causal feature (VC), and 3) domain-variant non-causal feature
(VN ). While these features are confounded by confounder (C) and domain
selector (D). To leverage causal features for prediction, we propose a Causal
Inspired Learning Framework (CILF), which includes three steps: 1) extracting
domain-invariant causal feature by means of an invariance loss, 2) extracting
domain variant feature by domain contrastive learning, and 3) separating
domain-variant causal and non-causal feature by encouraging causal sufficiency.
We evaluate the performance of CILF in different vehicle trajectory prediction
models on the mainstream datasets NGSIM and INTERACTION. Experiments show
promising improvements in CILF on domain generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05629">Characterization of AGM Belief Contraction in Terms of Conditionals. (arXiv:2307.05629v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bonanno_G/0/1/0/all/0/1">Giacomo Bonanno</a> (University of California, Davis)</p>
<p>We provide a semantic characterization of AGM belief contraction based on
frames consisting of a Kripke belief relation and a Stalnaker-Lewis selection
function. The central idea is as follows. Let K be the initial belief set and
K-A be the contraction of K by the formula A; then B belongs to the set K-A if
and only if, at the actual state, the agent believes B and believes that if
not-A is (were) the case then B is (would be) the case.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05631">Causal Kripke Models. (arXiv:2307.05631v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yiwen Ding</a> (Vrije Universiteit Amsterdam), <a href="http://arxiv.org/find/cs/1/au:+Manoorkar_K/0/1/0/all/0/1">Krishna Manoorkar</a> (Vrije Universiteit Amsterdam), <a href="http://arxiv.org/find/cs/1/au:+Tzimoulis_A/0/1/0/all/0/1">Apostolos Tzimoulis</a> (Vrije Universiteit Amsterdam), <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruoding Wang</a> (Vrije Universiteit Amsterdam), <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a> (Vrije Universiteit Amsterdam)</p>
<p>This work extends Halpern and Pearl's causal models for actual causality to a
possible world semantics environment. Using this framework we introduce a logic
of actual causality with modal operators, which allows for reasoning about
causality in scenarios involving multiple possibilities, temporality, knowledge
and uncertainty. We illustrate this with a number of examples, and conclude by
discussing some future directions for research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05632">Belief Revision from Probability. (arXiv:2307.05632v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goodman_J/0/1/0/all/0/1">Jeremy Goodman</a> (University of Southern California), <a href="http://arxiv.org/find/cs/1/au:+Salow_B/0/1/0/all/0/1">Bernhard Salow</a> (University of Oxford)</p>
<p>In previous work ("Knowledge from Probability", TARK 2021) we develop a
question-relative, probabilistic account of belief. On this account, what
someone believes relative to a given question is (i) closed under entailment,
(ii) sufficiently probable given their evidence, and (iii) sensitive to the
relative probabilities of the answers to the question. Here we explore the
implications of this account for the dynamics of belief. We show that the
principles it validates are much weaker than those of orthodox theories of
belief revision like AGM, but still stronger than those valid according to the
popular Lockean theory of belief, which equates belief with high subjective
probability. We then consider a restricted class of models, suitable for many
but not all applications, and identify some further natural principles valid on
this class. We conclude by arguing that the present framework compares
favorably to the rival probabilistic accounts of belief developed by Leitgeb
and by Lin and Kelly.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05638">A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions. (arXiv:2307.05638v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1">Peng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdulkadir_A/0/1/0/all/0/1">Ahmed Abdulkadir</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenthal_M/0/1/0/all/0/1">Matthias Rosenthal</a>, <a href="http://arxiv.org/find/cs/1/au:+Schatte_G/0/1/0/all/0/1">Gerrit A. Schatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1">Benjamin F. Grewe</a>, <a href="http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1">Thilo Stadelmann</a></p>
<p>Automating the monitoring of industrial processes has the potential to
enhance efficiency and optimize quality by promptly detecting abnormal events
and thus facilitating timely interventions. Deep learning, with its capacity to
discern non-trivial patterns within large datasets, plays a pivotal role in
this process. Standard deep learning methods are suitable to solve a specific
task given a specific type of data. During training, the algorithms demand
large volumes of labeled training data. However, due to the dynamic nature of
processes and the environment, it is impractical to acquire the needed data for
standard deep learning training for every slightly different case anew. Deep
transfer learning offers a solution to this problem. By leveraging knowledge
from related tasks and accounting for variations in data distributions, this
learning framework solves new tasks even with little or no additional labeled
data. The approach bypasses the need to retrain a model from scratch for every
new setup and dramatically reduces the labeled data requirement. This survey
provides an in-depth review of deep transfer learning, examining the problem
settings of transfer learning and classifying the prevailing deep transfer
learning methods. Moreover, we delve into applying deep transfer learning in
the context of a broad spectrum of time series anomaly detection tasks
prevalent in primary industrial domains, e.g., manufacturing process
monitoring, predictive maintenance, energy management, and infrastructure
facility monitoring. We conclude this survey by underlining the challenges and
limitations of deep transfer learning in industrial contexts. We also provide
practical directions for solution design and implementation for these tasks,
leading to specific, actionable suggestions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05639">Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks. (arXiv:2307.05639v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DAgostino_D/0/1/0/all/0/1">Danny D&#x27;Agostino</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilievski_I/0/1/0/all/0/1">Ilija Ilievski</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoemaker_C/0/1/0/all/0/1">Christine Annette Shoemaker</a></p>
<p>Providing a model that achieves a strong predictive performance and at the
same time is interpretable by humans is one of the most difficult challenges in
machine learning research due to the conflicting nature of these two
objectives. To address this challenge, we propose a modification of the Radial
Basis Function Neural Network model by equipping its Gaussian kernel with a
learnable precision matrix. We show that precious information is contained in
the spectrum of the precision matrix that can be extracted once the training of
the model is completed. In particular, the eigenvectors explain the directions
of maximum sensitivity of the model revealing the active subspace and
suggesting potential applications for supervised dimensionality reduction. At
the same time, the eigenvectors highlight the relationship in terms of absolute
variation between the input and the latent variables, thereby allowing us to
extract a ranking of the input variables based on their importance to the
prediction task enhancing the model interpretability. We conducted numerical
experiments for regression, classification, and feature selection tasks,
comparing our model against popular machine learning models and the
state-of-the-art deep learning-based embedding feature selection techniques.
Our results demonstrate that the proposed model does not only yield an
attractive prediction performance with respect to the competitors but also
provides meaningful and interpretable results that potentially could assist the
decision-making process in real-world applications. A PyTorch implementation of
the model is available on GitHub at the following link.
https://github.com/dannyzx/GRBF-NNs
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05643">Multiobjective Hydropower Reservoir Operation Optimization with Transformer-Based Deep Reinforcement Learning. (arXiv:2307.05643v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rixin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jie Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Ping Wang</a></p>
<p>Due to shortage of water resources and increasing water demands, the joint
operation of multireservoir systems for balancing power generation, ecological
protection, and the residential water supply has become a critical issue in
hydropower management. However, the numerous constraints and nonlinearity of
multiple reservoirs make solving this problem time-consuming. To address this
challenge, a deep reinforcement learning approach that incorporates a
transformer framework is proposed. The multihead attention mechanism of the
encoder effectively extracts information from reservoirs and residential areas,
and the multireservoir attention network of the decoder generates suitable
operational decisions. The proposed method is applied to Lake Mead and Lake
Powell in the Colorado River Basin. The experimental results demonstrate that
the transformer-based deep reinforcement learning approach can produce
appropriate operational outcomes. Compared to a state-of-the-art method, the
operation strategies produced by the proposed approach generate 10.11% more
electricity, reduce the amended annual proportional flow deviation by 39.69%,
and increase water supply revenue by 4.10%. Consequently, the proposed approach
offers an effective method for the multiobjective operation of multihydropower
reservoir systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05663">Objaverse-XL: A Universe of 10M+ 3D Objects. (arXiv:2307.05663v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deitke_M/0/1/0/all/0/1">Matt Deitke</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruoshi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1">Matthew Wallingford</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngo_H/0/1/0/all/0/1">Huong Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_O/0/1/0/all/0/1">Oscar Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1">Alan Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Laforte_C/0/1/0/all/0/1">Christian Laforte</a>, <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1">Samir Yitzhak Gadre</a>, <a href="http://arxiv.org/find/cs/1/au:+VanderBilt_E/0/1/0/all/0/1">Eli VanderBilt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1">Aniruddha Kembhavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vondrick_C/0/1/0/all/0/1">Carl Vondrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Gkioxari_G/0/1/0/all/0/1">Georgia Gkioxari</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehsani_K/0/1/0/all/0/1">Kiana Ehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1">Ludwig Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a></p>
<p>Natural language processing and 2D vision models have attained remarkable
proficiency on many tasks primarily by escalating the scale of training data.
However, 3D vision tasks have not seen the same progress, in part due to the
challenges of acquiring high-quality 3D data. In this work, we present
Objaverse-XL, a dataset of over 10 million 3D objects. Our dataset comprises
deduplicated 3D objects from a diverse set of sources, including manually
designed objects, photogrammetry scans of landmarks and everyday items, and
professional scans of historic and antique artifacts. Representing the largest
scale and diversity in the realm of 3D datasets, Objaverse-XL enables
significant new possibilities for 3D vision. Our experiments demonstrate the
improvements enabled with the scale provided by Objaverse-XL. We show that by
training Zero123 on novel view synthesis, utilizing over 100 million multi-view
rendered images, we achieve strong zero-shot generalization abilities. We hope
that releasing Objaverse-XL will enable further innovations in the field of 3D
vision at scale.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05696">A Personalized Reinforcement Learning Summarization Service for Learning Structure from Unstructured Data. (arXiv:2307.05696v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghodratnama_S/0/1/0/all/0/1">Samira Ghodratnama</a>, <a href="http://arxiv.org/find/cs/1/au:+Beheshti_A/0/1/0/all/0/1">Amin Beheshti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zakershahrak_M/0/1/0/all/0/1">Mehrdad Zakershahrak</a></p>
<p>The exponential growth of textual data has created a crucial need for tools
that assist users in extracting meaningful insights. Traditional document
summarization approaches often fail to meet individual user requirements and
lack structure for efficient information processing. To address these
limitations, we propose Summation, a hierarchical personalized concept-based
summarization approach. It synthesizes documents into a concise hierarchical
concept map and actively engages users by learning and adapting to their
preferences. Using a Reinforcement Learning algorithm, Summation generates
personalized summaries for unseen documents on specific topics. This framework
enhances comprehension, enables effective navigation, and empowers users to
extract meaningful insights from large document collections aligned with their
unique requirements.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05704">A Causal Ordering Prior for Unsupervised Representation Learning. (arXiv:2307.05704v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kori_A/0/1/0/all/0/1">Avinash Kori</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1">Pedro Sanchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vilouras_K/0/1/0/all/0/1">Konstantinos Vilouras</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsaftaris_S/0/1/0/all/0/1">Sotirios A. Tsaftaris</a></p>
<p>Unsupervised representation learning with variational inference relies
heavily on independence assumptions over latent variables. Causal
representation learning (CRL), however, argues that factors of variation in a
dataset are, in fact, causally related. Allowing latent variables to be
correlated, as a consequence of causal relationships, is more realistic and
generalisable. So far, provably identifiable methods rely on: auxiliary
information, weak labels, and interventional or even counterfactual data.
Inspired by causal discovery with functional causal models, we propose a fully
unsupervised representation learning method that considers a data generation
process with a latent additive noise model (ANM). We encourage the latent space
to follow a causal ordering via loss function based on the Hessian of the
latent distribution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05722">Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. (arXiv:2307.05722v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Likang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1">Zhaopeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hengshu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a></p>
<p>Large Language Models (LLMs) have revolutionized natural language processing
tasks, demonstrating their exceptional capabilities in various domains.
However, their potential for behavior graph understanding in job
recommendations remains largely unexplored. This paper focuses on unveiling the
capability of large language models in understanding behavior graphs and
leveraging this understanding to enhance recommendations in online recruitment,
including the promotion of out-of-distribution (OOD) application. We present a
novel framework that harnesses the rich contextual information and semantic
representations provided by large language models to analyze behavior graphs
and uncover underlying patterns and relationships. Specifically, we propose a
meta-path prompt constructor that leverages LLM recommender to understand
behavior graphs for the first time and design a corresponding path augmentation
module to alleviate the prompt bias introduced by path-based sequence input. By
leveraging this capability, our framework enables personalized and accurate job
recommendations for individual users. We evaluate the effectiveness of our
approach on a comprehensive dataset and demonstrate its ability to improve the
relevance and quality of recommended quality. This research not only sheds
light on the untapped potential of large language models but also provides
valuable insights for developing advanced recommendation systems in the
recruitment market. The findings contribute to the growing field of natural
language processing and offer practical implications for enhancing job search
experiences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05727">An Open-Source Knowledge Graph Ecosystem for the Life Sciences. (arXiv:2307.05727v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Callahan_T/0/1/0/all/0/1">Tiffany J. Callahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tripodi_I/0/1/0/all/0/1">Ignacio J. Tripodi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stefanski_A/0/1/0/all/0/1">Adrianne L. Stefanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Cappelletti_L/0/1/0/all/0/1">Luca Cappelletti</a>, <a href="http://arxiv.org/find/cs/1/au:+Taneja_S/0/1/0/all/0/1">Sanya B. Taneja</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyrwa_J/0/1/0/all/0/1">Jordan M. Wyrwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Casiraghi_E/0/1/0/all/0/1">Elena Casiraghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Matentzoglu_N/0/1/0/all/0/1">Nicolas A. Matentzoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reese_J/0/1/0/all/0/1">Justin Reese</a>, <a href="http://arxiv.org/find/cs/1/au:+Silverstein_J/0/1/0/all/0/1">Jonathan C. Silverstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoyt_C/0/1/0/all/0/1">Charles Tapley Hoyt</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyce_R/0/1/0/all/0/1">Richard D. Boyce</a>, <a href="http://arxiv.org/find/cs/1/au:+Malec_S/0/1/0/all/0/1">Scott A. Malec</a>, <a href="http://arxiv.org/find/cs/1/au:+Unni_D/0/1/0/all/0/1">Deepak R. Unni</a>, <a href="http://arxiv.org/find/cs/1/au:+Joachimiak_M/0/1/0/all/0/1">Marcin P. Joachimiak</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1">Peter N. Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mungall_C/0/1/0/all/0/1">Christopher J. Mungall</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavalleri_E/0/1/0/all/0/1">Emanuele Cavalleri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fontana_T/0/1/0/all/0/1">Tommaso Fontana</a>, <a href="http://arxiv.org/find/cs/1/au:+Valentini_G/0/1/0/all/0/1">Giorgio Valentini</a>, <a href="http://arxiv.org/find/cs/1/au:+Mesiti_M/0/1/0/all/0/1">Marco Mesiti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillenwater_L/0/1/0/all/0/1">Lucas A. Gillenwater</a>, <a href="http://arxiv.org/find/cs/1/au:+Santangelo_B/0/1/0/all/0/1">Brook Santangelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilevsky_N/0/1/0/all/0/1">Nicole A. Vasilevsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoehndorf_R/0/1/0/all/0/1">Robert Hoehndorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_T/0/1/0/all/0/1">Tellen D. Bennett</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryan_P/0/1/0/all/0/1">Patrick B. Ryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hripcsak_G/0/1/0/all/0/1">George Hripcsak</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahn_M/0/1/0/all/0/1">Michael G. Kahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Bada_M/0/1/0/all/0/1">Michael Bada</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_W/0/1/0/all/0/1">William A. Baumgartner Jr</a>, <a href="http://arxiv.org/find/cs/1/au:+Hunter_L/0/1/0/all/0/1">Lawrence E. Hunter</a></p>
<p>Translational research requires data at multiple scales of biological
organization. Advancements in sequencing and multi-omics technologies have
increased the availability of these data but researchers face significant
integration challenges. Knowledge graphs (KGs) are used to model complex
phenomena, and methods exist to automatically construct them. However, tackling
complex biomedical integration problems requires flexibility in the way
knowledge is modeled. Moreover, existing KG construction methods provide robust
tooling at the cost of fixed or limited choices among knowledge representation
models. PheKnowLator (Phenotype Knowledge Translator) is a semantic ecosystem
for automating the FAIR (Findable, Accessible, Interoperable, and Reusable)
construction of ontologically grounded KGs with fully customizable knowledge
representation. The ecosystem includes KG construction resources (e.g., data
preparation APIs), analysis tools (e.g., SPARQL endpoints and abstraction
algorithms), and benchmarks (e.g., prebuilt KGs and embeddings). We evaluate
the ecosystem by surveying open-source KG construction methods and analyzing
its computational performance when constructing 12 large-scale KGs. With
flexible knowledge representation, PheKnowLator enables fully customizable KGs
without compromising performance or usability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05728">Towards A Scalable Solution for Improving Multi-Group Fairness in Compositional Classification. (arXiv:2307.05728v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Atwood_J/0/1/0/all/0/1">James Atwood</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_T/0/1/0/all/0/1">Tina Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Packer_B/0/1/0/all/0/1">Ben Packer</a>, <a href="http://arxiv.org/find/cs/1/au:+Deodhar_M/0/1/0/all/0/1">Meghana Deodhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1">Alex Beutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Prost_F/0/1/0/all/0/1">Flavien Prost</a>, <a href="http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1">Ahmad Beirami</a></p>
<p>Despite the rich literature on machine learning fairness, relatively little
attention has been paid to remediating complex systems, where the final
prediction is the combination of multiple classifiers and where multiple groups
are present. In this paper, we first show that natural baseline approaches for
improving equal opportunity fairness scale linearly with the product of the
number of remediated groups and the number of remediated prediction labels,
rendering them impractical. We then introduce two simple techniques, called
{\em task-overconditioning} and {\em group-interleaving}, to achieve a constant
scaling in this multi-group multi-label setup. Our experimental results in
academic and real-world environments demonstrate the effectiveness of our
proposal at mitigation within this environment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05747">Integrating Curricula with Replays: Its Effects on Continual Learning. (arXiv:2307.05747v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tee_R/0/1/0/all/0/1">Ren Jie Tee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengmi Zhang</a></p>
<p>Humans engage in learning and reviewing processes with curricula when
acquiring new skills or knowledge. This human learning behavior has inspired
the integration of curricula with replay methods in continual learning agents.
The goal is to emulate the human learning process, thereby improving knowledge
retention and facilitating learning transfer. Existing replay methods in
continual learning agents involve the random selection and ordering of data
from previous tasks, which has shown to be effective. However, limited research
has explored the integration of different curricula with replay methods to
enhance continual learning. Our study takes initial steps in examining the
impact of integrating curricula with replay methods on continual learning in
three specific aspects: the interleaved frequency of replayed exemplars with
training data, the sequence in which exemplars are replayed, and the strategy
for selecting exemplars into the replay buffer. These aspects of curricula
design align with cognitive psychology principles and leverage the benefits of
interleaved practice during replays, easy-to-hard rehearsal, and exemplar
selection strategy involving exemplars from a uniform distribution of
difficulties. Based on our results, these three curricula effectively mitigated
catastrophic forgetting and enhanced positive knowledge transfer, demonstrating
the potential of curricula in advancing continual learning methodologies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05766">Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting. (arXiv:2307.05766v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pellegrini_C/0/1/0/all/0/1">Chantal Pellegrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Keicher_M/0/1/0/all/0/1">Matthias Keicher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozsoy_E/0/1/0/all/0/1">Ege &#xd6;zsoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a></p>
<p>Radiology reporting is a crucial part of the communication between
radiologists and other medical professionals, but it can be time-consuming and
error-prone. One approach to alleviate this is structured reporting, which
saves time and enables a more accurate evaluation than free-text reports.
However, there is limited research on automating structured reporting, and no
public benchmark is available for evaluating and comparing different methods.
To close this gap, we introduce Rad-ReStruct, a new benchmark dataset that
provides fine-grained, hierarchically ordered annotations in the form of
structured reports for X-Ray images. We model the structured reporting task as
hierarchical visual question answering (VQA) and propose hi-VQA, a novel method
that considers prior context in the form of previously asked questions and
answers for populating a structured radiology report. Our experiments show that
hi-VQA achieves competitive performance to the state-of-the-art on the medical
VQA benchmark VQARad while performing best among methods without
domain-specific vision-language pretraining and provides a strong baseline on
Rad-ReStruct. Our work represents a significant step towards the automated
population of structured radiology reports and provides a valuable first
benchmark for future research in this area. We will make all annotations and
our code for annotation generation, model evaluation, and training publicly
available upon acceptance. Our dataset and code is available at
https://github.com/ChantalMP/Rad-ReStruct.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05784">EgoAdapt: A multi-stream evaluation study of adaptation to real-world egocentric user video. (arXiv:2307.05784v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lange_M/0/1/0/all/0/1">Matthias De Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Eghbalzadeh_H/0/1/0/all/0/1">Hamid Eghbalzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_R/0/1/0/all/0/1">Reuben Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1">Michael Iuzzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Meier_F/0/1/0/all/0/1">Franziska Meier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ridgeway_K/0/1/0/all/0/1">Karl Ridgeway</a></p>
<p>In egocentric action recognition a single population model is typically
trained and subsequently embodied on a head-mounted device, such as an
augmented reality headset. While this model remains static for new users and
environments, we introduce an adaptive paradigm of two phases, where after
pretraining a population model, the model adapts on-device and online to the
user's experience. This setting is highly challenging due to the change from
population to user domain and the distribution shifts in the user's data
stream. Coping with the latter in-stream distribution shifts is the focus of
continual learning, where progress has been rooted in controlled benchmarks but
challenges faced in real-world applications often remain unaddressed. We
introduce EgoAdapt, a benchmark for real-world egocentric action recognition
that facilitates our two-phased adaptive paradigm, and real-world challenges
naturally occur in the egocentric video streams from Ego4d, such as long-tailed
action distributions and large-scale classification over 2740 actions. We
introduce an evaluation framework that directly exploits the user's data stream
with new metrics to measure the adaptation gain over the population model,
online generalization, and hindsight performance. In contrast to single-stream
evaluation in existing works, our framework proposes a meta-evaluation that
aggregates the results from 50 independent user streams. We provide an
extensive empirical study for finetuning and experience replay.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05786">Merging multiple input descriptors and supervisors in a deep neural network for tractogram filtering. (arXiv:2307.05786v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jorgens_D/0/1/0/all/0/1">Daniel J&#xf6;rgens</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Descoteaux_M/0/1/0/all/0/1">Maxime Descoteaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_R/0/1/0/all/0/1">Rodrigo Moreno</a></p>
<p>One of the main issues of the current tractography methods is their high
false-positive rate. Tractogram filtering is an option to remove false-positive
streamlines from tractography data in a post-processing step. In this paper, we
train a deep neural network for filtering tractography data in which every
streamline of a tractogram is classified as {\em plausible, implausible}, or
{\em inconclusive}. For this, we use four different tractogram filtering
strategies as supervisors: TractQuerier, RecobundlesX, TractSeg, and an
anatomy-inspired filter. Their outputs are combined to obtain the
classification labels for the streamlines. We assessed the importance of
different types of information along the streamlines for performing this
classification task, including the coordinates of the streamlines, diffusion
data, landmarks, T1-weighted information, and a brain parcellation. We found
that the streamline coordinates are the most relevant followed by the diffusion
data in this particular classification task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05793">Neuro-Inspired Efficient Map Building via Fragmentation and Recall. (arXiv:2307.05793v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jaedong Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1">Zhang-Wei Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Eric Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Boopathy_A/0/1/0/all/0/1">Akhilan Boopathy</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiete_I/0/1/0/all/0/1">Ila Fiete</a></p>
<p>Animals and robots navigate through environments by building and refining
maps of the space. These maps enable functions including navigating back to
home, planning, search, and foraging. In large environments, exploration of the
space is a hard problem: agents can become stuck in local regions. Here, we use
insights from neuroscience to propose and apply the concept of
Fragmentation-and-Recall (FarMap), with agents solving the mapping problem by
building local maps via a surprisal-based clustering of space, which they use
to set subgoals for spatial exploration. Agents build and use a local map to
predict their observations; high surprisal leads to a ``fragmentation event''
that truncates the local map. At these events, the recent local map is placed
into long-term memory (LTM), and a different local map is initialized. If
observations at a fracture point match observations in one of the stored local
maps, that map is recalled (and thus reused) from LTM. The fragmentation points
induce a natural online clustering of the larger space, forming a set of
intrinsic potential subgoals that are stored in LTM as a topological graph.
Agents choose their next subgoal from the set of near and far potential
subgoals from within the current local map or LTM, respectively. Thus, local
maps guide exploration locally, while LTM promotes global exploration. We
evaluate FarMap on complex procedurally-generated spatial environments to
demonstrate that this mapping strategy much more rapidly covers the environment
(number of agent steps and wall clock time) and is more efficient in active
memory usage, without loss of performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05827">Relational Extraction on Wikipedia Tables using Convolutional and Memory Networks. (arXiv:2307.05827v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shahriar_A/0/1/0/all/0/1">Arif Shahriar</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1">Rohan Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Barbosa_D/0/1/0/all/0/1">Denilson Barbosa</a></p>
<p>Relation extraction (RE) is the task of extracting relations between entities
in text. Most RE methods extract relations from free-form running text and
leave out other rich data sources, such as tables. We explore RE from the
perspective of applying neural methods on tabularly organized data. We
introduce a new model consisting of Convolutional Neural Network (CNN) and
Bidirectional-Long Short Term Memory (BiLSTM) network to encode entities and
learn dependencies among them, respectively. We evaluate our model on a large
and recent dataset and compare results with previous neural methods.
Experimental results show that our model consistently outperforms the previous
model for the task of relation extraction on tabular data. We perform
comprehensive error analyses and ablation study to show the contribution of
various components of our model. Finally, we discuss the usefulness and
trade-offs of our approach, and provide suggestions for fostering further
research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05831">Memorization Through the Lens of Curvature of Loss Function Around Samples. (arXiv:2307.05831v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garg_I/0/1/0/all/0/1">Isha Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1">Kaushik Roy</a></p>
<p>Neural networks are overparametrized and easily overfit the datasets they
train on. In the extreme case, it is shown that they can memorize a training
set with fully randomized labels. We propose using the curvature of loss
function around the training sample as a measure of its memorization, averaged
over all training epochs. We use this to study the generalization versus
memorization properties of different samples in popular image datasets. We
visualize samples with the highest curvature of loss around them, and show that
these visually correspond to long-tailed, mislabeled or conflicting samples.
This analysis helps us find a, to the best of our knowledge, novel failure
model on the CIFAR100 dataset, that of duplicated images with different labels.
We also synthetically mislabel a proportion of the dataset by randomly
corrupting the labels of a few samples, and show that sorting by curvature
yields high AUROC values for identifying the mislabeled samples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05832">Bag of Views: An Appearance-based Approach to Next-Best-View Planning for 3D Reconstruction. (arXiv:2307.05832v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gazani_S/0/1/0/all/0/1">Sara Hatami Gazani</a>, <a href="http://arxiv.org/find/cs/1/au:+Tucsok_M/0/1/0/all/0/1">Matthew Tucsok</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantegh_I/0/1/0/all/0/1">Iraj Mantegh</a>, <a href="http://arxiv.org/find/cs/1/au:+Najjaran_H/0/1/0/all/0/1">Homayoun Najjaran</a></p>
<p>UAV-based intelligent data acquisition for 3D reconstruction and monitoring
of infrastructure has been experiencing an increasing surge of interest due to
the recent advancements in image processing and deep learning-based techniques.
View planning is an essential part of this task that dictates the information
capture strategy and heavily impacts the quality of the 3D model generated from
the captured data. Recent methods have used prior knowledge or partial
reconstruction of the target to accomplish view planning for active
reconstruction; the former approach poses a challenge for complex or newly
identified targets while the latter is computationally expensive. In this work,
we present Bag-of-Views (BoV), a fully appearance-based model used to assign
utility to the captured views for both offline dataset refinement and online
next-best-view (NBV) planning applications targeting the task of 3D
reconstruction. With this contribution, we also developed the View Planning
Toolbox (VPT), a lightweight package for training and testing machine
learning-based view planning frameworks, custom view dataset generation of
arbitrary 3D scenes, and 3D reconstruction. Through experiments which pair a
BoV-based reinforcement learning model with VPT, we demonstrate the efficacy of
our model in reducing the number of required views for high-quality
reconstructions in dataset refinement and NBV planning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05834">Scaling Distributed Multi-task Reinforcement Learning with Experience Sharing. (arXiv:2307.05834v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amani_S/0/1/0/all/0/1">Sanae Amani</a>, <a href="http://arxiv.org/find/cs/1/au:+Pahwa_K/0/1/0/all/0/1">Khushbu Pahwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a></p>
<p>Recently, DARPA launched the ShELL program, which aims to explore how
experience sharing can benefit distributed lifelong learning agents in adapting
to new challenges. In this paper, we address this issue by conducting both
theoretical and empirical research on distributed multi-task reinforcement
learning (RL), where a group of $N$ agents collaboratively solves $M$ tasks
without prior knowledge of their identities. We approach the problem by
formulating it as linearly parameterized contextual Markov decision processes
(MDPs), where each task is represented by a context that specifies the
transition dynamics and rewards. To tackle this problem, we propose an
algorithm called DistMT-LSVI. First, the agents identify the tasks, and then
they exchange information through a central server to derive $\epsilon$-optimal
policies for the tasks. Our research demonstrates that to achieve
$\epsilon$-optimal policies for all $M$ tasks, a single agent using DistMT-LSVI
needs to run a total number of episodes that is at most
$\tilde{\mathcal{O}}({d^3H^6(\epsilon^{-2}+c_{\rm sep}^{-2})}\cdot M/N)$, where
$c_{\rm sep}&gt;0$ is a constant representing task separability, $H$ is the
horizon of each episode, and $d$ is the feature dimension of the dynamics and
rewards. Notably, DistMT-LSVI improves the sample complexity of non-distributed
settings by a factor of $1/N$, as each agent independently learns
$\epsilon$-optimal policies for all $M$ tasks using
$\tilde{\mathcal{O}}(d^3H^6M\epsilon^{-2})$ episodes. Additionally, we provide
numerical experiments conducted on OpenAI Gym Atari environments that validate
our theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05841">Influential Simplices Mining via Simplicial Convolutional Network. (arXiv:2307.05841v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yujie Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Linyuan L&#xfc;</a></p>
<p>Simplicial complexes have recently been in the limelight of higher-order
network analysis, where a minority of simplices play crucial roles in
structures and functions due to network heterogeneity. We find a significant
inconsistency between identifying influential nodes and simplices. Therefore,
it remains elusive how to characterize simplices' influence and identify
influential simplices, despite the relative maturity of research on influential
nodes (0-simplices) identification. Meanwhile, graph neural networks (GNNs) are
potent tools that can exploit network topology and node features
simultaneously, but they struggle to tackle higher-order tasks. In this paper,
we propose a higher-order graph learning model, named influential simplices
mining neural network (ISMnet), to identify vital h-simplices in simplicial
complexes. It can tackle higher-order tasks by leveraging novel higher-order
presentations: hierarchical bipartite graphs and higher-order hierarchical
(HoH) Laplacians, where targeted simplices are grouped into a hub set and can
interact with other simplices. Furthermore, ISMnet employs learnable graph
convolutional operators in each HoH Laplacian domain to capture interactions
among simplices, and it can identify influential simplices of arbitrary order
by changing the hub set. Empirical results demonstrate that ISMnet
significantly outperforms existing methods in ranking 0-simplices (nodes) and
2-simplices. In general, this novel framework excels in identifying influential
simplices and promises to serve as a potent tool in higher-order network
analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05857">FAIRO: Fairness-aware Adaptation in Sequential-Decision Making for Human-in-the-Loop Systems. (arXiv:2307.05857v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tianyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Taherisadr_M/0/1/0/all/0/1">Mojtaba Taherisadr</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmalaki_S/0/1/0/all/0/1">Salma Elmalaki</a></p>
<p>Achieving fairness in sequential-decision making systems within
Human-in-the-Loop (HITL) environments is a critical concern, especially when
multiple humans with different behavior and expectations are affected by the
same adaptation decisions in the system. This human variability factor adds
more complexity since policies deemed fair at one point in time may become
discriminatory over time due to variations in human preferences resulting from
inter- and intra-human variability. This paper addresses the fairness problem
from an equity lens, considering human behavior variability, and the changes in
human preferences over time. We propose FAIRO, a novel algorithm for
fairness-aware sequential-decision making in HITL adaptation, which
incorporates these notions into the decision-making process. In particular,
FAIRO decomposes this complex fairness task into adaptive sub-tasks based on
individual human preferences through leveraging the Options reinforcement
learning framework. We design FAIRO to generalize to three types of HITL
application setups that have the shared adaptation decision problem.
Furthermore, we recognize that fairness-aware policies can sometimes conflict
with the application's utility. To address this challenge, we provide a
fairness-utility tradeoff in FAIRO, allowing system designers to balance the
objectives of fairness and utility based on specific application requirements.
Extensive evaluations of FAIRO on the three HITL applications demonstrate its
generalizability and effectiveness in promoting fairness while accounting for
human variability. On average, FAIRO can improve fairness compared with other
methods across all three applications by 35.36%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05862">Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes. (arXiv:2307.05862v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Toups_C/0/1/0/all/0/1">Connor Toups</a>, <a href="http://arxiv.org/find/cs/1/au:+Bommasani_R/0/1/0/all/0/1">Rishi Bommasani</a>, <a href="http://arxiv.org/find/cs/1/au:+Creel_K/0/1/0/all/0/1">Kathleen A. Creel</a>, <a href="http://arxiv.org/find/cs/1/au:+Bana_S/0/1/0/all/0/1">Sarah H. Bana</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1">Dan Jurafsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a></p>
<p>Machine learning is traditionally studied at the model level: researchers
measure and improve the accuracy, robustness, bias, efficiency, and other
dimensions of specific models. In practice, the societal impact of machine
learning is determined by the surrounding context of machine learning
deployments. To capture this, we introduce ecosystem-level analysis: rather
than analyzing a single model, we consider the collection of models that are
deployed in a given context. For example, ecosystem-level analysis in hiring
recognizes that a job candidate's outcomes are not only determined by a single
hiring algorithm or firm but instead by the collective decisions of all the
firms they applied to. Across three modalities (text, images, speech) and 11
datasets, we establish a clear trend: deployed machine learning is prone to
systemic failure, meaning some users are exclusively misclassified by all
models available. Even when individual models improve at the population level
over time, we find these improvements rarely reduce the prevalence of systemic
failure. Instead, the benefits of these improvements predominantly accrue to
individuals who are already correctly classified by other models. In light of
these trends, we consider medical imaging for dermatology where the costs of
systemic failure are especially high. While traditional analyses reveal racial
performance disparities for both models and humans, ecosystem-level analysis
reveals new forms of racial disparity in model predictions that do not present
in human predictions. These examples demonstrate ecosystem-level analysis has
unique strengths for characterizing the societal impact of machine learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05891">PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks. (arXiv:2307.05891v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Char_I/0/1/0/all/0/1">Ian Char</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jeff Schneider</a></p>
<p>Deep reinforcement learning (RL) has shown immense potential for learning to
control systems through data alone. However, one challenge deep RL faces is
that the full state of the system is often not observable. When this is the
case, the policy needs to leverage the history of observations to infer the
current state. At the same time, differences between the training and testing
environments makes it critical for the policy not to overfit to the sequence of
observations it sees at training time. As such, there is an important balancing
act between having the history encoder be flexible enough to extract relevant
information, yet be robust to changes in the environment. To strike this
balance, we look to the PID controller for inspiration. We assert the PID
controller's success shows that only summing and differencing are needed to
accumulate information over time for many control tasks. Following this
principle, we propose two architectures for encoding history: one that directly
uses PID features and another that extends these core ideas and can be used in
arbitrary control tasks. When compared with prior approaches, our encoders
produce policies that are often more robust and achieve better performance on a
variety of tracking tasks. Going beyond tracking tasks, our policies achieve
1.7x better performance on average over previous state-of-the-art methods on a
suite of high dimensional control tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05902">Stability Guarantees for Feature Attributions with Multiplicative Smoothing. (arXiv:2307.05902v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xue_A/0/1/0/all/0/1">Anton Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Alur_R/0/1/0/all/0/1">Rajeev Alur</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1">Eric Wong</a></p>
<p>Explanation methods for machine learning models tend to not provide any
formal guarantees and may not reflect the underlying decision-making process.
In this work, we analyze stability as a property for reliable feature
attribution methods. We prove that relaxed variants of stability are guaranteed
if the model is sufficiently Lipschitz with respect to the masking of features.
To achieve such a model, we develop a smoothing method called Multiplicative
Smoothing (MuS). We show that MuS overcomes theoretical limitations of standard
smoothing techniques and can be integrated with any classifier and feature
attribution method. We evaluate MuS on vision and language models with a
variety of feature attribution methods, such as LIME and SHAP, and demonstrate
that MuS endows feature attributions with non-trivial stability guarantees.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05913">Close-up View synthesis by Interpolating Optical Flow. (arXiv:2307.05913v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xinyi Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ze Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hong Cheng</a></p>
<p>The virtual viewpoint is perceived as a new technique in virtual navigation,
as yet not supported due to the lack of depth information and obscure camera
parameters. In this paper, a method for achieving close-up virtual view is
proposed and it only uses optical flow to build parallax effects to realize
pseudo 3D projection without using depth sensor. We develop a bidirectional
optical flow method to obtain any virtual viewpoint by proportional
interpolation of optical flow. Moreover, with the ingenious application of the
optical-flow-value, we achieve clear and visual-fidelity magnified results
through lens stretching in any corner, which overcomes the visual distortion
and image blur through viewpoint magnification and transition in Google Street
View system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05921">Reading Radiology Imaging Like The Radiologist. (arXiv:2307.05921v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuhao Wang</a></p>
<p>Automated radiology report generation aims to generate radiology reports that
contain rich, fine-grained descriptions of radiology imaging. Compared with
image captioning in the natural image domain, medical images are very similar
to each other, with only minor differences in the occurrence of diseases. Given
the importance of these minor differences in the radiology report, it is
crucial to encourage the model to focus more on the subtle regions of disease
occurrence. Secondly, the problem of visual and textual data biases is serious.
Not only do normal cases make up the majority of the dataset, but sentences
describing areas with pathological changes also constitute only a small part of
the paragraph. Lastly, generating medical image reports involves the challenge
of long text generation, which requires more expertise and empirical training
in medical knowledge. As a result, the difficulty of generating such reports is
increased. To address these challenges, we propose a disease-oriented retrieval
framework that utilizes similar reports as prior knowledge references. We
design a factual consistency captioning generator to generate more accurate and
factually consistent disease descriptions. Our framework can find most similar
reports for a given disease from the CXR database by retrieving a
disease-oriented mask consisting of the position and morphological
characteristics. By referencing the disease-oriented similar report and the
visual features, the factual consistency model can generate a more accurate
radiology report.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05929">A New Dataset and Comparative Study for Aphid Cluster Detection. (arXiv:2307.05929v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianxiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kaidong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1">Cuncong Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Bo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teran_I/0/1/0/all/0/1">Ivan Grijalva Teran</a>, <a href="http://arxiv.org/find/cs/1/au:+McCornack_B/0/1/0/all/0/1">Brian McCornack</a>, <a href="http://arxiv.org/find/cs/1/au:+Flippo_D/0/1/0/all/0/1">Daniel Flippo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharda_A/0/1/0/all/0/1">Ajay Sharda</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a></p>
<p>Aphids are one of the main threats to crops, rural families, and global food
security. Chemical pest control is a necessary component of crop production for
maximizing yields, however, it is unnecessary to apply the chemical approaches
to the entire fields in consideration of the environmental pollution and the
cost. Thus, accurately localizing the aphid and estimating the infestation
level is crucial to the precise local application of pesticides. Aphid
detection is very challenging as each individual aphid is really small and all
aphids are crowded together as clusters. In this paper, we propose to estimate
the infection level by detecting aphid clusters. We have taken millions of
images in the sorghum fields, manually selected 5,447 images that contain
aphids, and annotated each aphid cluster in the image. To use these images for
machine learning models, we crop the images into patches and created a labeled
dataset with over 151,000 image patches. Then, we implement and compare the
performance of four state-of-the-art object detection models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05933">BiRP: Learning Robot Generalized Bimanual Coordination using Relative Parameterization Method on Human Demonstration. (arXiv:2307.05933v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junjia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sim_H/0/1/0/all/0/1">Hengyi Sim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenzui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fei Chen</a></p>
<p>Human bimanual manipulation can perform more complex tasks than a simple
combination of two single arms, which is credited to the spatio-temporal
coordination between the arms. However, the description of bimanual
coordination is still an open topic in robotics. This makes it difficult to
give an explainable coordination paradigm, let alone applied to robotics. In
this work, we divide the main bimanual tasks in human daily activities into two
types: leader-follower and synergistic coordination. Then we propose a relative
parameterization method to learn these types of coordination from human
demonstration. It represents coordination as Gaussian mixture models from
bimanual demonstration to describe the change in the importance of coordination
throughout the motions by probability. The learned coordinated representation
can be generalized to new task parameters while ensuring spatio-temporal
coordination. We demonstrate the method using synthetic motions and human
demonstration data and deploy it to a humanoid robot to perform a generalized
bimanual coordination motion. We believe that this easy-to-use bimanual
learning from demonstration (LfD) method has the potential to be used as a data
augmentation plugin for robot large manipulation model training. The
corresponding codes are open-sourced in https://github.com/Skylark0924/Rofunc.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05939">Automatically Reconciling the Trade-off between Prediction Accuracy and Earliness in Prescriptive Business Process Monitoring. (arXiv:2307.05939v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Metzger_A/0/1/0/all/0/1">Andreas Metzger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kley_T/0/1/0/all/0/1">Tristan Kley</a>, <a href="http://arxiv.org/find/cs/1/au:+Rothweiler_A/0/1/0/all/0/1">Aristide Rothweiler</a>, <a href="http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1">Klaus Pohl</a></p>
<p>Prescriptive business process monitoring provides decision support to process
managers on when and how to adapt an ongoing business process to prevent or
mitigate an undesired process outcome. We focus on the problem of automatically
reconciling the trade-off between prediction accuracy and prediction earliness
in determining when to adapt. Adaptations should happen sufficiently early to
provide enough lead time for the adaptation to become effective. However,
earlier predictions are typically less accurate than later predictions. This
means that acting on less accurate predictions may lead to unnecessary
adaptations or missed adaptations.
</p>
<p>Different approaches were presented in the literature to reconcile the
trade-off between prediction accuracy and earliness. So far, these approaches
were compared with different baselines, and evaluated using different data sets
or even confidential data sets. This limits the comparability and replicability
of the approaches and makes it difficult to choose a concrete approach in
practice.
</p>
<p>We perform a comparative evaluation of the main alternative approaches for
reconciling the trade-off between prediction accuracy and earliness. Using four
public real-world event log data sets and two types of prediction models, we
assess and compare the cost savings of these approaches. The experimental
results indicate which criteria affect the effectiveness of an approach and
help us state initial recommendations for the selection of a concrete approach
in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05959">Giving Robots a Hand: Learning Generalizable Manipulation with Eye-in-Hand Human Video Demonstrations. (arXiv:2307.05959v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Moo Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a></p>
<p>Eye-in-hand cameras have shown promise in enabling greater sample efficiency
and generalization in vision-based robotic manipulation. However, for robotic
imitation, it is still expensive to have a human teleoperator collect large
amounts of expert demonstrations with a real robot. Videos of humans performing
tasks, on the other hand, are much cheaper to collect since they eliminate the
need for expertise in robotic teleoperation and can be quickly captured in a
wide range of scenarios. Therefore, human video demonstrations are a promising
data source for learning generalizable robotic manipulation policies at scale.
In this work, we augment narrow robotic imitation datasets with broad unlabeled
human video demonstrations to greatly enhance the generalization of eye-in-hand
visuomotor policies. Although a clear visual domain gap exists between human
and robot data, our framework does not need to employ any explicit domain
adaptation method, as we leverage the partial observability of eye-in-hand
cameras as well as a simple fixed image masking scheme. On a suite of eight
real-world tasks involving both 3-DoF and 6-DoF robot arm control, our method
improves the success rates of eye-in-hand manipulation policies by 58%
(absolute) on average, enabling robots to generalize to both new environment
configurations and new tasks that are unseen in the robot demonstration data.
See video results at https://giving-robots-a-hand.github.io/ .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05973">VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models. (arXiv:2307.05973v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenlong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunzhu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a></p>
<p>Large language models (LLMs) are shown to possess a wealth of actionable
knowledge that can be extracted for robot manipulation in the form of reasoning
and planning. Despite the progress, most still rely on pre-defined motion
primitives to carry out the physical interactions with the environment, which
remains a major bottleneck. In this work, we aim to synthesize robot
trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a
large variety of manipulation tasks given an open-set of instructions and an
open-set of objects. We achieve this by first observing that LLMs excel at
inferring affordances and constraints given a free-form language instruction.
More importantly, by leveraging their code-writing capabilities, they can
interact with a visual-language model (VLM) to compose 3D value maps to ground
the knowledge into the observation space of the agent. The composed value maps
are then used in a model-based planning framework to zero-shot synthesize
closed-loop robot trajectories with robustness to dynamic perturbations. We
further demonstrate how the proposed framework can benefit from online
experiences by efficiently learning a dynamics model for scenes that involve
contact-rich interactions. We present a large-scale study of the proposed
method in both simulated and real-robot environments, showcasing the ability to
perform a large variety of everyday manipulation tasks specified in free-form
natural language. Project website: https://voxposer.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05977">Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion Models. (arXiv:2307.05977v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sanghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Seohyeon Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Balhae Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1">Moonseok Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a></p>
<p>Large-scale image generation models, with impressive quality made possible by
the vast amount of data available on the Internet, raise social concerns that
these models may generate harmful or copyrighted content. The biases and
harmfulness arise throughout the entire training process and are hard to
completely remove, which have become significant hurdles to the safe deployment
of these models. In this paper, we propose a method called SDD to prevent
problematic content generation in text-to-image diffusion models. We
self-distill the diffusion model to guide the noise estimate conditioned on the
target removal concept to match the unconditional one. Compared to the previous
methods, our method eliminates a much greater proportion of harmful content
from the generated images without degrading the overall image quality.
Furthermore, our method allows the removal of multiple concepts at once,
whereas previous works are limited to removing a single concept at a time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05979">Transformers in Reinforcement Learning: A Survey. (arXiv:2307.05979v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1">Pranav Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1">Aamer Abdul Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+St_Charles_P/0/1/0/all/0/1">Pierre-Luc St-Charles</a>, <a href="http://arxiv.org/find/cs/1/au:+Prince_S/0/1/0/all/0/1">Simon J.D. Prince</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1">Samira Ebrahimi Kahou</a></p>
<p>Transformers have significantly impacted domains like natural language
processing, computer vision, and robotics, where they improve performance
compared to other neural networks. This survey explores how transformers are
used in reinforcement learning (RL), where they are seen as a promising
solution for addressing challenges such as unstable training, credit
assignment, lack of interpretability, and partial observability. We begin by
providing a brief domain overview of RL, followed by a discussion on the
challenges of classical RL algorithms. Next, we delve into the properties of
the transformer and its variants and discuss the characteristics that make them
well-suited to address the challenges inherent in RL. We examine the
application of transformers to various aspects of RL, including representation
learning, transition and reward function modeling, and policy optimization. We
also discuss recent research that aims to enhance the interpretability and
efficiency of transformers in RL, using visualization techniques and efficient
training strategies. Often, the transformer architecture must be tailored to
the specific needs of a given application. We present a broad overview of how
transformers have been adapted for several applications, including robotics,
medicine, language modeling, cloud computing, and combinatorial optimization.
We conclude by discussing the limitations of using transformers in RL and
assess their potential for catalyzing future breakthroughs in this field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06013">An Effective and Efficient Time-aware Entity Alignment Framework via Two-aspect Three-view Label Propagation. (arXiv:2307.06013v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1">Li Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xin Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Youshao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Changxu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1">Man Lan</a></p>
<p>Entity alignment (EA) aims to find the equivalent entity pairs between
different knowledge graphs (KGs), which is crucial to promote knowledge fusion.
With the wide use of temporal knowledge graphs (TKGs), time-aware EA (TEA)
methods appear to enhance EA. Existing TEA models are based on Graph Neural
Networks (GNN) and achieve state-of-the-art (SOTA) performance, but it is
difficult to transfer them to large-scale TKGs due to the scalability issue of
GNN. In this paper, we propose an effective and efficient non-neural EA
framework between TKGs, namely LightTEA, which consists of four essential
components: (1) Two-aspect Three-view Label Propagation, (2) Sparse Similarity
with Temporal Constraints, (3) Sinkhorn Operator, and (4) Temporal Iterative
Learning. All of these modules work together to improve the performance of EA
while reducing the time consumption of the model. Extensive experiments on
public datasets indicate that our proposed model significantly outperforms the
SOTA methods for EA between TKGs, and the time consumed by LightTEA is only
dozens of seconds at most, no more than 10% of the most efficient TEA method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06033">AI-Generated Imagery: A New Era for the `Readymade&#x27;. (arXiv:2307.06033v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Amy Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Cook_M/0/1/0/all/0/1">Michael Cook</a></p>
<p>While the term `art' defies any concrete definition, this paper aims to
examine how digital images produced by generative AI systems, such as
Midjourney, have come to be so regularly referred to as such. The discourse
around the classification of AI-generated imagery as art is currently somewhat
homogeneous, lacking the more nuanced aspects that would apply to more
traditional modes of artistic media production. This paper aims to bring
important philosophical considerations to the surface of the discussion around
AI-generated imagery in the context of art. We employ existing philosophical
frameworks and theories of language to suggest that some AI-generated imagery,
by virtue of its visual properties within these frameworks, can be presented as
`readymades' for consideration as art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06046">An OOD Multi-Task Perspective for Link Prediction with New Relation Types and Nodes. (arXiv:2307.06046v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jincheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1">Beatrice Bevilacqua</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1">Bruno Ribeiro</a></p>
<p>The task of inductive link prediction in (discrete) attributed multigraphs
infers missing attributed links (relations) between nodes in new test
multigraphs. Traditional relational learning methods face the challenge of
limited generalization to OOD test multigraphs containing both novel nodes and
novel relation types not seen in training. Recently, under the only assumption
that all relation types share the same structural predictive patterns (single
task), Gao et al. (2023) proposed an OOD link prediction method using the
theoretical concept of double exchangeability (for nodes &amp; relation types), in
contrast to the (single) exchangeability (only for nodes) used to design Graph
Neural Networks (GNNs). In this work we further extend the double
exchangeability concept to multi-task double exchangeability, where we define
link prediction in attributed multigraphs that can have distinct and
potentially conflicting predictive patterns for different sets of relation
types (multiple tasks). Our empirical results on real-world datasets
demonstrate that our approach can effectively generalize to entirely new
relation types in test, without access to additional information, yielding
significant performance improvements over existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06052">Visualization for Multivariate Gaussian Anomaly Detection in Images. (arXiv:2307.06052v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bertoldo_J/0/1/0/all/0/1">Joao P C Bertoldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Arrustico_D/0/1/0/all/0/1">David Arrustico</a></p>
<p>This paper introduces a simplified variation of the PaDiM (Pixel-Wise Anomaly
Detection through Instance Modeling) method for anomaly detection in images,
fitting a single multivariate Gaussian (MVG) distribution to the feature
vectors extracted from a backbone convolutional neural network (CNN) and using
their Mahalanobis distance as the anomaly score. We introduce an intermediate
step in this framework by applying a whitening transformation to the feature
vectors, which enables the generation of heatmaps capable of visually
explaining the features learned by the MVG. The proposed technique is evaluated
on the MVTec-AD dataset, and the results show the importance of visual model
validation, providing insights into issues in this framework that were
otherwise invisible. The visualizations generated for this paper are publicly
available at https://doi.org/10.5281/zenodo.7937978.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06082">VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View. (arXiv:2307.06082v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schumann_R/0/1/0/all/0/1">Raphael Schumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wanrong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Weixi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1">Tsu-Jui Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1">Stefan Riezler</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a></p>
<p>Incremental decision making in real-world environments is one of the most
challenging tasks in embodied artificial intelligence. One particularly
demanding scenario is Vision and Language Navigation~(VLN) which requires
visual and natural language understanding as well as spatial and temporal
reasoning capabilities. The embodied agent needs to ground its understanding of
navigation instructions in observations of a real-world environment like Street
View. Despite the impressive results of LLMs in other research areas, it is an
ongoing problem of how to best connect them with an interactive visual
environment. In this work, we propose VELMA, an embodied LLM agent that uses a
verbalization of the trajectory and of visual environment observations as
contextual prompt for the next action. Visual information is verbalized by a
pipeline that extracts landmarks from the human written navigation instructions
and uses CLIP to determine their visibility in the current panorama view. We
show that VELMA is able to successfully follow navigation instructions in
Street View with only two in-context examples. We further finetune the LLM
agent on a few thousand examples and achieve 25%-30% relative improvement in
task completion over the previous state-of-the-art for two datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06092">Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1">Stefano Favaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1">Boris Hanin</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1">Domenico Marinucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1">Ivan Nourdin</a>, <a href="http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1">Giovanni Peccati</a></p>
<p>We study the distribution of a fully connected neural network with random
Gaussian weights and biases in which the hidden layer widths are proportional
to a large constant $n$. Under mild assumptions on the non-linearity, we obtain
quantitative bounds on normal approximations valid at large but finite $n$ and
any fixed network depth. Our theorems show, both for the finite-dimensional
distributions and the entire process, that the distance between a random fully
connected network (and its derivatives) to the corresponding infinite width
Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0,$ with the exponent
depending on the metric used to measure discrepancy. Our bounds are stronger in
terms of their dependence on network width than any previously available in the
literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06118">TreeFormer: a Semi-Supervised Transformer-based Framework for Tree Counting from a Single High Resolution Image. (arXiv:2307.06118v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amirkolaee_H/0/1/0/all/0/1">Hamed Amini Amirkolaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1">Miaojing Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulligan_M/0/1/0/all/0/1">Mark Mulligan</a></p>
<p>Automatic tree density estimation and counting using single aerial and
satellite images is a challenging task in photogrammetry and remote sensing,
yet has an important role in forest management. In this paper, we propose the
first semisupervised transformer-based framework for tree counting which
reduces the expensive tree annotations for remote sensing images. Our method,
termed as TreeFormer, first develops a pyramid tree representation module based
on transformer blocks to extract multi-scale features during the encoding
stage. Contextual attention-based feature fusion and tree density regressor
modules are further designed to utilize the robust features from the encoder to
estimate tree density maps in the decoder. Moreover, we propose a pyramid
learning strategy that includes local tree density consistency and local tree
count ranking losses to utilize unlabeled images into the training process.
Finally, the tree counter token is introduced to regulate the network by
computing the global tree counts for both labeled and unlabeled images. Our
model was evaluated on two benchmark tree counting datasets, Jiangsu, and
Yosemite, as well as a new dataset, KCL-London, created by ourselves. Our
TreeFormer outperforms the state of the art semi-supervised methods under the
same setting and exceeds the fully-supervised methods using the same number of
labeled images. The codes and datasets are available at
https://github.com/HAAClassic/TreeFormer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06125">Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation. (arXiv:2307.06125v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schmalstieg_F/0/1/0/all/0/1">Fabian Schmalstieg</a>, <a href="http://arxiv.org/find/cs/1/au:+Honerkamp_D/0/1/0/all/0/1">Daniel Honerkamp</a>, <a href="http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1">Tim Welschehold</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a></p>
<p>Existing object-search approaches enable robots to search through free
pathways, however, robots operating in unstructured human-centered environments
frequently also have to manipulate the environment to their needs. In this
work, we introduce a novel interactive multi-object search task in which a
robot has to open doors to navigate rooms and search inside cabinets and
drawers to find target objects. These new challenges require combining
manipulation and navigation skills in unexplored environments. We present
HIMOS, a hierarchical reinforcement learning approach that learns to compose
exploration, navigation, and manipulation skills. To achieve this, we design an
abstract high-level action space around a semantic map memory and leverage the
explored environment as instance navigation points. We perform extensive
experiments in simulation and the real-world that demonstrate that HIMOS
effectively transfers to new environments in a zero-shot manner. It shows
robustness to unseen subpolicies, failures in their execution, and different
robot kinematics. These capabilities open the door to a wide range of
downstream tasks across embodied AI and real-world use cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06126">Guided Bottom-Up Interactive Constraint Acquisition. (arXiv:2307.06126v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsouros_D/0/1/0/all/0/1">Dimos Tsouros</a>, <a href="http://arxiv.org/find/cs/1/au:+Berden_S/0/1/0/all/0/1">Senne Berden</a>, <a href="http://arxiv.org/find/cs/1/au:+Guns_T/0/1/0/all/0/1">Tias Guns</a></p>
<p>Constraint Acquisition (CA) systems can be used to assist in the modeling of
constraint satisfaction problems. In (inter)active CA, the system is given a
set of candidate constraints and posts queries to the user with the goal of
finding the right constraints among the candidates. Current interactive CA
algorithms suffer from at least two major bottlenecks. First, in order to
converge, they require a large number of queries to be asked to the user.
Second, they cannot handle large sets of candidate constraints, since these
lead to large waiting times for the user. For this reason, the user must have
fairly precise knowledge about what constraints the system should consider. In
this paper, we alleviate these bottlenecks by presenting two novel methods that
improve the efficiency of CA. First, we introduce a bottom-up approach named
GrowAcq that reduces the maximum waiting time for the user and allows the
system to handle much larger sets of candidate constraints. It also reduces the
total number of queries for problems in which the target constraint network is
not sparse. Second, we propose a probability-based method to guide query
generation and show that it can significantly reduce the number of queries
required to converge. We also propose a new technique that allows the use of
openly accessible CP solvers in query generation, removing the dependency of
existing methods on less well-maintained custom solvers that are not publicly
available. Experimental results show that our proposed methods outperform
state-of-the-art CA methods, reducing the number of queries by up to 60%. Our
methods work well even in cases where the set of candidate constraints is 50
times larger than the ones commonly used in the literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06135">SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning. (arXiv:2307.06135v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rana_K/0/1/0/all/0/1">Krishan Rana</a>, <a href="http://arxiv.org/find/cs/1/au:+Haviland_J/0/1/0/all/0/1">Jesse Haviland</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sourav Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Abou_Chakra_J/0/1/0/all/0/1">Jad Abou-Chakra</a>, <a href="http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1">Ian Reid</a>, <a href="http://arxiv.org/find/cs/1/au:+Suenderhauf_N/0/1/0/all/0/1">Niko Suenderhauf</a></p>
<p>Large language models (LLMs) have demonstrated impressive results in
developing generalist planning agents for diverse tasks. However, grounding
these plans in expansive, multi-floor, and multi-room environments presents a
significant challenge for robotics. We introduce SayPlan, a scalable approach
to LLM-based, large-scale task planning for robotics using 3D scene graph
(3DSG) representations. To ensure the scalability of our approach, we: (1)
exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a semantic
search for task-relevant subgraphs from a smaller, collapsed representation of
the full graph; (2) reduce the planning horizon for the LLM by integrating a
classical path planner and (3) introduce an iterative replanning pipeline that
refines the initial plan using feedback from a scene graph simulator,
correcting infeasible actions and avoiding planning failures. We evaluate our
approach on two large-scale environments spanning up to 3 floors, 36 rooms and
140 objects, and show that our approach is capable of grounding large-scale,
long-horizon task plans from abstract, and natural language instruction for a
mobile manipulator robot to execute.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06152">Maneuver Decision-Making Through Automatic Curriculum Reinforcement Learning Without Handcrafted Reward functions. (arXiv:2307.06152v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hong_Peng_Z/0/1/0/all/0/1">Zhang Hong-Peng</a></p>
<p>Maneuver decision-making is the core of unmanned combat aerial vehicle for
autonomous air combat. To solve this problem, we propose an automatic
curriculum reinforcement learning method, which enables agents to learn
effective decisions in air combat from scratch. The range of initial states are
used for distinguishing curricula of different difficulty levels, thereby
maneuver decision is divided into a series of sub-tasks from easy to difficult,
and test results are used to change sub-tasks. As sub-tasks change, agents
gradually learn to complete a series of sub-tasks from easy to difficult,
enabling them to make effective maneuvering decisions to cope with various
states without the need to spend effort designing reward functions. The
ablation studied show that the automatic curriculum learning proposed in this
article is an essential component for training through reinforcement learning,
namely, agents cannot complete effective decisions without curriculum learning.
Simulation experiments show that, after training, agents are able to make
effective decisions given different states, including tracking, attacking and
escaping, which are both rational and interpretable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06159">Reflective Hybrid Intelligence for Meaningful Human Control in Decision-Support Systems. (arXiv:2307.06159v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1">Catholijn M. Jonker</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebert_L/0/1/0/all/0/1">Luciano Cavalcante Siebert</a>, <a href="http://arxiv.org/find/cs/1/au:+Murukannaiah_P/0/1/0/all/0/1">Pradeep K. Murukannaiah</a></p>
<p>With the growing capabilities and pervasiveness of AI systems, societies must
collectively choose between reduced human autonomy, endangered democracies and
limited human rights, and AI that is aligned to human and social values,
nurturing collaboration, resilience, knowledge and ethical behaviour. In this
chapter, we introduce the notion of self-reflective AI systems for meaningful
human control over AI systems. Focusing on decision support systems, we propose
a framework that integrates knowledge from psychology and philosophy with
formal reasoning methods and machine learning approaches to create AI systems
responsive to human values and social norms. We also propose a possible
research approach to design and develop self-reflective capability in AI
systems. Finally, we argue that self-reflective AI systems can lead to
self-reflective hybrid systems (human + AI), thus increasing meaningful human
control and empowering human moral reasoning by providing comprehensible
information and insights on possible human moral blind spots.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06162">Deep Generative Models for Physiological Signals: A Systematic Literature Review. (arXiv:2307.06162v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Neifar_N/0/1/0/all/0/1">Nour Neifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mdhaffar_A/0/1/0/all/0/1">Afef Mdhaffar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_Hamadou_A/0/1/0/all/0/1">Achraf Ben-Hamadou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jmaiel_M/0/1/0/all/0/1">Mohamed Jmaiel</a></p>
<p>In this paper, we present a systematic literature review on deep generative
models for physiological signals, particularly electrocardiogram,
electroencephalogram, photoplethysmogram and electromyogram. Compared to the
existing review papers, we present the first review that summarizes the recent
state-of-the-art deep generative models. By analysing the state-of-the-art
research related to deep generative models along with their main applications
and challenges, this review contributes to the overall understanding of these
models applied to physiological signals. Additionally, by highlighting the
employed evaluation protocol and the most used physiological databases, this
review facilitates the assessment and benchmarking of deep generative models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06166">Can Vision-Language Models be a Good Guesser? Exploring VLMs for Times and Location Reasoning. (arXiv:2307.06166v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gengyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yurui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kerui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a></p>
<p>Vision-Language Models (VLMs) are expected to be capable of reasoning with
commonsense knowledge as human beings. One example is that humans can reason
where and when an image is taken based on their knowledge. This makes us wonder
if, based on visual cues, Vision-Language Models that are pre-trained with
large-scale image-text resources can achieve and even outperform human's
capability in reasoning times and location. To address this question, we
propose a two-stage \recognition\space and \reasoning\space probing task,
applied to discriminative and generative VLMs to uncover whether VLMs can
recognize times and location-relevant features and further reason about it. To
facilitate the investigation, we introduce WikiTiLo, a well-curated image
dataset compromising images with rich socio-cultural cues. In the extensive
experimental studies, we find that although VLMs can effectively retain
relevant features in visual encoders, they still fail to make perfect
reasoning. We will release our dataset and codes to facilitate future studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06187">Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems. (arXiv:2307.06187v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nascimento_N/0/1/0/all/0/1">Nathalia Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Alencar_P/0/1/0/all/0/1">Paulo Alencar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cowan_D/0/1/0/all/0/1">Donald Cowan</a></p>
<p>In autonomic computing, self-adaptation has been proposed as a fundamental
paradigm to manage the complexity of multiagent systems (MASs). This achieved
by extending a system with support to monitor and adapt itself to achieve
specific concerns of interest. Communication in these systems is key given that
in scenarios involving agent interaction, it enhances cooperation and reduces
coordination challenges by enabling direct, clear information exchange.
However, improving the expressiveness of the interaction communication with
MASs is not without challenges. In this sense, the interplay between
self-adaptive systems and effective communication is crucial for future MAS
advancements. In this paper, we propose the integration of large language
models (LLMs) such as GPT-based technologies into multiagent systems. We anchor
our methodology on the MAPE-K model, which is renowned for its robust support
in monitoring, analyzing, planning, and executing system adaptations in
response to dynamic environments. We also present a practical illustration of
the proposed approach, in which we implement and assess a basic MAS-based
application. The approach significantly advances the state-of-the-art of
self-adaptive systems by proposing a new paradigm for MAS self-adaptation of
autonomous systems based on LLM capabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06213">Testing different Log Bases For Vector Model Weighting Technique. (arXiv:2307.06213v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Assaf_K/0/1/0/all/0/1">Kamel Assaf</a></p>
<p>Information retrieval systems retrieves relevant documents based on a query
submitted by the user. The documents are initially indexed and the words in the
documents are assigned weights using a weighting technique called TFIDF which
is the product of Term Frequency (TF) and Inverse Document Frequency (IDF). TF
represents the number of occurrences of a term in a document. IDF measures
whether the term is common or rare across all documents. It is computed by
dividing the total number of documents in the system by the number of documents
containing the term and then computing the logarithm of the quotient. By
default, we use base 10 to calculate the logarithm. In this paper, we are going
to test this weighting technique by using a range of log bases from 0.1 to
100.0 to calculate the IDF. Testing different log bases for vector model
weighting technique is to highlight the importance of understanding the
performance of the system at different weighting values. We use the documents
of MED, CRAN, NPL, LISA, and CISI test collections that scientists assembled
explicitly for experiments in data information retrieval systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06240">DSSE: a drone swarm search environment. (arXiv:2307.06240v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Castanares_M/0/1/0/all/0/1">Manuel Castanares</a>, <a href="http://arxiv.org/find/cs/1/au:+Carrete_L/0/1/0/all/0/1">Luis F. S. Carrete</a>, <a href="http://arxiv.org/find/cs/1/au:+Damiani_E/0/1/0/all/0/1">Enrico F. Damiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Abreu_L/0/1/0/all/0/1">Leonardo D. M. de Abreu</a>, <a href="http://arxiv.org/find/cs/1/au:+Brancalion_J/0/1/0/all/0/1">Jos&#xe9; Fernando B. Brancalion</a>, <a href="http://arxiv.org/find/cs/1/au:+Barth_F/0/1/0/all/0/1">Fabr&#xed;cio J. Barth</a></p>
<p>The Drone Swarm Search project is an environment, based on PettingZoo, that
is to be used in conjunction with multi-agent (or single-agent) reinforcement
learning algorithms. It is an environment in which the agents (drones), have to
find the targets (shipwrecked people). The agents do not know the position of
the target and do not receive rewards related to their own distance to the
target(s). However, the agents receive the probabilities of the target(s) being
in a certain cell of the map. The aim of this project is to aid in the study of
reinforcement learning algorithms that require dynamic probabilities as inputs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06290">Instruction Mining: High-Quality Instruction Data Selection for Large Language Models. (arXiv:2307.06290v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yihan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yanbin Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a></p>
<p>Large language models typically undergo two training stages, pretraining and
finetuning. Despite that large-scale pretraining endows the model with strong
capabilities to generate natural language responses, these pretrained models
can still fail to understand human instructions at times. To enhance language
models' ability of interpreting and responding to instructions, instruction
finetuning has emerged as a critical method in this area. Recent studies found
that large language models can be finetuned to perform well even with a small
amount of high-quality instruction-following data. However, the selection of
high-quality datasets for finetuning language models still lacks clear
guidelines to follow. In this paper, we propose InstructMining, a linear rule
for evaluating instruction-following data quality. We formulate InstructMining
using specific natural language indicators. To investigate the relationship
between data quality and these indicators, we further conduct extensive
finetuning experiments. The experiment results are then applied to estimating
parameters in InstructMining. To further investigate its performance, we use
InstructMining to select high-quality data from unseen datasets. Results
demonstrate that InstructMining can help select relatively high-quality samples
from various instruction-following datasets. Compared to models finetuned on
unfiltered datasets, models finetuned on InstructMining selected datasets
perform better on 42.5% cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06304">Patch n&#x27; Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution. (arXiv:2307.06304v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1">Mostafa Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1">Basil Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Djolonga_J/0/1/0/all/0/1">Josip Djolonga</a>, <a href="http://arxiv.org/find/cs/1/au:+Heek_J/0/1/0/all/0/1">Jonathan Heek</a>, <a href="http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1">Matthias Minderer</a>, <a href="http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1">Mathilde Caron</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1">Andreas Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1">Joan Puigcerver</a>, <a href="http://arxiv.org/find/cs/1/au:+Geirhos_R/0/1/0/all/0/1">Robert Geirhos</a>, <a href="http://arxiv.org/find/cs/1/au:+Alabdulmohsin_I/0/1/0/all/0/1">Ibrahim Alabdulmohsin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliver_A/0/1/0/all/0/1">Avital Oliver</a>, <a href="http://arxiv.org/find/cs/1/au:+Padlewski_P/0/1/0/all/0/1">Piotr Padlewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1">Alexey Gritsenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1">Mario Lu&#x10d;i&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a></p>
<p>The ubiquitous and demonstrably suboptimal choice of resizing images to a
fixed resolution before processing them with computer vision models has not yet
been successfully challenged. However, models such as the Vision Transformer
(ViT) offer flexible sequence-based modeling, and hence varying input sequence
lengths. We take advantage of this with NaViT (Native Resolution ViT) which
uses sequence packing during training to process inputs of arbitrary
resolutions and aspect ratios. Alongside flexible model usage, we demonstrate
improved training efficiency for large-scale supervised and contrastive
image-text pretraining. NaViT can be efficiently transferred to standard tasks
such as image and video classification, object detection, and semantic
segmentation and leads to improved results on robustness and fairness
benchmarks. At inference time, the input resolution flexibility can be used to
smoothly navigate the test-time cost-performance trade-off. We believe that
NaViT marks a departure from the standard, CNN-designed, input and modelling
pipeline used by most computer vision models, and represents a promising
direction for ViTs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06328">Budgeting Counterfactual for Offline RL. (arXiv:2307.06328v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1">Pratik Chaudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1">Rasool Fakoor</a></p>
<p>The main challenge of offline reinforcement learning, where data is limited,
arises from a sequence of counterfactual reasoning dilemmas within the realm of
potential actions: What if we were to choose a different course of action?
These circumstances frequently give rise to extrapolation errors, which tend to
accumulate exponentially with the problem horizon. Hence, it becomes crucial to
acknowledge that not all decision steps are equally important to the final
outcome, and to budget the number of counterfactual decisions a policy make in
order to control the extrapolation. Contrary to existing approaches that use
regularization on either the policy or value function, we propose an approach
to explicitly bound the amount of out-of-distribution actions during training.
Specifically, our method utilizes dynamic programming to decide where to
extrapolate and where not to, with an upper bound on the decisions different
from behavior policy. It balances between the potential for improvement from
taking out-of-distribution actions and the risk of making errors due to
extrapolation. Theoretically, we justify our method by the constrained
optimality of the fixed point solution to our $Q$ updating rules. Empirically,
we show that the overall performance of our method is better than the
state-of-the-art offline RL methods on tasks in the widely-used D4RL
benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06333">Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation. (arXiv:2307.06333v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1">Andi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Netanyahu_A/0/1/0/all/0/1">Aviv Netanyahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_M/0/1/0/all/0/1">Mark Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1">Tianmin Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bobu_A/0/1/0/all/0/1">Andreea Bobu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_J/0/1/0/all/0/1">Julie Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a></p>
<p>Policies often fail due to distribution shift -- changes in the state and
reward that occur when a policy is deployed in new environments. Data
augmentation can increase robustness by making the model invariant to
task-irrelevant changes in the agent's observation. However, designers don't
know which concepts are irrelevant a priori, especially when different end
users have different preferences about how the task is performed. We propose an
interactive framework to leverage feedback directly from the user to identify
personalized task-irrelevant concepts. Our key idea is to generate
counterfactual demonstrations that allow users to quickly identify possible
task-relevant and irrelevant concepts. The knowledge of task-irrelevant
concepts is then used to perform data augmentation and thus obtain a policy
adapted to personalized user objectives. We present experiments validating our
framework on discrete and continuous control tasks with real human users. Our
method (1) enables users to better understand agent failure, (2) reduces the
number of demonstrations required for fine-tuning, and (3) aligns the agent to
individual user task preferences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2010.02613">Deep Learning based Uncertainty Decomposition for Real-time Control. (arXiv:2010.02613v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1">Neha Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Umlauft_J/0/1/0/all/0/1">Jonas Umlauft</a>, <a href="http://arxiv.org/find/cs/1/au:+Lederer_A/0/1/0/all/0/1">Armin Lederer</a>, <a href="http://arxiv.org/find/cs/1/au:+Beckers_T/0/1/0/all/0/1">Thomas Beckers</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirche_S/0/1/0/all/0/1">Sandra Hirche</a></p>
<p>Data-driven control in unknown environments requires a clear understanding of
the involved uncertainties for ensuring safety and efficient exploration. While
aleatoric uncertainty that arises from measurement noise can often be
explicitly modeled given a parametric description, it can be harder to model
epistemic uncertainty, which describes the presence or absence of training
data. The latter can be particularly useful for implementing exploratory
control strategies when system dynamics are unknown. We propose a novel method
for detecting the absence of training data using deep learning, which gives a
continuous valued scalar output between $0$ (indicating low uncertainty) and
$1$ (indicating high uncertainty). We utilize this detector as a proxy for
epistemic uncertainty and show its advantages over existing approaches on
synthetic and real-world datasets. Our approach can be directly combined with
aleatoric uncertainty estimates and allows for uncertainty estimation in
real-time as the inference is sample-free unlike existing approaches for
uncertainty modeling. We further demonstrate the practicality of this
uncertainty estimate in deploying online data-efficient control on a simulated
quadcopter acted upon by an unknown disturbance model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2101.10870">B-HAR: an open-source baseline framework for in depth study of human activity recognition datasets and workflows. (arXiv:2101.10870v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Demrozi_F/0/1/0/all/0/1">Florenc Demrozi</a>, <a href="http://arxiv.org/find/eess/1/au:+Turetta_C/0/1/0/all/0/1">Cristian Turetta</a>, <a href="http://arxiv.org/find/eess/1/au:+Pravadelli_G/0/1/0/all/0/1">Graziano Pravadelli</a></p>
<p>Human Activity Recognition (HAR), based on machine and deep learning
algorithms is considered one of the most promising technologies to monitor
professional and daily life activities for different categories of people
(e.g., athletes, elderly, kids, employers) in order to provide a variety of
services related, for example to well-being, empowering of technical
performances, prevention of risky situation, and educational purposes. However,
the analysis of the effectiveness and the efficiency of HAR methodologies
suffers from the lack of a standard workflow, which might represent the
baseline for the estimation of the quality of the developed pattern recognition
models. This makes the comparison among different approaches a challenging
task. In addition, researchers can make mistakes that, when not detected,
definitely affect the achieved results. To mitigate such issues, this paper
proposes an open-source automatic and highly configurable framework, named
B-HAR, for the definition, standardization, and development of a baseline
framework in order to evaluate and compare HAR methodologies. It implements the
most popular data processing methods for data preparation and the most commonly
used machine and deep learning pattern recognition models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2102.00479">Fast Rates for the Regret of Offline Reinforcement Learning. (arXiv:2102.00479v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yichun Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1">Nathan Kallus</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_M/0/1/0/all/0/1">Masatoshi Uehara</a></p>
<p>We study the regret of reinforcement learning from offline data generated by
a fixed behavior policy in an infinite-horizon discounted Markov decision
process (MDP). While existing analyses of common approaches, such as fitted
$Q$-iteration (FQI), suggest a $O(1/\sqrt{n})$ convergence for regret,
empirical behavior exhibits \emph{much} faster convergence. In this paper, we
present a finer regret analysis that exactly characterizes this phenomenon by
providing fast rates for the regret convergence. First, we show that given any
estimate for the optimal quality function $Q^*$, the regret of the policy it
defines converges at a rate given by the exponentiation of the $Q^*$-estimate's
pointwise convergence rate, thus speeding it up. The level of exponentiation
depends on the level of noise in the \emph{decision-making} problem, rather
than the estimation problem. We establish such noise levels for linear and
tabular MDPs as examples. Second, we provide new analyses of FQI and Bellman
residual minimization to establish the correct pointwise convergence
guarantees. As specific cases, our results imply $O(1/n)$ regret rates in
linear cases and $\exp(-\Omega(n))$ regret rates in tabular cases. We extend
our findings to general function approximation by extending our results to
regret guarantees based on $L_p$-convergence rates for estimating $Q^*$ rather
than pointwise rates, where $L_2$ guarantees for nonparametric $Q^*$-estimation
can be ensured under mild conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.00129">Fundamental Limits for Sensor-Based Robot Control. (arXiv:2202.00129v5 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1">Anirudha Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Z/0/1/0/all/0/1">Zhiting Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacelli_V/0/1/0/all/0/1">Vincent Pacelli</a></p>
<p>Our goal is to develop theory and algorithms for establishing fundamental
limits on performance imposed by a robot's sensors for a given task. In order
to achieve this, we define a quantity that captures the amount of task-relevant
information provided by a sensor. Using a novel version of the generalized Fano
inequality from information theory, we demonstrate that this quantity provides
an upper bound on the highest achievable expected reward for one-step decision
making tasks. We then extend this bound to multi-step problems via a dynamic
programming approach. We present algorithms for numerically computing the
resulting bounds, and demonstrate our approach on three examples: (i) the lava
problem from the literature on partially observable Markov decision processes,
(ii) an example with continuous state and observation spaces corresponding to a
robot catching a freely-falling object, and (iii) obstacle avoidance using a
depth sensor with non-Gaussian noise. We demonstrate the ability of our
approach to establish strong limits on achievable performance for these
problems by comparing our upper bounds with achievable lower bounds (computed
by synthesizing or learning concrete control policies).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2204.06438">Fair Algorithm Design: Fair and Efficacious Machine Scheduling. (arXiv:2204.06438v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Niu_A/0/1/0/all/0/1">April Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Totschnig_A/0/1/0/all/0/1">Agnes Totschnig</a>, <a href="http://arxiv.org/find/cs/1/au:+Vetta_A/0/1/0/all/0/1">Adrian Vetta</a></p>
<p>Motivated by a plethora of practical examples where bias is induced by
automated-decision making algorithms, there has been strong recent interest in
the design of fair algorithms. However, there is often a dichotomy between
fairness and efficacy: fair algorithms may proffer low social welfare solutions
whereas welfare optimizing algorithms may be very unfair. This issue is
exemplified in the machine scheduling problem where, for $n$ jobs, the social
welfare of any fair solution may be a factor $\Omega(n)$ worse than the optimal
welfare. In this paper, we prove that this dichotomy between fairness and
efficacy can be overcome if we allow for a negligible amount of bias: there
exist algorithms that are both "almost perfectly fair" and have a constant
factor efficacy ratio, that is, are guaranteed to output solutions that have
social welfare within a constant factor of optimal welfare. Specifically, for
any $\epsilon&gt;0$, there exist mechanisms with efficacy ratio
$\Theta(\frac{1}{\epsilon})$ and where no agent is more than an $\epsilon$
fraction worse off than they are in the fairest possible solution (given by an
algorithm that does not use personal or type data). Moreover, these bicriteria
guarantees are tight and apply to both the single machine case and the multiple
machine case. The key to our results are the use of Pareto scheduling
mechanisms. These mechanisms, by the judicious use of personal or type data,
are able to exploit Pareto improvements that benefit every individual; such
Pareto improvements would typically be forbidden by fair scheduling algorithms
designed to satisfy standard statistical measures of group fairness. We
anticipate this paradigm, the judicious use of personal data by a fair
algorithm to greatly improve performance at the cost of negligible bias, has
wider application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.09137">GreenKGC: A Lightweight Knowledge Graph Completion Method. (arXiv:2208.09137v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yun-Cheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_X/0/1/0/all/0/1">Xiou Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a></p>
<p>Knowledge graph completion (KGC) aims to discover missing relationships
between entities in knowledge graphs (KGs). Most prior KGC work focuses on
learning embeddings for entities and relations through a simple scoring
function. Yet, a higher-dimensional embedding space is usually required for a
better reasoning capability, which leads to a larger model size and hinders
applicability to real-world problems (e.g., large-scale KGs or mobile/edge
computing). A lightweight modularized KGC solution, called GreenKGC, is
proposed in this work to address this issue. GreenKGC consists of three
modules: representation learning, feature pruning, and decision learning, to
extract discriminant KG features and make accurate predictions on missing
relationships using classifiers and negative sampling. Experimental results
demonstrate that, in low dimensions, GreenKGC can outperform SOTA methods in
most datasets. In addition, low-dimensional GreenKGC can achieve competitive or
even better performance against high-dimensional models with a much smaller
model size.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.01892">Polysemanticity and Capacity in Neural Networks. (arXiv:2210.01892v3 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Scherlis_A/0/1/0/all/0/1">Adam Scherlis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_K/0/1/0/all/0/1">Kshitij Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermyn_A/0/1/0/all/0/1">Adam S. Jermyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Benton_J/0/1/0/all/0/1">Joe Benton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlegeris_B/0/1/0/all/0/1">Buck Shlegeris</a></p>
<p>Individual neurons in neural networks often represent a mixture of unrelated
features. This phenomenon, called polysemanticity, can make interpreting neural
networks more difficult and so we aim to understand its causes. We propose
doing so through the lens of feature \emph{capacity}, which is the fractional
dimension each feature consumes in the embedding space. We show that in a toy
model the optimal capacity allocation tends to monosemantically represent the
most important features, polysemantically represent less important features (in
proportion to their impact on the loss), and entirely ignore the least
important features. Polysemanticity is more prevalent when the inputs have
higher kurtosis or sparsity and more prevalent in some architectures than
others. Given an optimal allocation of capacity, we go on to study the geometry
of the embedding space. We find a block-semi-orthogonal structure, with
differing block sizes in different models, highlighting the impact of model
architecture on the interpretability of its neurons.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.03104">Distributionally Adaptive Meta Reinforcement Learning. (arXiv:2210.03104v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ajay_A/0/1/0/all/0/1">Anurag Ajay</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1">Dibya Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a></p>
<p>Meta-reinforcement learning algorithms provide a data-driven way to acquire
policies that quickly adapt to many tasks with varying rewards or dynamics
functions. However, learned meta-policies are often effective only on the exact
task distribution on which they were trained and struggle in the presence of
distribution shift of test-time rewards or transition dynamics. In this work,
we develop a framework for meta-RL algorithms that are able to behave
appropriately under test-time distribution shifts in the space of tasks. Our
framework centers on an adaptive approach to distributional robustness that
trains a population of meta-policies to be robust to varying levels of
distribution shift. When evaluated on a potentially shifted test-time
distribution of tasks, this allows us to choose the meta-policy with the most
appropriate level of robustness, and use it to perform fast adaptation. We
formally show how our framework allows for improved regret under distribution
shift, and empirically show its efficacy on simulated robotics problems under a
wide range of distribution shifts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.09452">Multiple Instance Learning via Iterative Self-Paced Supervised Contrastive Learning. (arXiv:2210.09452v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kangning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Weicheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yiqiu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Razavian_N/0/1/0/all/0/1">Narges Razavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1">Krzysztof J. Geras</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Granda_C/0/1/0/all/0/1">Carlos Fernandez-Granda</a></p>
<p>Learning representations for individual instances when only bag-level labels
are available is a fundamental challenge in multiple instance learning (MIL).
Recent works have shown promising results using contrastive self-supervised
learning (CSSL), which learns to push apart representations corresponding to
two different randomly-selected instances. Unfortunately, in real-world
applications such as medical image classification, there is often class
imbalance, so randomly-selected instances mostly belong to the same majority
class, which precludes CSSL from learning inter-class differences. To address
this issue, we propose a novel framework, Iterative Self-paced Supervised
Contrastive Learning for MIL Representations (ItS2CLR), which improves the
learned representation by exploiting instance-level pseudo labels derived from
the bag-level labels. The framework employs a novel self-paced sampling
strategy to ensure the accuracy of pseudo labels. We evaluate ItS2CLR on three
medical datasets, showing that it improves the quality of instance-level pseudo
labels and representations, and outperforms existing MIL methods in terms of
both bag and instance level accuracy. Code is available at
https://github.com/Kangningthu/ItS2CLR
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.15097">Contrastive Decoding: Open-ended Text Generation as Optimization. (arXiv:2210.15097v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Lisa Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1">Ari Holtzman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1">Daniel Fried</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1">Jason Eisner</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1">Tatsunori Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1">Mike Lewis</a></p>
<p>Given a language model (LM), maximum probability is a poor decoding objective
for open-ended generation, because it produces short and repetitive text. On
the other hand, sampling can often produce incoherent text that drifts from the
original topics. We propose contrastive decoding (CD), a reliable decoding
approach that optimizes a contrastive objective subject to a plausibility
constraint. The contrastive objective returns the difference between the
likelihood under a large LM (called the expert, e.g. OPT-13B) and a small LM
(called the amateur, e.g. OPT-125M), and the constraint ensures that the
outputs are plausible. CD is inspired by the fact that the failures of larger
LMs (e.g., repetition, incoherence) are even more prevalent in smaller LMs, and
that this difference signals which texts should be preferred. CD requires zero
additional training, and produces higher quality text than decoding from the
larger LM alone. It also works across model scales (OPT-13B and GPT2-1.5B) and
significantly outperforms four strong decoding algorithms (e.g., nucleus,
top-k) in automatic and human evaluations across wikipedia, news and story
domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.01413">Harnessing the Power of Explanations for Incremental Training: A LIME-Based Approach. (arXiv:2211.01413v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mazumder_A/0/1/0/all/0/1">Arnab Neelim Mazumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyons_N/0/1/0/all/0/1">Niall Lyons</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Ashutosh Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Santra_A/0/1/0/all/0/1">Avik Santra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohsenin_T/0/1/0/all/0/1">Tinoosh Mohsenin</a></p>
<p>Explainability of neural network prediction is essential to understand
feature importance and gain interpretable insight into neural network
performance. However, explanations of neural network outcomes are mostly
limited to visualization, and there is scarce work that looks to use these
explanations as feedback to improve model performance. In this work, model
explanations are fed back to the feed-forward training to help the model
generalize better. To this extent, a custom weighted loss where the weights are
generated by considering the Euclidean distances between true LIME (Local
Interpretable Model-Agnostic Explanations) explanations and model-predicted
LIME explanations is proposed. Also, in practical training scenarios,
developing a solution that can help the model learn sequentially without losing
information on previous data distribution is imperative due to the
unavailability of all the training data at once. Thus, the framework
incorporates the custom weighted loss with Elastic Weight Consolidation (EWC)
to maintain performance in sequential testing sets. The proposed custom
training procedure results in a consistent enhancement of accuracy ranging from
0.5% to 1.5% throughout all phases of the incremental learning setup compared
to traditional loss-based training methods for the keyword spotting task using
the Google Speech Commands dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.07625">What Images are More Memorable to Machines?. (arXiv:2211.07625v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junlin Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1">Huangying Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Jie Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_P/0/1/0/all/0/1">Pengfei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongdong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersson_L/0/1/0/all/0/1">Lars Petersson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1">Ian Reid</a></p>
<p>This paper studies the problem of measuring and predicting how memorable an
image is to pattern recognition machines, as a path to explore machine
intelligence. Firstly, we propose a self-supervised machine memory
quantification pipeline, dubbed ``MachineMem measurer'', to collect machine
memorability scores of images. Similar to humans, machines also tend to
memorize certain kinds of images, whereas the types of images that machines and
humans memorize are different. Through in-depth analysis and comprehensive
visualizations, we gradually unveil that``complex" images are usually more
memorable to machines. We further conduct extensive experiments across 11
different machines (from linear classifiers to modern ViTs) and 9 pre-training
methods to analyze and understand machine memory. This work proposes the
concept of machine memorability and opens a new research direction at the
interface between machine memory and visual data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.10590">Bidirectional Generation of Structure and Properties Through a Single Molecular Foundation Model. (arXiv:2211.10590v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jinho Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a></p>
<p>The recent success of large foundation models in artificial intelligence has
prompted the emergence of chemical pre-trained models. Despite the growing
interest in large molecular pre-trained models that provide informative
representations for downstream tasks, attempts for multimodal pre-training
approaches on the molecule domain were limited. To address this, we present a
novel multimodal molecular pre-trained model that incorporates the modalities
of structure and biochemical properties, drawing inspiration from recent
advances in multimodal learning techniques. Our proposed model pipeline of data
handling and training objectives aligns the structure/property features in a
common embedding space, which enables the model to regard bidirectional
information between the molecules' structure and properties. These
contributions emerge synergistic knowledge, allowing us to tackle both
multimodal and unimodal downstream tasks through a single model. Through
extensive experiments, we demonstrate that our model shows remarkable
capabilities in solving various meaningful chemical challenges, including
conditional molecule generation, property prediction, molecule classification,
and reaction prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.01241">Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses. (arXiv:2302.01241v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lim_B/0/1/0/all/0/1">Brian Y. Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cahaly_J/0/1/0/all/0/1">Joseph P. Cahaly</a>, <a href="http://arxiv.org/find/cs/1/au:+Sng_C/0/1/0/all/0/1">Chester Y. F. Sng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chew_A/0/1/0/all/0/1">Adam Chew</a></p>
<p>Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06375">One Transformer for All Time Series: Representing and Training with Time-Dependent Heterogeneous Tabular Data. (arXiv:2302.06375v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luetto_S/0/1/0/all/0/1">Simone Luetto</a>, <a href="http://arxiv.org/find/cs/1/au:+Garuti_F/0/1/0/all/0/1">Fabrizio Garuti</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1">Enver Sangineto</a>, <a href="http://arxiv.org/find/cs/1/au:+Forni_L/0/1/0/all/0/1">Lorenzo Forni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a></p>
<p>There is a recent growing interest in applying Deep Learning techniques to
tabular data, in order to replicate the success of other Artificial
Intelligence areas in this structured domain. Specifically interesting is the
case in which tabular data have a time dependence, such as, for instance
financial transactions. However, the heterogeneity of the tabular values, in
which categorical elements are mixed with numerical items, makes this
adaptation difficult. In this paper we propose a Transformer architecture to
represent heterogeneous time-dependent tabular data, in which numerical
features are represented using a set of frequency functions and the whole
network is uniformly trained with a unique loss function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.09582">Language-Specific Representation of Emotion-Concept Knowledge Causally Supports Emotion Inference. (arXiv:2302.09582v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Ming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yusheng Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hsiu-Yuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jiali Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinmiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huadong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yujia Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaozhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dan Zhang</a></p>
<p>Understanding how language supports emotion inference remains a topic of
debate in emotion science. The present study investigated whether
language-derived emotion-concept knowledge would causally support emotion
inference by manipulating the language-specific knowledge representations in
large language models. Using the prompt technique, 14 attributes of emotion
concepts were found to be represented by distinct artificial neuron
populations. By manipulating these attribute-related neurons, the majority of
the emotion inference tasks showed performance deterioration compared to random
manipulations. The attribute-specific performance deterioration was related to
the importance of different attributes in human mental space. Our findings
provide causal evidence in support of a language-based mechanism for emotion
inference and highlight the contributions of emotion-concept knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.02819">GPT detectors are biased against non-native English writers. (arXiv:2304.02819v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1">Weixin Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuksekgonul_M/0/1/0/all/0/1">Mert Yuksekgonul</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yining Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1">Eric Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a></p>
<p>The rapid adoption of generative language models has brought about
substantial advancements in digital communication, while simultaneously raising
concerns regarding the potential misuse of AI-generated content. Although
numerous detection methods have been proposed to differentiate between AI and
human-generated content, the fairness and robustness of these detectors remain
underexplored. In this study, we evaluate the performance of several
widely-used GPT detectors using writing samples from native and non-native
English writers. Our findings reveal that these detectors consistently
misclassify non-native English writing samples as AI-generated, whereas native
writing samples are accurately identified. Furthermore, we demonstrate that
simple prompting strategies can not only mitigate this bias but also
effectively bypass GPT detectors, suggesting that GPT detectors may
unintentionally penalize writers with constrained linguistic expressions. Our
results call for a broader conversation about the ethical implications of
deploying ChatGPT content detectors and caution against their use in evaluative
or educational settings, particularly when they may inadvertently penalize or
exclude non-native English speakers from the global discourse. The published
version of this study can be accessed at:
www.cell.com/patterns/fulltext/S2666-3899(23)00130-7
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06848">CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments. (arXiv:2304.06848v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cannizzaro_R/0/1/0/all/0/1">Ricardo Cannizzaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunze_L/0/1/0/all/0/1">Lars Kunze</a></p>
<p>Robots operating in real-world environments must reason about possible
outcomes of stochastic actions and make decisions based on partial observations
of the true world state. A major challenge for making accurate and robust
action predictions is the problem of confounding, which if left untreated can
lead to prediction errors. The partially observable Markov decision process
(POMDP) is a widely-used framework to model these stochastic and
partially-observable decision-making problems. However, due to a lack of
explicit causal semantics, POMDP planning methods are prone to confounding bias
and thus in the presence of unobserved confounders may produce underperforming
policies. This paper presents a novel causally-informed extension of "anytime
regularized determinized sparse partially observable tree" (AR-DESPOT), a
modern anytime online POMDP planner, using causal modelling and inference to
eliminate errors caused by unmeasured confounder variables. We further propose
a method to learn offline the partial parameterisation of the causal model for
planning, from ground truth model data. We evaluate our methods on a toy
problem with an unobserved confounder and show that the learned causal model is
highly accurate, while our planning method is more robust to confounding and
produces overall higher performing policies than AR-DESPOT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.11574">Meta-multigraph Search: Rethinking Meta-structure on Heterogeneous Information Networks. (arXiv:2304.11574v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a></p>
<p>Meta-structures are widely used to define which subset of neighbors to
aggregate information in heterogeneous information networks (HINs). In this
work, we investigate existing meta-structures, including meta-path and
meta-graph, and observe that they are initially designed manually with fixed
patterns and hence are insufficient to encode various rich semantic information
on diverse HINs. Through reflection on their limitation, we define a new
concept called meta-multigraph as a more expressive and flexible generalization
of meta-graph, and propose a stable differentiable search method to
automatically optimize the meta-multigraph for specific HINs and tasks. As the
flexibility of meta-multigraphs may propagate redundant messages, we further
introduce a complex-to-concise (C2C) meta-multigraph that propagates messages
from complex to concise along the depth of meta-multigraph. Moreover, we
observe that the differentiable search typically suffers from unstable search
and a significant gap between the meta-structures in search and evaluation. To
this end, we propose a progressive search algorithm by implicitly narrowing the
search space to improve search stability and reduce inconsistency. Extensive
experiments are conducted on six medium-scale benchmark datasets and one
large-scale benchmark dataset over two representative tasks, i.e., node
classification and recommendation. Empirical results demonstrate that our
search methods can automatically find expressive meta-multigraphs and C2C
meta-multigraphs, enabling our model to outperform state-of-the-art
heterogeneous graph neural networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.01424">Uncertain Machine Ethical Decisions Using Hypothetical Retrospection. (arXiv:2305.01424v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kolker_S/0/1/0/all/0/1">Simon Kolker</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennis_L/0/1/0/all/0/1">Louise Dennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1">Ramon Fraga Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengwei Xu</a></p>
<p>We propose the use of the hypothetical retrospection argumentation procedure,
developed by Sven Ove Hansson to improve existing approaches to machine ethical
reasoning by accounting for probability and uncertainty from a position of
Philosophy that resonates with humans. Actions are represented with a branching
set of potential outcomes, each with a state, utility, and either a numeric or
poetic probability estimate. Actions are chosen based on comparisons between
sets of arguments favouring actions from the perspective of their branches,
even those branches that led to an undesirable outcome. This use of arguments
allows a variety of philosophical theories for ethical reasoning to be used,
potentially in flexible combination with each other. We implement the
procedure, applying consequentialist and deontological ethical theories,
independently and concurrently, to an autonomous library system use case. We
introduce a preliminary framework that seems to meet the varied requirements of
a machine ethics system: versatility under multiple theories and a resonance
with humans that enables transparency and explainability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02759">Disentangled Contrastive Collaborative Filtering. (arXiv:2305.02759v3 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xubin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1">Lianghao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiashu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dawei Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a></p>
<p>Recent studies show that graph neural networks (GNNs) are prevalent to model
high-order relationships for collaborative filtering (CF). Towards this
research line, graph contrastive learning (GCL) has exhibited powerful
performance in addressing the supervision label shortage issue by learning
augmented user and item representations. While many of them show their
effectiveness, two key questions still remain unexplored: i) Most existing
GCL-based CF models are still limited by ignoring the fact that user-item
interaction behaviors are often driven by diverse latent intent factors (e.g.,
shopping for family party, preferred color or brand of products); ii) Their
introduced non-adaptive augmentation techniques are vulnerable to noisy
information, which raises concerns about the model's robustness and the risk of
incorporating misleading self-supervised signals. In light of these
limitations, we propose a Disentangled Contrastive Collaborative Filtering
framework (DCCF) to realize intent disentanglement with self-supervised
augmentation in an adaptive fashion. With the learned disentangled
representations with global context, our DCCF is able to not only distill
finer-grained latent factors from the entangled self-supervision signals but
also alleviate the augmentation-induced noise. Finally, the cross-view
contrastive learning task is introduced to enable adaptive augmentation with
our parameterized interaction mask generator. Experiments on various public
datasets demonstrate the superiority of our method compared to existing
solutions. Our model implementation is released at the link
https://github.com/HKUDS/DCCF.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.04003">ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Casadio_M/0/1/0/all/0/1">Marco Casadio</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnaboldi_L/0/1/0/all/0/1">Luca Arnaboldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Daggitt_M/0/1/0/all/0/1">Matthew L. Daggitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Isac_O/0/1/0/all/0/1">Omri Isac</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinkar_T/0/1/0/all/0/1">Tanvi Dinkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kienitz_D/0/1/0/all/0/1">Daniel Kienitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1">Verena Rieser</a>, <a href="http://arxiv.org/find/cs/1/au:+Komendantskaya_E/0/1/0/all/0/1">Ekaterina Komendantskaya</a></p>
<p>Verification of machine learning models used in Natural Language Processing
(NLP) is known to be a hard problem. In particular, many known neural network
verification methods that work for computer vision and other numeric datasets
do not work for NLP. Here, we study technical reasons that underlie this
problem. Based on this analysis, we propose practical methods and heuristics
for preparing NLP datasets and models in a way that renders them amenable to
known verification methods based on abstract interpretation. We implement these
methods as a Python library called ANTONIO that links to the neural network
verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP
dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP
applications. We hope that, thanks to its general applicability, this work will
open novel possibilities for including NLP verification problems into neural
network verification competitions, and will popularise NLP problems within this
community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11474">RAMiT: Reciprocal Attention Mixing Transformer for Lightweight Image Restoration. (arXiv:2305.11474v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Haram Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_C/0/1/0/all/0/1">Cheolwoong Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jihyeon Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungjae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jinseop Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_S/0/1/0/all/0/1">Subeen Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jeongmin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taehoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jihoon Yang</a></p>
<p>Although many recent works have made advancements in the image restoration
(IR) field, they often suffer from an excessive number of parameters. Another
issue is that most Transformer-based IR methods focus only on either local or
global features, leading to limited receptive fields or deficient parameter
issues. To address these problems, we propose a lightweight IR network,
Reciprocal Attention Mixing Transformer (RAMiT). It employs our proposed
dimensional reciprocal attention mixing Transformer (D-RAMiT) blocks, which
compute bi-dimensional (spatial and channel) self-attentions in parallel with
different numbers of multi-heads. The bi-dimensional attentions help each other
to complement their counterpart's drawbacks and are then mixed. Additionally,
we introduce a hierarchical reciprocal attention mixing (H-RAMi) layer that
compensates for pixel-level information losses and utilizes semantic
information while maintaining an efficient hierarchical structure. Furthermore,
we revisit and modify MobileNet V1 and V2 to attach efficient convolutions to
our proposed components. The experimental results demonstrate that RAMiT
achieves state-of-the-art performance on multiple lightweight IR tasks,
including super-resolution, color denoising, grayscale denoising, low-light
enhancement, and deraining. Codes are available at
https://github.com/rami0205/RAMiT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13783">Deep Reinforcement Learning-based Multi-objective Path Planning on the Off-road Terrain Environment for Ground Vehicles. (arXiv:2305.13783v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shuqiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiru Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guoming Huang</a></p>
<p>Due to the vastly different energy consumption between up-slope and
down-slope, a path with the shortest length on a complex off-road terrain
environment (2.5D map) is not always the path with the least energy
consumption. For any energy-sensitive vehicle, realizing a good trade-off
between distance and energy consumption in 2.5D path planning is significantly
meaningful. In this paper, we propose a deep reinforcement learning-based 2.5D
multi-objective path planning method (DMOP). The DMOP can efficiently find the
desired path in three steps: (1) Transform the high-resolution 2.5D map into a
small-size map. (2) Use a trained deep Q network (DQN) to find the desired path
on the small-size map. (3) Build the planned path to the original
high-resolution map using a path-enhanced method. In addition, the hybrid
exploration strategy and reward shaping theory are applied to train the DQN.
The reward function is constructed with the information of terrain, distance,
and border. Simulation results show that the proposed method can finish the
multi-objective 2.5D path planning task with significantly high efficiency.
With similar planned paths, the speed of the proposed method is more than 100
times faster than that of the A* method and 30 times faster than that of H3DM
method. Also, simulation proves that the method has powerful reasoning
capability that enables it to perform arbitrary untrained planning tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18703">Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey. (arXiv:2305.18703v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1">Chen Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xujiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiaying Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1">Chengyuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Can Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_T/0/1/0/all/0/1">Tanmoy Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tianjiao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Panalkar_A/0/1/0/all/0/1">Amit Panalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanchi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengzhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1">Chris White</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Quanquan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a></p>
<p>Large language models (LLMs) have significantly advanced the field of natural
language processing (NLP), providing a highly useful, task-agnostic foundation
for a wide range of applications. However, directly applying LLMs to solve
sophisticated problems in specific domains meets many hurdles, caused by the
heterogeneity of domain data, the sophistication of domain knowledge, the
uniqueness of domain objectives, and the diversity of the constraints (e.g.,
various social norms, cultural conformity, religious beliefs, and ethical
standards in the domain applications). Domain specification techniques are key
to make large language models disruptive in many applications. Specifically, to
solve these hurdles, there has been a notable increase in research and
practices conducted in recent years on the domain specialization of LLMs. This
emerging field of study, with its substantial potential for impact,
necessitates a comprehensive and systematic review to better summarize and
guide ongoing work in this area. In this article, we present a comprehensive
survey on domain specification techniques for large language models, an
emerging direction critical for large language model applications. First, we
propose a systematic taxonomy that categorizes the LLM domain-specialization
techniques based on the accessibility to LLMs and summarizes the framework for
all the subcategories as well as their relations and differences to each other.
Second, we present an extensive taxonomy of critical application domains that
can benefit dramatically from specialized LLMs, discussing their practical
significance and open challenges. Last, we offer our insights into the current
research status and future trends in this area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02121">Identifying Subgroups of ICU Patients Using End-to-End Multivariate Time-Series Clustering Algorithm Based on Real-World Vital Signs Data. (arXiv:2306.02121v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1">Tongyue Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhilong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Junhua Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jianguo Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1">Shuai Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Huiying Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_G/0/1/0/all/0/1">Guilan Kong</a></p>
<p>This study employed the MIMIC-IV database as data source to investigate the
use of dynamic, high-frequency, multivariate time-series vital signs data,
including temperature, heart rate, mean blood pressure, respiratory rate, and
SpO2, monitored first 8 hours data in the ICU stay. Various clustering
algorithms were compared, and an end-to-end multivariate time series clustering
system called Time2Feat, combined with K-Means, was chosen as the most
effective method to cluster patients in the ICU. In clustering analysis, data
of 8,080 patients admitted between 2008 and 2016 was used for model development
and 2,038 patients admitted between 2017 and 2019 for model validation. By
analyzing the differences in clinical mortality prognosis among different
categories, varying risks of ICU mortality and hospital mortality were found
between different subgroups. Furthermore, the study visualized the trajectory
of vital signs changes. The findings of this study provide valuable insights
into the potential use of multivariate time-series clustering systems in
patient management and monitoring in the ICU setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03717">Description Logics with Abstraction and Refinement. (arXiv:2306.03717v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lutz_C/0/1/0/all/0/1">Carsten Lutz</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulze_L/0/1/0/all/0/1">Lukas Schulze</a></p>
<p>Ontologies often require knowledge representation on multiple levels of
abstraction, but description logics (DLs) are not well-equipped for supporting
this. We propose an extension of DLs in which abstraction levels are
first-class citizens and which provides explicit operators for the abstraction
and refinement of concepts and roles across multiple abstraction levels, based
on conjunctive queries. We prove that reasoning in the resulting family of DLs
is decidable while several seemingly harmless variations turn out to be
undecidable. We also pinpoint the precise complexity of our logics and several
relevant fragments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04026">Value Functions are Control Barrier Functions: Verification of Safe Policies using Control Theory. (arXiv:2306.04026v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_D/0/1/0/all/0/1">Daniel C.H. Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Acero_F/0/1/0/all/0/1">Fernando Acero</a>, <a href="http://arxiv.org/find/cs/1/au:+McCarthy_R/0/1/0/all/0/1">Robert McCarthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanoulas_D/0/1/0/all/0/1">Dimitrios Kanoulas</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhibin Li</a></p>
<p>Guaranteeing safe behaviour of reinforcement learning (RL) policies poses
significant challenges for safety-critical applications, despite RL's
generality and scalability. To address this, we propose a new approach to apply
verification methods from control theory to learned value functions. By
analyzing task structures for safety preservation, we formalize original
theorems that establish links between value functions and control barrier
functions. Further, we propose novel metrics for verifying value functions in
safe control tasks and practical implementation details to improve learning.
Our work presents a novel method for certificate learning, which unlocks a
diversity of verification techniques from control theory for RL policies, and
marks a significant step towards a formal framework for the general, scalable,
and verifiable design of RL-based control systems. Code and videos are
available at this https url: https://rl-cbf.github.io/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05685">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lianmin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_W/0/1/0/all/0/1">Wei-Lin Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Y/0/1/0/all/0/1">Ying Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_S/0/1/0/all/0/1">Siyuan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhanghao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yonghao Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhuohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dacheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric. P Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a></p>
<p>Evaluating large language model (LLM) based chat assistants is challenging
due to their broad capabilities and the inadequacy of existing benchmarks in
measuring human preferences. To address this, we explore using strong LLMs as
judges to evaluate these models on more open-ended questions. We examine the
usage and limitations of LLM-as-a-judge, including position, verbosity, and
self-enhancement biases, as well as limited reasoning ability, and propose
solutions to mitigate some of them. We then verify the agreement between LLM
judges and human preferences by introducing two benchmarks: MT-bench, a
multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our
results reveal that strong LLM judges like GPT-4 can match both controlled and
crowdsourced human preferences well, achieving over 80\% agreement, the same
level of agreement between humans. Hence, LLM-as-a-judge is a scalable and
explainable way to approximate human preferences, which are otherwise very
expensive to obtain. Additionally, we show our benchmark and traditional
benchmarks complement each other by evaluating several variants of LLaMA and
Vicuna. We will publicly release MT-bench questions, 3K expert votes, and 30K
conversations with human preferences from Chatbot Arena.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07310">Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher Education. (arXiv:2306.07310v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyberatos_V/0/1/0/all/0/1">Vassilis Lyberatos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kantarelis_S/0/1/0/all/0/1">Spyridon Kantarelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaldeli_E/0/1/0/all/0/1">Eirini Kaldeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bekiaris_S/0/1/0/all/0/1">Spyros Bekiaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzortzis_P/0/1/0/all/0/1">Panagiotis Tzortzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mastromichalakis_O/0/1/0/all/0/1">Orfeas Menis - Mastromichalakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamou_G/0/1/0/all/0/1">Giorgos Stamou</a></p>
<p>This paper describes the methodology followed and the lessons learned from
employing crowdsourcing techniques as part of a homework assignment involving
higher education students of computer science. Making use of a platform that
supports crowdsourcing in the cultural heritage domain students were solicited
to enrich the metadata associated with a selection of music tracks. The results
of the campaign were further analyzed and exploited by students through the use
of semantic web technologies. In total, 98 students participated in the
campaign, contributing more than 6400 annotations concerning 854 tracks. The
process also led to the creation of an openly available annotated dataset,
which can be useful for machine learning models for music tagging. The
campaign's results and the comments gathered through an online survey enable us
to draw some useful insights about the benefits and challenges of integrating
crowdsourcing into computer science curricula and how this can enhance
students' engagement in the learning process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.08810">Deep Generative Models for Decision-Making and Control. (arXiv:2306.08810v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1">Michael Janner</a></p>
<p>Deep model-based reinforcement learning methods offer a conceptually simple
approach to the decision-making and control problem: use learning for the
purpose of estimating an approximate dynamics model, and offload the rest of
the work to classical trajectory optimization. However, this combination has a
number of empirical shortcomings, limiting the usefulness of model-based
methods in practice. The dual purpose of this thesis is to study the reasons
for these shortcomings and to propose solutions for the uncovered problems.
Along the way, we highlight how inference techniques from the contemporary
generative modeling toolbox, including beam search, classifier-guided sampling,
and image inpainting, can be reinterpreted as viable planning strategies for
reinforcement learning problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10548">MARBLE: Music Audio Representation Benchmark for Universal Evaluation. (arXiv:2306.10548v3 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1">Ruibin Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yinghao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yizhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Ge Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hanzhi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_L/0/1/0/all/0/1">Le Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yiqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiawen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zeyue Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Binyue Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Ningzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chenghua Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1">Emmanouil Benetos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragni_A/0/1/0/all/0/1">Anton Ragni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gyenge_N/0/1/0/all/0/1">Norbert Gyenge</a>, <a href="http://arxiv.org/find/cs/1/au:+Dannenberg_R/0/1/0/all/0/1">Roger Dannenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1">Gus Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wei Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Si Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruibo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jie Fu</a></p>
<p>In the era of extensive intersection between art and Artificial Intelligence
(AI), such as image generation and fiction co-creation, AI for music remains
relatively nascent, particularly in music understanding. This is evident in the
limited work on deep music representations, the scarcity of large-scale
datasets, and the absence of a universal and community-driven benchmark. To
address this issue, we introduce the Music Audio Representation Benchmark for
universaL Evaluation, termed MARBLE. It aims to provide a benchmark for various
Music Information Retrieval (MIR) tasks by defining a comprehensive taxonomy
with four hierarchy levels, including acoustic, performance, score, and
high-level description. We then establish a unified protocol based on 14 tasks
on 8 public-available datasets, providing a fair and standard assessment of
representations of all open-sourced pre-trained models developed on music
recordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, and
reproducible suite for the community, with a clear statement on copyright
issues on datasets. Results suggest recently proposed large-scale pre-trained
musical language models perform the best in most tasks, with room for further
improvement. The leaderboard and toolkit repository are published at
https://marble-bm.shef.ac.uk to promote future music AI research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11941">Efficient Dynamics Modeling in Interactive Environments with Koopman Theory. (arXiv:2306.11941v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1">Arnab Kumar Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Panigrahi_S/0/1/0/all/0/1">Siba Smarak Panigrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajeswar_S/0/1/0/all/0/1">Sai Rajeswar</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddiqi_K/0/1/0/all/0/1">Kaleem Siddiqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravanbakhsh_S/0/1/0/all/0/1">Siamak Ravanbakhsh</a></p>
<p>The accurate modeling of dynamics in interactive environments is critical for
successful long-range prediction. Such a capability could advance Reinforcement
Learning (RL) and Planning algorithms, but achieving it is challenging.
Inaccuracies in model estimates can compound, resulting in increased errors
over long horizons. We approach this problem from the lens of Koopman theory,
where the nonlinear dynamics of the environment can be linearized in a
high-dimensional latent space. This allows us to efficiently parallelize the
sequential problem of long-range prediction using convolution, while accounting
for the agent's action at every time step. Our approach also enables stability
analysis and better control over gradients through time. Taken together, these
advantages result in significant improvement over the existing approaches, both
in the efficiency and the accuracy of modeling dynamics over extended horizons.
We also report promising experimental results in dynamics modeling for the
scenarios of both model-based planning and model-free RL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12001">An Overview of Catastrophic AI Risks. (arXiv:2306.12001v3 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1">Mantas Mazeika</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodside_T/0/1/0/all/0/1">Thomas Woodside</a></p>
<p>Rapid advancements in artificial intelligence (AI) have sparked growing
concerns among experts, policymakers, and world leaders regarding the potential
for increasingly advanced AI systems to pose catastrophic risks. Although
numerous risks have been detailed separately, there is a pressing need for a
systematic discussion and illustration of the potential dangers to better
inform efforts to mitigate them. This paper provides an overview of the main
sources of catastrophic AI risks, which we organize into four categories:
malicious use, in which individuals or groups intentionally use AIs to cause
harm; AI race, in which competitive environments compel actors to deploy unsafe
AIs or cede control to AIs; organizational risks, highlighting how human
factors and complex systems can increase the chances of catastrophic accidents;
and rogue AIs, describing the inherent difficulty in controlling agents far
more intelligent than humans. For each category of risk, we describe specific
hazards, present illustrative stories, envision ideal scenarios, and propose
practical suggestions for mitigating these dangers. Our goal is to foster a
comprehensive understanding of these risks and inspire collective and proactive
efforts to ensure that AIs are developed and deployed in a safe manner.
Ultimately, we hope this will allow us to realize the benefits of this powerful
technology while minimizing the potential for catastrophic outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15724">REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction. (arXiv:2306.15724v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zeyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahety_A/0/1/0/all/0/1">Arpit Bahety</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuran Song</a></p>
<p>The ability to detect and analyze failed executions automatically is crucial
for an explainable and robust robotic system. Recently, Large Language Models
(LLMs) have demonstrated strong reasoning abilities on textual inputs. To
leverage the power of LLM for robot failure explanation, we introduce a
framework REFLECT, which queries LLM to identify and explain robot failures
given a hierarchical summary of robot past experiences generated from
multi-sensory data. Conditioned on the explanation, a task planner will
generate an executable plan for the robot to correct the failure and complete
the task. To systematically evaluate the framework, we create the RoboFail
dataset with a variety of tasks and failure scenarios. We demonstrate that the
LLM-based framework is able to generate informative failure explanations that
assist successful correction planning. Videos and code available at:
https://roboreflect.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15951">Reduce Computational Complexity for Convolutional Layers by Skipping Zeros. (arXiv:2306.15951v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengfei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhuopin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qi Wang</a></p>
<p>Deep neural networks rely on parallel processors for acceleration. To design
operators for them, it requires not only good algorithm to reduce complexity,
but also sufficient utilization of hardwares. Convolutional layers mainly
contain 3 kinds of operators: convolution in forward propagation, deconvolution
and dilated-convolution in backward propagation. When executing these
operators, 0s are always added to tensors, causing redundant calculations. This
paper gives C-K-S algorithm (ConvV2, KS-deconv, Sk-dilated), which skips these
0s in two ways: trim the filters to exclude padded 0s; transform sparse tensors
to dense tensors, to avoid inserted 0s in deconvolution and
dilated-convolution. In contrast to regular convolution, deconvolution is hard
to accelerate due to its complicacy. This paper provides high-performance GPU
implementations of C-K-S, and verifies their effectiveness with comparison to
PyTorch. According to the experiments, C-K-S has advantages over PyTorch in
certain cases, especially in deconvolution on small feature-maps. Further
enhancement of C-K-S can be done by making full optimizations oriented at
specific GPU architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00470">PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Le Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_X/0/1/0/all/0/1">Xin Shan</a></p>
<p>Large language models(LLMS) have shown excellent text generation
capabilities,capable of generating fluent responses for many downstream tasks.
However,applying large language models to real-world critical tasks remains
challenging due to their susceptibility to hallucinations and inability to
directly use external knowledge. To address the above challenges,this paper
proposes PatternGPT, a pattern-driven text generation framework for large
language models. First,the framework utilizes the extraction capabilities of
large language models to generate rich and diverse patterns and later draws on
the idea of federated learning. Using multiple agents to achieve sharing to
obtain more diverse patterns. Finally, it searches for high-quality patterns
using judgment criteria and optimization algorithms and uses the searched
patterns to guide the model for generation. This framework has the advantages
of generating diversified patterns, protecting data privacy,combining external
knowledge, and improving the quality of generation, which provides an effective
method to optimize the text generation capability of large language models,and
make it better applied to the field of intelligent dialogue and content
generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01227">ESGCN: Edge Squeeze Attention Graph Convolutional Network for Traffic Flow Forecasting. (arXiv:2307.01227v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangrok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Ha Young Kim</a></p>
<p>Traffic forecasting is a highly challenging task owing to the dynamical
spatio-temporal dependencies of traffic flows. To handle this, we focus on
modeling the spatio-temporal dynamics and propose a network termed Edge Squeeze
Graph Convolutional Network (ESGCN) to forecast traffic flow in multiple
regions. ESGCN consists of two modules: W-module and ES module. W-module is a
fully node-wise convolutional network. It encodes the time-series of each
traffic region separately and decomposes the time-series at various scales to
capture fine and coarse features. The ES module models the spatio-temporal
dynamics using Graph Convolutional Network (GCN) and generates an Adaptive
Adjacency Matrix (AAM) with temporal features. To improve the accuracy of AAM,
we introduce three key concepts. 1) Using edge features to directly capture the
spatiotemporal flow representation among regions. 2) Applying an edge attention
mechanism to GCN to extract the AAM from the edge features. Here, the attention
mechanism can effectively determine important spatio-temporal adjacency
relations. 3) Proposing a novel node contrastive loss to suppress obstructed
connections and emphasize related connections. Experimental results show that
ESGCN achieves state-of-the-art performance by a large margin on four
real-world datasets (PEMS03, 04, 07, and 08) with a low computational cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01719">MOPO-LSI: A User Guide. (arXiv:2307.01719v2 [q-fin.PM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Zheng_Y/0/1/0/all/0/1">Yong Zheng</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Shukla_K/0/1/0/all/0/1">Kumar Neelotpal Shukla</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Xu_J/0/1/0/all/0/1">Jasmine Xu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+David/0/1/0/all/0/1">David</a> (Xuejun) <a href="http://arxiv.org/find/q-fin/1/au:+Wang/0/1/0/all/0/1">Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+OLeary_M/0/1/0/all/0/1">Michael O&#x27;Leary</a></p>
<p>MOPO-LSI is an open-source Multi-Objective Portfolio Optimization Library for
Sustainable Investments. This document provides a user guide for MOPO-LSI
version 1.0, including problem setup, workflow and the hyper-parameters in
configurations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03109">A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yupeng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1">Kaijie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Linyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xiaoyuan Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cunxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1">Wei Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where' and `how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03718">Frontier AI Regulation: Managing Emerging Risks to Public Safety. (arXiv:2307.03718v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anderljung_M/0/1/0/all/0/1">Markus Anderljung</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnhart_J/0/1/0/all/0/1">Joslyn Barnhart</a>, <a href="http://arxiv.org/find/cs/1/au:+Korinek_A/0/1/0/all/0/1">Anton Korinek</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_J/0/1/0/all/0/1">Jade Leung</a>, <a href="http://arxiv.org/find/cs/1/au:+OKeefe_C/0/1/0/all/0/1">Cullen O&#x27;Keefe</a>, <a href="http://arxiv.org/find/cs/1/au:+Whittlestone_J/0/1/0/all/0/1">Jess Whittlestone</a>, <a href="http://arxiv.org/find/cs/1/au:+Avin_S/0/1/0/all/0/1">Shahar Avin</a>, <a href="http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1">Miles Brundage</a>, <a href="http://arxiv.org/find/cs/1/au:+Bullock_J/0/1/0/all/0/1">Justin Bullock</a>, <a href="http://arxiv.org/find/cs/1/au:+Cass_Beggs_D/0/1/0/all/0/1">Duncan Cass-Beggs</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Ben Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Collins_T/0/1/0/all/0/1">Tantum Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Fist_T/0/1/0/all/0/1">Tim Fist</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_G/0/1/0/all/0/1">Gillian Hadfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayes_A/0/1/0/all/0/1">Alan Hayes</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_L/0/1/0/all/0/1">Lewis Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>, <a href="http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1">Eric Horvitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolt_N/0/1/0/all/0/1">Noam Kolt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuett_J/0/1/0/all/0/1">Jonas Schuett</a>, <a href="http://arxiv.org/find/cs/1/au:+Shavit_Y/0/1/0/all/0/1">Yonadav Shavit</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddarth_D/0/1/0/all/0/1">Divya Siddarth</a>, <a href="http://arxiv.org/find/cs/1/au:+Trager_R/0/1/0/all/0/1">Robert Trager</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_K/0/1/0/all/0/1">Kevin Wolf</a></p>
<p>Advanced AI models hold the promise of tremendous benefits for humanity, but
society needs to proactively manage the accompanying risks. In this paper, we
focus on what we term "frontier AI" models: highly capable foundation models
that could possess dangerous capabilities sufficient to pose severe risks to
public safety. Frontier AI models pose a distinct regulatory challenge:
dangerous capabilities can arise unexpectedly; it is difficult to robustly
prevent a deployed model from being misused; and, it is difficult to stop a
model's capabilities from proliferating broadly. To address these challenges,
at least three building blocks for the regulation of frontier models are
needed: (1) standard-setting processes to identify appropriate requirements for
frontier AI developers, (2) registration and reporting requirements to provide
regulators with visibility into frontier AI development processes, and (3)
mechanisms to ensure compliance with safety standards for the development and
deployment of frontier AI models. Industry self-regulation is an important
first step. However, wider societal discussions and government intervention
will be needed to create standards and to ensure compliance with them. We
consider several options to this end, including granting enforcement powers to
supervisory authorities and licensure regimes for frontier AI models. Finally,
we propose an initial set of safety standards. These include conducting
pre-deployment risk assessments; external scrutiny of model behavior; using
risk assessments to inform deployment decisions; and monitoring and responding
to new information about model capabilities and uses post-deployment. We hope
this discussion contributes to the broader conversation on how to balance
public safety risks and innovation benefits from advances at the frontier of AI
development.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04132">Reasoning over the Behaviour of Objects in Video-Clips for Adverb-Type Recognition. (arXiv:2307.04132v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seshadri_A/0/1/0/all/0/1">Amrit Diggavi Seshadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1">Alessandra Russo</a></p>
<p>In this work, following the intuition that adverbs describing scene-sequences
are best identified by reasoning over high-level concepts of object-behavior,
we propose the design of a new framework that reasons over object-behaviours
extracted from raw-video-clips to recognize the clip's corresponding
adverb-types. Importantly, while previous works for general scene
adverb-recognition assume knowledge of the clips underlying action-types, our
method is directly applicable in the more general problem setting where the
action-type of a video-clip is unknown. Specifically, we propose a novel
pipeline that extracts human-interpretable object-behaviour-facts from raw
video clips and propose novel symbolic and transformer based reasoning methods
that operate over these extracted facts to identify adverb-types. Experiment
results demonstrate that our proposed methods perform favourably against the
previous state-of-the-art. Additionally, to support efforts in symbolic
video-processing, we release two new datasets of object-behaviour-facts
extracted from raw video clips - the MSR-VTT-ASP and ActivityNet-ASP datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04149">Latent Graph Attention for Enhanced Spatial Context. (arXiv:2307.04149v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Ayush Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhambhu_Y/0/1/0/all/0/1">Yash Bhambhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckchash_H/0/1/0/all/0/1">Himanshu Buckchash</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1">Deepak K. Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_D/0/1/0/all/0/1">Dilip K. Prasad</a></p>
<p>Global contexts in images are quite valuable in image-to-image translation
problems. Conventional attention-based and graph-based models capture the
global context to a large extent, however, these are computationally expensive.
Moreover, the existing approaches are limited to only learning the pairwise
semantic relation between any two points on the image. In this paper, we
present Latent Graph Attention (LGA) a computationally inexpensive (linear to
the number of nodes) and stable, modular framework for incorporating the global
context in the existing architectures, especially empowering small-scale
architectures to give performance closer to large size architectures, thus
making the light-weight architectures more useful for edge devices with lower
compute power and lower energy needs. LGA propagates information spatially
using a network of locally connected graphs, thereby facilitating to construct
a semantically coherent relation between any two spatially distant points that
also takes into account the influence of the intermediate pixels. Moreover, the
depth of the graph network can be used to adapt the extent of contextual spread
to the target dataset, thereby being able to explicitly control the added
computational cost. To enhance the learning mechanism of LGA, we also introduce
a novel contrastive loss term that helps our LGA module to couple well with the
original architecture at the expense of minimal additional computational load.
We show that incorporating LGA improves the performance on three challenging
applications, namely transparent object segmentation, image restoration for
dehazing and optical flow estimation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04195">Natural Language Instructions for Intuitive Human Interaction with Robotic Assistants in Field Construction Work. (arXiv:2307.04195v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Somin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Menassa_C/0/1/0/all/0/1">Carol C. Menassa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamat_V/0/1/0/all/0/1">Vineet R. Kamat</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1">Joyce Y. Chai</a></p>
<p>The introduction of robots is widely considered to have significant potential
of alleviating the issues of worker shortage and stagnant productivity that
afflict the construction industry. However, it is challenging to use fully
automated robots in complex and unstructured construction sites. Human-Robot
Collaboration (HRC) has shown promise of combining human workers' flexibility
and robot assistants' physical abilities to jointly address the uncertainties
inherent in construction work. When introducing HRC in construction, it is
critical to recognize the importance of teamwork and supervision in field
construction and establish a natural and intuitive communication system for the
human workers and robotic assistants. Natural language-based interaction can
enable intuitive and familiar communication with robots for human workers who
are non-experts in robot programming. However, limited research has been
conducted on this topic in construction. This paper proposes a framework to
allow human workers to interact with construction robots based on natural
language instructions. The proposed method consists of three stages: Natural
Language Understanding (NLU), Information Mapping (IM), and Robot Control (RC).
Natural language instructions are input to a language model to predict a tag
for each word in the NLU module. The IM module uses the result of the NLU
module and building component information to generate the final instructional
output essential for a robot to acknowledge and perform the construction task.
A case study for drywall installation is conducted to evaluate the proposed
approach. The obtained results highlight the potential of using natural
language-based interaction to replicate the communication that occurs between
human workers within the context of human-robot teams.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04617">Weakly-supervised positional contrastive learning: application to cirrhosis classification. (arXiv:2307.04617v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarfati_E/0/1/0/all/0/1">Emma Sarfati</a>, <a href="http://arxiv.org/find/cs/1/au:+Bone_A/0/1/0/all/0/1">Alexandre B&#xf4;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohe_M/0/1/0/all/0/1">Marc-Michel Roh&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a></p>
<p>Large medical imaging datasets can be cheaply and quickly annotated with
low-confidence, weak labels (e.g., radiological scores). Access to
high-confidence labels, such as histology-based diagnoses, is rare and costly.
Pretraining strategies, like contrastive learning (CL) methods, can leverage
unlabeled or weakly-annotated datasets. These methods typically require large
batch sizes, which poses a difficulty in the case of large 3D images at full
resolution, due to limited GPU memory. Nevertheless, volumetric positional
information about the spatial context of each 2D slice can be very important
for some medical applications. In this work, we propose an efficient
weakly-supervised positional (WSP) contrastive learning strategy where we
integrate both the spatial context of each 2D slice and a weak label via a
generic kernel-based loss function. We illustrate our method on cirrhosis
prediction using a large volume of weakly-labeled images, namely radiological
low-confidence annotations, and small strongly-labeled (i.e., high-confidence)
datasets. The proposed model improves the classification AUC by 5% with respect
to a baseline model on our internal dataset, and by 26% on the public LIHC
dataset from the Cancer Genome Atlas. The code is available at:
https://github.com/Guerbet-AI/wsp-contrastive.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04686">VampNet: Music Generation via Masked Acoustic Token Modeling. (arXiv:2307.04686v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garcia_H/0/1/0/all/0/1">Hugo Flores Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Seetharaman_P/0/1/0/all/0/1">Prem Seetharaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Rithesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pardo_B/0/1/0/all/0/1">Bryan Pardo</a></p>
<p>We introduce VampNet, a masked acoustic token modeling approach to music
synthesis, compression, inpainting, and variation. We use a variable masking
schedule during training which allows us to sample coherent music from the
model by applying a variety of masking approaches (called prompts) during
inference. VampNet is non-autoregressive, leveraging a bidirectional
transformer architecture that attends to all tokens in a forward pass. With
just 36 sampling passes, VampNet can generate coherent high-fidelity musical
waveforms. We show that by prompting VampNet in various ways, we can apply it
to tasks like music compression, inpainting, outpainting, continuation, and
looping with variation (vamping). Appropriately prompted, VampNet is capable of
maintaining style, genre, instrumentation, and other high-level aspects of the
music. This flexible prompting capability makes VampNet a powerful music
co-creation tool. Code and audio samples are available online.
</p>
</p>
</div>

    </div>
    </body>
    