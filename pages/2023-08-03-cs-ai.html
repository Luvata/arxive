<!DOCTYPE html>
<html>
<head>
<title>2023-08-03-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2308.00705">A Bibliographic Study on Artificial Intelligence Research: Global Panorama and Indian Appearance. (arXiv:2308.00705v1 [cs.DL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1">Amit Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Bardhan_S/0/1/0/all/0/1">Susmita Bardhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vikas Kumar</a></p>
<p>The present study identifies and assesses the bibliographic trend in
Artificial Intelligence (AI) research for the years 2015-2020 using the science
mapping method of bibliometric study. The required data has been collected from
the Scopus database. To make the collected data analysis-ready, essential data
transformation was performed manually and with the help of a tool viz.
OpenRefine. For determining the trend and performing the mapping techniques,
top five open access and commercial journals of AI have been chosen based on
their citescore driven ranking. The work includes 6880 articles published in
the specified period for analysis. The trend is based on Country-wise
publications, year-wise publications, topical terms in AI, top-cited articles,
prominent authors, major institutions, involvement of industries in AI and
Indian appearance. The results show that compared to open access journals;
commercial journals have a higher citescore and number of articles published
over the years. Additionally, IEEE is the prominent publisher which publishes
84% of the top-cited publications. Further, China and the United States are the
major contributors to literature in the AI domain. The study reveals that
neural networks and deep learning are the major topics included in top AI
research publications. Recently, not only public institutions but also private
bodies are investing their resources in AI research. The study also
investigates the relative position of Indian researchers in terms of AI
research. Present work helps in understanding the initial development, current
stand and future direction of AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00707">Approximate Model-Based Shielding for Safe Reinforcement Learning. (arXiv:2308.00707v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goodall_A/0/1/0/all/0/1">Alexander W. Goodall</a>, <a href="http://arxiv.org/find/cs/1/au:+Belardinelli_F/0/1/0/all/0/1">Francesco Belardinelli</a></p>
<p>Reinforcement learning (RL) has shown great potential for solving complex
tasks in a variety of domains. However, applying RL to safety-critical systems
in the real-world is not easy as many algorithms are sample-inefficient and
maximising the standard RL objective comes with no guarantees on worst-case
performance. In this paper we propose approximate model-based shielding (AMBS),
a principled look-ahead shielding algorithm for verifying the performance of
learned RL policies w.r.t. a set of given safety constraints. Our algorithm
differs from other shielding approaches in that it does not require prior
knowledge of the safety-relevant dynamics of the system. We provide a strong
theoretical justification for AMBS and demonstrate superior performance to
other safety-aware approaches on a set of Atari games with state-dependent
safety-labels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00710">Towards the Visualization of Aggregated Class Activation Maps to Analyse the Global Contribution of Class Features. (arXiv:2308.00710v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cherepanov_I/0/1/0/all/0/1">Igor Cherepanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sessler_D/0/1/0/all/0/1">David Sessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulmer_A/0/1/0/all/0/1">Alex Ulmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucke_Tieke_H/0/1/0/all/0/1">Hendrik L&#xfc;cke-Tieke</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohlhammer_J/0/1/0/all/0/1">J&#xf6;rn Kohlhammer</a></p>
<p>Deep learning (DL) models achieve remarkable performance in classification
tasks. However, models with high complexity can not be used in many
risk-sensitive applications unless a comprehensible explanation is presented.
Explainable artificial intelligence (xAI) focuses on the research to explain
the decision-making of AI systems like DL. We extend a recent method of Class
Activation Maps (CAMs) which visualizes the importance of each feature of a
data sample contributing to the classification. In this paper, we aggregate
CAMs from multiple samples to show a global explanation of the classification
for semantically structured data. The aggregation allows the analyst to make
sophisticated assumptions and analyze them with further drill-down
visualizations. Our visual representation for the global CAM illustrates the
impact of each feature with a square glyph containing two indicators. The color
of the square indicates the classification impact of this feature. The size of
the filled square describes the variability of the impact between single
samples. For interesting features that require further analysis, a detailed
view is necessary that provides the distribution of these values. We propose an
interactive histogram to filter samples and refine the CAM to show relevant
samples only. Our approach allows an analyst to detect important features of
high-dimensional data and derive adjustments to the AI model based on our
global explanation visualization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00721">A Pre-trained Data Deduplication Model based on Active Learning. (arXiv:2308.00721v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xinyao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Shengdong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1">Fengmao Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Hongtao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianrui Li</a></p>
<p>In the era of big data, the issue of data quality has become increasingly
prominent. One of the main challenges is the problem of duplicate data, which
can arise from repeated entry or the merging of multiple data sources. These
"dirty data" problems can significantly limit the effective application of big
data. To address the issue of data deduplication, we propose a pre-trained
deduplication model based on active learning, which is the first work that
utilizes active learning to address the problem of deduplication at the
semantic level. The model is built on a pre-trained Transformer and fine-tuned
to solve the deduplication problem as a sequence to classification task, which
firstly integrate the transformer with active learning into an end-to-end
architecture to select the most valuable data for deduplication model training,
and also firstly employ the R-Drop method to perform data augmentation on each
round of labeled data, which can reduce the cost of manual labeling and improve
the model's performance. Experimental results demonstrate that our proposed
model outperforms previous state-of-the-art (SOTA) for deduplicated data
identification, achieving up to a 28% improvement in Recall score on benchmark
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00735">A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem. (arXiv:2308.00735v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moreno_M/0/1/0/all/0/1">Marcio Ferreira Moreno</a>, <a href="http://arxiv.org/find/cs/1/au:+Brandao_R/0/1/0/all/0/1">Rafael Rossi de Mello Brand&#xe3;o</a></p>
<p>The Polkadot ecosystem is a disruptive and highly complex multi-chain
architecture that poses challenges in terms of data analysis and
communicability. Currently, there is a lack of standardized and holistic
approaches to retrieve and analyze data across parachains and applications,
making it difficult for general users and developers to access ecosystem data
consistently. This paper proposes a conceptual framework that includes a domain
ontology called POnto (a Polkadot Ontology) to address these challenges. POnto
provides a structured representation of the ecosystem's concepts and
relationships, enabling a formal understanding of the platform. The proposed
knowledge-oriented approach enhances integration and communicability, enabling
a wider range of users to participate in the ecosystem and facilitating the
development of AI-based applications. The paper presents a case study
methodology to validate the proposed framework, which includes expert feedback
and insights from the Polkadot community. The POnto ontology and the roadmap
for a query engine based on a Controlled Natural Language using the ontology,
provide valuable contributions to the growth and adoption of the Polkadot
ecosystem in heterogeneous socio-technical environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00801">Artificial Eye for the Blind. (arXiv:2308.00801v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Benagi_A/0/1/0/all/0/1">Abhinav Benagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayan_D/0/1/0/all/0/1">Dhanyatha Narayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rage_C/0/1/0/all/0/1">Charith Rage</a>, <a href="http://arxiv.org/find/cs/1/au:+Sushmitha_A/0/1/0/all/0/1">A Sushmitha</a></p>
<p>The main backbone of our Artificial Eye model is the Raspberry pi3 which is
connected to the webcam ,ultrasonic proximity sensor, speaker and we also run
all our software models i.e object detection, Optical Character recognition,
google text to speech conversion and the Mycroft voice assistance model. At
first the ultrasonic proximity sensor will be measuring the distance between
itself and any obstacle in front of it .When the Proximity sensor detects any
obstacle in front within its specified range, the blind person will hear an
audio prompt about an obstacle in his way at a certain distance. At this time
the Webcam will capture an image in front of it and the Object detection model
and the Optical Character Recognition model will begin to run on the Raspberry
pi. The imat of the blind person. The text and the object detected are conveyed
to the blind pege captured is first sent through the Tesseract OCR module to
detect any texts in the image and then through the Object detection model to
detect the objects in fronrson by converting the texts to speech by using the
gTTS module. Along with the above mentioned process going on there will be an
active MYCROFT voice assistant model which can be used to interact with the
blind person. The blind person can ask about the weather , daily news , any
information on the internet ,etc
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00813">Designing a Communication Bridge between Communities: Participatory Design for a Question-Answering AI Agent. (arXiv:2308.00813v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jeonghyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nandan_V/0/1/0/all/0/1">Vrinda Nandan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sikka_H/0/1/0/all/0/1">Harshvardhan Sikka</a>, <a href="http://arxiv.org/find/cs/1/au:+Rugaber_S/0/1/0/all/0/1">Spencer Rugaber</a>, <a href="http://arxiv.org/find/cs/1/au:+Gole_A/0/1/0/all/0/1">Ashok Gole</a></p>
<p>How do we design an AI system that is intended to act as a communication
bridge between two user communities with different mental models and
vocabularies? Skillsync is an interactive environment that engages employers
(companies) and training providers (colleges) in a sustained dialogue to help
them achieve the goal of building a training proposal that successfully meets
the needs of the employers and employees. We used a variation of participatory
design to elicit requirements for developing AskJill, a question-answering
agent that explains how Skillsync works and thus acts as a communication bridge
between company and college users. Our study finds that participatory design
was useful in guiding the requirements gathering and eliciting user questions
for the development of AskJill. Our results also suggest that the two Skillsync
user communities perceived glossary assistance as a key feature that AskJill
needs to offer, and they would benefit from such a shared vocabulary.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00854">Training on Foveated Images Improves Robustness to Adversarial Attacks. (arXiv:2308.00854v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Muhammad A. Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1">Bhiksha Raj</a></p>
<p>Deep neural networks (DNNs) have been shown to be vulnerable to adversarial
attacks -- subtle, perceptually indistinguishable perturbations of inputs that
change the response of the model. In the context of vision, we hypothesize that
an important contributor to the robustness of human visual perception is
constant exposure to low-fidelity visual stimuli in our peripheral vision. To
investigate this hypothesis, we develop \RBlur, an image transform that
simulates the loss in fidelity of peripheral vision by blurring the image and
reducing its color saturation based on the distance from a given fixation
point. We show that compared to DNNs trained on the original images, DNNs
trained on images transformed by \RBlur are substantially more robust to
adversarial attacks, as well as other, non-adversarial, corruptions, achieving
up to 25\% higher accuracy on perturbed data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00858">Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes. (arXiv:2308.00858v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lehmler_S/0/1/0/all/0/1">Stephan Johann Lehmler</a>, <a href="http://arxiv.org/find/cs/1/au:+Saif_ur_Rehman_M/0/1/0/all/0/1">Muhammad Saif-ur-Rehman</a>, <a href="http://arxiv.org/find/cs/1/au:+Glasmachers_T/0/1/0/all/0/1">Tobias Glasmachers</a>, <a href="http://arxiv.org/find/cs/1/au:+Iossifidis_I/0/1/0/all/0/1">Ioannis Iossifidis</a></p>
<p>To gain a deeper understanding of the behavior and learning dynamics of
(deep) artificial neural networks, it is valuable to employ mathematical
abstractions and models. These tools provide a simplified perspective on
network performance and facilitate systematic investigations through
simulations. In this paper, we propose utilizing the framework of stochastic
processes, which has been underutilized thus far.
</p>
<p>Our approach models activation patterns of thresholded nodes in (deep)
artificial neural networks as stochastic processes. We focus solely on
activation frequency, leveraging neuroscience techniques used for real neuron
spike trains. During a classification task, we extract spiking activity and use
an arrival process following the Poisson distribution.
</p>
<p>We examine observed data from various artificial neural networks in image
recognition tasks, fitting the proposed model's assumptions. Through this, we
derive parameters describing activation patterns in each network. Our analysis
covers randomly initialized, generalizing, and memorizing networks, revealing
consistent differences across architectures and training sets.
</p>
<p>Calculating Mean Firing Rate, Mean Fano Factor, and Variances, we find stable
indicators of memorization during learning, providing valuable insights into
network behavior. The proposed model shows promise in describing activation
patterns and could serve as a general framework for future investigations. It
has potential applications in theoretical simulations, pruning, and transfer
learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00861">Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy. (arXiv:2308.00861v1 [math.CT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Tull_S/0/1/0/all/0/1">Sean Tull</a>, <a href="http://arxiv.org/find/math/1/au:+Kleiner_J/0/1/0/all/0/1">Johannes Kleiner</a>, <a href="http://arxiv.org/find/math/1/au:+Smithe_T/0/1/0/all/0/1">Toby St Clere Smithe</a></p>
<p>We present a categorical formulation of the cognitive frameworks of
Predictive Processing and Active Inference, expressed in terms of string
diagrams interpreted in a monoidal category with copying and discarding. This
includes diagrammatic accounts of generative models, Bayesian updating,
perception, planning, active inference, and free energy. In particular we
present a diagrammatic derivation of the formula for active inference via free
energy minimisation, and establish a compositionality property for free energy,
allowing free energy to be applied at all levels of an agent's generative
model. Aside from aiming to provide a helpful graphical language for those
familiar with active inference, we conversely hope that this article may
provide a concise formulation and introduction to the framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00864">PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems. (arXiv:2308.00864v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Aamir Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_N/0/1/0/all/0/1">Neeloy Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haonan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jung-Hoon Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cathy Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1">Katherine Driggs-Campbell</a></p>
<p>Intelligent driving systems can be used to mitigate congestion through simple
actions, thus improving many socioeconomic factors such as commute time and gas
costs. However, these systems assume precise control over autonomous vehicle
fleets, and are hence limited in practice as they fail to account for
uncertainty in human behavior. Piecewise Constant (PC) Policies address these
issues by structurally modeling the likeness of human driving to reduce traffic
congestion in dense scenarios to provide action advice to be followed by human
drivers. However, PC policies assume that all drivers behave similarly. To this
end, we develop a co-operative advisory system based on PC policies with a
novel driver trait conditioned Personalized Residual Policy, PeRP. PeRP advises
drivers to behave in ways that mitigate traffic congestion. We first infer the
driver's intrinsic traits on how they follow instructions in an unsupervised
manner with a variational autoencoder. Then, a policy conditioned on the
inferred trait adapts the action of the PC policy to provide the driver with a
personalized recommendation. Our system is trained in simulation with novel
driver modeling of instruction adherence. We show that our approach
successfully mitigates congestion while adapting to different driver behaviors,
with 4 to 22% improvement in average speed over baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00868">Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems. (arXiv:2308.00868v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+London_A/0/1/0/all/0/1">Alex John London</a>, <a href="http://arxiv.org/find/cs/1/au:+heidari_H/0/1/0/all/0/1">Hoda heidari</a></p>
<p>The prevailing discourse around AI ethics lacks the language and formalism
necessary to capture the diverse ethical concerns that emerge when AI systems
interact with individuals. Drawing on Sen and Nussbaum's capability approach,
we present a framework formalizing a network of ethical concepts and
entitlements necessary for AI systems to confer meaningful benefit or
assistance to stakeholders. Such systems enhance stakeholders' ability to
advance their life plans and well-being while upholding their fundamental
rights. We characterize two necessary conditions for morally permissible
interactions between AI systems and those impacted by their functioning, and
two sufficient conditions for realizing the ideal of meaningful benefit. We
then contrast this ideal with several salient failure modes, namely, forms of
social interactions that constitute unjustified paternalism, coercion,
deception, exploitation and domination. The proliferation of incidents
involving AI in high-stakes domains underscores the gravity of these issues and
the imperative to take an ethics-led approach to AI systems from their
inception.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00886">Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction. (arXiv:2308.00886v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Faremi_B/0/1/0/all/0/1">Boluwatife E. Faremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavres_J/0/1/0/all/0/1">Jonathon Stavres</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_N/0/1/0/all/0/1">Nuno Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhaoxian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_A/0/1/0/all/0/1">Andrew H. Sung</a></p>
<p>Machine learning (ML) models trained on subjective self-report scores
struggle to objectively classify pain accurately due to the significant
variance between real-time pain experiences and recorded scores afterwards.
This study developed two devices for acquisition of real-time, continuous
in-session pain scores and gathering of ANS-modulated endodermal activity
(EDA).The experiment recruited N = 24 subjects who underwent a post-exercise
circulatory occlusion (PECO) with stretch, inducing discomfort. Subject data
were stored in a custom pain platform, facilitating extraction of time-domain
EDA features and in-session ground truth scores. Moreover, post-experiment
visual analog scale (VAS) scores were collected from each subject. Machine
learning models, namely Multi-layer Perceptron (MLP) and Random Forest (RF),
were trained using corresponding objective EDA features combined with
in-session scores and post-session scores, respectively. Over a 10-fold
cross-validation, the macro-averaged geometric mean score revealed MLP and RF
models trained with objective EDA features and in-session scores achieved
superior performance (75.9% and 78.3%) compared to models trained with
post-session scores (70.3% and 74.6%) respectively. This pioneering study
demonstrates that using continuous in-session ground truth scores significantly
enhances ML performance in pain intensity characterization, overcoming ground
truth sparsity-related issues, data imbalance, and high variance. This study
informs future objective-based ML pain system training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00904">VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference. (arXiv:2308.00904v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yonghe Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Siwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huiyan Sun</a></p>
<p>Causal inference plays a vital role in diverse domains like epidemiology,
healthcare, and economics. De-confounding and counterfactual prediction in
observational data has emerged as a prominent concern in causal inference
research. While existing models tackle observed confounders, the presence of
unobserved confounders remains a significant challenge, distorting causal
inference and impacting counterfactual outcome accuracy. To address this, we
propose a novel variational learning model of unobserved confounders for
counterfactual inference (VLUCI), which generates the posterior distribution of
unobserved confounders. VLUCI relaxes the unconfoundedness assumption often
overlooked by most causal inference methods. By disentangling observed and
unobserved confounders, VLUCI constructs a doubly variational inference model
to approximate the distribution of unobserved confounders, which are used for
inferring more accurate counterfactual outcomes. Extensive experiments on
synthetic and semi-synthetic datasets demonstrate VLUCI's superior performance
in inferring unobserved confounders. It is compatible with state-of-the-art
counterfactual inference models, significantly improving inference accuracy at
both group and individual levels. Additionally, VLUCI provides confidence
intervals for counterfactual outcomes, aiding decision-making in risk-sensitive
domains. We further clarify the considerations when applying VLUCI to cases
where unobserved confounders don't strictly conform to our model assumptions
using the public IHDP dataset as an example, highlighting the practical
advantages of VLUCI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00927">Physics-informed neural networks for blood flow inverse problems. (arXiv:2308.00927v1 [cs.CE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garay_J/0/1/0/all/0/1">Jeremias Garay</a>, <a href="http://arxiv.org/find/cs/1/au:+Dunstan_J/0/1/0/all/0/1">Jocelyn Dunstan</a>, <a href="http://arxiv.org/find/cs/1/au:+Uribe_S/0/1/0/all/0/1">Sergio Uribe</a>, <a href="http://arxiv.org/find/cs/1/au:+Costabal_F/0/1/0/all/0/1">Francisco Sahli Costabal</a></p>
<p>Physics-informed neural networks (PINNs) have emerged as a powerful tool for
solving inverse problems, especially in cases where no complete information
about the system is known and scatter measurements are available. This is
especially useful in hemodynamics since the boundary information is often
difficult to model, and high-quality blood flow measurements are generally hard
to obtain. In this work, we use the PINNs methodology for estimating
reduced-order model parameters and the full velocity field from scatter 2D
noisy measurements in the ascending aorta. The results show stable and accurate
parameter estimations when using the method with simulated data, while the
velocity reconstruction shows dependence on the measurement quality and the
flow pattern complexity. The method allows for solving clinical-relevant
inverse problems in hemodynamics and complex coupled physical systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00936">Particle swarm optimization with state-based adaptive velocity limit strategy. (arXiv:2308.00936v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_K/0/1/0/all/0/1">Kezhi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fanfan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xin Zhang</a></p>
<p>Velocity limit (VL) has been widely adopted in many variants of particle
swarm optimization (PSO) to prevent particles from searching outside the
solution space. Several adaptive VL strategies have been introduced with which
the performance of PSO can be improved. However, the existing adaptive VL
strategies simply adjust their VL based on iterations, leading to
unsatisfactory optimization results because of the incompatibility between VL
and the current searching state of particles. To deal with this problem, a
novel PSO variant with state-based adaptive velocity limit strategy (PSO-SAVL)
is proposed. In the proposed PSO-SAVL, VL is adaptively adjusted based on the
evolutionary state estimation (ESE) in which a high value of VL is set for
global searching state and a low value of VL is set for local searching state.
Besides that, limit handling strategies have been modified and adopted to
improve the capability of avoiding local optima. The good performance of
PSO-SAVL has been experimentally validated on a wide range of benchmark
functions with 50 dimensions. The satisfactory scalability of PSO-SAVL in
high-dimension and large-scale problems is also verified. Besides, the merits
of the strategies in PSO-SAVL are verified in experiments. Sensitivity analysis
for the relevant hyper-parameters in state-based adaptive VL strategy is
conducted, and insights in how to select these hyper-parameters are also
discussed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00937">LEMMA: Learning Language-Conditioned Multi-Robot Manipulation. (arXiv:2308.00937v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ran Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiaofeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qiaozi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakiah_S/0/1/0/all/0/1">Suhaila Shakiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Thattai_G/0/1/0/all/0/1">Govind Thattai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1">Gaurav S. Sukhatme</a></p>
<p>Complex manipulation tasks often require robots with complementary
capabilities to collaborate. We introduce a benchmark for LanguagE-Conditioned
Multi-robot MAnipulation (LEMMA) focused on task allocation and long-horizon
object manipulation based on human language instructions in a tabletop setting.
LEMMA features 8 types of procedurally generated tasks with varying degree of
complexity, some of which require the robots to use tools and pass tools to
each other. For each task, we provide 800 expert demonstrations and human
instructions for training and evaluations. LEMMA poses greater challenges
compared to existing benchmarks, as it requires the system to identify each
manipulator's limitations and assign sub-tasks accordingly while also handling
strong temporal dependencies in each task. To address these challenges, we
propose a modular hierarchical planning approach as a baseline. Our results
highlight the potential of LEMMA for developing future language-conditioned
multi-robot systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00939">Feature-aware conditional GAN for category text generation. (arXiv:2308.00939v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_K/0/1/0/all/0/1">Kezhi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fanfan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zijian Feng</a></p>
<p>Category text generation receives considerable attentions since it is
beneficial for various natural language processing tasks. Recently, the
generative adversarial network (GAN) has attained promising performance in text
generation, attributed to its adversarial training process. However, there are
several issues in text GANs, including discreteness, training instability, mode
collapse, lack of diversity and controllability etc. To address these issues,
this paper proposes a novel GAN framework, the feature-aware conditional GAN
(FA-GAN), for controllable category text generation. In FA-GAN, the generator
has a sequence-to-sequence structure for improving sentence diversity, which
consists of three encoders including a special feature-aware encoder and a
category-aware encoder, and one relational-memory-core-based decoder with the
Gumbel SoftMax activation function. The discriminator has an additional
category classification head. To generate sentences with specified categories,
the multi-class classification loss is supplemented in the adversarial
training. Comprehensive experiments have been conducted, and the results show
that FA-GAN consistently outperforms 10 state-of-the-art text generation
approaches on 6 text classification datasets. The case study demonstrates that
the synthetic sentences generated by FA-GAN can match the required categories
and are aware of the features of conditioned sentences, with good readability,
fluency, and text authenticity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00946">Teaching Smaller Language Models To Generalise To Unseen Compositional Questions. (arXiv:2308.00946v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hartill_T/0/1/0/all/0/1">Tim Hartill</a>, <a href="http://arxiv.org/find/cs/1/au:+TAN_N/0/1/0/all/0/1">Neset TAN</a>, <a href="http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1">Michael Witbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Riddle_P/0/1/0/all/0/1">Patricia J. Riddle</a></p>
<p>We equip a smaller Language Model to generalise to answering challenging
compositional questions that have not been seen in training. To do so we
propose a combination of multitask supervised pretraining on up to 93 tasks
designed to instill diverse reasoning abilities, and a dense retrieval system
that aims to retrieve a set of evidential paragraph fragments. Recent progress
in question-answering has been achieved either through prompting methods
against very large pretrained Language Models in zero or few-shot fashion, or
by fine-tuning smaller models, sometimes in conjunction with information
retrieval. We focus on the less explored question of the extent to which
zero-shot generalisation can be enabled in smaller models with retrieval
against a corpus within which sufficient information to answer a particular
question may not exist. We establish strong baselines in this setting for
diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and
ARC-DA), and show that performance can be significantly improved by adding
retrieval-augmented training datasets which are designed to expose our models
to a variety of heuristic reasoning strategies such as weighing partial
evidence or ignoring an irrelevant context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00951">From Sparse to Soft Mixtures of Experts. (arXiv:2308.00951v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1">Joan Puigcerver</a>, <a href="http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1">Carlos Riquelme</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1">Basil Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a></p>
<p>Sparse mixture of expert architectures (MoEs) scale model capacity without
large increases in training or inference costs. Despite their success, MoEs
suffer from a number of issues: training instability, token dropping, inability
to scale the number of experts, or ineffective finetuning. In this work, we
proposeSoft MoE, a fully-differentiable sparse Transformer that addresses these
challenges, while maintaining the benefits of MoEs. Soft MoE performs an
implicit soft assignment by passing different weighted combinations of all
input tokens to each expert. As in other MoE works, experts in Soft MoE only
process a subset of the (combined) tokens, enabling larger model capacity at
lower inference cost. In the context of visual recognition, Soft MoE greatly
outperforms standard Transformers (ViTs) and popular MoE variants (Tokens
Choice and Experts Choice). For example, Soft MoE-Base/16 requires 10.5x lower
inference cost (5.7x lower wall-clock time) than ViT-Huge/14 while matching its
performance after similar training. Soft MoE also scales well: Soft MoE Huge/14
with 128 experts in 16 MoE layers has over 40x more parameters than ViT
Huge/14, while inference time cost grows by only 2%, and it performs
substantially better.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00958">Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks. (arXiv:2308.00958v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Aishan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xingyu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1">Siyuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yisong Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yichao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianglong Liu</a></p>
<p>Despite the broad application of Machine Learning models as a Service
(MLaaS), they are vulnerable to model stealing attacks. These attacks can
replicate the model functionality by using the black-box query process without
any prior knowledge of the target victim model. Existing stealing defenses add
deceptive perturbations to the victim's posterior probabilities to mislead the
attackers. However, these defenses are now suffering problems of high inference
computational overheads and unfavorable trade-offs between benign accuracy and
stealing robustness, which challenges the feasibility of deployed models in
practice. To address the problems, this paper proposes Isolation and Induction
(InI), a novel and effective training framework for model stealing defenses.
Instead of deploying auxiliary defense modules that introduce redundant
inference time, InI directly trains a defensive model by isolating the
adversary's training gradient from the expected gradient, which can effectively
reduce the inference computational cost. In contrast to adding perturbations
over model predictions that harm the benign accuracy, we train models to
produce uninformative outputs against stealing queries, which can induce the
adversary to extract little useful knowledge from victim models with minimal
impact on the benign performance. Extensive experiments on several visual
classification datasets (e.g., MNIST and CIFAR10) demonstrate the superior
robustness (up to 48% reduction on stealing accuracy) and speed (up to 25.4x
faster) of our InI over other state-of-the-art methods. Our codes can be found
in https://github.com/DIG-Beihang/InI-Model-Stealing-Defense.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00989">Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning. (arXiv:2308.00989v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haorui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jiaqi Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Daniel Zeng</a></p>
<p>Hierarchical reinforcement learning composites subpolicies in different
hierarchies to accomplish complex tasks.Automated subpolicies discovery, which
does not depend on domain knowledge, is a promising approach to generating
subpolicies.However, the degradation problem is a challenge that existing
methods can hardly deal with due to the lack of consideration of diversity or
the employment of weak regularizers. In this paper, we propose a novel
task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer
(WDER), which enlarges the diversity of subpolicies by maximizing the
Wasserstein distances among action distributions. The proposed WDER can be
easily incorporated into the loss function of existing methods to boost their
performance further.Experimental results demonstrate that our WDER improves
performance and sample efficiency in comparison with prior work without
modifying hyperparameters, which indicates the applicability and robustness of
the WDER.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01006">FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving. (arXiv:2308.01006v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1">Tengju Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_W/0/1/0/all/0/1">Wei Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Chunyong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shikun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Lingping Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fangzhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingke Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1">Ke Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wencong Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_W/0/1/0/all/0/1">Weibo Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junbo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Kaicheng Yu</a></p>
<p>Building a multi-modality multi-task neural network toward accurate and
robust performance is a de-facto standard in perception task of autonomous
driving. However, leveraging such data from multiple sensors to jointly
optimize the prediction and planning tasks remains largely unexplored. In this
paper, we present FusionAD, to the best of our knowledge, the first unified
framework that fuse the information from two most critical sensors, camera and
LiDAR, goes beyond perception task. Concretely, we first build a transformer
based multi-modality fusion network to effectively produce fusion based
features. In constrast to camera-based end-to-end method UniAD, we then
establish a fusion aided modality-aware prediction and status-aware planning
modules, dubbed FMSPnP that take advantages of multi-modality features. We
conduct extensive experiments on commonly used benchmark nuScenes dataset, our
FusionAD achieves state-of-the-art performance and surpassing baselines on
average 15% on perception tasks like detection and tracking, 10% on occupancy
prediction accuracy, reducing prediction error from 0.708 to 0.389 in ADE score
and reduces the collision rate from 0.31% to only 0.12%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01011">Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chunwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoxu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lijun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuankai Wu</a></p>
<p>Time series analysis is a fundamental task in various application domains,
and deep learning approaches have demonstrated remarkable performance in this
area. However, many real-world time series data exhibit significant periodic or
quasi-periodic dynamics that are often not adequately captured by existing deep
learning-based solutions. This results in an incomplete representation of the
underlying dynamic behaviors of interest. To address this gap, we propose an
unsupervised method called Floss that automatically regularizes learned
representations in the frequency domain. The Floss method first automatically
detects major periodicities from the time series. It then employs periodic
shift and spectral density similarity measures to learn meaningful
representations with periodic consistency. In addition, Floss can be easily
incorporated into both supervised, semi-supervised, and unsupervised learning
frameworks. We conduct extensive experiments on common time series
classification, forecasting, and anomaly detection tasks to demonstrate the
effectiveness of Floss. We incorporate Floss into several representative deep
learning solutions to justify our design choices and demonstrate that it is
capable of automatically discovering periodic dynamics and improving
state-of-the-art deep learning models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01030">Three Factors to Improve Out-of-Distribution Detection. (arXiv:2308.01030v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Hyunjun Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">JaeHo Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Hawook Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jin Young Choi</a></p>
<p>In the problem of out-of-distribution (OOD) detection, the usage of auxiliary
data as outlier data for fine-tuning has demonstrated encouraging performance.
However, previous methods have suffered from a trade-off between classification
accuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve
this trade-off, we make three contributions: (i) Incorporating a self-knowledge
distillation loss can enhance the accuracy of the network; (ii) Sampling
semi-hard outlier data for training can improve OOD detection performance with
minimal impact on accuracy; (iii) The introduction of our novel supervised
contrastive learning can simultaneously improve OOD detection performance and
the accuracy of the network. By incorporating all three factors, our approach
enhances both accuracy and OOD detection performance by addressing the
trade-off between classification and OOD detection. Our method achieves
improvements over previous approaches in both performance metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01044">Chat Translation Error Detection for Assisting Cross-lingual Communications. (arXiv:2308.01044v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunmeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_J/0/1/0/all/0/1">Jun Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Morishita_M/0/1/0/all/0/1">Makoto Morishita</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_K/0/1/0/all/0/1">Kaori Abe</a>, <a href="http://arxiv.org/find/cs/1/au:+Tokuhisa_R/0/1/0/all/0/1">Ryoko Tokuhisa</a>, <a href="http://arxiv.org/find/cs/1/au:+Brassard_A/0/1/0/all/0/1">Ana Brassard</a>, <a href="http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1">Kentaro Inui</a></p>
<p>In this paper, we describe the development of a communication support system
that detects erroneous translations to facilitate crosslingual communications
due to the limitations of current machine chat translation methods. We trained
an error detector as the baseline of the system and constructed a new
Japanese-English bilingual chat corpus, BPersona-chat, which comprises
multiturn colloquial chats augmented with crowdsourced quality ratings. The
error detector can serve as an encouraging foundation for more advanced
erroneous translation detection systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01050">A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles&#x27; Riskiness. (arXiv:2308.01050v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zanardi_A/0/1/0/all/0/1">Alessandro Zanardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Censi_A/0/1/0/all/0/1">Andrea Censi</a>, <a href="http://arxiv.org/find/cs/1/au:+Atzei_M/0/1/0/all/0/1">Margherita Atzei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lillo_L/0/1/0/all/0/1">Luigi Di Lillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Frazzoli_E/0/1/0/all/0/1">Emilio Frazzoli</a></p>
<p>Autonomous Vehicles (AVs) have the potential to provide numerous societal
benefits, such as decreased road accidents and increased overall transportation
efficiency. However, quantifying the risk associated with AVs is challenging
due to the lack of historical data and the rapidly evolving technology. This
paper presents a data-driven framework for comparing the risk of different AVs'
behaviors in various operational design domains (ODDs), based on counterfactual
simulations of "misbehaving" road users. We introduce the concept of
counterfactual safety margin, which represents the minimum deviation from
normal behavior that could lead to a collision. This concept helps to find the
most critical scenarios but also to assess the frequency and severity of risk
of AVs. We show that the proposed methodology is applicable even when the AV's
behavioral policy is unknown -- through worst- and best-case analyses -- making
the method useful also to external third-party risk assessors. Our experimental
results demonstrate the correlation between the safety margin, the driving
policy quality, and the ODD shedding light on the relative risk associated with
different AV providers. This work contributes to AV safety assessment and aids
in addressing legislative and insurance concerns surrounding this emerging
technology.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01063">Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach. (arXiv:2308.01063v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ai_X/0/1/0/all/0/1">Xing Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jialong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yulin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gaolei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalak_T/0/1/0/all/0/1">Tomasz P. Michalak</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiapu Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a></p>
<p>Graph anomaly detection (GAD) has achieved success and has been widely
applied in various domains, such as fraud detection, cybersecurity, finance
security, and biochemistry. However, existing graph anomaly detection
algorithms focus on distinguishing individual entities (nodes or graphs) and
overlook the possibility of anomalous groups within the graph. To address this
limitation, this paper introduces a novel unsupervised framework for a new task
called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework
first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that
belong to potential anomaly groups by capturing long-range inconsistencies.
Subsequently, group sampling is employed to sample candidate groups, which are
then fed into the proposed Topology Pattern-based Graph Contrastive Learning
(TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to
generate embeddings for each candidate group and thus distinct anomaly groups.
The experimental results on both real-world and synthetic datasets demonstrate
that the proposed framework shows superior performance in identifying and
localizing anomaly groups, highlighting it as a promising solution for Gr-GAD.
Datasets and codes of the proposed framework are at the github repository
https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01085">Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making. (arXiv:2308.01085v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kikot_S/0/1/0/all/0/1">Stanislav Kikot</a></p>
<p>In this paper we show how rule-based decision making can be combined with
traditional motion planning techniques to achieve human-like behavior of a
self-driving vehicle in complex traffic situations. We give and discuss
examples of decision rules in autonomous driving. We draw on these examples to
illustrate that developing techniques for spatial awareness of robots is an
exciting activity which deserves more attention from spatial reasoning
community that it had received so far.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01088">Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks. (arXiv:2308.01088v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amprimo_G/0/1/0/all/0/1">Gianluca Amprimo</a>, <a href="http://arxiv.org/find/cs/1/au:+Masi_G/0/1/0/all/0/1">Giulia Masi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pettiti_G/0/1/0/all/0/1">Giuseppe Pettiti</a>, <a href="http://arxiv.org/find/cs/1/au:+Olmo_G/0/1/0/all/0/1">Gabriella Olmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Priano_L/0/1/0/all/0/1">Lorenzo Priano</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraris_C/0/1/0/all/0/1">Claudia Ferraris</a></p>
<p>Accurate 3D tracking of hand and fingers movements poses significant
challenges in computer vision. The potential applications span across multiple
domains, including human-computer interaction, virtual reality, industry, and
medicine. While gesture recognition has achieved remarkable accuracy,
quantifying fine movements remains a hurdle, particularly in clinical
applications where the assessment of hand dysfunctions and rehabilitation
training outcomes necessitate precise measurements. Several novel and
lightweight frameworks based on Deep Learning have emerged to address this
issue; however, their performance in accurately and reliably measuring fingers
movements requires validation against well-established gold standard systems.
In this paper, the aim is to validate the handtracking framework implemented by
Google MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D, that
exploits the depth estimation of an RGB-Depth camera to achieve more accurate
tracking of 3D movements. Three dynamic exercises commonly administered by
clinicians to assess hand dysfunctions, namely Hand Opening-Closing, Single
Finger Tapping and Multiple Finger Tapping are considered. Results demonstrate
high temporal and spectral consistency of both frameworks with the gold
standard. However, the enhanced GMH-D framework exhibits superior accuracy in
spatial measurements compared to the baseline GMH, for both slow and fast
movements. Overall, our study contributes to the advancement of hand tracking
technology, the establishment of a validation procedure as a good-practice to
prove efficacy of deep-learning-based hand-tracking, and proves the
effectiveness of GMH-D as a reliable framework for assessing 3D hand movements
in clinical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01094">Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case. (arXiv:2308.01094v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Baifan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolov_N/0/1/0/all/0/1">Nikolay Nikolov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhuoxun Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xianghui Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Savkovic_O/0/1/0/all/0/1">Ognjen Savkovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Roman_D/0/1/0/all/0/1">Dumitru Roman</a>, <a href="http://arxiv.org/find/cs/1/au:+Soylu_A/0/1/0/all/0/1">Ahmet Soylu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1">Evgeny Kharlamov</a></p>
<p>Industry 4.0 and Internet of Things (IoT) technologies unlock unprecedented
amount of data from factory production, posing big data challenges in volume
and variety. In that context, distributed computing solutions such as cloud
systems are leveraged to parallelise the data processing and reduce computation
time. As the cloud systems become increasingly popular, there is increased
demand that more users that were originally not cloud experts (such as data
scientists, domain experts) deploy their solutions on the cloud systems.
However, it is non-trivial to address both the high demand for cloud system
users and the excessive time required to train them. To this end, we propose
SemCloud, a semantics-enhanced cloud system, that couples cloud system with
semantic technologies and machine learning. SemCloud relies on domain
ontologies and mappings for data integration, and parallelises the semantic
data integration and data analysis on distributed computing nodes. Furthermore,
SemCloud adopts adaptive Datalog rules and machine learning for automated
resource configuration, allowing non-cloud experts to use the cloud system. The
system has been evaluated in industrial use case with millions of data,
thousands of repeated runs, and domain users, showing promising results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01098">Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search. (arXiv:2308.01098v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ning_K/0/1/0/all/0/1">Kun-Peng Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_M/0/1/0/all/0/1">Ming Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xue Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xi-Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chang-Ping Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhan-Gang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jing-He Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jing-Ping Shao</a></p>
<p>Search query classification, as an effective way to understand user intents,
is of great importance in real-world online ads systems. To ensure a lower
latency, a shallow model (e.g. FastText) is widely used for efficient online
inference. However, the representation ability of the FastText model is
insufficient, resulting in poor classification performance, especially on some
low-frequency queries and tailed categories. Using a deeper and more complex
model (e.g. BERT) is an effective solution, but it will cause a higher online
inference latency and more expensive computing costs. Thus, how to juggle both
inference efficiency and classification performance is obviously of great
practical importance. To overcome this challenge, in this paper, we propose
knowledge condensation (KC), a simple yet effective knowledge distillation
framework to boost the classification performance of the online FastText model
under strict low latency constraints. Specifically, we propose to train an
offline BERT model to retrieve more potentially relevant data. Benefiting from
its powerful semantic representation, more relevant labels not exposed in the
historical data will be added into the training set for better FastText model
training. Moreover, a novel distribution-diverse multi-expert learning strategy
is proposed to further improve the mining ability of relevant data. By training
multiple BERT models from different data distributions, it can respectively
perform better at high, middle, and low-frequency search queries. The model
ensemble from multi-distribution makes its retrieval ability more powerful. We
have deployed two versions of this framework in JD search, and both offline
experiments and online A/B testing from multiple datasets have validated the
effectiveness of the proposed approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01105">Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case. (arXiv:2308.01105v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhipeng Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Baifan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhuoxun Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Savkovic_O/0/1/0/all/0/1">Ognjen Savkovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziqi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_I/0/1/0/all/0/1">Irlan-Grangel Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Soylu_A/0/1/0/all/0/1">Ahmet Soylu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1">Evgeny Kharlamov</a></p>
<p>Recently there has been a series of studies in knowledge graph embedding
(KGE), which attempts to learn the embeddings of the entities and relations as
numerical vectors and mathematical mappings via machine learning (ML). However,
there has been limited research that applies KGE for industrial problems in
manufacturing. This paper investigates whether and to what extent KGE can be
used for an important problem: quality monitoring for welding in manufacturing
industry, which is an impactful process accounting for production of millions
of cars annually. The work is in line with Bosch research of data-driven
solutions that intends to replace the traditional way of destroying cars, which
is extremely costly and produces waste. The paper tackles two very challenging
questions simultaneously: how large the welding spot diameter is; and to which
car body the welded spot belongs to. The problem setting is difficult for
traditional ML because there exist a high number of car bodies that should be
assigned as class labels. We formulate the problem as link prediction, and
experimented popular KGE methods on real industry data, with consideration of
literals. Our results reveal both limitations and promising aspects of adapted
KGE methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01118">A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Klimashevskaia_A/0/1/0/all/0/1">Anastasiia Klimashevskaia</a>, <a href="http://arxiv.org/find/cs/1/au:+Jannach_D/0/1/0/all/0/1">Dietmar Jannach</a>, <a href="http://arxiv.org/find/cs/1/au:+Elahi_M/0/1/0/all/0/1">Mehdi Elahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Trattner_C/0/1/0/all/0/1">Christoph Trattner</a></p>
<p>Recommender systems help people find relevant content in a personalized way.
One main promise of such systems is that they are able to increase the
visibility of items in the long tail, i.e., the lesser-known items in a
catalogue. Existing research, however, suggests that in many situations today's
recommendation algorithms instead exhibit a popularity bias, meaning that they
often focus on rather popular items in their recommendations. Such a bias may
not only lead to limited value of the recommendations for consumers and
providers in the short run, but it may also cause undesired reinforcement
effects over time. In this paper, we discuss the potential reasons for
popularity bias and we review existing approaches to detect, quantify and
mitigate popularity bias in recommender systems. Our survey therefore includes
both an overview of the computational metrics used in the literature as well as
a review of the main technical approaches to reduce the bias. We furthermore
critically discuss today's literature, where we observe that the research is
almost entirely based on computational experiments and on certain assumptions
regarding the practical effects of including long-tail items in the
recommendations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01138">Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases. (arXiv:2308.01138v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Haiwen Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1">Zheng Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+An_Y/0/1/0/all/0/1">Yu An</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Honghui Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dongjie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhaoshuo Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawlor_A/0/1/0/all/0/1">Aonghus Lawlor</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1">Ruihai Dong</a></p>
<p>Spectrum analysis systems in online water quality testing are designed to
detect types and concentrations of pollutants and enable regulatory agencies to
respond promptly to pollution incidents. However, spectral data-based testing
devices suffer from complex noise patterns when deployed in non-laboratory
environments. To make the analysis model applicable to more environments, we
propose a noise patterns transferring model, which takes the spectrum of
standard water samples in different environments as cases and learns the
differences in their noise patterns, thus enabling noise patterns to transfer
to unknown samples. Unfortunately, the inevitable sample-level baseline noise
makes the model unable to obtain the paired data that only differ in
dataset-level environmental noise. To address the problem, we generate a
sample-to-sample case-base to exclude the interference of sample-level noise on
dataset-level noise learning, enhancing the system's learning performance.
Experiments on spectral data with different background noises demonstrate the
good noise-transferring ability of the proposed method against baseline systems
ranging from wavelet denoising, deep neural networks, and generative models.
From this research, we posit that our method can enhance the performance of DL
models by generating high-quality cases. The source code is made publicly
available online at https://github.com/Magnomic/CNST.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01154">Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maltoni_D/0/1/0/all/0/1">Davide Maltoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrara_M/0/1/0/all/0/1">Matteo Ferrara</a></p>
<p>A better understanding of the emergent computation and problem-solving
capabilities of recent large language models is of paramount importance to
further improve them and broaden their applicability. This work investigates
how a language model, trained to predict the next token, can perform arithmetic
computations generalizing beyond training data. Binary addition and
multiplication constitute a good testbed for this purpose, since they require a
very small vocabulary and exhibit relevant input/output discontinuities making
smooth input interpolation ineffective for novel data. We successfully trained
a light language model to learn these tasks and ran a number of experiments to
investigate the extrapolation capabilities and internal information processing.
Our findings support the hypotheses that the language model works as an
Encoding-Regression-Decoding machine where the computation takes place in the
value space once the input token representation is mapped to an appropriate
internal representation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01157">LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Lengerich_B/0/1/0/all/0/1">Benjamin J. Lengerich</a>, <a href="http://arxiv.org/find/stat/1/au:+Bordt_S/0/1/0/all/0/1">Sebastian Bordt</a>, <a href="http://arxiv.org/find/stat/1/au:+Nori_H/0/1/0/all/0/1">Harsha Nori</a>, <a href="http://arxiv.org/find/stat/1/au:+Nunnally_M/0/1/0/all/0/1">Mark E. Nunnally</a>, <a href="http://arxiv.org/find/stat/1/au:+Aphinyanaphongs_Y/0/1/0/all/0/1">Yin Aphinyanaphongs</a>, <a href="http://arxiv.org/find/stat/1/au:+Kellis_M/0/1/0/all/0/1">Manolis Kellis</a>, <a href="http://arxiv.org/find/stat/1/au:+Caruana_R/0/1/0/all/0/1">Rich Caruana</a></p>
<p>We show that large language models (LLMs) are remarkably good at working with
interpretable models that decompose complex outcomes into univariate
graph-represented components. By adopting a hierarchical approach to reasoning,
LLMs can provide comprehensive model-level summaries without ever requiring the
entire model to fit in context. This approach enables LLMs to apply their
extensive background knowledge to automate common tasks in data science such as
detecting anomalies that contradict prior knowledge, describing potential
reasons for the anomalies, and suggesting repairs that would remove the
anomalies. We use multiple examples in healthcare to demonstrate the utility of
these new capabilities of LLMs, with particular emphasis on Generalized
Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as
an open-source LLM-GAM interface.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01189">Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation. (arXiv:2308.01189v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yongkang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingjin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhijing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yongyi Lu</a></p>
<p>This paper seeks to address the dense labeling problems where a significant
fraction of the dataset can be pruned without sacrificing much accuracy. We
observe that, on standard medical image segmentation benchmarks, the loss
gradient norm-based metrics of individual training examples applied in image
classification fail to identify the important samples. To address this issue,
we propose a data pruning method by taking into consideration the training
dynamics on target regions using Dynamic Average Dice (DAD) score. To the best
of our knowledge, we are among the first to address the data importance in
dense labeling tasks in the field of medical image analysis, making the
following contributions: (1) investigating the underlying causes with rigorous
empirical analysis, and (2) determining effective data pruning approach in
dense labeling problems. Our solution can be used as a strong yet simple
baseline to select important examples for medical image segmentation with
combined data sources.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01193">Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator. (arXiv:2308.01193v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiaobei Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_X/0/1/0/all/0/1">Xiaoxuan Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guowen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1">Han Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shangwei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chip Hong Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianwei Zhang</a></p>
<p>DNN accelerators have been widely deployed in many scenarios to speed up the
inference process and reduce the energy consumption. One big concern about the
usage of the accelerators is the confidentiality of the deployed models: model
inference execution on the accelerators could leak side-channel information,
which enables an adversary to preciously recover the model details. Such model
extraction attacks can not only compromise the intellectual property of DNN
models, but also facilitate some adversarial attacks.
</p>
<p>Although previous works have demonstrated a number of side-channel techniques
to extract models from DNN accelerators, they are not practical for two
reasons. (1) They only target simplified accelerator implementations, which
have limited practicality in the real world. (2) They require heavy human
analysis and domain knowledge. To overcome these limitations, this paper
presents Mercury, the first automated remote side-channel attack against the
off-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to model
the side-channel extraction process as a sequence-to-sequence problem. The
adversary can leverage a time-to-digital converter (TDC) to remotely collect
the power trace of the target model's inference. Then he uses a learning model
to automatically recover the architecture details of the victim model from the
power trace without any prior knowledge. The adversary can further use the
attention mechanism to localize the leakage points that contribute most to the
attack. Evaluation results indicate that Mercury can keep the error rate of
model extraction below 1%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01195">Personalized Category Frequency prediction for Buy It Again recommendations. (arXiv:2308.01195v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pande_A/0/1/0/all/0/1">Amit Pande</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_K/0/1/0/all/0/1">Kunal Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_R/0/1/0/all/0/1">Rankyung Park</a></p>
<p>Buy It Again (BIA) recommendations are crucial to retailers to help improve
user experience and site engagement by suggesting items that customers are
likely to buy again based on their own repeat purchasing patterns. Most
existing BIA studies analyze guests personalized behavior at item granularity.
A category-based model may be more appropriate in such scenarios. We propose a
recommendation system called a hierarchical PCIC model that consists of a
personalized category model (PC model) and a personalized item model within
categories (IC model). PC model generates a personalized list of categories
that customers are likely to purchase again. IC model ranks items within
categories that guests are likely to consume within a category. The
hierarchical PCIC model captures the general consumption rate of products using
survival models. Trends in consumption are captured using time series models.
Features derived from these models are used in training a category-grained
neural network. We compare PCIC to twelve existing baselines on four standard
open datasets. PCIC improves NDCG up to 16 percent while improving recall by
around 2 percent. We were able to scale and train (over 8 hours) PCIC on a
large dataset of 100M guests and 3M items where repeat categories of a guest
out number repeat items. PCIC was deployed and AB tested on the site of a major
retailer, leading to significant gains in guest engagement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01207">BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization. (arXiv:2308.01207v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuanyang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jianye Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chunlin Chen</a></p>
<p>Evolutionary reinforcement learning (ERL) algorithms recently raise attention
in tackling complex reinforcement learning (RL) problems due to high
parallelism, while they are prone to insufficient exploration or model collapse
without carefully tuning hyperparameters (aka meta-parameters). In the paper,
we propose a general meta ERL framework via bilevel optimization (BiERL) to
jointly update hyperparameters in parallel to training the ERL model within a
single agent, which relieves the need for prior domain knowledge or costly
optimization procedure before model deployment. We design an elegant meta-level
architecture that embeds the inner-level's evolving experience into an
informative population representation and introduce a simple and feasible
evaluation of the meta-level fitness function to facilitate learning
efficiency. We perform extensive experiments in MuJoCo and Box2D tasks to
verify that as a general framework, BiERL outperforms various baselines and
consistently improves the learning performance for a diversity of ERL
algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01220">Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case. (arXiv:2308.01220v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorge_R/0/1/0/all/0/1">Rebekka G&#xf6;rge</a>, <a href="http://arxiv.org/find/cs/1/au:+Haedecke_E/0/1/0/all/0/1">Elena Haedecke</a>, <a href="http://arxiv.org/find/cs/1/au:+Mock_M/0/1/0/all/0/1">Michael Mock</a></p>
<p>Our Visual Analytics (VA) tool ScrutinAI supports human analysts to
investigate interactively model performanceand data sets. Model performance
depends on labeling quality to a large extent. In particular in medical
settings, generation of high quality labels requires in depth expert knowledge
and is very costly. Often, data sets are labeled by collecting opinions of
groups of experts. We use our VA tool to analyse the influence of label
variations between different experts on the model performance. ScrutinAI
facilitates to perform a root cause analysis that distinguishes weaknesses of
deep neural network (DNN) models caused by varying or missing labeling quality
from true weaknesses. We scrutinize the overall detection of intracranial
hemorrhages and the more subtle differentiation between subtypes in a publicly
available data set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01222">Calibration in Deep Learning: A Survey of the State-of-the-Art. (arXiv:2308.01222v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cheng Wang</a></p>
<p>Calibrating deep neural models plays an important role in building reliable,
robust AI systems in safety-critical applications. Recent work has shown that
modern neural networks that possess high predictive capability are poorly
calibrated and produce unreliable model predictions. Though deep learning
models achieve remarkable performance on various benchmarks, the study of model
calibration and reliability is relatively underexplored. Ideal deep models
should have not only high predictive performance but also be well calibrated.
There have been some recent methods proposed to calibrate deep models by using
different mechanisms. In this survey, we review the state-of-the-art
calibration methods and provide an understanding of their principles for
performing model calibration. First, we start with the definition of model
calibration and explain the root causes of model miscalibration. Then we
introduce the key metrics that can measure this aspect. It is followed by a
summary of calibration methods that we roughly classified into four categories:
post-hoc calibration, regularization methods, uncertainty estimation, and
composition methods. We also covered some recent advancements in calibrating
large models, particularly large language models (LLMs). Finally, we discuss
some open issues, challenges, and potential directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01223">Do Multilingual Language Models Think Better in English?. (arXiv:2308.01223v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Etxaniz_J/0/1/0/all/0/1">Julen Etxaniz</a>, <a href="http://arxiv.org/find/cs/1/au:+Azkune_G/0/1/0/all/0/1">Gorka Azkune</a>, <a href="http://arxiv.org/find/cs/1/au:+Soroa_A/0/1/0/all/0/1">Aitor Soroa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacalle_O/0/1/0/all/0/1">Oier Lopez de Lacalle</a>, <a href="http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1">Mikel Artetxe</a></p>
<p>Translate-test is a popular technique to improve the performance of
multilingual language models. This approach works by translating the input into
English using an external machine translation system, and running inference
over the translated input. However, these improvements can be attributed to the
use of a separate translation system, which is typically trained on large
amounts of parallel data not seen by the language model. In this work, we
introduce a new approach called self-translate, which overcomes the need of an
external translation system by leveraging the few-shot translation capabilities
of multilingual language models. Experiments over 5 tasks show that
self-translate consistently outperforms direct inference, demonstrating that
language models are unable to leverage their full multilingual potential when
prompted in non-English languages. Our code is available at
https://github.com/juletx/self-translate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01240">Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation. (arXiv:2308.01240v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhiqiang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_Q/0/1/0/all/0/1">Qiancheng Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xin Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yiling Lou</a></p>
<p>In this work, we evaluate 10 open-source instructed LLMs on four
representative code comprehension and generation tasks. We have the following
main findings. First, for the zero-shot setting, instructed LLMs are very
competitive on code comprehension and generation tasks and sometimes even
better than small SOTA models specifically fine-tuned on each downstream task.
We also find that larger instructed LLMs are not always better on code-related
tasks. Second, for the few-shot setting, we find that adding demonstration
examples substantially helps instructed LLMs perform better on most code
comprehension and generation tasks; however, the examples would sometimes
induce unstable or even worse performance. Furthermore, we find widely-used
BM25-based shot selection strategy significantly outperforms the basic random
selection or fixed selection only on generation problems. Third, for the
fine-tuning setting, we find that fine-tuning could further improve the model
performance on downstream code comprehension and generation tasks compared to
the zero-shot/one-shot performance. In addition, after being fine-tuned on the
same downstream task dataset, instructed LLMs outperform both the small SOTA
models and similar-scaled LLMs without instruction tuning. Based on our
findings, we further present practical implications on model and usage
recommendation, performance and cost trade-offs, and future direction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01263">XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models. (arXiv:2308.01263v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1">Paul R&#xf6;ttger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1">Hannah Rose Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertie Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Attanasio_G/0/1/0/all/0/1">Giuseppe Attanasio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1">Federico Bianchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1">Dirk Hovy</a></p>
<p>Without proper safeguards, large language models will readily follow
malicious instructions and generate toxic content. This motivates safety
efforts such as red-teaming and large-scale feedback learning, which aim to
make models both helpful and harmless. However, there is a tension between
these two objectives, since harmlessness requires models to refuse complying
with unsafe prompts, and thus not be helpful. Recent anecdotal evidence
suggests that some models may have struck a poor balance, so that even clearly
safe prompts are refused if they use similar language to unsafe prompts or
mention sensitive topics. In this paper, we introduce a new test suite called
XSTest to identify such eXaggerated Safety behaviours in a structured and
systematic way. In its current form, XSTest comprises 200 safe prompts across
ten prompt types that well-calibrated models should not refuse to comply with.
We describe XSTest's creation and composition, and use the test suite to
highlight systematic failure modes in a recently-released state-of-the-art
language model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01264">Exploring the psychology of GPT-4&#x27;s Moral and Legal Reasoning. (arXiv:2308.01264v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Almeida_G/0/1/0/all/0/1">Guilherme F. C. F. Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunes_J/0/1/0/all/0/1">Jos&#xe9; Luiz Nunes</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelmann_N/0/1/0/all/0/1">Neele Engelmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiegmann_A/0/1/0/all/0/1">Alex Wiegmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Araujo_M/0/1/0/all/0/1">Marcelo de Ara&#xfa;jo</a></p>
<p>Large language models have been used as the foundation of highly
sophisticated artificial intelligences, capable of delivering human-like
responses to probes about legal and moral issues. However, these models are
unreliable guides to their own inner workings, and even the engineering teams
behind their creation are unable to explain exactly how they came to develop
all of the capabilities they currently have. The emerging field of machine
psychology seeks to gain insight into the processes and concepts that these
models possess. In this paper, we employ the methods of psychology to probe
into GPT-4's moral and legal reasoning. More specifically, we investigate the
similarities and differences between GPT-4 and humans when it comes to
intentionality ascriptions, judgments about causation, the morality of
deception, moral foundations, the impact of moral luck on legal judgments, the
concept of consent, and rule violation judgments. We find high correlations
between human and AI responses, but also several significant systematic
differences between them. We conclude with a discussion of the philosophical
implications of our findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01271">A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC. (arXiv:2308.01271v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Javanbakhat_M/0/1/0/all/0/1">Masoumeh Javanbakhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lippert_C/0/1/0/all/0/1">Christoph Lippert</a></p>
<p>In this paper we present a practical Bayesian self-supervised learning method
with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this
framework, we place a prior over the parameters of a self-supervised learning
model and use cSGHMC to approximate the high dimensional and multimodal
posterior distribution over the embeddings. By exploring an expressive
posterior over the embeddings, Bayesian self-supervised learning produces
interpretable and diverse representations. Marginalizing over these
representations yields a significant gain in performance, calibration and
out-of-distribution detection on a variety of downstream classification tasks.
We provide experimental results on multiple classification tasks on four
challenging datasets. Moreover, we demonstrate the effectiveness of the
proposed method in out-of-distribution detection using the SVHN and CIFAR-10
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01274">BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems. (arXiv:2308.01274v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md Tamjid Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1">Hung Manh La</a>, <a href="http://arxiv.org/find/cs/1/au:+Badsha_S/0/1/0/all/0/1">Shahriar Badsha</a>, <a href="http://arxiv.org/find/cs/1/au:+Netchaev_A/0/1/0/all/0/1">Anton Netchaev</a></p>
<p>Although experience sharing (ES) accelerates multiagent reinforcement
learning (MARL) in an advisor-advisee framework, attempts to apply ES to
decentralized multiagent systems have so far relied on trusted environments and
overlooked the possibility of adversarial manipulation and inference.
Nevertheless, in a real-world setting, some Byzantine attackers, disguised as
advisors, may provide false advice to the advisee and catastrophically degrade
the overall learning performance. Also, an inference attacker, disguised as an
advisee, may conduct several queries to infer the advisors' private information
and make the entire ES process questionable in terms of privacy leakage. To
address and tackle these issues, we propose a novel MARL framework (BRNES) that
heuristically selects a dynamic neighbor zone for each advisee at each learning
step and adopts a weighted experience aggregation technique to reduce Byzantine
attack impact. Furthermore, to keep the agent's private information safe from
adversarial inference attacks, we leverage the local differential privacy
(LDP)-induced noise during the ES process. Our experiments show that our
framework outperforms the state-of-the-art in terms of the steps to goal,
obtained reward, and time to goal metrics. Particularly, our evaluation shows
that the proposed framework is 8.32x faster than the current non-private
frameworks and 1.41x faster than the private frameworks in an adversarial
setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01284">Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhattacharjee_A/0/1/0/all/0/1">Amrita Bhattacharjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huan Liu</a></p>
<p>Large language models (LLMs) such as ChatGPT are increasingly being used for
various use cases, including text content generation at scale. Although
detection methods for such AI-generated text exist already, we investigate
ChatGPT's performance as a detector on such AI-generated text, inspired by
works that use ChatGPT as a data labeler or annotator. We evaluate the
zero-shot performance of ChatGPT in the task of human-written vs. AI-generated
text detection, and perform experiments on publicly available datasets. We
empirically investigate if ChatGPT is symmetrically effective in detecting
AI-generated or human-written text. Our findings provide insight on how ChatGPT
and similar LLMs may be leveraged in automated detection pipelines by simply
focusing on solving a specific aspect of the problem and deriving the rest from
that solution. All code and data is available at
\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01285">Flows: Building Blocks of Reasoning and Collaborating AI. (arXiv:2308.01285v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1">Martin Josifoski</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_L/0/1/0/all/0/1">Lars Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1">Maxime Peyrard</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yifei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1">Saibo Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnitzler_J/0/1/0/all/0/1">Julian Paul Schnitzler</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuxing Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jiheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1">Debjit Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1">Robert West</a></p>
<p>Recent advances in artificial intelligence (AI) have produced highly capable
and controllable systems. This creates unprecedented opportunities for
structured reasoning as well as collaboration among multiple AI systems and
humans. To fully realize this potential, it is essential to develop a
principled way of designing and studying such structured interactions. For this
purpose, we introduce the conceptual framework of Flows: a systematic approach
to modeling complex interactions. Flows are self-contained building blocks of
computation, with an isolated state, communicating through a standardized
message-based interface. This modular design allows Flows to be recursively
composed into arbitrarily nested interactions, with a substantial reduction of
complexity. Crucially, any interaction can be implemented using this framework,
including prior work on AI--AI and human--AI interactions, prompt engineering
schemes, and tool augmentation. We demonstrate the potential of Flows on the
task of competitive coding, a challenging task on which even GPT-4 struggles.
Our results suggest that structured reasoning and collaboration substantially
improve generalization, with AI-only Flows adding +$21$ and human--AI Flows
adding +$54$ absolute points in terms of solve rate. To support rapid and
rigorous research, we introduce the aiFlows library. The library comes with a
repository of Flows that can be easily used, extended, and composed into novel,
more complex Flows.
</p>
<p>The aiFlows library is available at https://github.com/epfl-dlab/aiflows.
Data and Flows for reproducing our experiments are available at
https://github.com/epfl-dlab/cc_flows.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01312">Lode Encoder: AI-constrained co-creativity. (arXiv:2308.01312v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhaumik_D/0/1/0/all/0/1">Debosmita Bhaumik</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1">Ahmed Khalifa</a>, <a href="http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1">Julian Togelius</a></p>
<p>We present Lode Encoder, a gamified mixed-initiative level creation system
for the classic platform-puzzle game Lode Runner. The system is built around
several autoencoders which are trained on sets of Lode Runner levels. When fed
with the user's design, each autoencoder produces a version of that design
which is closer in style to the levels that it was trained on. The Lode Encoder
interface allows the user to build and edit levels through 'painting' from the
suggestions provided by the autoencoders. Crucially, in order to encourage
designers to explore new possibilities, the system does not include more
traditional editing tools. We report on the system design and training
procedure, as well as on the evolution of the system itself and user tests.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01313">More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes. (arXiv:2308.01313v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bang An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Sicheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Panaitescu_Liess_M/0/1/0/all/0/1">Michael-Andrei Panaitescu-Liess</a>, <a href="http://arxiv.org/find/cs/1/au:+Mummadi_C/0/1/0/all/0/1">Chaithanya Kumar Mummadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a></p>
<p>CLIP, as a foundational vision language model, is widely used in zero-shot
image classification due to its ability to understand various visual concepts
and natural language descriptions. However, how to fully leverage CLIP's
unprecedented human-like understanding capabilities to achieve better zero-shot
classification is still an open question. This paper draws inspiration from the
human visual perception process: a modern neuroscience view suggests that in
classifying an object, humans first infer its class-independent attributes
(e.g., background and orientation) which help separate the foreground object
from the background, and then make decisions based on this information.
Inspired by this, we observe that providing CLIP with contextual attributes
improves zero-shot classification and mitigates reliance on spurious features.
We also observe that CLIP itself can reasonably infer the attributes from an
image. With these observations, we propose a training-free, two-step zero-shot
classification method named PerceptionCLIP. Given an image, it first infers
contextual attributes (e.g., background) and then performs object
classification conditioning on them. Our experiments show that PerceptionCLIP
achieves better generalization, group robustness, and better interpretability.
For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by
16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2010.08657">Class-incremental Learning with Pre-allocated Fixed Classifiers. (arXiv:2010.08657v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pernici_F/0/1/0/all/0/1">Federico Pernici</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruni_M/0/1/0/all/0/1">Matteo Bruni</a>, <a href="http://arxiv.org/find/cs/1/au:+Baecchi_C/0/1/0/all/0/1">Claudio Baecchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Turchini_F/0/1/0/all/0/1">Francesco Turchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1">Alberto Del Bimbo</a></p>
<p>In class-incremental learning, a learning agent faces a stream of data with
the goal of learning new classes while not forgetting previous ones. Neural
networks are known to suffer under this setting, as they forget previously
acquired knowledge. To address this problem, effective methods exploit past
data stored in an episodic memory while expanding the final classifier nodes to
accommodate the new classes.
</p>
<p>In this work, we substitute the expanding classifier with a novel fixed
classifier in which a number of pre-allocated output nodes are subject to the
classification loss right from the beginning of the learning phase. Contrarily
to the standard expanding classifier, this allows: (a) the output nodes of
future unseen classes to firstly see negative samples since the beginning of
learning together with the positive samples that incrementally arrive; (b) to
learn features that do not change their geometric configuration as novel
classes are incorporated in the learning model.
</p>
<p>Experiments with public datasets show that the proposed approach is as
effective as the expanding classifier while exhibiting novel intriguing
properties of the internal feature representation that are otherwise
not-existent. Our ablation study on pre-allocating a large number of classes
further validates the approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2104.10401">Multi-Attention-Based Soft Partition Network for Vehicle Re-Identification. (arXiv:2104.10401v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangrok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_T/0/1/0/all/0/1">Taekang Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sang Hun Lee</a></p>
<p>Vehicle re-identification helps in distinguishing between images of the same
and other vehicles. It is a challenging process because of significant
intra-instance differences between identical vehicles from different views and
subtle inter-instance differences between similar vehicles. To solve this
issue, researchers have extracted view-aware or part-specific features via
spatial attention mechanisms, which usually result in noisy attention maps or
otherwise require expensive additional annotation for metadata, such as key
points, to improve the quality. Meanwhile, based on the researchers' insights,
various handcrafted multi-attention architectures for specific viewpoints or
vehicle parts have been proposed. However, this approach does not guarantee
that the number and nature of attention branches will be optimal for real-world
re-identification tasks. To address these problems, we proposed a new vehicle
re-identification network based on a multiple soft attention mechanism for
capturing various discriminative regions from different viewpoints more
efficiently. Furthermore, this model can significantly reduce the noise in
spatial attention maps by devising a new method for creating an attention map
for insignificant regions and then excluding it from generating the final
result. We also combined a channel-wise attention mechanism with a spatial
attention mechanism for the efficient selection of important semantic
attributes for vehicle re-identification. Our experiments showed that our
proposed model achieved a state-of-the-art performance among the
attention-based methods without metadata and was comparable to the approaches
using metadata for the VehicleID and VERI-Wild datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.15701">Successor Feature Representations. (arXiv:2110.15701v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Reinke_C/0/1/0/all/0/1">Chris Reinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1">Xavier Alameda-Pineda</a></p>
<p>Transfer in Reinforcement Learning aims to improve learning performance on
target tasks using knowledge from experienced source tasks. Successor
Representations (SR) and their extension Successor Features (SF) are prominent
transfer mechanisms in domains where reward functions change between tasks.
They reevaluate the expected return of previously learned policies in a new
target task to transfer their knowledge. The SF framework extended SR by
linearly decomposing rewards into successor features and a reward weight vector
allowing their application in high-dimensional tasks. But this came with the
cost of having a linear relationship between reward functions and successor
features, limiting its application to tasks where such a linear relationship
exists. We propose a novel formulation of SR based on learning the cumulative
discounted probability of successor features, called Successor Feature
Representations (SFR). Crucially, SFR allows to reevaluate the expected return
of policies for general reward functions. We introduce different SFR
variations, prove its convergence, and provide a guarantee on its transfer
performance. Experimental evaluations based on SFR with function approximation
demonstrate its advantage over SF not only for general reward functions, but
also in the case of linearly decomposable reward functions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.05877">Fabricated Flips: Poisoning Federated Learning without Data. (arXiv:2202.05877v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zilong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lydia Y. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roos_S/0/1/0/all/0/1">Stefanie Roos</a></p>
<p>Attacks on Federated Learning (FL) can severely reduce the quality of the
generated models and limit the usefulness of this emerging learning paradigm
that enables on-premise decentralized learning. However, existing untargeted
attacks are not practical for many scenarios as they assume that i) the
attacker knows every update of benign clients, or ii) the attacker has a large
dataset to locally train updates imitating benign parties. In this paper, we
propose a data-free untargeted attack (DFA) that synthesizes malicious data to
craft adversarial models without eavesdropping on the transmission of benign
clients at all or requiring a large quantity of task-specific training data. We
design two variants of DFA, namely DFA-R and DFA-G, which differ in how they
trade off stealthiness and effectiveness. Specifically, DFA-R iteratively
optimizes a malicious data layer to minimize the prediction confidence of all
outputs of the global model, whereas DFA-G interactively trains a malicious
data generator network by steering the output of the global model toward a
particular class. Experimental results on Fashion-MNIST, Cifar-10, and SVHN
show that DFA, despite requiring fewer assumptions than existing attacks,
achieves similar or even higher attack success rate than state-of-the-art
untargeted attacks against various state-of-the-art defense mechanisms.
Concretely, they can evade all considered defense mechanisms in at least 50% of
the cases for CIFAR-10 and often reduce the accuracy by more than a factor of
2. Consequently, we design REFD, a defense specifically crafted to protect
against data-free attacks. REFD leverages a reference dataset to detect updates
that are biased or have a low confidence. It greatly improves upon existing
defenses by filtering out the malicious updates and achieves high global model
accuracy
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.15925">Asynchronous, Option-Based Multi-Agent Policy Gradient: A Conditional Reasoning Approach. (arXiv:2203.15925v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xubo Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Banitalebi_Dehkordi_A/0/1/0/all/0/1">Amin Banitalebi-Dehkordi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a></p>
<p>Cooperative multi-agent problems often require coordination between agents,
which can be achieved through a centralized policy that considers the global
state. Multi-agent policy gradient (MAPG) methods are commonly used to learn
such policies, but they are often limited to problems with low-level action
spaces. In complex problems with large state and action spaces, it is
advantageous to extend MAPG methods to use higher-level actions, also known as
options, to improve the policy search efficiency. However, multi-robot option
executions are often asynchronous, that is, agents may select and complete
their options at different time steps. This makes it difficult for MAPG methods
to derive a centralized policy and evaluate its gradient, as centralized policy
always select new options at the same time. In this work, we propose a novel,
conditional reasoning approach to address this problem and demonstrate its
effectiveness on representative option-based multi-agent cooperative tasks
through empirical validation. Find code and videos at:
\href{https://sites.google.com/view/mahrlsupp/}{https://sites.google.com/view/mahrlsupp/}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.12490">Improve Event Extraction via Self-Training with Gradient Guidance. (arXiv:2205.12490v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jay-Yoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lifu Huang</a></p>
<p>Data scarcity has been the main factor that hinders the progress of event
extraction. To overcome this issue, we propose a Self-Training with Feedback
(STF) framework that leverages the large-scale unlabeled data and acquires
feedback for each new event prediction from the unlabeled data by comparing it
to the Abstract Meaning Representation (AMR) graph of the same sentence.
Specifically, STF consists of (1) a base event extraction model trained on
existing event annotations and then applied to large-scale unlabeled corpora to
predict new event mentions as pseudo training samples, and (2) a novel scoring
model that takes in each new predicted event trigger, an argument, its argument
role, as well as their paths in the AMR graph to estimate a compatibility score
indicating the correctness of the pseudo label. The compatibility scores
further act as feedback to encourage or discourage the model learning on the
pseudo labels during self-training. Experimental results on three benchmark
datasets, including ACE05-E, ACE05-E+, and ERE, demonstrate the effectiveness
of the STF framework on event extraction, especially event argument extraction,
with significant performance gain over the base event extraction models and
strong baselines. Our experimental analysis further shows that STF is a generic
framework as it can be applied to improve most, if not all, event extraction
models by leveraging large-scale unlabeled data, even when high-quality AMR
graph annotations are not available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.13492">Sparse Graph Learning from Spatiotemporal Time Series. (arXiv:2205.13492v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cini_A/0/1/0/all/0/1">Andrea Cini</a>, <a href="http://arxiv.org/find/cs/1/au:+Zambon_D/0/1/0/all/0/1">Daniele Zambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Alippi_C/0/1/0/all/0/1">Cesare Alippi</a></p>
<p>Outstanding achievements of graph neural networks for spatiotemporal time
series analysis show that relational constraints introduce an effective
inductive bias into neural forecasting architectures. Often, however, the
relational information characterizing the underlying data-generating process is
unavailable and the practitioner is left with the problem of inferring from
data which relational graph to use in the subsequent processing stages. We
propose novel, principled - yet practical - probabilistic score-based methods
that learn the relational dependencies as distributions over graphs while
maximizing end-to-end the performance at task. The proposed graph learning
framework is based on consolidated variance reduction techniques for Monte
Carlo score-based gradient estimation, is theoretically grounded, and, as we
show, effective in practice. In this paper, we focus on the time series
forecasting problem and show that, by tailoring the gradient estimators to the
graph learning problem, we are able to achieve state-of-the-art performance
while controlling the sparsity of the learned graph and the computational
scalability. We empirically assess the effectiveness of the proposed method on
synthetic and real-world benchmarks, showing that the proposed solution can be
used as a stand-alone graph identification procedure as well as a graph
learning component of an end-to-end forecasting architecture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.02231">Models of human preference for learning reward functions. (arXiv:2206.02231v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Knox_W/0/1/0/all/0/1">W. Bradley Knox</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatgis_Kessell_S/0/1/0/all/0/1">Stephane Hatgis-Kessell</a>, <a href="http://arxiv.org/find/cs/1/au:+Booth_S/0/1/0/all/0/1">Serena Booth</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1">Peter Stone</a>, <a href="http://arxiv.org/find/cs/1/au:+Allievi_A/0/1/0/all/0/1">Alessandro Allievi</a></p>
<p>The utility of reinforcement learning is limited by the alignment of reward
functions with the interests of human stakeholders. One promising method for
alignment is to learn the reward function from human-generated preferences
between pairs of trajectory segments, a type of reinforcement learning from
human feedback (RLHF). These human preferences are typically assumed to be
informed solely by partial return, the sum of rewards along each segment. We
find this assumption to be flawed and propose modeling human preferences
instead as informed by each segment's regret, a measure of a segment's
deviation from optimal decision-making. Given infinitely many preferences
generated according to regret, we prove that we can identify a reward function
equivalent to the reward function that generated those preferences, and we
prove that the previous partial return model lacks this identifiability
property in multiple contexts. We empirically show that our proposed regret
preference model outperforms the partial return preference model with finite
training data in otherwise the same setting. Additionally, we find that our
proposed regret preference model better predicts real human preferences and
also learns reward functions from these preferences that lead to policies that
are better human-aligned. Overall, this work establishes that the choice of
preference model is impactful, and our proposed regret preference model
provides an improvement upon a core assumption of recent research. We have open
sourced our experimental code, the human preferences dataset we gathered, and
our training and preference elicitation interfaces for gathering a such a
dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.13964">Graph Soft-Contrastive Learning via Neighborhood Ranking. (arXiv:2209.13964v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1">Zhiyuan Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengfei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1">Ziyue Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Denghui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yi Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuanchun Zhou</a></p>
<p>Graph Contrastive Learning (GCL) has emerged as a promising approach in the
realm of graph self-supervised learning. Prevailing GCL methods mainly derive
from the principles of contrastive learning in the field of computer vision:
modeling invariance by specifying absolutely similar pairs. However, when
applied to graph data, this paradigm encounters two significant limitations:
(1) the validity of the generated views cannot be guaranteed: graph
perturbation may produce invalid views against semantics and intrinsic topology
of graph data; (2) specifying absolutely similar pairs in the graph views is
unreliable: for abstract and non-Euclidean graph data, it is difficult for
humans to decide the absolute similarity and dissimilarity intuitively. Despite
the notable performance of current GCL methods, these challenges necessitate a
reevaluation: Could GCL be more effectively tailored to the intrinsic
properties of graphs, rather than merely adopting principles from computer
vision? In response to this query, we propose a novel paradigm, Graph
Soft-Contrastive Learning (GSCL). This approach facilitates GCL via
neighborhood ranking, avoiding the need to specify absolutely similar pairs.
GSCL leverages the underlying graph characteristic of diminishing label
consistency, asserting that nodes that are closer in the graph are overall more
similar than far-distant nodes. Within the GSCL framework, we introduce
pairwise and listwise gated ranking InfoNCE loss functions to effectively
preserve the relative similarity ranking within neighborhoods. Moreover, as the
neighborhood size exponentially expands with more hops considered, we propose
neighborhood sampling strategies to improve learning efficiency. Our extensive
empirical results across 11 commonly used graph datasets-including 8 homophily
graphs and 3 heterophily graphs-demonstrate GSCL's superior performance
compared to 20 SOTA GCL methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.07420">Learning to Efficiently Plan Robust Frictional Multi-Object Grasps. (arXiv:2210.07420v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agboh_W/0/1/0/all/0/1">Wisdom C. Agboh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Satvik Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivas_K/0/1/0/all/0/1">Kishore Srinivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Parulekar_M/0/1/0/all/0/1">Mallika Parulekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_G/0/1/0/all/0/1">Gaurav Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1">Tianshuang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ichnowski_J/0/1/0/all/0/1">Jeffrey Ichnowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Solowjow_E/0/1/0/all/0/1">Eugen Solowjow</a>, <a href="http://arxiv.org/find/cs/1/au:+Dogar_M/0/1/0/all/0/1">Mehmet Dogar</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1">Ken Goldberg</a></p>
<p>We consider a decluttering problem where multiple rigid convex polygonal
objects rest in randomly placed positions and orientations on a planar surface
and must be efficiently transported to a packing box using both single and
multi-object grasps. Prior work considered frictionless multi-object grasping.
In this paper, we introduce friction to increase the number of potential grasps
for a given group of objects, and thus increase picks per hour. We train a
neural network using real examples to plan robust multi-object grasps. In
physical experiments, we find a 13.7% increase in success rate, a 1.6x increase
in picks per hour, and a 6.3x decrease in grasp planning time compared to prior
work on multi-object grasping. Compared to single-object grasping, we find a
3.1x increase in picks per hour.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.08549">Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Hou_P/0/1/0/all/0/1">Po-Han Hou</a>, <a href="http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1">Wei-Chih Lin</a>, <a href="http://arxiv.org/find/stat/1/au:+Hou_H/0/1/0/all/0/1">Hong-Chun Hou</a>, <a href="http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Hao Huang</a>, <a href="http://arxiv.org/find/stat/1/au:+Shue_J/0/1/0/all/0/1">Jih-Hong Shue</a></p>
<p>With a rising attention for the issue of PM2.5 or PM0.3, particulate matters
have become not only a potential threat to both the environment and human, but
also a harming existence to instruments onboard International Space Station
(ISS). Our team is aiming to relate various concentration of particulate
matters to magnetic fields, humidity, acceleration, temperature, pressure and
CO2 concentration. Our goal is to establish an early warning system (EWS),
which is able to forecast the levels of particulate matters and provides ample
reaction time for astronauts to protect their instruments in some experiments
or increase the accuracy of the measurements; In addition, the constructed
model can be further developed into a prototype of a remote-sensing smoke alarm
for applications related to fires. In this article, we will implement the
Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for
past 90 minutes and predict the levels of particulates which over 2.5
micrometer per 0.1 liter for the next 1 minute, which is classified as an early
warning
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.05206">Thinking Fast and Slow in Large Language Models. (arXiv:2212.05206v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hagendorff_T/0/1/0/all/0/1">Thilo Hagendorff</a>, <a href="http://arxiv.org/find/cs/1/au:+Fabi_S/0/1/0/all/0/1">Sarah Fabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosinski_M/0/1/0/all/0/1">Michal Kosinski</a></p>
<p>Large language models (LLMs) are currently at the forefront of intertwining
AI systems with human communication and everyday life. Therefore, it is of
great importance to evaluate their emerging abilities. In this study, we show
that LLMs like GPT-3 exhibit behavior that strikingly resembles human-like
intuition - and the cognitive errors that come with it. However, LLMs with
higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to
avoid succumbing to these errors and perform in a hyperrational manner. For our
experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as
semantic illusions that were originally designed to investigate intuitive
decision-making in humans. Our study demonstrates that investigating LLMs with
methods from psychology has the potential to reveal otherwise unknown emergent
traits.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.07337">Graph Attention Multi-Agent Fleet Autonomy for Advanced Air Mobility. (arXiv:2302.07337v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fernando_M/0/1/0/all/0/1">Malintha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Senanayake_R/0/1/0/all/0/1">Ransalu Senanayake</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Heeyoul Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Swany_M/0/1/0/all/0/1">Martin Swany</a></p>
<p>Autonomous mobility is emerging as a new disruptive mode of urban
transportation for moving cargo and passengers. However, designing scalable
autonomous fleet coordination schemes to accommodate fast-growing mobility
systems is challenging primarily due to the increasing heterogeneity of the
fleets, time-varying demand patterns, service area expansions, and
communication limitations. We introduce the concept of partially observable
advanced air mobility games to coordinate a fleet of aerial vehicles by
accounting for the heterogeneity of the interacting agents and the
self-interested nature inherent to commercial mobility fleets. To model the
complex interactions among the agents and the observation uncertainty in the
mobility networks, we propose a novel heterogeneous graph attention
encoder-decoder (HetGAT Enc-Dec) neural network-based stochastic policy. We
train the policy by leveraging deep multi-agent reinforcement learning,
allowing decentralized decision-making for the agents using their local
observations. Through extensive experimentation, we show that the learned
policy generalizes to various fleet compositions, demand patterns, and
observation topologies. Further, fleets operating under the HetGAT Enc-Dec
policy outperform other state-of-the-art graph neural network policies by
achieving the highest fleet reward and fulfillment ratios in on-demand mobility
networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.01584">Evolutionary Augmentation Policy Optimization for Self-supervised Learning. (arXiv:2303.01584v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barrett_N/0/1/0/all/0/1">Noah Barrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadeghi_Z/0/1/0/all/0/1">Zahra Sadeghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1">Stan Matwin</a></p>
<p>Self-supervised Learning (SSL) is a machine learning algorithm for
pretraining Deep Neural Networks (DNNs) without requiring manually labeled
data. The central idea of this learning technique is based on an auxiliary
stage aka pretext task in which labeled data are created automatically through
data augmentation and exploited for pretraining the DNN. However, the effect of
each pretext task is not well studied or compared in the literature. In this
paper, we study the contribution of augmentation operators on the performance
of self supervised learning algorithms in a constrained settings. We propose an
evolutionary search method for optimization of data augmentation pipeline in
pretext tasks and measure the impact of augmentation operators in several SOTA
SSL algorithms. By encoding different combination of augmentation operators in
chromosomes we seek the optimal augmentation policies through an evolutionary
optimization mechanism. We further introduce methods for analyzing and
explaining the performance of optimized SSL algorithms. Our results indicate
that our proposed method can find solutions that outperform the accuracy of
classification of SSL algorithms which confirms the influence of augmentation
policy choice on the overall performance of SSL algorithms. We also compare
optimal SSL solutions found by our evolutionary search mechanism and show the
effect of batch size in the pretext task on two visual datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02139">Data Association Aware POMDP Planning with Hypothesis Pruning Performance Guarantees. (arXiv:2303.02139v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barenboim_M/0/1/0/all/0/1">Moran Barenboim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lev_Yehudi_I/0/1/0/all/0/1">Idan Lev-Yehudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Indelman_V/0/1/0/all/0/1">Vadim Indelman</a></p>
<p>Autonomous agents that operate in the real world must often deal with partial
observability, which is commonly modeled as partially observable Markov
decision processes (POMDPs). However, traditional POMDP models rely on the
assumption of complete knowledge of the observation source, known as fully
observable data association. To address this limitation, we propose a planning
algorithm that maintains multiple data association hypotheses, represented as a
belief mixture, where each component corresponds to a different data
association hypothesis. However, this method can lead to an exponential growth
in the number of hypotheses, resulting in significant computational overhead.
To overcome this challenge, we introduce a pruning-based approach for planning
with ambiguous data associations. Our key contribution is to derive bounds
between the value function based on the complete set of hypotheses and the
value function based on a pruned-subset of the hypotheses, enabling us to
establish a trade-off between computational efficiency and performance. We
demonstrate how these bounds can both be used to certify any pruning heuristic
in retrospect and propose a novel approach to determine which hypotheses to
prune in order to ensure a predefined limit on the loss. We evaluate our
approach in simulated environments and demonstrate its efficacy in handling
multi-modal belief hypotheses with ambiguous data associations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16132">Transformer and Snowball Graph Convolution Learning for Brain functional network Classification. (arXiv:2303.16132v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jinlong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yangmin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shoubin Dong</a></p>
<p>Advanced deep learning methods, especially graph neural networks (GNNs), are
increasingly expected to learn from brain functional network data and predict
brain disorders. In this paper, we proposed a novel Transformer and snowball
encoding networks (TSEN) for brain functional network classification, which
introduced Transformer architecture with graph snowball connection into GNNs
for learning whole-graph representation. TSEN combined graph snowball
connection with graph Transformer by snowball encoding layers, which enhanced
the power to capture multi-scale information and global patterns of brain
functional networks. TSEN also introduced snowball graph convolution as
position embedding in Transformer structure, which was a simple yet effective
method for capturing local patterns naturally. We evaluated the proposed model
by two large-scale brain functional network datasets from autism spectrum
disorder and major depressive disorder respectively, and the results
demonstrated that TSEN outperformed the state-of-the-art GNN models and the
graph-transformer based GNN models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.00365">A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Energy Optimization for Smart Buildings. (arXiv:2305.00365v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Genkin_M/0/1/0/all/0/1">Mikhail Genkin</a>, <a href="http://arxiv.org/find/cs/1/au:+McArthur_J/0/1/0/all/0/1">J.J. McArthur</a></p>
<p>Energy optimization leveraging artificially intelligent algorithms has been
proven effective. However, when buildings are commissioned, there is no
historical data that could be used to train these algorithms. On-line
Reinforcement Learning (RL) algorithms have shown significant promise, but
their deployment carries a significant risk, because as the RL agent initially
explores its action space it could cause significant discomfort to the building
residents. In this paper we present ReLBOT - a new technique that uses transfer
learning in conjunction with deep RL to transfer knowledge from an existing,
optimized and instrumented building, to the newly commissioning smart building,
to reduce the adverse impact of the reinforcement learning agent's warm-up
period. We demonstrate improvements of up to 6.2 times in the duration, and up
to 132 times in prediction variance, for the reinforcement learning agent's
warm-up period.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.03701">LMEye: An Interactive Perception Network for Large Language Models. (arXiv:2305.03701v5 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Baotian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a></p>
<p>Training a Large Visual Language Model (LVLM) from scratch, like GPT-4, is
resource-intensive. Our paper presents a play-and-plug module for Large
Language Models (LLMs), namely Interactive Perception Network (IPN), aiming to
achieve a LVLM by incorporating the image understanding capability into LLMs.
Previous methods incorporate visual information into LLMs with a simple visual
mapping network, where the image feature is projected into the embedding space
of LLMs via a linear layer. Such mapping network projects the image feature
once yet does not consider the interaction between the image and the human
input query. Hence, the obtained visual information with no connections with
human intention may be inadequate for LLMs to make intention-following
responses, which we term as static visual information. IPN addresses this issue
by allowing the LLM to request the desired visual information aligned with
various human instructions, which we term as the dynamic interaction between
the LLM and visual information. Specifically, IPN consists of a simple visual
mapping network to provide the basic perception of an image for LLMs. It also
contains additional modules responsible for acquiring requests from LLMs,
performing request-based visual information interaction, and transmitting the
resulting interacted visual information to LLMs, respectively. In this way,
LLMs act to understand the human query, deliver the corresponding request to
the request-based visual information interaction module, and generate the
response based on the interleaved multimodal information. We evaluate IPN
through extensive experiments on multimodal question answering, reasoning, and
so on, demonstrating that it significantly improves the zero-shot performance
of LVLMs on various multimodal tasks compared to previous methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.04312">The Human-or-Machine Matter: Turing-Inspired Reflections on an Everyday Issue. (arXiv:2305.04312v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Harel_D/0/1/0/all/0/1">David Harel</a>, <a href="http://arxiv.org/find/cs/1/au:+Marron_A/0/1/0/all/0/1">Assaf Marron</a></p>
<p>In his seminal paper ``Computing Machinery and Intelligence'', Alan Turing
introduced the ``imitation game'' as part of exploring the concept of machine
intelligence. The Turing Test has since been the subject of much analysis,
debate, refinement and extension. Here we sidestep the question of whether a
particular machine can be labeled intelligent, or can be said to match human
capabilities in a given context. Instead, we first draw attention to the
seemingly simpler question a person may ask themselves in an everyday
interaction: ``Am I interacting with a human or with a machine?''. We then
shift the focus from seeking a method for eliciting the answer, and, rather,
reflect upon the importance and significance of this Human-or-Machine question
and the use one may make of a reliable answer thereto. Whereas Turing's
original test is widely considered to be more of a thought experiment, the
Human-or-Machine matter as discussed here has obvious practical relevance.
While it is still unclear if and when machines will be able to mimic human
behavior with high fidelity in everyday contexts, we argue that near-term
exploration of the issues raised here can contribute to refinement of methods
for developing computerized systems, and may also lead to new insights into
fundamental characteristics of human behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11322">Knowing When to Stop: Delay-Adaptive Spiking Neural Network Classifiers with Reliability Guarantees. (arXiv:2305.11322v2 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiechen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sangwoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1">Osvaldo Simeone</a></p>
<p>Spiking neural networks (SNNs) process time-series data via internal
event-driven neural dynamics whose energy consumption depends on the number of
spikes exchanged between neurons over the course of the input presentation.
Typically, decisions are produced after the entire input sequence has been
processed, resulting in latency and energy consumption levels that are fairly
uniform across inputs. However, as explored in recent work, SNNs can produce an
early decision when the SNN model is sufficiently ``confident'', adapting delay
and energy consumption to the difficulty of each example. Existing techniques
are based on heuristic measures of confidence that do not provide reliability
guarantees, potentially exiting too early. In this paper, we introduce a novel
delay-adaptive SNN-based inference methodology that, wrapping around any
pre-trained SNN classifier, provides guaranteed reliability for the decisions
produced at input-dependent stopping times. The approach, dubbed SpikeCP,
leverages tools from conformal prediction (CP), and it entails minimal
complexity increase as compared to the underlying SNN, requiring only
additional thresholding and counting operations at run time. SpikeCP is also
extended to integrate a CP-aware training phase that targets delay performance.
Variants of CP based on alternative confidence correction schemes, from
Bonferroni to Simes, are explored, and extensive experiments are described
using the MNIST-DVS data set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11900">ChatGPT and the Labor Market: Unraveling the Effect of AI Discussions on Students&#x27; Earnings Expectations. (arXiv:2305.11900v2 [econ.GN] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Huseynov_S/0/1/0/all/0/1">Samir Huseynov</a></p>
<p>This paper investigates the causal impact of negatively and positively toned
ChatGPT Artificial Intelligence (AI) discussions on US students' anticipated
labor market outcomes. Our findings reveal students reduce their confidence
regarding their future earnings prospects after exposure to AI debates, and
this effect is more pronounced after reading discussion excerpts with a
negative tone. Unlike STEM majors, students in Non-STEM fields show asymmetric
and pessimistic belief changes, suggesting that they might feel more vulnerable
to emerging AI technologies. Pessimistic belief updates regarding future
earnings are also prevalent among non-male students, indicating widespread AI
concerns among vulnerable student subgroups. Educators, administrators, and
policymakers may regularly engage with students to address their concerns and
enhance educational curricula to better prepare them for a future that AI will
inevitably shape.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19569">Domain knowledge-informed Synthetic fault sample generation with Health Data Map for cross-domain Planetary Gearbox Fault Diagnosis. (arXiv:2305.19569v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1">Jong Moon Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Fink_O/0/1/0/all/0/1">Olga Fink</a></p>
<p>Extensive research has been conducted on fault diagnosis of planetary
gearboxes using vibration signals and deep learning (DL) approaches. However,
DL-based methods are susceptible to the domain shift problem caused by varying
operating conditions of the gearbox. Although domain adaptation and data
synthesis methods have been proposed to overcome such domain shifts, they are
often not directly applicable in real-world situations where only healthy data
is available in the target domain. To tackle the challenge of extreme domain
shift scenarios where only healthy data is available in the target domain, this
paper proposes two novel domain knowledge-informed data synthesis methods
utilizing the health data map (HDMap). The two proposed approaches are referred
to as scaled CutPaste and FaultPaste. The HDMap is used to physically represent
the vibration signal of the planetary gearbox as an image-like matrix, allowing
for visualization of fault-related features. CutPaste and FaultPaste are then
applied to generate faulty samples based on the healthy data in the target
domain, using domain knowledge and fault signatures extracted from the source
domain, respectively. In addition to generating realistic faults, the proposed
methods introduce scaling of fault signatures for controlled synthesis of
faults with various severity levels. A case study is conducted on a planetary
gearbox testbed to evaluate the proposed approaches. The results show that the
proposed methods are capable of accurately diagnosing faults, even in cases of
extreme domain shift, and can estimate the severity of faults that have not
been previously observed in the target domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05150">Bayesian Optimization of Expensive Nested Grey-Box Functions. (arXiv:2306.05150v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenjie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuning Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Svetozarevic_B/0/1/0/all/0/1">Bratislav Svetozarevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1">Colin N. Jones</a></p>
<p>We consider the problem of optimizing a grey-box objective function, i.e.,
nested function composed of both black-box and white-box functions. A general
formulation for such grey-box problems is given, which covers the existing
grey-box optimization formulations as special cases. We then design an
optimism-driven algorithm to solve it. Under certain regularity assumptions,
our algorithm achieves similar regret bound as that for the standard black-box
Bayesian optimization algorithm, up to a constant multiplicative term depending
on the Lipschitz constants of the functions considered. We further extend our
method to the constrained case and discuss special cases. For the commonly used
kernel functions, the regret bounds allow us to derive a convergence rate to
the optimal solution. Experimental results show that our grey-box optimization
method empirically improves the speed of finding the global optimal solution
significantly, as compared to the standard black-box optimization algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.10940">TeleViT: Teleconnection-driven Transformers Improve Subseasonal to Seasonal Wildfire Forecasting. (arXiv:2306.10940v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Prapas_I/0/1/0/all/0/1">Ioannis Prapas</a>, <a href="http://arxiv.org/find/cs/1/au:+Bountos_N/0/1/0/all/0/1">Nikolaos Ioannis Bountos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondylatos_S/0/1/0/all/0/1">Spyros Kondylatos</a>, <a href="http://arxiv.org/find/cs/1/au:+Michail_D/0/1/0/all/0/1">Dimitrios Michail</a>, <a href="http://arxiv.org/find/cs/1/au:+Camps_Valls_G/0/1/0/all/0/1">Gustau Camps-Valls</a>, <a href="http://arxiv.org/find/cs/1/au:+Papoutsis_I/0/1/0/all/0/1">Ioannis Papoutsis</a></p>
<p>Wildfires are increasingly exacerbated as a result of climate change,
necessitating advanced proactive measures for effective mitigation. It is
important to forecast wildfires weeks and months in advance to plan forest fuel
management, resource procurement and allocation. To achieve such accurate
long-term forecasts at a global scale, it is crucial to employ models that
account for the Earth system's inherent spatio-temporal interactions, such as
memory effects and teleconnections. We propose a teleconnection-driven vision
transformer (TeleViT), capable of treating the Earth as one interconnected
system, integrating fine-grained local-scale inputs with global-scale inputs,
such as climate indices and coarse-grained global variables. Through
comprehensive experimentation, we demonstrate the superiority of TeleViT in
accurately predicting global burned area patterns for various forecasting
windows, up to four months in advance. The gain is especially pronounced in
larger forecasting windows, demonstrating the improved ability of deep learning
models that exploit teleconnections to capture Earth system dynamics. Code
available at https://github.com/Orion-Ai-Lab/TeleViT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.15550">CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Touchent_R/0/1/0/all/0/1">Rian Touchent</a>, <a href="http://arxiv.org/find/cs/1/au:+Romary_L/0/1/0/all/0/1">Laurent Romary</a>, <a href="http://arxiv.org/find/cs/1/au:+Clergerie_E/0/1/0/all/0/1">Eric de la Clergerie</a></p>
<p>Clinical data in hospitals are increasingly accessible for research through
clinical data warehouses, however these documents are unstructured. It is
therefore necessary to extract information from medical reports to conduct
clinical studies. Transfer learning with BERT-like models such as CamemBERT has
allowed major advances, especially for named entity recognition. However, these
models are trained for plain language and are less efficient on biomedical
data. This is why we propose a new French public biomedical dataset on which we
have continued the pre-training of CamemBERT. Thus, we introduce a first
version of CamemBERT-bio, a specialized public model for the French biomedical
domain that shows 2.54 points of F1 score improvement on average on different
biomedical named entity recognition tasks. Our findings demonstrate the success
of continual pre-training from a French model and contrast with recent
proposals on the same domain and language. One of our key contributions
highlights the importance of using a standard evaluation protocol that enables
a clear view of the current state-of-the-art for French biomedical models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00925">Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1">Jorge Martinez-Gil</a></p>
<p>Semantic similarity measures are widely used in natural language processing
to catalyze various computer-related tasks. However, no single semantic
similarity measure is the most appropriate for all tasks, and researchers often
use ensemble strategies to ensure performance. This research work proposes a
method for automatically designing semantic similarity ensembles. In fact, our
proposed method uses grammatical evolution, for the first time, to
automatically select and aggregate measures from a pool of candidates to create
an ensemble that maximizes correlation to human judgment. The method is
evaluated on several benchmark datasets and compared to state-of-the-art
ensembles, showing that it can significantly improve similarity assessment
accuracy and outperform existing methods in some cases. As a result, our
research demonstrates the potential of using grammatical evolution to
automatically compare text and prove the benefits of using ensembles for
semantic similarity tasks. The source code that illustrates our approach can be
downloaded from https://github.com/jorge-martinez-gil/sesige.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03109">A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v6 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yupeng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Linyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1">Kaijie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xiaoyuan Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cunxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1">Wei Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where' and `how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03393">Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs. (arXiv:2307.03393v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhikai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Haitao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Hongzhi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaochi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuaiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dawei Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a></p>
<p>Learning on Graphs has attracted immense attention due to its wide real-world
applications. The most popular pipeline for learning on graphs with textual
node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes
shallow text embedding as initial node representations, which has limitations
in general knowledge and profound semantic understanding. In recent years,
Large Language Models (LLMs) have been proven to possess extensive common
knowledge and powerful semantic comprehension abilities that have
revolutionized existing workflows to handle text data. In this paper, we aim to
explore the potential of LLMs in graph machine learning, especially the node
classification task, and investigate two possible pipelines: LLMs-as-Enhancers
and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text
attributes with their massive knowledge and then generate predictions through
GNNs. The latter attempts to directly employ LLMs as standalone predictors. We
conduct comprehensive and systematical studies on these two pipelines under
various settings. From comprehensive empirical results, we make original
observations and find new insights that open new possibilities and suggest
promising directions to leverage LLMs for learning on graphs. Our codes and
datasets are available at https://github.com/CurryTang/Graph-LLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14510">Attention for Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control. (arXiv:2307.14510v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yijiong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Comi_M/0/1/0/all/0/1">Mauro Comi</a>, <a href="http://arxiv.org/find/cs/1/au:+Church_A/0/1/0/all/0/1">Alex Church</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dandan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepora_N/0/1/0/all/0/1">Nathan F. Lepora</a></p>
<p>High-resolution tactile sensing can provide accurate information about local
contact in contact-rich robotic tasks. However, the deployment of such tasks in
unstructured environments remains under-investigated. To improve the robustness
of tactile robot control in unstructured environments, we propose and study a
new concept: \textit{tactile saliency} for robot touch, inspired by the human
touch attention mechanism from neuroscience and the visual saliency prediction
problem from computer vision. In analogy to visual saliency, this concept
involves identifying key information in tactile images captured by a tactile
sensor. While visual saliency datasets are commonly annotated by humans,
manually labelling tactile images is challenging due to their counterintuitive
patterns. To address this challenge, we propose a novel approach comprised of
three interrelated networks: 1) a Contact Depth Network (ConDepNet), which
generates a contact depth map to localize deformation in a real tactile image
that contains target and noise features; 2) a Tactile Saliency Network
(TacSalNet), which predicts a tactile saliency map to describe the target areas
for an input contact depth map; 3) and a Tactile Noise Generator (TacNGen),
which generates noise features to train the TacSalNet. Experimental results in
contact pose estimation and edge-following in the presence of distractors
showcase the accurate prediction of target features from real tactile images.
Overall, our tactile saliency prediction approach gives robust sim-to-real
tactile control in environments with unknown distractors. Project page:
https://sites.google.com/view/tactile-saliency/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.15801">Primitive Skill-based Robot Learning from Human Evaluative Feedback. (arXiv:2307.15801v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hiranaka_A/0/1/0/all/0/1">Ayano Hiranaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_M/0/1/0/all/0/1">Minjune Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sharon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a></p>
<p>Reinforcement learning (RL) algorithms face significant challenges when
dealing with long-horizon robot manipulation tasks in real-world environments
due to sample inefficiency and safety issues. To overcome these challenges, we
propose a novel framework, SEED, which leverages two approaches: reinforcement
learning from human feedback (RLHF) and primitive skill-based reinforcement
learning. Both approaches are particularly effective in addressing sparse
reward issues and the complexities involved in long-horizon tasks. By combining
them, SEED reduces the human effort required in RLHF and increases safety in
training robot manipulation with RL in real-world settings. Additionally,
parameterized skills provide a clear view of the agent's high-level intentions,
allowing humans to evaluate skill choices before they are executed. This
feature makes the training process even safer and more efficient. To evaluate
the performance of SEED, we conducted extensive experiments on five
manipulation tasks with varying levels of complexity. Our results show that
SEED significantly outperforms state-of-the-art RL algorithms in sample
efficiency and safety. In addition, SEED also exhibits a substantial reduction
of human effort compared to other RLHF methods. Further details and video
results can be found at https://seediros23.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.16648">LLMs4OL: Large Language Models for Ontology Learning. (arXiv:2307.16648v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Giglou_H/0/1/0/all/0/1">Hamed Babaei Giglou</a>, <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a></p>
<p>We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)
for Ontology Learning (OL). LLMs have shown significant advancements in natural
language processing, demonstrating their ability to capture complex language
patterns in different knowledge domains. Our LLMs4OL paradigm investigates the
following hypothesis: \textit{Can LLMs effectively apply their language pattern
capturing capability to OL, which involves automatically extracting and
structuring knowledge from natural language text?} To test this hypothesis, we
conduct a comprehensive evaluation using the zero-shot prompting method. We
evaluate nine different LLM model families for three main OL tasks: term
typing, taxonomy discovery, and extraction of non-taxonomic relations.
Additionally, the evaluations encompass diverse genres of ontological
knowledge, including lexicosemantic knowledge in WordNet, geographical
knowledge in GeoNames, and medical knowledge in UMLS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.16773">AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder. (arXiv:2307.16773v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tianxing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xudong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yipeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feiyue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_T/0/1/0/all/0/1">Tianling Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_S/0/1/0/all/0/1">Shenqi Jing</a></p>
<p>To easily obtain the knowledge about autism spectrum disorder and help its
early screening and diagnosis, we create AsdKB, a Chinese knowledge base on
autism spectrum disorder. The knowledge base is built on top of various
sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical
descriptions on mental and behavioural disorders, 2) the diagnostic knowledge
from DSM-5 and different screening tools recommended by social organizations
and medical institutes, and 3) the expert knowledge on professional physicians
and hospitals from the Web. AsdKB contains both ontological and factual
knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The
potential applications of AsdKB are question answering, auxiliary diagnosis,
and expert recommendation, and we illustrate them with a prototype which can be
accessed at <a href="http://asdkb.org.cn/.">this http URL</a>
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00081">Towards Semantically Enriched Embeddings for Knowledge Graph Completion. (arXiv:2308.00081v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1">Mehwish Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Harmelen_F/0/1/0/all/0/1">Frank van Harmelen</a>, <a href="http://arxiv.org/find/cs/1/au:+Acosta_M/0/1/0/all/0/1">Maribel Acosta</a></p>
<p>Embedding based Knowledge Graph (KG) Completion has gained much attention
over the past few years. Most of the current algorithms consider a KG as a
multidirectional labeled graph and lack the ability to capture the semantics
underlying the schematic information. In a separate development, a vast amount
of information has been captured within the Large Language Models (LLMs) which
has revolutionized the field of Artificial Intelligence. KGs could benefit from
these LLMs and vice versa. This vision paper discusses the existing algorithms
for KG completion based on the variations for generating KG embeddings. It
starts with discussing various KG completion algorithms such as transductive
and inductive link prediction and entity type prediction algorithms. It then
moves on to the algorithms utilizing type information within the KGs, LLMs, and
finally to algorithms capturing the semantics represented in different
description logic axioms. We conclude the paper with a critical reflection on
the current state of work in the community and give recommendations for future
directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00352">MetaGPT: Meta Programming for Multi-Agent Collaborative Framework. (arXiv:2308.00352v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1">Sirui Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiawu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jonathan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yuheng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ceyao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zili Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yau_S/0/1/0/all/0/1">Steven Ka Shing Yau</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zijuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Liyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_C/0/1/0/all/0/1">Chenyu Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Lingfeng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenglin Wu</a></p>
<p>Recently, remarkable progress has been made in automated task-solving through
the use of multi-agents driven by large language models (LLMs). However,
existing works primarily focuses on simple tasks lacking exploration and
investigation in complicated tasks mainly due to the hallucination problem.
This kind of hallucination gets amplified infinitely as multiple intelligent
agents interact with each other, resulting in failures when tackling
complicated problems.Therefore, we introduce MetaGPT, an innovative framework
that infuses effective human workflows as a meta programming approach into
LLM-driven multi-agent collaboration. In particular, MetaGPT first encodes
Standardized Operating Procedures (SOPs) into prompts, fostering structured
coordination. And then, it further mandates modular outputs, bestowing agents
with domain expertise paralleling human professionals to validate outputs and
reduce compounded errors. In this way, MetaGPT leverages the assembly line work
model to assign diverse roles to various agents, thus establishing a framework
that can effectively and cohesively deconstruct complex multi-agent
collaborative problems. Our experiments conducted on collaborative software
engineering tasks illustrate MetaGPT's capability in producing comprehensive
solutions with higher coherence relative to existing conversational and
chat-based multi-agent systems. This underscores the potential of incorporating
human domain knowledge into multi-agents, thus opening up novel avenues for
grappling with intricate real-world challenges. The GitHub repository of this
project is made publicly available on: https://github.com/geekan/MetaGPT
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00436">SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Miao_N/0/1/0/all/0/1">Ning Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a></p>
<p>The recent progress in large language models (LLMs), especially the invention
of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning
problems. However, even the strongest LLMs are still struggling with more
complicated problems that require non-linear thinking and multi-step reasoning.
In this work, we explore whether LLMs have the ability to recognize their own
errors, without resorting to external resources. In particular, we investigate
whether they can be used to identify individual errors within a step-by-step
reasoning. To this end, we propose a zero-shot verification scheme to recognize
such errors. We then use this verification scheme to improve question-answering
performance, by using it to perform weighted voting on different generated
answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and
find that it successfully recognizes errors and, in turn, increases final
predictive performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13425">EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds. (arXiv:2305.13425v1 [cs.NE] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barbieux_A/0/1/0/all/0/1">Aidan Barbieux</a>, <a href="http://arxiv.org/find/cs/1/au:+Canaan_R/0/1/0/all/0/1">Rodrigo Canaan</a></p>
<p>This paper presents EINCASM, a prototype system employing a novel framework
for studying emergent intelligence in organisms resembling slime molds. EINCASM
evolves neural cellular automata with NEAT to maximize cell growth constrained
by nutrient and energy costs. These organisms capitalize physically simulated
fluid to transport nutrients and chemical-like signals to orchestrate growth
and adaptation to complex, changing environments. Our framework builds the
foundation for studying how the presence of puzzles, physics, communication,
competition and dynamic open-ended environments contribute to the emergence of
intelligent behavior. We propose preliminary tests for intelligence in such
organisms and suggest future work for more powerful systems employing EINCASM
to better understand intelligence in distributed dynamical systems.
</p>
</p>
</div>

    </div>
    </body>
    