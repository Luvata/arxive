<!DOCTYPE html>
<html>
<head>
<title>2023-12-21-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2312.11473">Synthetic Shifts to Initial Seed Vector Exposes the Brittle Nature of Latent-Based Diffusion Models. (arXiv:2312.11473v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Po_Yuan_M/0/1/0/all/0/1">Mao Po-Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1">Shashank Kotyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Foong_T/0/1/0/all/0/1">Tham Yik Foong</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1">Danilo Vasconcellos Vargas</a></p>
<p>Recent advances in Conditional Diffusion Models have led to substantial
capabilities in various domains. However, understanding the impact of
variations in the initial seed vector remains an underexplored area of concern.
Particularly, latent-based diffusion models display inconsistencies in image
generation under standard conditions when initialized with suboptimal initial
seed vectors. To understand the impact of the initial seed vector on generated
samples, we propose a reliability evaluation framework that evaluates the
generated samples of a diffusion model when the initial seed vector is
subjected to various synthetic shifts. Our results indicate that slight
manipulations to the initial seed vector of the state-of-the-art Stable
Diffusion (Rombach et al., 2022) can lead to significant disturbances in the
generated samples, consequently creating images without the effect of
conditioning variables. In contrast, GLIDE (Nichol et al., 2022) stands out in
generating reliable samples even when the initial seed vector is transformed.
Thus, our study sheds light on the importance of the selection and the impact
of the initial seed vector in the latent-based diffusion model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11475">A Hybrid SOM and K-means Model for Time Series Energy Consumption Clustering. (arXiv:2312.11475v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Majidi_F/0/1/0/all/0/1">Farideh Majidi</a></p>
<p>Energy consumption analysis plays a pivotal role in addressing the challenges
of sustainability and resource management. This paper introduces a novel
approach to effectively cluster monthly energy consumption patterns by
integrating two powerful techniques: Self-organizing maps and K-means
clustering. The proposed method aims to exploit the benefits of both of these
algorithms to enhance the accuracy and interpretability of clustering results
for a dataset in which finding patterns is difficult. The main focus of this
study is on a selection of time series energy consumption data from the Smart
meters in London dataset. The data was preprocessed and reduced in
dimensionality to capture essential temporal patterns while retaining their
underlying structures. The SOM algorithm was utilized to extract the central
representatives of the consumption patterns for each one of the houses over the
course of each month, effectively reducing the dimensionality of the dataset
and making it easier for analysis. Subsequently, the obtained SOM centroids
were clustered using K-means, a popular centroid-based clustering technique.
The experimental results demonstrated a significant silhouette score of 66%,
indicating strong intra-cluster cohesion and inter-cluster separation which
confirms the effectiveness of the proposed approach in the clustering task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11488">Low-Latency ML Inference by Grouping Correlated Data Objects and Computation. (arXiv:2312.11488v1 [cs.DC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garrett_T/0/1/0/all/0/1">Thiago Garrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Weijia Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Vitenberg_R/0/1/0/all/0/1">Roman Vitenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Birman_K/0/1/0/all/0/1">Ken Birman</a></p>
<p>ML inference workflows often require low latency and high throughput, yet we
lack good options for addressing this need. Techniques that reduce latency in
other streaming settings (such as caching and optimization-driven scheduling)
are of limited value because ML data dependencies are often very large and can
change dramatically depending on the triggering event. In this work, we propose
a novel correlation grouping mechanism that makes it easier for developers to
express application-specific data access correlations, enabling coordinated
management of data objects in server clusters hosting streaming inference
tasks. Experiments based on a latency-sensitive ML-based application confirm
the limitations of standard techniques while showing that our solution yields
dramatically better performance. The proposed mechanism is able to maintain
significantly lower and more consistent latency, achieves higher node
utilization as workload and scale-out increase, and yet requires only minor
changes to the code implementing the application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11492">Exploration-Exploitation Model of Moth-Inspired Olfactory Navigation. (arXiv:2312.11492v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lazebnik_T/0/1/0/all/0/1">Teddy Lazebnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Golov_Y/0/1/0/all/0/1">Yiftach Golov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurka_R/0/1/0/all/0/1">Roi Gurka</a>, <a href="http://arxiv.org/find/cs/1/au:+Harari_A/0/1/0/all/0/1">Ally Harari</a>, <a href="http://arxiv.org/find/cs/1/au:+Liberzon_A/0/1/0/all/0/1">Alex Liberzon</a></p>
<p>Navigation of male moths toward females during the mating search offers a
unique perspective on the exploration-exploitation (EE) model in
decision-making. This study uses the EE model to explain male moth
pheromone-driven flight paths. We leverage wind tunnel measurements and 3D
tracking using infrared cameras to gain insights into male moth behavior.
During the experiments in the wind tunnel, we add disturbance to the airflow
and analyze the effect of increased fluctuations on moth flights in the context
of the proposed EE model. We separate the exploration and exploitation phases
by applying a genetic algorithm to the dataset of moth 3D trajectories. First,
we demonstrate that the exploration-to-exploitation rate (EER) increases with
distance from the source of the female pheromone, which can be explained in the
context of the EE model. Furthermore, our findings reveal a compelling
relationship between EER and increased flow fluctuations near the pheromone
source. Using the open-source pheromone plume simulation and our moth-inspired
navigation model, we explain why male moths exhibit an enhanced EER as
turbulence levels increase, emphasizing the agent's adaptation to dynamically
changing environments. This research extends our understanding of optimal
navigation strategies based on general biological EE models and supports the
development of advanced, theoretically supported bio-inspired navigation
algorithms. We provide important insights into the potential of bio-inspired
navigation models for addressing complex decision-making challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11500">A Red Teaming Framework for Securing AI in Maritime Autonomous Systems. (arXiv:2312.11500v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1">Mathew J. Walter</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrett_A/0/1/0/all/0/1">Aaron Barrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Tam_K/0/1/0/all/0/1">Kimberly Tam</a></p>
<p>Artificial intelligence (AI) is being ubiquitously adopted to automate
processes in science and industry. However, due to its often intricate and
opaque nature, AI has been shown to possess inherent vulnerabilities which can
be maliciously exploited with adversarial AI, potentially putting AI users and
developers at both cyber and physical risk. In addition, there is insufficient
comprehension of the real-world effects of adversarial AI and an inadequacy of
AI security examinations; therefore, the growing threat landscape is unknown
for many AI solutions. To mitigate this issue, we propose one of the first red
team frameworks for evaluating the AI security of maritime autonomous systems.
The framework provides operators with a proactive (secure by design) and
reactive (post-deployment evaluation) response to securing AI technology today
and in the future. This framework is a multi-part checklist, which can be
tailored to different systems and requirements. We demonstrate this framework
to be highly effective for a red team to use to uncover numerous
vulnerabilities within a real-world maritime autonomous systems AI, ranging
from poisoning to adversarial patch attacks. The lessons learned from
systematic AI red teaming can help prevent MAS-related catastrophic events in a
world with increasing uptake and reliance on mission-critical AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11502">Labrador: Exploring the Limits of Masked Language Modeling for Laboratory Data. (arXiv:2312.11502v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bellamy_D/0/1/0/all/0/1">David R. Bellamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_B/0/1/0/all/0/1">Bhawesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cindy Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1">Andrew Beam</a></p>
<p>In this work we introduce Labrador, a pre-trained Transformer model for
laboratory data. Labrador and BERT were pre-trained on a corpus of 100 million
lab test results from electronic health records (EHRs) and evaluated on various
downstream outcome prediction tasks. Both models demonstrate mastery of the
pre-training task but neither consistently outperform XGBoost on downstream
supervised tasks. Our ablation studies reveal that transfer learning shows
limited effectiveness for BERT and achieves marginal success with Labrador. We
explore the reasons for the failure of transfer learning and suggest that the
data generating process underlying each patient cannot be characterized
sufficiently using labs alone, among other factors. We encourage future work to
focus on joint modeling of multiple EHR data categories and to include
tree-based baselines in their evaluations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11503">Speech and Text-Based Emotion Recognizer. (arXiv:2312.11503v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1">Varun Sharma</a></p>
<p>Affective computing is a field of study that focuses on developing systems
and technologies that can understand, interpret, and respond to human emotions.
Speech Emotion Recognition (SER), in particular, has got a lot of attention
from researchers in the recent past. However, in many cases, the publicly
available datasets, used for training and evaluation, are scarce and imbalanced
across the emotion labels. In this work, we focused on building a balanced
corpus from these publicly available datasets by combining these datasets as
well as employing various speech data augmentation techniques. Furthermore, we
experimented with different architectures for speech emotion recognition. Our
best system, a multi-modal speech, and text-based model, provides a performance
of UA(Unweighed Accuracy) + WA (Weighed Accuracy) of 157.57 compared to the
baseline algorithm performance of 119.66
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11504">The performance of multiple language models in identifying offensive language on social media. (arXiv:2312.11504v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_B/0/1/0/all/0/1">Brandon Bennett</a></p>
<p>Text classification is an important topic in the field of natural language
processing. It has been preliminarily applied in information retrieval, digital
library, automatic abstracting, text filtering, word semantic discrimination
and many other fields. The aim of this research is to use a variety of
algorithms to test the ability to identify offensive posts and evaluate their
performance against a variety of assessment methods. The motivation for this
project is to reduce the harm of these languages to human censors by automating
the screening of offending posts. The field is a new one, and despite much
interest in the past two years, there has been no focus on the object of the
offence. Through the experiment of this project, it should inspire future
research on identification methods as well as identification content.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11508">Variety and Quality over Quantity: Towards Versatile Instruction Curation. (arXiv:2312.11508v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yongqiang Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yufan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_M/0/1/0/all/0/1">Mengnan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Maoquan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1">Bin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1">Neel Sundaresan</a></p>
<p>Instruction fine-tuning, involving the refinement of pre-trained LLMs using
datasets accompanied by natural instructions, is a powerful approach. However,
its effectiveness is hindered by the redundancy and deficiencies in
LLM-generated instruction datasets. In this paper, we introduce a highly
effective and versatile paradigm for selecting diverse and high-quality
instruction-following data from fine-tuning datasets. We first employ the
dataset enhancement and expansion to augment the dataset with more diverse and
high-quality data, then we apply variety compression and quality compression
sequentially to curate the desired dataset. Our experimental results showcase
that, even with a limited quantity of high-quality instruction data, LLMs
consistently maintain robust performance across both natural language
understanding tasks and code generation tasks. Notably, they outperform models
trained on significantly larger instruction datasets in certain instances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11511">ComplexityNet: Increasing LLM Inference Efficiency by Learning Task Complexity. (arXiv:2312.11511v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bae_H/0/1/0/all/0/1">Henry Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Deeb_A/0/1/0/all/0/1">Aghyad Deeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleury_A/0/1/0/all/0/1">Alex Fleury</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1">Kehang Zhu</a></p>
<p>We present ComplexityNet, a streamlined language model designed for assessing
task complexity. This model predicts the likelihood of accurate output by
various language models, each with different capabilities. Our initial
application of ComplexityNet involves the Mostly Basic Python Problems (MBPP)
dataset. We pioneered the creation of the first set of labels to define task
complexity. ComplexityNet achieved a notable 79% accuracy in determining task
complexity, a significant improvement over the 34% accuracy of the original,
non fine-tuned model. Furthermore, ComplexityNet effectively reduces
computational resource usage by 90% compared to using the highest complexity
model, while maintaining a high code generation accuracy of 86.7%. This study
demonstrates that fine-tuning smaller models to categorize tasks based on their
complexity can lead to a more balanced trade-off between accuracy and
efficiency in the use of Large Language Models. Our findings suggest a
promising direction for optimizing LLM applications, especially in
resource-constrained environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11512">Path Signature Representation of Patient-Clinician Interactions as a Predictor for Neuropsychological Tests Outcomes in Children: A Proof of Concept. (arXiv:2312.11512v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Falcioni_G/0/1/0/all/0/1">Giulio Falcioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgescu_A/0/1/0/all/0/1">Alexandra Georgescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Molimpakis_E/0/1/0/all/0/1">Emilia Molimpakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottlieb_L/0/1/0/all/0/1">Lev Gottlieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_T/0/1/0/all/0/1">Taylor Kuhn</a>, <a href="http://arxiv.org/find/cs/1/au:+Goria_S/0/1/0/all/0/1">Stefano Goria</a></p>
<p>This research report presents a proof-of-concept study on the application of
machine learning techniques to video and speech data collected during
diagnostic cognitive assessments of children with a neurodevelopmental
disorder. The study utilised a dataset of 39 video recordings, capturing
extensive sessions where clinicians administered, among other things, four
cognitive assessment tests. From the first 40 minutes of each clinical session,
covering the administration of the Wechsler Intelligence Scale for Children
(WISC-V), we extracted head positions and speech turns of both clinician and
child. Despite the limited sample size and heterogeneous recording styles, the
analysis successfully extracted path signatures as features from the recorded
data, focusing on patient-clinician interactions. Importantly, these features
quantify the interpersonal dynamics of the assessment process (dialogue and
movement patterns). Results suggest that these features exhibit promising
potential for predicting all cognitive tests scores of the entire session
length and for prototyping a predictive model as a clinical decision support
tool. Overall, this proof of concept demonstrates the feasibility of leveraging
machine learning techniques for clinical video and speech data analysis in
order to potentially enhance the efficiency of cognitive assessments for
neurodevelopmental disorders in children.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11513">Maatphor: Automated Variant Analysis for Prompt Injection Attacks. (arXiv:2312.11513v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Salem_A/0/1/0/all/0/1">Ahmed Salem</a>, <a href="http://arxiv.org/find/cs/1/au:+Paverd_A/0/1/0/all/0/1">Andrew Paverd</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopf_B/0/1/0/all/0/1">Boris K&#xf6;pf</a></p>
<p>Prompt injection has emerged as a serious security threat to large language
models (LLMs). At present, the current best-practice for defending against
newly-discovered prompt injection techniques is to add additional guardrails to
the system (e.g., by updating the system prompt or using classifiers on the
input and/or output of the model.) However, in the same way that variants of a
piece of malware are created to evade anti-virus software, variants of a prompt
injection can be created to evade the LLM's guardrails. Ideally, when a new
prompt injection technique is discovered, candidate defenses should be tested
not only against the successful prompt injection, but also against possible
variants.
</p>
<p>In this work, we present, a tool to assist defenders in performing automated
variant analysis of known prompt injection attacks. This involves solving two
main challenges: (1) automatically generating variants of a given prompt
according, and (2) automatically determining whether a variant was effective
based only on the output of the model. This tool can also assist in generating
datasets for jailbreak and prompt injection attacks, thus overcoming the
scarcity of data in this domain.
</p>
<p>We evaluate Maatphor on three different types of prompt injection tasks.
Starting from an ineffective (0%) seed prompt, Maatphor consistently generates
variants that are at least 60% effective within the first 40 iterations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11514">LLM in a flash: Efficient Large Language Model Inference with Limited Memory. (arXiv:2312.11514v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alizadeh_K/0/1/0/all/0/1">Keivan Alizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirzadeh_I/0/1/0/all/0/1">Iman Mirzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Belenko_D/0/1/0/all/0/1">Dmitry Belenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Khatamifard_K/0/1/0/all/0/1">Karen Khatamifard</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1">Minsik Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Mundo_C/0/1/0/all/0/1">Carlo C Del Mundo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1">Mohammad Rastegari</a>, <a href="http://arxiv.org/find/cs/1/au:+Farajtabar_M/0/1/0/all/0/1">Mehrdad Farajtabar</a></p>
<p>Large language models (LLMs) are central to modern natural language
processing, delivering exceptional performance in various tasks. However, their
intensive computational and memory requirements present challenges, especially
for devices with limited DRAM capacity. This paper tackles the challenge of
efficiently running LLMs that exceed the available DRAM capacity by storing the
model parameters on flash memory but bringing them on demand to DRAM. Our
method involves constructing an inference cost model that harmonizes with the
flash memory behavior, guiding us to optimize in two critical areas: reducing
the volume of data transferred from flash and reading data in larger, more
contiguous chunks. Within this flash memory-informed framework, we introduce
two principal techniques. First, "windowing'" strategically reduces data
transfer by reusing previously activated neurons, and second, "row-column
bundling", tailored to the sequential data access strengths of flash memory,
increases the size of data chunks read from flash memory. These methods
collectively enable running models up to twice the size of the available DRAM,
with a 4-5x and 20-25x increase in inference speed compared to naive loading
approaches in CPU and GPU, respectively. Our integration of sparsity awareness,
context-adaptive loading, and a hardware-oriented design paves the way for
effective inference of LLMs on devices with limited memory.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11518">User Modeling in the Era of Large Language Models: Current Research and Future Directions. (arXiv:2312.11518v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhaoxuan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a></p>
<p>User modeling (UM) aims to discover patterns or learn representations from
user data about the characteristics of a specific user, such as profile,
preference, and personality. The user models enable personalization and
suspiciousness detection in many online applications such as recommendation,
education, and healthcare. Two common types of user data are text and graph, as
the data usually contain a large amount of user-generated content (UGC) and
online interactions. The research of text and graph mining is developing
rapidly, contributing many notable solutions in the past two decades. Recently,
large language models (LLMs) have shown superior performance on generating,
understanding, and even reasoning over text data. The approaches of user
modeling have been equipped with LLMs and soon become outstanding. This article
summarizes existing research about how and why LLMs are great tools of modeling
and understanding UGC. Then it reviews a few categories of large language
models for user modeling (LLM-UM) approaches that integrate the LLMs with text
and graph-based methods in different ways. Then it introduces specific LLM-UM
techniques for a variety of UM applications. Finally, it presents remaining
challenges and future directions in the LLM-UM research. We maintain the
reading list at: https://github.com/TamSiuhin/LLM-UM-Reading
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11521">Large Language Models are Complex Table Parsers. (arXiv:2312.11521v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bowen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_C/0/1/0/all/0/1">Changkai Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuejie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingwen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Rui Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaobo Zhang</a></p>
<p>With the Generative Pre-trained Transformer 3.5 (GPT-3.5) exhibiting
remarkable reasoning and comprehension abilities in Natural Language Processing
(NLP), most Question Answering (QA) research has primarily centered around
general QA tasks based on GPT, neglecting the specific challenges posed by
Complex Table QA. In this paper, we propose to incorporate GPT-3.5 to address
such challenges, in which complex tables are reconstructed into tuples and
specific prompt designs are employed for dialogues. Specifically, we encode
each cell's hierarchical structure, position information, and content as a
tuple. By enhancing the prompt template with an explanatory description of the
meaning of each tuple and the logical reasoning process of the task, we
effectively improve the hierarchical structure awareness capability of GPT-3.5
to better parse the complex tables. Extensive experiments and results on
Complex Table QA datasets, i.e., the open-domain dataset HiTAB and the aviation
domain dataset AIT-QA show that our approach significantly outperforms previous
work on both datasets, leading to state-of-the-art (SOTA) performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11522">Assessing SATNet&#x27;s Ability to Solve the Symbol Grounding Problem. (arXiv:2312.11522v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1">Oscar Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Flokas_L/0/1/0/all/0/1">Lampros Flokas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1">Hod Lipson</a>, <a href="http://arxiv.org/find/cs/1/au:+Spranger_M/0/1/0/all/0/1">Michael Spranger</a></p>
<p>SATNet is an award-winning MAXSAT solver that can be used to infer logical
rules and integrated as a differentiable layer in a deep neural network. It had
been shown to solve Sudoku puzzles visually from examples of puzzle digit
images, and was heralded as an impressive achievement towards the longstanding
AI goal of combining pattern recognition with logical reasoning. In this paper,
we clarify SATNet's capabilities by showing that in the absence of intermediate
labels that identify individual Sudoku digit images with their logical
representations, SATNet completely fails at visual Sudoku (0% test accuracy).
More generally, the failure can be pinpointed to its inability to learn to
assign symbols to perceptual phenomena, also known as the symbol grounding
problem, which has long been thought to be a prerequisite for intelligent
agents to perform real-world logical reasoning. We propose an MNIST based test
as an easy instance of the symbol grounding problem that can serve as a sanity
check for differentiable symbolic solvers in general. Naive applications of
SATNet on this test lead to performance worse than that of models without
logical reasoning capabilities. We report on the causes of SATNet's failure and
how to prevent them.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11523">ToViLaG: Your Visual-Language Generative Model is Also An Evildoer. (arXiv:2312.11523v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinpeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xiaoyuan Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Han Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shanlin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhihua Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>Warning: this paper includes model outputs showing offensive content. Recent
large-scale Visual-Language Generative Models (VLGMs) have achieved
unprecedented improvement in multimodal image/text generation. However, these
models might also generate toxic content, e.g., offensive text and pornography
images, raising significant ethical risks. Despite exhaustive studies on toxic
degeneration of language models, this problem remains largely unexplored within
the context of visual-language generation. This work delves into the propensity
for toxicity generation and susceptibility to toxic data across various VLGMs.
For this purpose, we built ToViLaG, a dataset comprising 32K
co-toxic/mono-toxic text-image pairs and 1K innocuous but evocative text that
tends to stimulate toxicity. Furthermore, we propose WInToRe, a novel toxicity
metric tailored to visual-language generation, which theoretically reflects
different aspects of toxicity considering both input and output. On such a
basis, we benchmarked the toxicity of a diverse spectrum of VLGMs and
discovered that some models do more evil than expected while some are more
vulnerable to infection, underscoring the necessity of VLGMs detoxification.
Therefore, we develop an innovative bottleneck-based detoxification method. Our
method could reduce toxicity while maintaining comparable generation quality,
providing a promising initial solution to this line of research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11524">Assessing GPT4-V on Structured Reasoning Tasks. (arXiv:2312.11524v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mukul Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambronero_J/0/1/0/all/0/1">Jos&#xe9; Cambronero</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1">Sumit Gulwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1">Vu Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbruggen_G/0/1/0/all/0/1">Gust Verbruggen</a></p>
<p>Multi-modality promises to unlock further uses for large language models.
Recently, the state-of-the-art language model GPT-4 was enhanced with vision
capabilities. We carry out a prompting evaluation of GPT-4V and five other
baselines on structured reasoning tasks, such as mathematical reasoning, visual
data analysis, and code generation. We show that visual Chain-of-Thought, an
extension of Chain-of-Thought to multi-modal LLMs, yields significant
improvements over the vanilla model. We also present a categorized analysis of
scenarios where these models perform well and where they struggle, highlighting
challenges associated with coherent multimodal reasoning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11525">Synocene, Beyond the Anthropocene: De-Anthropocentralising Human-Nature-AI Interaction. (arXiv:2312.11525v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hupont_I/0/1/0/all/0/1">Isabelle Hupont</a>, <a href="http://arxiv.org/find/cs/1/au:+Wainer_M/0/1/0/all/0/1">Marina Wainer</a>, <a href="http://arxiv.org/find/cs/1/au:+Nester_S/0/1/0/all/0/1">Sam Nester</a>, <a href="http://arxiv.org/find/cs/1/au:+Tissot_S/0/1/0/all/0/1">Sylvie Tissot</a>, <a href="http://arxiv.org/find/cs/1/au:+Iglesias_Blanco_L/0/1/0/all/0/1">Luc&#xed;a Iglesias-Blanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldassarri_S/0/1/0/all/0/1">Sandra Baldassarri</a></p>
<p>Recent publications explore AI biases in detecting objects and people in the
environment. However, there is no research tackling how AI examines nature.
This case study presents a pioneering exploration into the AI attitudes
(ecocentric, anthropocentric and antipathetic) toward nature. Experiments with
a Large Language Model (LLM) and an image captioning algorithm demonstrate the
presence of anthropocentric biases in AI. Moreover, to delve deeper into these
biases and Human-Nature-AI interaction, we conducted a real-life experiment in
which participants underwent an immersive de-anthropocentric experience in a
forest and subsequently engaged with ChatGPT to co-create narratives. By
creating fictional AI chatbot characters with ecocentric attributes, emotions
and views, we successfully amplified ecocentric exchanges. We encountered some
difficulties, mainly that participants deviated from narrative co-creation to
short dialogues and questions and answers, possibly due to the novelty of
interacting with LLMs. To solve this problem, we recommend providing
preliminary guidelines on interacting with LLMs and allowing participants to
get familiar with the technology. We plan to repeat this experiment in various
countries and forests to expand our corpus of ecocentric materials.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11526">ABiMed: An intelligent and visual clinical decision support system for medication reviews and polypharmacy management. (arXiv:2312.11526v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mouazer_A/0/1/0/all/0/1">Abdelmalek Mouazer</a>, <a href="http://arxiv.org/find/cs/1/au:+Leguillon_R/0/1/0/all/0/1">Romain L&#xe9;guillon</a>, <a href="http://arxiv.org/find/cs/1/au:+Boudegzdame_N/0/1/0/all/0/1">Nada Boudegzdame</a>, <a href="http://arxiv.org/find/cs/1/au:+Levrard_T/0/1/0/all/0/1">Thibaud Levrard</a>, <a href="http://arxiv.org/find/cs/1/au:+Bars_Y/0/1/0/all/0/1">Yoann Le Bars</a>, <a href="http://arxiv.org/find/cs/1/au:+Simon_C/0/1/0/all/0/1">Christian Simon</a>, <a href="http://arxiv.org/find/cs/1/au:+Seroussi_B/0/1/0/all/0/1">Brigitte S&#xe9;roussi</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosjean_J/0/1/0/all/0/1">Julien Grosjean</a>, <a href="http://arxiv.org/find/cs/1/au:+Lelong_R/0/1/0/all/0/1">Romain Lelong</a>, <a href="http://arxiv.org/find/cs/1/au:+Letord_C/0/1/0/all/0/1">Catherine Letord</a>, <a href="http://arxiv.org/find/cs/1/au:+Darmoni_S/0/1/0/all/0/1">St&#xe9;fan Darmoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuers_M/0/1/0/all/0/1">Matthieu Schuers</a>, <a href="http://arxiv.org/find/cs/1/au:+Sedki_K/0/1/0/all/0/1">Karima Sedki</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubois_S/0/1/0/all/0/1">Sophie Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Falcoff_H/0/1/0/all/0/1">Hector Falcoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsopra_R/0/1/0/all/0/1">Rosy Tsopra</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamy_J/0/1/0/all/0/1">Jean-Baptiste Lamy</a></p>
<p>Background: Polypharmacy, i.e. taking five drugs or more, is both a public
health and an economic issue. Medication reviews are structured interviews of
the patient by the community pharmacist, aiming at optimizing the drug
treatment and deprescribing useless, redundant or dangerous drugs. However,
they remain difficult to perform and time-consuming. Several clinical decision
support systems were developed for helping clinicians to manage polypharmacy.
However, most were limited to the implementation of clinical practice
guidelines. In this work, our objective is to design an innovative clinical
decision support system for medication reviews and polypharmacy management,
named ABiMed.
</p>
<p>Methods: ABiMed associates several approaches: guidelines implementation, but
the automatic extraction of patient data from the GP's electronic health record
and its transfer to the pharmacist, and the visual presentation of
contextualized drug knowledge using visual analytics. We performed an ergonomic
assessment and qualitative evaluations involving pharmacists and GPs during
focus groups and workshops.
</p>
<p>Results: We describe the proposed architecture, which allows a collaborative
multi-user usage. We present the various screens of ABiMed for entering or
verifying patient data, for accessing drug knowledge (posology, adverse
effects, interactions), for viewing STOPP/START rules and for suggesting
modification to the treatment. Qualitative evaluations showed that health
professionals were highly interested by our approach, associating the automatic
guidelines execution with the visual presentation of drug knowledge.
</p>
<p>Conclusions: The association of guidelines implementation with visual
presentation of knowledge is a promising approach for managing polypharmacy.
Future works will focus on the improvement and the evaluation of ABiMed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11527">A Simulated Annealing-Based Multiobjective Optimization Algorithm for Minimum Weight Minimum Connected Dominating Set Problem. (arXiv:2312.11527v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dahmri_H/0/1/0/all/0/1">Hayet Dahmri</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouamama_S/0/1/0/all/0/1">Salim Bouamama</a></p>
<p>Minimum connected dominating set problem is an NP-hard combinatorial
optimization problem in graph theory. Finding connected dominating set is of
high interest in various domains such as wireless sensor networks, optical
networks, and systems biology. Its weighted variant named minimum weight
connected dominating set is also useful in such applications. In this paper, we
propose a simulated annealing algorithm based on a greedy heuristic for
tackling a variant of the minimum connected dominating set problem and that by
exploiting two objectives together namely the cardinality and the total weight
of the connected dominating set. Experimental results compared to those
obtained by a recent proposed research show the superiority of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11532">Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">YoungJoon Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jongwon Choi</a></p>
<p>This paper introduces a novel approach for topic modeling utilizing latent
codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely
encapsulating the rich information of the pre-trained embeddings such as the
pre-trained language model. From the novel interpretation of the latent
codebooks and embeddings as conceptual bag-of-words, we propose a new
generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates
the original documents related to the respective latent codebook. The TVQ-VAE
can visualize the topics with various generative distributions including the
traditional BoW distribution and the autoregressive image generation. Our
experimental results on document analysis and image generation demonstrate that
TVQ-VAE effectively captures the topic context which reveals the underlying
structures of the dataset and supports flexible forms of document generation.
Official implementation of the proposed TVQ-VAE is available at
https://github.com/clovaai/TVQ-VAE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11535">Customize-It-3D: High-Quality 3D Creation from A Single Image Using Subject-Specific Knowledge Prior. (arXiv:2312.11535v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1">Nan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Ting Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yuhui Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a></p>
<p>In this paper, we present a novel two-stage approach that fully utilizes the
information provided by the reference image to establish a customized knowledge
prior for image-to-3D generation. While previous approaches primarily rely on a
general diffusion prior, which struggles to yield consistent results with the
reference image, we propose a subject-specific and multi-modal diffusion model.
This model not only aids NeRF optimization by considering the shading mode for
improved geometry but also enhances texture from the coarse results to achieve
superior refinement. Both aspects contribute to faithfully aligning the 3D
content with the subject. Extensive experiments showcase the superiority of our
method, Customize-It-3D, outperforming previous works by a substantial margin.
It produces faithful 360-degree reconstructions with impressive visual quality,
making it well-suited for various applications, including text-to-3D creation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11539">KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn&#x27;t Know. (arXiv:2312.11539v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shangshang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">He Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1">Xiaochuan Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1">Navdeep Jaitly</a></p>
<p>Current approaches to evaluating large language models (LLMs) with
pre-existing Knowledge Graphs (KG) mostly ignore the structure of the KG and
make arbitrary choices of which part of the graph to evaluate. In this paper,
we introduce KGLens, a method to evaluate LLMs by generating natural language
questions from a KG in a structure aware manner so that we can characterize its
performance on a more aggregated level. KGLens uses a parameterized KG, where
each edge is augmented with a beta distribution that guides how to sample edges
from the KG for QA testing. As the evaluation proceeds, different edges of the
parameterized KG are sampled and assessed appropriately, converging to a more
global picture of the performance of the LLMs on the KG as a whole. In our
experiments, we construct three domain-specific KGs for knowledge assessment,
comprising over 19,000 edges, 700 relations, and 21,000 entities. The results
demonstrate that KGLens can not only assess overall performance but also
provide topic, temporal, and relation analyses of LLMs. This showcases the
adaptability and customizability of KGLens, emphasizing its ability to focus
the evaluation based on specific criteria.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11541">CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization in Healthcare. (arXiv:2312.11541v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Akash Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1">Arkadeep Acharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Raghav Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sriparna Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1">Aman Chadha</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1">Setu Sinha</a></p>
<p>In the era of modern healthcare, swiftly generating medical question
summaries is crucial for informed and timely patient care. Despite the
increasing complexity and volume of medical data, existing studies have focused
solely on text-based summarization, neglecting the integration of visual
information. Recognizing the untapped potential of combining textual queries
with visual representations of medical conditions, we introduce the Multimodal
Medical Question Summarization (MMQS) Dataset. This dataset, a major
contribution to our work, pairs medical queries with visual aids, facilitating
a richer and more nuanced understanding of patient needs. We also propose a
framework, utilizing the power of Contrastive Language Image Pretraining(CLIP)
and Large Language Models(LLMs), consisting of four modules that identify
medical disorders, generate relevant context, filter medical concepts, and
craft visually aware summaries. Our comprehensive framework harnesses the power
of CLIP, a multimodal foundation model, and various general-purpose LLMs,
comprising four main modules: the medical disorder identification module, the
relevant context generation module, the context filtration module for
distilling relevant medical concepts and knowledge, and finally, a
general-purpose LLM to generate visually aware medical question summaries.
Leveraging our MMQS dataset, we showcase how visual cues from images enhance
the generation of medically nuanced summaries. This multimodal approach not
only enhances the decision-making process in healthcare but also fosters a more
nuanced understanding of patient queries, laying the groundwork for future
research in personalized and responsive medical care
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11545">Robust Communicative Multi-Agent Reinforcement Learning with Active Defense. (arXiv:2312.11545v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lebin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yunbo Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Quanming Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xudong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a></p>
<p>Communication in multi-agent reinforcement learning (MARL) has been proven to
effectively promote cooperation among agents recently. Since communication in
real-world scenarios is vulnerable to noises and adversarial attacks, it is
crucial to develop robust communicative MARL technique. However, existing
research in this domain has predominantly focused on passive defense
strategies, where agents receive all messages equally, making it hard to
balance performance and robustness. We propose an active defense strategy,
where agents automatically reduce the impact of potentially harmful messages on
the final decision. There are two challenges to implement this strategy, that
are defining unreliable messages and adjusting the unreliable messages' impact
on the final decision properly. To address them, we design an Active Defense
Multi-Agent Communication framework (ADMAC), which estimates the reliability of
received messages and adjusts their impact on the final decision accordingly
with the help of a decomposable decision structure. The superiority of ADMAC
over existing methods is validated by experiments in three
communication-critical tasks under four types of attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11547">A Unified Pre-training and Adaptation Framework for Combinatorial Optimization on Graphs. (arXiv:2312.11547v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_R/0/1/0/all/0/1">Ruibin Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_M/0/1/0/all/0/1">Minglong Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1">Lingfeng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Lan Cheng</a></p>
<p>Combinatorial optimization (CO) on graphs is a classic topic that has been
extensively studied across many scientific and industrial fields. Recently,
solving CO problems on graphs through learning methods has attracted great
attention. Advanced deep learning methods, e.g., graph neural networks (GNNs),
have been used to effectively assist the process of solving COs. However,
current frameworks based on GNNs are mainly designed for certain CO problems,
thereby failing to consider their transferable and generalizable abilities
among different COs on graphs. Moreover, simply using original graphs to model
COs only captures the direct correlations among objects, which does not
consider the mathematical logicality and properties of COs. In this paper, we
propose a unified pre-training and adaptation framework for COs on graphs with
the help of the maximum satisfiability (Max-SAT) problem. We first use Max-SAT
to bridge different COs on graphs since they can be converted to Max-SAT
problems represented by standard formulas and clauses with logical information.
Then, we further design a pre-training and domain adaptation framework to
extract the transferable and generalizable features so that different COs can
benefit from them. In the pre-training stage, Max-SAT instances are generated
to initialize the parameters of the model. In the fine-tuning stage, instances
from CO and Max-SAT problems are used for adaptation so that the transferable
ability can be further improved. Numerical experiments on several datasets show
that features extracted by our framework exhibit superior transferability and
Max-SAT can boost the ability to solve COs on graphs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11551">Probabilistic Offline Policy Ranking with Approximate Bayesian Computation. (arXiv:2312.11551v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Da_L/0/1/0/all/0/1">Longchao Da</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenkins_P/0/1/0/all/0/1">Porter Jenkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwantes_T/0/1/0/all/0/1">Trevor Schwantes</a>, <a href="http://arxiv.org/find/cs/1/au:+Dotson_J/0/1/0/all/0/1">Jeffrey Dotson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Hua Wei</a></p>
<p>In practice, it is essential to compare and rank candidate policies offline
before real-world deployment for safety and reliability. Prior work seeks to
solve this offline policy ranking (OPR) problem through value-based methods,
such as Off-policy evaluation (OPE). However, they fail to analyze special
cases performance (e.g., worst or best cases), due to the lack of holistic
characterization of policies performance. It is even more difficult to estimate
precise policy values when the reward is not fully accessible under sparse
settings. In this paper, we present Probabilistic Offline Policy Ranking
(POPR), a framework to address OPR problems by leveraging expert data to
characterize the probability of a candidate policy behaving like experts, and
approximating its entire performance posterior distribution to help with
ranking. POPR does not rely on value estimation, and the derived performance
posterior can be used to distinguish candidates in worst, best, and
average-cases. To estimate the posterior, we propose POPR-EABC, an Energy-based
Approximate Bayesian Computation (ABC) method conducting likelihood-free
inference. POPR-EABC reduces the heuristic nature of ABC by a smooth energy
function, and improves the sampling efficiency by a pseudo-likelihood. We
empirically demonstrate that POPR-EABC is adequate for evaluating policies in
both discrete and continuous action spaces across various experiment
environments, and facilitates probabilistic comparisons of candidate policies
before deployment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11553">SeGA: Preference-Aware Self-Contrastive Learning with Prompts for Anomalous User Detection on Twitter. (arXiv:2312.11553v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Ying-Ying Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei-Yao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wen-Chih Peng</a></p>
<p>In the dynamic and rapidly evolving world of social media, detecting
anomalous users has become a crucial task to address malicious activities such
as misinformation and cyberbullying. As the increasing number of anomalous
users improves the ability to mimic normal users and evade detection, existing
methods only focusing on bot detection are ineffective in terms of capturing
subtle distinctions between users. To address these challenges, we proposed
SeGA, preference-aware self-contrastive learning for anomalous user detection,
which leverages heterogeneous entities and their relations in the Twittersphere
to detect anomalous users with different malicious strategies. SeGA utilizes
the knowledge of large language models to summarize user preferences via posts.
In addition, integrating user preferences with prompts as pseudo-labels for
preference-aware self-contrastive learning enables the model to learn
multifaceted aspects for describing the behaviors of users. Extensive
experiments on the proposed TwBNT benchmark demonstrate that SeGA significantly
outperforms the state-of-the-art methods (+3.5\% ~ 27.6\%) and empirically
validate the effectiveness of the model design and pre-training strategies. Our
code and data are publicly available at https://github.com/ying0409/SeGA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11554">Deciphering Compatibility Relationships with Textual Descriptions via Extraction and Explanation. (arXiv:2312.11554v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zexue He</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhankui He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a></p>
<p>Understanding and accurately explaining compatibility relationships between
fashion items is a challenging problem in the burgeoning domain of AI-driven
outfit recommendations. Present models, while making strides in this area,
still occasionally fall short, offering explanations that can be elementary and
repetitive. This work aims to address these shortcomings by introducing the
Pair Fashion Explanation (PFE) dataset, a unique resource that has been curated
to illuminate these compatibility relationships. Furthermore, we propose an
innovative two-stage pipeline model that leverages this dataset. This
fine-tuning allows the model to generate explanations that convey the
compatibility relationships between items. Our experiments showcase the model's
potential in crafting descriptions that are knowledgeable, aligned with
ground-truth matching correlations, and that produce understandable and
informative descriptions, as assessed by both automatic metrics and human
evaluation. Our code and data are released at
https://github.com/wangyu-ustc/PairFashionExplanation
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11556">StarVector: Generating Scalable Vector Graphics Code from Images. (arXiv:2312.11556v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_J/0/1/0/all/0/1">Juan A. Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Shubham Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1">Issam H. Laradji</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1">Pau Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazquez_D/0/1/0/all/0/1">David Vazquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersoli_M/0/1/0/all/0/1">Marco Pedersoli</a></p>
<p>Scalable Vector Graphics (SVGs) have become integral in modern image
rendering applications due to their infinite scalability in resolution,
versatile usability, and editing capabilities. SVGs are particularly popular in
the fields of web development and graphic design. Existing approaches for SVG
modeling using deep learning often struggle with generating complex SVGs and
are restricted to simpler ones that require extensive processing and
simplification. This paper introduces StarVector, a multimodal SVG generation
model that effectively integrates Code Generation Large Language Models
(CodeLLMs) and vision models. Our approach utilizes a CLIP image encoder to
extract visual representations from pixel-based images, which are then
transformed into visual tokens via an adapter module. These visual tokens are
pre-pended to the SVG token embeddings, and the sequence is modeled by the
StarCoder model using next-token prediction, effectively learning to align the
visual and code tokens. This enables StarVector to generate unrestricted SVGs
that accurately represent pixel images. To evaluate StarVector's performance,
we present SVG-Bench, a comprehensive benchmark for evaluating SVG methods
across multiple datasets and relevant metrics. Within this benchmark, we
introduce novel datasets including SVG-Stack, a large-scale dataset of
real-world SVG examples, and use it to pre-train StarVector as a large
foundation model for SVGs. Our results demonstrate significant enhancements in
visual quality and complexity handling over current methods, marking a notable
advancement in SVG generation technology. Code and models:
https://github.com/joanrod/star-vector
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11560">Emergence Learning: A Rising Direction from Emergent Abilities and a Monosemanticity-Based Study. (arXiv:2312.11560v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiachuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Di_S/0/1/0/all/0/1">Shimin Di</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_C/0/1/0/all/0/1">Charles Wang Wai Ng</a></p>
<p>In the past 20 years, artificial neural networks have become dominant in
various areas, continually growing in scale. However, the current analysis of
large models has mainly focused on functionality, overlooking the influence of
scale differences on their properties. To address this, we propose the concept
of Emergence Learning, which emphasizes the significance of scale. By studying
models of different scales, we have identified a key factor in achieving higher
performance in large models: the decrease of monosemantic neurons. Building on
this insight, we propose a proactive approach to inhibit monosemanticity for
improved performance. Our solution involves a two-phase process that includes
monosemantic neuron detection and inhibition, supported by theoretical
analysis. Experimental results on various tasks and neural networks demonstrate
the effectiveness of our proposed method.
</p>
<p>Following the idea of Emergence Learning, though drawing inspiration from
scaling phenomena, the applicability of our method is not restricted to large
scale alone. Therefore, the experiment is self-contained. However, extending
this research to very large-scale datasets is appealing yet impossible for
research departments due to limited resources. We are delighted to share the
first co-authorship and eagerly await collaboration from any AI company before
submission.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11561">COPD-FlowNet: Elevating Non-invasive COPD Diagnosis with CFD Simulations. (arXiv:2312.11561v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1">Aryan Tyagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Aryaman Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1">Shubhanshu Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Raj Kumar Singh</a></p>
<p>Chronic Obstructive Pulmonary Disorder (COPD) is a prevalent respiratory
disease that significantly impacts the quality of life of affected individuals.
This paper presents COPDFlowNet, a novel deep-learning framework that leverages
a custom Generative Adversarial Network (GAN) to generate synthetic
Computational Fluid Dynamics (CFD) velocity flow field images specific to the
trachea of COPD patients. These synthetic images serve as a valuable resource
for data augmentation and model training. Additionally, COPDFlowNet
incorporates a custom Convolutional Neural Network (CNN) architecture to
predict the location of the obstruction site.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11562">A Survey of Reasoning with Foundation Models. (arXiv:2312.11562v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiankai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chuanyang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_R/0/1/0/all/0/1">Ruihang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiaqi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Mingyu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_M/0/1/0/all/0/1">Mengzhe Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junsong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhangyue Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaozhe Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jie Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Junxian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Wu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xihui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng Ann Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a></p>
<p>Reasoning, a crucial ability for complex problem-solving, plays a pivotal
role in various real-world settings such as negotiation, medical diagnosis, and
criminal investigation. It serves as a fundamental methodology in the field of
Artificial General Intelligence (AGI). With the ongoing development of
foundation models, there is a growing interest in exploring their abilities in
reasoning tasks. In this paper, we introduce seminal foundation models proposed
or adaptable for reasoning, highlighting the latest advancements in various
reasoning tasks, methods, and benchmarks. We then delve into the potential
future directions behind the emergence of reasoning abilities within foundation
models. We also discuss the relevance of multimodal learning, autonomous
agents, and super alignment in the context of reasoning. By discussing these
future research directions, we hope to inspire researchers in their exploration
of this field, stimulate further advancements in reasoning with foundation
models, and contribute to the development of AGI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11567">Students&#x27; Perceptions and Preferences of Generative Artificial Intelligence Feedback for Programming. (arXiv:2312.11567v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zihan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsuda_N/0/1/0/all/0/1">Noboru Matsuda</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_T/0/1/0/all/0/1">Thomas Price</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dongkuan Xu</a></p>
<p>The rapid evolution of artificial intelligence (AI), specifically large
language models (LLMs), has opened opportunities for various educational
applications. This paper explored the feasibility of utilizing ChatGPT, one of
the most popular LLMs, for automating feedback for Java programming assignments
in an introductory computer science (CS1) class. Specifically, this study
focused on three questions: 1) To what extent do students view LLM-generated
feedback as formative? 2) How do students see the comparative affordances of
feedback prompts that include their code, vs. those that exclude it? 3) What
enhancements do students suggest for improving AI-generated feedback? To
address these questions, we generated automated feedback using the ChatGPT API
for four lab assignments in the CS1 class. The survey results revealed that
students perceived the feedback as aligning well with formative feedback
guidelines established by Shute. Additionally, students showed a clear
preference for feedback generated by including the students' code as part of
the LLM prompt, and our thematic study indicated that the preference was mainly
attributed to the specificity, clarity, and corrective nature of the feedback.
Moreover, this study found that students generally expected specific and
corrective feedback with sufficient code examples, but had diverged opinions on
the tone of the feedback. This study demonstrated that ChatGPT could generate
Java programming assignment feedback that students perceived as formative. It
also offered insights into the specific improvements that would make the
ChatGPT-generated feedback useful for students.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11571">Model Stealing Attack against Recommender System. (arXiv:2312.11571v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1">Rui Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenwang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1">Defu Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a></p>
<p>Recent studies have demonstrated the vulnerability of recommender systems to
data privacy attacks. However, research on the threat to model privacy in
recommender systems, such as model stealing attacks, is still in its infancy.
Some adversarial attacks have achieved model stealing attacks against
recommender systems, to some extent, by collecting abundant training data of
the target model (target data) or making a mass of queries. In this paper, we
constrain the volume of available target data and queries and utilize auxiliary
data, which shares the item set with the target data, to promote model stealing
attacks. Although the target model treats target and auxiliary data
differently, their similar behavior patterns allow them to be fused using an
attention mechanism to assist attacks. Besides, we design stealing functions to
effectively extract the recommendation list obtained by querying the target
model. Experimental results show that the proposed methods are applicable to
most recommender systems and various scenarios and exhibit excellent attack
performance on multiple datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11573">Estimation of individual causal effects in network setup for multiple treatments. (arXiv:2312.11573v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thorat_A/0/1/0/all/0/1">Abhinav Thorat</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolla_R/0/1/0/all/0/1">Ravi Kolla</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedanekar_N/0/1/0/all/0/1">Niranjan Pedanekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Onoe_N/0/1/0/all/0/1">Naoyuki Onoe</a></p>
<p>We study the problem of estimation of Individual Treatment Effects (ITE) in
the context of multiple treatments and networked observational data. Leveraging
the network information, we aim to utilize hidden confounders that may not be
directly accessible in the observed data, thereby enhancing the practical
applicability of the strong ignorability assumption. To achieve this, we first
employ Graph Convolutional Networks (GCN) to learn a shared representation of
the confounders. Then, our approach utilizes separate neural networks to infer
potential outcomes for each treatment. We design a loss function as a weighted
combination of two components: representation loss and Mean Squared Error (MSE)
loss on the factual outcomes. To measure the representation loss, we extend
existing metrics such as Wasserstein and Maximum Mean Discrepancy (MMD) from
the binary treatment setting to the multiple treatments scenario. To validate
the effectiveness of our proposed methodology, we conduct a series of
experiments on the benchmark datasets such as BlogCatalog and Flickr. The
experimental results consistently demonstrate the superior performance of our
models when compared to baseline methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11581">Protect Your Score: Contact Tracing With Differential Privacy Guarantees. (arXiv:2312.11581v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1">Rob Romijnders</a>, <a href="http://arxiv.org/find/cs/1/au:+Louizos_C/0/1/0/all/0/1">Christos Louizos</a>, <a href="http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1">Yuki M. Asano</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a></p>
<p>The pandemic in 2020 and 2021 had enormous economic and societal
consequences, and studies show that contact tracing algorithms can be key in
the early containment of the virus. While large strides have been made towards
more effective contact tracing algorithms, we argue that privacy concerns
currently hold deployment back. The essence of a contact tracing algorithm
constitutes the communication of a risk score. Yet, it is precisely the
communication and release of this score to a user that an adversary can
leverage to gauge the private health status of an individual. We pinpoint a
realistic attack scenario and propose a contact tracing algorithm with
differential privacy guarantees against this attack. The algorithm is tested on
the two most widely used agent-based COVID19 simulators and demonstrates
superior performance in a wide range of settings. Especially for realistic test
scenarios and while releasing each risk score with epsilon=1 differential
privacy, we achieve a two to ten-fold reduction in the infection rate of the
virus. To the best of our knowledge, this presents the first contact tracing
algorithm with differential privacy guarantees when revealing risk scores for
COVID19.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11582">Shapley-PC: Constraint-based Causal Structure Learning with Shapley Values. (arXiv:2312.11582v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Russo_F/0/1/0/all/0/1">Fabrizio Russo</a>, <a href="http://arxiv.org/find/cs/1/au:+Toni_F/0/1/0/all/0/1">Francesca Toni</a></p>
<p>Causal Structure Learning (CSL), amounting to extracting causal relations
among the variables in a dataset, is widely perceived as an important step
towards robust and transparent models. Constraint-based CSL leverages
conditional independence tests to perform causal discovery. We propose
Shapley-PC, a novel method to improve constraint-based CSL algorithms by using
Shapley values over the possible conditioning sets to decide which variables
are responsible for the observed conditional (in)dependences. We prove
soundness and asymptotic consistency and demonstrate that it can outperform
state-of-the-art constraint-based, search-based and functional causal
model-based methods, according to standard metrics in CSL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11583">AI-Based Energy Transportation Safety: Pipeline Radial Threat Estimation Using Intelligent Sensing System. (arXiv:2312.11583v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chengyuan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaixiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haifeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qinmin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">C. L. Philip Chen</a></p>
<p>The application of artificial intelligence technology has greatly enhanced
and fortified the safety of energy pipelines, particularly in safeguarding
against external threats. The predominant methods involve the integration of
intelligent sensors to detect external vibration, enabling the identification
of event types and locations, thereby replacing manual detection methods.
However, practical implementation has exposed a limitation in current methods -
their constrained ability to accurately discern the spatial dimensions of
external signals, which complicates the authentication of threat events. Our
research endeavors to overcome the above issues by harnessing deep learning
techniques to achieve a more fine-grained recognition and localization process.
This refinement is crucial in effectively identifying genuine threats to
pipelines, thus enhancing the safety of energy transportation. This paper
proposes a radial threat estimation method for energy pipelines based on
distributed optical fiber sensing technology. Specifically, we introduce a
continuous multi-view and multi-domain feature fusion methodology to extract
comprehensive signal features and construct a threat estimation and recognition
network. The utilization of collected acoustic signal data is optimized, and
the underlying principle is elucidated. Moreover, we incorporate the concept of
transfer learning through a pre-trained model, enhancing both recognition
accuracy and training efficiency. Empirical evidence gathered from real-world
scenarios underscores the efficacy of our method, notably in its substantial
reduction of false alarms and remarkable gains in recognition accuracy. More
generally, our method exhibits versatility and can be extrapolated to a broader
spectrum of recognition tasks and scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11584">ContraNovo: A Contrastive Learning Approach to Enhance De Novo Peptide Sequencing. (arXiv:2312.11584v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Jin_Z/0/1/0/all/0/1">Zhi Jin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xu_S/0/1/0/all/0/1">Sheng Xu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_X/0/1/0/all/0/1">Xiang Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ling_T/0/1/0/all/0/1">Tianze Ling</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dong_N/0/1/0/all/0/1">Nanqing Dong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gao_Z/0/1/0/all/0/1">Zhiqiang Gao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chang_C/0/1/0/all/0/1">Cheng Chang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sun_S/0/1/0/all/0/1">Siqi Sun</a></p>
<p>De novo peptide sequencing from mass spectrometry (MS) data is a critical
task in proteomics research. Traditional de novo algorithms have encountered a
bottleneck in accuracy due to the inherent complexity of proteomics data. While
deep learning-based methods have shown progress, they reduce the problem to a
translation task, potentially overlooking critical nuances between spectra and
peptides. In our research, we present ContraNovo, a pioneering algorithm that
leverages contrastive learning to extract the relationship between spectra and
peptides and incorporates the mass information into peptide decoding, aiming to
address these intricacies more efficiently. Through rigorous evaluations on two
benchmark datasets, ContraNovo consistently outshines contemporary
state-of-the-art solutions, underscoring its promising potential in enhancing
de novo peptide sequencing. The source code is available at
https://github.com/BEAM-Labs/ContraNovo.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11589">Moral Uncertainty and the Problem of Fanaticism. (arXiv:2312.11589v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Szabo_J/0/1/0/all/0/1">Jazon Szabo</a>, <a href="http://arxiv.org/find/cs/1/au:+Such_J/0/1/0/all/0/1">Jose Such</a>, <a href="http://arxiv.org/find/cs/1/au:+Criado_N/0/1/0/all/0/1">Natalia Criado</a>, <a href="http://arxiv.org/find/cs/1/au:+Modgil_S/0/1/0/all/0/1">Sanjay Modgil</a></p>
<p>While there is universal agreement that agents ought to act ethically, there
is no agreement as to what constitutes ethical behaviour. To address this
problem, recent philosophical approaches to `moral uncertainty' propose
aggregation of multiple ethical theories to guide agent behaviour. However, one
of the foundational proposals for aggregation - Maximising Expected
Choiceworthiness (MEC) - has been criticised as being vulnerable to fanaticism;
the problem of an ethical theory dominating agent behaviour despite low
credence (confidence) in said theory. Fanaticism thus undermines the
`democratic' motivation for accommodating multiple ethical perspectives. The
problem of fanaticism has not yet been mathematically defined. Representing
moral uncertainty as an instance of social welfare aggregation, this paper
contributes to the field of moral uncertainty by 1) formalising the problem of
fanaticism as a property of social welfare functionals and 2) providing
non-fanatical alternatives to MEC, i.e. Highest k-trimmed Mean and Highest
Median.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11651">Bridging Logic and Learning: A Neural-Symbolic Approach for Enhanced Reasoning in Neural Models (ASPER). (arXiv:2312.11651v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Machot_F/0/1/0/all/0/1">Fadi Al Machot</a></p>
<p>Neural-symbolic learning, an intersection of neural networks and symbolic
reasoning, aims to blend neural networks' learning capabilities with symbolic
AI's interpretability and reasoning. This paper introduces an approach designed
to improve the performance of neural models in learning reasoning tasks. It
achieves this by integrating Answer Set Programming (ASP) solvers and
domain-specific expertise, which is an approach that diverges from traditional
complex neural-symbolic models. In this paper, a shallow artificial neural
network (ANN) is specifically trained to solve Sudoku puzzles with minimal
training data. The model has a unique loss function that integrates losses
calculated using the ASP solver outputs, effectively enhancing its training
efficiency. Most notably, the model shows a significant improvement in solving
Sudoku puzzles using only 12 puzzles for training and testing without
hyperparameter tuning. This advancement indicates that the model's enhanced
reasoning capabilities have practical applications, extending well beyond
Sudoku puzzles to potentially include a variety of other domains. The code can
be found on GitHub: https://github.com/Fadi2200/ASPEN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11658">Traces of Memorisation in Large Language Models for Code. (arXiv:2312.11658v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Al_Kaswan_A/0/1/0/all/0/1">Ali Al-Kaswan</a>, <a href="http://arxiv.org/find/cs/1/au:+Izadi_M/0/1/0/all/0/1">Maliheh Izadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Deursen_A/0/1/0/all/0/1">Arie van Deursen</a></p>
<p>Large language models have gained significant popularity because of their
ability to generate human-like text and potential applications in various
fields, such as Software Engineering. Large language models for code are
commonly trained on large unsanitised corpora of source code scraped from the
internet. The content of these datasets is memorised and can be extracted by
attackers with data extraction attacks. In this work, we explore memorisation
in large language models for code and compare the rate of memorisation with
large language models trained on natural language. We adopt an existing
benchmark for natural language and construct a benchmark for code by
identifying samples that are vulnerable to attack. We run both benchmarks
against a variety of models, and perform a data extraction attack. We find that
large language models for code are vulnerable to data extraction attacks, like
their natural language counterparts. From the training data that was identified
to be potentially extractable we were able to extract 47% from a
CodeGen-Mono-16B code completion model. We also observe that models memorise
more, as their parameter count grows, and that their pre-training data are also
vulnerable to attack. We also find that data carriers are memorised at a higher
rate than regular code or documentation and that different model architectures
memorise different samples. Data leakage has severe outcomes, so we urge the
research community to further investigate the extent of this phenomenon using a
wider range of models and extraction techniques in order to build safeguards to
mitigate this issue.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11669">Prediction and Control in Continual Reinforcement Learning. (arXiv:2312.11669v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anand_N/0/1/0/all/0/1">Nishanth Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a></p>
<p>Temporal difference (TD) learning is often used to update the estimate of the
value function which is used by RL agents to extract useful policies. In this
paper, we focus on value function estimation in continual reinforcement
learning. We propose to decompose the value function into two components which
update at different timescales: a permanent value function, which holds general
knowledge that persists over time, and a transient value function, which allows
quick adaptation to new situations. We establish theoretical results showing
that our approach is well suited for continual learning and draw connections to
the complementary learning systems (CLS) theory from neuroscience. Empirically,
this approach improves performance significantly on both prediction and control
problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11671">Evaluating Language-Model Agents on Realistic Autonomous Tasks. (arXiv:2312.11671v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kinniment_M/0/1/0/all/0/1">Megan Kinniment</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_L/0/1/0/all/0/1">Lucas Jun Koba Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Haoxing Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodrich_B/0/1/0/all/0/1">Brian Goodrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasin_M/0/1/0/all/0/1">Max Hasin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_L/0/1/0/all/0/1">Lawrence Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Miles_L/0/1/0/all/0/1">Luke Harold Miles</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tao R. Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijk_H/0/1/0/all/0/1">Hjalmar Wijk</a>, <a href="http://arxiv.org/find/cs/1/au:+Burget_J/0/1/0/all/0/1">Joel Burget</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_A/0/1/0/all/0/1">Aaron Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_E/0/1/0/all/0/1">Elizabeth Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Christiano_P/0/1/0/all/0/1">Paul Christiano</a></p>
<p>In this report, we explore the ability of language model agents to acquire
resources, create copies of themselves, and adapt to novel challenges they
encounter in the wild. We refer to this cluster of capabilities as "autonomous
replication and adaptation" or ARA. We believe that systems capable of ARA
could have wide-reaching and hard-to-anticipate consequences, and that
measuring and forecasting ARA may be useful for informing measures around
security, monitoring, and alignment. Additionally, once a system is capable of
ARA, placing bounds on a system's capabilities may become significantly more
difficult.
</p>
<p>We construct four simple example agents that combine language models with
tools that allow them to take actions in the world. We then evaluate these
agents on 12 tasks relevant to ARA. We find that these language model agents
can only complete the easiest tasks from this list, although they make some
progress on the more challenging tasks. Unfortunately, these evaluations are
not adequate to rule out the possibility that near-future agents will be
capable of ARA. In particular, we do not think that these evaluations provide
good assurance that the ``next generation'' of language models (e.g. 100x
effective compute scaleup on existing models) will not yield agents capable of
ARA, unless intermediate evaluations are performed during pretraining.
Relatedly, we expect that fine-tuning of the existing models could produce
substantially more competent agents, even if the fine-tuning is not directly
targeted at ARA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11675">PRP Rebooted: Advancing the State of the Art in FOND Planning. (arXiv:2312.11675v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Muise_C/0/1/0/all/0/1">Christian Muise</a>, <a href="http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1">Sheila A. McIlraith</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_J/0/1/0/all/0/1">J. Christopher Beck</a></p>
<p>Fully Observable Non-Deterministic (FOND) planning is a variant of classical
symbolic planning in which actions are nondeterministic, with an action's
outcome known only upon execution. It is a popular planning paradigm with
applications ranging from robot planning to dialogue-agent design and reactive
synthesis. Over the last 20 years, a number of approaches to FOND planning have
emerged. In this work, we establish a new state of the art, following in the
footsteps of some of the most powerful FOND planners to date. Our planner, \us,
decisively outperforms the four leading FOND planners, at times by a large
margin, in 17 of 18 domains that represent a comprehensive benchmark suite.
Ablation studies demonstrate the empirical impact of various techniques we
introduce, with the largest improvement coming from our novel FOND-aware
heuristic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11681">Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows. (arXiv:2312.11681v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Grunde_McLaughlin_M/0/1/0/all/0/1">Madeleine Grunde-McLaughlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1">Michelle S. Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel S. Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Heer_J/0/1/0/all/0/1">Jeffrey Heer</a></p>
<p>LLM chains enable complex tasks by decomposing work into a sequence of
sub-tasks. Crowdsourcing workflows similarly decompose complex tasks into
smaller tasks for human crowdworkers. Chains address LLM errors analogously to
the way crowdsourcing workflows address human error. To characterize
opportunities for LLM chaining, we survey 107 papers across the crowdsourcing
and chaining literature to construct a design space for chain development. The
design space connects an LLM designer's objectives to strategies they can use
to achieve those objectives, and tactics to implement each strategy. To explore
how techniques from crowdsourcing may apply to chaining, we adapt crowdsourcing
workflows to implement LLM chains across three case studies: creating a
taxonomy, shortening text, and writing a short story. From the design space and
our case studies, we identify which techniques transfer from crowdsourcing to
LLM chaining and raise implications for future research and development.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11690">Agent-based Learning of Materials Datasets from Scientific Literature. (arXiv:2312.11690v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mehrad Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosavi_S/0/1/0/all/0/1">Seyed Mohamad Moosavi</a></p>
<p>Advancements in machine learning and artificial intelligence are transforming
materials discovery. Yet, the availability of structured experimental data
remains a bottleneck. The vast corpus of scientific literature presents a
valuable and rich resource of such data. However, manual dataset creation from
these resources is challenging due to issues in maintaining quality and
consistency, scalability limitations, and the risk of human error and bias.
Therefore, in this work, we develop a chemist AI agent, powered by large
language models (LLMs), to overcome these challenges by autonomously creating
structured datasets from natural language text, ranging from sentences and
paragraphs to extensive scientific research articles. Our chemist AI agent,
Eunomia, can plan and execute actions by leveraging the existing knowledge from
decades of scientific research articles, scientists, the Internet and other
tools altogether. We benchmark the performance of our approach in three
different information extraction tasks with various levels of complexity,
including solid-state impurity doping, metal-organic framework (MOF) chemical
formula, and property relations. Our results demonstrate that our zero-shot
agent, with the appropriate tools, is capable of attaining performance that is
either superior or comparable to the state-of-the-art fine-tuned materials
information extraction methods. This approach simplifies compilation of machine
learning-ready datasets for various materials discovery applications, and
significantly ease the accessibility of advanced natural language processing
tools for novice users in natural language. The methodology in this work is
developed as an open-source software on https://github.com/AI4ChemS/Eunomia.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11713">Indoor and Outdoor 3D Scene Graph Generation via Language-Enabled Spatial Ontologies. (arXiv:2312.11713v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Strader_J/0/1/0/all/0/1">Jared Strader</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_N/0/1/0/all/0/1">Nathan Hughes</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">William Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Speranzon_A/0/1/0/all/0/1">Alberto Speranzon</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlone_L/0/1/0/all/0/1">Luca Carlone</a></p>
<p>This paper proposes an approach to build 3D scene graphs in arbitrary (indoor
and outdoor) environments. Such extension is challenging; the hierarchy of
concepts that describe an outdoor environment is more complex than for indoors,
and manually defining such hierarchy is time-consuming and does not scale.
Furthermore, the lack of training data prevents the straightforward application
of learning-based tools used in indoor settings. To address these challenges,
we propose two novel extensions. First, we develop methods to build a spatial
ontology defining concepts and relations relevant for indoor and outdoor robot
operation. In particular, we use a Large Language Model (LLM) to build such an
ontology, thus largely reducing the amount of manual effort required. Second,
we leverage the spatial ontology for 3D scene graph construction using Logic
Tensor Networks (LTN) to add logical rules, or axioms (e.g., "a beach contains
sand"), which provide additional supervisory signals at training time thus
reducing the need for labelled data, providing better predictions, and even
allowing predicting concepts unseen at training time. We test our approach in a
variety of datasets, including indoor, rural, and coastal environments, and
show that it leads to a significant increase in the quality of the 3D scene
graph generation with sparsely annotated data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11714">Time-Transformer: Integrating Local and Global Features for Better Time Series Generation. (arXiv:2312.11714v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuansan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijewickrema_S/0/1/0/all/0/1">Sudanthi Wijewickrema</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bester_C/0/1/0/all/0/1">Christofer Bester</a>, <a href="http://arxiv.org/find/cs/1/au:+OLeary_S/0/1/0/all/0/1">Stephen O&#x27;Leary</a>, <a href="http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1">James Bailey</a></p>
<p>Generating time series data is a promising approach to address data
deficiency problems. However, it is also challenging due to the complex
temporal properties of time series data, including local correlations as well
as global dependencies. Most existing generative models have failed to
effectively learn both the local and global properties of time series data. To
address this open problem, we propose a novel time series generative model
named 'Time-Transformer AAE', which consists of an adversarial autoencoder
(AAE) and a newly designed architecture named 'Time-Transformer' within the
decoder. The Time-Transformer first simultaneously learns local and global
features in a layer-wise parallel design, combining the abilities of Temporal
Convolutional Networks and Transformer in extracting local features and global
dependencies respectively. Second, a bidirectional cross attention is proposed
to provide complementary guidance across the two branches and achieve proper
fusion between local and global features. Experimental results demonstrate that
our model can outperform existing state-of-the-art models in 5 out of 6
datasets, specifically on those with data containing both global and local
properties. Furthermore, we highlight our model's advantage on handling this
kind of data via an artificial dataset. Finally, we show our model's ability to
address a real-world problem: data augmentation to support learning with small
datasets and imbalanced datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11718">Human-Machine Teaming for UAVs: An Experimentation Platform. (arXiv:2312.11718v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moujtahid_L/0/1/0/all/0/1">Laila El Moujtahid</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottipati_S/0/1/0/all/0/1">Sai Krishna Gottipati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mars_C/0/1/0/all/0/1">Clod&#xe9;ric Mars</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1">Matthew E. Taylor</a></p>
<p>Full automation is often not achievable or desirable in critical systems with
high-stakes decisions. Instead, human-AI teams can achieve better results. To
research, develop, evaluate, and validate algorithms suited for such teaming,
lightweight experimentation platforms that enable interactions between humans
and multiple AI agents are necessary. However, there are limited examples of
such platforms for defense environments. To address this gap, we present the
Cogment human-machine teaming experimentation platform, which implements
human-machine teaming (HMT) use cases that features heterogeneous multi-agent
systems and can involve learning AI agents, static AI agents, and humans. It is
built on the Cogment platform and has been used for academic research,
including work presented at the ALA workshop at AAMAS this year [1]. With this
platform, we hope to facilitate further research on human-machine teaming in
critical systems and defense environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11720">Assessing Logical Reasoning Capabilities of Encoder-Only Transformer Models. (arXiv:2312.11720v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pirozelli_P/0/1/0/all/0/1">Paulo Pirozelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Jose_M/0/1/0/all/0/1">Marcos M. Jos&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Filho_P/0/1/0/all/0/1">Paulo de Tarso P. Filho</a>, <a href="http://arxiv.org/find/cs/1/au:+Brandao_A/0/1/0/all/0/1">Anarosa A. F. Brand&#xe3;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Cozman_F/0/1/0/all/0/1">Fabio G. Cozman</a></p>
<p>Logical reasoning is central to complex human activities, such as thinking,
debating, and planning; it is also a central component of many AI systems as
well. In this paper, we investigate the extent to which encoder-only
transformer language models (LMs) can reason according to logical rules. We ask
whether those LMs can deduce theorems in propositional calculus and first-order
logic; if their relative success in these problems reflects general logical
capabilities; and which layers contribute the most to the task. First, we show
for several encoder-only LMs that they can be trained, to a reasonable degree,
to determine logical validity on various datasets. Next, by cross-probing
fine-tuned models on these datasets, we show that LMs have difficulty in
transferring their putative logical reasoning ability, which suggests that they
may have learned dataset-specific features, instead of a general capability.
Finally, we conduct a layerwise probing experiment, which shows that the
hypothesis classification task is mostly solved through higher layers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11747">Robust Stochastic Graph Generator for Counterfactual Explanations. (arXiv:2312.11747v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Prado_Romero_M/0/1/0/all/0/1">Mario Alfonso Prado-Romero</a>, <a href="http://arxiv.org/find/cs/1/au:+Prenkaj_B/0/1/0/all/0/1">Bardh Prenkaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Stilo_G/0/1/0/all/0/1">Giovanni Stilo</a></p>
<p>Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11752">Learning a Diffusion Model Policy from Rewards via Q-Score Matching. (arXiv:2312.11752v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Psenka_M/0/1/0/all/0/1">Michael Psenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Escontrela_A/0/1/0/all/0/1">Alejandro Escontrela</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a></p>
<p>Diffusion models have become a popular choice for representing actor policies
in behavior cloning and offline reinforcement learning. This is due to their
natural ability to optimize an expressive class of distributions over a
continuous space. However, previous works fail to exploit the score-based
structure of diffusion models, and instead utilize a simple behavior cloning
term to train the actor, limiting their ability in the actor-critic setting. In
this paper, we focus on off-policy reinforcement learning and propose a new
method for learning a diffusion model policy that exploits the linked structure
between the score of the policy and the action gradient of the Q-function. We
denote this method Q-score matching and provide theoretical justification for
this approach. We conduct experiments in simulated environments to demonstrate
the effectiveness of our proposed method and compare to popular baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11753">Poker Hand History File Format Specification. (arXiv:2312.11753v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juho Kim</a></p>
<p>This paper introduces the Poker Hand History (PHH) file format, designed to
standardize the recording of poker hands across different game variants.
Despite poker's widespread popularity in the mainstream culture as a mind sport
and its prominence in the field of artificial intelligence (AI) research as a
benchmark for imperfect information AI agents, it lacks a consistent format
that humans can use to document poker hands across different variants that can
also easily be parsed by machines. To address this gap in the literature, we
propose the PHH format which provides a concise human-readable machine-friendly
representation of hand history that comprehensively captures various details of
the hand, ranging from initial game parameters and actions to contextual
parameters including but not limited to the venue, players, and time control
information. In the supplementary, we provide over 10,000 hands covering 11
different variants in the PHH format. Building on our previous work on
PokerKit, a premier poker hand simulation tool, we demonstrate the usages of
our open-source Python implementation of the PHH parser. The source code of the
parser is available on GitHub: https://github.com/uoftcprg/pokerkit
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11761">MineObserver 2.0: A Deep Learning &amp; In-Game Framework for Assessing Natural Language Descriptions of Minecraft Imagery. (arXiv:2312.11761v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mahajan_J/0/1/0/all/0/1">Jay Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hum_S/0/1/0/all/0/1">Samuel Hum</a>, <a href="http://arxiv.org/find/cs/1/au:+Henhapl_J/0/1/0/all/0/1">Jack Henhapl</a>, <a href="http://arxiv.org/find/cs/1/au:+Yunus_D/0/1/0/all/0/1">Diya Yunus</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadbury_M/0/1/0/all/0/1">Matthew Gadbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_E/0/1/0/all/0/1">Emi Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginger_J/0/1/0/all/0/1">Jeff Ginger</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_H/0/1/0/all/0/1">H. Chad Lane</a></p>
<p>MineObserver 2.0 is an AI framework that uses Computer Vision and Natural
Language Processing for assessing the accuracy of learner-generated
descriptions of Minecraft images that include some scientifically relevant
content. The system automatically assesses the accuracy of participant
observations, written in natural language, made during science learning
activities that take place in Minecraft. We demonstrate our system working in
real-time and describe a teacher support dashboard to showcase observations,
both of which advance our previous work. We present the results of a study
showing that MineObserver 2.0 improves over its predecessor both in perceived
accuracy of the system's generated descriptions as well as in usefulness of the
system's feedback. In future work we intend improve system-generated
descriptions, give teachers more control and upgrade the system to perform
continuous learning to more effectively and rapidly respond to novel
observations made by learners.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11768">Curriculum Learning for Cooperation in Multi-Agent Reinforcement Learning. (arXiv:2312.11768v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bhati_R/0/1/0/all/0/1">Rupali Bhati</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottipati_S/0/1/0/all/0/1">Sai Krishna Gottipati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mars_C/0/1/0/all/0/1">Clod&#xe9;ric Mars</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1">Matthew E. Taylor</a></p>
<p>While there has been significant progress in curriculum learning and
continuous learning for training agents to generalize across a wide variety of
environments in the context of single-agent reinforcement learning, it is
unclear if these algorithms would still be valid in a multi-agent setting. In a
competitive setting, a learning agent can be trained by making it compete with
a curriculum of increasingly skilled opponents. However, a general intelligent
agent should also be able to learn to act around other agents and cooperate
with them to achieve common goals. When cooperating with other agents, the
learning agent must (a) learn how to perform the task (or subtask), and (b)
increase the overall team reward. In this paper, we aim to answer the question
of what kind of cooperative teammate, and a curriculum of teammates should a
learning agent be trained with to achieve these two objectives. Our results on
the game Overcooked show that a pre-trained teammate who is less skilled is the
best teammate for overall team reward but the worst for the learning of the
agent. Moreover, somewhat surprisingly, a curriculum of teammates with
decreasing skill levels performs better than other types of curricula.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11779">Are you talking to [&#x27;xem&#x27;] or [&#x27;x&#x27;, &#x27;em&#x27;]? On Tokenization and Addressing Misgendering in LLMs with Pronoun Tokenization Parity. (arXiv:2312.11779v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ovalle_A/0/1/0/all/0/1">Anaelia Ovalle</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrabi_N/0/1/0/all/0/1">Ninareh Mehrabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Palash Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamala_J/0/1/0/all/0/1">Jwala Dhamala</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinter_Y/0/1/0/all/0/1">Yuval Pinter</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1">Rahul Gupta</a></p>
<p>A large body of NLP research has documented the ways gender biases manifest
and amplify within large language models (LLMs), though this research has
predominantly operated within a gender binary-centric context. A growing body
of work has identified the harmful limitations of this gender-exclusive
framing; many LLMs cannot correctly and consistently refer to persons outside
the gender binary, especially if they use neopronouns. While data scarcity has
been identified as a possible culprit, the precise mechanisms through which it
influences LLM misgendering remain underexplored. Our work addresses this gap
by studying data scarcity's role in subword tokenization and, consequently, the
formation of LLM word representations. We uncover how the Byte-Pair Encoding
(BPE) tokenizer, a backbone for many popular LLMs, contributes to neopronoun
misgendering through out-of-vocabulary behavior. We introduce pronoun
tokenization parity (PTP), a novel approach to reduce LLM neopronoun
misgendering by preserving a token's functional structure. We evaluate PTP's
efficacy using pronoun consistency-based metrics and a novel syntax-based
metric. Through several controlled experiments, finetuning LLMs with PTP
improves neopronoun consistency from 14.5% to 58.4%, highlighting the
significant role tokenization plays in LLM pronoun consistency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11805">Gemini: A Family of Highly Capable Multimodal Models. (arXiv:2312.11805v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Team_Gemini/0/1/0/all/0/1">Gemini Team Google</a>: <a href="http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1">Rohan Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgeaud_S/0/1/0/all/0/1">Sebastian Borgeaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Alayrac_J/0/1/0/all/0/1">Jean-Baptiste Alayrac</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiahui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1">Radu Soricut</a>, <a href="http://arxiv.org/find/cs/1/au:+Schalkwyk_J/0/1/0/all/0/1">Johan Schalkwyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Andrew M. Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauth_A/0/1/0/all/0/1">Anja Hauth</a>, <a href="http://arxiv.org/find/cs/1/au:+Millican_K/0/1/0/all/0/1">Katie Millican</a>, <a href="http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1">David Silver</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrov_S/0/1/0/all/0/1">Slav Petrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1">Melvin Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Antonoglou_I/0/1/0/all/0/1">Ioannis Antonoglou</a>, <a href="http://arxiv.org/find/cs/1/au:+Schrittwieser_J/0/1/0/all/0/1">Julian Schrittwieser</a>, <a href="http://arxiv.org/find/cs/1/au:+Glaese_A/0/1/0/all/0/1">Amelia Glaese</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitler_E/0/1/0/all/0/1">Emily Pitler</a>, <a href="http://arxiv.org/find/cs/1/au:+Lillicrap_T/0/1/0/all/0/1">Timothy Lillicrap</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazaridou_A/0/1/0/all/0/1">Angeliki Lazaridou</a>, <a href="http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1">Orhan Firat</a>, <a href="http://arxiv.org/find/cs/1/au:+Molloy_J/0/1/0/all/0/1">James Molloy</a>, <a href="http://arxiv.org/find/cs/1/au:+Isard_M/0/1/0/all/0/1">Michael Isard</a>, <a href="http://arxiv.org/find/cs/1/au:+Barham_P/0/1/0/all/0/1">Paul R. Barham</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennigan_T/0/1/0/all/0/1">Tom Hennigan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Benjamin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Viola_F/0/1/0/all/0/1">Fabio Viola</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuanzhong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Doherty_R/0/1/0/all/0/1">Ryan Doherty</a>, <a href="http://arxiv.org/find/cs/1/au:+Collins_E/0/1/0/all/0/1">Eli Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_C/0/1/0/all/0/1">Clemens Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutherford_E/0/1/0/all/0/1">Eliza Rutherford</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreira_E/0/1/0/all/0/1">Erica Moreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayoub_K/0/1/0/all/0/1">Kareem Ayoub</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_M/0/1/0/all/0/1">Megha Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1">George Tucker</a>, <a href="http://arxiv.org/find/cs/1/au:+Piqueras_E/0/1/0/all/0/1">Enrique Piqueras</a>, <a href="http://arxiv.org/find/cs/1/au:+Krikun_M/0/1/0/all/0/1">Maxim Krikun</a>, <a href="http://arxiv.org/find/cs/1/au:+Barr_I/0/1/0/all/0/1">Iain Barr</a>, <a href="http://arxiv.org/find/cs/1/au:+Savinov_N/0/1/0/all/0/1">Nikolay Savinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Danihelka_I/0/1/0/all/0/1">Ivo Danihelka</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_B/0/1/0/all/0/1">Becca Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1">Ana&#xef;s White</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreassen_A/0/1/0/all/0/1">Anders Andreassen</a>, <a href="http://arxiv.org/find/cs/1/au:+Glehn_T/0/1/0/all/0/1">Tamara von Glehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Yagati_L/0/1/0/all/0/1">Lakshman Yagati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1">Mehran Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_L/0/1/0/all/0/1">Lucas Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalman_M/0/1/0/all/0/1">Misha Khalman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1">Jakub Sygnowski</a>, et al. (890 additional authors not shown)</p>
<p>This report introduces a new family of multimodal models, Gemini, that
exhibit remarkable capabilities across image, audio, video, and text
understanding. The Gemini family consists of Ultra, Pro, and Nano sizes,
suitable for applications ranging from complex reasoning tasks to on-device
memory-constrained use-cases. Evaluation on a broad range of benchmarks shows
that our most-capable Gemini Ultra model advances the state of the art in 30 of
32 of these benchmarks - notably being the first model to achieve human-expert
performance on the well-studied exam benchmark MMLU, and improving the state of
the art in every one of the 20 multimodal benchmarks we examined. We believe
that the new capabilities of Gemini models in cross-modal reasoning and
language understanding will enable a wide variety of use cases and we discuss
our approach toward deploying them responsibly to users.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11812">Advancements and Challenges in Arabic Optical Character Recognition: A Comprehensive Survey. (arXiv:2312.11812v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kasem_M/0/1/0/all/0/1">Mahmoud SalahEldin Kasem</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmoud_M/0/1/0/all/0/1">Mohamed Mahmoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Hyun-Soo Kang</a></p>
<p>Optical character recognition (OCR) is a vital process that involves the
extraction of handwritten or printed text from scanned or printed images,
converting it into a format that can be understood and processed by machines.
This enables further data processing activities such as searching and editing.
The automatic extraction of text through OCR plays a crucial role in digitizing
documents, enhancing productivity, improving accessibility, and preserving
historical records. This paper seeks to offer an exhaustive review of
contemporary applications, methodologies, and challenges associated with Arabic
Optical Character Recognition (OCR). A thorough analysis is conducted on
prevailing techniques utilized throughout the OCR process, with a dedicated
effort to discern the most efficacious approaches that demonstrate enhanced
outcomes. To ensure a thorough evaluation, a meticulous keyword-search
methodology is adopted, encompassing a comprehensive analysis of articles
relevant to Arabic OCR, including both backward and forward citation reviews.
In addition to presenting cutting-edge techniques and methods, this paper
critically identifies research gaps within the realm of Arabic OCR. By
highlighting these gaps, we shed light on potential areas for future
exploration and development, thereby guiding researchers toward promising
avenues in the field of Arabic OCR. The outcomes of this study provide valuable
insights for researchers, practitioners, and stakeholders involved in Arabic
OCR, ultimately fostering advancements in the field and facilitating the
creation of more accurate and efficient OCR systems for the Arabic language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11813">Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment. (arXiv:2312.11813v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fengli Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a></p>
<p>Urban environments, characterized by their complex, multi-layered networks
encompassing physical, social, economic, and environmental dimensions, face
significant challenges in the face of rapid urbanization. These challenges,
ranging from traffic congestion and pollution to social inequality, call for
advanced technological interventions. Recent developments in big data,
artificial intelligence, urban computing, and digital twins have laid the
groundwork for sophisticated city modeling and simulation. However, a gap
persists between these technological capabilities and their practical
implementation in addressing urban challenges in an systemic-intelligent way.
This paper proposes Urban Generative Intelligence (UGI), a novel foundational
platform integrating Large Language Models (LLMs) into urban systems to foster
a new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model
trained on city-specific multi-source data, to create embodied agents for
various urban tasks. These agents, operating within a textual urban environment
emulated by city simulator and urban knowledge graph, interact through a
natural language interface, offering an open platform for diverse intelligent
and embodied agent development. This platform not only addresses specific urban
issues but also simulates complex urban systems, providing a multidisciplinary
approach to understand and manage urban complexity. This work signifies a
transformative step in city science and urban intelligence, harnessing the
power of LLMs to unravel and address the intricate dynamics of urban systems.
The code repository with demonstrations will soon be released here
https://github.com/tsinghua-fib-lab/UGI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11816">A Dual-way Enhanced Framework from Text Matching Point of View for Multimodal Entity Linking. (arXiv:2312.11816v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shezheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1">Tianwei Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shasha Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xiaoguang Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a></p>
<p>Multimodal Entity Linking (MEL) aims at linking ambiguous mentions with
multimodal information to entity in Knowledge Graph (KG) such as Wikipedia,
which plays a key role in many applications. However, existing methods suffer
from shortcomings, including modality impurity such as noise in raw image and
ambiguous textual entity representation, which puts obstacles to MEL. We
formulate multimodal entity linking as a neural text matching problem where
each multimodal information (text and image) is treated as a query, and the
model learns the mapping from each query to the relevant entity from candidate
entities. This paper introduces a dual-way enhanced (DWE) framework for MEL:
(1) our model refines queries with multimodal data and addresses semantic gaps
using cross-modal enhancers between text and image information. Besides, DWE
innovatively leverages fine-grained image attributes, including facial
characteristic and scene feature, to enhance and refine visual features. (2)By
using Wikipedia descriptions, DWE enriches entity semantics and obtains more
comprehensive textual representation, which reduces between textual
representation and the entities in KG. Extensive experiments on three public
benchmarks demonstrate that our method achieves state-of-the-art (SOTA)
performance, indicating the superiority of our model. The code is released on
https://github.com/season1blue/DWE
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11818">Root Cause Explanation of Outliers under Noisy Mechanisms. (arXiv:2312.11818v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1">Phuoc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Truyen Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Sunil Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thin Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1">Svetha Venkatesh</a></p>
<p>Identifying root causes of anomalies in causal processes is vital across
disciplines. Once identified, one can isolate the root causes and implement
necessary measures to restore the normal operation. Causal processes are often
modelled as graphs with entities being nodes and their paths/interconnections
as edge. Existing work only consider the contribution of nodes in the
generative process, thus can not attribute the outlier score to the edges of
the mechanism if the anomaly occurs in the connections. In this paper, we
consider both individual edge and node of each mechanism when identifying the
root causes. We introduce a noisy functional causal model to account for this
purpose. Then, we employ Bayesian learning and inference methods to infer the
noises of the nodes and edges. We then represent the functional form of a
target outlier leaf as a function of the node and edge noises. Finally, we
propose an efficient gradient-based attribution method to compute the anomaly
attribution scores which scales linearly with the number of nodes and edges.
Experiments on simulated datasets and two real-world scenario datasets show
better anomaly attribution performance of the proposed method compared to the
baselines. Our method scales to larger graphs with more nodes and edges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11819">An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. (arXiv:2312.11819v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Youshao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Weichang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhenglei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_F/0/1/0/all/0/1">Fagui Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shangchun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_L/0/1/0/all/0/1">Lin Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1">Lei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a></p>
<p>Recently, ChatGPT or InstructGPT like large language models (LLM) has made a
significant impact in the AI world. These models are incredibly versatile,
capable of performing language tasks on par or even exceeding the capabilities
of human experts. Many works have attempted to reproduce the complex
InstructGPT's RLHF (Reinforcement Learning with Human Feedback) training
pipeline. However, the mainstream distributed RLHF training methods typically
adopt a fixed model placement strategy, referred to as the Flattening strategy.
This strategy treats all four models involved in RLHF as a single entity and
places them on all devices, regardless of their differences. Unfortunately,
this strategy exacerbates the generation bottlenecks in the RLHF training and
degrades the overall training efficiency. To address these issues, we propose
an adaptive model placement framework that offers two flexible model placement
strategies. These strategies allow for the agile allocation of models across
devices in a fine-grained manner. The Interleaving strategy helps reduce memory
redundancy and communication costs during RLHF training. On the other hand, the
Separation strategy improves the throughput of model training by separating the
training and generation stages of the RLHF pipeline. Notably, this framework
seamlessly integrates with other mainstream techniques for acceleration and
enables automatic hyperparameter search. Extensive experiments have
demonstrated that our Interleaving and Separation strategies can achieve
notable improvements up to 11x, compared to the current state-of-the-art (SOTA)
approaches. These experiments encompassed a wide range of training scenarios,
involving models of varying sizes and devices of different scales. The results
highlight the effectiveness and superiority of our approaches in accelerating
the training of distributed RLHF.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11831">Locally-Minimal Probabilistic Explanations. (arXiv:2312.11831v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1">Yacine Izza</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S. Meel</a>, <a href="http://arxiv.org/find/cs/1/au:+Marques_Silva_J/0/1/0/all/0/1">Joao Marques-Silva</a></p>
<p>Formal abductive explanations offer crucial guarantees of rigor and so are of
interest in high-stakes uses of machine learning (ML). One drawback of
abductive explanations is explanation size, justified by the cognitive limits
of human decision-makers. Probabilistic abductive explanations (PAXps) address
this limitation, but their theoretical and practical complexity makes their
exact computation most often unrealistic. This paper proposes novel efficient
algorithms for the computation of locally-minimal PXAps, which offer
high-quality approximations of PXAps in practice. The experimental results
demonstrate the practical efficiency of the proposed algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11834">Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics. (arXiv:2312.11834v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Komatsu_H/0/1/0/all/0/1">Hisato Komatsu</a></p>
<p>In recent years, simulations of pedestrians using the multi-agent
reinforcement learning (MARL) have been studied. This study considered the
roads on a grid-world environment, and implemented pedestrians as MARL agents
using an echo-state network and the least squares policy iteration method.
Under this environment, the ability of these agents to learn to move forward by
avoiding other agents was investigated. Specifically, we considered two types
of tasks: the choice between a narrow direct route and a broad detour, and the
bidirectional pedestrian flow in a corridor. The simulations results indicated
that the learning was successful when the density of the agents was not that
high.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11836">An All-Analog in-Memory Computing Architecture for Multi-Bit and Large-Scale Vector Matrix Multiplication. (arXiv:2312.11836v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xuan_Z/0/1/0/all/0/1">Zihao Xuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Song Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yi Kang</a></p>
<p>Analog in-memory computing (AiMC) is an emerging technology that shows
fantastic performance superiority for neural network acceleration. However, as
the computational bit-width and scale increase, high-precision data conversion
and long-distance data routing will result in unacceptable energy and latency
overheads in the AiMC system. In this work, we focus on the potential of
in-charge computing and in-time interconnection and show an innovative AiMC
architecture, named AiDAC, with three key contributions: (1) AiDAC enhances
multibit computing efficiency and reduces data conversion times by grouping
capacitors technology; (2) AiDAC first adopts row drivers and column time
accumulators to achieve large-scale AiMC arrays integration while minimizing
the energy cost of data movements. (3) AiDAC is the first work to support
large-scale all-analog multibit vector-matrix multiplication (VMM) operations.
The evaluation shows that AiDAC maintains high-precision calculation (less than
0.79% total computing error) while also possessing excellent performance
features, such as high parallelism (up to 26.2TOPS), low latency (&lt;20ns/VMM),
and high energy efficiency (123.8TOPS/W), for 8bits VMM with 1024 input
channels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11846">Initializing Services in Interactive ML Systems for Diverse Users. (arXiv:2312.11846v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1">Avinandan Bose</a>, <a href="http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1">Mihaela Curmei</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daniel L. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgenstern_J/0/1/0/all/0/1">Jamie Morgenstern</a>, <a href="http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1">Sarah Dean</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1">Lillian J.Ratliff</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazel_M/0/1/0/all/0/1">Maryam Fazel</a></p>
<p>This paper studies ML systems that interactively learn from users across
multiple subpopulations with heterogeneous data distributions. The primary
objective is to provide specialized services for different user groups while
also predicting user preferences. Once the users select a service based on how
well the service anticipated their preference, the services subsequently adapt
and refine themselves based on the user data they accumulate, resulting in an
iterative, alternating minimization process between users and services
(learning dynamics). Employing such tailored approaches has two main
challenges: (i) Unknown user preferences: Typically, data on user preferences
are unavailable without interaction, and uniform data collection across a large
and diverse user base can be prohibitively expensive. (ii) Suboptimal Local
Solutions: The total loss (sum of loss functions across all users and all
services) landscape is not convex even if the individual losses on a single
service are convex, making it likely for the learning dynamics to get stuck in
local minima. The final outcome of the aforementioned learning dynamics is thus
strongly influenced by the initial set of services offered to users, and is not
guaranteed to be close to the globally optimal outcome. In this work, we
propose a randomized algorithm to adaptively select very few users to collect
preference data from, while simultaneously initializing a set of services. We
prove that under mild assumptions on the loss functions, the expected total
loss achieved by the algorithm right after initialization is within a factor of
the globally optimal total loss with complete user preference data, and this
factor scales only logarithmically in the number of services. Our theory is
complemented by experiments on real as well as semi-synthetic datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11862">Topo-MLP : A Simplicial Network Without Message Passing. (arXiv:2312.11862v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramamurthy_K/0/1/0/all/0/1">Karthikeyan Natesan Ramamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzman_Saenz_A/0/1/0/all/0/1">Aldo Guzm&#xe1;n-S&#xe1;enz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1">Mustafa Hajij</a></p>
<p>Due to their ability to model meaningful higher order relations among a set
of entities, higher order network models have emerged recently as a powerful
alternative for graph-based network models which are only capable of modeling
binary relationships. Message passing paradigm is still dominantly used to
learn representations even for higher order network models. While powerful,
message passing can have disadvantages during inference, particularly when the
higher order connectivity information is missing or corrupted. To overcome such
limitations, we propose Topo-MLP, a purely MLP-based simplicial neural network
algorithm to learn the representation of elements in a simplicial complex
without explicitly relying on message passing. Our framework utilizes a novel
Higher Order Neighborhood Contrastive (HONC) loss which implicitly incorporates
the simplicial structure into representation learning. Our proposed model's
simplicity makes it faster during inference. Moreover, we show that our model
is robust when faced with missing or corrupted connectivity structure.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11863">Neural Network Approximation for Pessimistic Offline Reinforcement Learning. (arXiv:2312.11863v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yuling Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiliang Lu</a></p>
<p>Deep reinforcement learning (RL) has shown remarkable success in specific
offline decision-making scenarios, yet its theoretical guarantees are still
under development. Existing works on offline RL theory primarily emphasize a
few trivial settings, such as linear MDP or general function approximation with
strong assumptions and independent data, which lack guidance for practical use.
The coupling of deep learning and Bellman residuals makes this problem
challenging, in addition to the difficulty of data dependence. In this paper,
we establish a non-asymptotic estimation error of pessimistic offline RL using
general neural network approximation with $\mathcal{C}$-mixing data regarding
the structure of networks, the dimension of datasets, and the concentrability
of data coverage, under mild assumptions. Our result shows that the estimation
error consists of two parts: the first converges to zero at a desired rate on
the sample size with partially controllable concentrability, and the second
becomes negligible if the residual constraint is tight. This result
demonstrates the explicit efficiency of deep adversarial offline RL frameworks.
We utilize the empirical process tool for $\mathcal{C}$-mixing sequences and
the neural network approximation theory for the H\"{o}lder class to achieve
this. We also develop methods to bound the Bellman estimation error caused by
function approximation with empirical Bellman constraint perturbations.
Additionally, we present a result that lessens the curse of dimensionality
using data with low intrinsic dimensionality and function classes with low
complexity. Our estimation provides valuable insights into the development of
deep offline RL and guidance for algorithm model design.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11865">Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach. (arXiv:2312.11865v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Weiyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_Q/0/1/0/all/0/1">Qirui Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xue Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuqiao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Runji Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haifeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a></p>
<p>StarCraft II is a challenging benchmark for AI agents due to the necessity of
both precise micro level operations and strategic macro awareness. Previous
works, such as Alphastar and SCC, achieve impressive performance on tackling
StarCraft II , however, still exhibit deficiencies in long term strategic
planning and strategy interpretability. Emerging large language model (LLM)
agents, such as Voyage and MetaGPT, presents the immense potential in solving
intricate tasks. Motivated by this, we aim to validate the capabilities of LLMs
on StarCraft II, a highly complex RTS game.To conveniently take full advantage
of LLMs` reasoning abilities, we first develop textual StratCraft II
environment, called TextStarCraft II, which LLM agent can interact. Secondly,
we propose a Chain of Summarization method, including single frame
summarization for processing raw observations and multi frame summarization for
analyzing game information, providing command recommendations, and generating
strategic decisions. Our experiment consists of two parts: first, an evaluation
by human experts, which includes assessing the LLMs`s mastery of StarCraft II
knowledge and the performance of LLM agents in the game; second, the in game
performance of LLM agents, encompassing aspects like win rate and the impact of
Chain of Summarization.Experiment results demonstrate that: 1. LLMs possess the
relevant knowledge and complex planning abilities needed to address StarCraft
II scenarios; 2. Human experts consider the performance of LLM agents to be
close to that of an average player who has played StarCraft II for eight years;
3. LLM agents are capable of defeating the built in AI at the Harder(Lv5)
difficulty level. We have open sourced the code and released demo videos of LLM
agent playing StarCraft II.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11875">Sparse is Enough in Fine-tuning Pre-trained Large Language Model. (arXiv:2312.11875v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Weixi Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zuchao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lefei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a></p>
<p>With the prevalence of pre-training-fine-tuning paradigm, how to efficiently
adapt the pre-trained model to the downstream tasks has been an intriguing
issue. Parameter-Efficient Fine-Tuning (PEFT) methods have been proposed for
low-cost adaptation, including Adapters, Bia-only, and the recently widely used
Low-Rank Adaptation. Although these methods have demonstrated their
effectiveness to some extent and have been widely applied, the underlying
principles are still unclear. In this paper, we reveal the transition of loss
landscape in the downstream domain from random initialization to pre-trained
initialization, that is, from low-amplitude oscillation to high-amplitude
oscillation. The parameter gradients exhibit a property akin to sparsity, where
a small fraction of components dominate the total gradient norm, for instance,
1% of the components account for 99% of the gradient. This property ensures
that the pre-trained model can easily find a flat minimizer which guarantees
the model's ability to generalize even with a low number of trainable
parameters. Based on this, we propose a gradient-based sparse fine-tuning
algorithm, named Sparse Increment Fine-Tuning (SIFT), and validate its
effectiveness on a range of tasks including the GLUE Benchmark and
Instruction-tuning. The code is accessible at https://github.com/song-wx/SIFT/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11881">Punctuation restoration Model and Spacing Model for Korean Ancient Document. (arXiv:2312.11881v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jang_T/0/1/0/all/0/1">Taehong Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_J/0/1/0/all/0/1">Joonmo Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sojung Lucia Kim</a></p>
<p>In Korean ancient documents, there is no spacing or punctuation, and they are
written in classical Chinese characters. This makes it challenging for modern
individuals and translation models to accurately interpret and translate them.
While China has models predicting punctuation and spacing, applying them
directly to Korean texts is problematic due to data differences. Therefore, we
developed the first models which predict punctuation and spacing for Korean
historical texts and evaluated their performance. Our punctuation restoration
model achieved an F1 score of 0.84, and Spacing model achieved a score of 0.96.
It has the advantage of enabling inference on low-performance GPUs with less
VRAM while maintaining quite high accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11882">ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for Accelerating Language Models Inference. (arXiv:2312.11882v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Ziqian Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yihuai Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hongliang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1">Huiping Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cen Chen</a></p>
<p>Early Exiting is one of the most popular methods to achieve efficient
inference. Current early exiting methods adopt the (weighted) sum of the cross
entropy loss of all internal classifiers during training, imposing all these
classifiers to predict all instances correctly. However, during inference, as
long as one internal classifier predicts an instance correctly, it can
accelerate without losing accuracy. Thus, there is a notable gap between
training and inference. We propose ConsistentEE, an early exiting method that
is consistent in training and inference. ConsistentEE formulates the early
exiting process as a reinforcement learning problem. A policy network is added
to decide whether an instance should exit or continue. The training objective
of ConsistentEE only require each instance to be predicted correctly by one
internal classifier. Additionally, we introduce the concept Memorize Layer to
measure the hardness of an instance. We incorporate memorized layer into reward
function design, which allows ``easy'' instances to focus more on acceleration
while ``hard'' instances to focus more on accuracy. Experimental results show
that our method outperforms other baselines on various natural language
understanding and generation tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11889">Predicting Line-Level Defects by Capturing Code Contexts with Hierarchical Transformers. (arXiv:2312.11889v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mahbub_P/0/1/0/all/0/1">Parvez Mahbub</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mohammad Masudur Rahman</a></p>
<p>Software defects consume 40% of the total budget in software development and
cost the global economy billions of dollars every year. Unfortunately, despite
the use of many software quality assurance (SQA) practices in software
development (e.g., code review, continuous integration), defects may still
exist in the official release of a software product. Therefore, prioritizing
SQA efforts for the vulnerable areas of the codebase is essential to ensure the
high quality of a software release. Predicting software defects at the line
level could help prioritize the SQA effort but is a highly challenging task
given that only ~3% of lines of a codebase could be defective. Existing works
on line-level defect prediction often fall short and cannot fully leverage the
line-level defect information. In this paper, we propose Bugsplorer, a novel
deep-learning technique for line-level defect prediction. It leverages a
hierarchical structure of transformer models to represent two types of code
elements: code tokens and code lines. Unlike the existing techniques that are
optimized for file-level defect prediction, Bugsplorer is optimized for a
line-level defect prediction objective. Our evaluation with five performance
metrics shows that Bugsplorer has a promising capability of predicting
defective lines with 26-72% better accuracy than that of the state-of-the-art
technique. It can rank the first 20% defective lines within the top 1-3%
suspicious lines. Thus, Bugsplorer has the potential to significantly reduce
SQA costs by ranking defective lines higher.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11894">3D-LFM: Lifting Foundation Model. (arXiv:2312.11894v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dabhi_M/0/1/0/all/0/1">Mosam Dabhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeni_L/0/1/0/all/0/1">Laszlo A. Jeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1">Simon Lucey</a></p>
<p>The lifting of 3D structure and camera from 2D landmarks is at the
cornerstone of the entire discipline of computer vision. Traditional methods
have been confined to specific rigid objects, such as those in
Perspective-n-Point (PnP) problems, but deep learning has expanded our
capability to reconstruct a wide range of object classes (e.g. C3PDO and PAUL)
with resilience to noise, occlusions, and perspective distortions. All these
techniques, however, have been limited by the fundamental need to establish
correspondences across the 3D training data -- significantly limiting their
utility to applications where one has an abundance of "in-correspondence" 3D
data. Our approach harnesses the inherent permutation equivariance of
transformers to manage varying number of points per 3D data instance,
withstands occlusions, and generalizes to unseen categories. We demonstrate
state of the art performance across 2D-3D lifting task benchmarks. Since our
approach can be trained across such a broad class of structures we refer to it
simply as a 3D Lifting Foundation Model (3D-LFM) -- the first of its kind.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11895">Analyzing Public Reactions, Perceptions, and Attitudes during the MPox Outbreak: Findings from Topic Modeling of Tweets. (arXiv:2312.11895v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nirmalya Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Duggal_Y/0/1/0/all/0/1">Yuvraj Nihal Duggal</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihui Liu</a></p>
<p>The recent outbreak of the MPox virus has resulted in a tremendous increase
in the usage of Twitter. Prior works in this area of research have primarily
focused on the sentiment analysis and content analysis of these Tweets, and the
few works that have focused on topic modeling have multiple limitations. This
paper aims to address this research gap and makes two scientific contributions
to this field. First, it presents the results of performing Topic Modeling on
601,432 Tweets about the 2022 Mpox outbreak that were posted on Twitter between
7 May 2022 and 3 March 2023. The results indicate that the conversations on
Twitter related to Mpox during this time range may be broadly categorized into
four distinct themes - Views and Perspectives about Mpox, Updates on Cases and
Investigations about Mpox, Mpox and the LGBTQIA+ Community, and Mpox and
COVID-19. Second, the paper presents the findings from the analysis of these
Tweets. The results show that the theme that was most popular on Twitter (in
terms of the number of Tweets posted) during this time range was Views and
Perspectives about Mpox. This was followed by the theme of Mpox and the
LGBTQIA+ Community, which was followed by the themes of Mpox and COVID-19 and
Updates on Cases and Investigations about Mpox, respectively. Finally, a
comparison with related studies in this area of research is also presented to
highlight the novelty and significance of this research work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11922">Relation-Aware Question Answering for Heterogeneous Knowledge Graphs. (arXiv:2312.11922v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Haowei Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Quzhe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongyan Zhao</a></p>
<p>Multi-hop Knowledge Base Question Answering(KBQA) aims to find the answer
entity in a knowledge graph (KG), which requires multiple steps of reasoning.
Existing retrieval-based approaches solve this task by concentrating on the
specific relation at different hops and predicting the intermediate entity
within the reasoning path. During the reasoning process of these methods, the
representation of relations are fixed but the initial relation representation
may not be optimal. We claim they fail to utilize information from head-tail
entities and the semantic connection between relations to enhance the current
relation representation, which undermines the ability to capture information of
relations in KGs. To address this issue, we construct a \textbf{dual relation
graph} where each node denotes a relation in the original KG (\textbf{primal
entity graph}) and edges are constructed between relations sharing same head or
tail entities. Then we iteratively do primal entity graph reasoning, dual
relation graph information propagation, and interaction between these two
graphs. In this way, the interaction between entity and relation is enhanced,
and we derive better entity and relation representations. Experiments on two
public datasets, WebQSP and CWQ, show that our approach achieves a significant
performance gain over the prior state-of-the-art. Our code is available on
\url{https://github.com/yanmenxue/RAH-KBQA}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11929">Transformer Network for Multi-Person Tracking and Re-Identification in Unconstrained Environment. (arXiv:2312.11929v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mukhtar_H/0/1/0/all/0/1">Hamza Mukhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Muhammad Usman Ghani Khan</a></p>
<p>Multi-object tracking (MOT) has profound applications in a variety of fields,
including surveillance, sports analytics, self-driving, and cooperative
robotics. Despite considerable advancements, existing MOT methodologies tend to
falter when faced with non-uniform movements, occlusions, and
appearance-reappearance scenarios of the objects. Recognizing this inadequacy,
we put forward an integrated MOT method that not only marries object detection
and identity linkage within a singular, end-to-end trainable framework but also
equips the model with the ability to maintain object identity links over long
periods of time. Our proposed model, named STMMOT, is built around four key
modules: 1) candidate proposal generation, which generates object proposals via
a vision-transformer encoder-decoder architecture that detects the object from
each frame in the video; 2) scale variant pyramid, a progressive pyramid
structure to learn the self-scale and cross-scale similarities in multi-scale
feature maps; 3) spatio-temporal memory encoder, extracting the essential
information from the memory associated with each object under tracking; and 4)
spatio-temporal memory decoder, simultaneously resolving the tasks of object
detection and identity association for MOT. Our system leverages a robust
spatio-temporal memory module that retains extensive historical observations
and effectively encodes them using an attention-based aggregator. The
uniqueness of STMMOT lies in representing objects as dynamic query embeddings
that are updated continuously, which enables the prediction of object states
with attention mechanisms and eradicates the need for post-processing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11933">Dynamic Frequency Domain Graph Convolutional Network for Traffic Forecasting. (arXiv:2312.11933v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yujie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zezhi Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yongjun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Q/0/1/0/all/0/1">Qiang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhaogang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a></p>
<p>Complex spatial dependencies in transportation networks make traffic
prediction extremely challenging. Much existing work is devoted to learning
dynamic graph structures among sensors, and the strategy of mining spatial
dependencies from traffic data, known as data-driven, tends to be an intuitive
and effective approach. However, Time-Shift of traffic patterns and noise
induced by random factors hinder data-driven spatial dependence modeling. In
this paper, we propose a novel dynamic frequency domain graph convolution
network (DFDGCN) to capture spatial dependencies. Specifically, we mitigate the
effects of time-shift by Fourier transform, and introduce the identity
embedding of sensors and time embedding when capturing data for graph learning
since traffic data with noise is not entirely reliable. The graph is combined
with static predefined and self-adaptive graphs during graph convolution to
predict future traffic data through classical causal convolutions. Extensive
experiments on four real-world datasets demonstrate that our model is effective
and outperforms the baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11934">Identification of Causal Structure with Latent Variables Based on Higher Order Cumulants. (arXiv:2312.11934v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhifeng Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a></p>
<p>Causal discovery with latent variables is a crucial but challenging task.
Despite the emergence of numerous methods aimed at addressing this challenge,
they are not fully identified to the structure that two observed variables are
influenced by one latent variable and there might be a directed edge in
between. Interestingly, we notice that this structure can be identified through
the utilization of higher-order cumulants. By leveraging the higher-order
cumulants of non-Gaussian data, we provide an analytical solution for
estimating the causal coefficients or their ratios. With the estimated (ratios
of) causal coefficients, we propose a novel approach to identify the existence
of a causal edge between two observed variables subject to latent variable
influence. In case when such a causal edge exits, we introduce an asymmetry
criterion to determine the causal direction. The experimental results
demonstrate the effectiveness of our proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11935">Parameterized Decision-making with Multi-modal Perception for Autonomous Driving. (arXiv:2312.11935v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yuyang Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuncheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Quanlin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Liwei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">You Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Han Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kai Zheng</a></p>
<p>Autonomous driving is an emerging technology that has advanced rapidly over
the last decade. Modern transportation is expected to benefit greatly from a
wise decision-making framework of autonomous vehicles, including the
improvement of mobility and the minimization of risks and travel time. However,
existing methods either ignore the complexity of environments only fitting
straight roads, or ignore the impact on surrounding vehicles during
optimization phases, leading to weak environmental adaptability and incomplete
optimization objectives. To address these limitations, we propose a
parameterized decision-making framework with multi-modal perception based on
deep reinforcement learning, called AUTO. We conduct a comprehensive perception
to capture the state features of various traffic participants around the
autonomous vehicle, based on which we design a graph-based model to learn a
state representation of the multi-modal semantic features. To distinguish
between lane-following and lane-changing, we decompose an action of the
autonomous vehicle into a parameterized action structure that first decides
whether to change lanes and then computes an exact action to execute. A hybrid
reward function takes into account aspects of safety, traffic efficiency,
passenger comfort, and impact to guide the framework to generate optimal
actions. In addition, we design a regularization term and a multi-worker
paradigm to enhance the training. Extensive experiments offer evidence that
AUTO can advance state-of-the-art in terms of both macroscopic and microscopic
effectiveness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11936">Exact ASP Counting with Compact Encodings. (arXiv:2312.11936v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kabir_M/0/1/0/all/0/1">Mohimenul Kabir</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Supratik Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S Meel</a></p>
<p>Answer Set Programming (ASP) has emerged as a promising paradigm in knowledge
representation and automated reasoning owing to its ability to model hard
combinatorial problems from diverse domains in a natural way. Building on
advances in propositional SAT solving, the past two decades have witnessed the
emergence of well-engineered systems for solving the answer set satisfiability
problem, i.e., finding models or answer sets for a given answer set program. In
recent years, there has been growing interest in problems beyond
satisfiability, such as model counting, in the context of ASP. Akin to the
early days of propositional model counting, state-of-the-art exact answer set
counters do not scale well beyond small instances. Exact ASP counters struggle
with handling larger input formulas. The primary contribution of this paper is
a new ASP counting framework, called sharpASP, which counts answer sets
avoiding larger input formulas. This relies on an alternative way of defining
answer sets that allows for the lifting of key techniques developed in the
context of propositional model counting. Our extensive empirical analysis over
1470 benchmarks demonstrates significant performance gain over current
state-of-the-art exact answer set counters. Specifically, by using sharpASP, we
were able to solve 1062 benchmarks with PAR2 score of 3082 whereas using prior
state-of-the-art, we could only solve 895 benchmarks with a PAR2 score of 4205,
all other experimental conditions being the same.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11939">Time-Series Contrastive Learning against False Negatives and Class Imbalance. (arXiv:2312.11939v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiyuan Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a></p>
<p>As an exemplary self-supervised approach for representation learning,
time-series contrastive learning has exhibited remarkable advancements in
contemporary research. While recent contrastive learning strategies have
focused on how to construct appropriate positives and negatives, in this study,
we conduct theoretical analysis and find they have overlooked the fundamental
issues: false negatives and class imbalance inherent in the InfoNCE loss-based
framework. Therefore, we introduce a straightforward modification grounded in
the SimCLR framework, universally adaptable to models engaged in the instance
discrimination task. By constructing instance graphs to facilitate interactive
learning among instances, we emulate supervised contrastive learning via the
multiple-instances discrimination task, mitigating the harmful impact of false
negatives. Moreover, leveraging the graph structure and few-labeled data, we
perform semi-supervised consistency classification and enhance the
representative ability of minority classes. We compared our method with the
most popular time-series contrastive learning methods on four real-world
time-series datasets and demonstrated our significant advantages in overall
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11942">Skills or Degree? The Rise of Skill-Based Hiring for AI and Green Jobs. (arXiv:2312.11942v1 [econ.GN])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Ehlinger_E/0/1/0/all/0/1">Eugenia Gonzalez Ehlinger</a>, <a href="http://arxiv.org/find/econ/1/au:+Stephany_F/0/1/0/all/0/1">Fabian Stephany</a></p>
<p>For emerging professions, such as jobs in the field of Artificial
Intelligence (AI) or sustainability (green), labour supply does not meet
industry demand. In this scenario of labour shortages, our work aims to
understand whether employers have started focusing on individual skills rather
than on formal qualifications in their recruiting. By analysing a large time
series dataset of around one million online job vacancies between 2019 and 2022
from the UK and drawing on diverse literature on technological change and
labour market signalling, we provide evidence that employers have started
so-called "skill-based hiring" for AI and green roles, as more flexible hiring
practices allow them to increase the available talent pool. In our observation
period the demand for AI roles grew twice as much as average labour demand. At
the same time, the mention of university education for AI roles declined by
23%, while AI roles advertise five times as many skills as job postings on
average. Our regression analysis also shows that university degrees no longer
show an educational premium for AI roles, while for green positions the
educational premium persists. In contrast, AI skills have a wage premium of
16%, similar to having a PhD (17%). Our work recommends making use of
alternative skill building formats such as apprenticeships, on-the-job
training, MOOCs, vocational education and training, micro-certificates, and
online bootcamps to use human capital to its full potential and to tackle
talent shortages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11943">Stability of Multi-Agent Learning in Competitive Networks: Delaying the Onset of Chaos. (arXiv:2312.11943v1 [cs.GT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1">Aamal Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Belardinelli_F/0/1/0/all/0/1">Francesco Belardinelli</a></p>
<p>The behaviour of multi-agent learning in competitive network games is often
studied within the context of zero-sum games, in which convergence guarantees
may be obtained. However, outside of this class the behaviour of learning is
known to display complex behaviours and convergence cannot be always
guaranteed. Nonetheless, in order to develop a complete picture of the
behaviour of multi-agent learning in competitive settings, the zero-sum
assumption must be lifted. Motivated by this we study the Q-Learning dynamics,
a popular model of exploration and exploitation in multi-agent learning, in
competitive network games. We determine how the degree of competition,
exploration rate and network connectivity impact the convergence of Q-Learning.
To study generic competitive games, we parameterise network games in terms of
correlations between agent payoffs and study the average behaviour of the
Q-Learning dynamics across all games drawn from a choice of this parameter.
This statistical approach establishes choices of parameters for which
Q-Learning dynamics converge to a stable fixed point. Differently to previous
works, we find that the stability of Q-Learning is explicitly dependent only on
the network connectivity rather than the total number of agents. Our
experiments validate these findings and show that, under certain network
structures, the total number of agents can be increased without increasing the
likelihood of unstable or chaotic behaviours.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11952">Automatic Parameter Selection for Non-Redundant Clustering. (arXiv:2312.11952v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leiber_C/0/1/0/all/0/1">Collin Leiber</a>, <a href="http://arxiv.org/find/cs/1/au:+Mautz_D/0/1/0/all/0/1">Dominik Mautz</a>, <a href="http://arxiv.org/find/cs/1/au:+Plant_C/0/1/0/all/0/1">Claudia Plant</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohm_C/0/1/0/all/0/1">Christian B&#xf6;hm</a></p>
<p>High-dimensional datasets often contain multiple meaningful clusterings in
different subspaces. For example, objects can be clustered either by color,
weight, or size, revealing different interpretations of the given dataset. A
variety of approaches are able to identify such non-redundant clusterings.
However, most of these methods require the user to specify the expected number
of subspaces and clusters for each subspace. Stating these values is a
non-trivial problem and usually requires detailed knowledge of the input
dataset. In this paper, we propose a framework that utilizes the Minimum
Description Length Principle (MDL) to detect the number of subspaces and
clusters per subspace automatically. We describe an efficient procedure that
greedily searches the parameter space by splitting and merging subspaces and
clusters within subspaces. Additionally, an encoding strategy is introduced
that allows us to detect outliers in each subspace. Extensive experiments show
that our approach is highly competitive to state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11955">Vertical Symbolic Regression. (arXiv:2312.11955v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1">Md Nasim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Yexiang Xue</a></p>
<p>Automating scientific discovery has been a grand goal of Artificial
Intelligence (AI) and will bring tremendous societal impact. Learning symbolic
expressions from experimental data is a vital step in AI-driven scientific
discovery. Despite exciting progress, most endeavors have focused on the
horizontal discovery paths, i.e., they directly search for the best expression
in the full hypothesis space involving all the independent variables.
Horizontal paths are challenging due to the exponentially large hypothesis
space involving all the independent variables. We propose Vertical Symbolic
Regression (VSR) to expedite symbolic regression. The VSR starts by fitting
simple expressions involving a few independent variables under controlled
experiments where the remaining variables are held constant. It then extends
the expressions learned in previous rounds by adding new independent variables
and using new control variable experiments allowing these variables to vary.
The first few steps in vertical discovery are significantly cheaper than the
horizontal path, as their search is in reduced hypothesis spaces involving a
small set of variables. As a consequence, vertical discovery has the potential
to supercharge state-of-the-art symbolic regression approaches in handling
complex equations with many contributing factors. Theoretically, we show that
the search space of VSR can be exponentially smaller than that of horizontal
approaches when learning a class of expressions. Experimentally, VSR
outperforms several baselines in learning symbolic expressions involving many
independent variables.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11970">Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives. (arXiv:2312.11970v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_X/0/1/0/all/0/1">Xiaochong Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Nian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jingtao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhilun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fengli Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a></p>
<p>Agent-based modeling and simulation has evolved as a powerful tool for
modeling complex systems, offering insights into emergent behaviors and
interactions among diverse agents. Integrating large language models into
agent-based modeling and simulation presents a promising avenue for enhancing
simulation capabilities. This paper surveys the landscape of utilizing large
language models in agent-based modeling and simulation, examining their
challenges and promising future directions. In this survey, since this is an
interdisciplinary field, we first introduce the background of agent-based
modeling and simulation and large language model-empowered agents. We then
discuss the motivation for applying large language models to agent-based
simulation and systematically analyze the challenges in environment perception,
human alignment, action generation, and evaluation. Most importantly, we
provide a comprehensive overview of the recent works of large language
model-empowered agent-based modeling and simulation in multiple scenarios,
which can be divided into four domains: cyber, physical, social, and hybrid,
covering simulation of both real-world and virtual environments. Finally, since
this area is new and quickly evolving, we discuss the open problems and
promising future directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11973">Continual Learning: Forget-free Winning Subnetworks for Video Representations. (arXiv:2312.11973v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Haeyong Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jaehong Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1">Chang D. Yoo</a></p>
<p>Inspired by the Regularized Lottery Ticket Hypothesis (RLTH), which
highlights the presence of competitive subnetworks within dense networks for
continual learning tasks, we introduce Winning Subnetworks (WSN). This approach
utilizes reused weights in dense networks to enhance learning in Task
Incremental Learning (TIL) scenarios. To mitigate overfitting in Few-Shot Class
Incremental Learning (FSCIL), we have developed WSN variants referred to as the
Soft subnetwork (SoftNet). Furthermore, addressing WSN's limitation of sparse
reused weights in Video Incremental Learning (VIL), we propose the Fourier
Subneural Operator (FSO). The FSO, operating in Fourier space, adaptively and
compactly encodes videos, discovering reusable subnetworks with diverse
bandwidths. We have applied FSO's Fourier representations to various continual
learning contexts, including VIL, TIL, and FSCIL. Our extensive experiments
across these scenarios demonstrate FSO's remarkable efficacy in continual
learning, significantly enhancing task performance at various convolutional
representational levels: it boosts performance in the higher layers for TIL and
FSCIL and the lower layers for VIL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11976">When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection. (arXiv:2312.11976v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongmin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a></p>
<p>Time-series anomaly detection deals with the problem of detecting anomalous
timesteps by learning normality from the sequence of observations. However, the
concept of normality evolves over time, leading to a "new normal problem",
where the distribution of normality can be changed due to the distribution
shifts between training and test data. This paper highlights the prevalence of
the new normal problem in unsupervised time-series anomaly detection studies.
To tackle this issue, we propose a simple yet effective test-time adaptation
strategy based on trend estimation and a self-supervised approach to learning
new normalities during inference. Extensive experiments on real-world
benchmarks demonstrate that incorporating the proposed strategy into the
anomaly detector consistently improves the model's performance compared to the
baselines, leading to robustness to the distribution shifts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11983">Fluctuation-based Adaptive Structured Pruning for Large Language Models. (arXiv:2312.11983v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+An_Y/0/1/0/all/0/1">Yongqi An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1">Ming Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinqiao Wang</a></p>
<p>Network Pruning is a promising way to address the huge computing resource
demands of the deployment and inference of Large Language Models (LLMs).
Retraining-free is important for LLMs' pruning methods. However, almost all of
the existing retraining-free pruning approaches for LLMs focus on unstructured
pruning, which requires specific hardware support for acceleration. In this
paper, we propose a novel retraining-free structured pruning framework for
LLMs, named FLAP (FLuctuation-based Adaptive Structured Pruning). It is
hardware-friendly by effectively reducing storage and enhancing inference
speed. For effective structured pruning of LLMs, we highlight three critical
elements that demand the utmost attention: formulating structured importance
metrics, adaptively searching the global compressed model, and implementing
compensation mechanisms to mitigate performance loss. First, FLAP determines
whether the output feature map is easily recoverable when a column of weight is
removed, based on the fluctuation pruning metric. Then it standardizes the
importance scores to adaptively determine the global compressed model
structure. At last, FLAP adds additional bias terms to recover the output
feature maps using the baseline values. We thoroughly evaluate our approach on
a variety of language benchmarks. Without any retraining, our method
significantly outperforms the state-of-the-art methods, including LLM-Pruner
and the extension of Wanda in structured pruning. The code is released at
https://github.com/CASIA-IVA-Lab/FLAP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11988">Xpert: Empowering Incident Management with Query Recommendations via Large Language Models. (arXiv:2312.11988v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuxuan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chaoyun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shilin He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhihao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Minghua Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1">Si Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_Y/0/1/0/all/0/1">Yingnong Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1">Saravan Rajmohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1">Qingwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a></p>
<p>Large-scale cloud systems play a pivotal role in modern IT infrastructure.
However, incidents occurring within these systems can lead to service
disruptions and adversely affect user experience. To swiftly resolve such
incidents, on-call engineers depend on crafting domain-specific language (DSL)
queries to analyze telemetry data. However, writing these queries can be
challenging and time-consuming. This paper presents a thorough empirical study
on the utilization of queries of KQL, a DSL employed for incident management in
a large-scale cloud management system at Microsoft. The findings obtained
underscore the importance and viability of KQL queries recommendation to
enhance incident management.
</p>
<p>Building upon these valuable insights, we introduce Xpert, an end-to-end
machine learning framework that automates KQL recommendation process. By
leveraging historical incident data and large language models, Xpert generates
customized KQL queries tailored to new incidents. Furthermore, Xpert
incorporates a novel performance metric called Xcore, enabling a thorough
evaluation of query quality from three comprehensive perspectives. We conduct
extensive evaluations of Xpert, demonstrating its effectiveness in offline
settings. Notably, we deploy Xpert in the real production environment of a
large-scale incident management system in Microsoft, validating its efficiency
in supporting incident management. To the best of our knowledge, this paper
represents the first empirical study of its kind, and Xpert stands as a
pioneering DSL query recommendation framework designed for incident management.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12000">Diffusing More Objects for Semi-Supervised Domain Adaptation with Less Labeling. (arXiv:2312.12000v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Heuvel_L/0/1/0/all/0/1">Leander van den Heuvel</a>, <a href="http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1">Gertjan Burghouts</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">David W. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Englebienne_G/0/1/0/all/0/1">Gwenn Englebienne</a>, <a href="http://arxiv.org/find/cs/1/au:+Rooij_S/0/1/0/all/0/1">Sabina B. van Rooij</a></p>
<p>For object detection, it is possible to view the prediction of bounding boxes
as a reverse diffusion process. Using a diffusion model, the random bounding
boxes are iteratively refined in a denoising step, conditioned on the image. We
propose a stochastic accumulator function that starts each run with random
bounding boxes and combines the slightly different predictions. We empirically
verify that this improves detection performance. The improved detections are
leveraged on unlabelled images as weighted pseudo-labels for semi-supervised
learning. We evaluate the method on a challenging out-of-domain test set. Our
method brings significant improvements and is on par with human-selected
pseudo-labels, while not requiring any human involvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12009">Active Preference Inference using Language Models and Probabilistic Reasoning. (arXiv:2312.12009v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Piriyakulkij_T/0/1/0/all/0/1">Top Piriyakulkij</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1">Volodymyr Kuleshov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_K/0/1/0/all/0/1">Kevin Ellis</a></p>
<p>Actively inferring user preferences, for example by asking good questions, is
important for any human-facing decision-making system. Active inference allows
such systems to adapt and personalize themselves to nuanced individual
preferences. To enable this ability for instruction-tuned large language models
(LLMs), one may prompt them to ask users questions to infer their preferences,
transforming the language models into more robust, interactive systems.
However, out of the box, these models are not efficient at extracting
preferences: the questions they generate are not informative, requiring a high
number of user interactions and impeding the usability of the downstream
system. In this work, we introduce an inference-time algorithm that helps LLMs
quickly infer preferences by using more informative questions. Our algorithm
uses a probabilistic model whose conditional distributions are defined by
prompting an LLM, and returns questions that optimize expected entropy and
expected model change. Results in a simplified interactive web shopping setting
with real product items show that an LLM equipped with our entropy reduction
algorithm outperforms baselines with the same underlying LLM on task
performance while using fewer user interactions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12010">Flexible categorization using formal concept analysis and Dempster-Shafer theory. (arXiv:2312.12010v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Boersma_M/0/1/0/all/0/1">Marcel Boersma</a>, <a href="http://arxiv.org/find/cs/1/au:+Manoorkar_K/0/1/0/all/0/1">Krishna Manoorkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Palmigiano_A/0/1/0/all/0/1">Alessandra Palmigiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Panettiere_M/0/1/0/all/0/1">Mattia Panettiere</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzimoulis_A/0/1/0/all/0/1">Apostolos Tzimoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijnberg_N/0/1/0/all/0/1">Nachoem Wijnberg</a></p>
<p>Categorization of business processes is an important part of auditing. Large
amounts of transactional data in auditing can be represented as transactions
between financial accounts using weighted bipartite graphs. We view such
bipartite graphs as many-valued formal contexts, which we use to obtain
explainable categorization of these business processes in terms of financial
accounts involved in a business process by using methods in formal concept
analysis. We use Dempster-Shafer mass functions to represent agendas showing
different interest in different set of financial accounts. We also model some
possible deliberation scenarios between agents with different interrogative
agendas to reach an aggregated agenda and categorization. The framework
developed in this paper provides a formal ground to obtain and study
explainable categorizations from the data represented as bipartite graphs
according to the agendas of different agents in an organization (e.g. an audit
firm), and interaction between these through deliberation. We use this
framework to describe a machine-leaning meta algorithm for outlier detection
and classification which can provide local and global explanations of its
result and demonstrate it through an outlier detection algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12021">Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction. (arXiv:2312.12021v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DaLuo/0/1/0/all/0/1">DaLuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1">Yanglei Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1">Rui Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Run Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuxiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wannian Gao</a></p>
<p>Few-shot Relation Extraction (FSRE) aims to extract relational facts from a
sparse set of labeled corpora. Recent studies have shown promising results in
FSRE by employing Pre-trained Language Models (PLMs) within the framework of
supervised contrastive learning, which considers both instances and label
facts. However, how to effectively harness massive instance-label pairs to
encompass the learned representation with semantic richness in this learning
paradigm is not fully explored. To address this gap, we introduce a novel
synergistic anchored contrastive pre-training framework. This framework is
motivated by the insight that the diverse viewpoints conveyed through
instance-label pairs capture incomplete yet complementary intrinsic textual
semantics. Specifically, our framework involves a symmetrical contrastive
objective that encompasses both sentence-anchored and label-anchored
contrastive losses. By combining these two losses, the model establishes a
robust and uniform representation space. This space effectively captures the
reciprocal alignment of feature distributions among instances and relational
facts, simultaneously enhancing the maximization of mutual information across
diverse perspectives within the same relation. Experimental results demonstrate
that our framework achieves significant performance enhancements compared to
baseline models in downstream FSRE tasks. Furthermore, our approach exhibits
superior adaptability to handle the challenges of domain shift and zero-shot
relation extraction. Our code is available online at
https://github.com/AONE-NLP/FSRE-SaCon.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12030">Towards Accurate Guided Diffusion Sampling through Symplectic Adjoint Method. (arXiv:2312.12030v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jiachun Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hanshu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liew_J/0/1/0/all/0/1">Jun Hao Liew</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a></p>
<p>Training-free guided sampling in diffusion models leverages off-the-shelf
pre-trained networks, such as an aesthetic evaluation model, to guide the
generation process. Current training-free guided sampling algorithms obtain the
guidance energy function based on a one-step estimate of the clean image.
However, since the off-the-shelf pre-trained networks are trained on clean
images, the one-step estimation procedure of the clean image may be inaccurate,
especially in the early stages of the generation process in diffusion models.
This causes the guidance in the early time steps to be inaccurate. To overcome
this problem, we propose Symplectic Adjoint Guidance (SAG), which calculates
the gradient guidance in two inner stages. Firstly, SAG estimates the clean
image via $n$ function calls, where $n$ serves as a flexible hyperparameter
that can be tailored to meet specific image quality requirements. Secondly, SAG
uses the symplectic adjoint method to obtain the gradients accurately and
efficiently in terms of the memory requirements. Extensive experiments
demonstrate that SAG generates images with higher qualities compared to the
baselines in both guided image and video generation tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12036">LHManip: A Dataset for Long-Horizon Language-Grounded Manipulation Tasks in Cluttered Tabletop Environments. (arXiv:2312.12036v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ceola_F/0/1/0/all/0/1">Federico Ceola</a>, <a href="http://arxiv.org/find/cs/1/au:+Natale_L/0/1/0/all/0/1">Lorenzo Natale</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunderhauf_N/0/1/0/all/0/1">Niko S&#xfc;nderhauf</a>, <a href="http://arxiv.org/find/cs/1/au:+Rana_K/0/1/0/all/0/1">Krishan Rana</a></p>
<p>Instructing a robot to complete an everyday task within our homes has been a
long-standing challenge for robotics. While recent progress in
language-conditioned imitation learning and offline reinforcement learning has
demonstrated impressive performance across a wide range of tasks, they are
typically limited to short-horizon tasks -- not reflective of those a home
robot would be expected to complete. While existing architectures have the
potential to learn these desired behaviours, the lack of the necessary
long-horizon, multi-step datasets for real robotic systems poses a significant
challenge. To this end, we present the Long-Horizon Manipulation (LHManip)
dataset comprising 200 episodes, demonstrating 20 different manipulation tasks
via real robot teleoperation. The tasks entail multiple sub-tasks, including
grasping, pushing, stacking and throwing objects in highly cluttered
environments. Each task is paired with a natural language instruction and
multi-camera viewpoints for point-cloud or NeRF reconstruction. In total, the
dataset comprises 176,278 observation-action pairs which form part of the Open
X-Embodiment dataset. The full LHManip dataset is made publicly available
\href{https://github.com/fedeceola/LHManip}{here}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12037">Founder-GPT: Self-play to evaluate the Founder-Idea fit. (arXiv:2312.12037v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiong_S/0/1/0/all/0/1">Sichao Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ihlamur_Y/0/1/0/all/0/1">Yigit Ihlamur</a></p>
<p>This research introduces an innovative evaluation method for the
"founder-idea" fit in early-stage startups, utilizing advanced large language
model techniques to assess founders' profiles against their startup ideas to
enhance decision-making. Embeddings, self-play, tree-of-thought, and
critique-based refinement techniques show early promising results that each
idea's success patterns are unique and they should be evaluated based on the
context of the founder's background.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12050">Extension of the Dip-test Repertoire -- Efficient and Differentiable p-value Calculation for Clustering. (arXiv:2312.12050v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bauer_L/0/1/0/all/0/1">Lena G. M. Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Leiber_C/0/1/0/all/0/1">Collin Leiber</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohm_C/0/1/0/all/0/1">Christian B&#xf6;hm</a>, <a href="http://arxiv.org/find/cs/1/au:+Plant_C/0/1/0/all/0/1">Claudia Plant</a></p>
<p>Over the last decade, the Dip-test of unimodality has gained increasing
interest in the data mining community as it is a parameter-free statistical
test that reliably rates the modality in one-dimensional samples. It returns a
so called Dip-value and a corresponding probability for the sample's
unimodality (Dip-p-value). These two values share a sigmoidal relationship.
However, the specific transformation is dependent on the sample size. Many
Dip-based clustering algorithms use bootstrapped look-up tables translating
Dip- to Dip-p-values for a certain limited amount of sample sizes. We propose a
specifically designed sigmoid function as a substitute for these
state-of-the-art look-up tables. This accelerates computation and provides an
approximation of the Dip- to Dip-p-value transformation for every single sample
size. Further, it is differentiable and can therefore easily be integrated in
learning schemes using gradient descent. We showcase this by exploiting our
function in a novel subspace clustering algorithm called Dip'n'Sub. We
highlight in extensive experiments the various benefits of our proposal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2001.11165">Empirical Analysis of Fictitious Play for Nash Equilibrium Computation in Multiplayer Games. (arXiv:2001.11165v8 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1">Sam Ganzfried</a></p>
<p>While fictitious play is guaranteed to converge to Nash equilibrium in
certain game classes, such as two-player zero-sum games, it is not guaranteed
to converge in non-zero-sum and multiplayer games. We show that fictitious play
in fact leads to improved Nash equilibrium approximation over a variety of game
classes and sizes than (counterfactual) regret minimization, which has recently
produced superhuman play for multiplayer poker. We also show that when
fictitious play is run several times using random initializations it is able to
solve several known challenge problems in which the standard version is known
to not converge, including Shapley's classic counterexample. These provide some
of the first positive results for fictitious play in these settings, despite
the fact that worst-case theoretical results are negative.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2010.03744">Maximum Reward Formulation In Reinforcement Learning. (arXiv:2010.03744v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gottipati_S/0/1/0/all/0/1">Sai Krishna Gottipati</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_Y/0/1/0/all/0/1">Yashaswi Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuttall_R/0/1/0/all/0/1">Rohan Nuttall</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahir/0/1/0/all/0/1">Sahir</a>, <a href="http://arxiv.org/find/cs/1/au:+Chunduru_R/0/1/0/all/0/1">Raviteja Chunduru</a>, <a href="http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1">Ahmed Touati</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_S/0/1/0/all/0/1">Sriram Ganapathi Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1">Matthew E. Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a></p>
<p>Reinforcement learning (RL) algorithms typically deal with maximizing the
expected cumulative return (discounted or undiscounted, finite or infinite
horizon). However, several crucial applications in the real world, such as drug
discovery, do not fit within this framework because an RL agent only needs to
identify states (molecules) that achieve the highest reward within a trajectory
and does not need to optimize for the expected cumulative return. In this work,
we formulate an objective function to maximize the expected maximum reward
along a trajectory, derive a novel functional form of the Bellman equation,
introduce the corresponding Bellman operators, and provide a proof of
convergence. Using this formulation, we achieve state-of-the-art results on the
task of molecule generation that mimics a real-world drug discovery pipeline.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.03518">Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion Cause Extraction. (arXiv:2106.03518v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hanqi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1">Lin Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1">Gabriele Pergola</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yulan He</a></p>
<p>The Emotion Cause Extraction (ECE)} task aims to identify clauses which
contain emotion-evoking information for a particular emotion expressed in text.
We observe that a widely-used ECE dataset exhibits a bias that the majority of
annotated cause clauses are either directly before their associated emotion
clauses or are the emotion clauses themselves. Existing models for ECE tend to
explore such relative position information and suffer from the dataset bias. To
investigate the degree of reliance of existing ECE models on clause relative
positions, we propose a novel strategy to generate adversarial examples in
which the relative position information is no longer the indicative feature of
cause clauses. We test the performance of existing models on such adversarial
examples and observe a significant performance drop. To address the dataset
bias, we propose a novel graph-based method to explicitly model the emotion
triggering paths by leveraging the commonsense knowledge to enhance the
semantic dependencies between a candidate clause and an emotion clause.
Experimental results show that our proposed approach performs on par with the
existing state-of-the-art methods on the original ECE dataset, and is more
robust against adversarial attacks compared to existing models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.15677">Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1">Liang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yige Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Songtao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chongyang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Siyuan Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1">Pengfei Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huawei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a></p>
<p>Training generative adversarial networks (GANs) with limited data is
challenging because the discriminator is prone to overfitting. Previously
proposed differentiable augmentation demonstrates improved data efficiency of
training GANs. However, the augmentation implicitly introduces undesired
invariance to augmentation for the discriminator since it ignores the change of
semantics in the label space caused by data transformation, which may limit the
representation learning ability of the discriminator and ultimately affect the
generative modeling performance of the generator. To mitigate the negative
impact of invariance while inheriting the benefits of data augmentation, we
propose a novel augmentation-aware self-supervised discriminator that predicts
the augmentation parameter of the augmented data. Particularly, the prediction
targets of real data and generated data are required to be distinguished since
they are different during training. We further encourage the generator to
adversarially learn from the self-supervised discriminator by generating
augmentation-predictable real and not fake data. This formulation connects the
learning objective of the generator and the arithmetic $-$ harmonic mean
divergence under certain assumptions. We compare our method with
state-of-the-art (SOTA) methods using the class-conditional BigGAN and
unconditional StyleGAN2 architectures on data-limited CIFAR-10, CIFAR-100,
FFHQ, LSUN-Cat, and five low-shot datasets. Experimental results demonstrate
significant improvements of our method over SOTA methods in training
data-efficient GANs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.06009">Relative Policy-Transition Optimization for Fast Policy Transfer. (arXiv:2206.06009v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiawei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Cheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baoxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lei Han</a></p>
<p>We consider the problem of policy transfer between two Markov Decision
Processes (MDPs). We introduce a lemma based on existing theoretical results in
reinforcement learning to measure the relativity gap between two arbitrary
MDPs, that is the difference between any two cumulative expected returns
defined on different policies and environment dynamics. Based on this lemma, we
propose two new algorithms referred to as Relative Policy Optimization (RPO)
and Relative Transition Optimization (RTO), which offer fast policy transfer
and dynamics modelling, respectively. RPO transfers the policy evaluated in one
environment to maximize the return in another, while RTO updates the
parameterized dynamics model to reduce the gap between the dynamics of the two
environments. Integrating the two algorithms results in the complete Relative
Policy-Transition Optimization (RPTO) algorithm, in which the policy interacts
with the two environments simultaneously, such that data collections from two
environments, policy and transition updates are completed in one closed loop to
form a principled learning framework for policy transfer. We demonstrate the
effectiveness of RPTO on a set of MuJoCo continuous control tasks by creating
policy transfer problems via variant dynamics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.08563">Submodularity, pairwise independence and correlation gap. (arXiv:2209.08563v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Ramachandra_A/0/1/0/all/0/1">Arjun Ramachandra</a>, <a href="http://arxiv.org/find/math/1/au:+Natarajan_K/0/1/0/all/0/1">Karthik Natarajan</a></p>
<p>In this paper, we provide a characterization of the expected value of
monotone submodular set functions with $n$ pairwise independent random inputs.
Inspired by the notion of ``correlation gap'', we study the ratio of the
maximum expected value of a function with arbitrary dependence among the random
inputs with given marginal probabilities to the maximum expected value of the
function with pairwise independent random inputs and the same marginal
probabilities. Our results show that the ratio is upper bounded by: (a) $4/3$
for $n = 3$ with general marginal probabilities and any monotone submodular set
function (b) $4/3$ for general $n$ with small and large marginal probabilities
and any monotone submodular set function and (c) $4k/(4k-1)$ for general $n$,
general identical probabilities and rank functions of $k$-uniform matroids. The
bound is tight in all three cases. This contrasts with the $e/(e-1)$ bound on
the correlation gap ratio for monotone submodular set functions with mutually
independent random inputs (which is known to be tight in case (b)), and
illustrates a fundamental difference in the behavior of submodular functions
with weaker notions of independence. These results can be immediately extended
beyond pairwise independence to correlated random inputs. We discuss
applications in distributionally robust optimization and mechanism design and
end the paper with a conjecture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.11584">Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations. (arXiv:2210.11584v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yao Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Leemann_T/0/1/0/all/0/1">Tobias Leemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thai-trang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiedler_L/0/1/0/all/0/1">Lisa Fiedler</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_P/0/1/0/all/0/1">Peizhu Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Unhelkar_V/0/1/0/all/0/1">Vaibhav Unhelkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_T/0/1/0/all/0/1">Tina Seidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1">Gjergji Kasneci</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1">Enkelejda Kasneci</a></p>
<p>Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI
research. A better understanding of the needs of XAI users, as well as
human-centered evaluations of explainable models are both a necessity and a
challenge. In this paper, we explore how HCI and AI researchers conduct user
studies in XAI applications based on a systematic literature review. After
identifying and thoroughly analyzing 97core papers with human-based XAI
evaluations over the past five years, we categorize them along the measured
characteristics of explanatory methods, namely trust, understanding, usability,
and human-AI collaboration performance. Our research shows that XAI is
spreading more rapidly in certain application domains, such as recommender
systems than in others, but that user evaluations are still rather sparse and
incorporate hardly any insights from cognitive or social sciences. Based on a
comprehensive discussion of best practices, i.e., common models, design
choices, and measures in user studies, we propose practical guidelines on
designing and conducting user studies for XAI researchers and practitioners.
Lastly, this survey also highlights several open research directions,
particularly linking psychological science and human-centered XAI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.15657">Detecting fake accounts through Generative Adversarial Network in online social media. (arXiv:2210.15657v3 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bordbar_J/0/1/0/all/0/1">Jinus Bordbar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadrezaie_M/0/1/0/all/0/1">Mohammadreza Mohammadrezaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardalan_S/0/1/0/all/0/1">Saman Ardalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiri_M/0/1/0/all/0/1">Mohammad Ebrahim Shiri</a></p>
<p>Online social media is integral to human life, facilitating messaging,
information sharing, and confidential communication while preserving privacy.
Platforms like Twitter, Instagram, and Facebook exemplify this phenomenon.
However, users face challenges due to network anomalies, often stemming from
malicious activities such as identity theft for financial gain or harm. This
paper proposes a novel method using user similarity measures and the Generative
Adversarial Network (GAN) algorithm to identify fake user accounts in the
Twitter dataset. Despite the problem's complexity, the method achieves an AUC
rate of 80\% in classifying and detecting fake accounts. Notably, the study
builds on previous research, highlighting advancements and insights into the
evolving landscape of anomaly detection in online social networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.16058">Goal Exploration Augmentation via Pre-trained Skills for Sparse-Reward Long-Horizon Goal-Conditioned Reinforcement Learning. (arXiv:2210.16058v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lisheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a></p>
<p>Reinforcement learning (RL) often struggles to accomplish a sparse-reward
long-horizon task in a complex environment. Goal-conditioned reinforcement
learning (GCRL) has been employed to tackle this difficult problem via a
curriculum of easy-to-reach sub-goals. In GCRL, exploring novel sub-goals is
essential for the agent to ultimately find the pathway to the desired goal. How
to explore novel sub-goals efficiently is one of the most challenging issues in
GCRL. Several goal exploration methods have been proposed to address this issue
but still struggle to find the desired goals efficiently. In this paper, we
propose a novel learning objective by optimizing the entropy of both achieved
and new goals to be explored for more efficient goal exploration in sub-goal
selection based GCRL. To optimize this objective, we first explore and exploit
the frequently occurring goal-transition patterns mined in the environments
similar to the current task to compose skills via skill learning. Then, the
pretrained skills are applied in goal exploration. Evaluation on a variety of
spare-reward long-horizon benchmark tasks suggests that incorporating our
method into several state-of-the-art GCRL baselines significantly boosts their
exploration efficiency while improving or maintaining their performance. The
source code is available at: https://github.com/GEAPS/GEAPS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08494">Who Reviews The Reviewers? A Multi-Level Jury Problem. (arXiv:2211.08494v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abramowitz_B/0/1/0/all/0/1">Ben Abramowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lev_O/0/1/0/all/0/1">Omer Lev</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattei_N/0/1/0/all/0/1">Nicholas Mattei</a></p>
<p>We consider the problem of determining a binary ground truth using advice
from a group of independent reviewers (experts) who express their guess about a
ground truth correctly with some independent probability (competence). In this
setting, when all reviewers are competent (competence greater than one-half),
the Condorcet Jury Theorem tells us that adding more reviewers increases the
overall accuracy, and if all competences are known, then there exists an
optimal weighting of the reviewers. However, in practical settings, reviewers
may be noisy or incompetent, i.e., competence below half, and the number of
experts may be small, so the asymptotic Condorcet Jury Theorem is not
practically relevant. In such cases we explore appointing one or more chairs
(judges) who determine the weight of each reviewer for aggregation, creating
multiple levels. However, these chairs may be unable to correctly identify the
competence of the reviewers they oversee, and therefore unable to compute the
optimal weighting. We give conditions when a set of chairs is able to weight
the reviewers optimally, and depending on the competence distribution of the
agents, give results about when it is better to have more chairs or more
reviewers. Through numerical simulations we show that in some cases it is
better to have more chairs, but in many cases it is better to have more
reviewers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.01071">Fake detection in imbalance dataset by Semi-supervised learning with GAN. (arXiv:2212.01071v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bordbar_J/0/1/0/all/0/1">Jinus Bordbar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardalan_S/0/1/0/all/0/1">Saman Ardalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadrezaie_M/0/1/0/all/0/1">Mohammadreza Mohammadrezaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghasemi_Z/0/1/0/all/0/1">Zahra Ghasemi</a></p>
<p>As social media continues to grow rapidly, the prevalence of harassment on
these platforms has also increased. This has piqued the interest of researchers
in the field of fake detection. Social media data, often forms complex graphs
with numerous nodes, posing several challenges. These challenges and
limitations include dealing with a significant amount of irrelevant features in
matrices and addressing issues such as high data dispersion and an imbalanced
class distribution within the dataset. To overcome these challenges and
limitations, researchers have employed auto-encoders and a combination of
semi-supervised learning with a GAN algorithm, referred to as SGAN. Our
proposed method utilizes auto-encoders for feature extraction and incorporates
SGAN. By leveraging an unlabeled dataset, the unsupervised layer of SGAN
compensates for the limited availability of labeled data, making efficient use
of the limited number of labeled instances. Multiple evaluation metrics were
employed, including the Confusion Matrix and the ROC curve. The dataset was
divided into training and testing sets, with 100 labeled samples for training
and 1,000 samples for testing. The novelty of our research lies in applying
SGAN to address the issue of imbalanced datasets in fake account detection. By
optimizing the use of a smaller number of labeled instances and reducing the
need for extensive computational power, our method offers a more efficient
solution. Additionally, our study contributes to the field by achieving an 81%
accuracy in detecting fake accounts using only 100 labeled samples. This
demonstrates the potential of SGAN as a powerful tool for handling minority
classes and addressing big data challenges in fake account detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09010">Risk-Sensitive Reinforcement Learning with Exponential Criteria. (arXiv:2212.09010v4 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Noorani_E/0/1/0/all/0/1">Erfaun Noorani</a>, <a href="http://arxiv.org/find/eess/1/au:+Mavridis_C/0/1/0/all/0/1">Christos Mavridis</a>, <a href="http://arxiv.org/find/eess/1/au:+Baras_J/0/1/0/all/0/1">John Baras</a></p>
<p>While reinforcement learning has shown experimental success in a number of
applications, it is known to be sensitive to noise and perturbations in the
parameters of the system, leading to high variance in the total reward amongst
different episodes in slightly different environments. To introduce robustness,
as well as sample efficiency, risk-sensitive reinforcement learning methods are
being thoroughly studied. In this work, we provide a definition of robust
reinforcement learning policies and formulate a risk-sensitive reinforcement
learning problem to approximate them, by solving an optimization problem with
respect to a modified objective based on exponential criteria. In particular,
we study a model-free risk-sensitive variation of the widely-used Monte Carlo
Policy Gradient algorithm and introduce a novel risk-sensitive online
Actor-Critic algorithm based on solving a multiplicative Bellman equation using
stochastic approximation updates. Analytical results suggest that the use of
exponential criteria generalizes commonly used ad-hoc regularization
approaches, improves sample efficiency, and introduces robustness with respect
to perturbations in the model parameters and the environment. The
implementation, performance, and robustness properties of the proposed methods
are evaluated in simulated experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.12538">Mathematical Foundations for a Compositional Account of the Bayesian Brain. (arXiv:2212.12538v3 [q-bio.NC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Smithe_T/0/1/0/all/0/1">Toby St Clere Smithe</a></p>
<p>This dissertation reports some first steps towards a compositional account of
active inference and the Bayesian brain. Specifically, we use the tools of
contemporary applied category theory to supply functorial semantics for
approximate inference. To do so, we define on the `syntactic' side the new
notion of Bayesian lens and show that Bayesian updating composes according to
the compositional lens pattern. Using Bayesian lenses, and inspired by
compositional game theory, we define fibrations of statistical games and
classify various problems of statistical inference as corresponding sections:
the chain rule of the relative entropy is formalized as a strict section, while
maximum likelihood estimation and the free energy give lax sections. In the
process, we introduce a new notion of `copy-composition'.
</p>
<p>On the `semantic' side, we present a new formalization of general open
dynamical systems (particularly: deterministic, stochastic, and random; and
discrete- and continuous-time) as certain coalgebras of polynomial functors,
which we show collect into monoidal opindexed categories (or, alternatively,
into algebras for multicategories of generalized polynomial functors). We use
these opindexed categories to define monoidal bicategories of cilia: dynamical
systems which control lenses, and which supply the target for our functorial
semantics. Accordingly, we construct functors which explain the bidirectional
compositional structure of predictive coding neural circuits under the free
energy principle, thereby giving a formal mathematical underpinning to the
bidirectionality observed in the cortex. Along the way, we explain how to
compose rate-coded neural circuits using an algebra for a multicategory of
linear circuit diagrams, showing subsequently that this is subsumed by lenses
and polynomial functors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.08830">Finding Nash equilibria by minimizing approximate exploitability with learned best responses. (arXiv:2301.08830v2 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1">Carlos Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1">Tuomas Sandholm</a></p>
<p>There has been substantial progress on finding game-theoretic equilibria.
Most of that work has focused on games with finite, discrete action spaces.
However, many games involving space, time, money, and other fine-grained
quantities have continuous action spaces (or are best modeled as such). We
study the problem of finding an approximate Nash equilibrium of games with
continuous action sets. The standard measure of closeness to Nash equilibrium
is exploitability, which measures how much players can benefit from
unilaterally changing their strategy. We propose two new methods that minimize
an approximation of the exploitability with respect to the strategy profile.
The first method uses a learned best-response function, which takes the current
strategy profile as input and returns candidate best responses for each player.
The strategy profile and best-response functions are trained simultaneously,
with the former trying to minimize exploitability while the latter tries to
maximize it. The second method maintains an ensemble of candidate best
responses for each player. In each iteration, the best-performing elements of
each ensemble are used to update the current strategy profile. The strategy
profile and best-response ensembles are simultaneously trained to minimize and
maximize the approximate exploitability, respectively. We evaluate our methods
on various continuous games, showing that they outperform prior methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.01242">Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal. (arXiv:2302.01242v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marconato_E/0/1/0/all/0/1">Emanuele Marconato</a>, <a href="http://arxiv.org/find/cs/1/au:+Bontempo_G/0/1/0/all/0/1">Gianpaolo Bontempo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ficarra_E/0/1/0/all/0/1">Elisa Ficarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderara_S/0/1/0/all/0/1">Simone Calderara</a>, <a href="http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1">Andrea Passerini</a>, <a href="http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1">Stefano Teso</a></p>
<p>We introduce Neuro-Symbolic Continual Learning, where a model has to solve a
sequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to
high-level concepts and compute predictions by reasoning consistently with
prior knowledge. Our key observation is that neuro-symbolic tasks, although
different, often share concepts whose semantics remains stable over time.
Traditional approaches fall short: existing continual strategies ignore
knowledge altogether, while stock neuro-symbolic architectures suffer from
catastrophic forgetting. We show that leveraging prior knowledge by combining
neuro-symbolic architectures with continual strategies does help avoid
catastrophic forgetting, but also that doing so can yield models affected by
reasoning shortcuts. These undermine the semantics of the acquired concepts,
even when detailed prior knowledge is provided upfront and inference is exact,
and in turn continual performance. To overcome these issues, we introduce COOL,
a COncept-level cOntinual Learning strategy tailored for neuro-symbolic
continual problems that acquires high-quality concepts and remembers them over
time. Our experiments on three novel benchmarks highlights how COOL attains
sustained high performance on neuro-symbolic continual learning tasks in which
other strategies fail.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.09532">Pseudo Contrastive Learning for Graph-based Semi-supervised Learning. (arXiv:2302.09532v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Weigang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1">Ziyu Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yuanhai Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1">Lining Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Baosheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a></p>
<p>Pseudo Labeling is a technique used to improve the performance of
semi-supervised Graph Neural Networks (GNNs) by generating additional
pseudo-labels based on confident predictions. However, the quality of generated
pseudo-labels has been a longstanding concern due to the sensitivity of the
classification objective with respect to the given labels. To avoid the
untrustworthy classification supervision indicating ``a node belongs to a
specific class,'' we favor the fault-tolerant contrasting supervision
demonstrating ``two nodes do not belong to the same class.'' Thus, the problem
of generating high-quality pseudo-labels is then transformed into a relaxed
version, i.e., identifying reliable negative pairs. To achieve this, we propose
a general framework for GNNs, termed Pseudo Contrastive Learning (PCL). It
separates two nodes whose positive and negative pseudo-labels target the same
class. To incorporate topological knowledge into learning, we devise a
topologically weighted contrastive loss that spends more effort separating
negative pairs with smaller topological distances. Experimentally, we apply PCL
to various GNNs, which consistently outperform their counterparts using other
popular general techniques on five real-world graphs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.08774">GPT-4 Technical Report. (arXiv:2303.08774v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+OpenAI/0/1/0/all/0/1">OpenAI</a>: <a href="http://arxiv.org/find/cs/1/au:+Achiam_J/0/1/0/all/0/1">Josh Achiam</a>, <a href="http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1">Steven Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sandhini Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_L/0/1/0/all/0/1">Lama Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Akkaya_I/0/1/0/all/0/1">Ilge Akkaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Aleman_F/0/1/0/all/0/1">Florencia Leoni Aleman</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1">Diogo Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Altenschmidt_J/0/1/0/all/0/1">Janko Altenschmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Altman_S/0/1/0/all/0/1">Sam Altman</a>, <a href="http://arxiv.org/find/cs/1/au:+Anadkat_S/0/1/0/all/0/1">Shyamal Anadkat</a>, <a href="http://arxiv.org/find/cs/1/au:+Avila_R/0/1/0/all/0/1">Red Avila</a>, <a href="http://arxiv.org/find/cs/1/au:+Babuschkin_I/0/1/0/all/0/1">Igor Babuschkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaji_S/0/1/0/all/0/1">Suchir Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Balcom_V/0/1/0/all/0/1">Valerie Balcom</a>, <a href="http://arxiv.org/find/cs/1/au:+Baltescu_P/0/1/0/all/0/1">Paul Baltescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1">Haiming Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bavarian_M/0/1/0/all/0/1">Mo Bavarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Belgum_J/0/1/0/all/0/1">Jeff Belgum</a>, <a href="http://arxiv.org/find/cs/1/au:+Bello_I/0/1/0/all/0/1">Irwan Bello</a>, <a href="http://arxiv.org/find/cs/1/au:+Berdine_J/0/1/0/all/0/1">Jake Berdine</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernadett_Shapiro_G/0/1/0/all/0/1">Gabriel Bernadett-Shapiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Berner_C/0/1/0/all/0/1">Christopher Berner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogdonoff_L/0/1/0/all/0/1">Lenny Bogdonoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Boiko_O/0/1/0/all/0/1">Oleg Boiko</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyd_M/0/1/0/all/0/1">Madelaine Boyd</a>, <a href="http://arxiv.org/find/cs/1/au:+Brakman_A/0/1/0/all/0/1">Anna-Luisa Brakman</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockman_G/0/1/0/all/0/1">Greg Brockman</a>, <a href="http://arxiv.org/find/cs/1/au:+Brooks_T/0/1/0/all/0/1">Tim Brooks</a>, <a href="http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1">Miles Brundage</a>, <a href="http://arxiv.org/find/cs/1/au:+Button_K/0/1/0/all/0/1">Kevin Button</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Trevor Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_R/0/1/0/all/0/1">Rosie Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Cann_A/0/1/0/all/0/1">Andrew Cann</a>, <a href="http://arxiv.org/find/cs/1/au:+Carey_B/0/1/0/all/0/1">Brittany Carey</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlson_C/0/1/0/all/0/1">Chelsea Carlson</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmichael_R/0/1/0/all/0/1">Rory Carmichael</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_B/0/1/0/all/0/1">Brooke Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Che Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chantzis_F/0/1/0/all/0/1">Fotis Chantzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Derek Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sully Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Ruby Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jason Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mark Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chess_B/0/1/0/all/0/1">Ben Chess</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_C/0/1/0/all/0/1">Chester Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1">Casey Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hyung Won Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_D/0/1/0/all/0/1">Dave Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Currier_J/0/1/0/all/0/1">Jeremiah Currier</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yunxing Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Decareaux_C/0/1/0/all/0/1">Cory Decareaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Degry_T/0/1/0/all/0/1">Thomas Degry</a>, <a href="http://arxiv.org/find/cs/1/au:+Deutsch_N/0/1/0/all/0/1">Noah Deutsch</a>, et al. (226 additional authors not shown)</p>
<p>We report the development of GPT-4, a large-scale, multimodal model which can
accept image and text inputs and produce text outputs. While less capable than
humans in many real-world scenarios, GPT-4 exhibits human-level performance on
various professional and academic benchmarks, including passing a simulated bar
exam with a score around the top 10% of test takers. GPT-4 is a
Transformer-based model pre-trained to predict the next token in a document.
The post-training alignment process results in improved performance on measures
of factuality and adherence to desired behavior. A core component of this
project was developing infrastructure and optimization methods that behave
predictably across a wide range of scales. This allowed us to accurately
predict some aspects of GPT-4's performance based on models trained with no
more than 1/1,000th the compute of GPT-4.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10343">Supervision Interpolation via LossMix: Generalizing Mixup for Object Detection and Beyond. (arXiv:2303.10343v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1">Thanh Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Baochen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Bodi Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngai_A/0/1/0/all/0/1">Alex Ngai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yueqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Frahm_J/0/1/0/all/0/1">Jan-Michael Frahm</a></p>
<p>The success of data mixing augmentations in image classification tasks has
been well-received. However, these techniques cannot be readily applied to
object detection due to challenges such as spatial misalignment,
foreground/background distinction, and plurality of instances. To tackle these
issues, we first introduce a novel conceptual framework called Supervision
Interpolation (SI), which offers a fresh perspective on interpolation-based
augmentations by relaxing and generalizing Mixup. Based on SI, we propose
LossMix, a simple yet versatile and effective regularization that enhances the
performance and robustness of object detectors and more. Our key insight is
that we can effectively regularize the training on mixed data by interpolating
their loss errors instead of ground truth labels. Empirical results on the
PASCAL VOC and MS COCO datasets demonstrate that LossMix can consistently
outperform state-of-the-art methods widely adopted for detection. Furthermore,
by jointly leveraging LossMix with unsupervised domain adaptation, we
successfully improve existing approaches and set a new state of the art for
cross-domain object detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16737">Multi-Agent Reinforcement Learning with Action Masking for UAV-enabled Mobile Communications. (arXiv:2303.16737v2 [cs.MA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rizvi_D/0/1/0/all/0/1">Danish Rizvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyle_D/0/1/0/all/0/1">David Boyle</a></p>
<p>Unmanned Aerial Vehicles (UAVs) are increasingly used as aerial base stations
to provide ad hoc communications infrastructure. Building upon prior research
efforts which consider either static nodes, 2D trajectories or single UAV
systems, this paper focuses on the use of multiple UAVs for providing wireless
communication to mobile users in the absence of terrestrial communications
infrastructure. In particular, we jointly optimize UAV 3D trajectory and NOMA
power allocation to maximize system throughput. Firstly, a weighted
K-means-based clustering algorithm establishes UAV-user associations at regular
intervals. The efficacy of training a novel Shared Deep Q-Network (SDQN) with
action masking is then explored. Unlike training each UAV separately using DQN,
the SDQN reduces training time by using the experiences of multiple UAVs
instead of a single agent. We also show that SDQN can be used to train a
multi-agent system with differing action spaces. Simulation results confirm
that: 1) training a shared DQN outperforms a conventional DQN in terms of
maximum system throughput (+20%) and training time (-10%); 2) it can converge
for agents with different action spaces, yielding a 9% increase in throughput
compared to mutual learning algorithms; and 3) combining NOMA with an SDQN
architecture enables the network to achieve a better sum rate compared with
existing baseline schemes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.05805">GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v2 [econ.EM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Nemeth_K/0/1/0/all/0/1">Krist&#xf3;f N&#xe9;meth</a>, <a href="http://arxiv.org/find/econ/1/au:+Hadhazi_D/0/1/0/all/0/1">D&#xe1;niel Hadh&#xe1;zi</a></p>
<p>In our study, we apply artificial neural networks (ANNs) to nowcast quarterly
GDP growth for the U.S. economy. Using the monthly FRED-MD database, we compare
the nowcasting performance of five different ANN architectures: the multilayer
perceptron (MLP), the one-dimensional convolutional neural network (1D CNN),
the Elman recurrent neural network (RNN), the long short-term memory network
(LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the
results from two distinctively different evaluation periods. The first (2012:Q1
-- 2019:Q4) is characterized by balanced economic growth, while the second
(2012:Q1 -- 2022:Q4) also includes periods of the COVID-19 recession. According
to our results, longer input sequences result in more accurate nowcasts in
periods of balanced economic growth. However, this effect ceases above a
relatively low threshold value of around six quarters (eighteen months). During
periods of economic turbulence (e.g., during the COVID-19 recession), longer
input sequences do not help the models' predictive performance; instead, they
seem to weaken their generalization capability. Combined results from the two
evaluation periods indicate that architectural features enabling for long-term
memory do not result in more accurate nowcasts. On the other hand, the 1D CNN
has proved to be a highly suitable model for GDP nowcasting. The network has
shown good nowcasting performance among the competitors during the first
evaluation period and achieved the overall best accuracy during the second
evaluation period. Consequently, first in the literature, we propose the
application of the 1D CNN for economic nowcasting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11014">Generalized Planning in PDDL Domains with Pretrained Large Language Models. (arXiv:2305.11014v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Silver_T/0/1/0/all/0/1">Tom Silver</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1">Soham Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivas_K/0/1/0/all/0/1">Kavitha Srinivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1">Leslie Pack Kaelbling</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_M/0/1/0/all/0/1">Michael Katz</a></p>
<p>Recent work has considered whether large language models (LLMs) can function
as planners: given a task, generate a plan. We investigate whether LLMs can
serve as generalized planners: given a domain and training tasks, generate a
program that efficiently produces plans for other tasks in the domain. In
particular, we consider PDDL domains and use GPT-4 to synthesize Python
programs. We also consider (1) Chain-of-Thought (CoT) summarization, where the
LLM is prompted to summarize the domain and propose a strategy in words before
synthesizing the program; and (2) automated debugging, where the program is
validated with respect to the training tasks, and in case of errors, the LLM is
re-prompted with four types of feedback. We evaluate this approach in seven
PDDL domains and compare it to four ablations and four baselines. Overall, we
find that GPT-4 is a surprisingly powerful generalized planner. We also
conclude that automated debugging is very important, that CoT summarization has
non-uniform impact, that GPT-4 is far superior to GPT-3.5, and that just two
training tasks are often sufficient for strong generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12015">Inventing art styles with no artistic training data. (arXiv:2305.12015v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abrahamsen_N/0/1/0/all/0/1">Nilin Abrahamsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiahao Yao</a></p>
<p>We propose two procedures to create painting styles using models trained only
on natural images, providing objective proof that the model is not plagiarizing
human art styles. In the first procedure we use the inductive bias from the
artistic medium to achieve creative expression. Abstraction is achieved by
using a reconstruction loss. The second procedure uses an additional natural
image as inspiration to create a new style. These two procedures make it
possible to invent new painting styles with no artistic training data. We
believe that our approach can help pave the way for the ethical employment of
generative AI in art, without infringing upon the originality of human
creators.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13030">Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations. (arXiv:2305.13030v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1">Keisuke Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsutsui_K/0/1/0/all/0/1">Kazushi Tsutsui</a>, <a href="http://arxiv.org/find/cs/1/au:+Scott_A/0/1/0/all/0/1">Atom Scott</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakahara_H/0/1/0/all/0/1">Hiroshi Nakahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeishi_N/0/1/0/all/0/1">Naoya Takeishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawahara_Y/0/1/0/all/0/1">Yoshinobu Kawahara</a></p>
<p>Modeling of real-world biological multi-agents is a fundamental problem in
various scientific and engineering fields. Reinforcement learning (RL) is a
powerful framework to generate flexible and diverse behaviors in cyberspace;
however, when modeling real-world biological multi-agents, there is a domain
gap between behaviors in the source (i.e., real-world data) and the target
(i.e., cyberspace for RL), and the source environment parameters are usually
unknown. In this paper, we propose a method for adaptive action supervision in
RL from real-world demonstrations in multi-agent scenarios. We adopt an
approach that combines RL and supervised learning by selecting actions of
demonstrations in RL based on the minimum distance of dynamic time warping for
utilizing the information of the unknown source dynamics. This approach can be
easily applied to many existing neural network architectures and provide us
with an RL model balanced between reproducibility as imitation and
generalization ability to obtain rewards in cyberspace. In the experiments,
using chase-and-escape and football tasks with the different dynamics between
the unknown source and target environments, we show that our approach achieved
a balance between the reproducibility and the generalization ability compared
with the baselines. In particular, we used the tracking data of professional
football players as expert demonstrations in football and show successful
performances despite the larger gap between behaviors in the source and target
environments than the chase-and-escape task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06154">HypLL: The Hyperbolic Learning Library. (arXiv:2306.06154v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Spengler_M/0/1/0/all/0/1">Max van Spengler</a>, <a href="http://arxiv.org/find/cs/1/au:+Wirth_P/0/1/0/all/0/1">Philipp Wirth</a>, <a href="http://arxiv.org/find/cs/1/au:+Mettes_P/0/1/0/all/0/1">Pascal Mettes</a></p>
<p>Deep learning in hyperbolic space is quickly gaining traction in the fields
of machine learning, multimedia, and computer vision. Deep networks commonly
operate in Euclidean space, implicitly assuming that data lies on regular
grids. Recent advances have shown that hyperbolic geometry provides a viable
alternative foundation for deep learning, especially when data is hierarchical
in nature and when working with few embedding dimensions. Currently however, no
accessible open-source library exists to build hyperbolic network modules akin
to well-known deep learning libraries. We present HypLL, the Hyperbolic
Learning Library to bring the progress on hyperbolic deep learning together.
HypLL is built on top of PyTorch, with an emphasis in its design for
ease-of-use, in order to attract a broad audience towards this new and
open-ended research direction. The code is available at:
https://github.com/maxvanspengler/hyperbolic_learning_library.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06399">Designing Behavior Trees from Goal-Oriented LTLf Formulas. (arXiv:2307.06399v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Neupane_A/0/1/0/all/0/1">Aadesh Neupane</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercer_E/0/1/0/all/0/1">Eric G Mercer</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodrich_M/0/1/0/all/0/1">Michael A. Goodrich</a></p>
<p>Temporal logic can be used to formally specify autonomous agent goals, but
synthesizing planners that guarantee goal satisfaction can be computationally
prohibitive. This paper shows how to turn goals specified using a subset of
finite trace Linear Temporal Logic (LTL) into a behavior tree (BT) that
guarantees that successful traces satisfy the LTL goal. Useful LTL formulas for
achievement goals can be derived using achievement-oriented task mission
grammars, leading to missions made up of tasks combined using LTL operators.
Constructing BTs from LTL formulas leads to a relaxed behavior synthesis
problem in which a wide range of planners can implement the action nodes in the
BT. Importantly, any successful trace induced by the planners satisfies the
corresponding LTL formula. The usefulness of the approach is demonstrated in
two ways: a) exploring the alignment between two planners and LTL goals, and b)
solving a sequential key-door problem for a Fetch robot.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03358">RGMComm: Return Gap Minimization via Discrete Communications in Multi-Agent Reinforcement Learning. (arXiv:2308.03358v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingdi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_T/0/1/0/all/0/1">Tian Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joe_Wong_C/0/1/0/all/0/1">Carlee Joe-Wong</a></p>
<p>Communication is crucial for solving cooperative Multi-Agent Reinforcement
Learning tasks in partially observable Markov Decision Processes. Existing
works often rely on black-box methods to encode local information/features into
messages shared with other agents, leading to the generation of continuous
messages with high communication overhead and poor interpretability. Prior
attempts at discrete communication methods generate one-hot vectors trained as
part of agents' actions and use the Gumbel softmax operation for calculating
message gradients, which are all heuristic designs that do not provide any
quantitative guarantees on the expected return. This paper establishes an upper
bound on the return gap between an ideal policy with full observability and an
optimal partially observable policy with discrete communication. This result
enables us to recast multi-agent communication into a novel online clustering
problem over the local observations at each agent, with messages as cluster
labels and the upper bound on the return gap as clustering loss. To minimize
the return gap, we propose the Return-Gap-Minimization Communication (RGMComm)
algorithm, which is a surprisingly simple design of discrete message generation
functions and is integrated with reinforcement learning through the utilization
of a novel Regularized Information Maximization loss function, which
incorporates cosine-distance as the clustering metric. Evaluations show that
RGMComm significantly outperforms state-of-the-art multi-agent communication
baselines and can achieve nearly optimal returns with few-bit messages that are
naturally interpretable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04455">Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques. (arXiv:2308.04455v3 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Champion_P/0/1/0/all/0/1">Pierre Champion</a></p>
<p>The growing use of voice user interfaces has led to a surge in the collection
and storage of speech data. While data collection allows for the development of
efficient tools powering most speech services, it also poses serious privacy
issues for users as centralized storage makes private personal speech data
vulnerable to cyber threats. With the increasing use of voice-based digital
assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the
increasing ease with which personal speech data can be collected, the risk of
malicious use of voice-cloning and speaker/gender/pathological/etc. recognition
has increased.
</p>
<p>This thesis proposes solutions for anonymizing speech and evaluating the
degree of the anonymization. In this work, anonymization refers to making
personal speech data unlinkable to an identity while maintaining the usefulness
(utility) of the speech signal (e.g., access to linguistic content). We start
by identifying several challenges that evaluation protocols need to consider to
evaluate the degree of privacy protection properly. We clarify how
anonymization systems must be configured for evaluation purposes and highlight
that many practical deployment configurations do not permit privacy evaluation.
Furthermore, we study and examine the most common voice conversion-based
anonymization system and identify its weak points before suggesting new methods
to overcome some limitations. We isolate all components of the anonymization
system to evaluate the degree of speaker PPI associated with each of them.
Then, we propose several transformation methods for each component to reduce as
much as possible speaker PPI while maintaining utility. We promote
anonymization algorithms based on quantization-based transformation as an
alternative to the most-used and well-known noise-based approach. Finally, we
endeavor a new attack method to invert anonymization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04690">Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v2 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1">Jae Yong Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Ko_S/0/1/0/all/0/1">Seungchan Ko</a>, <a href="http://arxiv.org/find/math/1/au:+Hong_Y/0/1/0/all/0/1">Youngjoon Hong</a></p>
<p>Partial differential equations (PDEs) underlie our understanding and
prediction of natural phenomena across numerous fields, including physics,
engineering, and finance. However, solving parametric PDEs is a complex task
that necessitates efficient numerical methods. In this paper, we propose a
novel approach for solving parametric PDEs using a Finite Element Operator
Network (FEONet). Our proposed method leverages the power of deep learning in
conjunction with traditional numerical methods, specifically the finite element
method, to solve parametric PDEs in the absence of any paired input-output
training data. We performed various experiments on several benchmark problems
and confirmed that our approach has demonstrated excellent performance across
various settings and environments, proving its versatility in terms of
accuracy, generalization, and computational flexibility. Our FEONet framework
shows potential for application in various fields where PDEs play a crucial
role in modeling complex domains with diverse boundary conditions and singular
behavior. Furthermore, we provide theoretical convergence analysis to support
our approach, utilizing finite element approximation in numerical analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12681">LR-XFL: Logical Reasoning-based Explainable Federated Learning. (arXiv:2308.12681v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanci Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Yu</a></p>
<p>Federated learning (FL) is an emerging approach for training machine learning
models collaboratively while preserving data privacy. The need for privacy
protection makes it difficult for FL models to achieve global transparency and
explainability. To address this limitation, we incorporate logic-based
explanations into FL by proposing the Logical Reasoning-based eXplainable
Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local
logic rules based on their local data and send them, along with model updates,
to the FL server. The FL server connects the local logic rules through a proper
logical connector that is derived based on properties of client data, without
requiring access to the raw data. In addition, the server also aggregates the
local model updates with weight values determined by the quality of the
clients' local data as reflected by their uploaded logic rules. The results
show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and
5.41% in terms of classification accuracy, rule accuracy and rule fidelity,
respectively. The explicit rule evaluation and expression under LR-XFL enable
human experts to validate and correct the rules on the server side, hence
improving the global FL model's robustness to errors. It has the potential to
enhance the transparency of FL models for areas like healthcare and finance
where both data privacy and explainability are important.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.13976">Label Denoising through Cross-Model Agreement. (arXiv:2308.13976v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1">Zaiqiao Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jose_J/0/1/0/all/0/1">Joemon Jose</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a></p>
<p>Learning from corrupted labels is very common in real-world machine-learning
applications. Memorizing such noisy labels could affect the learning of the
model, leading to sub-optimal performances. In this work, we propose a novel
framework to learn robust machine-learning models from noisy labels. Through an
empirical study, we find that different models make relatively similar
predictions on clean examples, while the predictions on noisy examples vary
much more across different models. Motivated by this observation, we propose
\em denoising with cross-model agreement \em (DeCA) which aims to minimize the
KL-divergence between the true label distributions parameterized by two machine
learning models while maximizing the likelihood of data observation. We employ
the proposed DeCA on both the binary label scenario and the multiple label
scenario. For the binary label scenario, we select implicit feedback
recommendation as the downstream task and conduct experiments with four
state-of-the-art recommendation models on four datasets. For the multiple-label
scenario, the downstream application is image classification on two benchmark
datasets. Experimental results demonstrate that the proposed methods
significantly improve the model performance compared with normal training and
other denoising methods on both binary and multiple-label scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.04766">SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning. (arXiv:2309.04766v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_F/0/1/0/all/0/1">Fangkai Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Aw_A/0/1/0/all/0/1">Ai Ti Aw</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a></p>
<p>We present SeaEval, a benchmark for multilingual foundation models. In
addition to characterizing how these models understand and reason with natural
language, we also investigate how well they comprehend cultural practices,
nuances, and values. Alongside standard accuracy metrics, we investigate the
brittleness of foundation models in the dimensions of semantics and
multilinguality. Our analyses span both open-sourced and closed models, leading
to empirical results across classic NLP tasks, reasoning, and cultural
comprehension. Key findings indicate (1) Most models exhibit varied behavior
when given paraphrased instructions. (2) Many models still suffer from exposure
bias (e.g., positional bias, majority label bias). (3) For questions rooted in
factual, scientific, and commonsense knowledge, consistent responses are
expected across multilingual queries that are semantically equivalent. Yet,
most models surprisingly demonstrate inconsistent performance on these queries.
(4) Multilingually-trained models have not attained "balanced multilingual"
capabilities. Our endeavors underscore the need for more generalizable semantic
representations and enhanced multilingual contextualization. SeaEval can serve
as a launchpad for more thorough investigations and evaluations for
multilingual and multicultural scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10092">Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help. (arXiv:2309.10092v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_J/0/1/0/all/0/1">Jiaming Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1">Kaiyuan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1">Yevgeniy Vorobeychik</a>, <a href="http://arxiv.org/find/cs/1/au:+Kantaros_Y/0/1/0/all/0/1">Yiannis Kantaros</a></p>
<p>This paper addresses a new motion planning problem for mobile robots tasked
with accomplishing multiple high-level sub-tasks, expressed using natural
language (NL). These sub-tasks should be accomplished in a temporal and logical
order. To formally define the overarching mission, we leverage Linear Temporal
Logic (LTL) defined over atomic predicates modeling these NL-based sub-tasks.
This is in contrast to related planning approaches that define LTL tasks over
atomic predicates capturing desired low-level system configurations. Our goal
is to design robot plans that satisfy LTL tasks defined over NL-based atomic
propositions. A novel technical challenge arising in this setup lies in
reasoning about correctness of a robot plan with respect to such LTL-encoded
tasks. To address this problem, we propose HERACLEs, a hierarchical conformal
natural language planner, that relies on (i) automata theory to determine what
NL-specified sub-tasks should be accomplished next to make mission progress;
(ii) Large Language Models to design robot plans satisfying these sub-tasks;
and (iii) conformal prediction to reason probabilistically about correctness of
the designed plans and to determine if external assistance is required. We
provide theoretical probabilistic mission satisfaction guarantees as well as
extensive comparative experiments on mobile manipulation tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10625">NoisyNN: Exploring the Influence of Information Entropy Change in Learning Systems. (arXiv:2309.10625v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaowei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Yao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Li Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dajiang Zhu</a></p>
<p>We explore the impact of entropy change in deep learning systems via noise
injection at different levels, i.e., the latent space and input image. The
series of models that employ our methodology are collectively known as Noisy
Neural Networks (NoisyNN), with examples such as NoisyViT and NoisyCNN. Noise
is conventionally viewed as a harmful perturbation in various deep learning
architectures, such as convolutional neural networks (CNNs) and vision
transformers (ViTs), as well as different learning tasks like image
classification and transfer learning. However, this work shows noise can be an
effective way to change the entropy of the learning system. We demonstrate that
specific noise can boost the performance of various deep architectures under
certain conditions. We theoretically prove the enhancement gained from positive
noise by reducing the task complexity defined by information entropy and
experimentally show the significant performance gain in large image datasets,
such as the ImageNet. Herein, we use the information entropy to define the
complexity of the task. We categorize the noise into two types, positive noise
(PN) and harmful noise (HN), based on whether the noise can help reduce the
complexity of the task. Extensive experiments of CNNs and ViTs have shown
performance improvements by proactively injecting positive noise, where we
achieved an unprecedented top 1 accuracy of over 95$\%$ on ImageNet. Both
theoretical analysis and empirical evidence have confirmed that the presence of
positive noise, can benefit the learning process, while the traditionally
perceived harmful noise indeed impairs deep learning models. The different
roles of noise offer new explanations for deep models on specific tasks and
provide a new paradigm for improving model performance. Moreover, it reminds us
that we can influence the performance of learning systems via information
entropy change.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12276">LLMR: Real-time Prompting of Interactive Worlds using Large Language Models. (arXiv:2309.12276v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Torre_F/0/1/0/all/0/1">Fernanda De La Torre</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1">Cathy Mengying Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Han Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Banburski_Fahey_A/0/1/0/all/0/1">Andrzej Banburski-Fahey</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_J/0/1/0/all/0/1">Judith Amores Fernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanier_J/0/1/0/all/0/1">Jaron Lanier</a></p>
<p>We present Large Language Model for Mixed Reality (LLMR), a framework for the
real-time creation and modification of interactive Mixed Reality experiences
using LLMs. LLMR leverages novel strategies to tackle difficult cases where
ideal training data is scarce, or where the design goal requires the synthesis
of internal dynamics, intuitive analysis, or advanced interactivity. Our
framework relies on text interaction and the Unity game engine. By
incorporating techniques for scene understanding, task planning,
self-debugging, and memory management, LLMR outperforms the standard GPT-4 by
4x in average error rate. We demonstrate LLMR's cross-platform interoperability
with several example worlds, and evaluate it on a variety of creation and
modification tasks to show that it can produce and edit diverse objects, tools,
and scenes. Finally, we conducted a usability study (N=11) with a diverse set
that revealed participants had positive experiences with the system and would
use it again.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00757">Mind the Gap: Federated Learning Broadens Domain Generalization in Diagnostic AI Models. (arXiv:2310.00757v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arasteh_S/0/1/0/all/0/1">Soroosh Tayebi Arasteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhl_C/0/1/0/all/0/1">Christiane Kuhl</a>, <a href="http://arxiv.org/find/cs/1/au:+Saehn_M/0/1/0/all/0/1">Marwin-Jonathan Saehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Isfort_P/0/1/0/all/0/1">Peter Isfort</a>, <a href="http://arxiv.org/find/cs/1/au:+Truhn_D/0/1/0/all/0/1">Daniel Truhn</a>, <a href="http://arxiv.org/find/cs/1/au:+Nebelung_S/0/1/0/all/0/1">Sven Nebelung</a></p>
<p>Developing robust artificial intelligence (AI) models that generalize well to
unseen datasets is challenging and usually requires large and variable
datasets, preferably from multiple institutions. In federated learning (FL), a
model is trained collaboratively at numerous sites that hold local datasets
without exchanging them. So far, the impact of training strategy, i.e., local
versus collaborative, on the diagnostic on-domain and off-domain performance of
AI models interpreting chest radiographs has not been assessed. Consequently,
using 610,000 chest radiographs from five institutions across the globe, we
assessed diagnostic performance as a function of training strategy (i.e., local
vs. collaborative), network architecture (i.e., convolutional vs.
transformer-based), generalization performance (i.e., on-domain vs.
off-domain), imaging finding (i.e., cardiomegaly, pleural effusion, pneumonia,
atelectasis, consolidation, pneumothorax, and no abnormality), dataset size
(i.e., from n=18,000 to 213,921 radiographs), and dataset diversity. Large
datasets not only showed minimal performance gains with FL but, in some
instances, even exhibited decreases. In contrast, smaller datasets revealed
marked improvements. Thus, on-domain performance was mainly driven by training
data size. However, off-domain performance leaned more on training diversity.
When trained collaboratively across diverse external institutions, AI models
consistently surpassed models trained locally for off-domain tasks, emphasizing
FL's potential in leveraging data diversity. In conclusion, FL can bolster
diagnostic privacy, reproducibility, and off-domain reliability of AI models
and, potentially, optimize healthcare outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.03780">Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation. (arXiv:2310.03780v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Phung_T/0/1/0/all/0/1">Tung Phung</a>, <a href="http://arxiv.org/find/cs/1/au:+Padurean_V/0/1/0/all/0/1">Victor-Alexandru P&#x103;durean</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Anjali Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Brooks_C/0/1/0/all/0/1">Christopher Brooks</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambronero_J/0/1/0/all/0/1">Jos&#xe9; Cambronero</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1">Sumit Gulwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1">Adish Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_G/0/1/0/all/0/1">Gustavo Soares</a></p>
<p>Generative AI and large language models hold great promise in enhancing
programming education by automatically generating individualized feedback for
students. We investigate the role of generative AI models in providing human
tutor-style programming hints to help students resolve errors in their buggy
programs. Recent works have benchmarked state-of-the-art models for various
feedback generation scenarios; however, their overall quality is still inferior
to human tutors and not yet ready for real-world deployment. In this paper, we
seek to push the limits of generative AI models toward providing high-quality
programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a
first step, our technique leverages GPT-4 as a ``tutor'' model to generate
hints -- it boosts the generative quality by using symbolic information of
failing test cases and fixes in prompts. As a next step, our technique
leverages GPT-3.5, a weaker model, as a ``student'' model to further validate
the hint quality -- it performs an automatic quality validation by simulating
the potential utility of providing this feedback. We show the efficacy of our
technique via extensive evaluation using three real-world datasets of Python
programs covering a variety of concepts ranging from basic algorithms to
regular expressions and data analysis using pandas library.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.06009">Divide-and-Conquer Dynamics in AI-Driven Disempowerment. (arXiv:2310.06009v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_P/0/1/0/all/0/1">Peter S. Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Tegmark_M/0/1/0/all/0/1">Max Tegmark</a></p>
<p>AI companies are attempting to create AI systems that outperform humans at
most economically valuable work. Current AI models are already automating away
the livelihoods of some artists, actors, and writers. But there is infighting
between those who prioritize current harms and future harms. We construct a
game-theoretic model of conflict to study the causes and consequences of this
disunity. Our model also helps explain why throughout history, stakeholders
sharing a common threat have found it advantageous to unite against it, and why
the common threat has in turn found it advantageous to divide and conquer.
</p>
<p>Under realistic parameter assumptions, our model makes several predictions
that find preliminary corroboration in the historical-empirical record. First,
current victims of AI-driven disempowerment need the future victims to realize
that their interests are also under serious and imminent threat, so that future
victims are incentivized to support current victims in solidarity. Second, the
movement against AI-driven disempowerment can become more united, and thereby
more likely to prevail, if members believe that their efforts will be
successful as opposed to futile. Finally, the movement can better unite and
prevail if its members are less myopic. Myopic members prioritize their future
well-being less than their present well-being, and are thus disinclined to
solidarily support current victims today at personal cost, even if this is
necessary to counter the shared threat of AI-driven disempowerment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08206">Long-Tailed Classification Based on Coarse-Grained Leading Forest and Multi-Center Loss. (arXiv:2310.08206v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinye Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Ji Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jianhang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaobo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoyin Wang</a></p>
<p>Long-tailed (LT) classification is an unavoidable and challenging problem in
the real world. Most existing long-tailed classification methods focus only on
solving the class-wise imbalance while ignoring the attribute-wise imbalance.
The deviation of a classification model is caused by both class-wise and
attribute-wise imbalance. Due to the fact that attributes are implicit in most
datasets and the combination of attributes is complex, attribute-wise imbalance
is more difficult to handle. For this purpose, we proposed a novel long-tailed
classification framework, aiming to build a multi-granularity classification
model by means of invariant feature learning. This method first unsupervisedly
constructs Coarse-Grained forest (CLF) to better characterize the distribution
of attributes within a class. Depending on the distribution of attributes, one
can customize suitable sampling strategies to construct different imbalanced
datasets. We then introduce multi-center loss (MCL) that aims to gradually
eliminate confusing attributes during feature learning process. The proposed
framework does not necessarily couple to a specific LT classification model
structure and can be integrated with any existing LT method as an independent
component. Extensive experiments show that our approach achieves
state-of-the-art performance on both existing benchmarks ImageNet-GLT and
MSCOCO-GLT and can improve the performance of existing LT methods. Our codes
are available on GitHub: \url{https://github.com/jinyery/cognisance}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09767">VLIS: Unimodal Language Models Guide Multimodal Language Generation. (arXiv:2310.09767v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jiwan Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a></p>
<p>Multimodal language generation, which leverages the synergy of language and
vision, is a rapidly expanding field. However, existing vision-language models
face challenges in tasks that require complex linguistic understanding. To
address this issue, we introduce Visual-Language models as Importance Sampling
weights (VLIS), a novel framework that combines the visual conditioning
capability of vision-language models with the language understanding of
unimodal text-only language models without further training. It extracts
pointwise mutual information of each image and text from a visual-language
model and uses the value as an importance sampling weight to adjust the token
likelihood from a text-only model. VLIS improves vision-language models on
diverse tasks, including commonsense understanding (WHOOPS, OK-VQA, and
ScienceQA) and complex text generation (Concadia, Image Paragraph Captioning,
and ROCStories). Our results suggest that VLIS represents a promising new
direction for multimodal language generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.13023">GraphGPT: Graph Instruction Tuning for Large Language Models. (arXiv:2310.13023v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiabin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1">Lei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Lixin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Suqi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dawei Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a></p>
<p>Graph Neural Networks (GNNs) have advanced graph structure understanding via
recursive information exchange and aggregation among graph nodes. To improve
model robustness, self-supervised learning (SSL) has emerged as a promising
approach for data augmentation. However, existing methods for generating
pre-trained graph embeddings often rely on fine-tuning with specific downstream
task labels, which limits their usability in scenarios where labeled data is
scarce or unavailable. To address this, our research focuses on advancing the
generalization capabilities of graph models in challenging zero-shot learning
scenarios. Inspired by the success of large language models (LLMs), we aim to
develop a graph-oriented LLM that can achieve high generalization across
diverse downstream datasets and tasks, even without any information available
from the downstream graph data. In this work, we present the GraphGPT framework
that aligns LLMs with graph structural knowledge with a graph instruction
tuning paradigm. Our framework incorporates a text-graph grounding component to
establish a connection between textual information and graph structures.
Additionally, we propose a dual-stage instruction tuning paradigm, accompanied
by a lightweight graph-text alignment projector. This paradigm explores
self-supervised graph structural signals and task-specific graph instructions,
to guide LLMs in understanding complex graph structures and improving their
adaptability across different downstream tasks. Our framework is evaluated on
supervised and zero-shot graph learning tasks, demonstrating superior
generalization and outperforming state-of-the-art baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.17658">Is Channel Independent strategy optimal for Time Series Forecasting?. (arXiv:2310.17658v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peiwen_Y/0/1/0/all/0/1">Yuan Peiwen</a>, <a href="http://arxiv.org/find/cs/1/au:+Changsheng_Z/0/1/0/all/0/1">Zhu Changsheng</a></p>
<p>There has been an emergence of various models for long-term time series
forecasting. Recent studies have demonstrated that a single linear layer, using
Channel Dependent (CD) or Channel Independent (CI) modeling, can even
outperform a large number of sophisticated models. However, current research
primarily considers CD and CI as two complementary yet mutually exclusive
approaches, unable to harness these two extremes simultaneously. And it is also
a challenging issue that both CD and CI are static strategies that cannot be
determined to be optimal for a specific dataset without extensive experiments.
In this paper, we reconsider whether the current CI strategy is the best
solution for time series forecasting. First, we propose a simple yet effective
strategy called CSC, which stands for $\mathbf{C}$hannel
$\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel
Self-Clustering (CSC) enhances CI strategy's performance improvements while
reducing parameter size, for exmpale by over 10 times on electricity dataset,
and significantly cutting training time. Second, we further propose Channel
Rearrangement (CR), a method for deep models inspired by the self-clustering.
CR attains competitive performance against baselines. Finally, we also discuss
whether it is best to forecast the future values using the historical values of
the same channel as inputs. We hope our findings and methods could inspire new
solutions beyond CD/CI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18021">FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning. (arXiv:2310.18021v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaokai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_N/0/1/0/all/0/1">Na Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yiming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Jia Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qike Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiaoxiao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yanjun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1">Chenyang Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhe Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_D/0/1/0/all/0/1">Dengfeng Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fangzhen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiwen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Cheng Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhenbing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shaorong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiangfeng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_T/0/1/0/all/0/1">Tuo Leng</a></p>
<p>This is the first paper in a series of work we have accomplished over the
past three years. In this paper, we have constructed a consistent formal plane
geometry system. This will serve as a crucial bridge between IMO-level plane
geometry challenges and readable AI automated reasoning. Within this formal
framework, we have been able to seamlessly integrate modern AI models with our
formal system. AI is now capable of providing deductive reasoning solutions to
IMO-level plane geometry problems, just like handling other natural languages,
and these proofs are readable, traceable, and verifiable. We propose the
geometry formalization theory (GFT) to guide the development of the geometry
formal system. Based on the GFT, we have established the FormalGeo, which
consists of 88 geometric predicates and 196 theorems. It can represent,
validate, and solve IMO-level geometry problems. we also have crafted the FGPS
(formal geometry problem solver) in Python. It serves as both an interactive
assistant for verifying problem-solving processes and an automated problem
solver. We've annotated the formalgeo7k and formalgeo-imo datasets. The former
contains 6,981 (expand to 133,818 through data augmentation) geometry problems,
while the latter includes 18 (expand to 2,627 and continuously increasing)
IMO-level challenging geometry problems. All annotated problems include
detailed formal language descriptions and solutions. Implementation of the
formal system and experiments validate the correctness and utility of the GFT.
The backward depth-first search method only yields a 2.42% problem-solving
failure rate, and we can incorporate deep learning techniques to achieve lower
one. The source code of FGPS and datasets are available at
https://github.com/BitSecret/FGPS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.02775">AI-TA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs. (arXiv:2311.02775v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hicke_Y/0/1/0/all/0/1">Yann Hicke</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Anmol Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1">Qianou Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1">Paul Denny</a></p>
<p>Responding to the thousands of student questions on online QA platforms each
semester has a considerable human cost, particularly in computing courses with
rapidly growing enrollments. To address the challenges of scalable and
intelligent question-answering (QA), we introduce an innovative solution that
leverages open-source Large Language Models (LLMs) from the LLaMA-2 family to
ensure data privacy. Our approach combines augmentation techniques such as
retrieval augmented generation (RAG), supervised fine-tuning (SFT), and
learning from human preferences data using Direct Preference Optimization
(DPO). Through extensive experimentation on a Piazza dataset from an
introductory CS course, comprising 10,000 QA pairs and 1,500 pairs of
preference data, we demonstrate a significant 30% improvement in the quality of
answers, with RAG being a particularly impactful addition. Our contributions
include the development of a novel architecture for educational QA, extensive
evaluations of LLM performance utilizing both human assessments and LLM-based
metrics, and insights into the challenges and future directions of educational
data processing. This work paves the way for the development of AI-TA, an
intelligent QA assistant customizable for courses with an online QA platform
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07594">How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model. (arXiv:2311.07594v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shezheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaopeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shasha Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jie Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xiaoguang Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weimin Zhang</a></p>
<p>This review paper explores Multimodal Large Language Models (MLLMs), which
integrate Large Language Models (LLMs) like GPT-4 to handle multimodal data
such as text and vision. MLLMs demonstrate capabilities like generating image
narratives and answering image-based questions, bridging the gap towards
real-world human-computer interactions and hinting at a potential pathway to
artificial general intelligence. However, MLLMs still face challenges in
processing the semantic gap in multimodality, which may lead to erroneous
generation, posing potential risks to society. Choosing the appropriate
modality alignment method is crucial, as improper methods might require more
parameters with limited performance improvement. This paper aims to explore
modality alignment methods for LLMs and their existing capabilities.
Implementing modality alignment allows LLMs to address environmental issues and
enhance accessibility. The study surveys existing modal alignment methods in
MLLMs into four groups: (1) Multimodal Converters that change data into
something LLMs can understand; (2) Multimodal Perceivers to improve how LLMs
perceive different types of data; (3) Tools Assistance for changing data into
one common format, usually text; and (4) Data-Driven methods that teach LLMs to
understand specific types of data in a dataset. This field is still in a phase
of exploration and experimentation, and we will organize and update various
existing research methods for multimodal information alignment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10090">JaxMARL: Multi-Agent RL Environments in JAX. (arXiv:2311.10090v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rutherford_A/0/1/0/all/0/1">Alexander Rutherford</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_B/0/1/0/all/0/1">Benjamin Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallici_M/0/1/0/all/0/1">Matteo Gallici</a>, <a href="http://arxiv.org/find/cs/1/au:+Cook_J/0/1/0/all/0/1">Jonathan Cook</a>, <a href="http://arxiv.org/find/cs/1/au:+Lupu_A/0/1/0/all/0/1">Andrei Lupu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingvarsson_G/0/1/0/all/0/1">Gardar Ingvarsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Willi_T/0/1/0/all/0/1">Timon Willi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akbir Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1">Christian Schroeder de Witt</a>, <a href="http://arxiv.org/find/cs/1/au:+Souly_A/0/1/0/all/0/1">Alexandra Souly</a>, <a href="http://arxiv.org/find/cs/1/au:+Bandyopadhyay_S/0/1/0/all/0/1">Saptarashmi Bandyopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Samvelyan_M/0/1/0/all/0/1">Mikayel Samvelyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Minqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lange_R/0/1/0/all/0/1">Robert Tjarko Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacerda_B/0/1/0/all/0/1">Bruno Lacerda</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawes_N/0/1/0/all/0/1">Nick Hawes</a>, <a href="http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1">Tim Rocktaschel</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chris Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Nicolaus Foerster</a></p>
<p>Benchmarks play an important role in the development of machine learning
algorithms. For example, research in reinforcement learning (RL) has been
heavily influenced by available environments and benchmarks. However, RL
environments are traditionally run on the CPU, limiting their scalability with
typical academic compute. Recent advancements in JAX have enabled the wider use
of hardware acceleration to overcome these computational hurdles, enabling
massively parallel RL training pipelines and environments. This is particularly
useful for multi-agent reinforcement learning (MARL) research. First of all,
multiple agents must be considered at each environment step, adding
computational burden, and secondly, the sample complexity is increased due to
non-stationarity, decentralised partial observability, or other MARL
challenges. In this paper, we present JaxMARL, the first open-source code base
that combines ease-of-use with GPU enabled efficiency, and supports a large
number of commonly used MARL environments as well as popular baseline
algorithms. When considering wall clock time, our experiments show that per-run
our JAX-based training pipeline is up to 12500x faster than existing
approaches. This enables efficient and thorough evaluations, with the potential
to alleviate the evaluation crisis of the field. We also introduce and
benchmark SMAX, a vectorised, simplified version of the popular StarCraft
Multi-Agent Challenge, which removes the need to run the StarCraft II game
engine. This not only enables GPU acceleration, but also provides a more
flexible MARL environment, unlocking the potential for self-play,
meta-learning, and other future applications in MARL. We provide code at
https://github.com/flairox/jaxmarl.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.11608">Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks. (arXiv:2311.11608v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Ling Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_J/0/1/0/all/0/1">Jinzhong Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yingwen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhijun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zeyuan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1">Weiru Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1">Qinyu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guangtao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yunzhi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_D/0/1/0/all/0/1">Dinghao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiru Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wenduo Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1">Senbo Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhihao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuanyuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongfei Lin</a></p>
<p>Objective: Most existing fine-tuned biomedical large language models (LLMs)
focus on enhancing performance in monolingual biomedical question answering and
conversation tasks. To investigate the effectiveness of the fine-tuned LLMs on
diverse biomedical NLP tasks in different languages, We present Taiyi, a
bilingual fine-tuned LLM for diverse biomedical tasks. Materials and Methods:
We first curated a comprehensive collection of 140 existing biomedical text
mining datasets (102 English and 38 Chinese datasets) across over 10 task
types. Subsequently, a two-stage strategy is proposed for supervised
fine-tuning to optimize the model performance across varied tasks. Results:
Experimental results on 13 test sets covering named entity recognition,
relation extraction, text classification, question answering tasks demonstrate
that Taiyi achieves superior performance compared to general LLMs. The case
study involving additional biomedical NLP tasks further shows Taiyi's
considerable potential for bilingual biomedical multi-tasking. Conclusion:
Leveraging rich high-quality biomedical corpora and developing effective
fine-tuning strategies can significantly improve the performance of LLMs within
the biomedical domain. Taiyi shows the bilingual multi-tasking capability
through supervised fine-tuning. However, those tasks such as information
extraction that are not generation tasks in nature remain challenging for
LLM-based generative approaches, and they still underperform the conventional
discriminative approaches of smaller language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16502">MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. (arXiv:2311.16502v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1">Xiang Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1">Yuansheng Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tianyu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruoqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Ge Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1">Samuel Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Dongfu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1">Weiming Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Cong Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Botao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1">Ruibin Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Renliang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1">Ming Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Boyuan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhenzhu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yibo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenhao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a></p>
<p>We introduce MMMU: a new benchmark designed to evaluate multimodal models on
massive multi-discipline tasks demanding college-level subject knowledge and
deliberate reasoning. MMMU includes 11.5K meticulously collected multimodal
questions from college exams, quizzes, and textbooks, covering six core
disciplines: Art &amp; Design, Business, Science, Health &amp; Medicine, Humanities &amp;
Social Science, and Tech &amp; Engineering. These questions span 30 subjects and
183 subfields, comprising 30 highly heterogeneous image types, such as charts,
diagrams, maps, tables, music sheets, and chemical structures. Unlike existing
benchmarks, MMMU focuses on advanced perception and reasoning with
domain-specific knowledge, challenging models to perform tasks akin to those
faced by experts. The evaluation of 14 open-source LMMs as well as the
proprietary GPT-4V(ision) and Gemini highlights the substantial challenges
posed by MMMU. Even the advanced GPT-4V and Gemini Ultra only achieve
accuracies of 56% and 59% respectively, indicating significant room for
improvement. We believe MMMU will stimulate the community to build
next-generation multimodal foundation models towards expert artificial general
intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16895">Optimization Theory Based Deep Reinforcement Learning for Resource Allocation in Ultra-Reliable Wireless Networked Control Systems. (arXiv:2311.16895v2 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ali_H/0/1/0/all/0/1">Hamida Qumber Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Darabi_A/0/1/0/all/0/1">Amirhassan Babazadeh Darabi</a>, <a href="http://arxiv.org/find/eess/1/au:+Coleri_S/0/1/0/all/0/1">Sinem Coleri</a></p>
<p>The design of Wireless Networked Control System (WNCS) requires addressing
critical interactions between control and communication systems with minimal
complexity and communication overhead while providing ultra-high reliability.
This paper introduces a novel optimization theory based deep reinforcement
learning (DRL) framework for the joint design of controller and communication
systems. The objective of minimum power consumption is targeted while
satisfying the schedulability and rate constraints of the communication system
in the finite blocklength regime and stability constraint of the control
system. Decision variables include the sampling period in the control system,
and blocklength and packet error probability in the communication system. The
proposed framework contains two stages: optimization theory and DRL. In the
optimization theory stage, following the formulation of the joint optimization
problem, optimality conditions are derived to find the mathematical relations
between the optimal values of the decision variables. These relations allow the
decomposition of the problem into multiple building blocks. In the DRL stage,
the blocks that are simplified but not tractable are replaced by DRL. Via
extensive simulations, the proposed optimization theory based DRL approach is
demonstrated to outperform the optimization theory and pure DRL based
approaches, with close to optimal performance and much lower complexity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00812">Empowering Autonomous Driving with Large Language Models: A Safety Perspective. (arXiv:2312.00812v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_R/0/1/0/all/0/1">Ruochen Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_C/0/1/0/all/0/1">Chengtian Lang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_S/0/1/0/all/0/1">Sinong Simon Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a></p>
<p>Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably
in the form of diminished public trust and safety concerns from long-tail
unforeseen driving scenarios. This predicament is due to the limitation of deep
neural networks in AD software, which struggle with interpretability and
exhibit poor generalization capabilities in out-of-distribution and uncertain
scenarios. To this end, this paper advocates for the integration of Large
Language Models (LLMs) into the AD system, leveraging their robust common-sense
knowledge, reasoning abilities, and human-interaction capabilities. The
proposed approach deploys the LLM as an intelligent decision-maker in planning,
incorporating safety verifiers for contextual safety learning to enhance
overall AD performance and safety. We present results from two case studies
that affirm the efficacy of our approach. We further discuss the potential
integration of LLM for other AD software components including perception,
prediction, and simulation. Despite the observed challenges in the case
studies, the integration of LLMs is promising and beneficial for reinforcing
both safety and performance in AD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05571">Frugal LMs Trained to Invoke Symbolic Solvers Achieve Parameter-Efficient Arithmetic Reasoning. (arXiv:2312.05571v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Subhabrata Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1">Joykirat Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_I/0/1/0/all/0/1">Ishan Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Manchanda_S/0/1/0/all/0/1">Sunny Manchanda</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1">Soumen Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1">Tanmoy Chakraborty</a></p>
<p>Large Language Models (LLM) exhibit zero-shot mathematical reasoning capacity
as a behavior emergent with scale, commonly manifesting as chain-of-thoughts
(CoT) reasoning. However, multiple empirical findings suggest that this prowess
is exclusive to LLMs with exorbitant sizes (beyond 50 billion parameters).
Meanwhile, educational neuroscientists suggest that symbolic algebraic
manipulation be introduced around the same time as arithmetic word problems to
modularize language-to-formulation, symbolic manipulation of the formulation,
and endgame arithmetic. In this paper, we start with the hypothesis that much
smaller LMs, which are weak at multi-step reasoning, can achieve reasonable
arithmetic reasoning if arithmetic word problems are posed as a
formalize-then-solve task. In our architecture, which we call SYRELM, the LM
serves the role of a translator to map natural language arithmetic questions
into a formal language (FL) description. A symbolic solver then evaluates the
FL expression to obtain the answer. A small frozen LM, equipped with an
efficient low-rank adapter, is capable of generating FL expressions that
incorporate natural language descriptions of the arithmetic problem (e.g.,
variable names and their purposes, formal expressions combining variables,
etc.). We adopt policy-gradient reinforcement learning to train the adapted LM,
informed by the non-differentiable symbolic solver. This marks a sharp
departure from the recent development in tool-augmented LLMs, in which the
external tools (e.g., calculator, Web search, etc.) are essentially detached
from the learning phase of the LM. SYRELM shows massive improvements (e.g.,
+30.65 absolute point improvement in accuracy on the SVAMP dataset using GPT-J
6B model) over base LMs, while keeping our testbed easy to diagnose, interpret
and within reach of most researchers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07021">Transferring Modality-Aware Pedestrian Attentive Learning for Visible-Infrared Person Re-identification. (arXiv:2312.07021v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuwei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fang Liu</a></p>
<p>Visible-infrared person re-identification (VI-ReID) aims to search the same
pedestrian of interest across visible and infrared modalities. Existing models
mainly focus on compensating for modality-specific information to reduce
modality variation. However, these methods often lead to a higher computational
overhead and may introduce interfering information when generating the
corresponding images or features. To address this issue, it is critical to
leverage pedestrian-attentive features and learn modality-complete and
-consistent representation. In this paper, a novel Transferring Modality-Aware
Pedestrian Attentive Learning (TMPA) model is proposed, focusing on the
pedestrian regions to efficiently compensate for missing modality-specific
features. Specifically, we propose a region-based data augmentation module
PedMix to enhance pedestrian region coherence by mixing the corresponding
regions from different modalities. A lightweight hybrid compensation module,
i.e., the Modality Feature Transfer (MFT), is devised to integrate cross
attention and convolution networks to fully explore the discriminative
modality-complete features with minimal computational overhead. Extensive
experiments conducted on the benchmark SYSU-MM01 and RegDB datasets
demonstrated the effectiveness of our proposed TMPA model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08670">Temporal-Spatial Entropy Balancing for Causal Continuous Treatment-Effect Estimation. (arXiv:2312.08670v2 [stat.ME] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Hu_T/0/1/0/all/0/1">Tao Hu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1">Honglong Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeng_F/0/1/0/all/0/1">Fan Zeng</a>, <a href="http://arxiv.org/find/stat/1/au:+Du_M/0/1/0/all/0/1">Min Du</a>, <a href="http://arxiv.org/find/stat/1/au:+Du_X/0/1/0/all/0/1">XiangKun Du</a>, <a href="http://arxiv.org/find/stat/1/au:+Zheng_Y/0/1/0/all/0/1">Yue Zheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Q/0/1/0/all/0/1">Quanqi Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1">Mengran Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_D/0/1/0/all/0/1">Dan Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_J/0/1/0/all/0/1">Jihao Wu</a></p>
<p>In the field of intracity freight transportation, changes in order volume are
significantly influenced by temporal and spatial factors. When building subsidy
and pricing strategies, predicting the causal effects of these strategies on
order volume is crucial. In the process of calculating causal effects,
confounding variables can have an impact. Traditional methods to control
confounding variables handle data from a holistic perspective, which cannot
ensure the precision of causal effects in specific temporal and spatial
dimensions. However, temporal and spatial dimensions are extremely critical in
the logistics field, and this limitation may directly affect the precision of
subsidy and pricing strategies. To address these issues, this study proposes a
technique based on flexible temporal-spatial grid partitioning. Furthermore,
based on the flexible grid partitioning technique, we further propose a
continuous entropy balancing method in the temporal-spatial domain, which named
TS-EBCT (Temporal-Spatial Entropy Balancing for Causal Continue Treatments).
The method proposed in this paper has been tested on two simulation datasets
and two real datasets, all of which have achieved excellent performance. In
fact, after applying the TS-EBCT method to the intracity freight transportation
field, the prediction accuracy of the causal effect has been significantly
improved. It brings good business benefits to the company's subsidy and pricing
strategies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09313">LatentEditor: Text Driven Local Editing of 3D Scenes. (arXiv:2312.09313v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khalid_U/0/1/0/all/0/1">Umar Khalid</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1">Hasan Iqbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1">Nazmul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_J/0/1/0/all/0/1">Jing Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a></p>
<p>While neural fields have made significant strides in view synthesis and scene
reconstruction, editing them poses a formidable challenge due to their implicit
encoding of geometry and texture information from multi-view inputs. In this
paper, we introduce \textsc{LatentEditor}, an innovative framework designed to
empower users with the ability to perform precise and locally controlled
editing of neural fields using text prompts. Leveraging denoising diffusion
models, we successfully embed real-world scenes into the latent space,
resulting in a faster and more adaptable NeRF backbone for editing compared to
traditional methods. To enhance editing precision, we introduce a delta score
to calculate the 2D mask in the latent space that serves as a guide for local
modifications while preserving irrelevant regions. Our novel pixel-level
scoring approach harnesses the power of InstructPix2Pix (IP2P) to discern the
disparity between IP2P conditional and unconditional noise predictions in the
latent space. The edited latents conditioned on the 2D masks are then
iteratively updated in the training set to achieve 3D local editing. Our
approach achieves faster editing speeds and superior output quality compared to
existing 3D editing models, bridging the gap between textual instructions and
high-quality 3D scene editing in latent space. We show the superiority of our
approach on four benchmark 3D datasets, LLFF, IN2N, NeRFStudio and NeRF-Art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09323">Perspectives on the State and Future of Deep Learning - 2023. (arXiv:2312.09323v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1">Richard Baraniuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1">Melanie Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1">Preetum Nakkiran</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1">Andrew Gordon Wilson</a></p>
<p>The goal of this series is to chronicle opinions and issues in the field of
machine learning as they stand today and as they change over time. The plan is
to host this survey periodically until the AI singularity
paperclip-frenzy-driven doomsday, keeping an updated list of topical questions
and interviewing new community members for each edition. In this issue, we
probed people's opinions on interpretable AI, the value of benchmarking in
modern NLP, the state of progress towards understanding deep learning, and the
future of academia.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09844">Small Dataset, Big Gains: Enhancing Reinforcement Learning by Offline Pre-Training with Model Based Augmentation. (arXiv:2312.09844v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Macaluso_G/0/1/0/all/0/1">Girolamo Macaluso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sestini_A/0/1/0/all/0/1">Alessandro Sestini</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagdanov_A/0/1/0/all/0/1">Andrew D. Bagdanov</a></p>
<p>Offline reinforcement learning leverages pre-collected datasets of
transitions to train policies. It can serve as effective initialization for
online algorithms, enhancing sample efficiency and speeding up convergence.
However, when such datasets are limited in size and quality, offline
pre-training can produce sub-optimal policies and lead to degraded online
reinforcement learning performance. In this paper we propose a model-based data
augmentation strategy to maximize the benefits of offline reinforcement
learning pre-training and reduce the scale of data needed to be effective. Our
approach leverages a world model of the environment trained on the offline
dataset to augment states during offline pre-training. We evaluate our approach
on a variety of MuJoCo robotic tasks and our results show it can jump-start
online fine-tuning and substantially reduce - in some cases by an order of
magnitude - the required number of environment interactions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10237">Vertical Federated Alzheimer&#x27;s Detection on Multimodal Data. (arXiv:2312.10237v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mandal_P/0/1/0/all/0/1">Paul K. Mandal</a></p>
<p>In the era of rapidly advancing medical technologies, the segmentation of
medical data has become inevitable, necessitating the development of privacy
preserving machine learning algorithms that can train on distributed data.
Consolidating sensitive medical data is not always an option particularly due
to the stringent privacy regulations imposed by the Health Insurance
Portability and Accountability Act (HIPAA). In this paper, we introduce a HIPAA
compliant framework that can train from distributed data. We then propose a
multimodal vertical federated model for Alzheimer's Disease (AD) detection, a
serious neurodegenerative condition that can cause dementia, severely impairing
brain function and hindering simple tasks, especially without preventative
care. This vertical federated model offers a distributed architecture that
enables collaborative learning across diverse sources of medical data while
respecting privacy constraints imposed by HIPAA. It is also able to leverage
multiple modalities of data, enhancing the robustness and accuracy of AD
detection. Our proposed model not only contributes to the advancement of
federated learning techniques but also holds promise for overcoming the hurdles
posed by data segmentation in medical research. By using vertical federated
learning, this research strives to provide a framework that enables healthcare
institutions to harness the collective intelligence embedded in their
distributed datasets without compromising patient privacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10302">One Shot Learning as Instruction Data Prospector for Large Language Models. (arXiv:2312.10302v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunshui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hui_B/0/1/0/all/0/1">Binyuan Hui</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xiaobo Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaxi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Min Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1">Shuzheng Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yongbin Li</a></p>
<p>Aligning large language models(LLMs) with human is a critical step in
effectively utilizing their pre-trained capabilities across a wide array of
language tasks. Current instruction tuning practices often rely on expanding
dataset size without a clear strategy for ensuring data quality, which can
inadvertently introduce noise and degrade model performance. To address this
challenge, we introduce Nuggets, a novel and efficient methodology that employs
one shot learning to select high-quality instruction data from expansive
datasets. Nuggets assesses the potential of individual instruction examples to
act as effective one shot examples, thereby identifying those that can
significantly enhance diverse task performance. Nuggets utilizes a scoring
system based on the impact of candidate examples on the perplexity of a diverse
anchor set, facilitating the selection of the most beneficial data for
instruction tuning. Through rigorous testing on two benchmarks, including
MT-Bench and Alpaca-Eval, we demonstrate that instruction tuning with the top
1% of Nuggets-curated examples substantially outperforms conventional methods
that use the full dataset. These findings advocate for a data selection
paradigm that prioritizes quality, offering a more efficient pathway to align
LLMs with humans.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10572">Improved Anonymous Multi-Agent Path Finding Algorithm. (arXiv:2312.10572v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ali_Z/0/1/0/all/0/1">Zain Alabedeen Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Yakovlev_K/0/1/0/all/0/1">Konstantin Yakovlev</a></p>
<p>We consider an Anonymous Multi-Agent Path-Finding (AMAPF) problem where the
set of agents is confined to a graph, a set of goal vertices is given and each
of these vertices has to be reached by some agent. The problem is to find an
assignment of the goals to the agents as well as the collision-free paths, and
we are interested in finding the solution with the optimal makespan. A
well-established approach to solve this problem is to reduce it to a special
type of a graph search problem, i.e. to the problem of finding a maximum flow
on an auxiliary graph induced by the input one. The size of the former graph
may be very large and the search on it may become a bottleneck. To this end, we
suggest a specific search algorithm that leverages the idea of exploring the
search space not through considering separate search states but rather bulks of
them simultaneously. That is, we implicitly compress, store and expand bulks of
the search states as single states, which results in high reduction in runtime
and memory. Empirically, the resultant AMAPF solver demonstrates superior
performance compared to the state-of-the-art competitor and is able to solve
all publicly available MAPF instances from the well-known MovingAI benchmark in
less than 30 seconds.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10695">Nonparametric Strategy Test. (arXiv:2312.10695v2 [stat.ME] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ganzfried_S/0/1/0/all/0/1">Sam Ganzfried</a></p>
<p>We present a nonparametric statistical test for determining whether an agent
is following a given mixed strategy in a repeated strategic-form game given
samples of the agent's play. This involves two components: determining whether
the agent's frequencies of pure strategies are sufficiently close to the target
frequencies, and determining whether the pure strategies selected are
independent between different game iterations. Our integrated test involves
applying a chi-squared goodness of fit test for the first component and a
generalized Wald-Wolfowitz runs test for the second component. The results from
both tests are combined using Bonferroni correction to produce a complete test
for a given significance level $\alpha.$ We applied the test to publicly
available data of human rock-paper-scissors play. The data consists of 50
iterations of play for 500 human players. We test with a null hypothesis that
the players are following a uniform random strategy independently at each game
iteration. Using a significance level of $\alpha = 0.05$, we conclude that 305
(61%) of the subjects are following the target strategy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10793">Understanding the Instruction Mixture for Large Language Model Fine-tuning. (arXiv:2312.10793v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Renxi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Minghao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xudong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chiyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haonan Li</a></p>
<p>While instructions fine-tuning of large language models (LLMs) has been
proven to enhance performance across various applications, the influence of the
instruction dataset mixture on LLMs has not been thoroughly explored. In this
study, we classify instructions into three main types: NLP downstream tasks,
coding, and general chatting, and investigate their impact on LLMs. Our
findings reveal that specific types of instructions are more beneficial for
particular uses, while it may cause harms to other aspects, emphasizing the
importance of meticulously designing the instruction mixture to maximize model
performance. This study sheds light on the instruction mixture and paves the
way for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10798">Land use/land cover classification of fused Sentinel-1 and Sentinel-2 imageries using ensembles of Random Forests. (arXiv:2312.10798v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pande_S/0/1/0/all/0/1">Shivam Pande</a></p>
<p>The study explores the synergistic combination of Synthetic Aperture Radar
(SAR) and Visible-Near Infrared-Short Wave Infrared (VNIR-SWIR) imageries for
land use/land cover (LULC) classification. Image fusion, employing Bayesian
fusion, merges SAR texture bands with VNIR-SWIR imageries. The research aims to
investigate the impact of this fusion on LULC classification. Despite the
popularity of random forests for supervised classification, their limitations,
such as suboptimal performance with fewer features and accuracy stagnation, are
addressed. To overcome these issues, ensembles of random forests (RFE) are
created, introducing random rotations using the Forest-RC algorithm. Three
rotation approaches: principal component analysis (PCA), sparse random rotation
(SRP) matrix, and complete random rotation (CRP) matrix are employed.
Sentinel-1 SAR data and Sentinel-2 VNIR-SWIR data from the IIT-Kanpur region
constitute the training datasets, including SAR, SAR with texture, VNIR-SWIR,
VNIR-SWIR with texture, and fused VNIR-SWIR with texture. The study evaluates
classifier efficacy, explores the impact of SAR and VNIR-SWIR fusion on
classification, and significantly enhances the execution speed of Bayesian
fusion code. The SRP-based RFE outperforms other ensembles for the first two
datasets, yielding average overall kappa values of 61.80% and 68.18%, while the
CRP-based RFE excels for the last three datasets with average overall kappa
values of 95.99%, 96.93%, and 96.30%. The fourth dataset achieves the highest
overall kappa of 96.93%. Furthermore, incorporating texture with SAR bands
results in a maximum overall kappa increment of 10.00%, while adding texture to
VNIR-SWIR bands yields a maximum increment of approximately 3.45%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11111">The Good, The Bad, and Why: Unveiling Emotions in Generative AI. (arXiv:2312.11111v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Cheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1">Kaijie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1">Wenxin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_J/0/1/0/all/0/1">Jianxun Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Fang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>Emotion significantly impacts our daily behaviors and interactions. While
recent generative AI models, such as large language models, have shown
impressive performance in various tasks, it remains unclear whether they truly
comprehend emotions. This paper aims to address this gap by incorporating
psychological theories to gain a holistic understanding of emotions in
generative AI models. Specifically, we propose three approaches: 1)
EmotionPrompt to enhance AI model performance, 2) EmotionAttack to impair AI
model performance, and 3) EmotionDecode to explain the effects of emotional
stimuli, both benign and malignant. Through extensive experiments involving
language and multi-modal models on semantic understanding, logical reasoning,
and generation tasks, we demonstrate that both textual and visual EmotionPrompt
can boost the performance of AI models while EmotionAttack can hinder it.
Additionally, EmotionDecode reveals that AI models can comprehend emotional
stimuli akin to the mechanism of dopamine in the human brain. Our work heralds
a novel avenue for exploring psychology to enhance our understanding of
generative AI models. This paper is an extended version of our previous work
EmotionPrompt (<a href="/abs/2307.11760">arXiv:2307.11760</a>).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11193">&quot;Paraphrasing The Original Text&quot; Makes High Accuracy Long-Context QA. (arXiv:2312.11193v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yijiong Yu</a></p>
<p>Although LLMs continue to iterate and improve, most open-source models still
have a context window of no more than 4k, limiting their ability to handle
long-context problems. Most existing open-source models for long-context chat
still lack satisfactory accuracy. To address this issue, I approach it from the
perspective of training data and theoretically prove that training the
capability to handle long contexts requires "effective" rather than "long"
data. Based on this, I propose using the "original text paraphrase" task, and
successfully extend the context window of the existing model to 32k by a
low-cost and effective method, achieving extremely high accuracy in
multi-document-QA and surpassing all existing open-source models of the same
scale. The model and training data have been open-sourced on
HuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) and
WiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11297">Optimised Storage for Datalog Reasoning. (arXiv:2312.11297v2 [cs.DB] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinyue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Pan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nenov_Y/0/1/0/all/0/1">Yavor Nenov</a>, <a href="http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1">Ian Horrocks</a></p>
<p>Materialisation facilitates Datalog reasoning by precomputing all
consequences of the facts and the rules so that queries can be directly
answered over the materialised facts. However, storing all materialised facts
may be infeasible in practice, especially when the rules are complex and the
given set of facts is large. We observe that for certain combinations of rules,
there exist data structures that compactly represent the reasoning result and
can be efficiently queried when necessary. In this paper, we present a general
framework that allows for the integration of such optimised storage schemes
with standard materialisation algorithms. Moreover, we devise optimised storage
schemes targeting at transitive rules and union rules, two types of
(combination of) rules that commonly occur in practice. Our experimental
evaluation shows that our approach significantly improves memory consumption,
sometimes by orders of magnitude, while remaining competitive in terms of query
answering time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00760">Efficient Failure Pattern Identification of Predictive Algorithms. (arXiv:2306.00760v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bao Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Viet Anh Nguyen</a></p>
<p>Given a (machine learning) classifier and a collection of unlabeled data, how
can we efficiently identify misclassification patterns presented in this
dataset? To address this problem, we propose a human-machine collaborative
framework that consists of a team of human annotators and a sequential
recommendation algorithm. The recommendation algorithm is conceptualized as a
stochastic sampler that, in each round, queries the annotators a subset of
samples for their true labels and obtains the feedback information on whether
the samples are misclassified. The sampling mechanism needs to balance between
discovering new patterns of misclassification (exploration) and confirming the
potential patterns of classification (exploitation). We construct a
determinantal point process, whose intensity balances the
exploration-exploitation trade-off through the weighted update of the posterior
at each round to form the generator of the stochastic sampler. The numerical
results empirically demonstrate the competitive performance of our framework on
multiple datasets at various signal-to-noise ratios.
</p>
</p>
</div>

    </div>
    </body>
    