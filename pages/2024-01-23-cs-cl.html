<!DOCTYPE html>
<html>
<head>
<title>2024-01-23-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.10244">Knowledge graph driven recommendation model of graph neural network. (arXiv:2401.10244v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chaoyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1">Siwei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a></p>
<p>A new graph neural network-based recommendation model called KGLN, which
leverages Knowledge Graph (KG) information, was developed to enhance the
accuracy and effectiveness of personalized recommendations. This model begins
by using a single-layer neural network to merge individual node features in the
graph. It then adjusts the aggregation weights of neighboring entities by
incorporating influence factors. The model evolves from a single layer to
multiple layers through iteration, enabling entities to access extensive
multi-order associated entity information. The final step involves integrating
features of entities and users to produce a recommendation score. The model's
performance was evaluated by comparing its effects on various aggregation
methods and influence factors. In tests using the MovieLen-1M and Book-Crossing
datasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to
5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like
LibFM, DeepFM, Wide&amp;Deep, and RippleNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10279">A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems. (arXiv:2401.10279v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tucker_S/0/1/0/all/0/1">Sean Tucker</a></p>
<p>Geospatial Location Embedding (GLE) helps a Large Language Model (LLM)
assimilate and analyze spatial data. GLE emergence in Geospatial Artificial
Intelligence (GeoAI) is precipitated by the need for deeper geospatial
awareness in our complex contemporary spaces and the success of LLMs in
extracting deep meaning in Generative AI. We searched Google Scholar, Science
Direct, and arXiv for papers on geospatial location embedding and LLM and
reviewed articles focused on gaining deeper spatial "knowing" through LLMs. We
screened 304 titles, 30 abstracts, and 18 full-text papers that reveal four GLE
themes - Entity Location Embedding (ELE), Document Location Embedding (DLE),
Sequence Location Embedding (SLE), and Token Location Embedding (TLE).
Synthesis is tabular and narrative, including a dialogic conversation between
"Space" and "LLM." Though GLEs aid spatial understanding by superimposing
spatial data, they emphasize the need to advance in the intricacies of spatial
modalities and generalized reasoning. GLEs signal the need for a Spatial
Foundation/Language Model (SLM) that embeds spatial knowing within the model
architecture. The SLM framework advances Spatial Artificial Intelligence
Systems (SPAIS), establishing a Spatial Vector Space (SVS) that maps to
physical space. The resulting spatially imbued Language Model is unique. It
simultaneously represents actual space and an AI-capable space, paving the way
for AI native geo storage, analysis, and multi-modality as the basis for
Spatial Artificial Intelligence Systems (SPAIS).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10286">Top in Chinese Data Processing: English Code Models. (arXiv:2401.10286v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Linghan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xiaojun Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jiayuan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Y/0/1/0/all/0/1">Yue Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1">Gang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hongwei Chen</a></p>
<p>While the alignment between tasks and training corpora is a fundamental
consensus in the application of language models, our series of experiments and
the metrics we designed reveal that code-based Large Language Models (LLMs)
significantly outperform models trained on data that is closely matched to the
tasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to
Chinese hallucinations, models exhibiting fewer linguistic features of the
Chinese language achieve better performance. Our experimental results can be
easily replicated in Chinese data processing tasks, such as preparing data for
Retrieval-Augmented Generation (RAG), by simply replacing the base model with a
code-based model. Additionally, our research offers a distinct perspective for
discussion on the philosophical "Chinese Room" thought experiment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10334">DrugAssist: A Large Language Model for Molecule Optimization. (arXiv:2401.10334v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Ye_G/0/1/0/all/0/1">Geyan Ye</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cai_X/0/1/0/all/0/1">Xibao Cai</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lai_H/0/1/0/all/0/1">Houtim Lai</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1">Xing Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_J/0/1/0/all/0/1">Junhong Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1">Longyue Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zeng_X/0/1/0/all/0/1">Xiangxiang Zeng</a></p>
<p>Recently, the impressive performance of large language models (LLMs) on a
wide range of tasks has attracted an increasing number of attempts to apply
LLMs in drug discovery. However, molecule optimization, a critical task in the
drug discovery pipeline, is currently an area that has seen little involvement
from LLMs. Most of existing approaches focus solely on capturing the underlying
patterns in chemical structures provided by the data, without taking advantage
of expert feedback. These non-interactive approaches overlook the fact that the
drug discovery process is actually one that requires the integration of expert
experience and iterative refinement. To address this gap, we propose
DrugAssist, an interactive molecule optimization model which performs
optimization through human-machine dialogue by leveraging LLM's strong
interactivity and generalizability. DrugAssist has achieved leading results in
both single and multiple property optimization, simultaneously showcasing
immense potential in transferability and iterative optimization. In addition,
we publicly release a large instruction-based dataset called
MolOpt-Instructions for fine-tuning language models on molecule optimization
tasks. We have made our code and data publicly available at
https://github.com/blazerye/DrugAssist, which we hope to pave the way for
future research in LLMs' application for drug discovery.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10337">Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Srndic_N/0/1/0/all/0/1">Nedim Srndic</a>, <a href="http://arxiv.org/find/cs/1/au:+Neth_A/0/1/0/all/0/1">Alexander Neth</a></p>
<p>Tactics, Techniques and Procedures (TTPs) represent sophisticated attack
patterns in the cybersecurity domain, described encyclopedically in textual
knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP
mapping, is an important and challenging task. Conventional learning approaches
often target the problem in the classical multi-class or multilabel
classification setting. This setting hinders the learning ability of the model
due to a large number of classes (i.e., TTPs), the inevitable skewness of the
label distribution and the complex hierarchical structure of the label space.
We formulate the problem in a different learning paradigm, where the assignment
of a text to a TTP label is decided by the direct semantic similarity between
the two, thus reducing the complexity of competing solely over the large
labeling space. To that end, we propose a neural matching architecture with an
effective sampling-based learn-to-compare mechanism, facilitating the learning
process of the matching model despite constrained resources.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10352">Bridging Cultural Nuances in Dialogue Agents through Cultural Value Surveys. (arXiv:2401.10352v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1">Daniel Hershcovich</a></p>
<p>The cultural landscape of interactions with dialogue agents is a compelling
yet relatively unexplored territory. It's clear that various sociocultural
aspects -- from communication styles and beliefs to shared metaphors and
knowledge -- profoundly impact these interactions. To delve deeper into this
dynamic, we introduce cuDialog, a first-of-its-kind benchmark for dialogue
generation with a cultural lens. We also develop baseline models capable of
extracting cultural attributes from dialogue exchanges, with the goal of
enhancing the predictive accuracy and quality of dialogue agents. To
effectively co-learn cultural understanding and multi-turn dialogue
predictions, we propose to incorporate cultural dimensions with dialogue
encoding features. Our experimental findings highlight that incorporating
cultural value surveys boosts alignment with references and cultural markers,
demonstrating its considerable influence on personalization and dialogue
quality. To facilitate further exploration in this exciting domain, we publish
our benchmark publicly accessible at https://github.com/yongcaoplus/cuDialog.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10353">Inconsistent dialogue responses and how to recover from them. (arXiv:2401.10353v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lifeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Linfeng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1">Haitao Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dong Yu</a></p>
<p>One critical issue for chat systems is to stay consistent about preferences,
opinions, beliefs and facts of itself, which has been shown a difficult
problem. In this work, we study methods to assess and bolster utterance
consistency of chat systems. A dataset is first developed for studying the
inconsistencies, where inconsistent dialogue responses, explanations of the
inconsistencies, and recovery utterances are authored by annotators. This
covers the life span of inconsistencies, namely introduction, understanding,
and resolution. Building on this, we introduce a set of tasks centered on
dialogue consistency, specifically focused on its detection and resolution. Our
experimental findings indicate that our dataset significantly helps the
progress in identifying and resolving conversational inconsistencies, and
current popular large language models like ChatGPT which are good at resolving
inconsistencies however still struggle with detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10407">Learning High-Quality and General-Purpose Phrase Representations. (arXiv:2401.10407v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lihu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Varoquaux_G/0/1/0/all/0/1">Ga&#xeb;l Varoquaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Suchanek_F/0/1/0/all/0/1">Fabian M. Suchanek</a></p>
<p>Phrase representations play an important role in data science and natural
language processing, benefiting various tasks like Entity Alignment, Record
Linkage, Fuzzy Joins, and Paraphrase Classification. The current
state-of-the-art method involves fine-tuning pre-trained language models for
phrasal embeddings using contrastive learning. However, we have identified
areas for improvement. First, these pre-trained models tend to be unnecessarily
complex and require to be pre-trained on a corpus with context sentences.
Second, leveraging the phrase type and morphology gives phrase representations
that are both more precise and more flexible. We propose an improved framework
to learn phrase representations in a context-free fashion. The framework
employs phrase type classification as an auxiliary task and incorporates
character-level information more effectively into the phrase representation.
Furthermore, we design three granularities of data augmentation to increase the
diversity of training samples. Our experiments across a wide range of tasks
show that our approach generates superior phrase embeddings compared to
previous methods while requiring a smaller model size. The code is available at
\faGithub~ \url{https://github.com/tigerchen52/PEARL} \end{abstract}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10415">Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals?. (arXiv:2401.10415v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fonseca_M/0/1/0/all/0/1">Marcio Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Shay B. Cohen</a></p>
<p>In this work, we investigate the controllability of large language models
(LLMs) on scientific summarization tasks. We identify key stylistic and content
coverage factors that characterize different types of summaries such as paper
reviews, abstracts, and lay summaries. By controlling stylistic features, we
find that non-fine-tuned LLMs outperform humans in the MuP review generation
task, both in terms of similarity to reference summaries and human preferences.
Also, we show that we can improve the controllability of LLMs with
keyword-based classifier-free guidance (CFG) while achieving lexical overlap
comparable to strong fine-tuned baselines on arXiv and PubMed. However, our
results also indicate that LLMs cannot consistently generate long summaries
with more than 8 sentences. Furthermore, these models exhibit limited capacity
to produce highly abstractive lay summaries. Although LLMs demonstrate strong
generic summarization competency, sophisticated content control without costly
fine-tuning remains an open problem for domain-specific applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10440">Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models. (arXiv:2401.10440v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Blevins_T/0/1/0/all/0/1">Terra Blevins</a>, <a href="http://arxiv.org/find/cs/1/au:+Limisiewicz_T/0/1/0/all/0/1">Tomasz Limisiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1">Suchin Gururangan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Margaret Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonen_H/0/1/0/all/0/1">Hila Gonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a></p>
<p>Despite their popularity in non-English NLP, multilingual language models
often underperform monolingual ones due to inter-language competition for model
parameters. We propose Cross-lingual Expert Language Models (X-ELM), which
mitigate this competition by independently training language models on subsets
of the multilingual corpus. This process specializes X-ELMs to different
languages while remaining effective as a multilingual ensemble. Our experiments
show that when given the same compute budget, X-ELM outperforms jointly trained
multilingual models across all considered languages and that these gains
transfer to downstream tasks. X-ELM provides additional benefits over
performance improvements: new experts can be iteratively added, adapting X-ELM
to new languages without catastrophic forgetting. Furthermore, training is
asynchronous, reducing the hardware requirements for multilingual training and
democratizing multilingual modeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10446">Large Language Models are Efficient Learners of Noise-Robust Speech Recognition. (arXiv:2401.10446v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuchen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruizhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chng_E/0/1/0/all/0/1">EnSiong Chng</a></p>
<p>Recent advances in large language models (LLMs) have promoted generative
error correction (GER) for automatic speech recognition (ASR), which leverages
the rich linguistic knowledge and powerful reasoning ability of LLMs to improve
recognition results. The latest work proposes a GER benchmark with HyPoradise
dataset to learn the mapping from ASR N-best hypotheses to ground-truth
transcription by efficient LLM finetuning, which shows great effectiveness but
lacks specificity on noise-robust ASR. In this work, we extend the benchmark to
noisy conditions and investigate if we can teach LLMs to perform denoising for
GER just like what robust ASR do}, where one solution is introducing noise
information as a conditioner into LLM. However, directly incorporating noise
embeddings from audio encoder could harm the LLM tuning due to cross-modality
gap. To this end, we propose to extract a language-space noise embedding from
the N-best list to represent the noise conditions of source speech, which can
promote the denoising process in GER. Furthermore, in order to enhance its
representation ability of audio noise, we design a knowledge distillation (KD)
approach via mutual information estimation to distill the real noise
information in audio embeddings to our language embedding. Experiments on
various latest LLMs demonstrate our approach achieves a new breakthrough with
up to 53.9% correction improvement in terms of word error rate while with
limited training data. Analysis shows that our language-space noise embedding
can well represent the noise conditions of source speech, under which
off-the-shelf LLMs show strong ability of language-space denoising.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10447">Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition. (arXiv:2401.10447v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1">Tuan Dinh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_S/0/1/0/all/0/1">Sungho Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolehmainen_J/0/1/0/all/0/1">Jari Kolehmainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1">Roger Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Filimonov_D/0/1/0/all/0/1">Denis Filimonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shivakumar_P/0/1/0/all/0/1">Prashanth G. Shivakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhe_A/0/1/0/all/0/1">Ankur Gandhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastow_A/0/1/0/all/0/1">Ariya Rastow</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jia Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bulyko_I/0/1/0/all/0/1">Ivan Bulyko</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1">Andreas Stolcke</a></p>
<p>The use of low-rank adaptation (LoRA) with frozen pretrained language models
(PLMs) has become increasing popular as a mainstream, resource-efficient
modeling approach for memory-constrained hardware. In this study, we first
explore how to enhance model performance by introducing various LoRA training
strategies, achieving relative word error rate reductions of 3.50\% on the
public Librispeech dataset and of 3.67\% on an internal dataset in the
messaging domain. To further characterize the stability of LoRA-based
second-pass speech recognition models, we examine robustness against input
perturbations. These perturbations are rooted in homophone replacements and a
novel metric called N-best Perturbation-based Rescoring Robustness (NPRR), both
designed to measure the relative degradation in the performance of rescoring
models. Our experimental results indicate that while advanced variants of LoRA,
such as dynamic rank-allocated LoRA, lead to performance degradation in
$1$-best perturbation, they alleviate the degradation in $N$-best perturbation.
This finding is in comparison to fully-tuned models and vanilla LoRA tuning
baselines, suggesting that a comprehensive selection is needed when using
LoRA-based adaptation for compute-cost savings and robust language modeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10449">Contextualized Automatic Speech Recognition with Attention-Based Bias Phrase Boosted Beam Search. (arXiv:2401.10449v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Sudo_Y/0/1/0/all/0/1">Yui Sudo</a>, <a href="http://arxiv.org/find/eess/1/au:+Shakeel_M/0/1/0/all/0/1">Muhammad Shakeel</a>, <a href="http://arxiv.org/find/eess/1/au:+Fukumoto_Y/0/1/0/all/0/1">Yosuke Fukumoto</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_Y/0/1/0/all/0/1">Yifan Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a></p>
<p>End-to-end (E2E) automatic speech recognition (ASR) methods exhibit
remarkable performance. However, since the performance of such methods is
intrinsically linked to the context present in the training data, E2E-ASR
methods do not perform as desired for unseen user contexts (e.g., technical
terms, personal names, and playlists). Thus, E2E-ASR methods must be easily
contextualized by the user or developer. This paper proposes an attention-based
contextual biasing method that can be customized using an editable phrase list
(referred to as a bias list). The proposed method can be trained effectively by
combining a bias phrase index loss and special tokens to detect the bias
phrases in the input speech data. In addition, to improve the contextualization
performance during inference further, we propose a bias phrase boosted (BPB)
beam search algorithm based on the bias phrase index probability. Experimental
results demonstrate that the proposed method consistently improves the word
error rate and the character error rate of the target phrases in the bias list
on both the Librispeech-960 (English) and our in-house (Japanese) dataset,
respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10463">Critical Data Size of Language Models from a Grokking Perspective. (arXiv:2401.10463v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xuekai Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhouhan Lin</a></p>
<p>We explore the critical data size in language models, a threshold that marks
a fundamental shift from quick memorization to slow generalization. We
formalize the phase transition under the grokking configuration into the Data
Efficiency Hypothesis and identify data insufficiency, sufficiency, and surplus
regimes in language models training dynamics. We develop a grokking
configuration to reproduce grokking on simplistic language models stably by
rescaling initialization and weight decay. We show that generalization occurs
only when language models reach a critical size. We analyze grokking across
sample-wise and model-wise, verifying the proposed data efficiency hypothesis.
Our experiments reveal smoother phase transitions occurring at the critical
dataset size for language datasets. As the model size increases, this critical
point also becomes larger, indicating that larger models require more data. Our
results deepen the understanding of language model training, offering a novel
perspective on the role of data in the learning mechanism of language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10465">Data-driven grapheme-to-phoneme representations for a lexicon-free text-to-speech. (arXiv:2401.10465v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1">Abhinav Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jiyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Khyalia_S/0/1/0/all/0/1">Sushil Khyalia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Chanwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gowda_D/0/1/0/all/0/1">Dhananjaya Gowda</a></p>
<p>Grapheme-to-Phoneme (G2P) is an essential first step in any modern,
high-quality Text-to-Speech (TTS) system. Most of the current G2P systems rely
on carefully hand-crafted lexicons developed by experts. This poses a two-fold
problem. Firstly, the lexicons are generated using a fixed phoneme set,
usually, ARPABET or IPA, which might not be the most optimal way to represent
phonemes for all languages. Secondly, the man-hours required to produce such an
expert lexicon are very high. In this paper, we eliminate both of these issues
by using recent advances in self-supervised learning to obtain data-driven
phoneme representations instead of fixed representations. We compare our
lexicon-free approach against strong baselines that utilize a well-crafted
lexicon. Furthermore, we show that our data-driven lexicon-free method performs
as good or even marginally better than the conventional rule-based or
lexicon-based neural G2Ps in terms of Mean Opinion Score (MOS) while using no
prior language lexicon or phoneme set, i.e. no linguistic expertise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10471">DeepEdit: Knowledge Editing as Decoding with Constraints. (arXiv:2401.10471v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a></p>
<p>We develop a new perspective of knowledge editing for large language models
(LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search
based Progressive Decoding for Knowledge Editing), a neuro-symbolic method that
improves knowledge editing with better coherence of reasoning, relevance to the
question, and awareness of updated knowledge. DeepEdit can be flexibly applied
to all black-box LLMs: it does not require any access to the model parameters,
representations, or output vocabulary distributions. DeepEdit progressively
produces the high-quality reasoning steps towards effective knowledge editing.
It utilizes a depth-first search to revise the LLMs' output, which improves the
output's informativeness to the input question and awareness of the updated
knowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more
succinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit
yields significant gains on MQuaKE, a challenging multi-hop question-answering
dataset with knowledge editing. We release the source code at
https://github.com/wangywUST/DeepEdit.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10472">Name Tagging Under Domain Shift via Metric Learning for Life Sciences. (arXiv:2401.10472v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karisani_P/0/1/0/all/0/1">Payam Karisani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a></p>
<p>Name tagging is a key component of Information Extraction (IE), particularly
in scientific domains such as biomedicine and chemistry, where large language
models (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of
transfer learning for enhancing a name tagging model trained in the biomedical
domain (the source domain) to be used in the chemical domain (the target
domain). A common practice for training such a model in a few-shot learning
setting is to pretrain the model on the labeled source data, and then, to
finetune it on a hand-full of labeled target examples. In our experiments we
observed that such a model is prone to mis-labeling the source entities, which
can often appear in the text, as the target entities. To alleviate this
problem, we propose a model to transfer the knowledge from the source domain to
the target domain, however, at the same time, to project the source entities
and target entities into separate regions of the feature space. This diminishes
the risk of mis-labeling the source entities as the target entities. Our model
consists of two stages: 1) entity grouping in the source domain, which
incorporates knowledge from annotated events to establish relations between
entities, and 2) entity discrimination in the target domain, which relies on
pseudo labeling and contrastive learning to enhance discrimination between the
entities in the two domains. We carry out our extensive experiments across
three source and three target datasets, and demonstrate that our method
outperforms the baselines, in some scenarios by 5\% absolute value.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10480">Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning. (arXiv:2401.10480v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_P/0/1/0/all/0/1">Peiwen Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shaoxiong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1">Boyuan Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinglin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Bin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heda Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kan Li</a></p>
<p>Self-consistency (SC) has been a widely used decoding strategy for
chain-of-thought reasoning. Despite bringing significant performance
improvements across a variety of multi-step reasoning tasks, it is a high-cost
method that requires multiple sampling with the preset size. In this paper, we
propose a simple and scalable sampling process, \textbf{E}arly-Stopping
\textbf{S}elf-\textbf{C}onsistency (ESC), to greatly reduce the cost of SC
without sacrificing performance. On this basis, one control scheme for ESC is
further derivated to dynamically choose the performance-cost balance for
different tasks and models. To demonstrate ESC's effectiveness, we conducted
extensive experiments on three popular categories of reasoning tasks:
arithmetic, commonsense and symbolic reasoning over language models with
varying scales. The empirical results show that ESC reduces the average number
of sampling of chain-of-thought reasoning by a significant margin on six
benchmarks, including MATH (-33.8%), GSM8K (-80.1%), StrategyQA (-76.8%),
CommonsenseQA (-78.5%), Coin Flip (-84.2%) and Last Letters (-67.4%), while
attaining comparable performances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10487">Generative Dense Retrieval: Memory Can Be a Burden. (arXiv:2401.10487v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_P/0/1/0/all/0/1">Peiwen Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinglin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shaoxiong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1">Boyuan Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heda Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_X/0/1/0/all/0/1">Xupeng Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kan Li</a></p>
<p>Generative Retrieval (GR), autoregressively decoding relevant document
identifiers given a query, has been shown to perform well under the setting of
small-scale corpora. By memorizing the document corpus with model parameters,
GR implicitly achieves deep interaction between query and document. However,
such a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for
fine-grained features of documents; (2) Memory confusion gets worse as the
corpus size increases; (3) Huge memory update costs for new documents. To
alleviate these problems, we propose the Generative Dense Retrieval (GDR)
paradigm. Specifically, GDR first uses the limited memory volume to achieve
inter-cluster matching from query to relevant document clusters.
Memorizing-free matching mechanism from Dense Retrieval (DR) is then introduced
to conduct fine-grained intra-cluster matching from clusters to relevant
documents. The coarse-to-fine process maximizes the advantages of GR's deep
interaction and DR's scalability. Besides, we design a cluster identifier
constructing strategy to facilitate corpus memory and a cluster-adaptive
negative sampling strategy to enhance the intra-cluster mapping ability.
Empirical results show that GDR obtains an average of 3.0 R@100 improvement on
NQ dataset under multiple settings and has better scalability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10491">Knowledge Fusion of Large Language Models. (arXiv:2401.10491v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1">Fanqi Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xinting Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1">Wei Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuming Shi</a></p>
<p>While training large language models (LLMs) from scratch can generate models
with distinct functionalities and strengths, it comes at significant costs and
may result in redundant capabilities. Alternatively, a cost-effective and
compelling approach is to merge existing pre-trained LLMs into a more potent
model. However, due to the varying architectures of these LLMs, directly
blending their weights is impractical. In this paper, we introduce the notion
of knowledge fusion for LLMs, aimed at combining the capabilities of existing
LLMs and transferring them into a single LLM. By leveraging the generative
distributions of source LLMs, we externalize their collective knowledge and
unique strengths, thereby potentially elevating the capabilities of the target
model beyond those of any individual source LLM. We validate our approach using
three popular LLMs with different architectures--Llama-2, MPT, and
OpenLLaMA--across various benchmarks and tasks. Our findings confirm that the
fusion of LLMs can improve the performance of the target model across a range
of capabilities such as reasoning, commonsense, and code generation. Our code,
model weights, and data are public at
\url{https://github.com/fanqiwan/FuseLLM}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10506">FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis. (arXiv:2401.10506v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuren Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yijiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_Y/0/1/0/all/0/1">Yu Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunjun Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_D/0/1/0/all/0/1">Dongfang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jinshu Lin</a></p>
<p>Text-to-SQL, which provides zero-code interface for operating relational
databases, has gained much attention in financial analysis; because, financial
professionals may not well-skilled in SQL programming. However, until now,
there is no practical Text-to-SQL benchmark dataset for financial analysis, and
existing Text-to-SQL methods have not considered the unique characteristics of
databases in financial applications, such as commonly existing wide tables. To
address these issues, we collect a practical Text-to-SQL benchmark dataset and
propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL
framework for financial analysis. The benchmark dataset, BULL, is collected
from the practical financial analysis business of Hundsun Technologies Inc.,
including databases for fund, stock, and macro economy. Besides, the proposed
LLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for
financial Text-to-SQL from the perspectives of prompt construction,
parameter-efficient fine-tuning and output calibration. Extensive experimental
results on BULL demonstrate that FinSQL achieves the state-of-the-art
Text-to-SQL performance at a small cost; furthermore, FinSQL can bring up to
36.64% performance improvement in scenarios requiring few-shot cross-database
model transfer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10510">A match made in consistency heaven: when large language models meet evolutionary algorithms. (arXiv:2401.10510v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wang Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jiaxuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingling Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuyuan Yang</a></p>
<p>Pre-trained large language models (LLMs) have powerful capabilities for
generating creative natural text. Evolutionary algorithms (EAs) can discover
diverse solutions to complex real-world problems. Motivated by the common
collective and directionality of text sequence generation and evolution, this
paper illustrates the strong consistency of LLMs and EAs, which includes
multiple one-to-one key characteristics: token embedding and genotype-phenotype
mapping, position encoding and fitness shaping, position embedding and
selection, attention and crossover, feed-forward neural network and mutation,
model training and parameter update, and multi-task learning and
multi-objective optimization. Based on this consistency perspective, existing
coupling studies are analyzed, including evolutionary fine-tuning and
LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap
for future research in coupling LLMs and EAs, while highlighting key challenges
along the way. The consistency not only reveals the evolution mechanism behind
LLMs but also facilitates the development of evolved artificial agents that
approach or surpass biological organisms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10521">Cross-lingual Editing in Multilingual Language Models. (arXiv:2401.10521v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Beniwal_H/0/1/0/all/0/1">Himanshu Beniwal</a>, <a href="http://arxiv.org/find/cs/1/au:+D_K/0/1/0/all/0/1">Kowsik Nandagopan D</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mayank Singh</a></p>
<p>The training of large language models (LLMs) necessitates substantial data
and computational resources, and updating outdated LLMs entails significant
efforts and resources. While numerous model editing techniques (METs) have
emerged to efficiently update model outputs without retraining, their
effectiveness in multilingual LLMs, where knowledge is stored in diverse
languages, remains an underexplored research area. This research paper
introduces the cross-lingual model editing (\textbf{XME}) paradigm, wherein a
fact is edited in one language, and the subsequent update propagation is
observed across other languages. To investigate the XME paradigm, we conducted
experiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts:
\textit{Latin} (English, French, and Spanish) and \textit{Indic} (Hindi,
Gujarati, and Bengali). The results reveal notable performance limitations of
state-of-the-art METs under the XME setting, mainly when the languages involved
belong to two distinct script families. These findings highlight the need for
further research and development of XME techniques to address these challenges.
For more comprehensive information, the dataset used in this research and the
associated code are publicly available at the following
URL\url{https://github.com/lingo-iitgn/XME}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10529">Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences. (arXiv:2401.10529v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiyao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuhang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hongjin Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuancheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1">Feihong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jaehong Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Taixi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1">Gedas Bertasius</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Huaxiu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a></p>
<p>Multimodal Large Language Models (MLLMs) have demonstrated proficiency in
handling a variety of visual-language tasks. However, current MLLM benchmarks
are predominantly designed to evaluate reasoning based on static information
about a single image, and the ability of modern MLLMs to extrapolate from image
sequences, which is essential for understanding our ever-changing world, has
been less investigated. To address this challenge, this paper introduces
Mementos, a new benchmark designed to assess MLLMs' sequential image reasoning
abilities. Mementos features 4,761 diverse image sequences with varying
lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning
performance. Through a careful evaluation of nine recent MLLMs on Mementos,
including GPT-4V and Gemini, we find that they struggle to accurately describe
dynamic information about given image sequences, often leading to
hallucinations/misrepresentations of objects and their corresponding behaviors.
Our quantitative analysis and case studies identify three key factors impacting
MLLMs' sequential image reasoning: the correlation between object and
behavioral hallucinations, the influence of cooccurring behaviors, and the
compounding impact of behavioral hallucinations. Our dataset is available at
https://github.com/umd-huang-lab/Mementos.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10535">The &quot;Colonial Impulse&quot; of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases. (arXiv:2401.10535v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1">Dipto Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_S/0/1/0/all/0/1">Shion Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Brubaker_J/0/1/0/all/0/1">Jed Brubaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Semaan_B/0/1/0/all/0/1">Bryan Semaan</a></p>
<p>While colonization has sociohistorically impacted people's identities across
various dimensions, those colonial values and biases continue to be perpetuated
by sociotechnical systems. One category of sociotechnical systems--sentiment
analysis tools--can also perpetuate colonial values and bias, yet less
attention has been paid to how such tools may be complicit in perpetuating
coloniality, although they are often used to guide various practices (e.g.,
content moderation). In this paper, we explore potential bias in sentiment
analysis tools in the context of Bengali communities that have experienced and
continue to experience the impacts of colonialism. Drawing on identity
categories most impacted by colonialism amongst local Bengali communities, we
focused our analytic attention on gender, religion, and nationality. We
conducted an algorithmic audit of all sentiment analysis tools for Bengali,
available on the Python package index (PyPI) and GitHub. Despite similar
semantic content and structure, our analyses showed that in addition to
inconsistencies in output from different tools, Bengali sentiment analysis
tools exhibit bias between different identity categories and respond
differently to different ways of identity expression. Connecting our findings
with colonially shaped sociocultural structures of Bengali communities, we
discuss the implications of downstream bias of sentiment analysis tools.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10536">Speech Swin-Transformer: Exploring a Hierarchical Transformer with Shifted Windows for Speech Emotion Recognition. (arXiv:2401.10536v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_H/0/1/0/all/0/1">Hailun Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn Schuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_Y/0/1/0/all/0/1">Yuan Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wenming Zheng</a></p>
<p>Swin-Transformer has demonstrated remarkable success in computer vision by
leveraging its hierarchical feature representation based on Transformer. In
speech signals, emotional information is distributed across different scales of
speech features, e.\,g., word, phrase, and utterance. Drawing above
inspiration, this paper presents a hierarchical speech Transformer with shifted
windows to aggregate multi-scale emotion features for speech emotion
recognition (SER), called Speech Swin-Transformer. Specifically, we first
divide the speech spectrogram into segment-level patches in the time domain,
composed of multiple frame patches. These segment-level patches are then
encoded using a stack of Swin blocks, in which a local window Transformer is
utilized to explore local inter-frame emotional information across frame
patches of each segment patch. After that, we also design a shifted window
Transformer to compensate for patch correlations near the boundaries of segment
patches. Finally, we employ a patch merging operation to aggregate
segment-level emotional features for hierarchical speech representation by
expanding the receptive field of Transformer from frame-level to segment-level.
Experimental results demonstrate that our proposed Speech Swin-Transformer
outperforms the state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10543">Multilingual acoustic word embeddings for zero-resource languages. (arXiv:2401.10543v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Jacobs_C/0/1/0/all/0/1">Christiaan Jacobs</a>, <a href="http://arxiv.org/find/eess/1/au:+Kamper_H/0/1/0/all/0/1">Herman Kamper</a></p>
<p>This research addresses the challenge of developing speech applications for
zero-resource languages that lack labelled data. It specifically uses acoustic
word embedding (AWE) -- fixed-dimensional representations of variable-duration
speech segments -- employing multilingual transfer, where labelled data from
several well-resourced languages are used for pertaining. The study introduces
a new neural network that outperforms existing AWE models on zero-resource
languages. It explores the impact of the choice of well-resourced languages.
AWEs are applied to a keyword-spotting system for hate speech detection in
Swahili radio broadcasts, demonstrating robustness in real-world scenarios.
Additionally, novel semantic AWE models improve semantic query-by-example
search.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10559">OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy. (arXiv:2401.10559v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haowen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1">Kaixiang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Cong Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jinjie Gu</a></p>
<p>We advance the field of Parameter-Efficient Fine-Tuning (PEFT) with our novel
multi-adapter method, OrchMoE, which capitalizes on modular skill architecture
for enhanced forward transfer in neural networks. Unlike prior models that
depend on explicit task identification inputs, OrchMoE automatically discerns
task categories, streamlining the learning process. This is achieved through an
integrated mechanism comprising an Automatic Task Classification module and a
Task-Skill Allocation module, which collectively deduce task-specific
classifications and tailor skill allocation matrices. Our extensive evaluations
on the 'Super Natural Instructions' dataset, featuring 1,600 diverse
instructional tasks, indicate that OrchMoE substantially outperforms comparable
multi-adapter baselines in terms of both performance and sample utilization
efficiency, all while operating within the same parameter constraints. These
findings suggest that OrchMoE offers a significant leap forward in multi-task
learning efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10567">Self-training from Self-memory in Data-to-text Generation. (arXiv:2401.10567v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ta_H/0/1/0/all/0/1">Hoang-Thang Ta</a></p>
<p>This paper introduces a novel training model, self-training from self-memory
(STSM) in data-to-text generation (DTG), allowing the model to self-train on
subsets, including self-memory as outputs inferred directly from the trained
models and/or the new data. The quality of self-memory is validated by two
models, data-to-text (D2T) and text-to-data (T2D), by two pre-defined
conditions: (1) the appearance of all source values in the outputs of the D2T
model and (2) the ability to convert back to source data in the outputs in the
T2D model. We utilize a greedy algorithm to generate shorter D2T outputs if
they contain all source values. Subsequently, we use the T2D model to confirm
that these outputs can capture input relationships by demonstrating their
capacity to convert text back into data. With 30% of the dataset, we can train
the D2T model with a competitive performance compared to full training in the
same setup. We experiment with our model on two datasets, E2E NLG and DART.
STSM offers the D2T model a generalization capability from its subset memory
while reducing training data volume. Ultimately, we anticipate that this paper
will contribute to continual learning solutions that adapt to new training
data, incorporating it as a form of self-memory in DTG tasks. The curated
dataset is publicly available at: https://github.com/hoangthangta/STSM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10580">PHOENIX: Open-Source Language Adaption for Direct Preference Optimization. (arXiv:2401.10580v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Uhlig_M/0/1/0/all/0/1">Matthias Uhlig</a>, <a href="http://arxiv.org/find/cs/1/au:+Schacht_S/0/1/0/all/0/1">Sigurd Schacht</a>, <a href="http://arxiv.org/find/cs/1/au:+Barkur_S/0/1/0/all/0/1">Sudarshan Kamath Barkur</a></p>
<p>Large language models have gained immense importance in recent years and have
demonstrated outstanding results in solving various tasks. However, despite
these achievements, many questions remain unanswered in the context of large
language models. Besides the optimal use of the models for inference and the
alignment of the results to the desired specifications, the transfer of models
to other languages is still an underdeveloped area of research. The recent
publication of models such as Llama-2 and Zephyr has provided new insights into
architectural improvements and the use of human feedback. However, insights
into adapting these techniques to other languages remain scarce. In this paper,
we build on latest improvements and apply the Direct Preference
Optimization(DPO) approach to the German language. The model is available at
https://huggingface.co/DRXD1000/Phoenix.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10647">Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models. (arXiv:2401.10647v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1">Rima Hazra</a>, <a href="http://arxiv.org/find/cs/1/au:+Layek_S/0/1/0/all/0/1">Sayan Layek</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Somnath Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a></p>
<p>In the rapidly advancing field of artificial intelligence, the concept of
Red-Teaming or Jailbreaking large language models (LLMs) has emerged as a
crucial area of study. This approach is especially significant in terms of
assessing and enhancing the safety and robustness of these models. This paper
investigates the intricate consequences of such modifications through model
editing, uncovering a complex relationship between enhancing model accuracy and
preserving its ethical integrity. Our in-depth analysis reveals a striking
paradox: while injecting accurate information is crucial for model reliability,
it can paradoxically destabilize the model's foundational framework, resulting
in unpredictable and potentially unsafe behaviors. Additionally, we propose a
benchmark dataset NicheHazardQA to investigate this unsafe behavior both within
the same and cross topical domain. This aspect of our research sheds light on
how the edits, impact the model's safety metrics and guardrails. Our findings
show that model editing serves as a cost-effective tool for topical red-teaming
by methodically applying targeted edits and evaluating the resultant model
behavior
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10653">Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech Detection. (arXiv:2401.10653v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mandal_A/0/1/0/all/0/1">Atanu Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_G/0/1/0/all/0/1">Gargi Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Barman_A/0/1/0/all/0/1">Amit Barman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_I/0/1/0/all/0/1">Indranil Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Naskar_S/0/1/0/all/0/1">Sudip Kumar Naskar</a></p>
<p>With the recent surge and exponential growth of social media usage,
scrutinizing social media content for the presence of any hateful content is of
utmost importance. Researchers have been diligently working since the past
decade on distinguishing between content that promotes hatred and content that
does not. Traditionally, the main focus has been on analyzing textual content.
However, recent research attempts have also commenced into the identification
of audio-based content. Nevertheless, studies have shown that relying solely on
audio or text-based content may be ineffective, as recent upsurge indicates
that individuals often employ sarcasm in their speech and writing. To overcome
these challenges, we present an approach to identify whether a speech promotes
hate or not utilizing both audio and textual representations. Our methodology
is based on the Transformer framework that incorporates both audio and text
sampling, accompanied by our very own layer called "Attentive Fusion". The
results of our study surpassed previous state-of-the-art techniques, achieving
an impressive macro F1 score of 0.927 on the Test Set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10660">A Simple Framework to Accelerate Multilingual Language Model for Monolingual Text Generation. (arXiv:2401.10660v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Jimin Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gibbeum Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaewoong Cho</a></p>
<p>Recent advancements in large language models have facilitated the execution
of complex language tasks, not only in English but also in non-English
languages. However, the tokenizers of most language models, such as Llama,
trained on English-centric corpora, tend to excessively fragment tokens in
non-English languages. This issue is especially pronounced in non-roman
alphabetic languages, which are often divided at a character or even Unicode
level, leading to slower text generation. To address this, our study introduces
a novel framework designed to expedite text generation in these languages. This
framework predicts larger linguistic units than those of conventional
multilingual tokenizers and is specifically tailored to the target language,
thereby reducing the number of decoding steps required. Our empirical results
demonstrate that the proposed framework increases the generation speed by a
factor of 1.9 compared to standard decoding while maintaining the performance
of a pre-trained multilingual model on monolingual tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10695">LangBridge: Multilingual Reasoning Without Multilingual Supervision. (arXiv:2401.10695v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoon_D/0/1/0/all/0/1">Dongkeun Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1">Joel Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungdong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seungone Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafayat_S/0/1/0/all/0/1">Sheikh Shafayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minjoon Seo</a></p>
<p>We introduce LangBridge, a zero-shot approach to adapt language models for
multilingual reasoning tasks without multilingual supervision. LangBridge
operates by bridging two models, each specialized in different aspects: (1) one
specialized in understanding multiple languages (e.g., mT5 encoder) and (2) one
specialized in reasoning (e.g., Orca 2). LangBridge connects the two models by
introducing minimal trainable parameters between them. Despite utilizing only
English data for training, LangBridge considerably enhances the performance of
language models on low-resource languages across mathematical reasoning,
coding, and logical reasoning. Our analysis suggests that the efficacy of
LangBridge stems from the language-agnostic characteristics of multilingual
representations. We publicly release our code and models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10711">Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering. (arXiv:2401.10711v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chenghang Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yixuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1">Weifeng Ge</a></p>
<p>Video Question Answering (VideoQA) aims to answer natural language questions
based on the information observed in videos. Despite the recent success of
Large Multimodal Models (LMMs) in image-language understanding and reasoning,
they deal with VideoQA insufficiently by simply taking uniformly sampled frames
as visual inputs, which ignores question-relevant visual clues. Moreover, there
are no human annotations for question-critical timestamps in existing VideoQA
datasets. In light of this, we propose a novel weakly supervised framework to
enforce the LMMs to reason out the answers with question-critical moments as
visual inputs. Specifically, we fuse the question and answer pairs as event
descriptions to find multiple keyframes as target moments, which will be
pseudo-labels. With these pseudo-labels as additionally weak supervision, we
devise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCG
learns multiple Gaussian functions to characterize the temporal structure of
the video, and sample question-critical frames as positive moments to be the
visual inputs of LMMs. Extensive experiments on several VideoQA benchmarks
verify the effectiveness of our framework, and we achieve substantial
improvements compared to previous state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10712">Q&amp;A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge. (arXiv:2401.10712v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haibi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1">Weifeng Ge</a></p>
<p>With the breakthrough of multi-modal large language models, answering complex
visual questions that demand advanced reasoning abilities and world knowledge
has become a much more important testbed for developing AI models than ever.
However, equipping AI models with robust cross-modality reasoning ability
remains challenging since the cognition scheme of humans has not been
understood systematically. In this paper, we believe that if we can collect
visual clues in the given image as much as possible, we will recognize the
image more accurately, understand the question better, recall relevant
knowledge more easily, and finally reason out the answer. We discover these
rich visual clues by mining question-answer pairs in images and sending them
into multi-modal large language models as prompts. We call the proposed method
Q&amp;A Prompts. Specifically, we first use the image-answer pairs and the
corresponding questions in the training set as inputs and outputs to train a
visual question generation model. Then, we use an image tagging model to
identify various instances and send packaged image-tag pairs into the visual
question generation model to generate relevant questions with the extracted
image tags as answers. Finally, we encode these generated question-answer pairs
as prompts with a visual-aware prompting module and send them into pre-trained
multi-modal large language models to reason out the final answers. Experimental
results show that, compared with state-of-the-art methods, our Q&amp;A Prompts
achieves substantial improvements on the challenging visual question answering
datasets requiring reasoning over diverse world knowledge, such as OK-VQA and
A-OKVQA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10716">Structured Code Representations Enable Data-Efficient Adaptation of Code Language Models. (arXiv:2401.10716v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agarwal_M/0/1/0/all/0/1">Mayank Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yikang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bailin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a></p>
<p>Current language models tailored for code tasks often adopt the
pre-training-then-fine-tuning paradigm from natural language processing,
modeling source code as plain text. This approach, however, overlooks the
unambiguous structures inherent in programming languages. In this work, we
explore data-efficient adaptation of pre-trained code models by further
pre-training and fine-tuning them with program structures. Specifically, we
represent programs as parse trees -- also known as concrete syntax trees (CSTs)
-- and adapt pre-trained models on serialized CSTs. Although the models that we
adapt have been pre-trained only on the surface form of programs, we find that
a small amount of continual pre-training and fine-tuning on CSTs without
changing the model architecture yields improvements over the baseline approach
across various code tasks. The improvements are found to be particularly
significant when there are limited training examples, demonstrating the
effectiveness of integrating program structures with plain-text representation
even when working with backbone models that have not been pre-trained with
structures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10747">Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weide Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1">Huijing Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1">Fengmao Lv</a></p>
<p>Multimodal sentiment analysis aims to identify the emotions expressed by
individuals through visual, language, and acoustic cues. However, most of the
existing research efforts assume that all modalities are available during both
training and testing, making their algorithms susceptible to the missing
modality scenario. In this paper, we propose a novel knowledge-transfer network
to translate between different modalities to reconstruct the missing audio
modalities. Moreover, we develop a cross-modality attention mechanism to retain
the maximal information of the reconstructed and observed modalities for
sentiment prediction. Extensive experiments on three publicly available
datasets demonstrate significant improvements over baselines and achieve
comparable results to the previous methods with complete multi-modality
supervision.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10768">Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment. (arXiv:2401.10768v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1">Fanqi Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xinting Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Leyang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1">Wei Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuming Shi</a></p>
<p>While Large Language Models (LLMs) have proven to be exceptional on a variety
of tasks after alignment, they may still produce responses that contradict the
context or world knowledge confidently, a phenomenon known as
``hallucination''. In this paper, we demonstrate that reducing the
inconsistency between the external knowledge encapsulated in the training data
and the intrinsic knowledge inherited in the pretraining corpus could mitigate
hallucination in alignment. Specifically, we introduce a novel knowledge
consistent alignment (KCA) approach, which involves automatically formulating
examinations based on external knowledge for accessing the comprehension of
LLMs. For data encompassing knowledge inconsistency, KCA implements several
simple yet efficient strategies for processing. We illustrate the superior
performance of the proposed KCA approach in mitigating hallucinations across
six benchmarks using LLMs of different backbones and scales. Furthermore, we
confirm the correlation between knowledge inconsistency and hallucination,
signifying the effectiveness of reducing knowledge inconsistency in alleviating
hallucinations. Our code, model weights, and data are public at
\url{https://github.com/fanqiwan/KCA}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10774">Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads. (arXiv:2401.10774v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_Z/0/1/0/all/0/1">Zhengyang Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hongwu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Deming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dao_T/0/1/0/all/0/1">Tri Dao</a></p>
<p>The inference process in Large Language Models (LLMs) is often limited due to
the absence of parallelism in the auto-regressive decoding process, resulting
in most operations being restricted by the memory bandwidth of accelerators.
While methods such as speculative decoding have been suggested to address this
issue, their implementation is impeded by the challenges associated with
acquiring and maintaining a separate draft model. In this paper, we present
Medusa, an efficient method that augments LLM inference by adding extra
decoding heads to predict multiple subsequent tokens in parallel. Using a
tree-based attention mechanism, Medusa constructs multiple candidate
continuations and verifies them simultaneously in each decoding step. By
leveraging parallel processing, Medusa introduces only minimal overhead in
terms of single-step latency while substantially reducing the number of
decoding steps required.
</p>
<p>We present two levels of fine-tuning procedures for Medusa to meet the needs
of different use cases: Medusa-1: Medusa is directly fine-tuned on top of a
frozen backbone LLM, enabling lossless inference acceleration. Medusa-2: Medusa
is fine-tuned together with the backbone LLM, enabling better prediction
accuracy of Medusa heads and higher speedup but needing a special training
recipe that preserves the backbone model's capabilities.
</p>
<p>Moreover, we propose several extensions that improve or expand the utility of
Medusa, including a self-distillation to handle situations where no training
data is available and a typical acceptance scheme to boost the acceptance rate
while maintaining generation quality. We evaluate Medusa on models of various
sizes and training procedures. Our experiments demonstrate that Medusa-1 can
achieve over 2.2x speedup without compromising generation quality, while
Medusa-2 further improves the speedup to 2.3-3.6x.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10825">A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Keraghel_I/0/1/0/all/0/1">Imed Keraghel</a>, <a href="http://arxiv.org/find/cs/1/au:+Morbieu_S/0/1/0/all/0/1">Stanislas Morbieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadif_M/0/1/0/all/0/1">Mohamed Nadif</a></p>
<p>Named Entity Recognition seeks to extract substrings within a text that name
real-world objects and to determine their type (for example, whether they refer
to persons or organizations). In this survey, we first present an overview of
recent popular approaches, but we also look at graph- and transformer- based
methods including Large Language Models (LLMs) that have not had much coverage
in other surveys. Second, we focus on methods designed for datasets with scarce
annotations. Third, we evaluate the performance of the main NER implementations
on a variety of datasets with differing characteristics (as regards their
domain, their size, and their number of classes). We thus provide a deep
comparison of algorithms that are never considered together. Our experiments
shed some light on how the characteristics of datasets affect the behavior of
the methods that we compare.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10841">Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media. (arXiv:2401.10841v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kikkisetti_D/0/1/0/all/0/1">Dhanush Kikkisetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_R/0/1/0/all/0/1">Raza Ul Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Melillo_W/0/1/0/all/0/1">Wendy Melillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Corizzo_R/0/1/0/all/0/1">Roberto Corizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukouvalas_Z/0/1/0/all/0/1">Zois Boukouvalas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1">Jeff Gill</a>, <a href="http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1">Nathalie Japkowicz</a></p>
<p>Online hate speech proliferation has created a difficult problem for social
media platforms. A particular challenge relates to the use of coded language by
groups interested in both creating a sense of belonging for its users and
evading detection. Coded language evolves quickly and its use varies over time.
This paper proposes a methodology for detecting emerging coded hate-laden
terminology. The methodology is tested in the context of online antisemitic
discourse. The approach considers posts scraped from social media platforms,
often used by extremist users. The posts are scraped using seed expressions
related to previously known discourse of hatred towards Jews. The method begins
by identifying the expressions most representative of each post and calculating
their frequency in the whole corpus. It filters out grammatically incoherent
expressions as well as previously encountered ones so as to focus on emergent
well-formed terminology. This is followed by an assessment of semantic
similarity to known antisemitic terminology using a fine-tuned large language
model, and subsequent filtering out of the expressions that are too distant
from known expressions of hatred. Emergent antisemitic expressions containing
terms clearly relating to Jewish topics are then removed to return only coded
expressions of hatred.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10850">Advancements in eHealth Data Analytics through Natural Language Processing and Deep Learning. (arXiv:2401.10850v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Apostol_E/0/1/0/all/0/1">Elena-Simona Apostol</a>, <a href="http://arxiv.org/find/cs/1/au:+Truica_C/0/1/0/all/0/1">Ciprian-Octavian Truic&#x103;</a></p>
<p>The healthcare environment is commonly referred to as "information-rich" but
also "knowledge poor". Healthcare systems collect huge amounts of data from
various sources: lab reports, medical letters, logs of medical tools or
programs, medical prescriptions, etc. These massive sets of data can provide
great knowledge and information that can improve the medical services, and
overall the healthcare domain, such as disease prediction by analyzing the
patient's symptoms or disease prevention, by facilitating the discovery of
behavioral factors for diseases. Unfortunately, only a relatively small volume
of the textual eHealth data is processed and interpreted, an important factor
being the difficulty in efficiently performing Big Data operations. In the
medical field, detecting domain-specific multi-word terms is a crucial task as
they can define an entire concept with a few words. A term can be defined as a
linguistic structure or a concept, and it is composed of one or more words with
a specific meaning to a domain. All the terms of a domain create its
terminology. This chapter offers a critical study of the current, most
performant solutions for analyzing unstructured (image and textual) eHealth
data. This study also provides a comparison of the current Natural Language
Processing and Deep Learning techniques in the eHealth context. Finally, we
examine and discuss some of the current issues, and we define a set of research
directions in this area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10862">Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning. (arXiv:2401.10862v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Adib Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rugina_I/0/1/0/all/0/1">Ileana Rugina</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Alex Wang</a></p>
<p>Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a type
of attack that can coax these models into generating harmful and illegal
content. In this paper, we show that pruning up to 20% of LLM parameters
markedly increases their resistance to such attacks without additional training
and without sacrificing their performance in standard benchmarks. Intriguingly,
we discovered that the enhanced safety observed post-pruning correlates to the
initial safety training level of the model, hinting that the effect of pruning
could be more general and may hold for other LLM behaviors beyond safety.
Additionally, we introduce a curated dataset of 225 harmful tasks across five
categories, inserted into ten different Jailbreaking prompts, showing that
pruning aids LLMs in concentrating attention on task-relevant tokens in
jailbreaking prompts. Lastly, our experiments reveal that the prominent chat
models, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high
susceptibility to jailbreaking attacks, with some categories achieving nearly
70-100% success rate. These insights underline the potential of pruning as a
generalizable approach for improving LLM safety, reliability, and potentially
other desired behaviors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10882">Reinforcement learning for question answering in programming domain using public community scoring as a human feedback. (arXiv:2401.10882v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorbatovski_A/0/1/0/all/0/1">Alexey Gorbatovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovalchuk_S/0/1/0/all/0/1">Sergey Kovalchuk</a></p>
<p>In this study, we investigate the enhancement of the GPT Neo 125M performance
in Community Question Answering (CQA) with a focus on programming, through the
integration of Reinforcement Learning from Human Feedback (RLHF) and the
utilization of scores from Stack Overflow. Two distinct reward model training
strategies are employed for fine-tuning with Proximal Policy Optimization
(PPO). Notably, the improvements in performance achieved through this method
are comparable to those of GPT Neo 2.7B parameter variant. Additionally, an
auxiliary scoring mechanism is introduced, which demonstrates the limitations
of conventional linguistic metrics in evaluating responses in the programming
domain. Through accurate analysis, this paper looks at the divergence between
traditional linguistic metrics and our human-preferences-based reward model,
underscoring the imperative for domain-specific evaluation methods. By
elucidating the complexities involved in applying RLHF to programming CQA and
accentuating the significance of context-aware evaluation, this study
contributes to the ongoing efforts in refining Large Language Models through
focused human feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09726">Improving Faithfulness of Abstractive Summarization by Controlling Confounding Effect of Irrelevant Sentences. (arXiv:2212.09726v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghoshal_A/0/1/0/all/0/1">Asish Ghoshal</a>, <a href="http://arxiv.org/find/cs/1/au:+Einolghozati_A/0/1/0/all/0/1">Arash Einolghozati</a>, <a href="http://arxiv.org/find/cs/1/au:+Arun_A/0/1/0/all/0/1">Ankit Arun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lili Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gor_V/0/1/0/all/0/1">Vera Gor</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1">Yashar Mehdad</a>, <a href="http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1">Scott Wen-tau Yih</a>, <a href="http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1">Asli Celikyilmaz</a></p>
<p>Lack of factual correctness is an issue that still plagues state-of-the-art
summarization systems despite their impressive progress on generating seemingly
fluent summaries. In this paper, we show that factual inconsistency can be
caused by irrelevant parts of the input text, which act as confounders. To that
end, we leverage information-theoretic measures of causal effects to quantify
the amount of confounding and precisely quantify how they affect the
summarization performance. Based on insights derived from our theoretical
results, we design a simple multi-task model to control such confounding by
leveraging human-annotated relevant sentences when available. Crucially, we
give a principled characterization of data distributions where such confounding
can be large thereby necessitating the use of human annotated relevant
sentences to generate factual summaries. Our approach improves faithfulness
scores by 20\% over strong baselines on AnswerSumm
\citep{fabbri2021answersumm}, a conversation summarization dataset where lack
of faithfulness is a significant issue due to the subjective nature of the
task. Our best method achieves the highest faithfulness score while also
achieving state-of-the-art results on standard metrics like ROUGE and METEOR.
We corroborate these improvements through human evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.12190">MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for Real-Time Fake News Mitigation in Social Media. (arXiv:2302.12190v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Truica_C/0/1/0/all/0/1">Ciprian-Octavian Truic&#x103;</a>, <a href="http://arxiv.org/find/cs/1/au:+Apostol_E/0/1/0/all/0/1">Elena-Simona Apostol</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolescu_R/0/1/0/all/0/1">Radu-C&#x103;t&#x103;lin Nicolescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1">Panagiotis Karras</a></p>
<p>The widespread availability of internet access and handheld devices confers
to social media a power similar to the one newspapers used to have. People seek
affordable information on social media and can reach it within seconds. Yet
this convenience comes with dangers; any user may freely post whatever they
please and the content can stay online for a long period, regardless of its
truthfulness. A need to detect untruthful information, also known as fake news,
arises. In this paper, we present an end-to-end solution that accurately
detects fake news and immunizes network nodes that spread them in real-time. To
detect fake news, we propose two new stack deep learning architectures that
utilize convolutional and bidirectional LSTM layers. To mitigate the spread of
fake news, we propose a real-time network-aware strategy that (1) constructs a
minimum-cost weighted directed spanning tree for a detected node, and (2)
immunizes nodes in that tree by scoring their harmfulness using a novel ranking
function. We demonstrate the effectiveness of our solution on five real-world
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00168">Measuring the Robustness of NLP Models to Domain Shifts. (arXiv:2306.00168v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Calderon_N/0/1/0/all/0/1">Nitay Calderon</a>, <a href="http://arxiv.org/find/cs/1/au:+Porat_N/0/1/0/all/0/1">Naveh Porat</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1">Eyal Ben-David</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapanin_A/0/1/0/all/0/1">Alexander Chapanin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gekhman_Z/0/1/0/all/0/1">Zorik Gekhman</a>, <a href="http://arxiv.org/find/cs/1/au:+Oved_N/0/1/0/all/0/1">Nadav Oved</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalumov_V/0/1/0/all/0/1">Vitaly Shalumov</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a></p>
<p>Existing research on Domain Robustness (DR) suffers from disparate setups,
lack of task variety, and scarce research on recent models and capabilities
such as few-shot learning. Furthermore, we claim that the common practice of
measuring DR might further obscure the picture. Current research focuses on
challenge sets and relies solely on the Source Drop (SD): Using the source
in-domain performance as a reference point for degradation. However, the Target
Drop (TD) should be used as a complementary point of view. To understand the DR
challenge in modern NLP models, we developed a benchmark comprised of seven NLP
tasks, including classification, QA, and generation. Our benchmark focuses on
natural topical domain shifts and enables measuring both the SD and the TD. Our
comprehensive study, involving over 14,000 domain shifts across 18 fine-tuned
and few-shot models, shows that both models suffer from drops upon domain
shifts. While fine-tuned models excel in-domain, few-shot LLMs often surpass
them cross-domain, showing better robustness. In addition, we found that a
large SD can be explained by shifting to a harder domain rather than a genuine
DR challenge. Thus, the TD is a more reliable metric.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.16143">Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhukova_A/0/1/0/all/0/1">Anastasia Zhukova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperl_L/0/1/0/all/0/1">Lukas von Sperl</a>, <a href="http://arxiv.org/find/cs/1/au:+Matt_C/0/1/0/all/0/1">Christian E. Matt</a>, <a href="http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1">Bela Gipp</a></p>
<p>User experience (UX) is a part of human-computer interaction (HCI) research
and focuses on increasing intuitiveness, transparency, simplicity, and trust
for the system users. Most UX research for machine learning (ML) or natural
language processing (NLP) focuses on a data-driven methodology. It engages
domain users mainly for usability evaluation. Moreover, more typical UX methods
tailor the systems towards user usability, unlike learning about the user needs
first. This paper proposes a new methodology for integrating generative UX
research into developing domain NLP applications. Generative UX research
employs domain users at the initial stages of prototype development, i.e.,
ideation and concept evaluation, and the last stage for evaluating system
usefulness and user utility. The methodology emerged from and is evaluated on a
case study about the full-cycle prototype development of a domain-specific
semantic search for daily operations in the process industry. A key finding of
our case study is that involving domain experts increases their interest and
trust in the final NLP application. The combined UX+NLP research of the
proposed method efficiently considers data- and user-driven opportunities and
constraints, which can be crucial for developing NLP applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14995">TransNormerLLM: A Faster and Better Large Language Model with Improved TransNormer. (arXiv:2307.14995v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Weigao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Weixuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuyang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiaodong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunshen Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_B/0/1/0/all/0/1">Baohong Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yiran Zhong</a></p>
<p>We present TransNormerLLM, the first linear attention-based Large Language
Model (LLM) that outperforms conventional softmax attention-based models in
terms of both accuracy and efficiency. TransNormerLLM evolves from the previous
linear attention architecture TransNormer by making advanced modifications that
include positional embedding, linear attention acceleration, gating mechanisms,
tensor normalization, and inference acceleration and stabilization.
Specifically, we use LRPE together with an exponential decay to avoid attention
dilution issues while allowing the model to retain global interactions between
tokens. Additionally, we propose Lightning Attention, a cutting-edge technique
that accelerates linear attention by more than twice in runtime and reduces
memory usage by a remarkable four times. To further enhance the performance of
TransNormer, we leverage a gating mechanism for smooth training and a new
tensor normalization scheme to accelerate the model, resulting in an impressive
acceleration of over $20\%$. Furthermore, we develop a robust inference
algorithm that ensures numerical stability and consistent inference speed,
regardless of the sequence length, showcasing superior efficiency during both
training and inference stages. We also implement an efficient model parallel
schema for TransNormerLLM, enabling seamless deployment on large-scale clusters
and facilitating expansion to even more extensive models, i.e., LLMs with 175B
parameters. We validate our model design through a series of ablations and
train models with sizes of 385M, 1B, and 7B on our self-collected corpus.
Benchmark results demonstrate that our models not only match the performance of
state-of-the-art LLMs with Transformer but are also significantly faster. Code
is released at: https://github.com/OpenNLPLab/TransnormerLLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03279">UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition. (arXiv:2308.03279v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wenxuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1">Hoifung Poon</a></p>
<p>Large language models (LLMs) have demonstrated remarkable generalizability,
such as understanding arbitrary entities and relations. Instruction tuning has
proven effective for distilling LLMs into more cost-efficient models such as
Alpaca and Vicuna. Yet such student models still trail the original LLMs by
large margins in downstream applications. In this paper, we explore targeted
distillation with mission-focused instruction tuning to train student models
that can excel in a broad application class such as open information
extraction. Using named entity recognition (NER) for case study, we show how
ChatGPT can be distilled into much smaller UniversalNER models for open NER.
For evaluation, we assemble the largest NER benchmark to date, comprising 43
datasets across 9 diverse domains such as biomedicine, programming, social
media, law, finance. Without using any direct supervision, UniversalNER attains
remarkable NER accuracy across tens of thousands of entity types, outperforming
general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute
F1 points in average. With a tiny fraction of parameters, UniversalNER not only
acquires ChatGPT's capability in recognizing arbitrary entity types, but also
outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably,
UniversalNER even outperforms by a large margin state-of-the-art multi-task
instruction-tuned systems such as InstructUIE, which uses supervised NER
examples. We also conduct thorough ablation studies to assess the impact of
various components in our distillation approach. We release the distillation
recipe, data, and UniversalNER models to facilitate future research on targeted
distillation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.07107">Large Language Models for Information Retrieval: A Survey. (arXiv:2308.07107v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yutao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Huaying Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiongnan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wenhan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1">Chenlong Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haonan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zhicheng Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a></p>
<p>As a primary means of information acquisition, information retrieval (IR)
systems, such as search engines, have integrated themselves into our daily
lives. These systems also serve as components of dialogue, question-answering,
and recommender systems. The trajectory of IR has evolved dynamically from its
origins in term-based methods to its integration with advanced neural models.
While the neural models excel at capturing complex contextual signals and
semantic nuances, thereby reshaping the IR landscape, they still face
challenges such as data scarcity, interpretability, and the generation of
contextually plausible yet potentially inaccurate responses. This evolution
requires a combination of both traditional methods (such as term-based sparse
retrieval methods with rapid response) and modern neural architectures (such as
language models with powerful language understanding capacity). Meanwhile, the
emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has
revolutionized natural language processing due to their remarkable language
understanding, generation, generalization, and reasoning abilities.
Consequently, recent research has sought to leverage LLMs to improve IR
systems. Given the rapid evolution of this research trajectory, it is necessary
to consolidate existing methodologies and provide nuanced insights through a
comprehensive overview. In this survey, we delve into the confluence of LLMs
and IR systems, including crucial aspects such as query rewriters, retrievers,
rerankers, and readers. Additionally, we explore promising directions, such as
search agents, within this expanding field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.08565">How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Danni Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1">Jan Niehues</a></p>
<p>Customizing machine translation models to comply with fine-grained attributes
such as formality has seen tremendous progress recently. However, current
approaches mostly rely on at least some supervised data with attribute
annotation. Data scarcity therefore remains a bottleneck to democratizing such
customization possibilities to a wider range of languages, lower-resource ones
in particular. Given recent progress in pretrained massively multilingual
translation models, we use them as a foundation to transfer the attribute
controlling capabilities to languages without supervised data. In this work, we
present a comprehensive analysis of transferring attribute controllers based on
a pretrained NLLB-200 model. We investigate both training- and inference-time
control techniques under various data scenarios, and uncover their relative
strengths and weaknesses in zero-shot performance and domain robustness. We
show that both paradigms are complementary, as shown by consistent improvements
on 5 zero-shot directions. Moreover, a human evaluation on a real low-resource
language, Bengali, confirms our findings on zero-shot transfer to new target
languages. The code is
$\href{https://github.com/dannigt/attribute-controller-transfer}{\text{here}}$.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10444">Exploring Iterative Enhancement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1">Qiming Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Leinonen_J/0/1/0/all/0/1">Juho Leinonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1">Alex Yuxuan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1">Wanjun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1">Ga&#xeb;l Gendron</a>, <a href="http://arxiv.org/find/cs/1/au:+Pistotti_T/0/1/0/all/0/1">Timothy Pistotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Alice Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1">Paul Denny</a>, <a href="http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1">Michael Witbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiamou Liu</a></p>
<p>Large language models exhibit superior capabilities in processing and
understanding language, yet their applications in educational contexts remain
underexplored. Learnersourcing enhances learning by engaging students in
creating their own educational content. When learnersourcing multiple-choice
questions, creating explanations for the solution of a question is a crucial
step; it helps other students understand the solution and promotes a deeper
understanding of related concepts. However, it is often difficult for students
to craft effective solution explanations, due to limited subject understanding.
To help scaffold the task of automated explanation generation, we present and
evaluate a framework called "ILearner-LLM", that iteratively enhances the
generated explanations for the given questions with large language models.
Comprising an explanation generation model and an explanation evaluation model,
the framework generates high-quality student-aligned explanations by
iteratively feeding the quality rating score from the evaluation model back
into the instruction prompt of the explanation generation model. Experimental
results demonstrate the effectiveness of our ILearner-LLM on LLaMA2-13B and
GPT-4 to generate higher quality explanations that are closer to those written
by students on five PeerWise datasets. Our findings represent a promising path
to enrich the learnersourcing experience for students and to enhance the
capabilities of large language models for educational applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.14393">LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models. (arXiv:2309.14393v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Faiz_A/0/1/0/all/0/1">Ahmad Faiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaneda_S/0/1/0/all/0/1">Sotaro Kaneda</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruhan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Osi_R/0/1/0/all/0/1">Rita Osi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Prateek Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lei Jiang</a></p>
<p>The carbon footprint associated with large language models (LLMs) is a
significant concern, encompassing emissions from their training, inference,
experimentation, and storage processes, including operational and embodied
carbon emissions. An essential aspect is accurately estimating the carbon
impact of emerging LLMs even before their training, which heavily relies on GPU
usage. Existing studies have reported the carbon footprint of LLM training, but
only one tool, mlco2, can predict the carbon footprint of new neural networks
prior to physical training. However, mlco2 has several serious limitations. It
cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,
disregards critical architectural parameters, focuses solely on GPUs, and
cannot model embodied carbon footprints. Addressing these gaps, we introduce
\textit{\carb}, an end-to-end carbon footprint projection model designed for
both dense and MoE LLMs. Compared to mlco2, \carb~significantly enhances the
accuracy of carbon footprint estimations for various LLMs. The source code is
released at \url{https://github.com/SotaroKaneda/MLCarbon}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.04965">MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain Everyday Tasks. (arXiv:2310.04965v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jingyuan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minqian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Ying Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lifu Huang</a></p>
<p>Automatically generating scripts (i.e. sequences of key steps described in
text) from video demonstrations and reasoning about the subsequent steps are
crucial to the modern AI virtual assistants to guide humans to complete
everyday tasks, especially unfamiliar ones. However, current methods for
generative script learning rely heavily on well-structured preceding steps
described in text and/or images or are limited to a certain domain, resulting
in a disparity with real-world user scenarios. To address these limitations, we
present a new benchmark challenge -- MultiScript, with two new tasks on
task-oriented multimodal script learning: (1) multimodal script generation, and
(2) subsequent step prediction. For both tasks, the input consists of a target
task name and a video illustrating what has been done to complete the target
task, and the expected output is (1) a sequence of structured step descriptions
in text based on the demonstration video, and (2) a single text description for
the subsequent step, respectively. Built from WikiHow, MultiScript covers
multimodal scripts in videos and text descriptions for over 6,655 human
everyday tasks across 19 diverse domains. To establish baseline performance on
MultiScript, we propose two knowledge-guided multimodal generative frameworks
that incorporate the task-related knowledge prompted from large language models
such as Vicuna. Experimental results show that our proposed approaches
significantly improve over the competitive baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05492">How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. (arXiv:2310.05492v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1">Guanting Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hongyi Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Keming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1">Mingfeng Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dayiheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zheng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a></p>
<p>Large language models (LLMs) with enormous pre-training tokens and parameters
emerge diverse abilities, including math reasoning, code generation, and
instruction following. These abilities are further enhanced by supervised
fine-tuning (SFT). While the open-source community has explored ad-hoc SFT for
enhancing individual capabilities, proprietary LLMs exhibit versatility across
various skills. Therefore, understanding the facilitation of multiple abilities
via SFT is paramount. In this study, we specifically focuses on the interplay
of data composition between mathematical reasoning, code generation, and
general human-aligning abilities during SFT. We propose four intriguing
research questions to explore the association between model performance and
various factors including data amount, composition ratio, model size and SFT
strategies. Our experiments reveal that distinct capabilities scale differently
and larger models generally show superior performance with same amount of data.
Mathematical reasoning and code generation consistently improve with increasing
data amount, whereas general abilities plateau after roughly a thousand
samples. Moreover, we observe data composition appears to enhance various
abilities under limited data conditions, yet can lead to performance conflicts
when data is plentiful. Our findings also suggest the amount of composition
data influences performance more than the composition ratio. In analysis of SFT
strategies, we find that sequentially learning multiple skills risks
catastrophic forgetting. Our proposed Dual-stage Mixed Fine-tuning (DMT)
strategy offers a promising solution to learn multiple abilities with different
scaling patterns.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.12399">A Survey of Graph Meets Large Language Model: Progress and Future Directions. (arXiv:2311.12399v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhixun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peisong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiangguo Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jeffrey Xu Yu</a></p>
<p>Graph plays a significant role in representing and analyzing complex
relationships in real-world applications such as citation networks, social
networks, and biological data. Recently, Large Language Models (LLMs), which
have achieved tremendous success in various domains, have also been leveraged
in graph-related tasks to surpass traditional Graph Neural Networks (GNNs)
based methods and yield state-of-the-art performance. In this survey, we first
present a comprehensive review and analysis of existing methods that integrate
LLMs with graphs. First of all, we propose a new taxonomy, which organizes
existing methods into three categories based on the role (i.e., enhancer,
predictor, and alignment component) played by LLMs in graph-related tasks. Then
we systematically survey the representative methods along the three categories
of the taxonomy. Finally, we discuss the remaining limitations of existing
studies and highlight promising avenues for future research. The relevant
papers are summarized and will be consistently updated at:
https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13274">Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting. (arXiv:2311.13274v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zandvoort_D/0/1/0/all/0/1">Daphne van Zandvoort</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiersema_L/0/1/0/all/0/1">Laura Wiersema</a>, <a href="http://arxiv.org/find/cs/1/au:+Huibers_T/0/1/0/all/0/1">Tom Huibers</a>, <a href="http://arxiv.org/find/cs/1/au:+Dulmen_S/0/1/0/all/0/1">Sandra van Dulmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Brinkkemper_S/0/1/0/all/0/1">Sjaak Brinkkemper</a></p>
<p>Customized medical prompts enable Large Language Models (LLM) to effectively
address medical dialogue summarization. The process of medical reporting is
often time-consuming for healthcare professionals. Implementing medical
dialogue summarization techniques presents a viable solution to alleviate this
time constraint by generating automated medical reports. The effectiveness of
LLMs in this process is significantly influenced by the formulation of the
prompt, which plays a crucial role in determining the quality and relevance of
the generated reports. In this research, we used a combination of two distinct
prompting strategies, known as shot prompting and pattern prompting to enhance
the performance of automated medical reporting. The evaluation of the automated
medical reports is carried out using the ROUGE score and a human evaluation
with the help of an expert panel. The two-shot prompting approach in
combination with scope and domain context outperforms other methods and
achieves the highest score when compared to the human reference set by a
general practitioner. However, the automated reports are approximately twice as
long as the human references, due to the addition of both redundant and
relevant statements that are added to the report.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01185">A ripple in time: a discontinuity in American history. (arXiv:2312.01185v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kolpakov_A/0/1/0/all/0/1">Alexander Kolpakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivin_I/0/1/0/all/0/1">Igor Rivin</a></p>
<p>In this note we use the State of the Union Address (SOTU) dataset from Kaggle
to make some surprising (and some not so surprising) observations pertaining to
the general timeline of American history, and the character and nature of the
addresses themselves. Our main approach is using vector embeddings, such as
BERT (DistilBERT) and GPT-2.
</p>
<p>While it is widely believed that BERT (and its variations) is most suitable
for NLP classification tasks, we find out that GPT-2 in conjunction with
nonlinear dimension reduction methods such as UMAP provide better separation
and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In
our case, no model fine-tuning is required, and the pre-trained out-of-the-box
GPT-2 model is enough.
</p>
<p>We also used a fine-tuned DistilBERT model for classification detecting which
President delivered which address, with very good results (accuracy 93\% - 95\%
depending on the run). An analogous task was performed to determine the year of
writing, and we were able to pin it down to about 4 years (which is a single
presidential term).
</p>
<p>It is worth noting that SOTU addresses provide relatively small writing
samples (with about 8000 words on average, and varying widely from under 2000
words to more than 20000), and that the amount of authors is relatively large
(we used SOTU addresses of 42 US presidents). This shows that the techniques
employed turn out to be rather efficient, while all the computations described
in this note can be performed using a single GPU instance of Google Colab.
</p>
<p>The accompanying code is available on GitHub.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.15880">KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph. (arXiv:2312.15880v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1">Tiezheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qingwen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiawei Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dapeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yingyou Wen</a></p>
<p>Large language model (LLM) has achieved outstanding performance on various
downstream tasks with its powerful natural language understanding and zero-shot
capability, but LLM still suffers from knowledge limitation. Especially in
scenarios that require long logical chains or complex reasoning, the
hallucination and knowledge limitation of LLM limit its performance in question
answering (QA). In this paper, we propose a novel framework KnowledgeNavigator
to address these challenges by efficiently and accurately retrieving external
knowledge from knowledge graph and using it as a key factor to enhance LLM
reasoning. Specifically, KnowledgeNavigator first mines and enhances the
potential constraints of the given question to guide the reasoning. Then it
retrieves and filters external knowledge that supports answering through
iterative reasoning on knowledge graph with the guidance of LLM and the
question. Finally, KnowledgeNavigator constructs the structured knowledge into
effective prompts that are friendly to LLM to help its reasoning. We evaluate
KnowledgeNavigator on multiple public KGQA benchmarks, the experiments show the
framework has great effectiveness and generalization, outperforming previous
knowledge graph enhanced LLM methods and is comparable to the fully supervised
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.00368">Improving Text Embeddings with Large Language Models. (arXiv:2401.00368v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1">Nan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Linjun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_R/0/1/0/all/0/1">Rangan Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a></p>
<p>In this paper, we introduce a novel and simple method for obtaining
high-quality text embeddings using only synthetic data and less than 1k
training steps. Unlike existing methods that often depend on multi-stage
intermediate pre-training with billions of weakly-supervised text pairs,
followed by fine-tuning with a few labeled datasets, our method does not
require building complex training pipelines or relying on manually collected
datasets that are often constrained by task diversity and language coverage. We
leverage proprietary LLMs to generate diverse synthetic data for hundreds of
thousands of text embedding tasks across nearly 100 languages. We then
fine-tune open-source decoder-only LLMs on the synthetic data using standard
contrastive loss. Experiments demonstrate that our method achieves strong
performance on highly competitive text embedding benchmarks without using any
labeled data. Furthermore, when fine-tuned with a mixture of synthetic and
labeled data, our model sets new state-of-the-art results on the BEIR and MTEB
benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04398">Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding. (arXiv:2401.04398v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zilong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chun-Liang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1">Julian Martin Eisenschlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Perot_V/0/1/0/all/0/1">Vincent Perot</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miculicich_L/0/1/0/all/0/1">Lesly Miculicich</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1">Yasuhisa Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1">Jingbo Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chen-Yu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1">Tomas Pfister</a></p>
<p>Table-based reasoning with large language models (LLMs) is a promising
direction to tackle many table understanding tasks, such as table-based
question answering and fact verification. Compared with generic reasoning,
table-based reasoning requires the extraction of underlying semantics from both
free-form questions and semi-structured tabular data. Chain-of-Thought and its
similar approaches incorporate the reasoning chain in the form of textual
context, but it is still an open question how to effectively leverage tabular
data in the reasoning chain. We propose the Chain-of-Table framework, where
tabular data is explicitly used in the reasoning chain as a proxy for
intermediate thoughts. Specifically, we guide LLMs using in-context learning to
iteratively generate operations and update the table to represent a tabular
reasoning chain. LLMs can therefore dynamically plan the next operation based
on the results of the previous ones. This continuous evolution of the table
forms a chain, showing the reasoning process for a given tabular problem. The
chain carries structured information of the intermediate results, enabling more
accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art
performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM
choices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05273">INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges. (arXiv:2401.05273v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pereira_J/0/1/0/all/0/1">Jayr Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Assumpcao_A/0/1/0/all/0/1">Andre Assumpcao</a>, <a href="http://arxiv.org/find/cs/1/au:+Trecenti_J/0/1/0/all/0/1">Julio Trecenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Airosa_L/0/1/0/all/0/1">Luiz Airosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lente_C/0/1/0/all/0/1">Caio Lente</a>, <a href="http://arxiv.org/find/cs/1/au:+Cleto_J/0/1/0/all/0/1">Jhonatan Cl&#xe9;to</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobins_G/0/1/0/all/0/1">Guilherme Dobins</a>, <a href="http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1">Rodrigo Nogueira</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_L/0/1/0/all/0/1">Luis Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotufo_R/0/1/0/all/0/1">Roberto Lotufo</a></p>
<p>This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia
Artificial), a groundbreaking system designed to integrate Large Language
Models (LLMs) into the operational framework of Brazilian Federal Court of
Accounts (TCU). The system automates various stages of case analysis, including
basic information extraction, admissibility examination, Periculum in mora and
Fumus boni iuris analyses, and recommendations generation. Through a series of
experiments, we demonstrate INACIA's potential in extracting relevant
information from case documents, evaluating its legal plausibility, and
formulating propositions for judicial decision-making. Utilizing a validation
dataset alongside LLMs, our evaluation methodology presents an innovative
approach to assessing system performance, correlating highly with human
judgment. The results highlight INACIA's proficiency in handling complex legal
tasks, indicating its suitability for augmenting efficiency and judicial
fairness within legal systems. The paper also discusses potential enhancements
and future applications, positioning INACIA as a model for worldwide AI
integration in legal domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07106">Directed Regular and Context-Free Languages. (arXiv:2401.07106v2 [cs.FL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ganardi_M/0/1/0/all/0/1">Moses Ganardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saglam_I/0/1/0/all/0/1">Irmak Saglam</a>, <a href="http://arxiv.org/find/cs/1/au:+Zetzsche_G/0/1/0/all/0/1">Georg Zetzsche</a></p>
<p>We study the problem of deciding whether a given language is directed. A
language $L$ is \emph{directed} if every pair of words in $L$ have a common
(scattered) superword in $L$. Deciding directedness is a fundamental problem in
connection with ideal decompositions of downward closed sets. Another
motivation is that deciding whether two \emph{directed} context-free languages
have the same downward closures can be decided in polynomial time, whereas for
general context-free languages, this problem is known to be coNEXP-complete.
</p>
<p>We show that the directedness problem for regular languages, given as NFAs,
belongs to $AC^1$, and thus polynomial time. Moreover, it is NL-complete for
fixed alphabet sizes. Furthermore, we show that for context-free languages, the
directedness problem is PSPACE-complete.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08326">RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning. (arXiv:2401.08326v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Junjie Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yilong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Songyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Caishuang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sixian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiaoran Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1">Tao Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanjing Huang</a></p>
<p>Tool learning has generated widespread interest as a vital means of
interaction between Large Language Models (LLMs) and the physical world.
Current research predominantly emphasizes LLMs' capacity to utilize tools in
well-structured environments while overlooking their stability when confronted
with the inevitable noise of the real world. To bridge this gap, we introduce
RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool
learning. Specifically, we establish five external environments, each featuring
varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union),
providing an in-depth analysis of the model's resilience across three critical
phases: tool selection, parameter identification, and content filling.
Experiments involving six widely-used models underscore the urgent necessity
for enhancing the robustness of LLMs in tool learning. For instance, the
performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is
no substantial change in manual accuracy. More surprisingly, the noise
correction capability inherent in the GPT family paradoxically impedes its
adaptability in the face of mild noise. In light of these findings, we propose
RoTTuning, a strategy that enriches the diversity of training environments to
bolster the robustness of LLMs in tool learning. The code and data are
available at https://github.com/Junjie-Ye/RoTBench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09343">Efficient slot labelling. (arXiv:2401.09343v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vlasov_V/0/1/0/all/0/1">Vladimir Vlasov</a></p>
<p>Slot labelling is an essential component of any dialogue system, aiming to
find important arguments in every user turn. Common approaches involve large
pre-trained language models (PLMs) like BERT or RoBERTa, but they face
challenges such as high computational requirements and dependence on
pre-training data. In this work, we propose a lightweight method which performs
on par or better than the state-of-the-art PLM-based methods, while having
almost 10x less trainable parameters. This makes it especially applicable for
real-life industry scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09566">Aligning Large Language Models with Counterfactual DPO. (arXiv:2401.09566v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Butcher_B/0/1/0/all/0/1">Bradley Butcher</a></p>
<p>Advancements in large language models (LLMs) have demonstrated remarkable
capabilities across a diverse range of applications. These models excel in
generating text completions that are contextually coherent and cover an
extensive array of subjects. However, the vast datasets required for their
training make aligning response styles during the pretraining and instruction
tuning phases challenging. Consequently, an additional alignment phase is
typically employed, wherein the model is further trained with human preference
data to better align its outputs with human expectations. While this process
doesn't introduce new capabilities per se, it does accentuate generation styles
innate to the model. This paper explores the utilization of counterfactual
prompting within the framework of Direct Preference Optimization (DPO) to align
the model's style without relying on human intervention. We demonstrate that
this method effectively instils desirable behaviour, mitigates undesirable
ones, and encourages the model to disregard inappropriate instructions. Our
findings suggest that counterfactual prompting with DPO presents a low-resource
way to fine-tune LLMs to meet the demands for responsible and ethically aligned
AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09972">Better Explain Transformers by Illuminating Important Information. (arXiv:2401.09972v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Linxin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_A/0/1/0/all/0/1">Ao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lecue_F/0/1/0/all/0/1">Freddy Lecue</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1">Irene Li</a></p>
<p>Transformer-based models excel in various natural language processing (NLP)
tasks, attracting countless efforts to explain their inner workings. Prior
methods explain Transformers by focusing on the raw gradient and attention as
token attribution scores, where non-relevant information is often considered
during explanation computation, resulting in confusing results. In this work,
we propose highlighting the important information and eliminating irrelevant
information by a refined information flow on top of the layer-wise relevance
propagation (LRP) method. Specifically, we consider identifying syntactic and
positional heads as important attention heads and focus on the relevance
obtained from these important heads. Experimental results demonstrate that
irrelevant information does distort output attribution scores and then should
be masked during explanation computation. Compared to eight baselines on both
classification and question-answering datasets, our method consistently
outperforms with over 3\% to 33\% improvement on explanation metrics, providing
superior explanation performance. Our anonymous code repository is available
at: https://github.com/LinxinS97/Mask-LRP
</p>
</p>
</div>

    </div>
    </body>
    