<!DOCTYPE html>
<html>
<head>
<title>2023-11-18-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2311.09224">The Cybersecurity Crisis of Artificial Intelligence: Unrestrained Adoption and Natural Language-Based Attacks. (arXiv:2311.09224v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsamados_A/0/1/0/all/0/1">Andreas Tsamados</a>, <a href="http://arxiv.org/find/cs/1/au:+Floridi_L/0/1/0/all/0/1">Luciano Floridi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taddeo_M/0/1/0/all/0/1">Mariarosaria Taddeo</a></p>
<p>The widespread integration of autoregressive-large language models (AR-LLMs),
such as ChatGPT, across established applications, like search engines, has
introduced critical vulnerabilities with uniquely scalable characteristics. In
this commentary, we analyse these vulnerabilities, their dependence on natural
language as a vector of attack, and their challenges to cybersecurity best
practices. We offer recommendations designed to mitigate these challenges.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09229">CAPCODRE: A Computational Systems Biology and Machine Learning-Based Approach to Predict Cognitive Disorder Risk in the Elderly. (arXiv:2311.09229v1 [q-bio.NC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Mamidala_S/0/1/0/all/0/1">Srilekha Mamidala</a></p>
<p>As global life expectancy improves, the population of the elderly, persons
that are aged 65 years and older, is steadily increasing as well. However, with
aging populations a greater prevalence of cognitive impairment has emerged,
ranging from mild dementia to severe dementias such as Alzheimer's disease due
to genetic and environmental influences, among others. The purpose of this
research was to develop a computational algorithm to predict the risk of
developing cognitive disorders using a dual machine learning and systems
biology approach. The proposed method CAPCODRE (Computational Approach to
Predict COgnitive Disorder Risk for the Elderly) utilized air, water, and noise
environmental pollution data coupled with a gene-protein interaction network,
in addition to cognitive impairment hospitalizations in the United States to
create a tailorable, interactive network able to predict risk of dementia and
Alzheimer's disease. This network was inputted into a random selection
optimization algorithm to select optimal training parameters for training via
k-nearest neighbors, random forest regression, and decision trees. CAPCODRE was
successfully able to predict and model risk of cognitive health issues through
measures of specificity, sensitivity, and accuracy of &gt;85%. The algorithm was
integrated into an app for users to receive personalized predictions based on
their medical history and geographic location. CAPCODRE can point to the extent
of environmental pollution on human health and reveal steps to mitigate risk of
severe cognitive impairment. This research also has the potential to address
racial disparities in cognitive disorder diagnoses and treatment, promoting
more equitable and accessible care.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09233">Neural Packing: from Visual Sensing to Reinforcement Learning. (arXiv:2311.09233v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Juzhan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Minglun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Ruizhen Hu</a></p>
<p>We present a novel learning framework to solve the transport-and-packing
(TAP) problem in 3D. It constitutes a full solution pipeline from partial
observations of input objects via RGBD sensing and recognition to final box
placement, via robotic motion planning, to arrive at a compact packing in a
target container. The technical core of our method is a neural network for TAP,
trained via reinforcement learning (RL), to solve the NP-hard combinatorial
optimization problem. Our network simultaneously selects an object to pack and
determines the final packing location, based on a judicious encoding of the
continuously evolving states of partially observed source objects and available
spaces in the target container, using separate encoders both enabled with
attention mechanisms. The encoded feature vectors are employed to compute the
matching scores and feasibility masks of different pairings of box selection
and available space configuration for packing strategy optimization. Extensive
experiments, including ablation studies and physical packing execution by a
real robot (Universal Robot UR5e), are conducted to evaluate our method in
terms of its design choices, scalability, generalizability, and comparisons to
baselines, including the most recent RL-based TAP solution. We also contribute
the first benchmark for TAP which covers a variety of input settings and
difficulty levels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09235">Scalable Diffusion for Materials Generation. (arXiv:2311.09235v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Mengjiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">KwangHwan Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Merchant_A/0/1/0/all/0/1">Amil Merchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1">Dale Schuurmans</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>, <a href="http://arxiv.org/find/cs/1/au:+Cubuk_E/0/1/0/all/0/1">Ekin Dogus Cubuk</a></p>
<p>Generative models trained on internet-scale data are capable of generating
novel and realistic texts, images, and videos. A natural next question is
whether these models can advance science, for example by generating novel
stable materials. Traditionally, models with explicit structures (e.g., graphs)
have been used in modeling structural relationships in scientific data (e.g.,
atoms and bonds in crystals), but generating structures can be difficult to
scale to large and complex systems. Another challenge in generating materials
is the mismatch between standard generative modeling metrics and downstream
applications. For instance, common metrics such as the reconstruction error do
not correlate well with the downstream goal of discovering stable materials. In
this work, we tackle the scalability challenge by developing a unified crystal
representation that can represent any crystal structure (UniMat), followed by
training a diffusion probabilistic model on these UniMat representations. Our
empirical results suggest that despite the lack of explicit structure modeling,
UniMat can generate high fidelity crystal structures from larger and more
complex chemical systems, outperforming previous graph-based approaches under
various generative modeling metrics. To better connect the generation quality
of materials to downstream applications, such as discovering novel stable
materials, we propose additional metrics for evaluating generative models of
materials, including per-composition formation energy and stability with
respect to convex hulls through decomposition energy from Density Function
Theory (DFT). Lastly, we show that conditional generation with UniMat can scale
to previously established crystal datasets with up to millions of crystals
structures, outperforming random structure search (the current leading method
for structure discovery) in discovering new stable materials.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09237">An Innovative Tool for Uploading/Scraping Large Image Datasets on Social Networks. (arXiv:2311.09237v1 [cs.DL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arceri_N/0/1/0/all/0/1">Nicol&#xf2; Fabio Arceri</a>, <a href="http://arxiv.org/find/cs/1/au:+Giudice_O/0/1/0/all/0/1">Oliver Giudice</a>, <a href="http://arxiv.org/find/cs/1/au:+Battiato_S/0/1/0/all/0/1">Sebastiano Battiato</a></p>
<p>Nowadays, people can retrieve and share digital information in an
increasingly easy and fast fashion through the well-known digital platforms,
including sensitive data, inappropriate or illegal content, and, in general,
information that might serve as probative evidence in court. Consequently, to
assess forensics issues, we need to figure out how to trace back to the posting
chain of a digital evidence (e.g., a picture, an audio) throughout the involved
platforms -- this is what Digital (also Forensics) Ballistics basically deals
with. With the entry of Machine Learning as a tool of the trade in many
research areas, the need for vast amounts of data has been dramatically
increasing over the last few years. However, collecting or simply find the
"right" datasets that properly enables data-driven research studies can turn
out to be not trivial in some cases, if not extremely challenging, especially
when it comes with highly specialized tasks, such as creating datasets analyzed
to detect the source media platform of a given digital media. In this paper we
propose an automated approach by means of a digital tool that we created on
purpose. The tool is capable of automatically uploading an entire image dataset
to the desired digital platform and then downloading all the uploaded pictures,
thus shortening the overall time required to output the final dataset to be
analyzed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09241">Chain of Images for Intuitively Reasoning. (arXiv:2311.09241v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanxu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haotong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiding Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Muhan Zhang</a></p>
<p>The human brain is naturally equipped to comprehend and interpret visual
information rapidly. When confronted with complex problems or concepts, we use
flowcharts, sketches, and diagrams to aid our thought process. Leveraging this
inherent ability can significantly enhance logical reasoning. However, current
Large Language Models (LLMs) do not utilize such visual intuition to help their
thinking. Even the most advanced version language models (e.g., GPT-4V and
LLaVA) merely align images into textual space, which means their reasoning
processes remain purely verbal. To mitigate such limitations, we present a
Chain of Images (CoI) approach, which can convert complex language reasoning
problems to simple pattern recognition by generating a series of images as
intermediate representations. Furthermore, we have developed a CoI evaluation
dataset encompassing 15 distinct domains where images can intuitively aid
problem-solving. Based on this dataset, we aim to construct a benchmark to
assess the capability of future multimodal large-scale models to leverage
images for reasoning. In supporting our CoI reasoning, we introduce a symbolic
multimodal large language model (SyMLLM) that generates images strictly based
on language instructions and accepts both text and image as input. Experiments
on Geometry, Chess and Common Sense tasks sourced from the CoI evaluation
dataset show that CoI improves performance significantly over the pure-language
Chain of Thoughts (CoT) baselines. The code is available at
https://github.com/GraphPKU/CoI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09245">Affine Invariance in Continuous-Domain Convolutional Neural Networks. (arXiv:2311.09245v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mohaddes_A/0/1/0/all/0/1">Ali Mohaddes</a>, <a href="http://arxiv.org/find/cs/1/au:+Lederer_J/0/1/0/all/0/1">Johannes Lederer</a></p>
<p>The notion of group invariance helps neural networks in recognizing patterns
and features under geometric transformations. Indeed, it has been shown that
group invariance can largely improve deep learning performances in practice,
where such transformations are very common. This research studies affine
invariance on continuous-domain convolutional neural networks. Despite other
research considering isometric invariance or similarity invariance, we focus on
the full structure of affine transforms generated by the generalized linear
group $\mathrm{GL}_2(\mathbb{R})$. We introduce a new criterion to assess the
similarity of two input signals under affine transformations. Then, unlike
conventional methods that involve solving complex optimization problems on the
Lie group $G_2$, we analyze the convolution of lifted signals and compute the
corresponding integration over $G_2$. In sum, our research could eventually
extend the scope of geometrical transformations that practical deep-learning
pipelines can handle.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09247">Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks. (arXiv:2311.09247v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1">Melanie Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Palmarini_A/0/1/0/all/0/1">Alessandro B. Palmarini</a>, <a href="http://arxiv.org/find/cs/1/au:+Moskvichev_A/0/1/0/all/0/1">Arseny Moskvichev</a></p>
<p>We explore the abstract reasoning abilities of text-only and multimodal
versions of GPT-4, using the ConceptARC benchmark [10], which is designed to
evaluate robust understanding and reasoning with core-knowledge concepts. We
extend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed,
one-shot prompting (rather than simple, zero-shot prompts) with text versions
of ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4,
on zero- and one-shot prompts using image versions of the simplest tasks. Our
experimental results support the conclusion that neither version of GPT-4 has
developed robust abstraction abilities at humanlike levels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09251">A Simple and Powerful Framework for Stable Dynamic Network Embedding. (arXiv:2311.09251v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Davis_E/0/1/0/all/0/1">Ed Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallagher_I/0/1/0/all/0/1">Ian Gallagher</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawson_D/0/1/0/all/0/1">Daniel John Lawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_Delanchy_P/0/1/0/all/0/1">Patrick Rubin-Delanchy</a></p>
<p>In this paper, we address the problem of dynamic network embedding, that is,
representing the nodes of a dynamic network as evolving vectors within a
low-dimensional space. While the field of static network embedding is wide and
established, the field of dynamic network embedding is comparatively in its
infancy. We propose that a wide class of established static network embedding
methods can be used to produce interpretable and powerful dynamic network
embeddings when they are applied to the dilated unfolded adjacency matrix. We
provide a theoretical guarantee that, regardless of embedding dimension, these
unfolded methods will produce stable embeddings, meaning that nodes with
identical latent behaviour will be exchangeable, regardless of their position
in time or space. We additionally define a hypothesis testing framework which
can be used to evaluate the quality of a dynamic network embedding by testing
for planted structure in simulated networks. Using this, we demonstrate that,
even in trivial cases, unstable methods are often either conservative or encode
incorrect structure. In contrast, we demonstrate that our suite of stable
unfolded methods are not only more interpretable but also more powerful in
comparison to their unstable counterparts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09253">The Perception-Robustness Tradeoff in Deterministic Image Restoration. (arXiv:2311.09253v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ohayon_G/0/1/0/all/0/1">Guy Ohayon</a>, <a href="http://arxiv.org/find/eess/1/au:+Michaeli_T/0/1/0/all/0/1">Tomer Michaeli</a>, <a href="http://arxiv.org/find/eess/1/au:+Elad_M/0/1/0/all/0/1">Michael Elad</a></p>
<p>We study the behavior of deterministic methods for solving inverse problems
in imaging. These methods are commonly designed to achieve two goals: (1)
attaining high perceptual quality, and (2) generating reconstructions that are
consistent with the measurements. We provide a rigorous proof that the better a
predictor satisfies these two requirements, the larger its Lipschitz constant
must be, regardless of the nature of the degradation involved. In particular,
to approach perfect perceptual quality and perfect consistency, the Lipschitz
constant of the model must grow to infinity. This implies that such methods are
necessarily more susceptible to adversarial attacks. We demonstrate our theory
on single image super-resolution algorithms, addressing both noisy and
noiseless settings. We also show how this undesired behavior can be leveraged
to explore the posterior distribution, thereby allowing the deterministic model
to imitate stochastic methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09261">Emerging Drug Interaction Prediction Enabled by Flow-based Graph Neural Network with Biomedical Network. (arXiv:2311.09261v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_Y/0/1/0/all/0/1">Yongqi Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yao_Q/0/1/0/all/0/1">Quanming Yao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yue_L/0/1/0/all/0/1">Ling Yue</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_X/0/1/0/all/0/1">Xian Wu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_Z/0/1/0/all/0/1">Ziheng Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lin_Z/0/1/0/all/0/1">Zhenxi Lin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a></p>
<p>Accurately predicting drug-drug interactions (DDI) for emerging drugs, which
offer possibilities for treating and alleviating diseases, with computational
methods can improve patient care and contribute to efficient drug development.
However, many existing computational methods require large amounts of known DDI
information, which is scarce for emerging drugs. In this paper, we propose
EmerGNN, a graph neural network (GNN) that can effectively predict interactions
for emerging drugs by leveraging the rich information in biomedical networks.
EmerGNN learns pairwise representations of drugs by extracting the paths
between drug pairs, propagating information from one drug to the other, and
incorporating the relevant biomedical concepts on the paths. The different
edges on the biomedical network are weighted to indicate the relevance for the
target DDI prediction. Overall, EmerGNN has higher accuracy than existing
approaches in predicting interactions for emerging drugs and can identify the
most relevant information on the biomedical network.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09263">Auto-ICL: In-Context Learning without Human Supervision. (arXiv:2311.09263v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinghan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shuming Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a></p>
<p>In the era of Large Language Models (LLMs), human-computer interaction has
evolved towards natural language, offering unprecedented flexibility. Despite
this, LLMs are heavily reliant on well-structured prompts to function
efficiently within the realm of In-Context Learning. Vanilla In-Context
Learning relies on human-provided contexts, such as labeled examples, explicit
instructions, or other guiding mechanisms that shape the model's outputs. To
address this challenge, our study presents a universal framework named
Automatic In-Context Learning. Upon receiving a user's request, we ask the
model to independently generate examples, including labels, instructions, or
reasoning pathways. The model then leverages this self-produced context to
tackle the given problem. Our approach is universally adaptable and can be
implemented in any setting where vanilla In-Context Learning is applicable. We
demonstrate that our method yields strong performance across a range of tasks,
standing up well when compared to existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09264">Cross-domain feature disentanglement for interpretable modeling of tumor microenvironment impact on drug response. (arXiv:2311.09264v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhai_J/0/1/0/all/0/1">Jia Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a></p>
<p>High-throughput screening technology has facilitated the generation of
large-scale drug responses across hundreds of cancer cell lines. However, there
exists significant discrepancy between in vitro cell lines and actual tumors in
vivo in terms of their response to drug treatments, because of tumors comprise
of complex cellular compositions and histopathology structure, known as tumor
microenvironment (TME), which greatly influences the drug cytotoxicity against
tumor cells. To date, no study has focused on modeling the impact of the TME on
clinical drug response. This paper proposed a domain adaptation network for
feature disentanglement to separate representations of cancer cells and TME of
a tumor in patients. Two denoising autoencoders were separately used to extract
features from cell lines (source domain) and tumors (target domain) for partial
domain alignment and feature decoupling. The specific encoder was enforced to
extract information only about TME. Moreover, to ensure generalizability to
novel drugs, we applied a graph attention network to learn the latent
representation of drugs, allowing us to linearly model the drug perturbation on
cellular state in latent space. We calibrated our model on a benchmark dataset
and demonstrated its superior performance in predicting clinical drug response
and dissecting the influence of the TME on drug efficacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09266">Adversarially Robust Spiking Neural Networks Through Conversion. (arXiv:2311.09266v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ozdenizci_O/0/1/0/all/0/1">Ozan &#xd6;zdenizci</a>, <a href="http://arxiv.org/find/cs/1/au:+Legenstein_R/0/1/0/all/0/1">Robert Legenstein</a></p>
<p>Spiking neural networks (SNNs) provide an energy-efficient alternative to a
variety of artificial neural network (ANN) based AI applications. As the
progress in neuromorphic computing with SNNs expands their use in applications,
the problem of adversarial robustness of SNNs becomes more pronounced. To the
contrary of the widely explored end-to-end adversarial training based
solutions, we address the limited progress in scalable robust SNN training
methods by proposing an adversarially robust ANN-to-SNN conversion algorithm.
Our method provides an efficient approach to embrace various computationally
demanding robust learning objectives that have been proposed for ANNs. During a
post-conversion robust finetuning phase, our method adversarially optimizes
both layer-wise firing thresholds and synaptic connectivity weights of the SNN
to maintain transferred robustness gains from the pre-trained ANN. We perform
experimental evaluations in numerous adaptive adversarial settings that account
for the spike-based operation dynamics of SNNs, and show that our approach
yields a scalable state-of-the-art solution for adversarially robust deep SNNs
with low-latency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09267">Neuroscience inspired scientific machine learning (Part-1): Variable spiking neuron for regression. (arXiv:2311.09267v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Shailesh Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Souvik Chakraborty</a></p>
<p>Redundant information transfer in a neural network can increase the
complexity of the deep learning model, thus increasing its power consumption.
We introduce in this paper a novel spiking neuron, termed Variable Spiking
Neuron (VSN), which can reduce the redundant firing using lessons from
biological neuron inspired Leaky Integrate and Fire Spiking Neurons (LIF-SN).
The proposed VSN blends LIF-SN and artificial neurons. It garners the advantage
of intermittent firing from the LIF-SN and utilizes the advantage of continuous
activation from the artificial neuron. This property of the proposed VSN makes
it suitable for regression tasks, which is a weak point for the vanilla spiking
neurons, all while keeping the energy budget low. The proposed VSN is tested
against both classification and regression tasks. The results produced advocate
favorably towards the efficacy of the proposed spiking neuron, particularly for
regression tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09270">FedCode: Communication-Efficient Federated Learning via Transferring Codebooks. (arXiv:2311.09270v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khalilian_S/0/1/0/all/0/1">Saeed Khalilian</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsouvalas_V/0/1/0/all/0/1">Vasileios Tsouvalas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozcelebi_T/0/1/0/all/0/1">Tanir Ozcelebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Meratnia_N/0/1/0/all/0/1">Nirvana Meratnia</a></p>
<p>Federated Learning (FL) is a distributed machine learning paradigm that
enables learning models from decentralized local data. While FL offers
appealing properties for clients' data privacy, it imposes high communication
burdens for exchanging model weights between a server and the clients. Existing
approaches rely on model compression techniques, such as pruning and weight
clustering to tackle this. However, transmitting the entire set of weight
updates at each federated round, even in a compressed format, limits the
potential for a substantial reduction in communication volume. We propose
FedCode where clients transmit only codebooks, i.e., the cluster centers of
updated model weight values. To ensure a smooth learning curve and proper
calibration of clusters between the server and the clients, FedCode
periodically transfers model weights after multiple rounds of solely
communicating codebooks. This results in a significant reduction in
communication volume between clients and the server in both directions, without
imposing significant computational overhead on the clients or leading to major
performance degradation of the models. We evaluate the effectiveness of FedCode
using various publicly available datasets with ResNet-20 and MobileNet backbone
model architectures. Our evaluations demonstrate a 12.2-fold data transmission
reduction on average while maintaining a comparable model performance with an
average accuracy loss of 1.3% compared to FedAvg. Further validation of FedCode
performance under non-IID data distributions showcased an average accuracy loss
of 2.0% compared to FedAvg while achieving approximately a 12.7-fold data
transmission reduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09272">Linear time Evidence Accumulation Clustering with KMeans. (arXiv:2311.09272v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Candel_G/0/1/0/all/0/1">Ga&#xeb;lle Candel</a></p>
<p>Among ensemble clustering methods, Evidence Accumulation Clustering is one of
the simplest technics. In this approach, a co-association (CA) matrix
representing the co-clustering frequency is built and then clustered to extract
consensus clusters. Compared to other approaches, this one is simple as there
is no need to find matches between clusters obtained from two different
partitionings. Nevertheless, this method suffers from computational issues, as
it requires to compute and store a matrix of size n x n, where n is the number
of items. Due to the quadratic cost, this approach is reserved for small
datasets. This work describes a trick which mimic the behavior of average
linkage clustering. We found a way of computing efficiently the density of a
partitioning, reducing the cost from a quadratic to linear complexity.
Additionally, we proved that the k-means maximizes naturally the density. We
performed experiments on several benchmark datasets where we compared the
k-means and the bisecting version to other state-of-the-art consensus
algorithms. The k-means results are comparable to the best state of the art in
terms of NMI while keeping the computational cost low. Additionally, the
k-means led to the best results in terms of density. These results provide
evidence that consensus clustering can be solved with simple algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09274">Constructing interpretable principal curve using Neural ODEs. (arXiv:2311.09274v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangzheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Bingxian Xu</a></p>
<p>The study of high dimensional data sets often rely on their low dimensional
projections that preserve the local geometry of the original space. While
numerous methods have been developed to summarize this space as variations of
tree-like structures, they are usually non-parametric and "static" in nature.
As data may come from systems that are dynamical such as a differentiating
cell, a static, non-parametric characterization of the space may not be the
most appropriate. Here, we developed a framework, the principal flow, that is
capable of characterizing the space in a dynamical manner. The principal flow,
defined using neural ODEs, directs motion of a particle through the space,
where the trajectory of the particle resembles the principal curve of the
dataset. We illustrate that our framework can be used to characterize shapes of
various complexities, and is flexible to incorporate summaries of relaxation
dynamics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09275">Improved Sparse Ising Optimization. (arXiv:2311.09275v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zick_K/0/1/0/all/0/1">Kenneth M. Zick</a></p>
<p>Sparse Ising problems can be found in application areas such as logistics,
condensed matter physics and training of deep Boltzmann networks, but can be
very difficult to tackle with high efficiency and accuracy. This report
presents new data demonstrating significantly higher performance on some
longstanding benchmark problems with up to 20,000 variables. The data come from
a new heuristic algorithm tested on the large sparse instances from the Gset
benchmark suite. Relative to leading reported combinations of speed and
accuracy (e.g., from Toshiba's Simulated Bifurcation Machine and Breakout Local
Search), a proof-of-concept implementation reached targets 2-4 orders of
magnitude faster. For two instances (G72 and G77) the new algorithm discovered
a better solution than all previously reported values. Solution bitstrings
confirming these two best solutions are provided. The data suggest exciting
possibilities for pushing the sparse Ising performance frontier to potentially
strengthen algorithm portfolios, AI toolkits and decision-making systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09276">Leveraging Citizen Science for Flood Extent Detection using Machine Learning Benchmark Dataset. (arXiv:2311.09276v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramasubramanian_M/0/1/0/all/0/1">Muthukumaran Ramasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurung_I/0/1/0/all/0/1">Iksha Gurung</a>, <a href="http://arxiv.org/find/cs/1/au:+Gahlot_S/0/1/0/all/0/1">Shubhankar Gahlot</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansch_R/0/1/0/all/0/1">Ronny H&#xe4;nsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Molthan_A/0/1/0/all/0/1">Andrew L. Molthan</a>, <a href="http://arxiv.org/find/cs/1/au:+Maskey_M/0/1/0/all/0/1">Manil Maskey</a></p>
<p>Accurate detection of inundated water extents during flooding events is
crucial in emergency response decisions and aids in recovery efforts. Satellite
Remote Sensing data provides a global framework for detecting flooding extents.
Specifically, Sentinel-1 C-Band Synthetic Aperture Radar (SAR) imagery has
proven to be useful in detecting water bodies due to low backscatter of water
features in both co-polarized and cross-polarized SAR imagery. However,
increased backscatter can be observed in certain flooded regions such as
presence of infrastructure and trees - rendering simple methods such as pixel
intensity thresholding and time-series differencing inadequate. Machine
Learning techniques has been leveraged to precisely capture flood extents in
flooded areas with bumps in backscatter but needs high amounts of labelled data
to work desirably. Hence, we created a labeled known water body extent and
flooded area extents during known flooding events covering about 36,000 sq.
kilometers of regions within mainland U.S and Bangladesh. Further, We also
leveraged citizen science by open-sourcing the dataset and hosting an open
competition based on the dataset to rapidly prototype flood extent detection
using community generated models. In this paper we present the information
about the dataset, the data processing pipeline, a baseline model and the
details about the competition, along with discussion on winning approaches. We
believe the dataset adds to already existing datasets based on Sentinel-1C SAR
data and leads to more robust modeling of flood extents. We also hope the
results from the competition pushes the research in flood extent detection
further.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09308">Divergences between Language Models and Human Brains. (arXiv:2311.09308v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuchen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1">Emmy Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehbe_L/0/1/0/all/0/1">Leila Wehbe</a></p>
<p>Do machines and humans process language in similar ways? A recent line of
research has hinted in the affirmative, demonstrating that human brain signals
can be effectively predicted using the internal representations of language
models (LMs). This is thought to reflect shared computational principles
between LMs and human language processing. However, there are also clear
differences in how LMs and humans acquire and use language, even if the final
task they are performing is the same. Despite this, there is little work
exploring systematic differences between human and machine language processing
using brain data. To address this question, we examine the differences between
LM representations and the human brain's responses to language, specifically by
examining a dataset of Magnetoencephalography (MEG) responses to a written
narrative. In doing so we identify three phenomena that, in prior work, LMs
have been found to not capture well: emotional understanding, figurative
language processing, and physical commonsense. By fine-tuning LMs on datasets
related to these phenomena, we observe that fine-tuned LMs show improved
alignment with human brain responses across these tasks. Our study implies that
the observed divergences between LMs and human brains may stem from LMs'
inadequate representation of these specific types of knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09312">H-Packer: Holographic Rotationally Equivariant Convolutional Neural Network for Protein Side-Chain Packing. (arXiv:2311.09312v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Visani_G/0/1/0/all/0/1">Gian Marco Visani</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Galvin_W/0/1/0/all/0/1">William Galvin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pun_M/0/1/0/all/0/1">Michael Neal Pun</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Nourmohammad_A/0/1/0/all/0/1">Armita Nourmohammad</a></p>
<p>Accurately modeling protein 3D structure is essential for the design of
functional proteins. An important sub-task of structure modeling is protein
side-chain packing: predicting the conformation of side-chains (rotamers) given
the protein's backbone structure and amino-acid sequence. Conventional
approaches for this task rely on expensive sampling procedures over
hand-crafted energy functions and rotamer libraries. Recently, several deep
learning methods have been developed to tackle the problem in a data-driven
way, albeit with vastly different formulations (from image-to-image translation
to directly predicting atomic coordinates). Here, we frame the problem as a
joint regression over the side-chains' true degrees of freedom: the dihedral
$\chi$ angles. We carefully study possible objective functions for this task,
while accounting for the underlying symmetries of the task. We propose
Holographic Packer (H-Packer), a novel two-stage algorithm for side-chain
packing built on top of two light-weight rotationally equivariant neural
networks. We evaluate our method on CASP13 and CASP14 targets. H-Packer is
computationally efficient and shows favorable performance against conventional
physics-based algorithms and is competitive against alternative deep learning
solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09329">A Comparative Analysis of Machine Learning Models for Early Detection of Hospital-Acquired Infections. (arXiv:2311.09329v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Harvey_E/0/1/0/all/0/1">Ethan Harvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Junzi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_E/0/1/0/all/0/1">Erina Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Samadani_A/0/1/0/all/0/1">Ali Samadani</a></p>
<p>As more and more infection-specific machine learning models are developed and
planned for clinical deployment, simultaneously running predictions from
different models may provide overlapping or even conflicting information. It is
important to understand the concordance and behavior of parallel models in
deployment. In this study, we focus on two models for the early detection of
hospital-acquired infections (HAIs): 1) the Infection Risk Index (IRI) and 2)
the Ventilator-Associated Pneumonia (VAP) prediction model. The IRI model was
built to predict all HAIs, whereas the VAP model identifies patients at risk of
developing ventilator-associated pneumonia. These models could make important
improvements in patient outcomes and hospital management of infections through
early detection of infections and in turn, enable early interventions. The two
models vary in terms of infection label definition, cohort selection, and
prediction schema. In this work, we present a comparative analysis between the
two models to characterize concordances and confusions in predicting HAIs by
these models. The learnings from this study will provide important findings for
how to deploy multiple concurrent disease-specific models in the future.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09333">Strategic Data Augmentation with CTGAN for Smart Manufacturing: Enhancing Machine Learning Predictions of Paper Breaks in Pulp-and-Paper Production. (arXiv:2311.09333v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khosravi_H/0/1/0/all/0/1">Hamed Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadpour_S/0/1/0/all/0/1">Sarah Farhadpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Grandhi_M/0/1/0/all/0/1">Manikanta Grandhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Raihan_A/0/1/0/all/0/1">Ahmed Shoyeb Raihan</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srinjoy Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_I/0/1/0/all/0/1">Imtiaz Ahmed</a></p>
<p>A significant challenge for predictive maintenance in the pulp-and-paper
industry is the infrequency of paper breaks during the production process. In
this article, operational data is analyzed from a paper manufacturing machine
in which paper breaks are relatively rare but have a high economic impact.
Utilizing a dataset comprising 18,398 instances derived from a quality
assurance protocol, we address the scarcity of break events (124 cases) that
pose a challenge for machine learning predictive models. With the help of
Conditional Generative Adversarial Networks (CTGAN) and Synthetic Minority
Oversampling Technique (SMOTE), we implement a novel data augmentation
framework. This method ensures that the synthetic data mirrors the distribution
of the real operational data but also seeks to enhance the performance metrics
of predictive modeling. Before and after the data augmentation, we evaluate
three different machine learning algorithms-Decision Trees (DT), Random Forest
(RF), and Logistic Regression (LR). Utilizing the CTGAN-enhanced dataset, our
study achieved significant improvements in predictive maintenance performance
metrics. The efficacy of CTGAN in addressing data scarcity was evident, with
the models' detection of machine breaks (Class 1) improving by over 30% for
Decision Trees, 20% for Random Forest, and nearly 90% for Logistic Regression.
With this methodological advancement, this study contributes to industrial
quality control and maintenance scheduling by addressing rare event prediction
in manufacturing processes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09338">Challenges for Predictive Modeling with Neural Network Techniques using Error-Prone Dietary Intake Data. (arXiv:2311.09338v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Spicker_D/0/1/0/all/0/1">Dylan Spicker</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazemi_A/0/1/0/all/0/1">Amir Nazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutchinson_J/0/1/0/all/0/1">Joy Hutchinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Fieguth_P/0/1/0/all/0/1">Paul Fieguth</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirkpatrick_S/0/1/0/all/0/1">Sharon I. Kirkpatrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_M/0/1/0/all/0/1">Michael Wallace</a>, <a href="http://arxiv.org/find/cs/1/au:+Dodd_K/0/1/0/all/0/1">Kevin W. Dodd</a></p>
<p>Dietary intake data are routinely drawn upon to explore diet-health
relationships. However, these data are often subject to measurement error,
distorting the true relationships. Beyond measurement error, there are likely
complex synergistic and sometimes antagonistic interactions between different
dietary components, complicating the relationships between diet and health
outcomes. Flexible models are required to capture the nuance that these complex
interactions introduce. This complexity makes research on diet-health
relationships an appealing candidate for the application of machine learning
techniques, and in particular, neural networks. Neural networks are
computational models that are able to capture highly complex, nonlinear
relationships so long as sufficient data are available. While these models have
been applied in many domains, the impacts of measurement error on the
performance of predictive modeling has not been systematically investigated.
However, dietary intake data are typically collected using self-report methods
and are prone to large amounts of measurement error. In this work, we
demonstrate the ways in which measurement error erodes the performance of
neural networks, and illustrate the care that is required for leveraging these
models in the presence of error. We demonstrate the role that sample size and
replicate measurements play on model performance, indicate a motivation for the
investigation of transformations to additivity, and illustrate the caution
required to prevent model overfitting. While the past performance of neural
networks across various domains make them an attractive candidate for examining
diet-health relationships, our work demonstrates that substantial care and
further methodological development are both required to observe increased
predictive performance when applying these techniques, compared to more
traditional statistical procedures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09346">Nothing Stands Still: A Spatiotemporal Benchmark on 3D Point Cloud Registration Under Large Geometric and Temporal Change. (arXiv:2311.09346v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1">Yan Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>, <a href="http://arxiv.org/find/cs/1/au:+Armeni_I/0/1/0/all/0/1">Iro Armeni</a></p>
<p>Building 3D geometric maps of man-made spaces is a well-established and
active field that is fundamental to computer vision and robotics. However,
considering the evolving nature of built environments, it is essential to
question the capabilities of current mapping efforts in handling temporal
changes. In addition, spatiotemporal mapping holds significant potential for
achieving sustainability and circularity goals. Existing mapping approaches
focus on small changes, such as object relocation or self-driving car
operation; in all cases where the main structure of the scene remains fixed.
Consequently, these approaches fail to address more radical changes in the
structure of the built environment, such as geometry and topology. To this end,
we introduce the Nothing Stands Still (NSS) benchmark, which focuses on the
spatiotemporal registration of 3D scenes undergoing large spatial and temporal
change, ultimately creating one coherent spatiotemporal map. Specifically, the
benchmark involves registering two or more partial 3D point clouds (fragments)
from the same scene but captured from different spatiotemporal views. In
addition to the standard pairwise registration, we assess the multi-way
registration of multiple fragments that belong to any temporal stage. As part
of NSS, we introduce a dataset of 3D point clouds recurrently captured in
large-scale building indoor environments that are under construction or
renovation. The NSS benchmark presents three scenarios of increasing
difficulty, to quantify the generalization ability of point cloud registration
methods over space (within one building and across buildings) and time. We
conduct extensive evaluations of state-of-the-art methods on NSS. The results
demonstrate the necessity for novel methods specifically designed to handle
large spatiotemporal changes. The homepage of our benchmark is at
<a href="http://nothing-stands-still.com.">this http URL</a>
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09349">Generative AI-Based Probabilistic Constellation Shaping With Diffusion Models. (arXiv:2311.09349v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Letafati_M/0/1/0/all/0/1">Mehdi Letafati</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Samad Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Latva_aho_M/0/1/0/all/0/1">Matti Latva-aho</a></p>
<p>Diffusion models are at the vanguard of generative AI research with renowned
solutions such as ImageGen by Google Brain and DALL.E 3 by OpenAI.
Nevertheless, the potential merits of diffusion models for communication
engineering applications are not fully understood yet. In this paper, we aim to
unleash the power of generative AI for PHY design of constellation symbols in
communication systems. Although the geometry of constellations is predetermined
according to networking standards, e.g., quadrature amplitude modulation (QAM),
probabilistic shaping can design the probability of occurrence (generation) of
constellation symbols. This can help improve the information rate and decoding
performance of communication systems. We exploit the ``denoise-and-generate''
characteristics of denoising diffusion probabilistic models (DDPM) for
probabilistic constellation shaping. The key idea is to learn generating
constellation symbols out of noise, ``mimicking'' the way the receiver performs
symbol reconstruction. This way, we make the constellation symbols sent by the
transmitter, and what is inferred (reconstructed) at the receiver become as
similar as possible, resulting in as few mismatches as possible. Our results
show that the generative AI-based scheme outperforms deep neural network
(DNN)-based benchmark and uniform shaping, while providing network resilience
as well as robust out-of-distribution performance under low-SNR regimes and
non-Gaussian assumptions. Numerical evaluations highlight 30% improvement in
terms of cosine similarity and a threefold improvement in terms of mutual
information compared to DNN-based approach for 64-QAM geometry.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09354">Nondestructive, quantitative viability analysis of 3D tissue cultures using machine learning image segmentation. (arXiv:2311.09354v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Trettner_K/0/1/0/all/0/1">Kylie J. Trettner</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hsieh_J/0/1/0/all/0/1">Jeremy Hsieh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xiao_W/0/1/0/all/0/1">Weikun Xiao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lee_J/0/1/0/all/0/1">Jerry S.H. Lee</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Armani_A/0/1/0/all/0/1">Andrea M. Armani</a></p>
<p>Ascertaining the collective viability of cells in different cell culture
conditions has typically relied on averaging colorimetric indicators and is
often reported out in simple binary readouts. Recent research has combined
viability assessment techniques with image-based deep-learning models to
automate the characterization of cellular properties. However, further
development of viability measurements to assess the continuity of possible
cellular states and responses to perturbation across cell culture conditions is
needed. In this work, we demonstrate an image processing algorithm for
quantifying cellular viability in 3D cultures without the need for assay-based
indicators. We show that our algorithm performs similarly to a pair of human
experts in whole-well images over a range of days and culture matrix
compositions. To demonstrate potential utility, we perform a longitudinal study
investigating the impact of a known therapeutic on pancreatic cancer spheroids.
Using images taken with a high content imaging system, the algorithm
successfully tracks viability at the individual spheroid and whole-well level.
The method we propose reduces analysis time by 97% in comparison to the
experts. Because the method is independent of the microscope or imaging system
used, this approach lays the foundation for accelerating progress in and for
improving the robustness and reproducibility of 3D culture analysis across
biological and clinical research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09355">Privacy Threats in Stable Diffusion Models. (arXiv:2311.09355v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cilloni_T/0/1/0/all/0/1">Thomas Cilloni</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleming_C/0/1/0/all/0/1">Charles Fleming</a>, <a href="http://arxiv.org/find/cs/1/au:+Walter_C/0/1/0/all/0/1">Charles Walter</a></p>
<p>This paper introduces a novel approach to membership inference attacks (MIA)
targeting stable diffusion computer vision models, specifically focusing on the
highly sophisticated Stable Diffusion V2 by StabilityAI. MIAs aim to extract
sensitive information about a model's training data, posing significant privacy
concerns. Despite its advancements in image synthesis, our research reveals
privacy vulnerabilities in the stable diffusion models' outputs. Exploiting
this information, we devise a black-box MIA that only needs to query the victim
model repeatedly. Our methodology involves observing the output of a stable
diffusion model at different generative epochs and training a classification
model to distinguish when a series of intermediates originated from a training
sample or not. We propose numerous ways to measure the membership features and
discuss what works best. The attack's efficacy is assessed using the ROC AUC
method, demonstrating a 60\% success rate in inferring membership information.
This paper contributes to the growing body of research on privacy and security
in machine learning, highlighting the need for robust defenses against MIAs.
Our findings prompt a reevaluation of the privacy implications of stable
diffusion models, urging practitioners and developers to implement enhanced
security measures to safeguard against such attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09369">Time-dependent Probabilistic Generative Models for Disease Progression. (arXiv:2311.09369v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zaballa_O/0/1/0/all/0/1">Onintze Zaballa</a>, <a href="http://arxiv.org/find/stat/1/au:+Perez_A/0/1/0/all/0/1">Aritz P&#xe9;rez</a>, <a href="http://arxiv.org/find/stat/1/au:+Gomez_Inhiesto_E/0/1/0/all/0/1">Elisa G&#xf3;mez-Inhiesto</a>, <a href="http://arxiv.org/find/stat/1/au:+Acaiturri_Ayesta_T/0/1/0/all/0/1">Teresa Acaiturri-Ayesta</a>, <a href="http://arxiv.org/find/stat/1/au:+Lozano_J/0/1/0/all/0/1">Jose A. Lozano</a></p>
<p>Electronic health records contain valuable information for monitoring
patients' health trajectories over time. Disease progression models have been
developed to understand the underlying patterns and dynamics of diseases using
these data as sequences. However, analyzing temporal data from EHRs is
challenging due to the variability and irregularities present in medical
records. We propose a Markovian generative model of treatments developed to (i)
model the irregular time intervals between medical events; (ii) classify
treatments into subtypes based on the patient sequence of medical events and
the time intervals between them; and (iii) segment treatments into subsequences
of disease progression patterns. We assume that sequences have an associated
structure of latent variables: a latent class representing the different
subtypes of treatments; and a set of latent stages indicating the phase of
progression of the treatments. We use the Expectation-Maximization algorithm to
learn the model, which is efficiently solved with a dynamic programming-based
method. Various parametric models have been employed to model the time
intervals between medical events during the learning process, including the
geometric, exponential, and Weibull distributions. The results demonstrate the
effectiveness of our model in recovering the underlying model from data and
accurately modeling the irregular time intervals between medical actions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09383">Long-form Question Answering: An Iterative Planning-Retrieval-Generation Approach. (arXiv:2311.09383v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akash_P/0/1/0/all/0/1">Pritom Saha Akash</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1">Kashob Kumar Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1">Lucian Popa</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kevin Chen-Chuan Chang</a></p>
<p>Long-form question answering (LFQA) poses a challenge as it involves
generating detailed answers in the form of paragraphs, which go beyond simple
yes/no responses or short factual answers. While existing QA models excel in
questions with concise answers, LFQA requires handling multiple topics and
their intricate relationships, demanding comprehensive explanations. Previous
attempts at LFQA focused on generating long-form answers by utilizing relevant
contexts from a corpus, relying solely on the question itself. However, they
overlooked the possibility that the question alone might not provide sufficient
information to identify the relevant contexts. Additionally, generating
detailed long-form answers often entails aggregating knowledge from diverse
sources. To address these limitations, we propose an LFQA model with iterative
Planning, Retrieval, and Generation. This iterative process continues until a
complete answer is generated for the given question. From an extensive
experiment on both an open domain and a technical domain QA dataset, we find
that our model outperforms the state-of-the-art models on various textual and
factual metrics for the LFQA task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09386">Beyond PCA: A Probabilistic Gram-Schmidt Approach to Feature Extraction. (arXiv:2311.09386v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yaghooti_B/0/1/0/all/0/1">Bahram Yaghooti</a>, <a href="http://arxiv.org/find/cs/1/au:+Raviv_N/0/1/0/all/0/1">Netanel Raviv</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinopoli_B/0/1/0/all/0/1">Bruno Sinopoli</a></p>
<p>Linear feature extraction at the presence of nonlinear dependencies among the
data is a fundamental challenge in unsupervised learning. We propose using a
Probabilistic Gram-Schmidt (PGS) type orthogonalization process in order to
detect and map out redundant dimensions. Specifically, by applying the PGS
process over any family of functions which presumably captures the nonlinear
dependencies in the data, we construct a series of covariance matrices that can
either be used to remove those dependencies from the principal components, or
to identify new large-variance directions. In the former case, we prove that
under certain assumptions the resulting algorithms detect and remove nonlinear
dependencies whenever those dependencies lie in the linear span of the chosen
function family. In the latter, we provide information-theoretic guarantees in
terms of entropy reduction. Both proposed methods extract linear features from
the data while removing nonlinear redundancies. We provide simulation results
on synthetic and real-world datasets which show improved performance over PCA
and state-of-the-art linear feature extraction algorithms, both in terms of
variance maximization of the extracted features, and in terms of improved
performance of classification algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09387">Banach-Tarski Embeddings and Transformers. (arXiv:2311.09387v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maher_J/0/1/0/all/0/1">Joshua Maher</a></p>
<p>We introduce a new construction of embeddings of arbitrary recursive data
structures into high dimensional vectors. These embeddings provide an
interpretable model for the latent state vectors of transformers. We
demonstrate that these embeddings can be decoded to the original data structure
when the embedding dimension is sufficiently large. This decoding algorithm has
a natural implementation as a transformer. We also show that these embedding
vectors can be manipulated directly to perform computations on the underlying
data without decoding. As an example we present an algorithm that constructs
the embedded parse tree of an embedded token sequence using only vector
operations in embedding space.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09389">Neural machine translation for automated feedback on children&#x27;s early-stage writing. (arXiv:2311.09389v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jensen_J/0/1/0/all/0/1">Jonas Vestergaard Jensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordahn_M/0/1/0/all/0/1">Mikkel Jordahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Andersen_M/0/1/0/all/0/1">Michael Riis Andersen</a></p>
<p>In this work, we address the problem of assessing and constructing feedback
for early-stage writing automatically using machine learning. Early-stage
writing is typically vastly different from conventional writing due to phonetic
spelling and lack of proper grammar, punctuation, spacing etc. Consequently,
early-stage writing is highly non-trivial to analyze using common linguistic
metrics. We propose to use sequence-to-sequence models for "translating"
early-stage writing by students into "conventional" writing, which allows the
translated text to be analyzed using linguistic metrics. Furthermore, we
propose a novel robust likelihood to mitigate the effect of noise in the
dataset. We investigate the proposed methods using a set of numerical
experiments and demonstrate that the conventional text can be predicted with
high accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09401">MoCo-Transfer: Investigating out-of-distribution contrastive learning for limited-data domains. (arXiv:2311.09401v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Helen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a></p>
<p>Medical imaging data is often siloed within hospitals, limiting the amount of
data available for specialized model development. With limited in-domain data,
one might hope to leverage larger datasets from related domains. In this paper,
we analyze the benefit of transferring self-supervised contrastive
representations from moment contrast (MoCo) pretraining on out-of-distribution
data to settings with limited data. We consider two X-ray datasets which image
different parts of the body, and compare transferring from each other to
transferring from ImageNet. We find that depending on quantity of labeled and
unlabeled data, contrastive pretraining on larger out-of-distribution datasets
can perform nearly as well or better than MoCo pretraining in-domain, and
pretraining on related domains leads to higher performance than if one were to
use the ImageNet pretrained weights. Finally, we provide a preliminary way of
quantifying similarity between datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09402">Synthetically Enhanced: Unveiling Synthetic Data&#x27;s Potential in Medical Imaging Research. (arXiv:2311.09402v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khosravi_B/0/1/0/all/0/1">Bardia Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Frank Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dapamede_T/0/1/0/all/0/1">Theo Dapamede</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouzrokh_P/0/1/0/all/0/1">Pouria Rouzrokh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gamble_C/0/1/0/all/0/1">Cooper U. Gamble</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1">Hari M. Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyles_C/0/1/0/all/0/1">Cody C. Wyles</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellergren_A/0/1/0/all/0/1">Andrew B. Sellergren</a>, <a href="http://arxiv.org/find/cs/1/au:+Purkayastha_S/0/1/0/all/0/1">Saptarshi Purkayastha</a>, <a href="http://arxiv.org/find/cs/1/au:+Erickson_B/0/1/0/all/0/1">Bradley J. Erickson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gichoya_J/0/1/0/all/0/1">Judy W. Gichoya</a></p>
<p>Chest X-rays (CXR) are the most common medical imaging study and are used to
diagnose multiple medical conditions. This study examines the impact of
synthetic data supplementation, using diffusion models, on the performance of
deep learning (DL) classifiers for CXR analysis. We employed three datasets:
CheXpert, MIMIC-CXR, and Emory Chest X-ray, training conditional denoising
diffusion probabilistic models (DDPMs) to generate synthetic frontal
radiographs. Our approach ensured that synthetic images mirrored the
demographic and pathological traits of the original data. Evaluating the
classifiers' performance on internal and external datasets revealed that
synthetic data supplementation enhances model accuracy, particularly in
detecting less prevalent pathologies. Furthermore, models trained on synthetic
data alone approached the performance of those trained on real data. This
suggests that synthetic data can potentially compensate for real data shortages
in training robust DL models. However, despite promising outcomes, the
superiority of real data persists.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09406">Alternatives to the Scaled Dot Product for Attention in the Transformer Neural Network Architecture. (arXiv:2311.09406v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bernhard_J/0/1/0/all/0/1">James Bernhard</a></p>
<p>The transformer neural network architecture uses a form of attention in which
the dot product of query and key is divided by the square root of the key
dimension before applying softmax. This scaling of the dot product is designed
to avoid the absolute value of the dot products becoming so large that applying
softmax leads to vanishing gradients. In this paper, we propose some
alternative scalings, including dividing the dot product instead by the sum of
the key lengths before applying softmax. We use simulated keys and queries to
show that in many situations this appears to be more effective at avoiding
regions where applying softmax leads to vanishing gradients.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09428">Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language Models. (arXiv:2311.09428v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yueqing Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Lu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Payani_A/0/1/0/all/0/1">Ali Payani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1">Kai Shu</a></p>
<p>This work investigates the potential of undermining both fairness and
detection performance in abusive language detection. In a dynamic and complex
digital world, it is crucial to investigate the vulnerabilities of these
detection models to adversarial fairness attacks to improve their fairness
robustness. We propose a simple yet effective framework FABLE that leverages
backdoor attacks as they allow targeted control over the fairness and detection
performance. FABLE explores three types of trigger designs (i.e., rare,
artificial, and natural triggers) and novel sampling strategies. Specifically,
the adversary can inject triggers into samples in the minority group with the
favored outcome (i.e., ``non-abusive'') and flip their labels to the unfavored
outcome, i.e., ``abusive''. Experiments on benchmark datasets demonstrate the
effectiveness of FABLE attacking fairness and utility in abusive language
detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09431">Striped Attention: Faster Ring Attention for Causal Transformers. (arXiv:2311.09431v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brandon_W/0/1/0/all/0/1">William Brandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Nrusimha_A/0/1/0/all/0/1">Aniruddha Nrusimha</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1">Kevin Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ankner_Z/0/1/0/all/0/1">Zachary Ankner</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1">Tian Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhiye Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragan_Kelley_J/0/1/0/all/0/1">Jonathan Ragan-Kelley</a></p>
<p>To help address the growing demand for ever-longer sequence lengths in
transformer models, Liu et al. recently proposed Ring Attention, an exact
attention algorithm capable of overcoming per-device memory bottle- necks by
distributing self-attention across multiple devices. In this paper, we study
the performance characteristics of Ring Attention in the important special case
of causal transformer models, and identify a key workload imbal- ance due to
triangular structure of causal attention computations. We propose a simple
extension to Ring Attention, which we call Striped Attention to fix this
imbalance. Instead of devices having contiguous subsequences, each device has a
subset of tokens distributed uniformly throughout the sequence, which we
demonstrate leads to more even workloads. In experiments running Striped
Attention on A100 GPUs and TPUv4s, we are able to achieve up to 1.45x
end-to-end throughput improvements over the original Ring Attention algorithm
on causal transformer training at a sequence length of 256k. Furthermore, on 16
TPUv4 chips, we were able to achieve 1.65x speedups at sequence lengths of
786k. We release the code for our experiments as open source
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09438">Labeled Interactive Topic Models. (arXiv:2311.09438v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seelman_K/0/1/0/all/0/1">Kyle Seelman</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mozhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1">Jordan Boyd-Graber</a></p>
<p>Topic models help users understand large document collections; however, topic
models do not always find the ``right'' topics. While classical probabilistic
and anchor-based topic models have interactive variants to guide models toward
better topics, such interactions are not available for neural topic models such
as the embedded topic model (\abr{etm}). We correct this lacuna by adding an
intuitive interaction to neural topic models: users can label a topic with a
word, and topics are updated so that the topic words are close to the label.
This allows a user to refine topics based on their information need. While,
interactivity is intuitive for \abr{etm}, we extend this framework to work with
other neural topic models as well. We develop an interactive interface which
allows users to interact and relabel topic models as they see fit. We evaluate
our method through a human study, where users can relabel topics to find
relevant documents. Using our method, user labeling improves document rank
scores, helping to find more relevant documents to a given query when compared
to no user labeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09441">Exploring the Privacy-Energy Consumption Tradeoff for Split Federated Learning. (arXiv:2311.09441v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joohyung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Seif_M/0/1/0/all/0/1">Mohamed Seif</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jungchan Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1">H. Vincent Poor</a></p>
<p>Split Federated Learning (SFL) has recently emerged as a promising
distributed learning technology, leveraging the strengths of both federated
learning and split learning. It emphasizes the advantages of rapid convergence
while addressing privacy concerns. As a result, this innovation has received
significant attention from both industry and academia. However, since the model
is split at a specific layer, known as a cut layer, into both client-side and
server-side models for the SFL, the choice of the cut layer in SFL can have a
substantial impact on the energy consumption of clients and their privacy, as
it influences the training burden and the output of the client-side models.
Moreover, the design challenge of determining the cut layer is highly
intricate, primarily due to the inherent heterogeneity in the computing and
networking capabilities of clients. In this article, we provide a comprehensive
overview of the SFL process and conduct a thorough analysis of energy
consumption and privacy. This analysis takes into account the influence of
various system parameters on the cut layer selection strategy. Additionally, we
provide an illustrative example of the cut layer selection, aiming to minimize
the risk of clients from reconstructing the raw data at the server while
sustaining energy consumption within the required energy budget, which involve
trade-offs. Finally, we address open challenges in this field including their
applications to 6G technology. These directions represent promising avenues for
future research and development.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09466">Soft Matching Distance: A metric on neural representations that captures single-neuron tuning. (arXiv:2311.09466v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1">Meenakshi Khosla</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Alex H. Williams</a></p>
<p>Common measures of neural representational (dis)similarity are designed to be
insensitive to rotations and reflections of the neural activation space.
Motivated by the premise that the tuning of individual units may be important,
there has been recent interest in developing stricter notions of
representational (dis)similarity that require neurons to be individually
matched across networks. When two networks have the same size (i.e. same number
of neurons), a distance metric can be formulated by optimizing over neuron
index permutations to maximize tuning curve alignment. However, it is not clear
how to generalize this metric to measure distances between networks with
different sizes. Here, we leverage a connection to optimal transport theory to
derive a natural generalization based on "soft" permutations. The resulting
metric is symmetric, satisfies the triangle inequality, and can be interpreted
as a Wasserstein distance between two empirical distributions. Further, our
proposed metric avoids counter-intuitive outcomes suffered by alternative
approaches, and captures complementary geometric insights into neural
representations that are entirely missed by rotation-invariant metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09480">Show Your Work with Confidence: Confidence Bands for Tuning Curves. (arXiv:2311.09480v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lourie_N/0/1/0/all/0/1">Nicholas Lourie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a></p>
<p>The choice of hyperparameters greatly impacts performance in natural language
processing. Often, it is hard to tell if a method is better than another or
just better tuned. Tuning curves fix this ambiguity by accounting for tuning
effort. Specifically, they plot validation performance as a function of the
number of hyperparameter choices tried so far. While several estimators exist
for these curves, it is common to use point estimates, which we show fail
silently and give contradictory results when given too little data.
</p>
<p>Beyond point estimates, confidence bands are necessary to rigorously
establish the relationship between different approaches. We present the first
method to construct valid confidence bands for tuning curves. The bands are
exact, simultaneous, and distribution-free, thus they provide a robust basis
for comparing methods.
</p>
<p>Empirical analysis shows that while bootstrap confidence bands, which serve
as a baseline, fail to approximate their target confidence, ours achieve it
exactly. We validate our design with ablations, analyze the effect of sample
size, and provide guidance on comparing models with our method. To promote
confident comparisons in future work, we release a library implementing the
method at https://github.com/nalourie/opda .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09483">Adaptive Interventions with User-Defined Goals for Health Behavior Change. (arXiv:2311.09483v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mandyam_A/0/1/0/all/0/1">Aishwarya Mandyam</a>, <a href="http://arxiv.org/find/cs/1/au:+Joerke_M/0/1/0/all/0/1">Matthew Joerke</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelhardt_B/0/1/0/all/0/1">Barbara E. Engelhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1">Emma Brunskill</a></p>
<p>Physical inactivity remains a major public health concern, having
associations with adverse health outcomes such as cardiovascular disease and
type-2 diabetes. Mobile health applications present a promising avenue for
low-cost, scalable physical activity promotion, yet often suffer from small
effect sizes and low adherence rates, particularly in comparison to human
coaching. Goal-setting is a critical component of health coaching that has been
underutilized in adaptive algorithms for mobile health interventions. This
paper introduces a modification to the Thompson sampling algorithm that places
emphasis on individualized goal-setting by optimizing personalized reward
functions. As a step towards supporting goal-setting, this paper offers a
balanced approach that can leverage shared structure while optimizing
individual preferences and goals. We prove that our modification incurs only a
constant penalty on the cumulative regret while preserving the sample
complexity benefits of data sharing. In a physical activity simulator, we
demonstrate that our algorithm achieves substantial improvements in cumulative
regret compared to baselines that do not share data or do not optimize for
individualized rewards.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09491">Spatial Bayesian Neural Networks. (arXiv:2311.09491v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zammit_Mangion_A/0/1/0/all/0/1">Andrew Zammit-Mangion</a>, <a href="http://arxiv.org/find/stat/1/au:+Kaminski_M/0/1/0/all/0/1">Michael D. Kaminski</a>, <a href="http://arxiv.org/find/stat/1/au:+Tran_B/0/1/0/all/0/1">Ba-Hien Tran</a>, <a href="http://arxiv.org/find/stat/1/au:+Filippone_M/0/1/0/all/0/1">Maurizio Filippone</a>, <a href="http://arxiv.org/find/stat/1/au:+Cressie_N/0/1/0/all/0/1">Noel Cressie</a></p>
<p>Statistical models for spatial processes play a central role in statistical
analyses of spatial data. Yet, it is the simple, interpretable, and well
understood models that are routinely employed even though, as is revealed
through prior and posterior predictive checks, these can poorly characterise
the spatial heterogeneity in the underlying process of interest. Here, we
propose a new, flexible class of spatial-process models, which we refer to as
spatial Bayesian neural networks (SBNNs). An SBNN leverages the
representational capacity of a Bayesian neural network; it is tailored to a
spatial setting by incorporating a spatial "embedding layer" into the network
and, possibly, spatially-varying network parameters. An SBNN is calibrated by
matching its finite-dimensional distribution at locations on a fine gridding of
space to that of a target process of interest. That process could be easy to
simulate from or we have many realisations from it. We propose several variants
of SBNNs, most of which are able to match the finite-dimensional distribution
of the target process at the selected grid better than conventional BNNs of
similar complexity. We also show that a single SBNN can be used to represent a
variety of spatial processes often used in practice, such as Gaussian processes
and lognormal processes. We briefly discuss the tools that could be used to
make inference with SBNNs, and we conclude with a discussion of their
advantages and limitations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09498">Network Wide Evacuation Traffic Prediction in a Rapidly Intensifying Hurricane from Traffic Detectors and Facebook Movement Data: A Deep Learning Approach. (arXiv:2311.09498v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1">Md Mobasshir Rashid</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_R/0/1/0/all/0/1">Rezaur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1">Samiul Hasan</a></p>
<p>Traffic prediction during hurricane evacuation is essential for optimizing
the use of transportation infrastructures. It can reduce evacuation time by
providing information on future congestion in advance. However, evacuation
traffic prediction can be challenging as evacuation traffic patterns is
significantly different than regular period traffic. A data-driven traffic
prediction model is developed in this study by utilizing traffic detector and
Facebook movement data during Hurricane Ian, a rapidly intensifying hurricane.
We select 766 traffic detectors from Florida's 4 major interstates to collect
traffic features. Additionally, we use Facebook movement data collected during
Hurricane Ian's evacuation period. The deep-learning model is first trained on
regular period (May-August 2022) data to understand regular traffic patterns
and then Hurricane Ian's evacuation period data is used as test data. The model
achieves 95% accuracy (RMSE = 356) during regular period, but it underperforms
with 55% accuracy (RMSE = 1084) during the evacuation period. Then, a transfer
learning approach is adopted where a pretrained model is used with additional
evacuation related features to predict evacuation period traffic. After
transfer learning, the model achieves 89% accuracy (RMSE = 514). Adding
Facebook movement data further reduces model's RMSE value to 393 and increases
accuracy to 93%. The proposed model is capable to forecast traffic up to
6-hours in advance. Evacuation traffic management officials can use the
developed traffic prediction model to anticipate future traffic congestion in
advance and take proactive measures to reduce delays during evacuation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09505">SegMix: A Simple Structure-Aware Data Augmentation Method. (arXiv:2311.09505v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pei_Y/0/1/0/all/0/1">Yuxin Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhuse_P/0/1/0/all/0/1">Pushkar Bhuse</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengzhong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric Xing</a></p>
<p>Interpolation-based Data Augmentation (DA) methods (Mixup) linearly
interpolate the inputs and labels of two or more training examples. Mixup has
more recently been adapted to the field of Natural Language Processing (NLP),
mainly for sequence labeling tasks. However, such a simple adoption yields
mixed or unstable improvements over the baseline models. We argue that the
direct-adoption methods do not account for structures in NLP tasks. To this
end, we propose SegMix, a collection of interpolation-based DA algorithms that
can adapt to task-specific structures. SegMix poses fewer constraints on data
structures, is robust to various hyperparameter settings, applies to more task
settings, and adds little computational overhead. In the algorithm's core, we
apply interpolation methods on task-specific meaningful segments, in contrast
to applying them on sequences as in prior work. We find SegMix to be a flexible
framework that combines rule-based DA methods with interpolation-based methods,
creating interesting mixtures of DA techniques. We show that SegMix
consistently improves performance over strong baseline models in Named Entity
Recognition (NER) and Relation Extraction (RE) tasks, especially under
data-scarce settings. Furthermore, this method is easy to implement and adds
negligible training overhead.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09506">Investigating the Impact of Weight Sharing Decisions on Knowledge Transfer in Continual Learning. (arXiv:2311.09506v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Andle_J/0/1/0/all/0/1">Josh Andle</a>, <a href="http://arxiv.org/find/cs/1/au:+Payani_A/0/1/0/all/0/1">Ali Payani</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasaei_Sekeh_S/0/1/0/all/0/1">Salimeh Yasaei-Sekeh</a></p>
<p>Continual Learning (CL) has generated attention as a method of avoiding
Catastrophic Forgetting (CF) in the sequential training of neural networks,
improving network efficiency and adaptability to different tasks. Additionally,
CL serves as an ideal setting for studying network behavior and Forward
Knowledge Transfer (FKT) between tasks. Pruning methods for CL train
subnetworks to handle the sequential tasks which allows us to take a structured
approach to investigating FKT. Sharing prior subnetworks' weights leverages
past knowledge for the current task through FKT. Understanding which weights to
share is important as sharing all weights can yield sub-optimal accuracy. This
paper investigates how different sharing decisions affect the FKT between
tasks. Through this lens we demonstrate how task complexity and similarity
influence the optimal weight sharing decisions, giving insights into the
relationships between tasks and helping inform decision making in similar CL
methods. We implement three sequential datasets designed to emphasize variation
in task complexity and similarity, reporting results for both ResNet-18 and
VGG-16. By sharing in accordance with the decisions supported by our findings,
we show that we can improve task accuracy compared to other sharing decisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09511">Identifying Systems with Symmetries using Equivariant Autoregressive Reservoir Computers. (arXiv:2311.09511v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Vides_F/0/1/0/all/0/1">Fredy Vides</a>, <a href="http://arxiv.org/find/eess/1/au:+Nogueira_I/0/1/0/all/0/1">Idelfonso B. R. Nogueira</a>, <a href="http://arxiv.org/find/eess/1/au:+Banegas_L/0/1/0/all/0/1">Lendy Banegas</a>, <a href="http://arxiv.org/find/eess/1/au:+Flores_E/0/1/0/all/0/1">Evelyn Flores</a></p>
<p>The investigation reported in this document focuses on identifying systems
with symmetries using equivariant autoregressive reservoir computers. General
results in structured matrix approximation theory are presented, exploring a
two-fold approach. Firstly, a comprehensive examination of generic
symmetry-preserving nonlinear time delay embedding is conducted. This involves
analyzing time series data sampled from an equivariant system under study.
Secondly, sparse least-squares methods are applied to discern approximate
representations of the output coupling matrices. These matrices play a pivotal
role in determining the nonlinear autoregressive representation of an
equivariant system. The structural characteristics of these matrices are
dictated by the set of symmetries inherent in the system. The document outlines
prototypical algorithms derived from the described techniques, offering insight
into their practical applications. Emphasis is placed on their effectiveness in
the identification and predictive simulation of equivariant nonlinear systems,
regardless of whether such systems exhibit chaotic behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09514">Know Thy Neighbors: A Graph Based Approach for Effective Sensor-Based Human Activity Recognition in Smart Homes. (arXiv:2311.09514v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+P_S/0/1/0/all/0/1">Srivatsa P</a>, <a href="http://arxiv.org/find/cs/1/au:+Plotz_T/0/1/0/all/0/1">Thomas Pl&#xf6;tz</a></p>
<p>There has been a resurgence of applications focused on Human Activity
Recognition (HAR) in smart homes, especially in the field of ambient
intelligence and assisted living technologies. However, such applications
present numerous significant challenges to any automated analysis system
operating in the real world, such as variability, sparsity, and noise in sensor
measurements. Although state-of-the-art HAR systems have made considerable
strides in addressing some of these challenges, they especially suffer from a
practical limitation: they require successful pre-segmentation of continuous
sensor data streams before automated recognition, i.e., they assume that an
oracle is present during deployment, which is capable of identifying time
windows of interest across discrete sensor events. To overcome this limitation,
we propose a novel graph-guided neural network approach that performs activity
recognition by learning explicit co-firing relationships between sensors. We
accomplish this by learning a more expressive graph structure representing the
sensor network in a smart home, in a data-driven manner. Our approach maps
discrete input sensor measurements to a feature space through the application
of attention mechanisms and hierarchical pooling of node embeddings. We
demonstrate the effectiveness of our proposed approach by conducting several
experiments on CASAS datasets, showing that the resulting graph-guided neural
network outperforms the state-of-the-art method for HAR in smart homes across
multiple datasets and by large margins. These results are promising because
they push HAR for smart homes closer to real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09528">HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM. (arXiv:2311.09528v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Jiaqi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Adams_V/0/1/0/all/0/1">Virginia Adams</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreedhar_M/0/1/0/all/0/1">Makesh Narsimhan Sreedhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Egert_D/0/1/0/all/0/1">Daniel Egert</a>, <a href="http://arxiv.org/find/cs/1/au:+Delalleau_O/0/1/0/all/0/1">Olivier Delalleau</a>, <a href="http://arxiv.org/find/cs/1/au:+Scowcroft_J/0/1/0/all/0/1">Jane Polak Scowcroft</a>, <a href="http://arxiv.org/find/cs/1/au:+Kant_N/0/1/0/all/0/1">Neel Kant</a>, <a href="http://arxiv.org/find/cs/1/au:+Swope_A/0/1/0/all/0/1">Aidan Swope</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1">Oleksii Kuchaiev</a></p>
<p>Existing open-source helpfulness preference datasets do not specify what
makes some responses more helpful and others less so. Models trained on these
datasets can incidentally learn to model dataset artifacts (e.g. preferring
longer but unhelpful responses only due to their length). To alleviate this
problem, we collect HelpSteer, a multi-attribute helpfulness dataset annotated
for the various aspects that make responses helpful. Specifically, our
37k-sample dataset has annotations for correctness, coherence, complexity, and
verbosity in addition to overall helpfulness of responses. Training Llama 2 70B
using the HelpSteer dataset with SteerLM technique produces a model that scores
7.54 on MT Bench, which is currently the highest score for open models that do
not require training data from more powerful models (e.g. GPT4). We release
this dataset with CC-BY-4.0 license at
https://huggingface.co/datasets/nvidia/HelpSteer
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09544">Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta. (arXiv:2311.09544v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Fang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhongke Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuewei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ru Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yaning Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Dong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengxing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Min Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fenggang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minghai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huayu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yunnan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_Z/0/1/0/all/0/1">Zhan Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Mindi Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Sri Reddy</a></p>
<p>Effective user representations are pivotal in personalized advertising.
However, stringent constraints on training throughput, serving latency, and
memory, often limit the complexity and input feature set of online ads ranking
models. This challenge is magnified in extensive systems like Meta's, which
encompass hundreds of models with diverse specifications, rendering the
tailoring of user representation learning for each model impractical. To
address these challenges, we present Scaling User Modeling (SUM), a framework
widely deployed in Meta's ads ranking system, designed to facilitate efficient
and scalable sharing of online user representation across hundreds of ads
models. SUM leverages a few designated upstream user models to synthesize user
embeddings from massive amounts of user features with advanced modeling
techniques. These embeddings then serve as inputs to downstream online ads
ranking models, promoting efficient representation sharing. To adapt to the
dynamic nature of user features and ensure embedding freshness, we designed SUM
Online Asynchronous Platform (SOAP), a latency free online serving system
complemented with model freshness and embedding stabilization, which enables
frequent user model updates and online inference of user embeddings upon each
user request. We share our hands-on deployment experiences for the SUM
framework and validate its superiority through comprehensive experiments. To
date, SUM has been launched to hundreds of ads ranking models in Meta,
processing hundreds of billions of user requests daily, yielding significant
online metric gains and infrastructure cost savings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09550">A Speed Odyssey for Deployable Quantization of LLMs. (arXiv:2311.09550v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1">Ran Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiduo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yifan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yerui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuchen Xie</a></p>
<p>The large language model era urges faster and less costly inference. Prior
model compression works on LLMs tend to undertake a software-centric approach
primarily focused on the simulated quantization performance. By neglecting the
feasibility of deployment, these approaches are typically disabled in real
practice. They used to drastically push down the quantization bit range for a
reduced computation which might not be supported by the mainstream hardware, or
involve sophisticated algorithms that introduce extra computation or memory
access overhead. We argue that pursuing a hardware-centric approach in the
construction of quantization algorithms is crucial. In this regard, we are
driven to build our compression method on top of hardware awareness,
eliminating impractical algorithm choices while maximizing the benefit of
hardware acceleration. Our method, OdysseyLLM, comes with a novel W4A8 kernel
implementation called FastGEMM and a combined recipe of quantization
strategies. Extensive experiments manifest the superiority of our W4A8 method
which brings the actual speed boosting up to \textbf{4$\times$} compared to
Hugging Face FP16 inference and \textbf{2.23$\times$} vs. the state-of-the-art
inference engine TensorRT-LLM in FP16, and \textbf{1.45$\times$} vs.
TensorRT-LLM in INT8, yet without substantially harming the performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09566">A Knowledge Distillation Approach for Sepsis Outcome Prediction from Multivariate Clinical Time Series. (arXiv:2311.09566v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Anna Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1">Shu Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Oufattole_N/0/1/0/all/0/1">Nassim Oufattole</a>, <a href="http://arxiv.org/find/cs/1/au:+Dejl_A/0/1/0/all/0/1">Adam Dejl</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_M/0/1/0/all/0/1">Megan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Saeedi_A/0/1/0/all/0/1">Ardavan Saeedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehman_L/0/1/0/all/0/1">Li-wei H. Lehman</a></p>
<p>Sepsis is a life-threatening condition triggered by an extreme infection
response. Our objective is to forecast sepsis patient outcomes using their
medical history and treatments, while learning interpretable state
representations to assess patients' risks in developing various adverse
outcomes. While neural networks excel in outcome prediction, their limited
interpretability remains a key issue. In this work, we use knowledge
distillation via constrained variational inference to distill the knowledge of
a powerful "teacher" neural network model with high predictive power to train a
"student" latent variable model to learn interpretable hidden state
representations to achieve high predictive performance for sepsis outcome
prediction. Using real-world data from the MIMIC-IV database, we trained an
LSTM as the "teacher" model to predict mortality for sepsis patients, given
information about their recent history of vital signs, lab values and
treatments. For our student model, we use an autoregressive hidden Markov model
(AR-HMM) to learn interpretable hidden states from patients' clinical time
series, and use the posterior distribution of the learned state representations
to predict various downstream outcomes, including hospital mortality, pulmonary
edema, need for diuretics, dialysis, and mechanical ventilation. Our results
show that our approach successfully incorporates the constraint to achieve high
predictive power similar to the teacher model, while maintaining the generative
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09574">LymphoML: An interpretable artificial intelligence-based method identifies morphologic features that correlate with lymphoma subtype. (arXiv:2311.09574v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1">Vivek Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoli Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_V/0/1/0/all/0/1">Vrishab Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_B/0/1/0/all/0/1">Brent Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_O/0/1/0/all/0/1">Oscar Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojansky_R/0/1/0/all/0/1">Rebecca Rojansky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Valvert_F/0/1/0/all/0/1">Fabiola Valvert</a>, <a href="http://arxiv.org/find/cs/1/au:+Briercheck_E/0/1/0/all/0/1">Edward Briercheck</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinstock_D/0/1/0/all/0/1">David Weinstock</a>, <a href="http://arxiv.org/find/cs/1/au:+Natkunam_Y/0/1/0/all/0/1">Yasodha Natkunam</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Pol_S/0/1/0/all/0/1">Sebastian Fernandez-Pol</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a></p>
<p>The accurate classification of lymphoma subtypes using hematoxylin and eosin
(H&amp;E)-stained tissue is complicated by the wide range of morphological features
these cancers can exhibit. We present LymphoML - an interpretable machine
learning method that identifies morphologic features that correlate with
lymphoma subtypes. Our method applies steps to process H&amp;E-stained tissue
microarray cores, segment nuclei and cells, compute features encompassing
morphology, texture, and architecture, and train gradient-boosted models to
make diagnostic predictions. LymphoML's interpretable models, developed on a
limited volume of H&amp;E-stained tissue, achieve non-inferior diagnostic accuracy
to pathologists using whole-slide images and outperform black box deep-learning
on a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using
SHapley Additive exPlanation (SHAP) analysis, we assess the impact of each
feature on model prediction and find that nuclear shape features are most
discriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma
(F1-score: 74.5%). Finally, we provide the first demonstration that a model
combining features from H&amp;E-stained tissue with features from a standardized
panel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a
46-stain panel (86.1%).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09577">Group-Aware Interest Disentangled Dual-Training for Personalized Recommendation. (arXiv:2311.09577v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaolong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Liangwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Mingdai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a></p>
<p>Personalized recommender systems aim to predict users' preferences for items.
It has become an indispensable part of online services. Online social platforms
enable users to form groups based on their common interests. The users' group
participation on social platforms reveals their interests and can be utilized
as side information to mitigate the data sparsity and cold-start problem in
recommender systems. Users join different groups out of different interests. In
this paper, we generate group representation from the user's interests and
propose IGRec (Interest-based Group enhanced Recommendation) to utilize the
group information accurately. It consists of four modules. (1) Interest
disentangler via self-gating that disentangles users' interests from their
initial embedding representation. (2) Interest aggregator that generates the
interest-based group representation by Gumbel-Softmax aggregation on the group
members' interests. (3) Interest-based group aggregation that fuses user's
representation with the participated group representation. (4) A dual-trained
rating prediction module to utilize both user-item and group-item interactions.
We conduct extensive experiments on three publicly available datasets. Results
show IGRec can effectively alleviate the data sparsity problem and enhance the
recommender system with interest-based group representation. Experiments on the
group recommendation task further show the informativeness of interest-based
group representation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09578">Tied-Lora: Enhacing parameter efficiency of LoRA with weight tying. (arXiv:2311.09578v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Renduchintala_A/0/1/0/all/0/1">Adithya Renduchintala</a>, <a href="http://arxiv.org/find/cs/1/au:+Konuk_T/0/1/0/all/0/1">Tugrul Konuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1">Oleksii Kuchaiev</a></p>
<p>We propose Tied-LoRA, a simple paradigm utilizes weight tying and selective
training to further increase parameter efficiency of the Low-rank adaptation
(LoRA) method. Our investigations include all feasible combinations parameter
training/freezing in conjunction with weight tying to identify the optimal
balance between performance and the number of trainable parameters. Through
experiments covering a variety of tasks and two base language models, we
provide analysis revealing trade-offs between efficiency and performance. Our
experiments uncovered a particular Tied-LoRA configuration that stands out by
demonstrating comparable performance across several tasks while employing only
13~\% percent of parameters utilized by the standard LoRA method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09591">Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization. (arXiv:2311.09591v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Raihan_A/0/1/0/all/0/1">Ahmed Shoyeb Raihan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_H/0/1/0/all/0/1">Hamed Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srinjoy Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_I/0/1/0/all/0/1">Imtiaz Ahmed</a></p>
<p>Advancements in materials play a crucial role in technological progress.
However, the process of discovering and developing materials with desired
properties is often impeded by substantial experimental costs, extensive
resource utilization, and lengthy development periods. To address these
challenges, modern approaches often employ machine learning (ML) techniques
such as Bayesian Optimization (BO), which streamline the search for optimal
materials by iteratively selecting experiments that are most likely to yield
beneficial results. However, traditional BO methods, while beneficial, often
struggle with balancing the trade-off between exploration and exploitation,
leading to sub-optimal performance in material discovery processes. This paper
introduces a novel Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO)
method, which dynamically integrates the strengths of Upper Confidence Bound
(UCB) and Expected Improvement (EI) acquisition functions to optimize the
material discovery process. Unlike the classical BO, our method focuses on
efficiently navigating the high-dimensional material design space (MDS).
TDUE-BO begins with an exploration-focused UCB approach, ensuring a
comprehensive initial sweep of the MDS. As the model gains confidence,
indicated by reduced uncertainty, it transitions to the more exploitative EI
method, focusing on promising areas identified earlier. The UCB-to-EI switching
policy dictated guided through continuous monitoring of the model uncertainty
during each step of sequential sampling results in navigating through the MDS
more efficiently while ensuring rapid convergence. The effectiveness of TDUE-BO
is demonstrated through its application on three different material datasets,
showing significantly better approximation and optimization performance over
the EI and UCB-based BO methods in terms of the RMSE scores and convergence
efficiency, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09596">Generating Drug Repurposing Hypotheses through the Combination of Disease-Specific Hypergraphs. (arXiv:2311.09596v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Jain_A/0/1/0/all/0/1">Ayush Jain</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Laure_Charpignon_M/0/1/0/all/0/1">Marie Laure-Charpignon</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_I/0/1/0/all/0/1">Irene Y. Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Philippakis_A/0/1/0/all/0/1">Anthony Philippakis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Alaa_A/0/1/0/all/0/1">Ahmed Alaa</a></p>
<p>The drug development pipeline for a new compound can last 10-20 years and
cost over 10 billion. Drug repurposing offers a more time- and cost-effective
alternative. Computational approaches based on biomedical knowledge graph
representations have recently yielded new drug repurposing hypotheses. In this
study, we present a novel, disease-specific hypergraph representation learning
technique to derive contextual embeddings of biological pathways of various
lengths but that all start at any given drug and all end at the disease of
interest. Further, we extend this method to multi-disease hypergraphs. To
determine the repurposing potential of each of the 1,522 drugs, we derive
drug-specific distributions of cosine similarity values and ultimately consider
the median for ranking. Cosine similarity values are computed between (1) all
biological pathways starting at the considered drug and ending at the disease
of interest and (2) all biological pathways starting at drugs currently
prescribed against that disease and ending at the disease of interest. We
illustrate our approach with Alzheimer's disease (AD) and two of its risk
factors: hypertension (HTN) and type 2 diabetes (T2D). We compare each drug's
rank across four hypergraph settings (single- or multi-disease): AD only, AD +
HTN, AD + T2D, and AD + HTN + T2D. Notably, our framework led to the
identification of two promising drugs whose repurposing potential was
significantly higher in hypergraphs combining two diseases: dapagliflozin
(antidiabetic; moved up, from top 32$\%$ to top 7$\%$, across all considered
drugs) and debrisoquine (antihypertensive; moved up, from top 76$\%$ to top
23$\%$). Our approach serves as a hypothesis generation tool, to be paired with
a validation pipeline relying on laboratory experiments and semi-automated
parsing of the biomedical literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09614">Comprehensive Evaluation and Insights into the Use of Deep Neural Networks to Detect and Quantify Lymphoma Lesions in PET/CT Images. (arXiv:2311.09614v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahamed_S/0/1/0/all/0/1">Shadab Ahamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yixi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gowdy_C/0/1/0/all/0/1">Claire Gowdy</a>, <a href="http://arxiv.org/find/cs/1/au:+O_J/0/1/0/all/0/1">Joo H. O</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloise_I/0/1/0/all/0/1">Ingrid Bloise</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1">Don Wilson</a>, <a href="http://arxiv.org/find/cs/1/au:+Martineau_P/0/1/0/all/0/1">Patrick Martineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Benard_F/0/1/0/all/0/1">Fran&#xe7;ois B&#xe9;nard</a>, <a href="http://arxiv.org/find/cs/1/au:+Yousefirizi_F/0/1/0/all/0/1">Fereshteh Yousefirizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavista_J/0/1/0/all/0/1">Juan M. Lavista</a>, <a href="http://arxiv.org/find/cs/1/au:+Weeks_W/0/1/0/all/0/1">William B. Weeks</a>, <a href="http://arxiv.org/find/cs/1/au:+Uribe_C/0/1/0/all/0/1">Carlos F. Uribe</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmim_A/0/1/0/all/0/1">Arman Rahmim</a></p>
<p>This study performs comprehensive evaluation of four neural network
architectures (UNet, SegResNet, DynUNet, and SwinUNETR) for lymphoma lesion
segmentation from PET/CT images. These networks were trained, validated, and
tested on a diverse, multi-institutional dataset of 611 cases. Internal testing
(88 cases; total metabolic tumor volume (TMTV) range [0.52, 2300] ml) showed
SegResNet as the top performer with a median Dice similarity coefficient (DSC)
of 0.76 and median false positive volume (FPV) of 4.55 ml; all networks had a
median false negative volume (FNV) of 0 ml. On the unseen external test set
(145 cases with TMTV range: [0.10, 2480] ml), SegResNet achieved the best
median DSC of 0.68 and FPV of 21.46 ml, while UNet had the best FNV of 0.41 ml.
We assessed reproducibility of six lesion measures, calculated their prediction
errors, and examined DSC performance in relation to these lesion measures,
offering insights into segmentation accuracy and clinical relevance.
Additionally, we introduced three lesion detection criteria, addressing the
clinical need for identifying lesions, counting them, and segmenting based on
metabolic characteristics. We also performed expert intra-observer variability
analysis revealing the challenges in segmenting ``easy'' vs. ``hard'' cases, to
assist in the development of more resilient segmentation algorithms. Finally,
we performed inter-observer agreement assessment underscoring the importance of
a standardized ground truth segmentation protocol involving multiple expert
annotators. Code is available at:
https://github.com/microsoft/lymphoma-segmentation-dnn
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09620">GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection. (arXiv:2311.09620v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jinggang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaoyang Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianzong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1">Jiguang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jing Xiao</a></p>
<p>Detecting out-of-distribution (OOD) examples is crucial to guarantee the
reliability and safety of deep neural networks in real-world settings. In this
paper, we offer an innovative perspective on quantifying the disparities
between in-distribution (ID) and OOD data -- analyzing the uncertainty that
arises when models attempt to explain their predictive decisions. This
perspective is motivated by our observation that gradient-based attribution
methods encounter challenges in assigning feature importance to OOD data,
thereby yielding divergent explanation patterns. Consequently, we investigate
how attribution gradients lead to uncertain explanation outcomes and introduce
two forms of abnormalities for OOD detection: the zero-deflation abnormality
and the channel-wise average abnormality. We then propose GAIA, a simple and
effective approach that incorporates Gradient Abnormality Inspection and
Aggregation. The effectiveness of GAIA is validated on both commonly utilized
(CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces
the average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to
advanced post-hoc methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09627">CRISPR: Eliminating Bias Neurons from an Instruction-following Language Model. (arXiv:2311.09627v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1">Nakyeong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_T/0/1/0/all/0/1">Taegwan Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1">Kyomin Jung</a></p>
<p>Large language models (LLMs) executing tasks through instruction-based
prompts often face challenges stemming from distribution differences between
user instructions and training instructions. This leads to distractions and
biases, especially when dealing with inconsistent dynamic labels. In this
paper, we introduces a novel bias mitigation method, CRISPR, designed to
alleviate instruction-label biases in LLMs. CRISPR utilizes attribution methods
to identify bias neurons influencing biased outputs and employs pruning to
eliminate the bias neurons. Experimental results demonstrate the method's
effectiveness in mitigating biases in instruction-based prompting, enhancing
language model performance on social bias benchmarks without compromising
pre-existing knowledge. CRISPR proves highly practical, model-agnostic,
offering flexibility in adapting to evolving social biases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09649">ICXML: An In-Context Learning Framework for Zero-Shot Extreme Multi-Label Classification. (arXiv:2311.09649v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yaxin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1">Hamed Zamani</a></p>
<p>This paper focuses on the task of Extreme Multi-Label Classification (XMC)
whose goal is to predict multiple labels for each instance from an extremely
large label space. While existing research has primarily focused on fully
supervised XMC, real-world scenarios often lack complete supervision signals,
highlighting the importance of zero-shot settings. Given the large label space,
utilizing in-context learning approaches is not trivial. We address this issue
by introducing In-Context Extreme Multilabel Learning (ICXML), a two-stage
framework that cuts down the search space by generating a set of candidate
labels through incontext learning and then reranks them. Extensive experiments
suggest that ICXML advances the state of the art on two diverse public
benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09663">Zenkai -- Framework For Exploring Beyond Backpropagation. (arXiv:2311.09663v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Short_G/0/1/0/all/0/1">Greg Short</a></p>
<p>Zenkai is an open-source framework designed to give researchers more control
and flexibility over building and training deep learning machines. It does this
by dividing the deep learning machine into layers of semi-autonomous learning
machines with their own target and learning algorithm. This is to allow
researchers greater exploration such as the use of non-differentiable layers or
learning algorithms beyond those based on error backpropagation.
</p>
<p>Backpropagation Rumelhart et al. [1986] has powered deep learning to become
one of the most exciting fields of the 21st century. As a result, a large
number of software tools have been developed to support efficient
implementation and training of neural networks through the use of backpropa-
gation. While these have been critical to the success of deep learning,
building frameworks around backpropagation can make it challenging to implement
solutions that do not adhere to it. Zenkai aims to make it easier to get around
these limitations and help researchers more easily explore new frontiers in
deep learning that do not strictly adhere to the backpropagation framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09668">Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring. (arXiv:2311.09668v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yihan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhouxing Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a></p>
<p>The strong general capabilities of Large Language Models (LLMs) bring
potential ethical risks if they are unrestrictedly accessible to malicious
users. Token-level watermarking inserts watermarks in the generated texts by
altering the token probability distributions with a private random number
generator seeded by its prefix tokens. However, this watermarking algorithm
alters the logits during generation, which can lead to a downgraded text
quality if it chooses to promote tokens that are less relevant given the input.
In this work, we propose to improve the quality of texts generated by a
watermarked language model by Watermarking with Importance Scoring (WIS). At
each generation step, we estimate the importance of the token to generate, and
prevent it from being impacted by watermarking if it is important for the
semantic correctness of the output. We further propose three methods to predict
importance scoring, including a perturbation-based method and two model-based
methods. Empirical experiments show that our method can generate texts with
better quality with comparable level of detection rate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09671">Robust Contrastive Learning With Theory Guarantee. (arXiv:2311.09671v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1">Ngoc N. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_L/0/1/0/all/0/1">Lam Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1">Hoang Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_A/0/1/0/all/0/1">Anh Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Tung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Toan Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Trung Le</a></p>
<p>Contrastive learning (CL) is a self-supervised training paradigm that allows
us to extract meaningful features without any label information. A typical CL
framework is divided into two phases, where it first tries to learn the
features from unlabelled data, and then uses those features to train a linear
classifier with the labeled data. While a fair amount of existing theoretical
works have analyzed how the unsupervised loss in the first phase can support
the supervised loss in the second phase, none has examined the connection
between the unsupervised loss and the robust supervised loss, which can shed
light on how to construct an effective unsupervised loss for the first phase of
CL. To fill this gap, our work develops rigorous theories to dissect and
identify which components in the unsupervised loss can help improve the robust
supervised loss and conduct proper experiments to verify our findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09683">Modelling daily mobility using mobile data traffic at fine spatiotemporal scale. (arXiv:2311.09683v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Christidis_P/0/1/0/all/0/1">Panayotis Christidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalo_M/0/1/0/all/0/1">Maria Vega Gonzalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Radics_M/0/1/0/all/0/1">Miklos Radics</a></p>
<p>We applied a data-driven approach that explores the usability of the NetMob
2023 dataset in modelling mobility patterns within an urban context. We
combined the data with a highly suitable external source, the ENACT dataset,
which provides a 1 km x 1km grid with estimates of the day and night population
across Europe. We developed three sets of XGBoost models that predict the
population in each 100m x 100m grid cell used in NetMob2023 based on the mobile
data traffic of the 68 online services covered in the dataset, using the ENACT
values as ground truth. The results suggest that the NetMob 2023 data can be
useful for the estimation of the day and night population and grid cell level
and can explain part of the dynamics of urban mobility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09690">CDMPP: A Device-Model Agnostic Framework for Latency Prediction of Tensor Programs. (arXiv:2311.09690v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hanpeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Junwei Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Juntao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yanghua Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yibo Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haibin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuan Wu</a></p>
<p>Deep Neural Networks (DNNs) have shown excellent performance in a wide range
of machine learning applications. Knowing the latency of running a DNN model or
tensor program on a specific device is useful in various tasks, such as DNN
graph- or tensor-level optimization and device selection. Considering the large
space of DNN models and devices that impede direct profiling of all
combinations, recent efforts focus on building a predictor to model the
performance of DNN models on different devices. However, none of the existing
attempts have achieved a cost model that can accurately predict the performance
of various tensor programs while supporting both training and inference
accelerators. We propose CDMPP, an efficient tensor program latency prediction
framework for both cross-model and cross-device prediction. We design an
informative but efficient representation of tensor programs, called compact
ASTs, and a pre-order-based positional encoding method, to capture the internal
structure of tensor programs. We develop a domain-adaption-inspired method to
learn domain-invariant representations and devise a KMeans-based sampling
algorithm, for the predictor to learn from different domains (i.e., different
DNN operators and devices). Our extensive experiments on a diverse range of DNN
models and devices demonstrate that CDMPP significantly outperforms
state-of-the-art baselines with 14.03% and 10.85% prediction error for
cross-model and cross-device prediction, respectively, and one order of
magnitude higher training efficiency. The implementation and the expanded
dataset are available at https://github.com/joapolarbear/cdmpp.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09692">Augmenting Unsupervised Reinforcement Learning with Self-Reference. (arXiv:2311.09692v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1">Andrew Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1">Erle Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Rui Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Matthieu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong-Jin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a></p>
<p>Humans possess the ability to draw on past experiences explicitly when
learning new tasks and applying them accordingly. We believe this capacity for
self-referencing is especially advantageous for reinforcement learning agents
in the unsupervised pretrain-then-finetune setting. During pretraining, an
agent's past experiences can be explicitly utilized to mitigate the
nonstationarity of intrinsic rewards. In the finetuning phase, referencing
historical trajectories prevents the unlearning of valuable exploratory
behaviors. Motivated by these benefits, we propose the Self-Reference (SR)
approach, an add-on module explicitly designed to leverage historical
information and enhance agent performance within the pretrain-finetune
paradigm. Our approach achieves state-of-the-art results in terms of
Interquartile Mean (IQM) performance and Optimality Gap reduction on the
Unsupervised Reinforcement Learning Benchmark for model-free methods, recording
an 86% IQM and a 16% Optimality Gap. Additionally, it improves current
algorithms by up to 17% IQM and reduces the Optimality Gap by 31%. Beyond
performance enhancement, the Self-Reference add-on also increases sample
efficiency, a crucial attribute for real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09706">Towards Autonomous Hypothesis Verification via Language Models with Minimal Guidance. (arXiv:2311.09706v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Takagi_S/0/1/0/all/0/1">Shiro Takagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamauchi_R/0/1/0/all/0/1">Ryutaro Yamauchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumagai_W/0/1/0/all/0/1">Wataru Kumagai</a></p>
<p>Research automation efforts usually employ AI as a tool to automate specific
tasks within the research process. To create an AI that truly conduct research
themselves, it must independently generate hypotheses, design verification
plans, and execute verification. Therefore, we investigated if an AI itself
could autonomously generate and verify hypothesis for a toy machine learning
research problem. We prompted GPT-4 to generate hypotheses and Python code for
hypothesis verification with limited methodological guidance. Our findings
suggest that, in some instances, GPT-4 can autonomously generate and validate
hypotheses without detailed guidance. While this is a promising result, we also
found that none of the verifications were flawless, and there remain
significant challenges in achieving autonomous, human-level research using only
generic instructions. These findings underscore the need for continued
exploration to develop a general and autonomous AI researcher.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09730">Aligning with Whom? Large Language Models Have Gender and Racial Biases in Subjective NLP Tasks. (arXiv:2311.09730v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huaman Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jiaxin Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1">Minje Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1">David Jurgens</a></p>
<p>Human perception of language depends on personal backgrounds like gender and
ethnicity. While existing studies have shown that large language models (LLMs)
hold values that are closer to certain societal groups, it is unclear whether
their prediction behaviors on subjective NLP tasks also exhibit a similar bias.
In this study, leveraging the POPQUORN dataset which contains annotations of
diverse demographic backgrounds, we conduct a series of experiments on four
popular LLMs to investigate their capability to understand group differences
and potential biases in their predictions for politeness and offensiveness. We
find that for both tasks, model predictions are closer to the labels from White
and female participants. We further explore prompting with the target
demographic labels and show that including the target demographic in the prompt
actually worsens the model's performance. More specifically, when being
prompted to respond from the perspective of "Black" and "Asian" individuals,
models show lower performance in predicting both overall scores as well as the
scores from corresponding groups. Our results suggest that LLMs hold gender and
racial biases for subjective NLP tasks and that demographic-infused prompts
alone may be insufficient to mitigate such effects. Code and data are available
at https://github.com/Jiaxin-Pei/LLM-Group-Bias.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09731">Prudent Silence or Foolish Babble? Examining Large Language Models&#x27; Responses to the Unknown. (arXiv:2311.09731v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Genglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingyao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lifan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yangyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a></p>
<p>Large Language Models (LLMs) often struggle when faced with situations where
they lack the prerequisite knowledge to generate a sensical response. In these
cases, models tend to fabricate and hallucinate, rather than appropriately
signaling uncertainty as humans would. This behavior misaligns with human
conversational norms and presents challenges surrounding responsible and
ethical AI development. This work aims to systematically investigate LLMs'
behaviors in such situations. We curate an adversarial question-answering
benchmark containing unanswerable questions targeting information absent from
the LLM's training data. Concretely, these unanswerable questions contain
non-existent concepts or false premises. When presented with such unanswerable
questions, an LLM should appropriately convey uncertainty, and be able to
challenge the premise and refuse to generate a response. While facing
answerable valid questions, a model should demonstrate a positive correlation
between accuracy and confidence. Using a model-agnostic unified confidence
elicitation approach, we observe that LLMs that have gone through instruction
finetuning and reinforcement learning from human feedback (RLHF) perform
significantly better than their counterparts that do not. Moreover, uncertainty
expression 1 through our elicitation method does not always stay consistent
with the perceived confidence of the direct response of an LLM. Our findings
call for further research into teaching LLMs to proactively and reliably
express uncertainty.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09735">GEO: Generative Engine Optimization. (arXiv:2311.09735v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_P/0/1/0/all/0/1">Pranjal Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Murahari_V/0/1/0/all/0/1">Vishvak Murahari</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurohit_T/0/1/0/all/0/1">Tanmay Rajpurohit</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1">Ashwin Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1">Karthik R Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Ameet Deshpande</a></p>
<p>The advent of large language models (LLMs) has ushered in a new paradigm of
search engines that use generative models to gather and summarize information
to answer user queries. This emerging technology, which we formalize under the
unified framework of Generative Engines (GEs), has the potential to generate
accurate and personalized responses, and is rapidly replacing traditional
search engines like Google and Bing. Generative Engines typically satisfy
queries by synthesizing information from multiple sources and summarizing them
with the help of LLMs. While this shift significantly improves \textit{user}
utility and \textit{generative search engine} traffic, it results in a huge
challenge for the third stakeholder -- website and content creators. Given the
black-box and fast-moving nature of Generative Engines, content creators have
little to no control over when and how their content is displayed. With
generative engines here to stay, the right tools should be provided to ensure
that creator economy is not severely disadvantaged. To address this, we
introduce Generative Engine Optimization (GEO), a novel paradigm to aid content
creators in improving the visibility of their content in Generative Engine
responses through a black-box optimization framework for optimizing and
defining visibility metrics. We facilitate systematic evaluation in this new
paradigm by introducing GEO-bench, a benchmark of diverse user queries across
multiple domains, coupled with sources required to answer these queries.
Through rigorous evaluation, we show that GEO can boost visibility by up to
40\% in generative engine responses. Moreover, we show the efficacy of these
strategies varies across domains, underscoring the need for domain-specific
methods. Our work opens a new frontier in the field of information discovery
systems, with profound implications for generative engines and content
creators.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09740">Redefining Super-Resolution: Fine-mesh PDE predictions without classical simulations. (arXiv:2311.09740v1 [physics.flu-dyn])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Sarkar_R/0/1/0/all/0/1">Rajat Kumar Sarkar</a>, <a href="http://arxiv.org/find/physics/1/au:+Majumdar_R/0/1/0/all/0/1">Ritam Majumdar</a>, <a href="http://arxiv.org/find/physics/1/au:+Jadhav_V/0/1/0/all/0/1">Vishal Jadhav</a>, <a href="http://arxiv.org/find/physics/1/au:+Sakhinana_S/0/1/0/all/0/1">Sagar Srinivas Sakhinana</a>, <a href="http://arxiv.org/find/physics/1/au:+Runkana_V/0/1/0/all/0/1">Venkataramana Runkana</a></p>
<p>In Computational Fluid Dynamics (CFD), coarse mesh simulations offer
computational efficiency but often lack precision. Applying conventional
super-resolution to these simulations poses a significant challenge due to the
fundamental contrast between downsampling high-resolution images and
authentically emulating low-resolution physics. The former method conserves
more of the underlying physics, surpassing the usual constraints of real-world
scenarios. We propose a novel definition of super-resolution tailored for
PDE-based problems. Instead of simply downsampling from a high-resolution
dataset, we use coarse-grid simulated data as our input and predict fine-grid
simulated outcomes. Employing a physics-infused UNet upscaling method, we
demonstrate its efficacy across various 2D-CFD problems such as discontinuity
detection in Burger's equation, Methane combustion, and fouling in Industrial
heat exchangers. Our method enables the generation of fine-mesh solutions
bypassing traditional simulation, ensuring considerable computational saving
and fidelity to the original ground truth outcomes. Through diverse boundary
conditions during training, we further establish the robustness of our method,
paving the way for its broad applications in engineering and scientific CFD
solvers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09741">What Constitutes a Faithful Summary? Preserving Author Perspectives in News Summarization. (arXiv:2311.09741v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuhan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shangbin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiaochuang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1">Vidhisha Balachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1">Chan Young Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sachin Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1">Yulia Tsvetkov</a></p>
<p>In this work, we take a first step towards designing summarization systems
that are faithful to the author's opinions and perspectives. Focusing on a case
study of preserving political perspectives in news summarization, we find that
existing approaches alter the political opinions and stances of news articles
in more than 50% of summaries, misrepresenting the intent and perspectives of
the news authors. We thus propose P^3Sum, a diffusion model-based summarization
approach controlled by political perspective classifiers. In P^3Sum, the
political leaning of a generated summary is iteratively evaluated at each
decoding step, and any drift from the article's original stance incurs a loss
back-propagated to the embedding layers, steering the political stance of the
summary at inference time. Extensive experiments on three news summarization
datasets demonstrate that P^3Sum outperforms state-of-the-art summarization
systems and large language models by up to 11.4% in terms of the success rate
of stance preservation, with on-par performance on standard summarization
utility metrics. These findings highlight the lacunae that even for
state-of-the-art models it is still challenging to preserve author perspectives
in news summarization, while P^3Sum presents an important first step towards
evaluating and developing summarization systems that are faithful to author
intent and perspectives.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09761">MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and Classification. (arXiv:2311.09761v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Helwe_C/0/1/0/all/0/1">Chadi Helwe</a>, <a href="http://arxiv.org/find/cs/1/au:+Calamai_T/0/1/0/all/0/1">Tom Calamai</a>, <a href="http://arxiv.org/find/cs/1/au:+Paris_P/0/1/0/all/0/1">Pierre-Henri Paris</a>, <a href="http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1">Chlo&#xe9; Clavel</a>, <a href="http://arxiv.org/find/cs/1/au:+Suchanek_F/0/1/0/all/0/1">Fabian Suchanek</a></p>
<p>Fallacies can be used to spread disinformation, fake news, and propaganda,
underlining the importance of their detection. Automated detection and
classification of fallacies, however, remain challenging, mainly because of the
innate subjectivity of the task and the need for a comprehensive, unified
approach in existing research. Addressing these limitations, our study
introduces a novel taxonomy of fallacies that aligns and refines previous
classifications, a new annotation scheme tailored for subjective NLP tasks, and
a new evaluation method designed to handle subjectivity, adapted to precision,
recall, and F1-Score metrics. Using our annotation scheme, the paper introduces
MAFALDA (Multi-level Annotated FALlacy DAtaset), a gold standard dataset.
MAFALDA is based on examples from various previously existing fallacy datasets
under our unified taxonomy across three levels of granularity. We then evaluate
several language models under a zero-shot learning setting using MAFALDA to
assess their fallacy detection and classification capability. Our comprehensive
evaluation not only benchmarks the performance of these models but also
provides valuable insights into their strengths and limitations in addressing
fallacious reasoning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09762">Graph-Guided Reasoning for Multi-Hop Question Answering in Large Language Models. (arXiv:2311.09762v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinyoung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1">Ameen Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_O/0/1/0/all/0/1">Omar Zia Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunwoo J. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Joo-Kyung Kim</a></p>
<p>Chain-of-Thought (CoT) prompting has boosted the multi-step reasoning
capabilities of Large Language Models (LLMs) by generating a series of
rationales before the final answer. We analyze the reasoning paths generated by
CoT and find two issues in multi-step reasoning: (i) Generating rationales
irrelevant to the question, (ii) Unable to compose subquestions or queries for
generating/retrieving all the relevant information. To address them, we propose
a graph-guided CoT prompting method, which guides the LLMs to reach the correct
answer with graph representation/verification steps. Specifically, we first
leverage LLMs to construct a "question/rationale graph" by using knowledge
extraction prompting given the initial question and the rationales generated in
the previous steps. Then, the graph verification step diagnoses the current
rationale triplet by comparing it with the existing question/rationale graph to
filter out irrelevant rationales and generate follow-up questions to obtain
relevant information. Additionally, we generate CoT paths that exclude the
extracted graph information to represent the context information missed from
the graph extraction. Our graph-guided reasoning method shows superior
performance compared to previous CoT prompting and the variants on multi-hop
question answering benchmark datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09774">HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs. (arXiv:2311.09774v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_A/0/1/0/all/0/1">Anningzhe Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1">Feng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shunian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dingjie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Wenya Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_C/0/1/0/all/0/1">Chuyi Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianquan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haizhou Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Benyou Wang</a></p>
<p>Adapting a language model into a specific domain, a.k.a `domain adaption', is
a common practice when specialized knowledge, e.g. medicine, is not
encapsulated in a general language model like Llama2. The challenge lies in the
heterogeneity of data across the two training stages, as it varies in
languages, genres, or formats. To tackle this and simplify the learning
protocol, we propose to transform heterogeneous data, from the both
pre-training and supervised stages, into a unified, simple input-output pair
format. We validate the new protocol in the domains where proprietary LLMs like
ChatGPT perform relatively poorly, such as Traditional Chinese Medicine. The
developed model, HuatuoGPT-II, has shown state-of-the-art performance in
Chinese medicine domain on a number of benchmarks, e.g. medical licensing
exams. It even outperforms proprietary models like ChatGPT and GPT-4 in some
aspects, especially in Traditional Chinese Medicine. Expert manual evaluations
further validate HuatuoGPT-II's advantages over existing LLMs. Notably,
HuatuoGPT-II was benchmarked in a fresh Chinese National Medical Licensing
Examination where it achieved the best performance, showcasing not only its
effectiveness but also its generalization capabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09790">Breaking Boundaries: Balancing Performance and Robustness in Deep Wireless Traffic Forecasting. (arXiv:2311.09790v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Romain_I/0/1/0/all/0/1">Ilbert Romain</a>, <a href="http://arxiv.org/find/cs/1/au:+Thai_V/0/1/0/all/0/1">V. Hoang Thai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonghua_Z/0/1/0/all/0/1">Zhang Zonghua</a>, <a href="http://arxiv.org/find/cs/1/au:+Themis_P/0/1/0/all/0/1">Palpanas Themis</a></p>
<p>Balancing the trade-off between accuracy and robustness is a long-standing
challenge in time series forecasting. While most of existing robust algorithms
have achieved certain suboptimal performance on clean data, sustaining the same
performance level in the presence of data perturbations remains extremely hard.
% In this paper, we study a wide array of perturbation scenarios and propose
novel defense mechanisms against adversarial attacks using real-world telecom
data. We compare our strategy against two existing adversarial training
algorithms under a range of maximal allowed perturbations, defined using
$\ell_{\infty}$-norm, $\in [0.1,0.4]$. % Our findings reveal that our hybrid
strategy, which is composed of a classifier to detect adversarial examples, a
denoiser to eliminate noise from the perturbed data samples, and a standard
forecaster, achieves the best performance on both clean and perturbed data. %
Our optimal model can retain up to $92.02\%$ the performance of the original
forecasting model in terms of Mean Squared Error (MSE) on clean data, while
being more robust than the standard adversarially trained models on perturbed
data. Its MSE is 2.71$\times$ and 2.51$\times$ lower than those of comparing
methods on normal and perturbed data, respectively. In addition, the components
of our models can be trained in parallel, resulting in better computational
efficiency. % Our results indicate that we can optimally balance the trade-off
between the performance and robustness of forecasting models by improving the
classifier and denoiser, even in the presence of sophisticated and destructive
poisoning attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09793">Fossil 2.0: Formal Certificate Synthesis for the Verification and Control of Dynamical Models. (arXiv:2311.09793v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Edwards_A/0/1/0/all/0/1">Alec Edwards</a>, <a href="http://arxiv.org/find/eess/1/au:+Peruffo_A/0/1/0/all/0/1">Andrea Peruffo</a>, <a href="http://arxiv.org/find/eess/1/au:+Abate_A/0/1/0/all/0/1">Alessandro Abate</a></p>
<p>This paper presents Fossil 2.0, a new major release of a software tool for
the synthesis of certificates (e.g., Lyapunov and barrier functions) for
dynamical systems modelled as ordinary differential and difference equations.
Fossil 2.0 is much improved from its original release, including new
interfaces, a significantly expanded certificate portfolio, controller
synthesis and enhanced extensibility. We present these new features as part of
this tool paper. Fossil implements a counterexample-guided inductive synthesis
(CEGIS) loop ensuring the soundness of the method. Our tool uses neural
networks as templates to generate candidate functions, which are then formally
proven by an SMT solver acting as an assertion verifier. Improvements with
respect to the first release include a wider range of certificates, synthesis
of control laws, and support for discrete-time models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09809">Comparing Differentiable Logics for Learning Systems: A Research Preview. (arXiv:2311.09809v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Flinkow_T/0/1/0/all/0/1">Thomas Flinkow</a> (Maynooth University), <a href="http://arxiv.org/find/cs/1/au:+Pearlmutter_B/0/1/0/all/0/1">Barak A. Pearlmutter</a> (Maynooth University), <a href="http://arxiv.org/find/cs/1/au:+Monahan_R/0/1/0/all/0/1">Rosemary Monahan</a> (Maynooth University)</p>
<p>Extensive research on formal verification of machine learning (ML) systems
indicates that learning from data alone often fails to capture underlying
background knowledge. A variety of verifiers have been developed to ensure that
a machine-learnt model satisfies correctness and safety properties, however,
these verifiers typically assume a trained network with fixed weights.
ML-enabled autonomous systems are required to not only detect incorrect
predictions, but should also possess the ability to self-correct, continuously
improving and adapting. A promising approach for creating ML models that
inherently satisfy constraints is to encode background knowledge as logical
constraints that guide the learning process via so-called differentiable
logics. In this research preview, we compare and evaluate various logics from
the literature in weakly-supervised contexts, presenting our findings and
highlighting open problems for future work. Our experimental results are
broadly consistent with results reported previously in literature; however,
learning with differentiable logics introduces a new hyperparameter that is
difficult to tune and has significant influence on the effectiveness of the
logics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09811">Runtime Verification of Learning Properties for Reinforcement Learning Algorithms. (arXiv:2311.09811v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mannucci_T/0/1/0/all/0/1">Tommaso Mannucci</a> (TNO -- Netherlands Organisation for Applied Scientific Research), <a href="http://arxiv.org/find/cs/1/au:+Filho_J/0/1/0/all/0/1">Julio de Oliveira Filho</a> (TNO -- Netherlands Organisation for Applied Scientific Research)</p>
<p>Reinforcement learning (RL) algorithms interact with their environment in a
trial-and-error fashion. Such interactions can be expensive, inefficient, and
timely when learning on a physical system rather than in a simulation. This
work develops new runtime verification techniques to predict when the learning
phase has not met or will not meet qualitative and timely expectations. This
paper presents three verification properties concerning the quality and
timeliness of learning in RL algorithms. With each property, we propose design
steps for monitoring and assessing the properties during the system's
operation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09816">Performance Trade-offs of Watermarking Large Language Models. (arXiv:2311.09816v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1">Anirudh Ajith</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1">Danish Pruthi</a></p>
<p>Amidst growing concerns of large language models (LLMs) being misused for
generating misinformation or completing homework assignments, watermarking has
emerged as an effective solution for distinguishing human-written and
LLM-generated text. A prominent watermarking strategy is to embed a signal into
generated text by upsampling a (pseudorandomly-chosen) subset of tokens at
every generation step. Although this signal is imperceptible to a human reader,
it is detectable through statistical testing. However, implanting such signals
alters the model's output distribution and can have unintended effects when
watermarked LLMs are used for downstream applications. In this work, we
evaluate the performance of watermarked LLMs on a diverse suite of tasks,
including text classification, textual entailment, reasoning, question
answering, translation, summarization, and language modeling. We find that
watermarking has negligible impact on the performance of tasks posed as k-class
classification problems in the average case. However, the accuracy can plummet
to that of a random classifier for some scenarios (that occur with
non-negligible probability). Tasks that are cast as multiple-choice questions
and short-form generation are surprisingly unaffected by watermarking. For
long-form generation tasks, including summarization and translation, we see a
drop of 15-20% in the performance due to watermarking. Our findings highlight
the trade-offs that users should be cognizant of when using watermarked models,
and point to cases where future research could improve existing trade-offs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09819">PWISeg: Point-based Weakly-supervised Instance Segmentation for Surgical Instruments. (arXiv:2311.09819v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jinlin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1">Zhen Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongbin Liu</a></p>
<p>In surgical procedures, correct instrument counting is essential. Instance
segmentation is a location method that locates not only an object's bounding
box but also each pixel's specific details. However, obtaining mask-level
annotations is labor-intensive in instance segmentation. To address this issue,
we propose a novel yet effective weakly-supervised surgical instrument instance
segmentation approach, named Point-based Weakly-supervised Instance
Segmentation (PWISeg). PWISeg adopts an FCN-based architecture with
point-to-box and point-to-mask branches to model the relationships between
feature points and bounding boxes, as well as feature points and segmentation
masks on FPN, accomplishing instrument detection and segmentation jointly in a
single model. Since mask level annotations are hard to available in the real
world, for point-to-mask training, we introduce an unsupervised projection
loss, utilizing the projected relation between predicted masks and bboxes as
supervision signal. On the other hand, we annotate a few pixels as the key
pixel for each instrument. Based on this, we further propose a key pixel
association loss and a key pixel distribution loss, driving the point-to-mask
branch to generate more accurate segmentation predictions. To comprehensively
evaluate this task, we unveil a novel surgical instrument dataset with manual
annotations, setting up a benchmark for further research. Our comprehensive
research trial validated the superior performance of our PWISeg. The results
show that the accuracy of surgical instrument segmentation is improved,
surpassing most methods of instance segmentation via weakly supervised bounding
boxes. This improvement is consistently observed in our proposed dataset and
when applied to the public HOSPI-Tools dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09841">Leveraging LLMs in Scholarly Knowledge Graph Question Answering. (arXiv:2311.09841v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Taffa_T/0/1/0/all/0/1">Tilahun Abedissa Taffa</a>, <a href="http://arxiv.org/find/cs/1/au:+Usbeck_R/0/1/0/all/0/1">Ricardo Usbeck</a></p>
<p>This paper presents a scholarly Knowledge Graph Question Answering (KGQA)
that answers bibliographic natural language questions by leveraging a large
language model (LLM) in a few-shot manner. The model initially identifies the
top-n similar training questions related to a given test question via a
BERT-based sentence encoder and retrieves their corresponding SPARQL. Using the
top-n similar question-SPARQL pairs as an example and the test question creates
a prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs
the SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and
returns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of
the Scholarly-QALD-23 challenge benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09846">GroupMixer: Patch-based Group Convolutional Neural Network for Breast Cancer Detection from Histopathological Images. (arXiv:2311.09846v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Modarres_A/0/1/0/all/0/1">Ardavan Modarres</a>, <a href="http://arxiv.org/find/eess/1/au:+Esfahani_E/0/1/0/all/0/1">Erfan Ebrahim Esfahani</a>, <a href="http://arxiv.org/find/eess/1/au:+Bahrami_M/0/1/0/all/0/1">Mahsa Bahrami</a></p>
<p>Diagnosis of breast cancer malignancy at the early stages is a crucial step
for controlling its side effects. Histopathological analysis provides a unique
opportunity for malignant breast cancer detection. However, such a task would
be tedious and time-consuming for the histopathologists. Deep Neural Networks
enable us to learn informative features directly from raw histopathological
images without manual feature extraction. Although Convolutional Neural
Networks (CNNs) have been the dominant architectures in the computer vision
realm, Transformer-based architectures have shown promising results in
different computer vision tasks. Although harnessing the capability of
Transformer-based architectures for medical image analysis seems interesting,
these architectures are large, have a significant number of trainable
parameters, and require large datasets to be trained on, which are usually rare
in the medical domain. It has been claimed and empirically proved that at least
part of the superior performance of Transformer-based architectures in Computer
Vision domain originates from patch embedding operation. In this paper, we
borrowed the previously introduced idea of integrating a fully Convolutional
Neural Network architecture with Patch Embedding operation and presented an
efficient CNN architecture for breast cancer malignancy detection from
histopathological images. Despite the number of parameters that is
significantly smaller than other methods, the accuracy performance metrics
achieved 97.65%, 98.92%, 99.21%, and 98.01% for 40x, 100x, 200x, and 400x
magnifications respectively. We took a step forward and modified the
architecture using Group Convolution and Channel Shuffling ideas and reduced
the number of trainable parameters even more with a negligible decline in
performance and achieved 95.42%, 98.16%, 96.05%, and 97.92% accuracy for the
mentioned magnifications respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09847">Overcoming Data Scarcity in Biomedical Imaging with a Foundational Multi-Task Model. (arXiv:2311.09847v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schafer_R/0/1/0/all/0/1">Raphael Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicke_T/0/1/0/all/0/1">Till Nicke</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofener_H/0/1/0/all/0/1">Henning H&#xf6;fener</a>, <a href="http://arxiv.org/find/cs/1/au:+Lange_A/0/1/0/all/0/1">Annkristin Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1">Dorit Merhof</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuerhake_F/0/1/0/all/0/1">Friedrich Feuerhake</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulz_V/0/1/0/all/0/1">Volkmar Schulz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotz_J/0/1/0/all/0/1">Johannes Lotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiessling_F/0/1/0/all/0/1">Fabian Kiessling</a></p>
<p>Foundational models, pretrained on a large scale, have demonstrated
substantial success across non-medical domains. However, training these models
typically requires large, comprehensive datasets, which contrasts with the
smaller and more heterogeneous datasets common in biomedical imaging. Here, we
propose a multi-task learning strategy that decouples the number of training
tasks from memory requirements. We trained a Universal bioMedical PreTrained
model (UMedPT) on a multi-task database including tomographic, microscopic, and
X-ray images, with various labelling strategies such as classification,
segmentation, and object detection. The UMedPT foundational model outperformed
ImageNet pretraining and the previous state-of-the-art models. For tasks
related to the pretraining database, it maintained its performance with only 1%
of the original training data and without fine-tuning. For out-of-domain tasks
it required not more than 50% of the original training data. In an external
independent validation imaging features extracted using UMedPT proved to be a
new standard for cross-center transferability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09848">Diffusion-Augmented Neural Processes. (arXiv:2311.09848v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bonito_L/0/1/0/all/0/1">Lorenzo Bonito</a>, <a href="http://arxiv.org/find/cs/1/au:+Requeima_J/0/1/0/all/0/1">James Requeima</a>, <a href="http://arxiv.org/find/cs/1/au:+Shysheya_A/0/1/0/all/0/1">Aliaksandra Shysheya</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1">Richard E. Turner</a></p>
<p>Over the last few years, Neural Processes have become a useful modelling tool
in many application areas, such as healthcare and climate sciences, in which
data are scarce and prediction uncertainty estimates are indispensable.
However, the current state of the art in the field (AR CNPs; Bruinsma et al.,
2023) presents a few issues that prevent its widespread deployment. This work
proposes an alternative, diffusion-based approach to NPs which, through
conditioning on noised datasets, addresses many of these limitations, whilst
also exceeding SOTA performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09852">Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning. (arXiv:2311.09852v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chuhao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pournaras_E/0/1/0/all/0/1">Evangelos Pournaras</a></p>
<p>Swarms of smart drones, with the support of charging technology, can provide
completing sensing capabilities in Smart Cities, such as traffic monitoring and
disaster response. Existing approaches, including distributed optimization and
deep reinforcement learning (DRL), aim to coordinate drones to achieve
cost-effective, high-quality navigation, sensing, and recharging. However, they
have distinct challenges: short-term optimization struggles to provide
sustained benefits, while long-term DRL lacks scalability, resilience, and
flexibility. To bridge this gap, this paper introduces a new progressive
approach that encompasses the planning and selection based on distributed
optimization, as well as DRL-based flying direction scheduling. Extensive
experiment with datasets generated from realisitic urban mobility demonstrate
the outstanding performance of the proposed solution in traffic monitoring
compared to three baseline methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09854">SurvTimeSurvival: Survival Analysis On The Patient With Multiple Visits/Records. (arXiv:2311.09854v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Eng_Jon_O/0/1/0/all/0/1">Ong Eng-Jon</a>, <a href="http://arxiv.org/find/cs/1/au:+Miroslaw_B/0/1/0/all/0/1">Bober Miroslaw</a></p>
<p>The accurate prediction of survival times for patients with severe diseases
remains a critical challenge despite recent advances in artificial
intelligence. This study introduces "SurvTimeSurvival: Survival Analysis On
Patients With Multiple Visits/Records", utilizing the Transformer model to not
only handle the complexities of time-varying covariates but also covariates
data. We also tackle the data sparsity issue common to survival analysis
datasets by integrating synthetic data generation into the learning process of
our model. We show that our method outperforms state-of-the-art deep learning
approaches on both covariates and time-varying covariates datasets. Our
approach aims not only to enhance the understanding of individual patient
survival trajectories across various medical conditions, thereby improving
prediction accuracy, but also to play a pivotal role in designing clinical
trials and creating new treatments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09856">Contribution Evaluation in Federated Learning: Examining Current Approaches. (arXiv:2311.09856v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Siomos_V/0/1/0/all/0/1">Vasilis Siomos</a>, <a href="http://arxiv.org/find/cs/1/au:+Passerat_Palmbach_J/0/1/0/all/0/1">Jonathan Passerat-Palmbach</a></p>
<p>Federated Learning (FL) has seen increasing interest in cases where entities
want to collaboratively train models while maintaining privacy and governance
over their data. In FL, clients with private and potentially heterogeneous data
and compute resources come together to train a common model without raw data
ever leaving their locale. Instead, the participants contribute by sharing
local model updates, which, naturally, differ in quality. Quantitatively
evaluating the worth of these contributions is termed the Contribution
Evaluation (CE) problem. We review current CE approaches from the underlying
mathematical framework to efficiently calculate a fair value for each client.
Furthermore, we benchmark some of the most promising state-of-the-art
approaches, along with a new one we introduce, on MNIST and CIFAR-10, to
showcase their differences. Designing a fair and efficient CE method, while a
small part of the overall FL system design, is tantamount to the mainstream
adoption of FL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09858">Polynomially Over-Parameterized Convolutional Neural Networks Contain Structured Strong Winning Lottery Tickets. (arXiv:2311.09858v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cunha_A/0/1/0/all/0/1">Arthur da Cunha</a>, <a href="http://arxiv.org/find/cs/1/au:+dAmore_F/0/1/0/all/0/1">Francesco d&#x27;Amore</a>, <a href="http://arxiv.org/find/cs/1/au:+Natale_E/0/1/0/all/0/1">Emanuele Natale</a></p>
<p>The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialised
neural networks likely contain subnetworks that perform well without any
training. Although unstructured pruning has been extensively studied in this
context, its structured counterpart, which can deliver significant
computational and memory efficiency gains, has been largely unexplored. One of
the main reasons for this gap is the limitations of the underlying mathematical
tools used in formal analyses of the SLTH. In this paper, we overcome these
limitations: we leverage recent advances in the multidimensional generalisation
of the Random Subset-Sum Problem and obtain a variant that admits the
stochastic dependencies that arise when addressing structured pruning in the
SLTH. We apply this result to prove, for a wide class of random Convolutional
Neural Networks, the existence of structured subnetworks that can approximate
any sufficiently smaller network.
</p>
<p>This result provides the first sub-exponential bound around the SLTH for
structured pruning, opening up new avenues for further research on the
hypothesis and contributing to the understanding of the role of
over-parameterization in deep learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09878">Safety Aware Autonomous Path Planning Using Model Predictive Reinforcement Learning for Inland Waterways. (arXiv:2311.09878v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vanneste_A/0/1/0/all/0/1">Astrid Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanneste_S/0/1/0/all/0/1">Simon Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasseur_O/0/1/0/all/0/1">Olivier Vasseur</a>, <a href="http://arxiv.org/find/cs/1/au:+Janssens_R/0/1/0/all/0/1">Robin Janssens</a>, <a href="http://arxiv.org/find/cs/1/au:+Billast_M/0/1/0/all/0/1">Mattias Billast</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1">Ali Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mets_K/0/1/0/all/0/1">Kevin Mets</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_T/0/1/0/all/0/1">Tom De Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercelis_S/0/1/0/all/0/1">Siegfried Mercelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellinckx_P/0/1/0/all/0/1">Peter Hellinckx</a></p>
<p>In recent years, interest in autonomous shipping in urban waterways has
increased significantly due to the trend of keeping cars and trucks out of city
centers. Classical approaches such as Frenet frame based planning and potential
field navigation often require tuning of many configuration parameters and
sometimes even require a different configuration depending on the situation. In
this paper, we propose a novel path planning approach based on reinforcement
learning called Model Predictive Reinforcement Learning (MPRL). MPRL calculates
a series of waypoints for the vessel to follow. The environment is represented
as an occupancy grid map, allowing us to deal with any shape of waterway and
any number and shape of obstacles. We demonstrate our approach on two scenarios
and compare the resulting path with path planning using a Frenet frame and path
planning based on a proximal policy optimization (PPO) agent. Our results show
that MPRL outperforms both baselines in both test scenarios. The PPO based
approach was not able to reach the goal in either scenario while the Frenet
frame approach failed in the scenario consisting of a corner with obstacles.
MPRL was able to safely (collision free) navigate to the goal in both of the
test scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09891">On some elusive aspects of databases hindering AI based discovery: A case study on superconducting materials. (arXiv:2311.09891v1 [cond-mat.other])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Trezza_G/0/1/0/all/0/1">Giovanni Trezza</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Chiavazzo_E/0/1/0/all/0/1">Eliodoro Chiavazzo</a></p>
<p>It stands to reason that the amount and the quality of big data is of key
importance for setting up accurate AI-driven models. Nonetheless, we believe
there are still critical roadblocks in the inherent generation of databases,
that are often underestimated and poorly discussed in the literature. In our
view, such issues can seriously hinder the AI-based discovery process, even
when high quality, sufficiently large and highly reputable data sources are
available. Here, considering superconducting and thermoelectric materials as
two representative case studies, we specifically discuss three aspects, namely
intrinsically biased sample selection, possible hidden variables, disparate
data age. Importantly, to our knowledge, we suggest and test a first strategy
capable of detecting and quantifying the presence of the intrinsic data bias.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09922">Fast multiplication by two&#x27;s complement addition of numbers represented as a set of polynomial radix 2 indexes, stored as an integer list for massively parallel computation. (arXiv:2311.09922v1 [cs.MS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stocks_M/0/1/0/all/0/1">Mark Stocks</a></p>
<p>We demonstrate a multiplication method based on numbers represented as set of
polynomial radix 2 indices stored as an integer list. The 'polynomial integer
index multiplication' method is a set of algorithms implemented in python code.
We demonstrate the method to be faster than both the Number Theoretic Transform
(NTT) and Karatsuba for multiplication within a certain bit range. Also
implemented in python code for comparison purposes with the polynomial radix 2
integer method. We demonstrate that it is possible to express any integer or
real number as a list of integer indices, representing a finite series in base
two. The finite series of integer index representation of a number can then be
stored and distributed across multiple CPUs / GPUs. We show that operations of
addition and multiplication can be applied as two's complement additions
operating on the index integer representations and can be fully distributed
across a given CPU / GPU architecture. We demonstrate fully distributed
arithmetic operations such that the 'polynomial integer index multiplication'
method overcomes the current limitation of parallel multiplication methods. Ie,
the need to share common core memory and common disk for the calculation of
results and intermediate results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09930">A Framework for Monitoring and Retraining Language Models in Real-World Applications. (arXiv:2311.09930v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kasundra_J/0/1/0/all/0/1">Jaykumar Kasundra</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulz_C/0/1/0/all/0/1">Claudia Schulz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirsafian_M/0/1/0/all/0/1">Melicaalsadat Mirsafian</a>, <a href="http://arxiv.org/find/cs/1/au:+Skylaki_S/0/1/0/all/0/1">Stavroula Skylaki</a></p>
<p>In the Machine Learning (ML) model development lifecycle, training candidate
models using an offline holdout dataset and identifying the best model for the
given task is only the first step. After the deployment of the selected model,
continuous model monitoring and model retraining is required in many real-world
applications. There are multiple reasons for retraining, including data or
concept drift, which may be reflected on the model performance as monitored by
an appropriate metric. Another motivation for retraining is the acquisition of
increasing amounts of data over time, which may be used to retrain and improve
the model performance even in the absence of drifts. We examine the impact of
various retraining decision points on crucial factors, such as model
performance and resource utilization, in the context of Multilabel
Classification models. We explain our key decision points and propose a
reference framework for designing an effective model retraining strategy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09947">Natural Disaster Analysis using Satellite Imagery and Social-Media Data for Emergency Response Situations. (arXiv:2311.09947v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mandyam_S/0/1/0/all/0/1">Sukeerthi Mandyam</a>, <a href="http://arxiv.org/find/cs/1/au:+MG_S/0/1/0/all/0/1">Shanmuga Priya MG</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1">Shalini Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_K/0/1/0/all/0/1">Kavitha Srinivasan</a></p>
<p>Disaster Management is one of the most promising research areas because of
its significant economic, environmental and social repercussions. This research
focuses on analyzing different types of data (pre and post satellite images and
twitter data) related to disaster management for in-depth analysis of
location-wise emergency requirements. This research has been divided into two
stages, namely, satellite image analysis and twitter data analysis followed by
integration using location. The first stage involves pre and post disaster
satellite image analysis of the location using multi-class land cover
segmentation technique based on U-Net architecture. The second stage focuses on
mapping the region with essential information about the disaster situation and
immediate requirements for relief operations. The severely affected regions are
demarcated and twitter data is extracted using keywords respective to that
location. The extraction of situational information from a large corpus of raw
tweets adopts Content Word based Tweet Summarization (COWTS) technique. An
integration of these modules using real-time location-based mapping and
frequency analysis technique gathers multi-dimensional information in the
advent of disaster occurrence such as the Kerala and Mississippi floods that
were analyzed and validated as test cases. The novelty of this research lies in
the application of segmented satellite images for disaster relief using
highlighted land cover changes and integration of twitter data by mapping these
region-specific filters for obtaining a complete overview of the disaster.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09948">Hijacking Large Language Models via Adversarial In-Context Learning. (arXiv:2311.09948v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiang_Y/0/1/0/all/0/1">Yao Qiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiangyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dongxiao Zhu</a></p>
<p>In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMs
for specific tasks by utilizing labeled examples as demonstrations in the
precondition prompts. Despite its promising performance, ICL suffers from
instability with the choice and arrangement of examples. Additionally, crafted
adversarial attacks pose a notable threat to the robustness of ICL. However,
existing attacks are either easy to detect, rely on external models, or lack
specificity towards ICL. To address these issues, this work introduces a novel
transferable attack for ICL, aiming to hijack LLMs to generate the targeted
response. The proposed LLM hijacking attack leverages a gradient-based prompt
search method to learn and append imperceptible adversarial suffixes to the
in-context demonstrations. Extensive experimental results on various tasks and
datasets demonstrate the effectiveness of our LLM hijacking attack, resulting
in a distracted attention towards adversarial tokens, consequently leading to
the targeted unwanted outputs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09952">Score-based generative models learn manifold-like structures with constrained mixing. (arXiv:2311.09952v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wenliang_L/0/1/0/all/0/1">Li Kevin Wenliang</a>, <a href="http://arxiv.org/find/stat/1/au:+Moran_B/0/1/0/all/0/1">Ben Moran</a></p>
<p>How do score-based generative models (SBMs) learn the data distribution
supported on a low-dimensional manifold? We investigate the score model of a
trained SBM through its linear approximations and subspaces spanned by local
feature vectors. During diffusion as the noise decreases, the local
dimensionality increases and becomes more varied between different sample
sequences. Importantly, we find that the learned vector field mixes samples by
a non-conservative field within the manifold, although it denoises with normal
projections as if there is an energy function in off-manifold directions. At
each noise level, the subspace spanned by the local features overlap with an
effective density function. These observations suggest that SBMs can flexibly
mix samples with the learned score field while carefully maintaining a
manifold-like structure of the data distribution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09962">Self-supervised learning of multi-omics embeddings in the low-label, high-data regime. (arXiv:2311.09962v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hurry_C/0/1/0/all/0/1">Christian John Hurry</a>, <a href="http://arxiv.org/find/cs/1/au:+Slade_E/0/1/0/all/0/1">Emma Slade</a></p>
<p>Contrastive, self-supervised learning (SSL) is used to train a model that
predicts cancer type from miRNA, mRNA or RPPA expression data. This model, a
pretrained FT-Transformer, is shown to outperform XGBoost and CatBoost,
standard benchmarks for tabular data, when labelled samples are scarce but the
number of unlabelled samples is high. This is despite the fact that the
datasets we use have $\mathcal{O}(10^{1})$ classes and
$\mathcal{O}(10^{2})-\mathcal{O}(10^{4})$ features. After demonstrating the
efficacy of our chosen method of self-supervised pretraining, we investigate
SSL for multi-modal models. A late-fusion model is proposed, where each omics
is passed through its own sub-network, the outputs of which are averaged and
passed to the pretraining or downstream objective function. Multi-modal
pretraining is shown to improve predictions from a single omics, and we argue
that this is useful for datasets with many unlabelled multi-modal samples, but
few labelled unimodal samples. Additionally, we show that pretraining each
omics-specific module individually is highly effective. This enables the
application of the proposed model in a variety of contexts where a large amount
of unlabelled data is available from each omics, but only a few labelled
samples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09965">SurgPLAN: Surgical Phase Localization Network for Phase Recognition. (arXiv:2311.09965v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xingjian Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">You Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jinlin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zongmin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1">Zhen Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongbin Liu</a></p>
<p>Surgical phase recognition is crucial to providing surgery understanding in
smart operating rooms. Despite great progress in automatic surgical phase
recognition, most existing methods are still restricted by two problems. First,
these methods cannot capture discriminative visual features for each frame and
motion information with simple 2D networks. Second, the frame-by-frame
recognition paradigm degrades the performance due to unstable predictions
within each phase, termed as phase shaking. To address these two challenges, we
propose a Surgical Phase LocAlization Network, named SurgPLAN, to facilitate a
more accurate and stable surgical phase recognition with the principle of
temporal detection. Specifically, we first devise a Pyramid SlowFast (PSF)
architecture to serve as the visual backbone to capture multi-scale spatial and
temporal features by two branches with different frame sampling rates.
Moreover, we propose a Temporal Phase Localization (TPL) module to generate the
phase prediction based on temporal region proposals, which ensures accurate and
consistent predictions within each surgical phase. Extensive experiments
confirm the significant advantages of our SurgPLAN over frame-by-frame
approaches in terms of both accuracy and stability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09989">Xputer: Bridging Data Gaps with NMF, XGBoost, and a Streamlined GUI Experience. (arXiv:2311.09989v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Younus_S/0/1/0/all/0/1">Saleena Younus</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronnstrand_L/0/1/0/all/0/1">Lars R&#xf6;nnstrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazi_J/0/1/0/all/0/1">Julhash U. Kazi</a></p>
<p>The rapid proliferation of data across diverse fields has accentuated the
importance of accurate imputation for missing values. This task is crucial for
ensuring data integrity and deriving meaningful insights. In response to this
challenge, we present Xputer, a novel imputation tool that adeptly integrates
Non-negative Matrix Factorization (NMF) with the predictive strengths of
XGBoost. One of Xputer's standout features is its versatility: it supports zero
imputation, enables hyperparameter optimization through Optuna, and allows
users to define the number of iterations. For enhanced user experience and
accessibility, we have equipped Xputer with an intuitive Graphical User
Interface (GUI) ensuring ease of handling, even for those less familiar with
computational tools. In performance benchmarks, Xputer not only rivals the
computational speed of established tools such as IterativeImputer but also
often outperforms them in terms of imputation accuracy. Furthermore, Xputer
autonomously handles a diverse spectrum of data types, including categorical,
continuous, and Boolean, eliminating the need for prior preprocessing. Given
its blend of performance, flexibility, and user-friendly design, Xputer emerges
as a state-of-the-art solution in the realm of data imputation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09997">Co-data Learning for Bayesian Additive Regression Trees. (arXiv:2311.09997v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Goedhart_J/0/1/0/all/0/1">Jeroen M. Goedhart</a>, <a href="http://arxiv.org/find/stat/1/au:+Klausch_T/0/1/0/all/0/1">Thomas Klausch</a>, <a href="http://arxiv.org/find/stat/1/au:+Janssen_J/0/1/0/all/0/1">Jurriaan Janssen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wiel_M/0/1/0/all/0/1">Mark A. van de Wiel</a></p>
<p>Medical prediction applications often need to deal with small sample sizes
compared to the number of covariates. Such data pose problems for prediction
and variable selection, especially when the covariate-response relationship is
complicated. To address these challenges, we propose to incorporate co-data,
i.e. external information on the covariates, into Bayesian additive regression
trees (BART), a sum-of-trees prediction model that utilizes priors on the tree
parameters to prevent overfitting. To incorporate co-data, an empirical Bayes
(EB) framework is developed that estimates, assisted by a co-data model, prior
covariate weights in the BART model. The proposed method can handle multiple
types of co-data simultaneously. Furthermore, the proposed EB framework enables
the estimation of the other hyperparameters of BART as well, rendering an
appealing alternative to cross-validation. We show that the method finds
relevant covariates and that it improves prediction compared to default BART in
simulations. If the covariate-response relationship is nonlinear, the method
benefits from the flexibility of BART to outperform regression-based co-data
learners. Finally, the use of co-data enhances prediction in an application to
diffuse large B-cell lymphoma prognosis based on clinical covariates, gene
mutations, DNA translocations, and DNA copy number data.
</p>
<p>Keywords: Bayesian additive regression trees; Empirical Bayes; Co-data;
High-dimensional data; Omics; Prediction
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09998">DeepEMD: A Transformer-based Fast Estimation of the Earth Mover&#x27;s Distance. (arXiv:2311.09998v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1">Atul Kumar Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleuret_F/0/1/0/all/0/1">Francois Fleuret</a></p>
<p>The Earth Mover's Distance (EMD) is the measure of choice between point
clouds. However the computational cost to compute it makes it prohibitive as a
training loss, and the standard approach is to use a surrogate such as the
Chamfer distance. We propose an attention-based model to compute an accurate
approximation of the EMD that can be used as a training loss for generative
models. To get the necessary accurate estimation of the gradients we train our
model to explicitly compute the matching between point clouds instead of EMD
itself. We cast this new objective as the estimation of an attention matrix
that approximates the ground truth matching matrix. Experiments show that this
model provides an accurate estimate of the EMD and its gradient with a wall
clock speed-up of more than two orders of magnitude with respect to the exact
Hungarian matching algorithm and one order of magnitude with respect to the
standard approximate Sinkhorn algorithm, allowing in particular to train a
point cloud VAE with the EMD itself. Extensive evaluation show the remarkable
behaviour of this model when operating out-of-distribution, a key requirement
for a distance surrogate. Finally, the model generalizes very well to point
clouds during inference several times larger than during training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.10002">Straggler-resilient Federated Learning: Tackling Computation Heterogeneity with Layer-wise Partial Model Training in Mobile Edge Network. (arXiv:2311.10002v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongda Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Ping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayana_C/0/1/0/all/0/1">C V Aswartha Narayana</a></p>
<p>Federated Learning (FL) enables many resource-limited devices to train a
model collaboratively without data sharing. However, many existing works focus
on model-homogeneous FL, where the global and local models are the same size,
ignoring the inherently heterogeneous computational capabilities of different
devices and restricting resource-constrained devices from contributing to FL.
In this paper, we consider model-heterogeneous FL and propose Federated Partial
Model Training (FedPMT), where devices with smaller computational capabilities
work on partial models (subsets of the global model) and contribute to the
global model. Different from Dropout-based partial model generation, which
removes neurons in hidden layers at random, model training in FedPMT is
achieved from the back-propagation perspective. As such, all devices in FedPMT
prioritize the most crucial parts of the global model. Theoretical analysis
shows that the proposed partial model training design has a similar convergence
rate to the widely adopted Federated Averaging (FedAvg) algorithm,
$\mathcal{O}(1/T)$, with the sub-optimality gap enlarged by a constant factor
related to the model splitting design in FedPMT. Empirical results show that
FedPMT significantly outperforms the existing benchmark FedDrop. Meanwhile,
compared to the popular model-homogeneous benchmark, FedAvg, FedPMT reaches the
learning target in a shorter completion time, thus achieving a better trade-off
between learning accuracy and completion time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2104.12679">Impact of Spatial Frequency Based Constraints on Adversarial Robustness. (arXiv:2104.12679v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bernhard_R/0/1/0/all/0/1">R&#xe9;mi Bernhard</a>, <a href="http://arxiv.org/find/cs/1/au:+Moellic_P/0/1/0/all/0/1">Pierre-Alain Moellic</a>, <a href="http://arxiv.org/find/cs/1/au:+Mermillod_M/0/1/0/all/0/1">Martial Mermillod</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourrier_Y/0/1/0/all/0/1">Yannick Bourrier</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohendet_R/0/1/0/all/0/1">Romain Cohendet</a>, <a href="http://arxiv.org/find/cs/1/au:+Solinas_M/0/1/0/all/0/1">Miguel Solinas</a>, <a href="http://arxiv.org/find/cs/1/au:+Reyboz_M/0/1/0/all/0/1">Marina Reyboz</a></p>
<p>Adversarial examples mainly exploit changes to input pixels to which humans
are not sensitive to, and arise from the fact that models make decisions based
on uninterpretable features. Interestingly, cognitive science reports that the
process of interpretability for human classification decision relies
predominantly on low spatial frequency components. In this paper, we
investigate the robustness to adversarial perturbations of models enforced
during training to leverage information corresponding to different spatial
frequency ranges. We show that it is tightly linked to the spatial frequency
characteristics of the data at stake. Indeed, depending on the data set, the
same constraint may results in very different level of robustness (up to 0.41
adversarial accuracy difference). To explain this phenomenon, we conduct
several experiments to enlighten influential factors such as the level of
sensitivity to high frequencies, and the transferability of adversarial
perturbations between original and low-pass filtered inputs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.03178">Student of Games: A unified learning algorithm for both perfect and imperfect information games. (arXiv:2112.03178v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schmid_M/0/1/0/all/0/1">Martin Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Moravcik_M/0/1/0/all/0/1">Matej Moravcik</a>, <a href="http://arxiv.org/find/cs/1/au:+Burch_N/0/1/0/all/0/1">Neil Burch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadlec_R/0/1/0/all/0/1">Rudolf Kadlec</a>, <a href="http://arxiv.org/find/cs/1/au:+Davidson_J/0/1/0/all/0/1">Josh Davidson</a>, <a href="http://arxiv.org/find/cs/1/au:+Waugh_K/0/1/0/all/0/1">Kevin Waugh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bard_N/0/1/0/all/0/1">Nolan Bard</a>, <a href="http://arxiv.org/find/cs/1/au:+Timbers_F/0/1/0/all/0/1">Finbarr Timbers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanctot_M/0/1/0/all/0/1">Marc Lanctot</a>, <a href="http://arxiv.org/find/cs/1/au:+Holland_G/0/1/0/all/0/1">G. Zacharias Holland</a>, <a href="http://arxiv.org/find/cs/1/au:+Davoodi_E/0/1/0/all/0/1">Elnaz Davoodi</a>, <a href="http://arxiv.org/find/cs/1/au:+Christianson_A/0/1/0/all/0/1">Alden Christianson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowling_M/0/1/0/all/0/1">Michael Bowling</a></p>
<p>Games have a long history as benchmarks for progress in artificial
intelligence. Approaches using search and learning produced strong performance
across many perfect information games, and approaches using game-theoretic
reasoning and learning demonstrated strong performance for specific imperfect
information poker variants. We introduce Student of Games, a general-purpose
algorithm that unifies previous approaches, combining guided search, self-play
learning, and game-theoretic reasoning. Student of Games achieves strong
empirical performance in large perfect and imperfect information games -- an
important step towards truly general algorithms for arbitrary environments. We
prove that Student of Games is sound, converging to perfect play as available
computation and approximation capacity increases. Student of Games reaches
strong performance in chess and Go, beats the strongest openly available agent
in heads-up no-limit Texas hold'em poker, and defeats the state-of-the-art
agent in Scotland Yard, an imperfect information game that illustrates the
value of guided search, learning, and game-theoretic reasoning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.00292">Fair Data Representation for Machine Learning at the Pareto Frontier. (arXiv:2201.00292v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Xu_S/0/1/0/all/0/1">Shizhou Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Strohmer_T/0/1/0/all/0/1">Thomas Strohmer</a></p>
<p>As machine learning powered decision-making becomes increasingly important in
our daily lives, it is imperative to strive for fairness in the underlying data
processing. We propose a pre-processing algorithm for fair data representation
via which supervised learning results in estimations of the Pareto frontier
between prediction error and statistical disparity. Particularly, the present
work applies the optimal affine transport to approach the post-processing
Wasserstein-2 barycenter characterization of the optimal fair $L^2$-objective
supervised learning via a pre-processing data deformation. Furthermore, we show
that the Wasserstein-2 geodesics from the conditional (on sensitive
information) distributions of the learning outcome to their barycenter
characterizes the Pareto frontier between $L^2$-loss and the average pairwise
Wasserstein-2 distance among sensitive groups on the learning outcome.
Numerical simulations underscore the advantages: (1) the pre-processing step is
compositive with arbitrary conditional expectation estimation supervised
learning methods and unseen data; (2) the fair representation protects the
sensitive information by limiting the inference capability of the remaining
data with respect to the sensitive data; (3) the optimal affine maps are
computationally efficient even for high-dimensional data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.03397">Bilevel Optimization with a Lower-level Contraction: Optimal Sample Complexity without Warm-start. (arXiv:2202.03397v4 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Grazzi_R/0/1/0/all/0/1">Riccardo Grazzi</a>, <a href="http://arxiv.org/find/stat/1/au:+Pontil_M/0/1/0/all/0/1">Massimiliano Pontil</a>, <a href="http://arxiv.org/find/stat/1/au:+Salzo_S/0/1/0/all/0/1">Saverio Salzo</a></p>
<p>We analyse a general class of bilevel problems, in which the upper-level
problem consists in the minimization of a smooth objective function and the
lower-level problem is to find the fixed point of a smooth contraction map.
This type of problems include instances of meta-learning, equilibrium models,
hyperparameter optimization and data poisoning adversarial attacks. Several
recent works have proposed algorithms which warm-start the lower-level problem,
i.e.~they use the previous lower-level approximate solution as a staring point
for the lower-level solver. This warm-start procedure allows one to improve the
sample complexity in both the stochastic and deterministic settings, achieving
in some cases the order-wise optimal sample complexity. However, there are
situations, e.g., meta learning and equilibrium models, in which the warm-start
procedure is not well-suited or ineffective. In this work we show that without
warm-start, it is still possible to achieve order-wise (near) optimal sample
complexity. In particular, we propose a simple method which uses (stochastic)
fixed point iterations at the lower-level and projected inexact gradient
descent at the upper-level, that reaches an $\epsilon$-stationary point using
$O(\epsilon^{-2})$ and $\tilde{O}(\epsilon^{-1})$ samples for the stochastic
and the deterministic setting, respectively. Finally, compared to methods using
warm-start, our approach yields a simpler analysis that does not need to study
the coupled interactions between the upper-level and lower-level iterates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.10367">Probabilities of the third type: Statistical Relational Learning and Reasoning with Relative Frequencies. (arXiv:2202.10367v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weitkamper_F/0/1/0/all/0/1">Felix Weitk&#xe4;mper</a></p>
<p>Dependencies on the relative frequency of a state in the domain are common
when modelling probabilistic dependencies on relational data. For instance, the
likelihood of a school closure during an epidemic might depend on the
proportion of infected pupils exceeding a threshold. Often, rather than
depending on discrete thresholds, dependencies are continuous: for instance,
the likelihood of any one mosquito bite transmitting an illness depends on the
proportion of carrier mosquitoes. Current approaches usually only consider
probabilities over possible worlds rather than over domain elements themselves.
An exception are the recently introduced Lifted Bayesian Networks for
Conditional Probability Logic, which express discrete dependencies on
probabilistic data. We introduce functional lifted Bayesian networks, a
formalism that explicitly incorporates continuous dependencies on relative
frequencies into statistical relational artificial intelligence. and compare
and contrast them with ifted Bayesian Networks for Conditional Probability
Logic. Incorporating relative frequencies is not only beneficial to modelling;
it also provides a more rigorous approach to learning problems where training
and test or application domains have different sizes. To this end, we provide a
representation of the asymptotic probability distributions induced by
functional lifted Bayesian networks on domains of increasing sizes. Since that
representation has well-understood scaling behaviour across domain sizes, it
can be used to estimate parameters for a large domain consistently from
randomly sampled subpopulations. Furthermore, we show that in parametric
families of FLBN, convergence is uniform in the parameters, which ensures a
meaningful dependence of the asymptotic probabilities on the parameters of the
model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.00256">Heterogeneous Graph Neural Networks using Self-supervised Reciprocally Contrastive Learning. (arXiv:2205.00256v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huo_C/0/1/0/all/0/1">Cuiying Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongxiao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yawen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Di Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_J/0/1/0/all/0/1">Jianwu Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weixiong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a></p>
<p>Heterogeneous graph neural network (HGNN) is a very popular technique for the
modeling and analysis of heterogeneous graphs. Most existing HGNN-based
approaches are supervised or semi-supervised learning methods requiring graphs
to be annotated, which is costly and time-consuming. Self-supervised
contrastive learning has been proposed to address the problem of requiring
annotated data by mining intrinsic information hidden within the given data.
However, the existing contrastive learning methods are inadequate for
heterogeneous graphs because they construct contrastive views only based on
data perturbation or pre-defined structural properties (e.g., meta-path) in
graph data while ignore the noises that may exist in both node attributes and
graph topologies. We develop for the first time a novel and robust
heterogeneous graph contrastive learning approach, namely HGCL, which
introduces two views on respective guidance of node attributes and graph
topologies and integrates and enhances them by reciprocally contrastive
mechanism to better model heterogeneous graphs. In this new approach, we adopt
distinct but most suitable attribute and topology fusion mechanisms in the two
views, which are conducive to mining relevant information in attributes and
topologies separately. We further use both attribute similarity and topological
correlation to construct high-quality contrastive samples. Extensive
experiments on three large real-world heterogeneous graphs demonstrate the
superiority and robustness of HGCL over state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.07394">Sibyl: Adaptive and Extensible Data Placement in Hybrid Storage Systems Using Online Reinforcement Learning. (arXiv:2205.07394v2 [cs.AR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadig_R/0/1/0/all/0/1">Rakesh Nadig</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jisung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bera_R/0/1/0/all/0/1">Rahul Bera</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajinazar_N/0/1/0/all/0/1">Nastaran Hajinazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Novo_D/0/1/0/all/0/1">David Novo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Luna_J/0/1/0/all/0/1">Juan G&#xf3;mez-Luna</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuijk_S/0/1/0/all/0/1">Sander Stuijk</a>, <a href="http://arxiv.org/find/cs/1/au:+Corporaal_H/0/1/0/all/0/1">Henk Corporaal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1">Onur Mutlu</a></p>
<p>Hybrid storage systems (HSS) use multiple different storage devices to
provide high and scalable storage capacity at high performance. Recent research
proposes various techniques that aim to accurately identify
performance-critical data to place it in a "best-fit" storage device.
Unfortunately, most of these techniques are rigid, which (1) limits their
adaptivity to perform well for a wide range of workloads and storage device
configurations, and (2) makes it difficult for designers to extend these
techniques to different storage system configurations (e.g., with a different
number or different types of storage devices) than the configuration they are
designed for. We introduce Sibyl, the first technique that uses reinforcement
learning for data placement in hybrid storage systems. Sibyl observes different
features of the running workload as well as the storage devices to make
system-aware data placement decisions. For every decision it makes, Sibyl
receives a reward from the system that it uses to evaluate the long-term
performance impact of its decision and continuously optimizes its data
placement policy online. We implement Sibyl on real systems with various HSS
configurations. Our results show that Sibyl provides 21.6%/19.9% performance
improvement in a performance-oriented/cost-oriented HSS configuration compared
to the best previous data placement technique. Our evaluation using an HSS
configuration with three different storage devices shows that Sibyl outperforms
the state-of-the-art data placement policy by 23.9%-48.2%, while significantly
reducing the system architect's burden in designing a data placement mechanism
that can simultaneously incorporate three storage devices. We show that Sibyl
achieves 80% of the performance of an oracle policy that has complete knowledge
of future access patterns while incurring a very modest storage overhead of
only 124.4 KiB.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.12683">Rethinking Fano&#x27;s Inequality in Ensemble Learning. (arXiv:2205.12683v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Morishita_T/0/1/0/all/0/1">Terufumi Morishita</a>, <a href="http://arxiv.org/find/cs/1/au:+Morio_G/0/1/0/all/0/1">Gaku Morio</a>, <a href="http://arxiv.org/find/cs/1/au:+Horiguchi_S/0/1/0/all/0/1">Shota Horiguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozaki_H/0/1/0/all/0/1">Hiroaki Ozaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Nukaga_N/0/1/0/all/0/1">Nobuo Nukaga</a></p>
<p>We propose a fundamental theory on ensemble learning that answers the central
question: what factors make an ensemble system good or bad? Previous studies
used a variant of Fano's inequality of information theory and derived a lower
bound of the classification error rate on the basis of the $\textit{accuracy}$
and $\textit{diversity}$ of models. We revisit the original Fano's inequality
and argue that the studies did not take into account the information lost when
multiple model predictions are combined into a final prediction. To address
this issue, we generalize the previous theory to incorporate the information
loss, which we name $\textit{combination loss}$. Further, we empirically
validate and demonstrate the proposed theory through extensive experiments on
actual systems. The theory reveals the strengths and weaknesses of systems on
each metric, which will push the theoretical understanding of ensemble learning
and give us insights into designing systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.04876">On the Intrinsic Structures of Spiking Neural Networks. (arXiv:2207.04876v3 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shao-Qun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jia-Yi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jin-Hui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Huan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1">Bin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a></p>
<p>Recent years have emerged a surge of interest in SNNs owing to their
remarkable potential to handle time-dependent and event-driven data. The
performance of SNNs hinges not only on selecting an apposite architecture and
fine-tuning connection weights, similar to conventional ANNs, but also on the
meticulous configuration of intrinsic structures within spiking computations.
However, there has been a dearth of comprehensive studies examining the impact
of intrinsic structures. Consequently, developers often find it challenging to
apply a standardized configuration of SNNs across diverse datasets or tasks.
This work delves deep into the intrinsic structures of SNNs. Initially, we
unveil two pivotal components of intrinsic structures: the integration
operation and firing-reset mechanism, by elucidating their influence on the
expressivity of SNNs. Furthermore, we draw two key conclusions: the membrane
time hyper-parameter is intimately linked to the eigenvalues of the integration
operation, dictating the functional topology of spiking dynamics, and various
hyper-parameters of the firing-reset mechanism govern the overall firing
capacity of an SNN, mitigating the injection ratio or sampling density of input
data. These findings elucidate why the efficacy of SNNs hinges heavily on the
configuration of intrinsic structures and lead to a recommendation that
enhancing the adaptability of these structures contributes to improving the
overall performance and applicability of SNNs. Inspired by this recognition, we
propose two feasible approaches to enhance SNN learning. These involve
leveraging self-connection architectures and employing stochastic spiking
neurons to augment the adaptability of the integration operation and
firing-reset mechanism, respectively. We verify the effectiveness of the
proposed methods from perspectives of theory and practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.10265">FOCUS: Fairness via Agent-Awareness for Federated Learning on Heterogeneous Data. (arXiv:2207.10265v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1">Wenda Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chulin Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1">Lang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nourian_A/0/1/0/all/0/1">Arash Nourian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a></p>
<p>Federated learning (FL) allows agents to jointly train a global model without
sharing their local data. However, due to the heterogeneous nature of local
data, it is challenging to optimize or even define fairness of the trained
global model for the agents. For instance, existing work usually considers
accuracy equity as fairness for different agents in FL, which is limited,
especially under the heterogeneous setting, since it is intuitively "unfair" to
enforce agents with high-quality data to achieve similar accuracy to those who
contribute low-quality data, which may discourage the agents from participating
in FL. In this work, we propose a formal FL fairness definition, fairness via
agent-awareness (FAA), which takes different contributions of heterogeneous
agents into account. Under FAA, the performance of agents with high-quality
data will not be sacrificed just due to the existence of large amounts of
agents with low-quality data. In addition, we propose a fair FL training
algorithm based on agent clustering (FOCUS) to achieve fairness in FL measured
by FAA. Theoretically, we prove the convergence and optimality of FOCUS under
mild conditions for linear and general convex loss functions with bounded
smoothness. We also prove that FOCUS always achieves higher fairness in terms
of FAA compared with standard FedAvg under both linear and general convex loss
functions. Empirically, we show that on four FL datasets, including synthetic
data, images, and texts, FOCUS achieves significantly higher fairness in terms
of FAA while maintaining competitive prediction accuracy compared with FedAvg
and state-of-the-art fair FL algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.12560">AMLB: an AutoML Benchmark. (arXiv:2207.12560v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gijsbers_P/0/1/0/all/0/1">Pieter Gijsbers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bueno_M/0/1/0/all/0/1">Marcos L. P. Bueno</a>, <a href="http://arxiv.org/find/cs/1/au:+Coors_S/0/1/0/all/0/1">Stefan Coors</a>, <a href="http://arxiv.org/find/cs/1/au:+LeDell_E/0/1/0/all/0/1">Erin LeDell</a>, <a href="http://arxiv.org/find/cs/1/au:+Poirier_S/0/1/0/all/0/1">S&#xe9;bastien Poirier</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_J/0/1/0/all/0/1">Janek Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1">Bernd Bischl</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanschoren_J/0/1/0/all/0/1">Joaquin Vanschoren</a></p>
<p>Comparing different AutoML frameworks is notoriously challenging and often
done incorrectly. We introduce an open and extensible benchmark that follows
best practices and avoids common mistakes when comparing AutoML frameworks. We
conduct a thorough comparison of 9 well-known AutoML frameworks across 71
classification and 33 regression tasks. The differences between the AutoML
frameworks are explored with a multi-faceted analysis, evaluating model
accuracy, its trade-offs with inference time, and framework failures. We also
use Bradley-Terry trees to discover subsets of tasks where the relative AutoML
framework rankings differ. The benchmark comes with an open-source tool that
integrates with many AutoML frameworks and automates the empirical evaluation
process end-to-end: from framework installation and resource allocation to
in-depth evaluation. The benchmark uses public data sets, can be easily
extended with other AutoML frameworks and tasks, and has a website with
up-to-date results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.09106">A Risk-Sensitive Approach to Policy Optimization. (arXiv:2208.09106v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Markowitz_J/0/1/0/all/0/1">Jared Markowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_R/0/1/0/all/0/1">Ryan W. Gardner</a>, <a href="http://arxiv.org/find/cs/1/au:+Llorens_A/0/1/0/all/0/1">Ashley Llorens</a>, <a href="http://arxiv.org/find/cs/1/au:+Arora_R/0/1/0/all/0/1">Raman Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_I/0/1/0/all/0/1">I-Jeng Wang</a></p>
<p>Standard deep reinforcement learning (DRL) aims to maximize expected reward,
considering collected experiences equally in formulating a policy. This differs
from human decision-making, where gains and losses are valued differently and
outlying outcomes are given increased consideration. It also fails to
capitalize on opportunities to improve safety and/or performance through the
incorporation of distributional context. Several approaches to distributional
DRL have been investigated, with one popular strategy being to evaluate the
projected distribution of returns for possible actions. We propose a more
direct approach whereby risk-sensitive objectives, specified in terms of the
cumulative distribution function (CDF) of the distribution of full-episode
rewards, are optimized. This approach allows for outcomes to be weighed based
on relative quality, can be used for both continuous and discrete action
spaces, and may naturally be applied in both constrained and unconstrained
settings. We show how to compute an asymptotically consistent estimate of the
policy gradient for a broad class of risk-sensitive objectives via sampling,
subsequently incorporating variance reduction and regularization measures to
facilitate effective on-policy learning. We then demonstrate that the use of
moderately "pessimistic" risk profiles, which emphasize scenarios where the
agent performs poorly, leads to enhanced exploration and a continual focus on
addressing deficiencies. We test the approach using different risk profiles in
six OpenAI Safety Gym environments, comparing to state of the art on-policy
methods. Without cost constraints, we find that pessimistic risk profiles can
be used to reduce cost while improving total reward accumulation. With cost
constraints, they are seen to provide higher positive rewards than risk-neutral
approaches at the prescribed allowable cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.10161">MUDGUARD: Taming Malicious Majorities in Federated Learning using Privacy-Preserving Byzantine-Robust Clustering. (arXiv:2208.10161v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingkai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huanhuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Decouchant_J/0/1/0/all/0/1">J&#xe9;r&#xe9;mie Decouchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Picek_S/0/1/0/all/0/1">Stjepan Picek</a>, <a href="http://arxiv.org/find/cs/1/au:+Laoutaris_N/0/1/0/all/0/1">Nikolaos Laoutaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1">Kaitai Liang</a></p>
<p>Byzantine-robust Federated Learning (FL) aims to counter malicious clients
and train an accurate global model while maintaining an extremely low attack
success rate. Most existing systems, however, are only robust when most of the
clients are honest. FLTrust (NDSS '21) and Zeno++ (ICML '20) do not make such
an honest majority assumption but can only be applied to scenarios where the
server is provided with an auxiliary dataset used to filter malicious updates.
FLAME (USENIX '22) and EIFFeL (CCS '22) maintain the semi-honest majority
assumption to guarantee robustness and the confidentiality of updates. It is
therefore currently impossible to ensure Byzantine robustness and
confidentiality of updates without assuming a semi-honest majority. To tackle
this problem, we propose a novel Byzantine-robust and privacy-preserving FL
system, called MUDGUARD, that can operate under malicious minority \emph{or
majority} in both the server and client sides. Based on DBSCAN, we design a new
method for extracting features from model updates via pairwise adjusted cosine
similarity to boost the accuracy of the resulting clustering. To thwart attacks
from a malicious majority, we develop a method called \textit{Model
Segmentation}, that aggregates together only the updates from within a cluster,
sending the corresponding model only to the clients of the corresponding
cluster. The fundamental idea is that even if malicious clients are in their
majority, their poisoned updates cannot harm benign clients if they are
confined only within the malicious cluster. We also leverage multiple
cryptographic tools to conduct clustering without sacrificing training
correctness and updates confidentiality. We present a detailed security proof
and empirical evaluation along with a convergence analysis for MUDGUARD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.01125">Spectral2Spectral: Image-spectral Similarity Assisted Spectral CT Deep Reconstruction without Reference. (arXiv:2210.01125v3 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Guo_X/0/1/0/all/0/1">Xiaodong Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1">Longhui Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_D/0/1/0/all/0/1">Dingyue Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+He_P/0/1/0/all/0/1">Peng He</a>, <a href="http://arxiv.org/find/eess/1/au:+Feng_P/0/1/0/all/0/1">Peng Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1">Hengyong Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1">Weiwen Wu</a></p>
<p>Spectral computed tomography based on a photon-counting detector (PCD)
attracts more and more attentions since it has the capability to provide more
accurate identification and quantitative analysis for biomedical materials. The
limited number of photons within narrow energy bins leads to imaging results of
low signal-noise ratio. The existing supervised deep reconstruction networks
for CT reconstruction are difficult to address these challenges because it is
usually impossible to acquire noise-free clinical images with clear structures
as references. In this paper, we propose an iterative deep reconstruction
network to synergize unsupervised method and data priors into a unified
framework, named as Spectral2Spectral. Our Spectral2Spectral employs an
unsupervised deep training strategy to obtain high-quality images from noisy
data in an end-to-end fashion. The structural similarity prior within
image-spectral domain is refined as a regularization term to further constrain
the network training. The weights of neural network are automatically updated
to capture image features and structures within the iterative process. Three
large-scale preclinical datasets experiments demonstrate that the
Spectral2spectral reconstructs better image quality than other the
state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.04822">Private estimation algorithms for stochastic block models and mixture models. (arXiv:2301.04822v2 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1">Vincent Cohen-Addad</a>, <a href="http://arxiv.org/find/cs/1/au:+dOrsi_T/0/1/0/all/0/1">Tommaso d&#x27;Orsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Epasto_A/0/1/0/all/0/1">Alessandro Epasto</a>, <a href="http://arxiv.org/find/cs/1/au:+Imola_J/0/1/0/all/0/1">Jacob Imola</a>, <a href="http://arxiv.org/find/cs/1/au:+Steurer_D/0/1/0/all/0/1">David Steurer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiegel_S/0/1/0/all/0/1">Stefan Tiegel</a></p>
<p>We introduce general tools for designing efficient private estimation
algorithms, in the high-dimensional settings, whose statistical guarantees
almost match those of the best known non-private algorithms. To illustrate our
techniques, we consider two problems: recovery of stochastic block models and
learning mixtures of spherical Gaussians. For the former, we present the first
efficient $(\epsilon, \delta)$-differentially private algorithm for both weak
recovery and exact recovery. Previously known algorithms achieving comparable
guarantees required quasi-polynomial time. For the latter, we design an
$(\epsilon, \delta)$-differentially private algorithm that recovers the centers
of the $k$-mixture when the minimum separation is at least $
O(k^{1/t}\sqrt{t})$. For all choices of $t$, this algorithm requires sample
complexity $n\geq k^{O(1)}d^{O(t)}$ and time complexity $(nd)^{O(t)}$. Prior
work required minimum separation at least $O(\sqrt{k})$ as well as an explicit
upper bound on the Euclidean norm of the centers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.10365">Data Consistent Deep Rigid MRI Motion Correction. (arXiv:2301.10365v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Singh_N/0/1/0/all/0/1">Nalini M. Singh</a>, <a href="http://arxiv.org/find/eess/1/au:+Dey_N/0/1/0/all/0/1">Neel Dey</a>, <a href="http://arxiv.org/find/eess/1/au:+Hoffmann_M/0/1/0/all/0/1">Malte Hoffmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Fischl_B/0/1/0/all/0/1">Bruce Fischl</a>, <a href="http://arxiv.org/find/eess/1/au:+Adalsteinsson_E/0/1/0/all/0/1">Elfar Adalsteinsson</a>, <a href="http://arxiv.org/find/eess/1/au:+Frost_R/0/1/0/all/0/1">Robert Frost</a>, <a href="http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1">Adrian V. Dalca</a>, <a href="http://arxiv.org/find/eess/1/au:+Golland_P/0/1/0/all/0/1">Polina Golland</a></p>
<p>Motion artifacts are a pervasive problem in MRI, leading to misdiagnosis or
mischaracterization in population-level imaging studies. Current retrospective
rigid intra-slice motion correction techniques jointly optimize estimates of
the image and the motion parameters. In this paper, we use a deep network to
reduce the joint image-motion parameter search to a search over rigid motion
parameters alone. Our network produces a reconstruction as a function of two
inputs: corrupted k-space data and motion parameters. We train the network
using simulated, motion-corrupted k-space data generated with known motion
parameters. At test-time, we estimate unknown motion parameters by minimizing a
data consistency loss between the motion parameters, the network-based image
reconstruction given those parameters, and the acquired measurements.
Intra-slice motion correction experiments on simulated and realistic 2D fast
spin echo brain MRI achieve high reconstruction fidelity while providing the
benefits of explicit data consistency optimization. Our code is publicly
available at https://www.github.com/nalinimsingh/neuroMoCo.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.12618">ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning. (arXiv:2301.12618v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Junguang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Baixu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Junwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Ximei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dapeng_L/0/1/0/all/0/1">Liu Dapeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jie Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1">Mingsheng Long</a></p>
<p>Auxiliary-Task Learning (ATL) aims to improve the performance of the target
task by leveraging the knowledge obtained from related tasks. Occasionally,
learning multiple tasks simultaneously results in lower accuracy than learning
only the target task, which is known as negative transfer. This problem is
often attributed to the gradient conflicts among tasks, and is frequently
tackled by coordinating the task gradients in previous works. However, these
optimization-based methods largely overlook the auxiliary-target generalization
capability. To better understand the root cause of negative transfer, we
experimentally investigate it from both optimization and generalization
perspectives. Based on our findings, we introduce ForkMerge, a novel approach
that periodically forks the model into multiple branches, automatically
searches the varying task weights by minimizing target validation errors, and
dynamically merges all branches to filter out detrimental task-parameter
updates. On a series of auxiliary-task learning benchmarks, ForkMerge
outperforms existing methods and effectively mitigates negative transfer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.14838">EvoPrompting: Language Models for Code-Level Neural Architecture Search. (arXiv:2302.14838v3 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Angelica Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dohan_D/0/1/0/all/0/1">David M. Dohan</a>, <a href="http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1">David R. So</a></p>
<p>Given the recent impressive accomplishments of language models (LMs) for code
generation, we explore the use of LMs as adaptive mutation and crossover
operators for an evolutionary neural architecture search (NAS) algorithm. While
NAS still proves too difficult a task for LMs to succeed at solely through
prompting, we find that the combination of evolutionary prompt engineering with
soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse
and high performing models. We first demonstrate that EvoPrompting is effective
on the computationally efficient MNIST-1D dataset, where EvoPrompting produces
convolutional architecture variants that outperform both those designed by
human experts and naive few-shot prompting in terms of accuracy and model size.
We then apply our method to searching for graph neural networks on the CLRS
Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel
architectures that outperform current state-of-the-art models on 21 out of 30
algorithmic reasoning tasks while maintaining similar model size. EvoPrompting
is successful at designing accurate and efficient neural network architectures
across a variety of machine learning tasks, while also being general enough for
easy adaptation to other tasks beyond neural network design.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.00783">Adversarial Examples Exist in Two-Layer ReLU Networks for Low Dimensional Linear Subspaces. (arXiv:2303.00783v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Melamed_O/0/1/0/all/0/1">Odelia Melamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1">Gilad Yehudai</a>, <a href="http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1">Gal Vardi</a></p>
<p>Despite a great deal of research, it is still not well-understood why trained
neural networks are highly vulnerable to adversarial examples. In this work we
focus on two-layer neural networks trained using data which lie on a low
dimensional linear subspace. We show that standard gradient methods lead to
non-robust neural networks, namely, networks which have large gradients in
directions orthogonal to the data subspace, and are susceptible to small
adversarial $L_2$-perturbations in these directions. Moreover, we show that
decreasing the initialization scale of the training algorithm, or adding $L_2$
regularization, can make the trained network more robust to adversarial
perturbations orthogonal to the data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.08691">Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v3 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Tachella_J/0/1/0/all/0/1">Juli&#xe1;n Tachella</a>, <a href="http://arxiv.org/find/eess/1/au:+Jacques_L/0/1/0/all/0/1">Laurent Jacques</a></p>
<p>Recent advances in unsupervised learning have highlighted the possibility of
learning to reconstruct signals from noisy and incomplete linear measurements
alone. These methods play a key role in medical and scientific imaging and
sensing, where ground truth data is often scarce or difficult to obtain.
However, in practice, measurements are not only noisy and incomplete but also
quantized. Here we explore the extreme case of learning from binary
observations and provide necessary and sufficient conditions on the number of
measurements required for identifying a set of signals from incomplete binary
data. Our results are complementary to existing bounds on signal recovery from
binary measurements. Furthermore, we introduce a novel self-supervised learning
approach, which we name SSBM, that only requires binary data for training. We
demonstrate in a series of experiments with real datasets that SSBM performs on
par with supervised learning and outperforms sparse reconstruction methods with
a fixed wavelet basis by a large margin.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.09986">Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning. (arXiv:2303.09986v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wannawas_N/0/1/0/all/0/1">Nat Wannawas</a>, <a href="http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1">A. Aldo Faisal</a></p>
<p>Functional electrical stimulation (FES) has been increasingly integrated with
other rehabilitation devices, including robots. FES cycling is one of the
common FES applications in rehabilitation, which is performed by stimulating
leg muscles in a certain pattern. The appropriate pattern varies across
individuals and requires manual tuning which can be time-consuming and
challenging for the individual user. Here, we present an AI-based method for
finding the patterns, which requires no extra hardware or sensors. Our method
has two phases, starting with finding model-based patterns using reinforcement
learning and detailed musculoskeletal models. The models, built using
open-source software, can be customised through our automated script and can be
therefore used by non-technical individuals without extra cost. Next, our
method fine-tunes the pattern using real cycling data. We test our both in
simulation and experimentally on a stationary tricycle. In the simulation test,
our method can robustly deliver model-based patterns for different cycling
configurations. The experimental evaluation shows that our method can find a
model-based pattern that induces higher cycling speed than an EMG-based
pattern. By using just 100 seconds of cycling data, our method can deliver a
fine-tuned pattern that gives better cycling performance. Beyond FES cycling,
this work is a showcase, displaying the feasibility and potential of
human-in-the-loop AI in real-world rehabilitation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05400">Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Siedel_G/0/1/0/all/0/1">Georg Siedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Weijia Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Vock_S/0/1/0/all/0/1">Silvia Vock</a>, <a href="http://arxiv.org/find/cs/1/au:+Morozov_A/0/1/0/all/0/1">Andrey Morozov</a></p>
<p>Robustness is a fundamental property of machine learning classifiers to
achieve safety and reliability. In the fields of adversarial robustness and
formal robustness verification of image classification models, robustness is
commonly defined as the stability to all input variations within an Lp-norm
distance. However, robustness to random corruptions is usually improved and
evaluated using variations observed in the real-world, while mathematically
defined Lp-norm corruptions are rarely considered. This study investigates the
use of random Lp-norm corruptions to augment the training and test data of
image classifiers. We adapt an approach from the field of adversarial
robustness to assess the model robustness to imperceptible random corruptions.
We empirically and theoretically investigate whether robustness is transferable
across different Lp-norms and derive conclusions on which Lp-norm corruptions a
model should be trained and evaluated on. We find that training data
augmentation with L0-norm corruptions improves corruption robustness while
maintaining accuracy compared to standard training and when applied on top of
selected state-of-the-art data augmentation techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12025">Biomembrane-based Memcapacitive Reservoir Computing System for Energy Efficient Temporal Data Processing. (arXiv:2305.12025v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md Razuan Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Ahmed Salah Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Armendarez_N/0/1/0/all/0/1">Nicholas Xavier Armendarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Najem_J/0/1/0/all/0/1">Joseph S. Najem</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md Sakib Hasan</a></p>
<p>Reservoir computing is a highly efficient machine learning framework for
processing temporal data by extracting features from the input signal and
mapping them into higher dimensional spaces. Physical reservoir layers have
been realized using spintronic oscillators, atomic switch networks, silicon
photonic modules, ferroelectric transistors, and volatile memristors. However,
these devices are intrinsically energy-dissipative due to their resistive
nature, which leads to increased power consumption. Therefore, capacitive
memory devices can provide a more energy-efficient approach. Here, we leverage
volatile biomembrane-based memcapacitors that closely mimic certain short-term
synaptic plasticity functions as reservoirs to solve classification tasks and
analyze time-series data in simulation and experimentally. Our system achieves
a 99.6% accuracy rate for spoken digit classification and a normalized mean
square error of 7.81*10^{-4} in a second-order non-linear regression task.
Furthermore, to showcase the device's real-time temporal data processing
capability, we achieve 100% accuracy for a real-time epilepsy detection problem
from an inputted electroencephalography (EEG) signal. Most importantly, we
demonstrate that each memcapacitor consumes an average of 41.5 fJ of energy per
spike, regardless of the selected input voltage pulse width, while maintaining
an average power of 415 fW for a pulse width of 100 ms. These values are orders
of magnitude lower than those achieved by state-of-the-art memristors used as
reservoirs. Lastly, we believe the biocompatible, soft nature of our
memcapacitor makes it highly suitable for computing and signal-processing
applications in biological environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14456">Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. (arXiv:2305.14456v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Naous_T/0/1/0/all/0/1">Tarek Naous</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryan_M/0/1/0/all/0/1">Michael J. Ryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1">Alan Ritter</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a></p>
<p>It is important that language models appropriately adapt to specific cultural
contexts. However, as we show in this paper, multilingual and Arabic
monolingual language models default to Western culture even when prompted in
Arabic and contextualized by an Arab cultural setting. To measure this Western
bias, we introduce CAMeL, a dataset of naturally occurring Arabic prompts
spanning eight diverse cultural aspects and an extensive list of 20,504
cultural targets corresponding to Arab or Western culture. Using CAMeL, we show
that models favor Western targets and demonstrate cultural unfairness on
downstream tasks such as named entity recognition and sentiment analysis. Our
analyses of pretraining corpora also reveal that commonly used sources such as
Wikipedia may not be suited to build culturally aware models, underscoring the
importance of carefully curating pretraining data in constructing language
models to serve a global population.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15798">BK-SDM: A Lightweight, Fast, and Cheap Version of Stable Diffusion. (arXiv:2305.15798v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Bo-Kyeong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hyoung-Kyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Castells_T/0/1/0/all/0/1">Thibault Castells</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Shinkook Choi</a></p>
<p>Text-to-image (T2I) generation with Stable Diffusion models (SDMs) involves
high computing demands due to billion-scale parameters. To enhance efficiency,
recent studies have reduced sampling steps and applied network quantization
while retaining the original architectures. The lack of architectural reduction
attempts may stem from worries over expensive retraining for such massive
models. In this work, we uncover the surprising potential of block pruning and
feature distillation for low-cost general-purpose T2I. By removing several
residual and attention blocks from the U-Net of SDMs, we achieve 30%~50%
reduction in model size, MACs, and latency. We show that distillation
retraining is effective even under limited resources: using only 13 A100 days
and a tiny dataset, our compact models can imitate the original SDMs (v1.4 and
v2.1-base with over 6,000 A100 days). Benefiting from the transferred
knowledge, our BK-SDMs deliver competitive results on zero-shot MS-COCO against
larger multi-billion parameter models. We further demonstrate the applicability
of our lightweight backbones in personalized generation and image-to-image
translation. Deployment of our models on edge devices attains 4-second
inference. We hope this work can help build small yet powerful diffusion models
with feasible training budgets. Code and models can be found at:
https://github.com/Nota-NetsPresso/BK-SDM
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18651">UMD: Unsupervised Model Detection for X2X Backdoor Attacks. (arXiv:2305.18651v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1">Zhen Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zidi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a></p>
<p>Backdoor (Trojan) attack is a common threat to deep neural networks, where
samples from one or more source classes embedded with a backdoor trigger will
be misclassified to adversarial target classes. Existing methods for detecting
whether a classifier is backdoor attacked are mostly designed for attacks with
a single adversarial target (e.g., all-to-one attack). To the best of our
knowledge, without supervision, no existing methods can effectively address the
more general X2X attack with an arbitrary number of source classes, each paired
with an arbitrary target class. In this paper, we propose UMD, the first
Unsupervised Model Detection method that effectively detects X2X backdoor
attacks via a joint inference of the adversarial (source, target) class pairs.
In particular, we first define a novel transferability statistic to measure and
select a subset of putative backdoor class pairs based on a proposed clustering
approach. Then, these selected class pairs are jointly assessed based on an
aggregation of their reverse-engineered trigger size for detection inference,
using a robust and unsupervised anomaly detector we proposed. We conduct
comprehensive evaluations on CIFAR-10, GTSRB, and Imagenette dataset, and show
that our unsupervised UMD outperforms SOTA detectors (even with supervision) by
17%, 4%, and 8%, respectively, in terms of the detection accuracy against
diverse X2X attacks. We also show the strong detection performance of UMD
against several strong adaptive attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18787">Universality and Limitations of Prompt Tuning. (arXiv:2305.18787v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yihan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_J/0/1/0/all/0/1">Jatin Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a></p>
<p>Despite the demonstrated empirical efficacy of prompt tuning to adapt a
pretrained language model for a new task, the theoretical underpinnings of the
difference between "tuning parameters before the input" against "the tuning of
model weights" are limited. We thus take one of the first steps to understand
the role of soft-prompt tuning for transformer-based architectures. By
considering a general purpose architecture, we analyze prompt tuning from the
lens of both: universal approximation and limitations with finite-depth
fixed-weight pretrained transformers for continuous-valued functions. Our
universality result guarantees the existence of a strong transformer with a
prompt to approximate any sequence-to-sequence function in the set of Lipschitz
functions. The limitations of prompt tuning for limited-depth transformers are
first proved by constructing a set of datasets, that cannot be memorized by a
prompt of any length for a given single encoder layer. We also provide a lower
bound on the required number of tunable prompt parameters and compare the
result with the number of parameters required for a low-rank update (based on
LoRA) for a single-layer setting. We finally extend our analysis to multi-layer
settings by providing sufficient conditions under which the transformer can at
best learn datasets from invertible functions only. Our theoretical claims are
also corroborated by empirical results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19730">Data Representations&#x27; Study of Latent Image Manifolds. (arXiv:2305.19730v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kaufman_I/0/1/0/all/0/1">Ilya Kaufman</a>, <a href="http://arxiv.org/find/cs/1/au:+Azencot_O/0/1/0/all/0/1">Omri Azencot</a></p>
<p>Deep neural networks have been demonstrated to achieve phenomenal success in
many domains, and yet their inner mechanisms are not well understood. In this
paper, we investigate the curvature of image manifolds, i.e., the manifold
deviation from being flat in its principal directions. We find that
state-of-the-art trained convolutional neural networks for image classification
have a characteristic curvature profile along layers: an initial steep
increase, followed by a long phase of a plateau, and followed by another
increase. In contrast, this behavior does not appear in untrained networks in
which the curvature flattens. We also show that the curvature gap between the
last two layers has a strong correlation with the generalization capability of
the network. Moreover, we find that the intrinsic dimension of latent codes is
not necessarily indicative of curvature. Finally, we observe that common
regularization methods such as mixup yield flatter representations when
compared to other methods. Our experiments show consistent results over a
variety of deep learning architectures and multiple data sets. Our code is
publicly available at https://github.com/azencot-group/CRLM
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02896">Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sanford_C/0/1/0/all/0/1">Clayton Sanford</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1">Daniel Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1">Matus Telgarsky</a></p>
<p>Attention layers, as commonly used in transformers, form the backbone of
modern deep learning, yet there is no mathematical description of their
benefits and deficiencies as compared with other architectures. In this work we
establish both positive and negative results on the representation power of
attention layers, with a focus on intrinsic complexity parameters such as
width, depth, and embedding dimension. On the positive side, we present a
sparse averaging task, where recurrent networks and feedforward networks all
have complexity scaling polynomially in the input size, whereas transformers
scale merely logarithmically in the input size; furthermore, we use the same
construction to show the necessity and role of a large embedding dimension in a
transformer. On the negative side, we present a triple detection task, where
attention layers in turn have complexity scaling linearly in the input size; as
this scenario seems rare in practice, we also present natural variants that can
be efficiently solved by attention layers. The proof techniques emphasize the
value of communication complexity in the analysis of transformers and related
models, and the role of sparse averaging as a prototypical attention task,
which even finds use in the analysis of triple detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07255">Conditional Matrix Flows for Gaussian Graphical Models. (arXiv:2306.07255v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1">Marcello Massimo Negri</a>, <a href="http://arxiv.org/find/cs/1/au:+Torres_F/0/1/0/all/0/1">F. Arend Torres</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_V/0/1/0/all/0/1">Volker Roth</a></p>
<p>Studying conditional independence among many variables with few observations
is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by
encouraging sparsity in the precision matrix through $l_q$ regularization with
$q\leq1$. However, most GMMs rely on the $l_1$ norm because the objective is
highly non-convex for sub-$l_1$ pseudo-norms. In the frequentist formulation,
the $l_1$ norm relaxation provides the solution path as a function of the
shrinkage parameter $\lambda$. In the Bayesian formulation, sparsity is instead
encouraged through a Laplace prior, but posterior inference for different
$\lambda$ requires repeated runs of expensive Gibbs samplers. Here we propose a
general framework for variational inference with matrix-variate Normalizing
Flow in GGMs, which unifies the benefits of frequentist and Bayesian
frameworks. As a key improvement on previous work, we train with one flow a
continuum of sparse regression models jointly for all regularization parameters
$\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.
Within one model we thus have access to (i) the evolution of the posterior for
any $\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood
for model selection, and (iii) the frequentist solution paths through simulated
annealing in the MAP limit.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11928">Open Problem: Learning with Variational Objectives on Measures. (arXiv:2306.11928v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1">Vivien Cabannes</a>, <a href="http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1">Carles Domingo-Enrich</a></p>
<p>The theory of statistical learning has focused on variational objectives
expressed on functions. In this note, we discuss motivations to write similar
objectives on measures, in particular to discuss out-of-distribution
generalization and weakly-supervised learning. It raises a natural question:
can one cast usual statistical learning results to objectives expressed on
measures? Does the resulting construction lead to new algorithms of practical
interest?
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12047">Residual-Based Error Corrector Operator to Enhance Accuracy and Reliability of Neural Operator Surrogates of Nonlinear Variational Boundary-Value Problems. (arXiv:2306.12047v3 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Jha_P/0/1/0/all/0/1">Prashant K. Jha</a></p>
<p>This work focuses on developing methods for approximating the solution
operators of a class of parametric partial differential equations via neural
operators. Neural operators have several challenges, including the issue of
generating appropriate training data, cost-accuracy trade-offs, and nontrivial
hyperparameter tuning. The unpredictability of the accuracy of neural operators
impacts their applications in downstream problems of inference, optimization,
and control. A framework based on the linear variational problem that gives the
correction to the prediction furnished by neural operators is considered based
on earlier work in JCP 486 (2023) 112104. The operator, called Residual-based
Error Corrector Operator or simply Corrector Operator, associated with the
corrector problem is analyzed further. Numerical results involving a nonlinear
reaction-diffusion model in two dimensions with PCANet-type neural operators
show almost two orders of increase in the accuracy of approximations when
neural operators are corrected using the correction scheme. Further, topology
optimization involving a nonlinear reaction-diffusion model is considered to
highlight the limitations of neural operators and the efficacy of the
correction scheme. Optimizers with neural operator surrogates are seen to make
significant errors (as high as 80 percent). However, the errors are much lower
(below 7 percent) when neural operators are corrected.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12251">GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection. (arXiv:2306.12251v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jianheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_F/0/1/0/all/0/1">Fengrui Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Ziqi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a></p>
<p>With a long history of traditional Graph Anomaly Detection (GAD) algorithms
and recently popular Graph Neural Networks (GNNs), it is still not clear (1)
how they perform under a standard comprehensive setting, (2) whether GNNs can
outperform traditional algorithms such as tree ensembles, and (3) how about
their efficiency on large-scale graphs. In response, we introduce GADBench -- a
benchmark tool dedicated to supervised anomalous node detection in static
graphs. GADBench facilitates a detailed comparison across 29 distinct models on
ten real-world GAD datasets, encompassing thousands to millions ($\sim$6M)
nodes. Our main finding is that tree ensembles with simple neighborhood
aggregation can outperform the latest GNNs tailored for the GAD task. We shed
light on the current progress of GAD, setting a robust groundwork for
subsequent investigations in this domain. GADBench is open-sourced at
https://github.com/squareRoot3/GADBench.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12983">Towards More Realistic Membership Inference Attacks on Large Diffusion Models. (arXiv:2306.12983v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dubinski_J/0/1/0/all/0/1">Jan Dubi&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalczuk_A/0/1/0/all/0/1">Antoni Kowalczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pawlak_S/0/1/0/all/0/1">Stanis&#x142;aw Pawlak</a>, <a href="http://arxiv.org/find/cs/1/au:+Rokita_P/0/1/0/all/0/1">Przemys&#x142;aw Rokita</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Morawiecki_P/0/1/0/all/0/1">Pawe&#x142; Morawiecki</a></p>
<p>Generative diffusion models, including Stable Diffusion and Midjourney, can
generate visually appealing, diverse, and high-resolution images for various
applications. These models are trained on billions of internet-sourced images,
raising significant concerns about the potential unauthorized use of
copyright-protected images. In this paper, we examine whether it is possible to
determine if a specific image was used in the training set, a problem known in
the cybersecurity community and referred to as a membership inference attack.
Our focus is on Stable Diffusion, and we address the challenge of designing a
fair evaluation framework to answer this membership question. We propose a
methodology to establish a fair evaluation setup and apply it to Stable
Diffusion, enabling potential extensions to other generative models. Utilizing
this evaluation setup, we execute membership attacks (both known and newly
introduced). Our research reveals that previously proposed evaluation setups do
not provide a full understanding of the effectiveness of membership inference
attacks. We conclude that the membership inference attack remains a significant
challenge for large diffusion models (often deployed as black-box systems),
indicating that related privacy and copyright issues will persist in the
foreseeable future.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.14670">Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v2 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jagadeesan_M/0/1/0/all/0/1">Meena Jagadeesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1">Jacob Steinhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1">Nika Haghtalab</a></p>
<p>As the scale of machine learning models increases, trends such as scaling
laws anticipate consistent downstream improvements in predictive accuracy.
However, these trends take the perspective of a single model-provider in
isolation, while in reality providers often compete with each other for users.
In this work, we demonstrate that competition can fundamentally alter the
behavior of these scaling trends, even causing overall predictive accuracy
across users to be non-monotonic or decreasing with scale. We define a model of
competition for classification tasks, and use data representations as a lens
for studying the impact of increases in scale. We find many settings where
improving data representation quality (as measured by Bayes risk) decreases the
overall predictive accuracy across users (i.e., social welfare) for a
marketplace of competing model-providers. Our examples range from closed-form
formulas in simple settings to simulations with pretrained representations on
CIFAR-10. At a conceptual level, our work suggests that favorable scaling
trends for individual model-providers need not translate to downstream
improvements in social welfare in marketplaces with multiple model providers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00310">Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thudi_A/0/1/0/all/0/1">Anvith Thudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">Hengrui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Meehan_C/0/1/0/all/0/1">Casey Meehan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1">Ilia Shumailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a></p>
<p>Differentially private stochastic gradient descent (DP-SGD) is the canonical
approach to private deep learning. While the current privacy analysis of DP-SGD
is known to be tight in some settings, several empirical results suggest that
models trained on common benchmark datasets leak significantly less privacy for
many datapoints. Yet, despite past attempts, a rigorous explanation for why
this is the case has not been reached. Is it because there exist tighter
privacy upper bounds when restricted to these dataset settings, or are our
attacks not strong enough for certain datapoints? In this paper, we provide the
first per-instance (i.e., ``data-dependent") DP analysis of DP-SGD. Our
analysis captures the intuition that points with similar neighbors in the
dataset enjoy better data-dependent privacy than outliers. Formally, this is
done by modifying the per-step privacy analysis of DP-SGD to introduce a
dependence on the distribution of model updates computed from a training
dataset. We further develop a new composition theorem to effectively use this
new per-step analysis to reason about an entire training run. Put all together,
our evaluation shows that this novel DP-SGD analysis allows us to now formally
show that DP-SGD leaks significantly less privacy for many datapoints (when
trained on common benchmarks) than the current data-independent guarantee. This
implies privacy attacks will necessarily fail against many datapoints if the
adversary does not have sufficient control over the possible training datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00534">Shared Growth of Graph Neural Networks via Prompted Free-direction Knowledge Distillation. (arXiv:2307.00534v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feng_K/0/1/0/all/0/1">Kaituo Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1">Yikun Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Changsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Ye Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoren Wang</a></p>
<p>Knowledge distillation (KD) has shown to be effective to boost the
performance of graph neural networks (GNNs), where the typical objective is to
distill knowledge from a deeper teacher GNN into a shallower student GNN.
However, it is often quite challenging to train a satisfactory deeper GNN due
to the well-known over-parametrized and over-smoothing issues, leading to
invalid knowledge transfer in practical applications. In this paper, we propose
the first Free-direction Knowledge Distillation framework via reinforcement
learning for GNNs, called FreeKD, which is no longer required to provide a
deeper well-optimized teacher GNN. Our core idea is to collaboratively learn
two shallower GNNs to exchange knowledge between them. As we observe that one
typical GNN model often exhibits better and worse performances at different
nodes during training, we devise a dynamic and free-direction knowledge
transfer strategy that involves two levels of actions: 1) node-level action
determines the directions of knowledge transfer between the corresponding nodes
of two networks; and then 2) structure-level action determines which of the
local structures generated by the node-level actions to be propagated.
Additionally, considering that different augmented graphs can potentially
capture distinct perspectives of the graph data, we propose FreeKD-Prompt that
learns undistorted and diverse augmentations based on prompt learning for
exchanging varied knowledge. Furthermore, instead of confining knowledge
exchange within two GNNs, we develop FreeKD++ to enable free-direction
knowledge transfer among multiple GNNs. Extensive experiments on five benchmark
datasets demonstrate our approaches outperform the base GNNs in a large margin.
More surprisingly, our FreeKD has comparable or even better performance than
traditional KD algorithms that distill knowledge from a deeper and stronger
teacher GNN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08390">Correlation-aware Spatial-Temporal Graph Learning for Multivariate Time-series Anomaly Detection. (arXiv:2307.08390v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Koh_H/0/1/0/all/0/1">Huan Yee Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Ming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_L/0/1/0/all/0/1">Lianhua Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_K/0/1/0/all/0/1">Khoa T. Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Ping Phoebe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1">Wei Xiang</a></p>
<p>Multivariate time-series anomaly detection is critically important in many
applications, including retail, transportation, power grid, and water treatment
plants. Existing approaches for this problem mostly employ either statistical
models which cannot capture the non-linear relations well or conventional deep
learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise
correlations among variables. To overcome these limitations, we propose a novel
method, correlation-aware spatial-temporal graph learning (termed CST-GL), for
time series anomaly detection. CST-GL explicitly captures the pairwise
correlations via a multivariate time series correlation learning module based
on which a spatial-temporal graph neural network (STGNN) can be developed.
Then, by employing a graph convolution network that exploits one- and multi-hop
neighbor information, our STGNN component can encode rich spatial information
from complex pairwise dependencies between variables. With a temporal module
that consists of dilated convolutional functions, the STGNN can further capture
long-range dependence over time. A novel anomaly scoring component is further
integrated into CST-GL to estimate the degree of an anomaly in a purely
unsupervised manner. Experimental results demonstrate that CST-GL can detect
anomalies effectively in general settings as well as enable early detection
across different time delays.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00002">An Overview Of Temporal Commonsense Reasoning and Acquisition. (arXiv:2308.00002v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wenzel_G/0/1/0/all/0/1">Georg Wenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Jatowt_A/0/1/0/all/0/1">Adam Jatowt</a></p>
<p>Temporal commonsense reasoning refers to the ability to understand the
typical temporal context of phrases, actions, and events, and use it to reason
over problems requiring such knowledge. This trait is essential in temporal
natural language processing tasks, with possible applications such as timeline
summarization, temporal question answering, and temporal natural language
inference. Recent research on the performance of large language models suggests
that, although they are adept at generating syntactically correct sentences and
solving classification tasks, they often take shortcuts in their reasoning and
fall prey to simple linguistic traps. This article provides an overview of
research in the domain of temporal commonsense reasoning, particularly focusing
on enhancing language model performance through a variety of augmentations and
their evaluation across a growing number of datasets. However, these augmented
models still struggle to approach human performance on reasoning tasks over
temporal common sense properties, such as the typical occurrence times,
orderings, or durations of events. We further emphasize the need for careful
interpretation of research to guard against overpromising evaluation results in
light of the shallow reasoning present in transformers. This can be achieved by
appropriately preparing datasets and suitable evaluation metrics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.09543">Latent State Models of Training Dynamics. (arXiv:2308.09543v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Michael Y. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Angelica Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1">Naomi Saphra</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a></p>
<p>The impact of randomness on model training is poorly understood. How do
differences in data order and initialization actually manifest in the model,
such that some training runs outperform others or converge faster? Furthermore,
how can we interpret the resulting training dynamics and the phase transitions
that characterize different trajectories? To understand the effect of
randomness on the dynamics and outcomes of neural network training, we train
models multiple times with different random seeds and compute a variety of
metrics throughout training, such as the $L_2$ norm, mean, and variance of the
neural network's weights. We then fit a hidden Markov model (HMM) over the
resulting sequences of metrics. The HMM represents training as a stochastic
process of transitions between latent states, providing an intuitive overview
of significant changes during training. Using our method, we produce a
low-dimensional, discrete representation of training dynamics on grokking
tasks, image classification, and masked language modeling. We use the HMM
representation to study phase transitions and identify latent "detour" states
that slow down convergence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07383">Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning. (arXiv:2309.07383v3 [eess.SY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Bouland_A/0/1/0/all/0/1">Ali Bouland</a>, <a href="http://arxiv.org/find/eess/1/au:+Niu_S/0/1/0/all/0/1">Shengyuan Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Paruchuri_S/0/1/0/all/0/1">Sai Tej Paruchuri</a>, <a href="http://arxiv.org/find/eess/1/au:+Kurdila_A/0/1/0/all/0/1">Andrew Kurdila</a>, <a href="http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1">John Burns</a>, <a href="http://arxiv.org/find/eess/1/au:+Schuster_E/0/1/0/all/0/1">Eugenio Schuster</a></p>
<p>This paper studies convergence rates for some value function approximations
that arise in a collection of reproducing kernel Hilbert spaces (RKHS)
$H(\Omega)$. By casting an optimal control problem in a specific class of
native spaces, strong rates of convergence are derived for the operator
equation that enables offline approximations that appear in policy iteration.
Explicit upper bounds on error in value function and controller approximations
are derived in terms of power function $\Pwr_{H,N}$ for the space of finite
dimensional approximants $H_N$ in the native space $H(\Omega)$. These bounds
are geometric in nature and refine some well-known, now classical results
concerning convergence of approximations of value functions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.09801">Learning Optimal Contracts: How to Exploit Small Action Spaces. (arXiv:2309.09801v2 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bacchiocchi_F/0/1/0/all/0/1">Francesco Bacchiocchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Castiglioni_M/0/1/0/all/0/1">Matteo Castiglioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchesi_A/0/1/0/all/0/1">Alberto Marchesi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatti_N/0/1/0/all/0/1">Nicola Gatti</a></p>
<p>We study principal-agent problems in which a principal commits to an
outcome-dependent payment scheme -- called contract -- in order to induce an
agent to take a costly, unobservable action leading to favorable outcomes. We
consider a generalization of the classical (single-round) version of the
problem in which the principal interacts with the agent by committing to
contracts over multiple rounds. The principal has no information about the
agent, and they have to learn an optimal contract by only observing the outcome
realized at each round. We focus on settings in which the size of the agent's
action space is small. We design an algorithm that learns an
approximately-optimal contract with high probability in a number of rounds
polynomial in the size of the outcome space, when the number of actions is
constant. Our algorithm solves an open problem by Zhu et al.[2022]. Moreover,
it can also be employed to provide a $\tilde{\mathcal{O}}(T^{4/5})$ regret
bound in the related online learning setting in which the principal aims at
maximizing their cumulative utility, thus considerably improving
previously-known regret bounds.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10923">Semi-automatic staging area for high-quality structured data extraction from scientific literature. (arXiv:2309.10923v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Foppiano_L/0/1/0/all/0/1">Luca Foppiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Mato_T/0/1/0/all/0/1">Tomoya Mato</a>, <a href="http://arxiv.org/find/cs/1/au:+Terashima_K/0/1/0/all/0/1">Kensei Terashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Suarez_P/0/1/0/all/0/1">Pedro Ortiz Suarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tou_T/0/1/0/all/0/1">Taku Tou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakai_C/0/1/0/all/0/1">Chikako Sakai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei-Sheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Amagasa_T/0/1/0/all/0/1">Toshiyuki Amagasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Takano_Y/0/1/0/all/0/1">Yoshihiko Takano</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1">Masashi Ishii</a></p>
<p>We propose a semi-automatic staging area for efficiently building an accurate
database of experimental physical properties of superconductors from
literature, called SuperCon2, to enrich the existing manually-built
superconductor database SuperCon. Here we report our curation interface
(SuperCon2 Interface) and a workflow managing the state transitions of each
examined record, to validate the dataset of superconductors from PDF documents
collected using Grobid-superconductors in a previous work. This curation
workflow allows both automatic and manual operations, the former contains
``anomaly detection'' that scans new data identifying outliers, and a
``training data collector'' mechanism that collects training data examples
based on manual corrections. Such training data collection policy is effective
in improving the machine-learning models with a reduced number of examples. For
manual operations, the interface (SuperCon2 interface) is developed to increase
efficiency during manual correction by providing a smart interface and an
enhanced PDF document viewer. We show that our interface significantly improves
the curation quality by boosting precision and recall as compared with the
traditional ``manual correction''. Our semi-automatic approach would provide a
solution for achieving a reliable database with text-data mining of scientific
documents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12620">Data-driven Preference Learning Methods for Sorting Problems with Multiple Temporal Criteria. (arXiv:2309.12620v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yijun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mengzhuo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadzinski_M/0/1/0/all/0/1">Mi&#x142;osz Kadzi&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingpeng Zhang</a></p>
<p>The advent of predictive methodologies has catalyzed the emergence of
data-driven decision support across various domains. However, developing models
capable of effectively handling input time series data presents an enduring
challenge. This study presents novel preference learning approaches to multiple
criteria sorting problems in the presence of temporal criteria. We first
formulate a convex quadratic programming model characterized by fixed time
discount factors, operating within a regularization framework. To enhance
scalability and accommodate learnable time discount factors, we introduce a
novel monotonic Recurrent Neural Network (mRNN). It is designed to capture the
evolving dynamics of preferences over time while upholding critical properties
inherent to MCS problems, including criteria monotonicity, preference
independence, and the natural ordering of classes. The proposed mRNN can
describe the preference dynamics by depicting marginal value functions and
personalized time discount factors along with time, effectively amalgamating
the interpretability of traditional MCS methods with the predictive potential
offered by deep preference learning models. Comprehensive assessments of the
proposed models are conducted, encompassing synthetic data scenarios and a
real-case study centered on classifying valuable users within a mobile gaming
app based on their historical in-app behavioral sequences. Empirical findings
underscore the notable performance improvements achieved by the proposed models
when compared to a spectrum of baseline methods, spanning machine learning,
deep learning, and conventional multiple criteria sorting approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.04955">Information-Theoretic Bounds on The Removal of Attribute-Specific Bias From Neural Networks. (arXiv:2310.04955v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiazhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Khayatkhoei_M/0/1/0/all/0/1">Mahyar Khayatkhoei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiageng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Hanchen Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussein_M/0/1/0/all/0/1">Mohamed E. Hussein</a>, <a href="http://arxiv.org/find/cs/1/au:+AbdAlmageed_W/0/1/0/all/0/1">Wael AbdAlmageed</a></p>
<p>Ensuring a neural network is not relying on protected attributes (e.g., race,
sex, age) for predictions is crucial in advancing fair and trustworthy AI.
While several promising methods for removing attribute bias in neural networks
have been proposed, their limitations remain under-explored. In this work, we
mathematically and empirically reveal an important limitation of attribute bias
removal methods in presence of strong bias. Specifically, we derive a general
non-vacuous information-theoretical upper bound on the performance of any
attribute bias removal method in terms of the bias strength. We provide
extensive experiments on synthetic, image, and census datasets to verify the
theoretical bound and its consequences in practice. Our findings show that
existing attribute bias removal methods are effective only when the inherent
bias in the dataset is relatively weak, thus cautioning against the use of
these methods in smaller datasets where strong attribute bias can occur, and
advocating the need for methods that can overcome this limitation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08176">Infinite Width Graph Neural Networks for Node Regression/ Classification. (arXiv:2310.08176v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cobanoglu_Y/0/1/0/all/0/1">Yunus Cobanoglu</a></p>
<p>This work analyzes Graph Neural Networks, a generalization of Fully-Connected
Deep Neural Nets on Graph structured data, when their width, that is the number
of nodes in each fullyconnected layer is increasing to infinity. Infinite Width
Neural Networks are connecting Deep Learning to Gaussian Processes and Kernels,
both Machine Learning Frameworks with long traditions and extensive theoretical
foundations. Gaussian Processes and Kernels have much less hyperparameters then
Neural Networks and can be used for uncertainty estimation, making them more
user friendly for applications. This works extends the increasing amount of
research connecting Gaussian Processes and Kernels to Neural Networks. The
Kernel and Gaussian Process closed forms are derived for a variety of
architectures, namely the standard Graph Neural Network, the Graph Neural
Network with Skip-Concatenate Connections and the Graph Attention Neural
Network. All architectures are evaluated on a variety of datasets on the task
of transductive Node Regression and Classification. Additionally, a Spectral
Sparsification method known as Effective Resistance is used to improve runtime
and memory requirements. Extending the setting to inductive graph learning
tasks (Graph Regression/ Classification) is straightforward and is briefly
discussed in 3.5.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15015">Leveraging Deep Learning for Abstractive Code Summarization of Unofficial Documentation. (arXiv:2310.15015v3 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Naghshzan_A/0/1/0/all/0/1">AmirHossein Naghshzan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerrouj_L/0/1/0/all/0/1">Latifa Guerrouj</a>, <a href="http://arxiv.org/find/cs/1/au:+Baysal_O/0/1/0/all/0/1">Olga Baysal</a></p>
<p>Usually, programming languages have official documentation to guide
developers with APIs, methods, and classes. However, researchers identified
insufficient or inadequate documentation examples and flaws with the API's
complex structure as barriers to learning an API. As a result, developers may
consult other sources (StackOverflow, GitHub, etc.) to learn more about an API.
Recent research studies have shown that unofficial documentation is a valuable
source of information for generating code summaries. We, therefore, have been
motivated to leverage such a type of documentation along with deep learning
techniques towards generating high-quality summaries for APIs discussed in
informal documentation. This paper proposes an automatic approach using the
BART algorithm, a state-of-the-art transformer model, to generate summaries for
APIs discussed in StackOverflow. We built an oracle of human-generated
summaries to evaluate our approach against it using ROUGE and BLEU metrics
which are the most widely used evaluation metrics in text summarization.
Furthermore, we evaluated our summaries empirically against a previous work in
terms of quality. Our findings demonstrate that using deep learning algorithms
can improve summaries' quality and outperform the previous work by an average
of %57 for Precision, %66 for Recall, and %61 for F-measure, and it runs 4.4
times faster.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19537">On consequences of finetuning on data with highly discriminative features. (arXiv:2310.19537v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Masarczyk_W/0/1/0/all/0/1">Wojciech Masarczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostaszewski_M/0/1/0/all/0/1">Mateusz Ostaszewski</a></p>
<p>In the era of transfer learning, training neural networks from scratch is
becoming obsolete. Transfer learning leverages prior knowledge for new tasks,
conserving computational resources. While its advantages are well-documented,
we uncover a notable drawback: networks tend to prioritize basic data patterns,
forsaking valuable pre-learned features. We term this behavior "feature
erosion" and analyze its impact on network performance and internal
representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19548">Approximation Theory, Computing, and Deep Learning on the Wasserstein Space. (arXiv:2310.19548v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Fornasier_M/0/1/0/all/0/1">Massimo Fornasier</a>, <a href="http://arxiv.org/find/math/1/au:+Heid_P/0/1/0/all/0/1">Pascal Heid</a>, <a href="http://arxiv.org/find/math/1/au:+Sodini_G/0/1/0/all/0/1">Giacomo Enrico Sodini</a></p>
<p>The challenge of approximating functions in infinite-dimensional spaces from
finite samples is widely regarded as formidable. In this study, we delve into
the challenging problem of the numerical approximation of Sobolev-smooth
functions defined on probability spaces. Our particular focus centers on the
Wasserstein distance function, which serves as a relevant example. In contrast
to the existing body of literature focused on approximating efficiently
pointwise evaluations, we chart a new course to define functional approximants
by adopting three machine learning-based approaches: 1. Solving a finite number
of optimal transport problems and computing the corresponding Wasserstein
potentials. 2. Employing empirical risk minimization with Tikhonov
regularization in Wasserstein Sobolev spaces. 3. Addressing the problem through
the saddle point formulation that characterizes the weak form of the Tikhonov
functional's Euler-Lagrange equation. As a theoretical contribution, we furnish
explicit and quantitative bounds on generalization errors for each of these
solutions. In the proofs, we leverage the theory of metric Sobolev spaces and
we combine it with techniques of optimal transport, variational calculus, and
large deviation bounds. In our numerical implementation, we harness
appropriately designed neural networks to serve as basis functions. These
networks undergo training using diverse methodologies. This approach allows us
to obtain approximating functions that can be rapidly evaluated after training.
Consequently, our constructive solutions significantly enhance at equal
accuracy the evaluation speed, surpassing that of state-of-the-art methods by
several orders of magnitude.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.00619">Loss Modeling for Multi-Annotator Datasets. (arXiv:2311.00619v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jinadu_U/0/1/0/all/0/1">Uthman Jinadu</a>, <a href="http://arxiv.org/find/cs/1/au:+Annan_J/0/1/0/all/0/1">Jesse Annan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1">Shanshan Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a></p>
<p>Accounting for the opinions of all annotators of a dataset is critical for
fairness. However, when annotating large datasets, individual annotators will
frequently provide thousands of ratings which can lead to fatigue.
Additionally, these annotation processes can occur over multiple days which can
lead to an inaccurate representation of an annotator's opinion over time. To
combat this, we propose to learn a more accurate representation of diverse
opinions by utilizing multitask learning in conjunction with loss-based label
correction. We show that using our novel formulation, we can cleanly separate
agreeing and disagreeing annotations. Furthermore, we demonstrate that this
modification can improve prediction performance in a single or multi-annotator
setting. Lastly, we show that this method remains robust to additional label
noise that is applied to subjective data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01052">Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Letzelter_V/0/1/0/all/0/1">Victor Letzelter</a>, <a href="http://arxiv.org/find/stat/1/au:+Fontaine_M/0/1/0/all/0/1">Mathieu Fontaine</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1">Micka&#xeb;l Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Perez_P/0/1/0/all/0/1">Patrick P&#xe9;rez</a>, <a href="http://arxiv.org/find/stat/1/au:+Essid_S/0/1/0/all/0/1">Slim Essid</a>, <a href="http://arxiv.org/find/stat/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a></p>
<p>We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings
where multiple targets may be sampled for each training input. Multiple Choice
Learning is a simple framework to tackle multimodal density estimation, using
the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression
settings, the existing MCL variants focus on merging the hypotheses, thereby
eventually sacrificing the diversity of the predictions. In contrast, our
method relies on a novel learned scoring scheme underpinned by a mathematical
framework based on Voronoi tessellations of the output space, from which we can
derive a probabilistic interpretation. After empirically validating rMCL with
experiments on synthetic data, we further assess its merits on the sound source
localization problem, demonstrating its practical usefulness and the relevance
of its interpretation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.01655">Detecting Spurious Correlations via Robust Visual Concepts in Real and AI-Generated Image Classification. (arXiv:2311.01655v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dammu_P/0/1/0/all/0/1">Preetam Prabhu Srikar Dammu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1">Chirag Shah</a></p>
<p>Often machine learning models tend to automatically learn associations
present in the training data without questioning their validity or
appropriateness. This undesirable property is the root cause of the
manifestation of spurious correlations, which render models unreliable and
prone to failure in the presence of distribution shifts. Research shows that
most methods attempting to remedy spurious correlations are only effective for
a model's known spurious associations. Current spurious correlation detection
algorithms either rely on extensive human annotations or are too restrictive in
their formulation. Moreover, they rely on strict definitions of visual
artifacts that may not apply to data produced by generative models, as they are
known to hallucinate contents that do not conform to standard specifications.
In this work, we introduce a general-purpose method that efficiently detects
potential spurious correlations, and requires significantly less human
interference in comparison to the prior art. Additionally, the proposed method
provides intuitive explanations while eliminating the need for pixel-level
annotations. We demonstrate the proposed method's tolerance to the peculiarity
of AI-generated images, which is a considerably challenging task, one where
most of the existing methods fall short. Consequently, our method is also
suitable for detecting spurious correlations that may propagate to downstream
applications originating from generative models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.04950">Lightweight Diffusion Models with Distillation-Based Block Neural Architecture Search. (arXiv:2311.04950v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Chaoyu Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yansong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+zhu_W/0/1/0/all/0/1">Wenwu zhu</a></p>
<p>Diffusion models have recently shown remarkable generation ability, achieving
state-of-the-art performance in many tasks. However, the high computational
cost is still a troubling problem for diffusion models. To tackle this problem,
we propose to automatically remove the structural redundancy in diffusion
models with our proposed Diffusion Distillation-based Block-wise Neural
Architecture Search (DiffNAS). Specifically, given a larger pretrained teacher,
we leverage DiffNAS to search for the smallest architecture which can achieve
on-par or even better performance than the teacher. Considering current
diffusion models are based on UNet which naturally has a block-wise structure,
we perform neural architecture search independently in each block, which
largely reduces the search space. Different from previous block-wise NAS
methods, DiffNAS contains a block-wise local search strategy and a retraining
strategy with a joint dynamic loss. Concretely, during the search process, we
block-wisely select the best subnet to avoid the unfairness brought by the
global search strategy used in previous works. When retraining the searched
architecture, we adopt a dynamic joint loss to maintain the consistency between
supernet training and subnet retraining, which also provides informative
objectives for each block and shortens the paths of gradient propagation. We
demonstrate this joint loss can effectively improve model performance. We also
prove the necessity of the dynamic adjustment of this loss. The experiments
show that our method can achieve significant computational reduction,
especially on latent diffusion models with about 50\% MACs and Parameter
reduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05116">Covering Number of Real Algebraic Varieties and Beyond: Improved Bounds and Applications. (arXiv:2311.05116v2 [math.AG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Kileel_J/0/1/0/all/0/1">Joe Kileel</a></p>
<p>We prove an upper bound on the covering number of real algebraic varieties,
images of polynomial maps and semialgebraic sets. The bound remarkably improves
the best known general bound by Yomdin-Comte, and its proof is much more
straightforward. As a consequence, our result gives new bounds on the volume of
the tubular neighborhood of the image of a polynomial map and a semialgebraic
set, where results for varieties by Lotz and Basu-Lerario are not directly
applicable. We apply our theory to three main application domains. Firstly, we
derive a near-optimal bound on the covering number of low rank CP tensors.
Secondly, we prove a bound on the sketching dimension for (general) polynomial
optimization problems. Lastly, we deduce generalization error bounds for deep
neural networks with rational or ReLU activations, improving or matching the
best known results in the literature.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05417">Predicting the Position Uncertainty at the Time of Closest Approach with Diffusion Models. (arXiv:2311.05417v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guimaraes_M/0/1/0/all/0/1">Marta Guimar&#xe3;es</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1">Cl&#xe1;udia Soares</a>, <a href="http://arxiv.org/find/cs/1/au:+Manfletti_C/0/1/0/all/0/1">Chiara Manfletti</a></p>
<p>The risk of collision between resident space objects has significantly
increased in recent years. As a result, spacecraft collision avoidance
procedures have become an essential part of satellite operations. To ensure
safe and effective space activities, satellite owners and operators rely on
constantly updated estimates of encounters. These estimates include the
uncertainty associated with the position of each object at the expected TCA.
These estimates are crucial in planning risk mitigation measures, such as
collision avoidance manoeuvres. As the TCA approaches, the accuracy of these
estimates improves, as both objects' orbit determination and propagation
procedures are made for increasingly shorter time intervals. However, this
improvement comes at the cost of taking place close to the critical decision
moment. This means that safe avoidance manoeuvres might not be possible or
could incur significant costs. Therefore, knowing the evolution of this
variable in advance can be crucial for operators. This work proposes a machine
learning model based on diffusion models to forecast the position uncertainty
of objects involved in a close encounter, particularly for the secondary object
(usually debris), which tends to be more unpredictable. We compare the
performance of our model with other state-of-the-art solutions and a na\"ive
baseline approach, showing that the proposed solution has the potential to
significantly improve the safety and effectiveness of spacecraft operations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05426">Statistical Learning of Conjunction Data Messages Through a Bayesian Non-Homogeneous Poisson Process. (arXiv:2311.05426v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guimaraes_M/0/1/0/all/0/1">Marta Guimar&#xe3;es</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1">Cl&#xe1;udia Soares</a>, <a href="http://arxiv.org/find/cs/1/au:+Manfletti_C/0/1/0/all/0/1">Chiara Manfletti</a></p>
<p>Current approaches for collision avoidance and space traffic management face
many challenges, mainly due to the continuous increase in the number of objects
in orbit and the lack of scalable and automated solutions. To avoid
catastrophic incidents, satellite owners/operators must be aware of their
assets' collision risk to decide whether a collision avoidance manoeuvre needs
to be performed. This process is typically executed through the use of warnings
issued in the form of CDMs which contain information about the event, such as
the expected TCA and the probability of collision. Our previous work presented
a statistical learning model that allowed us to answer two important questions:
(1) Will any new conjunctions be issued in the next specified time interval?
(2) When and with what uncertainty will the next CDM arrive? However, the model
was based on an empirical Bayes homogeneous Poisson process, which assumes that
the arrival rates of CDMs are constant over time. In fact, the rate at which
the CDMs are issued depends on the behaviour of the objects as well as on the
screening process performed by third parties. Thus, in this work, we extend the
previous study and propose a Bayesian non-homogeneous Poisson process
implemented with high precision using a Probabilistic Programming Language to
fully describe the underlying phenomena. We compare the proposed solution with
a baseline model to demonstrate the added value of our approach. The results
show that this problem can be successfully modelled by our Bayesian
non-homogeneous Poisson Process with greater accuracy, contributing to the
development of automated collision avoidance systems and helping operators
react timely but sparingly with satellite manoeuvres.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05430">Taxonomy for Resident Space Objects in LEO: A Deep Learning Approach. (arXiv:2311.05430v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guimaraes_M/0/1/0/all/0/1">Marta Guimar&#xe3;es</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1">Cl&#xe1;udia Soares</a>, <a href="http://arxiv.org/find/cs/1/au:+Manfletti_C/0/1/0/all/0/1">Chiara Manfletti</a></p>
<p>The increasing number of RSOs has raised concerns about the risk of
collisions and catastrophic incidents for all direct and indirect users of
space. To mitigate this issue, it is essential to have a good understanding of
the various RSOs in orbit and their behaviour. A well-established taxonomy
defining several classes of RSOs is a critical step in achieving this
understanding. This taxonomy helps assign objects to specific categories based
on their main characteristics, leading to better tracking services.
Furthermore, a well-established taxonomy can facilitate research and analysis
processes by providing a common language and framework for better understanding
the factors that influence RSO behaviour in space. These factors, in turn, help
design more efficient and effective strategies for space traffic management.
Our work proposes a new taxonomy for RSOs focusing on the low Earth orbit
regime to enhance space traffic management. In addition, we present a deep
learning-based model that uses an autoencoder architecture to reduce the
features representing the characteristics of the RSOs. The autoencoder
generates a lower-dimensional space representation that is then explored using
techniques such as Uniform Manifold Approximation and Projection to identify
fundamental clusters of RSOs based on their unique characteristics. This
approach captures the complex and non-linear relationships between the features
and the RSOs' classes identified. Our proposed taxonomy and model offer a
significant contribution to the ongoing efforts to mitigate the overall risks
posed by the increasing number of RSOs in orbit.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07141">SABAF: Removing Strong Attribute Bias from Neural Networks with Adversarial Filtering. (arXiv:2311.07141v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiazhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Khayatkhoei_M/0/1/0/all/0/1">Mahyar Khayatkhoei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiageng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Hanchen Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussein_M/0/1/0/all/0/1">Mohamed E. Hussein</a>, <a href="http://arxiv.org/find/cs/1/au:+AbdAlmageed_W/0/1/0/all/0/1">Wael AbdAlmageed</a></p>
<p>Ensuring a neural network is not relying on protected attributes (e.g., race,
sex, age) for prediction is crucial in advancing fair and trustworthy AI. While
several promising methods for removing attribute bias in neural networks have
been proposed, their limitations remain under-explored. To that end, in this
work, we mathematically and empirically reveal the limitation of existing
attribute bias removal methods in presence of strong bias and propose a new
method that can mitigate this limitation. Specifically, we first derive a
general non-vacuous information-theoretical upper bound on the performance of
any attribute bias removal method in terms of the bias strength, revealing that
they are effective only when the inherent bias in the dataset is relatively
weak. Next, we derive a necessary condition for the existence of any method
that can remove attribute bias regardless of the bias strength. Inspired by
this condition, we then propose a new method using an adversarial objective
that directly filters out protected attributes in the input space while
maximally preserving all other attributes, without requiring any specific
target label. The proposed method achieves state-of-the-art performance in both
strong and moderate bias settings. We provide extensive experiments on
synthetic, image, and census datasets, to verify the derived theoretical bound
and its consequences in practice, and evaluate the effectiveness of the
proposed method in removing strong attribute bias.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07468">Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse. (arXiv:2311.07468v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lv_A/0/1/0/all/0/1">Ang Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shufang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Q/0/1/0/all/0/1">Quan Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuhan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Rui Yan</a></p>
<p>Recent studies have highlighted a phenomenon in large language models (LLMs)
known as "the reversal curse," in which the order of knowledge entities in the
training data biases the models' comprehension. For example, if a model is
trained on sentences where entity A consistently appears before entity B, it
can respond to queries about A by providing B as the answer. However, it may
encounter confusion when presented with questions concerning B. We contend that
the reversal curse is partially a result of specific model training objectives,
particularly evident in the prevalent use of the next-token prediction within
most causal language models. For the next-token prediction, models solely focus
on a token's preceding context, resulting in a restricted comprehension of the
input. In contrast, we illustrate that the GLM, trained using the
autoregressive blank infilling objective where tokens to be predicted have
access to the entire context, exhibits better resilience against the reversal
curse. We propose a novel training method, BIdirectional Casual language
modeling Optimization (BICO), designed to mitigate the reversal curse when
fine-tuning pretrained causal language models on new data. BICO modifies the
causal attention mechanism to function bidirectionally and employs a mask
denoising optimization. In the task designed to assess the reversal curse, our
approach improves Llama's accuracy from the original 0% to around 70%. We hope
that more attention can be focused on exploring and addressing these inherent
weaknesses of the current LLMs, in order to achieve a higher level of
intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07587">Frontier Language Models are not Robust to Adversarial Arithmetic, or &quot;What do I need to say so you agree 2+2=5?. (arXiv:2311.07587v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Freeman_C/0/1/0/all/0/1">C. Daniel Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Culp_L/0/1/0/all/0/1">Laura Culp</a>, <a href="http://arxiv.org/find/cs/1/au:+Parisi_A/0/1/0/all/0/1">Aaron Parisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bileschi_M/0/1/0/all/0/1">Maxwell L Bileschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsayed_G/0/1/0/all/0/1">Gamaleldin F Elsayed</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizkowsky_A/0/1/0/all/0/1">Alex Rizkowsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Simpson_I/0/1/0/all/0/1">Isabelle Simpson</a>, <a href="http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1">Alex Alemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nova_A/0/1/0/all/0/1">Azade Nova</a>, <a href="http://arxiv.org/find/cs/1/au:+Adlam_B/0/1/0/all/0/1">Ben Adlam</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohnet_B/0/1/0/all/0/1">Bernd Bohnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1">Gaurav Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sedghi_H/0/1/0/all/0/1">Hanie Sedghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>, <a href="http://arxiv.org/find/cs/1/au:+Gur_I/0/1/0/all/0/1">Izzeddin Gur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaehoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Co_Reyes_J/0/1/0/all/0/1">JD Co-Reyes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pennington_J/0/1/0/all/0/1">Jeffrey Pennington</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kelvin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1">Kevin Swersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_K/0/1/0/all/0/1">Kshiteej Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Lechao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rosanne Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1">Simon Kornblith</a>, <a href="http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1">Noah Constant</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peter J. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Novak_R/0/1/0/all/0/1">Roman Novak</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yundi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiedel_N/0/1/0/all/0/1">Noah Fiedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1">Jascha Sohl-Dickstein</a></p>
<p>We introduce and study the problem of adversarial arithmetic, which provides
a simple yet challenging testbed for language model alignment. This problem is
comprised of arithmetic questions posed in natural language, with an arbitrary
adversarial string inserted before the question is complete. Even in the simple
setting of 1-digit addition problems, it is easy to find adversarial prompts
that make all tested models (including PaLM2, GPT4, Claude2) misbehave, and
even to steer models to a particular wrong answer. We additionally provide a
simple algorithm for finding successful attacks by querying those same models,
which we name "prompt inversion rejection sampling" (PIRS). We finally show
that models can be partially hardened against these attacks via reinforcement
learning and via agentic constitutional loops. However, we were not able to
make a language model fully robust against adversarial arithmetic attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08433">Clinical Characteristics and Laboratory Biomarkers in ICU-admitted Septic Patients with and without Bacteremia. (arXiv:2311.08433v2 [q-bio.QM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Baek_S/0/1/0/all/0/1">Sangwon Baek</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lee_S/0/1/0/all/0/1">Seung Jun Lee</a></p>
<p>Few studies have investigated the diagnostic utilities of biomarkers for
predicting bacteremia among septic patients admitted to intensive care units
(ICU). Therefore, this study evaluated the prediction power of laboratory
biomarkers to utilize those markers with high performance to optimize the
predictive model for bacteremia. This retrospective cross-sectional study was
conducted at the ICU department of Gyeongsang National University Changwon
Hospital in 2019. Adult patients qualifying SEPSIS-3 (increase in sequential
organ failure score greater than or equal to 2) criteria with at least two sets
of blood culture were selected. Collected data was initially analyzed
independently to identify the significant predictors, which was then used to
build the multivariable logistic regression (MLR) model. A total of 218
patients with 48 cases of true bacteremia were analyzed in this research. Both
CRP and PCT showed a substantial area under the curve (AUC) value for
discriminating bacteremia among septic patients (0.757 and 0.845,
respectively). To further enhance the predictive accuracy, we combined PCT,
bilirubin, neutrophil lymphocyte ratio (NLR), platelets, lactic acid,
erythrocyte sedimentation rate (ESR), and Glasgow Coma Scale (GCS) score to
build the predictive model with an AUC of 0.907 (95% CI, 0.843 to 0.956). In
addition, a high association between bacteremia and mortality rate was
discovered through the survival analysis (0.004). While PCT is certainly a
useful index for distinguishing patients with and without bacteremia by itself,
our MLR model indicates that the accuracy of bacteremia prediction
substantially improves by the combined use of PCT, bilirubin, NLR, platelets,
lactic acid, ESR, and GCS score.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08870">One-Shot Federated Learning with Classifier-Guided Diffusion Models. (arXiv:2311.08870v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Mingzhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1">Shangchao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xiangyang Xue</a></p>
<p>One-shot federated learning (OSFL) has gained attention in recent years due
to its low communication cost. However, most of the existing methods require
auxiliary datasets or training generators, which hinders their practicality in
real-world scenarios. In this paper, we explore the novel opportunities that
diffusion models bring to OSFL and propose FedCADO, utilizing guidance from
client classifiers to generate data that complies with clients' distributions
and subsequently training the aggregated model on the server. Specifically, our
method involves targeted optimizations in two aspects. On one hand, we
conditionally edit the randomly sampled initial noises, embedding them with
specified semantics and distributions, resulting in a significant improvement
in both the quality and stability of generation. On the other hand, we employ
the BN statistics from the classifiers to provide detailed guidance during
generation. These tailored optimizations enable us to limitlessly generate
datasets, which closely resemble the distribution and quality of the original
client dataset. Our method effectively handles the heterogeneous client models
and the problems of non-IID features or labels. In terms of privacy protection,
our method avoids training any generator or transferring any auxiliary
information on clients, eliminating any additional privacy leakage risks.
Leveraging the extensive knowledge stored in the pre-trained diffusion model,
the synthetic datasets can assist us in surpassing the knowledge limitations of
the client samples, resulting in aggregation models that even outperform the
performance ceiling of centralized training in some cases, which is
convincingly demonstrated in the sufficient quantification and visualization
experiments conducted on three large-scale multi-domain image datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2010.10242">Ulixes: Facial Recognition Privacy with Adversarial Machine Learning. (arXiv:2010.10242v2 [cs.CV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cilloni_T/0/1/0/all/0/1">Thomas Cilloni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Walter_C/0/1/0/all/0/1">Charles Walter</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleming_C/0/1/0/all/0/1">Charles Fleming</a></p>
<p>Facial recognition tools are becoming exceptionally accurate in identifying
people from images. However, this comes at the cost of privacy for users of
online services with photo management (e.g. social media platforms).
Particularly troubling is the ability to leverage unsupervised learning to
recognize faces even when the user has not labeled their images. In this paper
we propose Ulixes, a strategy to generate visually non-invasive facial noise
masks that yield adversarial examples, preventing the formation of identifiable
user clusters in the embedding space of facial encoders. This is applicable
even when a user is unmasked and labeled images are available online. We
demonstrate the effectiveness of Ulixes by showing that various classification
and clustering methods cannot reliably label the adversarial examples we
generate. We also study the effects of Ulixes in various black-box settings and
compare it to the current state of the art in adversarial machine learning.
Finally, we challenge the effectiveness of Ulixes against adversarially trained
models and show that it is robust to countermeasures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.00282">FedScore: A privacy-preserving framework for federated scoring system development. (arXiv:2303.00282v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1">Yilin Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Ong_M/0/1/0/all/0/1">Marcus Eng Hock Ong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_B/0/1/0/all/0/1">Bibhas Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1">Chuan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1">Feng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Han Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingxuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckland_D/0/1/0/all/0/1">Daniel M. Buckland</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Nan Liu</a></p>
<p>We propose FedScore, a privacy-preserving federated learning framework for
scoring system generation across multiple sites to facilitate
cross-institutional collaborations. The FedScore framework includes five
modules: federated variable ranking, federated variable transformation,
federated score derivation, federated model selection and federated model
evaluation. To illustrate usage and assess FedScore's performance, we built a
hypothetical global scoring system for mortality prediction within 30 days
after a visit to an emergency department using 10 simulated sites divided from
a tertiary hospital in Singapore. We employed a pre-existing score generator to
construct 10 local scoring systems independently at each site and we also
developed a scoring system using centralized data for comparison. We compared
the acquired FedScore model's performance with that of other scoring models
using the receiver operating characteristic (ROC) analysis. The FedScore model
achieved an average area under the curve (AUC) value of 0.763 across all sites,
with a standard deviation (SD) of 0.020. We also calculated the average AUC
values and SDs for each local model, and the FedScore model showed promising
accuracy and stability with a high average AUC value which was closest to the
one of the pooled model and SD which was lower than that of most local models.
This study demonstrates that FedScore is a privacy-preserving scoring system
generator with potentially good generalizability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05853">Reframing Audience Expansion through the Lens of Probability Density Estimation. (arXiv:2311.05853v1 [cs.AI] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Carvalhaes_C/0/1/0/all/0/1">Claudio Carvalhaes</a></p>
<p>Audience expansion has become an important element of prospective marketing,
helping marketers create target audiences based on a mere representative sample
of their current customer base. Within the realm of machine learning, a favored
algorithm for scaling this sample into a broader audience hinges on a binary
classification task, with class probability estimates playing a crucial role.
In this paper, we review this technique and introduce a key change in how we
choose training examples to ensure the quality of the generated audience. We
present a simulation study based on the widely used MNIST dataset, where
consistent high precision and recall values demonstrate our approach's ability
to identify the most relevant users for an expanded audience. Our results are
easily reproducible and a Python implementation is openly available on GitHub:
\url{https://github.com/carvalhaes-ai/audience-expansion}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08811">Correlation-aware active learning for surgery video segmentation. (arXiv:2311.08811v1 [cs.CV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquez_Neila_P/0/1/0/all/0/1">Pablo Marquez-Neila</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Mingyi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafii_Tari_H/0/1/0/all/0/1">Hedyeh Rafii-Tari</a>, <a href="http://arxiv.org/find/cs/1/au:+Sznitman_R/0/1/0/all/0/1">Raphael Sznitman</a></p>
<p>Semantic segmentation is a complex task that relies heavily on large amounts
of annotated image data. However, annotating such data can be time-consuming
and resource-intensive, especially in the medical domain. Active Learning (AL)
is a popular approach that can help to reduce this burden by iteratively
selecting images for annotation to improve the model performance. In the case
of video data, it is important to consider the model uncertainty and the
temporal nature of the sequences when selecting images for annotation. This
work proposes a novel AL strategy for surgery video segmentation, \COALSamp{},
COrrelation-aWare Active Learning. Our approach involves projecting images into
a latent space that has been fine-tuned using contrastive learning and then
selecting a fixed number of representative images from local clusters of video
frames. We demonstrate the effectiveness of this approach on two video datasets
of surgical instruments and three real-world video datasets. The datasets and
code will be made publicly available upon receiving necessary approvals.
</p>
</p>
</div>

    </div>
    </body>
    