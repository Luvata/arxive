<!DOCTYPE html>
<html>
<head>
<title>2023-12-25-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2312.13289">Stoichiometry Representation Learning with Polymorphic Crystal Structures. (arXiv:2312.13289v1 [cond-mat.mtrl-sci])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Lee_N/0/1/0/all/0/1">Namkyeong Lee</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Noh_H/0/1/0/all/0/1">Heewoong Noh</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Na_G/0/1/0/all/0/1">Gyoung S. Na</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fu_T/0/1/0/all/0/1">Tianfan Fu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Park_C/0/1/0/all/0/1">Chanyoung Park</a></p>
<p>Despite the recent success of machine learning (ML) in materials science, its
success heavily relies on the structural description of crystal, which is
itself computationally demanding and occasionally unattainable. Stoichiometry
descriptors can be an alternative approach, which reveals the ratio between
elements involved to form a certain compound without any structural
information. However, it is not trivial to learn the representations of
stoichiometry due to the nature of materials science called polymorphism, i.e.,
a single stoichiometry can exist in multiple structural forms due to the
flexibility of atomic arrangements, inducing uncertainties in representation.
To this end, we propose PolySRL, which learns the probabilistic representation
of stoichiometry by utilizing the readily available structural information,
whose uncertainty reveals the polymorphic structures of stoichiometry.
Extensive experiments on sixteen datasets demonstrate the superiority of
PolySRL, and analysis of uncertainties shed light on the applicability of
PolySRL in real-world material discovery. The source code for PolySRL is
available at https://github.com/Namkyeong/PolySRL_AI4Science.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13301">SimQ-NAS: Simultaneous Quantization Policy and Neural Architecture Search. (arXiv:2312.13301v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sridhar_S/0/1/0/all/0/1">Sharath Nittur Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Szankin_M/0/1/0/all/0/1">Maciej Szankin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_S/0/1/0/all/0/1">Sairam Sundaresan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarah_A/0/1/0/all/0/1">Anthony Sarah</a></p>
<p>Recent one-shot Neural Architecture Search algorithms rely on training a
hardware-agnostic super-network tailored to a specific task and then extracting
efficient sub-networks for different hardware platforms. Popular approaches
separate the training of super-networks from the search for sub-networks, often
employing predictors to alleviate the computational overhead associated with
search. Additionally, certain methods also incorporate the quantization policy
within the search space. However, while the quantization policy search for
convolutional neural networks is well studied, the extension of these methods
to transformers and especially foundation models remains under-explored. In
this paper, we demonstrate that by using multi-objective search algorithms
paired with lightly trained predictors, we can efficiently search for both the
sub-network architecture and the corresponding quantization policy and
outperform their respective baselines across different performance objectives
such as accuracy, model size, and latency. Specifically, we demonstrate that
our approach performs well across both uni-modal (ViT and BERT) and multi-modal
(BEiT-3) transformer-based architectures as well as convolutional architectures
(ResNet). For certain networks, we demonstrate an improvement of up to $4.80x$
and $3.44x$ for latency and model size respectively, without degradation in
accuracy compared to the fully quantized INT8 baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13302">Longitudinal prediction of DNA methylation to forecast epigenetic outcomes. (arXiv:2312.13302v1 [q-bio.GN])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Leroy_A/0/1/0/all/0/1">Arthur Leroy</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Teh_A/0/1/0/all/0/1">Ai Ling Teh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dondelinger_F/0/1/0/all/0/1">Frank Dondelinger</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Alvarez_M/0/1/0/all/0/1">Mauricio A. Alvarez</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_D/0/1/0/all/0/1">Dennis Wang</a></p>
<p>Interrogating the evolution of biological changes at early stages of life
requires longitudinal profiling of molecules, such as DNA methylation, which
can be challenging with children. We introduce a probabilistic and longitudinal
machine learning framework based on multi-mean Gaussian processes (GPs),
accounting for individual and gene correlations across time. This method
provides future predictions of DNA methylation status at different individual
ages while accounting for uncertainty. Our model is trained on a birth cohort
of children with methylation profiled at ages 0-4, and we demonstrated that the
status of methylation sites for each child can be accurately predicted at ages
5-7. We show that methylation profiles predicted by multi-mean GPs can be used
to estimate other phenotypes, such as epigenetic age, and enable comparison to
other health measures of interest. This approach encourages epigenetic studies
to move towards longitudinal design for investigating epigenetic changes during
development, ageing and disease progression.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13303">RealGen: Retrieval Augmented Generation for Controllable Traffic Scenarios. (arXiv:2312.13303v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenhao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yulong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a></p>
<p>Simulation plays a crucial role in the development of autonomous vehicles
(AVs) due to the potential risks associated with real-world testing. Although
significant progress has been made in the visual aspects of simulators,
generating complex behavior among agents remains a formidable challenge. It is
not only imperative to ensure realism in the scenarios generated but also
essential to incorporate preferences and conditions to facilitate controllable
generation for AV training and evaluation. Traditional methods, mainly relying
on memorizing the distribution of training datasets, often fall short in
generating unseen scenarios. Inspired by the success of retrieval augmented
generation in large language models, we present RealGen, a novel
retrieval-based in-context learning framework for traffic scenario generation.
RealGen synthesizes new scenarios by combining behaviors from multiple
retrieved examples in a gradient-free way, which may originate from templates
or tagged scenarios. This in-context learning framework endows versatile
generative capabilities, including the ability to edit scenarios, compose
various behaviors, and produce critical scenarios. Evaluations show that
RealGen offers considerable flexibility and controllability, marking a new
direction in the field of controllable traffic scenario generation. Check our
project website for more information: https://realgen.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13306">Towards Fair Graph Federated Learning via Incentive Mechanisms. (arXiv:2312.13306v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1">Chenglu Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiarong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingbiao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chunping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a></p>
<p>Graph federated learning (FL) has emerged as a pivotal paradigm enabling
multiple agents to collaboratively train a graph model while preserving local
data privacy. Yet, current efforts overlook a key issue: agents are
self-interested and would hesitant to share data without fair and satisfactory
incentives. This paper is the first endeavor to address this issue by studying
the incentive mechanism for graph federated learning. We identify a unique
phenomenon in graph federated learning: the presence of agents posing potential
harm to the federation and agents contributing with delays. This stands in
contrast to previous FL incentive mechanisms that assume all agents contribute
positively and in a timely manner. In view of this, this paper presents a novel
incentive mechanism tailored for fair graph federated learning, integrating
incentives derived from both model gradient and payoff. To achieve this, we
first introduce an agent valuation function aimed at quantifying agent
contributions through the introduction of two criteria: gradient alignment and
graph diversity. Moreover, due to the high heterogeneity in graph federated
learning, striking a balance between accuracy and fairness becomes particularly
crucial. We introduce motif prototypes to enhance accuracy, communicated
between the server and agents, enhancing global model aggregation and aiding
agents in local model optimization. Extensive experiments show that our model
achieves the best trade-off between accuracy and the fairness of model
gradient, as well as superior payoff fairness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13307">Not All Steps are Equal: Efficient Generation with Progressive Diffusion Models. (arXiv:2312.13307v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1">Xiu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1">Shan You</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1">Chen Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a></p>
<p>Diffusion models have demonstrated remarkable efficacy in various generative
tasks with the predictive prowess of denoising model. Currently, these models
employ a uniform denoising approach across all timesteps. However, the inherent
variations in noisy latents at each timestep lead to conflicts during training,
constraining the potential of diffusion models. To address this challenge, we
propose a novel two-stage training strategy termed Step-Adaptive Training. In
the initial stage, a base denoising model is trained to encompass all
timesteps. Subsequently, we partition the timesteps into distinct groups,
fine-tuning the model within each group to achieve specialized denoising
capabilities. Recognizing that the difficulties of predicting noise at
different timesteps vary, we introduce a diverse model size requirement. We
dynamically adjust the model size for each timestep by estimating task
difficulty based on its signal-to-noise ratio before fine-tuning. This
adjustment is facilitated by a proxy-based structural importance assessment
mechanism, enabling precise and efficient pruning of the base denoising model.
Our experiments validate the effectiveness of the proposed training strategy,
demonstrating an improvement in the FID score on CIFAR10 by over 0.3 while
utilizing only 80\% of the computational resources. This innovative approach
not only enhances model performance but also significantly reduces
computational costs, opening new avenues for the development and application of
diffusion models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13311">Unlocking Deep Learning: A BP-Free Approach for Parallel Block-Wise Training of Neural Networks. (arXiv:2312.13311v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_A/0/1/0/all/0/1">Anzhe Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhenkun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Chenzhong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Mingxi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_H/0/1/0/all/0/1">Heng Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xiongye Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazarian_S/0/1/0/all/0/1">Shahin Nazarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1">Paul Bogdan</a></p>
<p>Backpropagation (BP) has been a successful optimization technique for deep
learning models. However, its limitations, such as backward- and
update-locking, and its biological implausibility, hinder the concurrent
updating of layers and do not mimic the local learning processes observed in
the human brain. To address these issues, recent research has suggested using
local error signals to asynchronously train network blocks. However, this
approach often involves extensive trial-and-error iterations to determine the
best configuration for local training. This includes decisions on how to
decouple network blocks and which auxiliary networks to use for each block. In
our work, we introduce a novel BP-free approach: a block-wise BP-free (BWBPF)
neural network that leverages local error signals to optimize distinct
sub-neural networks separately, where the global loss is only responsible for
updating the output layer. The local error signals used in the BP-free model
can be computed in parallel, enabling a potential speed-up in the weight update
process through parallel implementation. Our experimental results consistently
show that this approach can identify transferable decoupled architectures for
VGG and ResNet variations, outperforming models trained with end-to-end
backpropagation and other state-of-the-art block-wise learning techniques on
datasets such as CIFAR-10 and Tiny-ImageNet. The code is released at
https://github.com/Belis0811/BWBPF.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13312">Multi-label Learning from Privacy-Label. (arXiv:2312.13312v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhongnian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Haotian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tongfeng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhichen Li</a></p>
<p>Multi-abel Learning (MLL) often involves the assignment of multiple relevant
labels to each instance, which can lead to the leakage of sensitive information
(such as smoking, diseases, etc.) about the instances. However, existing MLL
suffer from failures in protection for sensitive information. In this paper, we
propose a novel setting named Multi-Label Learning from Privacy-Label (MLLPL),
which Concealing Labels via Privacy-Label Unit (CLPLU). Specifically, during
the labeling phase, each privacy-label is randomly combined with a non-privacy
label to form a Privacy-Label Unit (PLU). If any label within a PLU is
positive, the unit is labeled as positive; otherwise, it is labeled negative,
as shown in Figure 1. PLU ensures that only non-privacy labels are appear in
the label set, while the privacy-labels remain concealed. Moreover, we further
propose a Privacy-Label Unit Loss (PLUL) to learn the optimal classifier by
minimizing the empirical risk of PLU. Experimental results on multiple
benchmark datasets demonstrate the effectiveness and superiority of the
proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13314">Unlocking Pre-trained Image Backbones for Semantic Image Synthesis. (arXiv:2312.13314v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Berrada_T/0/1/0/all/0/1">Tariq Berrada</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1">Jakob Verbeek</a>, <a href="http://arxiv.org/find/cs/1/au:+Couprie_C/0/1/0/all/0/1">Camille Couprie</a>, <a href="http://arxiv.org/find/cs/1/au:+Alahari_K/0/1/0/all/0/1">Karteek Alahari</a></p>
<p>Semantic image synthesis, i.e., generating images from user-provided semantic
label maps, is an important conditional image generation task as it allows to
control both the content as well as the spatial layout of generated images.
Although diffusion models have pushed the state of the art in generative image
modeling, the iterative nature of their inference process makes them
computationally demanding. Other approaches such as GANs are more efficient as
they only need a single feed-forward pass for generation, but the image quality
tends to suffer on large and diverse datasets. In this work, we propose a new
class of GAN discriminators for semantic image synthesis that generates highly
realistic images by exploiting feature backbone networks pre-trained for tasks
such as image classification. We also introduce a new generator architecture
with better context modeling and using cross-attention to inject noise into
latent variables, leading to more diverse generated images. Our model, which we
dub DP-SIMS, achieves state-of-the-art results in terms of image quality and
consistency with the input label maps on ADE-20K, COCO-Stuff, and Cityscapes,
surpassing recent diffusion models while requiring two orders of magnitude less
compute for inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13318">One-Shot Initial Orbit Determination in Low-Earth Orbit. (arXiv:2312.13318v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Ferreira_R/0/1/0/all/0/1">Ricardo Ferreira</a>, <a href="http://arxiv.org/find/eess/1/au:+Guimaraes_M/0/1/0/all/0/1">Marta Guimar&#xe3;es</a>, <a href="http://arxiv.org/find/eess/1/au:+Valdeira_F/0/1/0/all/0/1">Filipa Valdeira</a>, <a href="http://arxiv.org/find/eess/1/au:+Soares_C/0/1/0/all/0/1">Cl&#xe1;udia Soares</a></p>
<p>Due to the importance of satellites for society and the exponential increase
in the number of objects in orbit, it is important to accurately determine the
state (e.g., position and velocity) of these Resident Space Objects (RSOs) at
any time and in a timely manner. State-of-the-art methodologies for initial
orbit determination consist of Kalman-type filters that process sequential data
over time and return the state and associated uncertainty of the object, as is
the case of the Extended Kalman Filter (EKF). However, these methodologies are
dependent on a good initial guess for the state vector and usually simplify the
physical dynamical model, due to the difficulty of precisely modeling
perturbative forces, such as atmospheric drag and solar radiation pressure.
Other approaches do not require assumptions about the dynamical system, such as
the trilateration method, and require simultaneous measurements, such as three
measurements of range and range-rate for the particular case of trilateration.
We consider the same setting of simultaneous measurements (one-shot), resorting
to time delay and Doppler shift measurements. Based on recent advancements in
the problem of moving target localization for sonar multistatic systems, we are
able to formulate the problem of initial orbit determination as a Weighted
Least Squares. With this approach, we are able to directly obtain the state of
the object (position and velocity) and the associated covariance matrix from
the Fisher's Information Matrix (FIM). We demonstrate that, for small noise,
our estimator is able to attain the Cram\'er-Rao Lower Bound accuracy, i.e.,
the accuracy attained by the unbiased estimator with minimum variance. We also
numerically demonstrate that our estimator is able to attain better accuracy on
the state estimation than the trilateration method and returns a smaller
uncertainty associated with the estimation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13322">Domain-Specific Code Language Models: Unraveling the Potential for HPC Codes and Tasks. (arXiv:2312.13322v1 [cs.PL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kadosh_T/0/1/0/all/0/1">Tal Kadosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasabnis_N/0/1/0/all/0/1">Niranjan Hasabnis</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1">Vy A. Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1">Nadav Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Krien_N/0/1/0/all/0/1">Neva Krien</a>, <a href="http://arxiv.org/find/cs/1/au:+Capota_M/0/1/0/all/0/1">Mihai Capota</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasay_A/0/1/0/all/0/1">Abdul Wasay</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1">Nesreen Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Willke_T/0/1/0/all/0/1">Ted Willke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamir_G/0/1/0/all/0/1">Guy Tamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinter_Y/0/1/0/all/0/1">Yuval Pinter</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1">Timothy Mattson</a>, <a href="http://arxiv.org/find/cs/1/au:+Oren_G/0/1/0/all/0/1">Gal Oren</a></p>
<p>With easier access to powerful compute resources, there is a growing trend in
AI for software development to develop larger language models (LLMs) to address
a variety of programming tasks. Even LLMs applied to tasks from the
high-performance computing (HPC) domain are huge in size and demand expensive
compute resources for training. This is partly because these LLMs for HPC tasks
are obtained by finetuning existing LLMs that support several natural and/or
programming languages. We found this design choice confusing - why do we need
large LMs trained on natural languages and programming languages unrelated to
HPC for HPC-specific tasks?
</p>
<p>In this line of work, we aim to question choices made by existing LLMs by
developing smaller LMs for specific domains - we call them domain-specific LMs.
Specifically, we start off with HPC as a domain and build an HPC-specific LM,
named MonoCoder, that is orders of magnitude smaller than existing LMs but
delivers similar, if not better performance, on non-HPC and HPC tasks.
Specifically, we pre-trained MonoCoder on an HPC-specific dataset (named
HPCorpus) of C and C++ programs mined from GitHub. We evaluated the performance
of MonoCoder against conventional multi-lingual LLMs. Results demonstrate that
MonoCoder, although much smaller than existing LMs, achieves similar results on
normalized-perplexity tests and much better ones in CodeBLEU competence for
high-performance and parallel code generations. Furthermore, fine-tuning the
base model for the specific task of parallel code generation (OpenMP parallel
for pragmas) demonstrates outstanding results compared to GPT, especially when
local misleading semantics are removed by our novel pre-processor Tokompiler,
showcasing the ability of domain-specific models to assist in HPC-relevant
tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13327">In-Context Reinforcement Learning for Variable Action Spaces. (arXiv:2312.13327v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sinii_V/0/1/0/all/0/1">Viacheslav Sinii</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikulin_A/0/1/0/all/0/1">Alexander Nikulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurenkov_V/0/1/0/all/0/1">Vladislav Kurenkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisman_I/0/1/0/all/0/1">Ilya Zisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_S/0/1/0/all/0/1">Sergey Kolesnikov</a></p>
<p>Recent work has shown that supervised pre-training on learning histories of
RL algorithms results in a model that captures the learning process and is able
to improve in-context on novel tasks through interactions with an environment.
Despite the progress in this area, there is still a gap in the existing
literature, particularly in the in-context generalization to new action spaces.
While existing methods show high performance on new tasks created by different
reward distributions, their architectural design and training process are not
suited for the introduction of new actions during evaluation. We aim to bridge
this gap by developing an architecture and training methodology specifically
for the task of generalizing to new action spaces. Inspired by Headless LLM, we
remove the dependence on the number of actions by directly predicting the
action embeddings. Furthermore, we use random embeddings to force the semantic
inference of actions from context and to prepare for the new unseen embeddings
during test time. Using multi-armed bandit environments with a variable number
of arms, we show that our model achieves the performance of the data generation
algorithm without requiring retraining for each new environment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13334">Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection. (arXiv:2312.13334v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Awosika_T/0/1/0/all/0/1">Tomisin Awosika</a>, <a href="http://arxiv.org/find/cs/1/au:+Shukla_R/0/1/0/all/0/1">Raj Mani Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Pranggono_B/0/1/0/all/0/1">Bernardi Pranggono</a></p>
<p>Fraudulent transactions and how to detect them remain a significant problem
for financial institutions around the world. The need for advanced fraud
detection systems to safeguard assets and maintain customer trust is paramount
for financial institutions, but some factors make the development of effective
and efficient fraud detection systems a challenge. One of such factors is the
fact that fraudulent transactions are rare and that many transaction datasets
are imbalanced; that is, there are fewer significant samples of fraudulent
transactions than legitimate ones. This data imbalance can affect the
performance or reliability of the fraud detection model. Moreover, due to the
data privacy laws that all financial institutions are subject to follow,
sharing customer data to facilitate a higher-performing centralized model is
impossible. Furthermore, the fraud detection technique should be transparent so
that it does not affect the user experience. Hence, this research introduces a
novel approach using Federated Learning (FL) and Explainable AI (XAI) to
address these challenges. FL enables financial institutions to collaboratively
train a model to detect fraudulent transactions without directly sharing
customer data, thereby preserving data privacy and confidentiality. Meanwhile,
the integration of XAI ensures that the predictions made by the model can be
understood and interpreted by human experts, adding a layer of transparency and
trust to the system. Experimental results, based on realistic transaction
datasets, reveal that the FL-based fraud detection system consistently
demonstrates high performance metrics. This study grounds FL's potential as an
effective and privacy-preserving tool in the fight against fraud.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13379">Sampling Complexity of Deep Approximation Spaces. (arXiv:2312.13379v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdeljawad_A/0/1/0/all/0/1">Ahmed Abdeljawad</a>, <a href="http://arxiv.org/find/cs/1/au:+Grohs_P/0/1/0/all/0/1">Philipp Grohs</a></p>
<p>While it is well-known that neural networks enjoy excellent approximation
capabilities, it remains a big challenge to compute such approximations from
point samples. Based on tools from Information-based complexity, recent work by
Grohs and Voigtlaender [Journal of the FoCM (2023)] developed a rigorous
framework for assessing this so-called "theory-to-practice gap". More
precisely, in that work it is shown that there exist functions that can be
approximated by neural networks with ReLU activation function at an arbitrary
rate while requiring an exponentially growing (in the input dimension) number
of samples for their numerical computation. The present study extends these
findings by showing analogous results for the ReQU activation function.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13380">Fed-QSSL: A Framework for Personalized Federated Learning under Bitwidth and Data Heterogeneity. (arXiv:2312.13380v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiyue Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vikalo_H/0/1/0/all/0/1">Haris Vikalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chianing Wang</a></p>
<p>Motivated by high resource costs of centralized machine learning schemes as
well as data privacy concerns, federated learning (FL) emerged as an efficient
alternative that relies on aggregating locally trained models rather than
collecting clients' potentially private data. In practice, available resources
and data distributions vary from one client to another, creating an inherent
system heterogeneity that leads to deterioration of the performance of
conventional FL algorithms. In this work, we present a federated
quantization-based self-supervised learning scheme (Fed-QSSL) designed to
address heterogeneity in FL systems. At clients' side, to tackle data
heterogeneity we leverage distributed self-supervised learning while utilizing
low-bit quantization to satisfy constraints imposed by local infrastructure and
limited communication resources. At server's side, Fed-QSSL deploys
de-quantization, weighted aggregation and re-quantization, ultimately creating
models personalized to both data distribution as well as specific
infrastructure of each client's device. We validated the proposed algorithm on
real world datasets, demonstrating its efficacy, and theoretically analyzed
impact of low-bit training on the convergence and robustness of the learned
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13385">ORBSLAM3-Enhanced Autonomous Toy Drones: Pioneering Indoor Exploration. (arXiv:2312.13385v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tukan_M/0/1/0/all/0/1">Murad Tukan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fares_F/0/1/0/all/0/1">Fares Fares</a>, <a href="http://arxiv.org/find/cs/1/au:+Grufinkle_Y/0/1/0/all/0/1">Yotam Grufinkle</a>, <a href="http://arxiv.org/find/cs/1/au:+Talmor_I/0/1/0/all/0/1">Ido Talmor</a>, <a href="http://arxiv.org/find/cs/1/au:+Mualem_L/0/1/0/all/0/1">Loay Mualem</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1">Dan Feldman</a></p>
<p>Navigating toy drones through uncharted GPS-denied indoor spaces poses
significant difficulties due to their reliance on GPS for location
determination. In such circumstances, the necessity for achieving proper
navigation is a primary concern. In response to this formidable challenge, we
introduce a real-time autonomous indoor exploration system tailored for drones
equipped with a monocular \emph{RGB} camera.
</p>
<p>Our system utilizes \emph{ORB-SLAM3}, a state-of-the-art vision feature-based
SLAM, to handle both the localization of toy drones and the mapping of unmapped
indoor terrains. Aside from the practicability of \emph{ORB-SLAM3}, the
generated maps are represented as sparse point clouds, making them prone to the
presence of outlier data. To address this challenge, we propose an outlier
removal algorithm with provable guarantees. Furthermore, our system
incorporates a novel exit detection algorithm, ensuring continuous exploration
by the toy drone throughout the unfamiliar indoor environment. We also
transform the sparse point to ensure proper path planning using existing path
planners.
</p>
<p>To validate the efficacy and efficiency of our proposed system, we conducted
offline and real-time experiments on the autonomous exploration of indoor
spaces. The results from these endeavors demonstrate the effectiveness of our
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13389">Enhancing Trade-offs in Privacy, Utility, and Computational Efficiency through MUltistage Sampling Technique (MUST). (arXiv:2312.13389v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zhao_X/0/1/0/all/0/1">Xingyuan Zhao</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_F/0/1/0/all/0/1">Fang Liu</a></p>
<p>Applying a randomized algorithm to a subset of a dataset rather than the
entire dataset is a common approach to amplify its privacy guarantees in the
released information. We propose a class of subsampling methods named
MUltistage Sampling Technique (MUST) for privacy amplification (PA) in the
context of differential privacy (DP). We conduct comprehensive analyses of the
PA effects and utility for several 2-stage MUST procedures, namely, MUST.WO,
MUST.OW, and MUST.WW that respectively represent sampling with (W), without
(O), with (W) replacement from the original dataset in stage I and then
sampling without (O), with (W), with (W) replacement in stage II from the
subset drawn in stage I. We also provide the privacy composition analysis over
repeated applications of MUST via the Fourier accountant algorithm. Our
theoretical and empirical results suggest that MUST.OW and MUST.WW have
stronger PA in $\epsilon$ than the common one-stage sampling procedures
including Poisson sampling, sampling without replacement, and sampling with
replacement, while the results on $\delta$ vary case by case. We also prove
that MUST.WO is equivalent to sampling with replacement in PA. Furthermore, the
final subset generated by a MUST procedure is a multiset that may contain
multiple copies of the same data points due to sampling with replacement
involved, which enhances the computational efficiency of algorithms that
require complex function calculations on distinct data points (e.g., gradient
descent). Our utility experiments show that MUST delivers similar or improved
utility and stability in the privacy-preserving outputs compared to one-stage
subsampling methods at similar privacy loss. MUST can be seamlessly integrated
into stochastic optimization algorithms or procedures that involve parallel or
simultaneous subsampling (e.g., bagging and subsampling bootstrap) when DP
guarantees are necessary.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13397">Review and experimental benchmarking of machine learning algorithms for efficient optimization of cold atom experiments. (arXiv:2312.13397v1 [physics.atom-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Anton_O/0/1/0/all/0/1">Oliver Anton</a>, <a href="http://arxiv.org/find/physics/1/au:+Henderson_V/0/1/0/all/0/1">Victoria A. Henderson</a>, <a href="http://arxiv.org/find/physics/1/au:+Ros_E/0/1/0/all/0/1">Elisa Da Ros</a>, <a href="http://arxiv.org/find/physics/1/au:+Sekulic_I/0/1/0/all/0/1">Ivan Sekulic</a>, <a href="http://arxiv.org/find/physics/1/au:+Burger_S/0/1/0/all/0/1">Sven Burger</a>, <a href="http://arxiv.org/find/physics/1/au:+Schneider_P/0/1/0/all/0/1">Philipp-Immanuel Schneider</a>, <a href="http://arxiv.org/find/physics/1/au:+Krutzik_M/0/1/0/all/0/1">Markus Krutzik</a></p>
<p>The generation of cold atom clouds is a complex process which involves the
optimization of noisy data in high dimensional parameter spaces. Optimization
can be challenging both in and especially outside of the lab due to lack of
time, expertise, or access for lengthy manual optimization. In recent years, it
was demonstrated that machine learning offers a solution since it can optimize
high dimensional problems quickly, without knowledge of the experiment itself.
In this paper we present results showing the benchmarking of nine different
optimization techniques and implementations, alongside their ability to
optimize a Rubidium (Rb) cold atom experiment. The investigations are performed
on a 3D $^{87}$Rb molasses with 10 and 18 adjustable parameters, respectively,
where the atom number obtained by absorption imaging was chosen as the test
problem. We further compare the best performing optimizers under different
effective noise conditions by reducing the Signal-to-Noise ratio of the images
via adapting the atomic vapor pressure in the 2D+ MOT and the detection laser
frequency stability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13403">Packed-Ensemble Surrogate Models for Fluid Flow Estimation Arround Airfoil Geometries. (arXiv:2312.13403v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kalaydjian_A/0/1/0/all/0/1">Anthony Kalaydjian</a>, <a href="http://arxiv.org/find/cs/1/au:+Balykov_A/0/1/0/all/0/1">Anton Balykov</a>, <a href="http://arxiv.org/find/cs/1/au:+Semiz_A/0/1/0/all/0/1">Alexi Semiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_Hon_Tong_A/0/1/0/all/0/1">Adrien Chan-Hon-Tong</a></p>
<p>Physical based simulations can be very time and computationally demanding
tasks. One way of accelerating these processes is by making use of data-driven
surrogate models that learn from existing simulations. Ensembling methods are
particularly relevant in this domain as their smoothness properties coincide
with the smoothness of physical phenomena. The drawback is that they can remain
costly. This research project focused on studying Packed-Ensembles that
generalize Deep Ensembles but remain faster to train. Several models have been
trained and compared in terms of multiple important metrics. PE(8,4,1) has been
identified as the clear winner in this particular task, beating down its Deep
Ensemble conterpart while accelerating the training time by 25%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13422">Texture Matching GAN for CT Image Enhancement. (arXiv:2312.13422v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Nagare_M/0/1/0/all/0/1">Madhuri Nagare</a>, <a href="http://arxiv.org/find/eess/1/au:+Buzzard_G/0/1/0/all/0/1">Gregery T. Buzzard</a>, <a href="http://arxiv.org/find/eess/1/au:+Bouman_C/0/1/0/all/0/1">Charles A. Bouman</a></p>
<p>Deep neural networks (DNN) are commonly used to denoise and sharpen X-ray
computed tomography (CT) images with the goal of reducing patient X-ray dosage
while maintaining reconstruction quality. However, naive application of
DNN-based methods can result in image texture that is undesirable in clinical
applications. Alternatively, generative adversarial network (GAN) based methods
can produce appropriate texture, but naive application of GANs can introduce
inaccurate or even unreal image detail. In this paper, we propose a texture
matching generative adversarial network (TMGAN) that enhances CT images while
generating an image texture that can be matched to a target texture. We use
parallel generators to separate anatomical features from the generated texture,
which allows the GAN to be trained to match the desired texture without
directly affecting the underlying CT image. We demonstrate that TMGAN generates
enhanced image quality while also producing image texture that is desirable for
clinical application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13426">Consistent Long-Term Forecasting of Ergodic Dynamical Systems. (arXiv:2312.13426v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Inzerilli_P/0/1/0/all/0/1">Prune Inzerilli</a>, <a href="http://arxiv.org/find/stat/1/au:+Kostic_V/0/1/0/all/0/1">Vladimir Kostic</a>, <a href="http://arxiv.org/find/stat/1/au:+Lounici_K/0/1/0/all/0/1">Karim Lounici</a>, <a href="http://arxiv.org/find/stat/1/au:+Novelli_P/0/1/0/all/0/1">Pietro Novelli</a>, <a href="http://arxiv.org/find/stat/1/au:+Pontil_M/0/1/0/all/0/1">Massimiliano Pontil</a></p>
<p>We study the evolution of distributions under the action of an ergodic
dynamical system, which may be stochastic in nature. By employing tools from
Koopman and transfer operator theory one can evolve any initial distribution of
the state forward in time, and we investigate how estimators of these operators
perform on long-term forecasting. Motivated by the observation that standard
estimators may fail at this task, we introduce a learning paradigm that neatly
combines classical techniques of eigenvalue deflation from operator theory and
feature centering from statistics. This paradigm applies to any operator
estimator based on empirical risk minimization, making them satisfy learning
bounds which hold uniformly on the entire trajectory of future distributions,
and abide to the conservation of mass for each of the forecasted distributions.
Numerical experiments illustrates the advantages of our approach in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13437">A General Model for Aggregating Annotations Across Simple, Complex, and Multi-Object Annotation Tasks. (arXiv:2312.13437v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Braylan_A/0/1/0/all/0/1">Alexander Braylan</a>, <a href="http://arxiv.org/find/cs/1/au:+Marabella_M/0/1/0/all/0/1">Madalyn Marabella</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_O/0/1/0/all/0/1">Omar Alonso</a>, <a href="http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1">Matthew Lease</a></p>
<p>Human annotations are vital to supervised learning, yet annotators often
disagree on the correct label, especially as annotation tasks increase in
complexity. A strategy to improve label quality is to ask multiple annotators
to label the same item and aggregate their labels. Many aggregation models have
been proposed for categorical or numerical annotation tasks, but far less work
has considered more complex annotation tasks involving open-ended,
multivariate, or structured responses. While a variety of bespoke models have
been proposed for specific tasks, our work is the first to introduce
aggregation methods that generalize across many diverse complex tasks,
including sequence labeling, translation, syntactic parsing, ranking, bounding
boxes, and keypoints. This generality is achieved by devising a task-agnostic
method to model distances between labels rather than the labels themselves.
</p>
<p>This article extends our prior work with investigation of three new research
questions. First, how do complex annotation properties impact aggregation
accuracy? Second, how should a task owner navigate the many modeling choices to
maximize aggregation accuracy? Finally, what diagnoses can verify that
aggregation models are specified correctly for the given data? To understand
how various factors impact accuracy and to inform model selection, we conduct
simulation studies and experiments on real, complex datasets. Regarding
testing, we introduce unit tests for aggregation models and present a suite of
such tests to ensure that a given model is not mis-specified and exhibits
expected behavior.
</p>
<p>Beyond investigating these research questions above, we discuss the
foundational concept of annotation complexity, present a new aggregation model
as a bridge between traditional models and our own, and contribute a new
semi-supervised learning method for complex label aggregation that outperforms
prior work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13438">Independent Mechanism Analysis and the Manifold Hypothesis. (arXiv:2312.13438v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1">Shubhangi Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1">Luigi Gresele</a>, <a href="http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1">Michel Besserve</a>, <a href="http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a></p>
<p>Independent Mechanism Analysis (IMA) seeks to address non-identifiability in
nonlinear Independent Component Analysis (ICA) by assuming that the Jacobian of
the mixing function has orthogonal columns. As typical in ICA, previous work
focused on the case with an equal number of latent components and observed
mixtures. Here, we extend IMA to settings with a larger number of mixtures that
reside on a manifold embedded in a higher-dimensional than the latent space --
in line with the manifold hypothesis in representation learning. For this
setting, we show that IMA still circumvents several non-identifiability issues,
suggesting that it can also be a beneficial principle for higher-dimensional
observations when the manifold hypothesis holds. Further, we prove that the IMA
principle is approximately satisfied with high probability (increasing with the
number of observed mixtures) when the directions along which the latent
components influence the observations are chosen independently at random. This
provides a new and rigorous statistical interpretation of IMA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13451">Learning the Factors Controlling Mineralization for Geologic Carbon Sequestration. (arXiv:2312.13451v1 [cs.CE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pachalieva_A/0/1/0/all/0/1">Aleksandra Pachalieva</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyman_J/0/1/0/all/0/1">Jeffrey D. Hyman</a>, <a href="http://arxiv.org/find/cs/1/au:+OMalley_D/0/1/0/all/0/1">Daniel O&#x27;Malley</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanathan_H/0/1/0/all/0/1">Hari Viswanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_G/0/1/0/all/0/1">Gowri Srinivasan</a></p>
<p>We perform a set of flow and reactive transport simulations within
three-dimensional fracture networks to learn the factors controlling mineral
reactions. CO$_2$ mineralization requires CO$_2$-laden water, dissolution of a
mineral that then leads to precipitation of a CO$_2$-bearing mineral. Our
discrete fracture networks (DFN) are partially filled with quartz that
gradually dissolves until it reaches a quasi-steady state. At the end of the
simulation, we measure the quartz remaining in each fracture within the domain.
We observe that a small backbone of fracture exists, where the quartz is fully
dissolved which leads to increased flow and transport. However, depending on
the DFN topology and the rate of dissolution, we observe a large variability of
these changes, which indicates an interplay between the fracture network
structure and the impact of geochemical dissolution. In this work, we developed
a machine learning framework to extract the important features that support
mineralization in the form of dissolution. In addition, we use structural and
topological features of the fracture network to predict the remaining quartz
volume in quasi-steady state conditions. As a first step to characterizing
carbon mineralization, we study dissolution with this framework. We studied a
variety of reaction and fracture parameters and their impact on the dissolution
of quartz in fracture networks. We found that the dissolution reaction rate
constant of quartz and the distance to the flowing backbone in the fracture
network are the two most important features that control the amount of quartz
left in the system. For the first time, we use a combination of a finite-volume
reservoir model and graph-based approach to study reactive transport in a
complex fracture network to determine the key features that control
dissolution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13454">MixEHR-SurG: a joint proportional hazard and guided topic model for inferring mortality-associated topics from electronic health records. (arXiv:2312.13454v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Marelli_A/0/1/0/all/0/1">Ariane Marelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Archer Y. Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yue Li</a></p>
<p>Objective: To improve survival analysis using EHR data, we aim to develop a
supervised topic model called MixEHR-SurG to simultaneously integrate
heterogeneous EHR data and model survival hazard.
</p>
<p>Materials and Methods: Our technical contributions are three-folds: (1)
integrating EHR topic inference with Cox proportional hazards likelihood; (2)
inferring patient-specific topic hyperparameters using the PheCode concepts
such that each topic can be identified with exactly one PheCode-associated
phenotype; (3) multi-modal survival topic inference. This leads to a highly
interpretable survival and guided topic model that can infer PheCode-specific
phenotype topics associated with patient mortality. We evaluated MixEHR-G using
a simulated dataset and two real-world EHR datasets: the Quebec Congenital
Heart Disease (CHD) data consisting of 8,211 subjects with 75,187 outpatient
claim data of 1,767 unique ICD codes; the MIMIC-III consisting of 1,458
subjects with multi-modal EHR records.
</p>
<p>Results: Compared to the baselines, MixEHR-G achieved a superior dynamic
AUROC for mortality prediction, with a mean AUROC score of 0.89 in the
simulation dataset and a mean AUROC of 0.645 on the CHD dataset. Qualitatively,
MixEHR-G associates severe cardiac conditions with high mortality risk among
the CHD patients after the first heart failure hospitalization and critical
brain injuries with increased mortality among the MIMIC-III patients after
their ICU discharge.
</p>
<p>Conclusion: The integration of the Cox proportional hazards model and EHR
topic inference in MixEHR-SurG led to not only competitive mortality prediction
but also meaningful phenotype topics for systematic survival analysis. The
software is available at GitHub: https://github.com/li-lab-mcgill/MixEHR-SurG.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13455">Revisiting Deep Generalized Canonical Correlation Analysis. (arXiv:2312.13455v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Karakasis_P/0/1/0/all/0/1">Paris A. Karakasis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidiropoulos_N/0/1/0/all/0/1">Nicholas D. Sidiropoulos</a></p>
<p>Canonical correlation analysis (CCA) is a classic statistical method for
discovering latent co-variation that underpins two or more observed random
vectors. Several extensions and variations of CCA have been proposed that have
strengthened our capabilities in terms of revealing common random factors from
multiview datasets. In this work, we first revisit the most recent
deterministic extensions of deep CCA and highlight the strengths and
limitations of these state-of-the-art methods. Some methods allow trivial
solutions, while others can miss weak common factors. Others overload the
problem by also seeking to reveal what is not common among the views -- i.e.,
the private components that are needed to fully reconstruct each view. The
latter tends to overload the problem and its computational and sample
complexities. Aiming to improve upon these limitations, we design a novel and
efficient formulation that alleviates some of the current restrictions. The
main idea is to model the private components as conditionally independent given
the common ones, which enables the proposed compact formulation. In addition,
we also provide a sufficient condition for identifying the common random
factors. Judicious experiments with synthetic and real datasets showcase the
validity of our claims and the effectiveness of the proposed approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13469">Neural feels with neural fields: Visuo-tactile perception for in-hand manipulation. (arXiv:2312.13469v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1">Sudharshan Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Haozhi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tingfan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1">Taosha Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineda_L/0/1/0/all/0/1">Luis Pineda</a>, <a href="http://arxiv.org/find/cs/1/au:+Lambeta_M/0/1/0/all/0/1">Mike Lambeta</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalakrishnan_M/0/1/0/all/0/1">Mrinal Kalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1">Roberto Calandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaess_M/0/1/0/all/0/1">Michael Kaess</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortiz_J/0/1/0/all/0/1">Joseph Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukadam_M/0/1/0/all/0/1">Mustafa Mukadam</a></p>
<p>To achieve human-level dexterity, robots must infer spatial awareness from
multimodal sensing to reason over contact interactions. During in-hand
manipulation of novel objects, such spatial awareness involves estimating the
object's pose and shape. The status quo for in-hand perception primarily
employs vision, and restricts to tracking a priori known objects. Moreover,
visual occlusion of objects in-hand is imminent during manipulation, preventing
current systems to push beyond tasks without occlusion. We combine vision and
touch sensing on a multi-fingered hand to estimate an object's pose and shape
during in-hand manipulation. Our method, NeuralFeels, encodes object geometry
by learning a neural field online and jointly tracks it by optimizing a pose
graph problem. We study multimodal in-hand perception in simulation and the
real-world, interacting with different objects via a proprioception-driven
policy. Our experiments show final reconstruction F-scores of $81$% and average
pose drifts of $4.7\,\text{mm}$, further reduced to $2.3\,\text{mm}$ with known
CAD models. Additionally, we observe that under heavy visual occlusion we can
achieve up to $94$% improvements in tracking compared to vision-only methods.
Our results demonstrate that touch, at the very least, refines and, at the very
best, disambiguates visual estimates during in-hand manipulation. We release
our evaluation dataset of 70 experiments, FeelSight, as a step towards
benchmarking in this domain. Our neural representation driven by multimodal
sensing can serve as a perception backbone towards advancing robot dexterity.
Videos can be found on our project website
https://suddhu.github.io/neural-feels/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13473">Accuracy vs Memory Advantage in the Quantum Simulation of Stochastic Processes. (arXiv:2312.13473v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Banchi_L/0/1/0/all/0/1">Leonardo Banchi</a></p>
<p>Many inference scenarios rely on extracting relevant information from known
data in order to make future predictions. When the underlying stochastic
process satisfies certain assumptions, there is a direct mapping between its
exact classical and quantum simulators, with the latter asymptotically using
less memory. Here we focus on studying whether such quantum advantage persists
when those assumptions are not satisfied, and the model is doomed to have
imperfect accuracy. By studying the trade-off between accuracy and memory
requirements, we show that quantum models can reach the same accuracy with less
memory, or alternatively, better accuracy with the same memory. Finally, we
discuss the implications of this result for learning tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13480">InvertibleNetworks.jl: A Julia package for scalable normalizing flows. (arXiv:2312.13480v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Orozco_R/0/1/0/all/0/1">Rafael Orozco</a>, <a href="http://arxiv.org/find/cs/1/au:+Witte_P/0/1/0/all/0/1">Philipp Witte</a>, <a href="http://arxiv.org/find/cs/1/au:+Louboutin_M/0/1/0/all/0/1">Mathias Louboutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Siahkoohi_A/0/1/0/all/0/1">Ali Siahkoohi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizzuti_G/0/1/0/all/0/1">Gabrio Rizzuti</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_B/0/1/0/all/0/1">Bas Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrmann_F/0/1/0/all/0/1">Felix J. Herrmann</a></p>
<p>InvertibleNetworks.jl is a Julia package designed for the scalable
implementation of normalizing flows, a method for density estimation and
sampling in high-dimensional distributions. This package excels in memory
efficiency by leveraging the inherent invertibility of normalizing flows, which
significantly reduces memory requirements during backpropagation compared to
existing normalizing flow packages that rely on automatic differentiation
frameworks. InvertibleNetworks.jl has been adapted for diverse applications,
including seismic imaging, medical imaging, and CO2 monitoring, demonstrating
its effectiveness in learning high-dimensional distributions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13484">Bayesian Transfer Learning. (arXiv:2312.13484v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Suder_P/0/1/0/all/0/1">Piotr M. Suder</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1">Jason Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1">David B. Dunson</a></p>
<p>Transfer learning is a burgeoning concept in statistical machine learning
that seeks to improve inference and/or predictive accuracy on a domain of
interest by leveraging data from related domains. While the term "transfer
learning" has garnered much recent interest, its foundational principles have
existed for years under various guises. Prior literature reviews in computer
science and electrical engineering have sought to bring these ideas into focus,
primarily surveying general methodologies and works from these disciplines.
This article highlights Bayesian approaches to transfer learning, which have
received relatively limited attention despite their innate compatibility with
the notion of drawing upon prior knowledge to guide new learning tasks. Our
survey encompasses a wide range of Bayesian transfer learning frameworks
applicable to a variety of practical settings. We discuss how these methods
address the problem of finding the optimal information to transfer between
domains, which is a central question in transfer learning. We illustrate the
utility of Bayesian transfer learning methods via a simulation study where we
compare performance against frequentist competitors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13486">Meta-Learning with Versatile Loss Geometries for Fast Adaptation Using Mirror Descent. (arXiv:2312.13486v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yilang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bingcong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1">Georgios B. Giannakis</a></p>
<p>Utilizing task-invariant prior knowledge extracted from related tasks,
meta-learning is a principled framework that empowers learning a new task
especially when data records are limited. A fundamental challenge in
meta-learning is how to quickly "adapt" the extracted prior in order to train a
task-specific model within a few optimization steps. Existing approaches deal
with this challenge using a preconditioner that enhances convergence of the
per-task training process. Though effective in representing locally a quadratic
training loss, these simple linear preconditioners can hardly capture complex
loss geometries. The present contribution addresses this limitation by learning
a nonlinear mirror map, which induces a versatile distance metric to enable
capturing and optimizing a wide range of loss geometries, hence facilitating
the per-task training. Numerical tests on few-shot learning datasets
demonstrate the superior expressiveness and convergence of the advocated
approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13508">Multimodal Federated Learning with Missing Modality via Prototype Mask and Contrast. (arXiv:2312.13508v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bao_G/0/1/0/all/0/1">Guangyin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_D/0/1/0/all/0/1">Duoqian Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zixuan Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Liang Hu</a></p>
<p>In real-world scenarios, multimodal federated learning often faces the
practical challenge of intricate modality missing, which poses constraints on
building federated frameworks and significantly degrades model inference
accuracy. Existing solutions for addressing missing modalities generally
involve developing modality-specific encoders on clients and training modality
fusion modules on servers. However, these methods are primarily constrained to
specific scenarios with either unimodal clients or complete multimodal clients,
struggling to generalize effectively in the intricate modality missing
scenarios. In this paper, we introduce a prototype library into the
FedAvg-based Federated Learning framework, thereby empowering the framework
with the capability to alleviate the global model performance degradation
resulting from modality missing during both training and testing. The proposed
method utilizes prototypes as masks representing missing modalities to
formulate a task-calibrated training loss and a model-agnostic uni-modality
inference strategy. In addition, a proximal term based on prototypes is
constructed to enhance local training. Experimental results demonstrate the
state-of-the-art performance of our approach. Compared to the baselines, our
method improved inference accuracy by 3.7\% with 50\% modality missing during
training and by 23.8\% during uni-modality inference. Code is available at
https://github.com/BaoGuangYin/PmcmFL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13511">Symmetry-enforcing neural networks with applications to constitutive modeling. (arXiv:2312.13511v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Garanger_K/0/1/0/all/0/1">K&#xe9;vin Garanger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraus_J/0/1/0/all/0/1">Julie Kraus</a>, <a href="http://arxiv.org/find/cs/1/au:+Rimoli_J/0/1/0/all/0/1">Julian J. Rimoli</a></p>
<p>The use of machine learning techniques to homogenize the effective behavior
of arbitrary microstructures has been shown to be not only efficient but also
accurate. In a recent work, we demonstrated how to combine state-of-the-art
micromechanical modeling and advanced machine learning techniques to homogenize
complex microstructures exhibiting non-linear and history dependent behaviors.
The resulting homogenized model, termed smart constitutive law (SCL), enables
the adoption of microstructurally informed constitutive laws into finite
element solvers at a fraction of the computational cost required by traditional
concurrent multiscale approaches. In this work, the capabilities of SCLs are
expanded via the introduction of a novel methodology that enforces material
symmetries at the neuron level, applicable across various neural network
architectures. This approach utilizes tensor-based features in neural networks,
facilitating the concise and accurate representation of symmetry-preserving
operations, and is general enough to be extend to problems beyond constitutive
modeling. Details on the construction of these tensor-based neural networks and
their application in learning constitutive laws are presented for both elastic
and inelastic materials. The superiority of this approach over traditional
neural networks is demonstrated in scenarios with limited data and strong
symmetries, through comprehensive testing on various materials, including
isotropic neo-Hookean materials and tensegrity lattice metamaterials. This work
is concluded by a discussion on the potential of this methodology to discover
symmetry bases in materials and by an outline of future research directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13519">Secure Information Embedding in Images with Hybrid Firefly Algorithm. (arXiv:2312.13519v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1">Sahil Nokhwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandrasekharan_M/0/1/0/all/0/1">Manoj Chandrasekharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1">Ankit Chaudhary</a></p>
<p>Various methods have been proposed to secure access to sensitive information
over time, such as the many cryptographic methods in use to facilitate secure
communications on the internet. But other methods like steganography have been
overlooked which may be more suitable in cases where the act of transmission of
sensitive information itself should remain a secret. Multiple techniques that
are commonly discussed for such scenarios suffer from low capacity and high
distortion in the output signal. This research introduces a novel
steganographic approach for concealing a confidential portable document format
(PDF) document within a host image by employing the Hybrid Firefly algorithm
(HFA) proposed to select the pixel arrangement. This algorithm combines two
widely used optimization algorithms to improve their performance. The suggested
methodology utilizes the HFA algorithm to conduct a search for optimal pixel
placements in the spatial domain. The purpose of this search is to accomplish
two main goals: increasing the host image's capacity and reducing distortion.
Moreover, the proposed approach intends to reduce the time required for the
embedding procedure. The findings indicate a decrease in image distortion and
an accelerated rate of convergence in the search process. The resultant
embeddings exhibit robustness against steganalytic assaults, hence rendering
the identification of the embedded data a formidable undertaking.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13530">HW-V2W-Map: Hardware Vulnerability to Weakness Mapping Framework for Root Cause Analysis with GPT-assisted Mitigation Suggestion. (arXiv:2312.13530v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yu-Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mamun_M/0/1/0/all/0/1">Muntasir Mamun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1">Muhtasim Alam Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1">Shuyu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Latibari_B/0/1/0/all/0/1">Banafsheh Saber Latibari</a>, <a href="http://arxiv.org/find/cs/1/au:+Gubbi_K/0/1/0/all/0/1">Kevin Immanuel Gubbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bavarsad_N/0/1/0/all/0/1">Najmeh Nazari Bavarsad</a>, <a href="http://arxiv.org/find/cs/1/au:+Caputo_A/0/1/0/all/0/1">Arjun Caputo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasan_A/0/1/0/all/0/1">Avesta Sasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Homayoun_H/0/1/0/all/0/1">Houman Homayoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafatirad_S/0/1/0/all/0/1">Setareh Rafatirad</a>, <a href="http://arxiv.org/find/cs/1/au:+Satam_P/0/1/0/all/0/1">Pratik Satam</a>, <a href="http://arxiv.org/find/cs/1/au:+Salehi_S/0/1/0/all/0/1">Soheil Salehi</a></p>
<p>The escalating complexity of modern computing frameworks has resulted in a
surge in the cybersecurity vulnerabilities reported to the National
Vulnerability Database (NVD) by practitioners. Despite the fact that the
stature of NVD is one of the most significant databases for the latest insights
into vulnerabilities, extracting meaningful trends from such a large amount of
unstructured data is still challenging without the application of suitable
technological methodologies. Previous efforts have mostly concentrated on
software vulnerabilities; however, a holistic strategy incorporates approaches
for mitigating vulnerabilities, score prediction, and a knowledge-generating
system that may extract relevant insights from the Common Weakness Enumeration
(CWE) and Common Vulnerability Exchange (CVE) databases is notably absent. As
the number of hardware attacks on Internet of Things (IoT) devices continues to
rapidly increase, we present the Hardware Vulnerability to Weakness Mapping
(HW-V2W-Map) Framework, which is a Machine Learning (ML) framework focusing on
hardware vulnerabilities and IoT security. The architecture that we have
proposed incorporates an Ontology-driven Storytelling framework, which
automates the process of updating the ontology in order to recognize patterns
and evolution of vulnerabilities over time and provides approaches for
mitigating the vulnerabilities. The repercussions of vulnerabilities can be
mitigated as a result of this, and conversely, future exposures can be
predicted and prevented. Furthermore, our proposed framework utilized
Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) to
provide mitigation suggestions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13536">Domain Adaptive Graph Classification. (arXiv:2312.13536v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Siyang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Ziyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaoxuan Liang</a></p>
<p>Despite the remarkable accomplishments of graph neural networks (GNNs), they
typically rely on task-specific labels, posing potential challenges in terms of
their acquisition. Existing work have been made to address this issue through
the lens of unsupervised domain adaptation, wherein labeled source graphs are
utilized to enhance the learning process for target data. However, the
simultaneous exploration of graph topology and reduction of domain disparities
remains a substantial hurdle. In this paper, we introduce the Dual Adversarial
Graph Representation Learning (DAGRL), which explore the graph topology from
dual branches and mitigate domain discrepancies via dual adversarial learning.
Our method encompasses a dual-pronged structure, consisting of a graph
convolutional network branch and a graph kernel branch, which enables us to
capture graph semantics from both implicit and explicit perspectives. Moreover,
our approach incorporates adaptive perturbations into the dual branches, which
align the source and target distribution to address domain discrepancies.
Extensive experiments on a wild range graph classification datasets demonstrate
the effectiveness of our proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13555">CR-SAM: Curvature Regularized Sharpness-Aware Minimization. (arXiv:2312.13555v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wunsch_D/0/1/0/all/0/1">Donald C. Wunsch</a></p>
<p>The capacity to generalize to future unseen data stands as one of the utmost
crucial attributes of deep neural networks. Sharpness-Aware Minimization (SAM)
aims to enhance the generalizability by minimizing worst-case loss using
one-step gradient ascent as an approximation. However, as training progresses,
the non-linearity of the loss landscape increases, rendering one-step gradient
ascent less effective. On the other hand, multi-step gradient ascent will incur
higher training cost. In this paper, we introduce a normalized Hessian trace to
accurately measure the curvature of loss landscape on {\em both} training and
test sets. In particular, to counter excessive non-linearity of loss landscape,
we propose Curvature Regularized SAM (CR-SAM), integrating the normalized
Hessian trace as a SAM regularizer. Additionally, we present an efficient way
to compute the trace via finite differences with parallelism. Our theoretical
analysis based on PAC-Bayes bounds establishes the regularizer's efficacy in
reducing generalization error. Empirical evaluation on CIFAR and ImageNet
datasets shows that CR-SAM consistently enhances classification performance for
ResNet and Vision Transformer (ViT) models across various datasets. Our code is
available at https://github.com/TrustAIoT/CR-SAM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13558">The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction. (arXiv:2312.13558v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Pratyusha Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1">Jordan T. Ash</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1">Dipendra Misra</a></p>
<p>Transformer-based Large Language Models (LLMs) have become a fixture in
modern machine learning. Correspondingly, significant resources are allocated
towards research that aims to further advance this technology, typically
resulting in models of increasing size that are trained on increasing amounts
of data. This work, however, demonstrates the surprising result that it is
often possible to significantly improve the performance of LLMs by selectively
removing higher-order components of their weight matrices. This simple
intervention, which we call LAyer-SElective Rank reduction (LASER), can be done
on a model after training has completed, and requires no additional parameters
or data. We show extensive experiments demonstrating the generality of this
finding across language models and datasets, and provide in-depth analyses
offering insights into both when LASER is effective and the mechanism by which
it operates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13565">Automatic Curriculum Learning with Gradient Reward Signals. (arXiv:2312.13565v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Campbell_R/0/1/0/all/0/1">Ryan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Junsang Yoon</a></p>
<p>This paper investigates the impact of using gradient norm reward signals in
the context of Automatic Curriculum Learning (ACL) for deep reinforcement
learning (DRL). We introduce a framework where the teacher model, utilizing the
gradient norm information of a student model, dynamically adapts the learning
curriculum. This approach is based on the hypothesis that gradient norms can
provide a nuanced and effective measure of learning progress. Our experimental
setup involves several reinforcement learning environments (PointMaze, AntMaze,
and AdroitHandRelocate), to assess the efficacy of our method. We analyze how
gradient norm rewards influence the teacher's ability to craft challenging yet
achievable learning sequences, ultimately enhancing the student's performance.
Our results show that this approach not only accelerates the learning process
but also leads to improved generalization and adaptability in complex tasks.
The findings underscore the potential of gradient norm signals in creating more
efficient and robust ACL systems, opening new avenues for research in
curriculum learning and reinforcement learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13575">ARBiBench: Benchmarking Adversarial Robustness of Binarized Neural Networks. (arXiv:2312.13575v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiehua Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Bowen Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Longguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">YingMei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Li Liu</a></p>
<p>Network binarization exhibits great potential for deployment on
resource-constrained devices due to its low computational cost. Despite the
critical importance, the security of binarized neural networks (BNNs) is rarely
investigated. In this paper, we present ARBiBench, a comprehensive benchmark to
evaluate the robustness of BNNs against adversarial perturbations on CIFAR-10
and ImageNet. We first evaluate the robustness of seven influential BNNs on
various white-box and black-box attacks. The results reveal that 1) The
adversarial robustness of BNNs exhibits a completely opposite performance on
the two datasets under white-box attacks. 2) BNNs consistently exhibit better
adversarial robustness under black-box attacks. 3) Different BNNs exhibit
certain similarities in their robustness performance. Then, we conduct
experiments to analyze the adversarial robustness of BNNs based on these
insights. Our research contributes to inspiring future research on enhancing
the robustness of BNNs and advancing their application in real-world scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13583">Fine-tuning Graph Neural Networks by Preserving Graph Generative Patterns. (arXiv:2312.13583v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yifei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chunping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1">Tianyu Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiajun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a></p>
<p>Recently, the paradigm of pre-training and fine-tuning graph neural networks
has been intensively studied and applied in a wide range of graph mining tasks.
Its success is generally attributed to the structural consistency between
pre-training and downstream datasets, which, however, does not hold in many
real-world scenarios. Existing works have shown that the structural divergence
between pre-training and downstream graphs significantly limits the
transferability when using the vanilla fine-tuning strategy. This divergence
leads to model overfitting on pre-training graphs and causes difficulties in
capturing the structural properties of the downstream graphs. In this paper, we
identify the fundamental cause of structural divergence as the discrepancy of
generative patterns between the pre-training and downstream graphs.
Furthermore, we propose G-Tuning to preserve the generative patterns of
downstream graphs. Given a downstream graph G, the core idea is to tune the
pre-trained GNN so that it can reconstruct the generative patterns of G, the
graphon W. However, the exact reconstruction of a graphon is known to be
computationally expensive. To overcome this challenge, we provide a theoretical
analysis that establishes the existence of a set of alternative graphons called
graphon bases for any given graphon. By utilizing a linear combination of these
graphon bases, we can efficiently approximate W. This theoretical finding forms
the basis of our proposed model, as it enables effective learning of the
graphon bases and their associated coefficients. Compared with existing
algorithms, G-Tuning demonstrates an average improvement of 0.5% and 2.6% on
in-domain and out-of-domain transfer learning experiments, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13584">Wave Physics-informed Matrix Factorizations. (arXiv:2312.13584v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tetali_H/0/1/0/all/0/1">Harsha Vardhan Tetali</a>, <a href="http://arxiv.org/find/cs/1/au:+Harley_J/0/1/0/all/0/1">Joel B. Harley</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1">Benjamin D. Haeffele</a></p>
<p>With the recent success of representation learning methods, which includes
deep learning as a special case, there has been considerable interest in
developing techniques that incorporate known physical constraints into the
learned representation. As one example, in many applications that involve a
signal propagating through physical media (e.g., optics, acoustics, fluid
dynamics, etc), it is known that the dynamics of the signal must satisfy
constraints imposed by the wave equation. Here we propose a matrix
factorization technique that decomposes such signals into a sum of components,
where each component is regularized to ensure that it {nearly} satisfies wave
equation constraints. Although our proposed formulation is non-convex, we prove
that our model can be efficiently solved to global optimality. Through this
line of work we establish theoretical connections between wave-informed
learning and filtering theory in signal processing. We further demonstrate the
application of this work on modal analysis problems commonly arising in
structural diagnostics and prognostics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13596">Anchoring Path for Inductive Relation Prediction in Knowledge Graphs. (arXiv:2312.13596v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1">Zhixiang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Lizhen Cui</a></p>
<p>Aiming to accurately predict missing edges representing relations between
entities, which are pervasive in real-world Knowledge Graphs (KGs), relation
prediction plays a critical role in enhancing the comprehensiveness and utility
of KGs. Recent research focuses on path-based methods due to their inductive
and explainable properties. However, these methods face a great challenge when
lots of reasoning paths do not form Closed Paths (CPs) in the KG. To address
this challenge, we propose Anchoring Path Sentence Transformer (APST) by
introducing Anchoring Paths (APs) to alleviate the reliance of CPs.
Specifically, we develop a search-based description retrieval method to enrich
entity descriptions and an assessment mechanism to evaluate the rationality of
APs. APST takes both APs and CPs as the inputs of a unified Sentence
Transformer architecture, enabling comprehensive predictions and high-quality
explanations. We evaluate APST on three public datasets and achieve
state-of-the-art (SOTA) performance in 30 of 36 transductive, inductive, and
few-shot experimental settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13602">Peer-to-Peer Learning + Consensus with Non-IID Data. (arXiv:2312.13602v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pranav_S/0/1/0/all/0/1">Srinivasa Pranav</a>, <a href="http://arxiv.org/find/cs/1/au:+Moura_J/0/1/0/all/0/1">Jos&#xe9; M. F. Moura</a></p>
<p>Peer-to-peer deep learning algorithms are enabling distributed edge devices
to collaboratively train deep neural networks without exchanging raw training
data or relying on a central server. Peer-to-Peer Learning (P2PL) and other
algorithms based on Distributed Local-Update Stochastic/mini-batch Gradient
Descent (local DSGD) rely on interleaving epochs of training with distributed
consensus steps. This process leads to model parameter drift/divergence amongst
participating devices in both IID and non-IID settings. We observe that model
drift results in significant oscillations in test performance evaluated after
local training and consensus phases. We then identify factors that amplify
performance oscillations and demonstrate that our novel approach, P2PL with
Affinity, dampens test performance oscillations in non-IID settings without
incurring any additional communication cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13611">Topology Learning for Heterogeneous Decentralized Federated Learning over Unreliable D2D Networks. (arXiv:2312.13611v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zheshun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Dun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junfan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jie Liu</a></p>
<p>With the proliferation of intelligent mobile devices in wireless
device-to-device (D2D) networks, decentralized federated learning (DFL) has
attracted significant interest. Compared to centralized federated learning
(CFL), DFL mitigates the risk of central server failures due to communication
bottlenecks. However, DFL faces several challenges, such as the severe
heterogeneity of data distributions in diverse environments, and the
transmission outages and package errors caused by the adoption of the User
Datagram Protocol (UDP) in D2D networks. These challenges often degrade the
convergence of training DFL models. To address these challenges, we conduct a
thorough theoretical convergence analysis for DFL and derive a convergence
bound. By defining a novel quantity named unreliable links-aware neighborhood
discrepancy in this convergence bound, we formulate a tractable optimization
objective, and develop a novel Topology Learning method considering the
Representation Discrepancy and Unreliable Links in DFL, named ToLRDUL.
Intensive experiments under both feature skew and label skew settings have
validated the effectiveness of our proposed method, demonstrating improved
convergence speed and test accuracy, consistent with our theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13614">Structure-Aware Path Inference for Neural Finite State Transducers. (arXiv:2312.13614v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1">Weiting Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chu-cheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1">Jason Eisner</a></p>
<p>Neural finite-state transducers (NFSTs) form an expressive family of
neurosymbolic sequence transduction models. An NFST models each string pair as
having been generated by a latent path in a finite-state transducer. As they
are deep generative models, both training and inference of NFSTs require
inference networks that approximate posterior distributions over such latent
variables. In this paper, we focus on the resulting challenge of imputing the
latent alignment path that explains a given pair of input and output strings
(e.g., during training). We train three autoregressive approximate models for
amortized inference of the path, which can then be used as proposal
distributions for importance sampling. All three models perform lookahead. Our
most sophisticated (and novel) model leverages the FST structure to consider
the graph of future paths; unfortunately, we find that it loses out to the
simpler approaches -- except on an artificial task that we concocted to confuse
the simpler approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13616">Navigating the Structured What-If Spaces: Counterfactual Generation via Structured Diffusion. (arXiv:2312.13616v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madaan_N/0/1/0/all/0/1">Nishtha Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bedathur_S/0/1/0/all/0/1">Srikanta Bedathur</a></p>
<p>Generating counterfactual explanations is one of the most effective
approaches for uncovering the inner workings of black-box neural network models
and building user trust. While remarkable strides have been made in generative
modeling using diffusion models in domains like vision, their utility in
generating counterfactual explanations in structured modalities remains
unexplored. In this paper, we introduce Structured Counterfactual Diffuser or
SCD, the first plug-and-play framework leveraging diffusion for generating
counterfactual explanations in structured data. SCD learns the underlying data
distribution via a diffusion model which is then guided at test time to
generate counterfactuals for any arbitrary black-box model, input, and desired
prediction. Our experiments show that our counterfactuals not only exhibit high
plausibility compared to the existing state-of-the-art but also show
significantly better proximity and diversity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13628">Where and How to Attack? A Causality-Inspired Recipe for Generating Counterfactual Adversarial Examples. (arXiv:2312.13628v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuxuan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1">Jie Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1">Zefeng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Furui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhifeng Hao</a></p>
<p>Deep neural networks (DNNs) have been demonstrated to be vulnerable to
well-crafted \emph{adversarial examples}, which are generated through either
well-conceived $\mathcal{L}_p$-norm restricted or unrestricted attacks.
Nevertheless, the majority of those approaches assume that adversaries can
modify any features as they wish, and neglect the causal generating process of
the data, which is unreasonable and unpractical. For instance, a modification
in income would inevitably impact features like the debt-to-income ratio within
a banking system. By considering the underappreciated causal generating
process, first, we pinpoint the source of the vulnerability of DNNs via the
lens of causality, then give theoretical results to answer \emph{where to
attack}. Second, considering the consequences of the attack interventions on
the current state of the examples to generate more realistic adversarial
examples, we propose CADE, a framework that can generate
\textbf{C}ounterfactual \textbf{AD}versarial \textbf{E}xamples to answer
\emph{how to attack}. The empirical results demonstrate CADE's effectiveness,
as evidenced by its competitive performance across diverse attack scenarios,
including white-box, transfer-based, and random intervention attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13630">MFABA: A More Faithful and Accelerated Boundary-based Attribution Method for Deep Neural Networks. (arXiv:2312.13630v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhiyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huaming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiayu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhibo Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1">Minhui Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dongxiao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_K/0/1/0/all/0/1">Kim-Kwang Raymond Choo</a></p>
<p>To better understand the output of deep neural networks (DNN), attribution
based methods have been an important approach for model interpretability, which
assign a score for each input dimension to indicate its importance towards the
model outcome. Notably, the attribution methods use the axioms of sensitivity
and implementation invariance to ensure the validity and reliability of
attribution results. Yet, the existing attribution methods present challenges
for effective interpretation and efficient computation. In this work, we
introduce MFABA, an attribution algorithm that adheres to axioms, as a novel
method for interpreting DNN. Additionally, we provide the theoretical proof and
in-depth analysis for MFABA algorithm, and conduct a large scale experiment.
The results demonstrate its superiority by achieving over 101.5142 times faster
speed than the state-of-the-art attribution algorithms. The effectiveness of
MFABA is thoroughly evaluated through the statistical analysis in comparison to
other methods, and the full implementation package is open-source at:
https://github.com/LMBTough/MFABA
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13632">ProvFL: Client-Driven Interpretability of Global Model Predictions in Federated Learning. (arXiv:2312.13632v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gill_W/0/1/0/all/0/1">Waris Gill</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1">Ali Anwar</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Gulzar_M/0/1/0/all/0/1">Muhammad Ali Gulzar</a> (1) ((1) Virginia Tech, (2) University of Minnesota Twin Cities)</p>
<p>Federated Learning (FL) trains a collaborative machine learning model by
aggregating multiple privately trained clients' models over several training
rounds. Such a long, continuous action of model aggregations poses significant
challenges in reasoning about the origin and composition of such a global
model. Regardless of the quality of the global model or if it has a fault,
understanding the model's origin is equally important for debugging,
interpretability, and explainability in federated learning. FL application
developers often question: (1) what clients contributed towards a global model
and (2) if a global model predicts a label, which clients are responsible for
it?
</p>
<p>We introduce, neuron provenance, a fine-grained lineage capturing mechanism
that tracks the flow of information between the individual participating
clients in FL and the final global model. We operationalize this concept in
ProvFL that functions on two key principles. First, recognizing that monitoring
every neuron of every client's model statically is ineffective and noisy due to
the uninterpretable nature of individual neurons, ProvFL dynamically isolates
influential and sensitive neurons in the global model, significantly reducing
the search space. Second, as multiple clients' models are fused in each round
to form a global model, tracking each client's contribution becomes
challenging. ProvFL leverages the invertible nature of fusion algorithms to
precisely isolate each client's contribution derived from selected neurons.
When asked to localize the clients responsible for the given behavior (i.e.,
prediction) of the global model, ProvFL successfully localizes them with an
average provenance accuracy of 97%. Additionally, ProvFL outperforms the
state-of-the-art FL fault localization approach by an average margin of 50%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13650">Distributed Quantum Neural Networks via Partitioned Features Encoding. (arXiv:2312.13650v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Kawase_Y/0/1/0/all/0/1">Yoshiaki Kawase</a></p>
<p>Quantum neural networks are expected to be a promising application in
near-term quantum computation, but face challenges such as vanishing gradients
during optimization and limited expressibility by a limited number of qubits
and shallow circuits. To mitigate these challenges, distributed quantum neural
networks have been proposed to make a prediction by approximating a large
circuit with multiple small circuits. However, the approximation of a large
circuit requires an exponential number of small circuit evaluations. Here, we
instead propose to distribute partitioned features over multiple small quantum
neural networks and use the ensemble of their expectation values to generate
predictions. To verify our distributed approach, we demonstrate multi-class
classifications of handwritten digit datasets. Especially for the MNIST
dataset, we succeeded in ten class classifications of the dataset with
exceeding 96% accuracy. Our proposed method not only achieved highly accurate
predictions for a large dataset but also reduced the hardware requirements for
each quantum neural network compared to a single quantum neural network. Our
results highlight distributed quantum neural networks as a promising direction
for practical quantum machine learning algorithms compatible with near-term
quantum devices. We hope that our approach is useful for exploring quantum
machine learning applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13671">Text2Analysis: A Benchmark of Table Question Answering with Advanced Data Analysis and Unclear Queries. (arXiv:2312.13671v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xinyi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mengyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinrun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaojun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1">Rui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Lun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ran Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zejian Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a></p>
<p>Tabular data analysis is crucial in various fields, and large language models
show promise in this area. However, current research mostly focuses on
rudimentary tasks like Text2SQL and TableQA, neglecting advanced analysis like
forecasting and chart generation. To address this gap, we developed the
Text2Analysis benchmark, incorporating advanced analysis tasks that go beyond
the SQL-compatible operations and require more in-depth analysis. We also
develop five innovative and effective annotation methods, harnessing the
capabilities of large language models to enhance data quality and quantity.
Additionally, we include unclear queries that resemble real-world user
questions to test how well models can understand and tackle such challenges.
Finally, we collect 2249 query-result pairs with 347 tables. We evaluate five
state-of-the-art models using three different metrics and the results show that
our benchmark presents introduces considerable challenge in the field of
tabular data analysis, paving the way for more advanced research opportunities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13677">Parallel Trust-Region Approaches in Neural Network Training: Beyond Traditional Methods. (arXiv:2312.13677v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Trotti_K/0/1/0/all/0/1">Ken Trotti</a>, <a href="http://arxiv.org/find/math/1/au:+Alegria_S/0/1/0/all/0/1">Samuel A. Cruz Alegr&#xed;a</a>, <a href="http://arxiv.org/find/math/1/au:+Kopanicakova_A/0/1/0/all/0/1">Alena Kopani&#x10d;&#xe1;kov&#xe1;</a>, <a href="http://arxiv.org/find/math/1/au:+Krause_R/0/1/0/all/0/1">Rolf Krause</a></p>
<p>We propose to train neural networks (NNs) using a novel variant of the
``Additively Preconditioned Trust-region Strategy'' (APTS). The proposed method
is based on a parallelizable additive domain decomposition approach applied to
the neural network's parameters. Built upon the TR framework, the APTS method
ensures global convergence towards a minimizer. Moreover, it eliminates the
need for computationally expensive hyper-parameter tuning, as the TR algorithm
automatically determines the step size in each iteration. We demonstrate the
capabilities, strengths, and limitations of the proposed APTS training method
by performing a series of numerical experiments. The presented numerical study
includes a comparison with widely used training methods such as SGD, Adam,
LBFGS, and the standard TR method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13699">Adapt &amp; Align: Continual Learning with Generative Models Latent Space Alignment. (arXiv:2312.13699v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deja_K/0/1/0/all/0/1">Kamil Deja</a>, <a href="http://arxiv.org/find/cs/1/au:+Cywinski_B/0/1/0/all/0/1">Bartosz Cywi&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rybarczyk_J/0/1/0/all/0/1">Jan Rybarczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a></p>
<p>In this work, we introduce Adapt &amp; Align, a method for continual learning of
neural networks by aligning latent representations in generative models. Neural
Networks suffer from abrupt loss in performance when retrained with additional
training data from different distributions. At the same time, training with
additional data without access to the previous examples rarely improves the
model's performance. In this work, we propose a new method that mitigates those
problems by employing generative models and splitting the process of their
update into two parts. In the first one, we train a local generative model
using only data from a new task. In the second phase, we consolidate latent
representations from the local model with a global one that encodes knowledge
of all past experiences. We introduce our approach with Variational
Auteoncoders and Generative Adversarial Networks. Moreover, we show how we can
use those generative models as a general method for continual knowledge
consolidation that can be used in downstream tasks such as classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13704">A Forecasting-Based DLP Approach for Data Security. (arXiv:2312.13704v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1">Kishu Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kush_A/0/1/0/all/0/1">Ashwani Kush</a></p>
<p>Sensitive data leakage is the major growing problem being faced by
enterprises in this technical era. Data leakage causes severe threats for
organization of data safety which badly affects the reputation of
organizations. Data leakage is the flow of sensitive data/information from any
data holder to an unauthorized destination. Data leak prevention (DLP) is set
of techniques that try to alleviate the threats which may hinder data security.
DLP unveils guilty user responsible for data leakage and ensures that user
without appropriate permission cannot access sensitive data and also provides
protection to sensitive data if sensitive data is shared accidentally. In this
paper, data leakage prevention (DLP) model is used to restrict/grant data
access permission to user, based on the forecast of their access to data. This
study provides a DLP solution using data statistical analysis to forecast the
data access possibilities of any user in future based on the access to data in
the past. The proposed approach makes use of renowned simple piecewise linear
function for learning/training to model. The results show that the proposed DLP
approach with high level of precision can correctly classify between users even
in cases of extreme data access.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13711">A Learning oriented DLP System based on Classification Model. (arXiv:2312.13711v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1">Kishu Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kush_A/0/1/0/all/0/1">Ashwani Kush</a></p>
<p>Data is the key asset for organizations and data sharing is lifeline for
organization growth; which may lead to data loss. Data leakage is the most
critical issue being faced by organizations. In order to mitigate the data
leakage issues data leakage prevention systems (DLPSs) are deployed at various
levels by the organizations. DLPSs are capable to protect all kind of data i.e.
DAR, DIM/DIT, DIU. Statistical analysis, regular expression, data
fingerprinting are common approaches exercised in DLP system. Out of these
techniques; statistical analysis approach is most appropriate for proposed DLP
model of data security. This paper defines a statistical DLP model for document
classification. Model uses various statistical approaches like TF-IDF (Term
Frequency- Inverse Document Frequency) a renowned term count/weighing function,
Vectorization, Gradient boosting document classification etc. to classify the
documents before allowing any access to it. Machine learning is used to test
and train the model. Proposed model also introduces an extremely efficient and
more accurate approach; IGBCA (Improvised Gradient Boosting Classification
Algorithm); for document classification, to prevent them from possible data
leakage. Results depicts that proposed model can classify documents with high
accuracy and on basis of which data can be prevented from being loss.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13716">Critic-Guided Decision Transformer for Offline Reinforcement Learning. (arXiv:2312.13716v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuanfu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Ying Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a></p>
<p>Recent advancements in offline reinforcement learning (RL) have underscored
the capabilities of Return-Conditioned Supervised Learning (RCSL), a paradigm
that learns the action distribution based on target returns for each state in a
supervised manner. However, prevailing RCSL methods largely focus on
deterministic trajectory modeling, disregarding stochastic state transitions
and the diversity of future trajectory distributions. A fundamental challenge
arises from the inconsistency between the sampled returns within individual
trajectories and the expected returns across multiple trajectories.
Fortunately, value-based methods offer a solution by leveraging a value
function to approximate the expected returns, thereby addressing the
inconsistency effectively. Building upon these insights, we propose a novel
approach, termed the Critic-Guided Decision Transformer (CGDT), which combines
the predictability of long-term returns from value-based methods with the
trajectory modeling capability of the Decision Transformer. By incorporating a
learned value function, known as the critic, CGDT ensures a direct alignment
between the specified target returns and the expected returns of actions. This
integration bridges the gap between the deterministic nature of RCSL and the
probabilistic characteristics of value-based methods. Empirical evaluations on
stochastic environments and D4RL benchmark datasets demonstrate the superiority
of CGDT over traditional RCSL methods. These results highlight the potential of
CGDT to advance the state of the art in offline RL and extend the applicability
of RCSL to a wide range of RL tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13754">Cross-Layer Optimization for Fault-Tolerant Deep Learning. (arXiv:2312.13754v1 [cs.AR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haitong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Ying Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huawei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaowei Li</a></p>
<p>Fault-tolerant deep learning accelerator is the basis for highly reliable
deep learning processing and critical to deploy deep learning in
safety-critical applications such as avionics and robotics. Since deep learning
is known to be computing- and memory-intensive, traditional fault-tolerant
approaches based on redundant computing will incur substantial overhead
including power consumption and chip area. To this end, we propose to
characterize deep learning vulnerability difference across both neurons and
bits of each neuron, and leverage the vulnerability difference to enable
selective protection of the deep learning processing components from the
perspective of architecture layer and circuit layer respectively. At the same
time, we observe the correlation between model quantization and bit protection
overhead of the underlying processing elements of deep learning accelerators,
and propose to reduce the bit protection overhead by adding additional
quantization constrain without compromising the model accuracy. Finally, we
employ Bayesian optimization strategy to co-optimize the correlated cross-layer
design parameters at algorithm layer, architecture layer, and circuit layer to
minimize the hardware resource consumption while fulfilling multiple user
constraints including reliability, accuracy, and performance of the deep
learning processing at the same time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13763">Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models. (arXiv:2312.13763v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Huan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seung Wook Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreis_K/0/1/0/all/0/1">Karsten Kreis</a></p>
<p>Text-guided diffusion models have revolutionized image and video generation
and have also been successfully used for optimization-based 3D object
synthesis. Here, we instead focus on the underexplored text-to-4D setting and
synthesize dynamic, animated 3D objects using score distillation methods with
an additional temporal dimension. Compared to previous work, we pursue a novel
compositional generation-based approach, and combine text-to-image,
text-to-video, and 3D-aware multiview diffusion models to provide feedback
during 4D object optimization, thereby simultaneously enforcing temporal
consistency, high-quality visual appearance and realistic geometry. Our method,
called Align Your Gaussians (AYG), leverages dynamic 3D Gaussian Splatting with
deformation fields as 4D representation. Crucial to AYG is a novel method to
regularize the distribution of the moving 3D Gaussians and thereby stabilize
the optimization and induce motion. We also propose a motion amplification
mechanism as well as a new autoregressive synthesis scheme to generate and
combine multiple 4D sequences for longer generation. These techniques allow us
to synthesize vivid dynamic scenes, outperform previous work qualitatively and
quantitatively and achieve state-of-the-art text-to-4D performance. Due to the
Gaussian 4D representation, different 4D animations can be seamlessly combined,
as we demonstrate. AYG opens up promising avenues for animation, simulation and
digital content creation as well as synthetic data generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13764">A Semantic Space is Worth 256 Language Descriptions: Make Stronger Segmentation Models with Descriptive Properties. (arXiv:2312.13764v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Junfei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Ziqi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1">Shiyi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1">Jieru Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Cihang Xie</a></p>
<p>This paper introduces ProLab, a novel approach using property-level label
space for creating strong interpretable segmentation models. Instead of relying
solely on category-specific annotations, ProLab uses descriptive properties
grounded in common sense knowledge for supervising segmentation models. It is
based on two core designs. First, we employ Large Language Models (LLMs) and
carefully crafted prompts to generate descriptions of all involved categories
that carry meaningful common sense knowledge and follow a structured format.
Second, we introduce a description embedding model preserving semantic
correlation across descriptions and then cluster them into a set of descriptive
properties (e.g., 256) using K-Means. These properties are based on
interpretable common sense knowledge consistent with theories of human
recognition. We empirically show that our approach makes segmentation models
perform stronger on five classic benchmarks (e.g., ADE20K, COCO-Stuff, Pascal
Context, Cityscapes, and BDD). Our method also shows better scalability with
extended training steps than category-level supervision. Our interpretable
segmentation framework also emerges with the generalization ability to segment
out-of-domain or unknown categories using only in-domain descriptive
properties. Code is available at https://github.com/lambert-x/ProLab.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13772">On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning. (arXiv:2312.13772v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengzu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Han Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a></p>
<p>Following the standard supervised fine-tuning (SFT) paradigm, in-context
learning (ICL) has become an efficient approach propelled by the recent
advancements in large language models (LLMs), yielding promising performance
across various tasks in few-shot data setups. However, both paradigms are prone
to suffer from the critical problem of overconfidence (i.e., miscalibration),
especially in such limited data setups. In this work, we deliver an in-depth
analysis of the behavior across different choices of learning methods from the
perspective of both performance and calibration, as well as their interplay.
Through extensive controlled experiments, we find that simultaneous gains for
both task performance and calibration are difficult to achieve, and the problem
of miscalibration exists across all learning methods in low-resource
scenarios.To address this challenging trade-off between performance and
calibration, we then investigate the potential of self-ensembling techniques
applied at different modeling stages (e.g., variations of in-context examples
or variations in prompts or different ensembling strategies). We justify the
feasibility of self-ensembling on SFT in addition to ICL, to make the
predictions more calibrated and have comparable or even better performance. Our
work sheds light on which learning paradigm to choose and how to enhance both
task performance and calibration of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13783">Few Shot Part Segmentation Reveals Compositional Logic for Industrial Anomaly Detection. (arXiv:2312.13783v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soopil Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1">Sion An</a>, <a href="http://arxiv.org/find/cs/1/au:+Chikontwe_P/0/1/0/all/0/1">Philip Chikontwe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Myeongkyun Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1">Kilian M. Pohl</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sanghyun Park</a></p>
<p>Logical anomalies (LA) refer to data violating underlying logical constraints
e.g., the quantity, arrangement, or composition of components within an image.
Detecting accurately such anomalies requires models to reason about various
component types through segmentation. However, curation of pixel-level
annotations for semantic segmentation is both time-consuming and expensive.
Although there are some prior few-shot or unsupervised co-part segmentation
algorithms, they often fail on images with industrial object. These images have
components with similar textures and shapes, and a precise differentiation
proves challenging. In this study, we introduce a novel component segmentation
model for LA detection that leverages a few labeled samples and unlabeled
images sharing logical constraints. To ensure consistent segmentation across
unlabeled images, we employ a histogram matching loss in conjunction with an
entropy loss. As segmentation predictions play a crucial role, we propose to
enhance both local and global sample validity detection by capturing key
aspects from visual semantics via three memory banks: class histograms,
component composition embeddings and patch-level representations. For effective
LA detection, we propose an adaptive scaling strategy to standardize anomaly
scores from different memory banks in inference. Extensive experiments on the
public benchmark MVTec LOCO AD reveal our method achieves 98.1% AUROC in LA
detection vs. 89.6% from competing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13795">Sparse Training for Federated Learning with Regularized Error Correction. (arXiv:2312.13795v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Greidi_R/0/1/0/all/0/1">Ran Greidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_K/0/1/0/all/0/1">Kobi Cohen</a></p>
<p>Federated Learning (FL) has attracted much interest due to the significant
advantages it brings to training deep neural network (DNN) models. However,
since communications and computation resources are limited, training DNN models
in FL systems face challenges such as elevated computational and communication
costs in complex tasks. Sparse training schemes gain increasing attention in
order to scale down the dimensionality of each client (i.e., node)
transmission. Specifically, sparsification with error correction methods is a
promising technique, where only important updates are sent to the parameter
server (PS) and the rest are accumulated locally. While error correction
methods have shown to achieve a significant sparsification level of the
client-to-PS message without harming convergence, pushing sparsity further
remains unresolved due to the staleness effect. In this paper, we propose a
novel algorithm, dubbed Federated Learning with Accumulated Regularized
Embeddings (FLARE), to overcome this challenge. FLARE presents a novel sparse
training approach via accumulated pulling of the updated models with
regularization on the embeddings in the FL process, providing a powerful
solution to the staleness effect, and pushing sparsity to an exceptional level.
The performance of FLARE is validated through extensive experiments on diverse
and complex models, achieving a remarkable sparsity level (10 times and more
beyond the current state-of-the-art) along with significantly improved
accuracy. Additionally, an open-source software package has been developed for
the benefit of researchers and developers in related fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13807">Optimized classification with neural ODEs via separability. (arXiv:2312.13807v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Alvarez_Lopez_A/0/1/0/all/0/1">Antonio &#xc1;lvarez-L&#xf3;pez</a>, <a href="http://arxiv.org/find/math/1/au:+Orive_Illera_R/0/1/0/all/0/1">Rafael Orive-Illera</a>, <a href="http://arxiv.org/find/math/1/au:+Zuazua_E/0/1/0/all/0/1">Enrique Zuazua</a></p>
<p>Classification of $N$ points becomes a simultaneous control problem when
viewed through the lens of neural ordinary differential equations (neural
ODEs), which represent the time-continuous limit of residual networks. For the
narrow model, with one neuron per hidden layer, it has been shown that the task
can be achieved using $O(N)$ neurons. In this study, we focus on estimating the
number of neurons required for efficient cluster-based classification,
particularly in the worst-case scenario where points are independently and
uniformly distributed in $[0,1]^d$. Our analysis provides a novel method for
quantifying the probability of requiring fewer than $O(N)$ neurons, emphasizing
the asymptotic behavior as both $d$ and $N$ increase. Additionally, under the
sole assumption that the data are in general position, we propose a new
constructive algorithm that simultaneously classifies clusters of $d$ points
from any initial configuration, effectively reducing the maximal complexity to
$O(N/d)$ neurons.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13839">Q-SENN: Quantized Self-Explaining Neural Networks. (arXiv:2312.13839v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Norrenbrock_T/0/1/0/all/0/1">Thomas Norrenbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1">Marco Rudolph</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a></p>
<p>Explanations in Computer Vision are often desired, but most Deep Neural
Networks can only provide saliency maps with questionable faithfulness.
Self-Explaining Neural Networks (SENN) extract interpretable concepts with
fidelity, diversity, and grounding to combine them linearly for
decision-making. While they can explain what was recognized, initial
realizations lack accuracy and general applicability. We propose the
Quantized-Self-Explaining Neural Network Q-SENN. Q-SENN satisfies or exceeds
the desiderata of SENN while being applicable to more complex datasets and
maintaining most or all of the accuracy of an uninterpretable baseline model,
out-performing previous work in all considered metrics. Q-SENN describes the
relationship between every class and feature as either positive, negative or
neutral instead of an arbitrary number of possible relations, enforcing more
binary human-friendly features. Since every class is assigned just 5
interpretable features on average, Q-SENN shows convincing local and global
interpretability. Additionally, we propose a feature alignment method, capable
of aligning learned features with human language-based concepts without
additional supervision. Thus, what is learned can be more easily verbalized.
The code is published: https://github.com/ThomasNorr/Q-SENN
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13842">Statistical learning theory and Occam&#x27;s razor: The argument from empirical risk minimization. (arXiv:2312.13842v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sterkenburg_T/0/1/0/all/0/1">Tom F. Sterkenburg</a></p>
<p>This paper considers the epistemic justification for a simplicity preference
in inductive inference that may be obtained from the machine learning framework
of statistical learning theory. Uniting elements from both earlier arguments
suggesting and rejecting such a justification, the paper spells out a qualified
means-ends and model-relative justificatory argument, built on statistical
learning theory's central mathematical learning guarantee for the method of
empirical risk minimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13863">Manipulating Trajectory Prediction with Backdoors. (arXiv:2312.13863v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Massoud_K/0/1/0/all/0/1">Kaouther Massoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1">Kathrin Grosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mickael Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1">Patrick P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Alahi_A/0/1/0/all/0/1">Alexandre Alahi</a></p>
<p>Autonomous vehicles ought to predict the surrounding agents' trajectories to
allow safe maneuvers in uncertain and complex traffic situations. As companies
increasingly apply trajectory prediction in the real world, security becomes a
relevant concern. In this paper, we focus on backdoors - a security threat
acknowledged in other fields but so far overlooked for trajectory prediction.
To this end, we describe and investigate four triggers that could affect
trajectory prediction. We then show that these triggers (for example, a braking
vehicle), when correlated with a desired output (for example, a curve) during
training, cause the desired output of a state-of-the-art trajectory prediction
model. In other words, the model has good benign performance but is vulnerable
to backdoors. This is the case even if the trigger maneuver is performed by a
non-casual agent behind the target vehicle. As a side-effect, our analysis
reveals interesting limitations within trajectory prediction models. Finally,
we evaluate a range of defenses against backdoors. While some, like simple
offroad checks, do not enable detection for all triggers, clustering is a
promising candidate to support manual inspection to find backdoors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13868">Data-driven path collective variables. (arXiv:2312.13868v1 [physics.chem-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+France_Lanord_A/0/1/0/all/0/1">Arthur France-Lanord</a>, <a href="http://arxiv.org/find/physics/1/au:+Vroylandt_H/0/1/0/all/0/1">Hadrien Vroylandt</a>, <a href="http://arxiv.org/find/physics/1/au:+Salanne_M/0/1/0/all/0/1">Mathieu Salanne</a>, <a href="http://arxiv.org/find/physics/1/au:+Rotenberg_B/0/1/0/all/0/1">Benjamin Rotenberg</a>, <a href="http://arxiv.org/find/physics/1/au:+Saitta_A/0/1/0/all/0/1">A. Marco Saitta</a>, <a href="http://arxiv.org/find/physics/1/au:+Pietrucci_F/0/1/0/all/0/1">Fabio Pietrucci</a></p>
<p>Identifying optimal collective variables to model transformations, using
atomic-scale simulations, is a long-standing challenge. We propose a new method
for the generation, optimization, and comparison of collective variables, which
can be thought of as a data-driven generalization of the path collective
variable concept. It consists in a kernel ridge regression of the committor
probability, which encodes a transformation's progress. The resulting
collective variable is one-dimensional, interpretable, and differentiable,
making it appropriate for enhanced sampling simulations requiring biasing. We
demonstrate the validity of the method on two different applications: a
precipitation model, and the association of Li$^+$ and F$^-$ in water. For the
former, we show that global descriptors such as the permutation invariant
vector allow to reach an accuracy far from the one achieved \textit{via}
simpler, more intuitive variables. For the latter, we show that information
correlated with the transformation mechanism is contained in the first
solvation shell only, and that inertial effects prevent the derivation of
optimal collective variables from the atomic positions only.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13875">Best Arm Identification in Batched Multi-armed Bandit Problems. (arXiv:2312.13875v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Cao_S/0/1/0/all/0/1">Shengyu Cao</a>, <a href="http://arxiv.org/find/stat/1/au:+He_S/0/1/0/all/0/1">Simai He</a>, <a href="http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1">Ruoqing Jiang</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Yuan_H/0/1/0/all/0/1">Hongsong Yuan</a></p>
<p>Recently multi-armed bandit problem arises in many real-life scenarios where
arms must be sampled in batches, due to limited time the agent can wait for the
feedback. Such applications include biological experimentation and online
marketing. The problem is further complicated when the number of arms is large
and the number of batches is small. We consider pure exploration in a batched
multi-armed bandit problem. We introduce a general linear programming framework
that can incorporate objectives of different theoretical settings in best arm
identification. The linear program leads to a two-stage algorithm that can
achieve good theoretical properties. We demonstrate by numerical studies that
the algorithm also has good performance compared to certain UCB-type or
Thompson sampling methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13876">Capture the Flag: Uncovering Data Insights with Large Language Models. (arXiv:2312.13876v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1">Issam Laradji</a>, <a href="http://arxiv.org/find/cs/1/au:+Taslakian_P/0/1/0/all/0/1">Perouz Taslakian</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajeswar_S/0/1/0/all/0/1">Sai Rajeswar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zantedeschi_V/0/1/0/all/0/1">Valentina Zantedeschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_A/0/1/0/all/0/1">Alexandre Lacoste</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapados_N/0/1/0/all/0/1">Nicolas Chapados</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazquez_D/0/1/0/all/0/1">David Vazquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1">Alexandre Drouin</a></p>
<p>The extraction of a small number of relevant insights from vast amounts of
data is a crucial component of data-driven decision-making. However,
accomplishing this task requires considerable technical skills, domain
expertise, and human labor. This study explores the potential of using Large
Language Models (LLMs) to automate the discovery of insights in data,
leveraging recent advances in reasoning and code generation techniques. We
propose a new evaluation methodology based on a "capture the flag" principle,
measuring the ability of such models to recognize meaningful and pertinent
information (flags) in a dataset. We further propose two proof-of-concept
agents, with different inner workings, and compare their ability to capture
such flags in a real-world sales dataset. While the work reported here is
preliminary, our results are sufficiently interesting to mandate future
exploration by the community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13896">Comparative Evaluation of Anomaly Detection Methods for Fraud Detection in Online Credit Card Payments. (arXiv:2312.13896v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thimonier_H/0/1/0/all/0/1">Hugo Thimonier</a>, <a href="http://arxiv.org/find/cs/1/au:+Popineau_F/0/1/0/all/0/1">Fabrice Popineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Rimmel_A/0/1/0/all/0/1">Arpad Rimmel</a>, <a href="http://arxiv.org/find/cs/1/au:+Doan_B/0/1/0/all/0/1">Bich-Li&#xea;n Doan</a>, <a href="http://arxiv.org/find/cs/1/au:+Daniel_F/0/1/0/all/0/1">Fabrice Daniel</a></p>
<p>This study explores the application of anomaly detection (AD) methods in
imbalanced learning tasks, focusing on fraud detection using real online credit
card payment data. We assess the performance of several recent AD methods and
compare their effectiveness against standard supervised learning methods.
Offering evidence of distribution shift within our dataset, we analyze its
impact on the tested models' performances. Our findings reveal that LightGBM
exhibits significantly superior performance across all evaluated metrics but
suffers more from distribution shifts than AD methods. Furthermore, our
investigation reveals that LightGBM also captures the majority of frauds
detected by AD methods. This observation challenges the potential benefits of
ensemble methods to combine supervised, and AD approaches to enhance
performance. In summary, this research provides practical insights into the
utility of these techniques in real-world scenarios, showing LightGBM's
superiority in fraud detection while highlighting challenges related to
distribution shifts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13905">Domain-Specific Fine-Tuning of Large Language Models for Interactive Robot Programming. (arXiv:2312.13905v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alt_B/0/1/0/all/0/1">Benjamin Alt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kessner_U/0/1/0/all/0/1">Urs Ke&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Taranovic_A/0/1/0/all/0/1">Aleksandar Taranovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Katic_D/0/1/0/all/0/1">Darko Katic</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermann_A/0/1/0/all/0/1">Andreas Hermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakel_R/0/1/0/all/0/1">Rainer J&#xe4;kel</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a></p>
<p>Industrial robots are applied in a widening range of industries, but robot
programming mostly remains a task limited to programming experts. We propose a
natural language-based assistant for programming of advanced, industrial
robotic applications and investigate strategies for domain-specific fine-tuning
of foundation models with limited data and compute.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13906">EfficientPPS: Part-aware Panoptic Segmentation of Transparent Objects for Robotic Manipulation. (arXiv:2312.13906v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alt_B/0/1/0/all/0/1">Benjamin Alt</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh Dang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermann_A/0/1/0/all/0/1">Andreas Hermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Katic_D/0/1/0/all/0/1">Darko Katic</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakel_R/0/1/0/all/0/1">Rainer J&#xe4;kel</a>, <a href="http://arxiv.org/find/cs/1/au:+Dillmann_R/0/1/0/all/0/1">R&#xfc;diger Dillmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sax_E/0/1/0/all/0/1">Eric Sax</a></p>
<p>The use of autonomous robots for assistance tasks in hospitals has the
potential to free up qualified staff and im-prove patient care. However, the
ubiquity of deformable and transparent objects in hospital settings poses
signif-icant challenges to vision-based perception systems. We present
EfficientPPS, a neural architecture for part-aware panoptic segmentation that
provides robots with semantically rich visual information for grasping and
ma-nipulation tasks. We also present an unsupervised data collection and
labelling method to reduce the need for human involvement in the training
process. EfficientPPS is evaluated on a dataset containing real-world hospital
objects and demonstrated to be robust and efficient in grasping transparent
transfusion bags with a collaborative robot arm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13910">Multi-Agent Probabilistic Ensembles with Trajectory Sampling for Connected Autonomous Vehicles. (arXiv:2312.13910v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wen_R/0/1/0/all/0/1">Ruoqi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rongpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guoru Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhifeng Zhao</a></p>
<p>Autonomous Vehicles (AVs) have attracted significant attention in recent
years and Reinforcement Learning (RL) has shown remarkable performance in
improving the autonomy of vehicles. In that regard, the widely adopted
Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs
(CAVs), contingent on the readiness of a significant amount of data samples for
training. Nevertheless, it might be infeasible in practice and possibly lead to
learning instability. In contrast, Model-Based RL (MBRL) manifests itself in
sample-efficient learning, but the asymptotic performance of MBRL might lag
behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs
are limited to the decision-making of a single AV only, thus underscoring the
performance due to the absence of communications. In this study, we try to
address the decision-making problem of multiple CAVs with limited
communications and propose a decentralized Multi-Agent Probabilistic Ensembles
with Trajectory Sampling algorithm MA-PETS. In particular, in order to better
capture the uncertainty of the unknown environment, MA-PETS leverages
Probabilistic Ensemble (PE) neural networks to learn from communicated samples
among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory
Sampling (TS)-based model-predictive control for decision-making. On this
basis, we derive the multi-agent group regret bound affected by the number of
agents within the communication range and mathematically validate that
incorporating effective information exchange among agents into the multi-agent
learning scheme contributes to reducing the group regret bound in the worst
case. Finally, we empirically demonstrate the superiority of MA-PETS in terms
of the sample efficiency comparable to MFBL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13923">Fed-CO$_{2}$: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning. (arXiv:2312.13923v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhongyi Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Ye Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingya Wang</a></p>
<p>Federated Learning (FL) has emerged as a promising distributed learning
paradigm that enables multiple clients to learn a global model collaboratively
without sharing their private data. However, the effectiveness of FL is highly
dependent on the quality of the data that is being used for training. In
particular, data heterogeneity issues, such as label distribution skew and
feature skew, can significantly impact the performance of FL. Previous studies
in FL have primarily focused on addressing label distribution skew data
heterogeneity, while only a few recent works have made initial progress in
tackling feature skew issues. Notably, these two forms of data heterogeneity
have been studied separately and have not been well explored within a unified
FL framework. To address this gap, we propose Fed-CO$_{2}$, a universal FL
framework that handles both label distribution skew and feature skew within a
\textbf{C}ooperation mechanism between the \textbf{O}nline and \textbf{O}ffline
models. Specifically, the online model learns general knowledge that is shared
among all clients, while the offline model is trained locally to learn the
specialized knowledge of each individual client. To further enhance model
cooperation in the presence of feature shifts, we design an intra-client
knowledge transfer mechanism that reinforces mutual learning between the online
and offline models, and an inter-client knowledge transfer mechanism to
increase the models' domain generalization ability. Extensive experiments show
that our Fed-CO$_{2}$ outperforms a wide range of existing personalized
federated learning algorithms in terms of handling label distribution skew and
feature skew, both individually and collectively. The empirical results are
supported by our convergence analyses in a simplified setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13927">On the convergence of loss and uncertainty-based active learning algorithms. (arXiv:2312.13927v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Haimovich_D/0/1/0/all/0/1">Daniel Haimovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Karamshuk_D/0/1/0/all/0/1">Dima Karamshuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Linder_F/0/1/0/all/0/1">Fridolin Linder</a>, <a href="http://arxiv.org/find/cs/1/au:+Tax_N/0/1/0/all/0/1">Niek Tax</a>, <a href="http://arxiv.org/find/cs/1/au:+Vojnovic_M/0/1/0/all/0/1">Milan Vojnovic</a></p>
<p>We study convergence rates of loss and uncertainty-based active learning
algorithms under various assumptions. First, we provide a set of conditions
under which a convergence rate guarantee holds, and use this for linear
classifiers and linearly separable datasets to show convergence rate guarantees
for loss-based sampling and different loss functions. Second, we provide a
framework that allows us to derive convergence rate bounds for loss-based
sampling by deploying known convergence rate bounds for stochastic gradient
descent algorithms. Third, and last, we propose an active learning algorithm
that combines sampling of points and stochastic Polyak's step size. We show a
condition on the sampling that ensures a convergence rate guarantee for this
algorithm for smooth convex loss functions. Our numerical results demonstrate
efficiency of our proposed algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13931">Joint Sensing and Task-Oriented Communications with Image and Wireless Data Modalities for Dynamic Spectrum Access. (arXiv:2312.13931v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1">Yalin E. Sagduyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Erpek_T/0/1/0/all/0/1">Tugba Erpek</a>, <a href="http://arxiv.org/find/cs/1/au:+Yener_A/0/1/0/all/0/1">Aylin Yener</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulukus_S/0/1/0/all/0/1">Sennur Ulukus</a></p>
<p>This paper introduces a deep learning approach to dynamic spectrum access,
leveraging the synergy of multi-modal image and spectrum data for the
identification of potential transmitters. We consider an edge device equipped
with a camera that is taking images of potential objects such as vehicles that
may harbor transmitters. Recognizing the computational constraints and trust
issues associated with on-device computation, we propose a collaborative system
wherein the edge device communicates selectively processed information to a
trusted receiver acting as a fusion center, where a decision is made to
identify whether a potential transmitter is present, or not. To achieve this,
we employ task-oriented communications, utilizing an encoder at the transmitter
for joint source coding, channel coding, and modulation. This architecture
efficiently transmits essential information of reduced dimension for object
classification. Simultaneously, the transmitted signals may reflect off objects
and return to the transmitter, allowing for the collection of target sensing
data. Then the collected sensing data undergoes a second round of encoding at
the transmitter, with the reduced-dimensional information communicated back to
the fusion center through task-oriented communications. On the receiver side, a
decoder performs the task of identifying a transmitter by fusing data received
through joint sensing and task-oriented communications. The two encoders at the
transmitter and the decoder at the receiver are jointly trained, enabling a
seamless integration of image classification and wireless signal detection.
Using AWGN and Rayleigh channel models, we demonstrate the effectiveness of the
proposed approach, showcasing high accuracy in transmitter identification
across diverse channel conditions while sustaining low latency in decision
making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13933">Structured Probabilistic Coding. (arXiv:2312.13933v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yaxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songlin Hu</a></p>
<p>This paper presents a new supervised representation learning framework,
namely Structured Probabilistic Coding (SPC), to learn compact and informative
representations from input related to the target task. SPC is an encoder-only
probabilistic coding technology with a structured regularization from the
target label space. By extracting compact and informative representations from
input related to the target task, SPC can enhance the generalization ability of
pre-trained language models for better language understanding. Specifically,
the hidden representation is encoded into a Gaussian distribution space, while
maximizing the prior entropy of latent representations concerning label space.
This technique can simultaneously perform information encoding and task
prediction in one module to more fully utilize the effective information from
input data, and use variational inference in the output space to reduce
randomness and uncertainty. To better control the probability distribution in
the latent space, a structured regularization is proposed to promote
class-level uniformity in the latent space. With the regularization term, SPC
can preserve the Gaussian distribution structure of latent code as well as
better cover the hidden space with class uniformly. We conduct evaluations on
12 natural language understanding tasks. The results show that our SPC can
effectively improve the performance of pre-trained language models for various
classification and regression tasks. Experiments demonstrate that SPC can
enhance the generalization capability, robustness to label noise, and
clustering quality of output representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13944">Docking-based generative approaches in the search for new drug candidates. (arXiv:2312.13944v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Danel_T/0/1/0/all/0/1">Tomasz Danel</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Leski_J/0/1/0/all/0/1">Jan &#x141;&#x119;ski</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Podlewska_S/0/1/0/all/0/1">Sabina Podlewska</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Podolak_I/0/1/0/all/0/1">Igor T. Podolak</a></p>
<p>Despite the great popularity of virtual screening of existing compound
libraries, the search for new potential drug candidates also takes advantage of
generative protocols, where new compound suggestions are enumerated using
various algorithms. To increase the activity potency of generative approaches,
they have recently been coupled with molecular docking, a leading methodology
of structure-based drug design. In this review, we summarize progress since
docking-based generative models emerged. We propose a new taxonomy for these
methods and discuss their importance for the field of computer-aided drug
design. In addition, we discuss the most promising directions for further
development of generative protocols coupled with docking.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13947">PhysRFANet: Physics-Guided Neural Network for Real-Time Prediction of Thermal Effect During Radiofrequency Ablation Treatment. (arXiv:2312.13947v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Shin_M/0/1/0/all/0/1">Minwoo Shin</a>, <a href="http://arxiv.org/find/eess/1/au:+Seo_M/0/1/0/all/0/1">Minjee Seo</a>, <a href="http://arxiv.org/find/eess/1/au:+Cho_S/0/1/0/all/0/1">Seonaeng Cho</a>, <a href="http://arxiv.org/find/eess/1/au:+Park_J/0/1/0/all/0/1">Juil Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Kwon_J/0/1/0/all/0/1">Joon Ho Kwon</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1">Deukhee Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Yoon_K/0/1/0/all/0/1">Kyungho Yoon</a></p>
<p>Radiofrequency ablation (RFA) is a widely used minimally invasive technique
for ablating solid tumors. Achieving precise personalized treatment
necessitates feedback information on in situ thermal effects induced by the RFA
procedure. While computer simulation facilitates the prediction of electrical
and thermal phenomena associated with RFA, its practical implementation in
clinical settings is hindered by high computational demands. In this paper, we
propose a physics-guided neural network model, named PhysRFANet, to enable
real-time prediction of thermal effect during RFA treatment. The networks,
designed for predicting temperature distribution and the corresponding ablation
lesion, were trained using biophysical computational models that integrated
electrostatics, bio-heat transfer, and cell necrosis, alongside magnetic
resonance (MR) images of breast cancer patients. Validation of the
computational model was performed through experiments on ex vivo bovine liver
tissue. Our model demonstrated a 96% Dice score in predicting the lesion volume
and an RMSE of 0.4854 for temperature distribution when tested with foreseen
tumor images. Notably, even with unforeseen images, it achieved a 93% Dice
score for the ablation lesion and an RMSE of 0.6783 for temperature
distribution. All networks were capable of inferring results within 10 ms. The
presented technique, applied to optimize the placement of the electrode for a
specific target region, holds significant promise in enhancing the safety and
efficacy of RFA treatments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13970">On Partial Optimal Transport: Revising the Infeasibility of Sinkhorn and Efficient Gradient Methods. (arXiv:2312.13970v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Anh Duc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tuan Dung Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quang Minh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hoang H. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Toh_K/0/1/0/all/0/1">Kim-Chuan Toh</a></p>
<p>This paper studies the Partial Optimal Transport (POT) problem between two
unbalanced measures with at most $n$ supports and its applications in various
AI tasks such as color transfer or domain adaptation. There is hence the need
for fast approximations of POT with increasingly large problem sizes in arising
applications. We first theoretically and experimentally investigate the
infeasibility of the state-of-the-art Sinkhorn algorithm for POT due to its
incompatible rounding procedure, which consequently degrades its qualitative
performance in real world applications like point-cloud registration. To this
end, we propose a novel rounding algorithm for POT, and then provide a feasible
Sinkhorn procedure with a revised computation complexity of
$\mathcal{\widetilde O}(n^2/\varepsilon^4)$. Our rounding algorithm also
permits the development of two first-order methods to approximate the POT
problem. The first algorithm, Adaptive Primal-Dual Accelerated Gradient Descent
(APDAGD), finds an $\varepsilon$-approximate solution to the POT problem in
$\mathcal{\widetilde O}(n^{2.5}/\varepsilon)$, which is better in $\varepsilon$
than revised Sinkhorn. The second method, Dual Extrapolation, achieves the
computation complexity of $\mathcal{\widetilde O}(n^2/\varepsilon)$, thereby
being the best in the literature. We further demonstrate the flexibility of POT
compared to standard OT as well as the practicality of our algorithms on real
applications where two marginal distributions are unbalanced.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13978">Metalearning with Very Few Samples Per Task. (arXiv:2312.13978v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aliakbarpour_M/0/1/0/all/0/1">Maryam Aliakbarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Bairaktari_K/0/1/0/all/0/1">Konstantina Bairaktari</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_G/0/1/0/all/0/1">Gavin Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Adam Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1">Jonathan Ullman</a></p>
<p>Metalearning and multitask learning are two frameworks for solving a group of
related learning tasks more efficiently than we could hope to solve each of the
individual tasks on their own. In multitask learning, we are given a fixed set
of related learning tasks and need to output one accurate model per task,
whereas in metalearning we are given tasks that are drawn i.i.d. from a
metadistribution and need to output some common information that can be easily
specialized to new, previously unseen tasks from the metadistribution.
</p>
<p>In this work, we consider a binary classification setting where tasks are
related by a shared representation, that is, every task $P$ of interest can be
solved by a classifier of the form $f_{P} \circ h$ where $h \in H$ is a map
from features to some representation space that is shared across tasks, and
$f_{P} \in F$ is a task-specific classifier from the representation space to
labels. The main question we ask in this work is how much data do we need to
metalearn a good representation? Here, the amount of data is measured in terms
of both the number of tasks $t$ that we need to see and the number of samples
$n$ per task. We focus on the regime where the number of samples per task is
extremely small. Our main result shows that, in a distribution-free setting
where the feature vectors are in $\mathbb{R}^d$, the representation is a linear
map from $\mathbb{R}^d \to \mathbb{R}^k$, and the task-specific classifiers are
halfspaces in $\mathbb{R}^k$, we can metalearn a representation with error
$\varepsilon$ using just $n = k+2$ samples per task, and $d \cdot
(1/\varepsilon)^{O(k)}$ tasks. Learning with so few samples per task is
remarkable because metalearning would be impossible with $k+1$ samples per
task, and because we cannot even hope to learn an accurate task-specific
classifier with just $k+2$ samples per task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13985">R\&#x27;enyi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration. (arXiv:2312.13985v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pierquin_C/0/1/0/all/0/1">Cl&#xe9;ment Pierquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1">Aur&#xe9;lien Bellet</a>, <a href="http://arxiv.org/find/cs/1/au:+Tommasi_M/0/1/0/all/0/1">Marc Tommasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Boussard_M/0/1/0/all/0/1">Matthieu Boussard</a></p>
<p>Pufferfish privacy is a flexible generalization of differential privacy that
allows to model arbitrary secrets and adversary's prior knowledge about the
data. Unfortunately, designing general and tractable Pufferfish mechanisms that
do not compromise utility is challenging. Furthermore, this framework does not
provide the composition guarantees needed for a direct use in iterative machine
learning algorithms. To mitigate these issues, we introduce a R\'enyi
divergence-based variant of Pufferfish and show that it allows us to extend the
applicability of the Pufferfish framework. We first generalize the Wasserstein
mechanism to cover a wide range of noise distributions and introduce several
ways to improve its utility. We also derive stronger guarantees against
out-of-distribution adversaries. Finally, as an alternative to composition, we
prove privacy amplification results for contractive noisy iterations and
showcase the first use of Pufferfish in private convex optimization. A common
ingredient underlying our results is the use and extension of shift reduction
lemmas.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13987">Modular Neural Network Policies for Learning In-Flight Object Catching with a Robot Hand-Arm System. (arXiv:2312.13987v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenbin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Acero_F/0/1/0/all/0/1">Fernando Acero</a>, <a href="http://arxiv.org/find/cs/1/au:+Triantafyllidis_E/0/1/0/all/0/1">Eleftherios Triantafyllidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhaocheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhibin Li</a></p>
<p>We present a modular framework designed to enable a robot hand-arm system to
learn how to catch flying objects, a task that requires fast, reactive, and
accurately-timed robot motions. Our framework consists of five core modules:
(i) an object state estimator that learns object trajectory prediction, (ii) a
catching pose quality network that learns to score and rank object poses for
catching, (iii) a reaching control policy trained to move the robot hand to
pre-catch poses, (iv) a grasping control policy trained to perform soft
catching motions for safe and robust grasping, and (v) a gating network trained
to synthesize the actions given by the reaching and grasping policy. The former
two modules are trained via supervised learning and the latter three use deep
reinforcement learning in a simulated environment. We conduct extensive
evaluations of our framework in simulation for each module and the integrated
system, to demonstrate high success rates of in-flight catching and robustness
to perturbations and sensory noise. Whilst only simple cylindrical and
spherical objects are used for training, the integrated system shows successful
generalization to a variety of household objects that are not used in training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14000">Risk-Sensitive Stochastic Optimal Control as Rao-Blackwellized Markovian Score Climbing. (arXiv:2312.14000v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abdulsamad_H/0/1/0/all/0/1">Hany Abdulsamad</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_S/0/1/0/all/0/1">Sahel Iqbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Corenflos_A/0/1/0/all/0/1">Adrien Corenflos</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkka_S/0/1/0/all/0/1">Simo S&#xe4;rkk&#xe4;</a></p>
<p>Stochastic optimal control of dynamical systems is a crucial challenge in
sequential decision-making. Recently, control-as-inference approaches have had
considerable success, providing a viable risk-sensitive framework to address
the exploration-exploitation dilemma. Nonetheless, a majority of these
techniques only invoke the inference-control duality to derive a modified risk
objective that is then addressed within a reinforcement learning framework.
This paper introduces a novel perspective by framing risk-sensitive stochastic
control as Markovian score climbing under samples drawn from a conditional
particle filter. Our approach, while purely inference-centric, provides
asymptotically unbiased estimates for gradient-based policy optimization with
optimal importance weighting and no explicit value function learning. To
validate our methodology, we apply it to the task of learning neural
non-Gaussian feedback policies, showcasing its efficacy on numerical benchmarks
of stochastic dynamical systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14020">BANSpEmo: A Bangla Emotional Speech Recognition Dataset. (arXiv:2312.14020v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hussain_M/0/1/0/all/0/1">Md Gulzar Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahmuda Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sultana_B/0/1/0/all/0/1">Babe Sultana</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiren_Y/0/1/0/all/0/1">Ye Shiren</a></p>
<p>In the field of audio and speech analysis, the ability to identify emotions
from acoustic signals is essential. Human-computer interaction (HCI) and
behavioural analysis are only a few of the many areas where the capacity to
distinguish emotions from speech signals has an extensive range of
applications. Here, we are introducing BanSpEmo, a corpus of emotional speech
that only consists of audio recordings and has been created specifically for
the Bangla language. This corpus contains 792 audio recordings over a duration
of more than 1 hour and 23 minutes. 22 native speakers took part in the
recording of two sets of sentences that represent the six desired emotions. The
data set consists of 12 Bangla sentences which are uttered in 6 emotions as
Disgust, Happy, Sad, Surprised, Anger, and Fear. This corpus is not also gender
balanced. Ten individuals who either have experience in related field or have
acting experience took part in the assessment of this corpus. It has a balanced
number of audio recordings in each emotion class. BanSpEmo can be considered as
a useful resource to promote emotion and speech recognition research and
related applications in the Bangla language. The dataset can be found here:
https://data.mendeley.com/datasets/rdwn4bs5ky and might be employed for
academic research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14021">Leveraging Visual Supervision for Array-based Active Speaker Detection and Localization. (arXiv:2312.14021v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Berghi_D/0/1/0/all/0/1">Davide Berghi</a>, <a href="http://arxiv.org/find/eess/1/au:+Jackson_P/0/1/0/all/0/1">Philip J. B. Jackson</a></p>
<p>Conventional audio-visual approaches for active speaker detection (ASD)
typically rely on visually pre-extracted face tracks and the corresponding
single-channel audio to find the speaker in a video. Therefore, they tend to
fail every time the face of the speaker is not visible. We demonstrate that a
simple audio convolutional recurrent neural network (CRNN) trained with spatial
input features extracted from multichannel audio can perform simultaneous
horizontal active speaker detection and localization (ASDL), independently of
the visual modality. To address the time and cost of generating ground truth
labels to train such a system, we propose a new self-supervised training
pipeline that embraces a ``student-teacher'' learning approach. A conventional
pre-trained active speaker detector is adopted as a ``teacher'' network to
provide the position of the speakers as pseudo-labels. The multichannel audio
``student'' network is trained to generate the same results. At inference, the
student network can generalize and locate also the occluded speakers that the
teacher network is not able to detect visually, yielding considerable
improvements in recall rate. Experiments on the TragicTalkers dataset show that
an audio network trained with the proposed self-supervised learning approach
can exceed the performance of the typical audio-visual methods and produce
results competitive with the costly conventional supervised training. We
demonstrate that improvements can be achieved when minimal manual supervision
is introduced in the learning pipeline. Further gains may be sought with larger
training sets and integrating vision with the multichannel audio system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14027">AdamMCMC: Combining Metropolis Adjusted Langevin with Momentum-based Optimization. (arXiv:2312.14027v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Bieringer_S/0/1/0/all/0/1">Sebastian Bieringer</a>, <a href="http://arxiv.org/find/stat/1/au:+Kasieczka_G/0/1/0/all/0/1">Gregor Kasieczka</a>, <a href="http://arxiv.org/find/stat/1/au:+Steffen_M/0/1/0/all/0/1">Maximilian F. Steffen</a>, <a href="http://arxiv.org/find/stat/1/au:+Trabs_M/0/1/0/all/0/1">Mathias Trabs</a></p>
<p>Uncertainty estimation is a key issue when considering the application of
deep neural network methods in science and engineering. In this work, we
introduce a novel algorithm that quantifies epistemic uncertainty via Monte
Carlo sampling from a tempered posterior distribution. It combines the well
established Metropolis Adjusted Langevin Algorithm (MALA) with momentum-based
optimization using Adam and leverages a prolate proposal distribution, to
efficiently draw from the posterior. We prove that the constructed chain admits
the Gibbs posterior as an invariant distribution and converges to this Gibbs
posterior in total variation distance. Numerical evaluations are postponed to a
first revision.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14037">Neural Contextual Bandits for Personalized Recommendation. (arXiv:2312.14037v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ban_Y/0/1/0/all/0/1">Yikun Ban</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yunzhe Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jingrui He</a></p>
<p>In the dynamic landscape of online businesses, recommender systems are
pivotal in enhancing user experiences. While traditional approaches have relied
on static supervised learning, the quest for adaptive, user-centric
recommendations has led to the emergence of the formulation of contextual
bandits. This tutorial investigates the contextual bandits as a powerful
framework for personalized recommendations. We delve into the challenges,
advanced algorithms and theories, collaborative strategies, and open challenges
and future prospects within this field. Different from existing related
tutorials, (1) we focus on the exploration perspective of contextual bandits to
alleviate the ``Matthew Effect'' in the recommender systems, i.e., the rich get
richer and the poor get poorer, concerning the popularity of items; (2) in
addition to the conventional linear contextual bandits, we will also dedicated
to neural contextual bandits which have emerged as an important branch in
recent years, to investigate how neural networks benefit contextual bandits for
personalized recommendation both empirically and theoretically; (3) we will
cover the latest topic, collaborative neural contextual bandits, to incorporate
both user heterogeneity and user correlations customized for recommender
system; (4) we will provide and discuss the new emerging challenges and open
questions for neural contextual bandits with applications in the personalized
recommendation, especially for large neural models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14050">Machine learning and domain decomposition methods -- a survey. (arXiv:2312.14050v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Klawonn_A/0/1/0/all/0/1">Axel Klawonn</a>, <a href="http://arxiv.org/find/math/1/au:+Lanser_M/0/1/0/all/0/1">Martin Lanser</a>, <a href="http://arxiv.org/find/math/1/au:+Weber_J/0/1/0/all/0/1">Janine Weber</a></p>
<p>Hybrid algorithms, which combine black-box machine learning methods with
experience from traditional numerical methods and domain expertise from diverse
application areas, are progressively gaining importance in scientific machine
learning and various industrial domains, especially in computational science
and engineering. In the present survey, several promising avenues of research
will be examined which focus on the combination of machine learning (ML) and
domain decomposition methods (DDMs). The aim of this survey is to provide an
overview of existing work within this field and to structure it into domain
decomposition for machine learning and machine learning-enhanced domain
decomposition, including: domain decomposition for classical machine learning,
domain decomposition to accelerate the training of physics-aware neural
networks, machine learning to enhance the convergence properties or
computational efficiency of DDMs, and machine learning as a discretization
method in a DDM for the solution of PDEs. In each of these fields, we summarize
existing work and key advances within a common framework and, finally, disuss
ongoing challenges and opportunities for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14057">Weighted least-squares approximation with determinantal point processes and generalized volume sampling. (arXiv:2312.14057v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Nouy_A/0/1/0/all/0/1">Anthony Nouy</a>, <a href="http://arxiv.org/find/math/1/au:+Michel_B/0/1/0/all/0/1">Bertrand Michel</a></p>
<p>We consider the problem of approximating a function from $L^2$ by an element
of a given $m$-dimensional space $V_m$, associated with some feature map
$\varphi$, using evaluations of the function at random points $x_1,\dots,x_n$.
After recalling some results on optimal weighted least-squares using
independent and identically distributed points, we consider weighted
least-squares using projection determinantal point processes (DPP) or volume
sampling. These distributions introduce dependence between the points that
promotes diversity in the selected features $\varphi(x_i)$. We first provide a
generalized version of volume-rescaled sampling yielding quasi-optimality
results in expectation with a number of samples $n = O(m\log(m))$, that means
that the expected $L^2$ error is bounded by a constant times the best
approximation error in $L^2$. Also, further assuming that the function is in
some normed vector space $H$ continuously embedded in $L^2$, we further prove
that the approximation is almost surely bounded by the best approximation error
measured in the $H$-norm. This includes the cases of functions from $L^\infty$
or reproducing kernel Hilbert spaces. Finally, we present an alternative
strategy consisting in using independent repetitions of projection DPP (or
volume sampling), yielding similar error bounds as with i.i.d. or volume
sampling, but in practice with a much lower number of samples. Numerical
experiments illustrate the performance of the different strategies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14066">Upper Bounding Barlow Twins: A Novel Filter for Multi-Relational Clustering. (arXiv:2312.14066v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xiaowei Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bingheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a></p>
<p>Multi-relational clustering is a challenging task due to the fact that
diverse semantic information conveyed in multi-layer graphs is difficult to
extract and fuse. Recent methods integrate topology structure and node
attribute information through graph filtering. However, they often use a
low-pass filter without fully considering the correlation among multiple
graphs. To overcome this drawback, we propose to learn a graph filter motivated
by the theoretical analysis of Barlow Twins. We find that input with a negative
semi-definite inner product provides a lower bound for Barlow Twins loss, which
prevents it from reaching a better solution. We thus learn a filter that yields
an upper bound for Barlow Twins. Afterward, we design a simple clustering
architecture and demonstrate its state-of-the-art performance on four benchmark
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14078">Learned reconstruction methods for inverse problems: sample error estimates. (arXiv:2312.14078v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ratti_L/0/1/0/all/0/1">Luca Ratti</a></p>
<p>Learning-based and data-driven techniques have recently become a subject of
primary interest in the field of reconstruction and regularization of inverse
problems. Besides the development of novel methods, yielding excellent results
in several applications, their theoretical investigation has attracted growing
interest, e.g., on the topics of reliability, stability, and interpretability.
In this work, a general framework is described, allowing us to interpret many
of these techniques in the context of statistical learning. This is not
intended to provide a complete survey of existing methods, but rather to put
them in a working perspective, which naturally allows their theoretical
treatment. The main goal of this dissertation is thereby to address the
generalization properties of learned reconstruction methods, and specifically
to perform their sample error analysis. This task, well-developed in
statistical learning, consists in estimating the dependence of the learned
operators with respect to the data employed for their training. A rather
general strategy is proposed, whose assumptions are met for a large class of
inverse problems and learned methods, as depicted via a selection of examples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14095">RetailSynth: Synthetic Data Generation for Retail AI Systems Evaluation. (arXiv:2312.14095v1 [stat.AP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Xia_Y/0/1/0/all/0/1">Yu Xia</a>, <a href="http://arxiv.org/find/stat/1/au:+Arian_A/0/1/0/all/0/1">Ali Arian</a>, <a href="http://arxiv.org/find/stat/1/au:+Narayanamoorthy_S/0/1/0/all/0/1">Sriram Narayanamoorthy</a>, <a href="http://arxiv.org/find/stat/1/au:+Mabry_J/0/1/0/all/0/1">Joshua Mabry</a></p>
<p>Significant research effort has been devoted in recent years to developing
personalized pricing, promotions, and product recommendation algorithms that
can leverage rich customer data to learn and earn. Systematic benchmarking and
evaluation of these causal learning systems remains a critical challenge, due
to the lack of suitable datasets and simulation environments. In this work, we
propose a multi-stage model for simulating customer shopping behavior that
captures important sources of heterogeneity, including price sensitivity and
past experiences. We embedded this model into a working simulation environment
-- RetailSynth. RetailSynth was carefully calibrated on publicly available
grocery data to create realistic synthetic shopping transactions. Multiple
pricing policies were implemented within the simulator and analyzed for impact
on revenue, category penetration, and customer retention. Applied researchers
can use RetailSynth to validate causal demand models for multi-category retail
and to incorporate realistic price sensitivity into emerging benchmarking
suites for personalized pricing, promotions, and product recommendations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14106">Learning Human-like Representations to Enable Learning Human Values. (arXiv:2312.14106v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wynn_A/0/1/0/all/0/1">Andrea Wynn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sucholutsky_I/0/1/0/all/0/1">Ilia Sucholutsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a></p>
<p>How can we build AI systems that are aligned with human values and objectives
in order to avoid causing harm or violating societal standards for acceptable
behavior? Making AI systems learn human-like representations of the world has
many known benefits, including improving generalization, robustness to domain
shifts, and few-shot learning performance, among others. We propose that this
kind of representational alignment between machine learning (ML) models and
humans is also a necessary condition for value alignment, where ML systems
conform to human values and societal norms. We focus on ethics as one aspect of
value alignment and train multiple ML agents (support vector regression and
kernel regression) in a multi-armed bandit setting, where rewards are sampled
from a distribution that reflects the morality of the chosen action. We then
study the relationship between each agent's degree of representational
alignment with humans and their performance when learning to take the most
ethical actions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14129">WellFactor: Patient Profiling using Integrative Embedding of Healthcare Data. (arXiv:2312.14129v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dongjin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_A/0/1/0/all/0/1">Andy Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozturk_O/0/1/0/all/0/1">Ozgur Ozturk</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrestha_D/0/1/0/all/0/1">Deep Shrestha</a>, <a href="http://arxiv.org/find/cs/1/au:+Drake_B/0/1/0/all/0/1">Barry Drake</a>, <a href="http://arxiv.org/find/cs/1/au:+Haidarian_H/0/1/0/all/0/1">Hamid Haidarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Javed_F/0/1/0/all/0/1">Faizan Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Haesun Park</a></p>
<p>In the rapidly evolving healthcare industry, platforms now have access to not
only traditional medical records, but also diverse data sets encompassing
various patient interactions, such as those from healthcare web portals. To
address this rich diversity of data, we introduce WellFactor: a method that
derives patient profiles by integrating information from these sources. Central
to our approach is the utilization of constrained low-rank approximation.
WellFactor is optimized to handle the sparsity that is often inherent in
healthcare data. Moreover, by incorporating task-specific label information,
our method refines the embedding results, offering a more informed perspective
on patients. One important feature of WellFactor is its ability to compute
embeddings for new, previously unobserved patient data instantaneously,
eliminating the need to revisit the entire data set or recomputing the
embedding. Comprehensive evaluations on real-world healthcare data demonstrate
WellFactor's effectiveness. It produces better results compared to other
existing methods in classification performance, yields meaningful clustering of
patients, and delivers consistent results in patient similarity searches and
predictions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14134">Diffusion Reward: Learning Rewards via Conditional Video Diffusion. (arXiv:2312.14134v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_G/0/1/0/all/0/1">Guangqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ze_Y/0/1/0/all/0/1">Yanjie Ze</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a></p>
<p>Learning rewards from expert videos offers an affordable and effective
solution to specify the intended behaviors for reinforcement learning tasks. In
this work, we propose Diffusion Reward, a novel framework that learns rewards
from expert videos via conditional video diffusion models for solving complex
visual RL problems. Our key insight is that lower generative diversity is
observed when conditioned on expert trajectories. Diffusion Reward is
accordingly formalized by the negative of conditional entropy that encourages
productive exploration of expert-like behaviors. We show the efficacy of our
method over 10 robotic manipulation tasks from MetaWorld and Adroit with visual
input and sparse reward. Moreover, Diffusion Reward could even solve unseen
tasks successfully and effectively, largely surpassing baseline methods.
Project page and code: https://diffusion-reward.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14136">Fast kernel half-space depth for data with non-convex supports. (arXiv:2312.14136v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Castellanos_A/0/1/0/all/0/1">Arturo Castellanos</a>, <a href="http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1">Pavlo Mozharovskyi</a>, <a href="http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1">Florence d&#x27;Alch&#xe9;-Buc</a>, <a href="http://arxiv.org/find/stat/1/au:+Janati_H/0/1/0/all/0/1">Hicham Janati</a></p>
<p>Data depth is a statistical function that generalizes order and quantiles to
the multivariate setting and beyond, with applications spanning over
descriptive and visual statistics, anomaly detection, testing, etc. The
celebrated halfspace depth exploits data geometry via an optimization program
to deliver properties of invariances, robustness, and non-parametricity.
Nevertheless, it implicitly assumes convex data supports and requires
exponential computational cost. To tackle distribution's multimodality, we
extend the halfspace depth in a Reproducing Kernel Hilbert Space (RKHS). We
show that the obtained depth is intuitive and establish its consistency with
provable concentration bounds that allow for homogeneity testing. The proposed
depth can be computed using manifold gradient making faster than halfspace
depth by several orders of magnitude. The performance of our depth is
demonstrated through numerical simulations as well as applications such as
anomaly detection on real data and homogeneity testing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.14141">Quantum Algorithms for the Pathwise Lasso. (arXiv:2312.14141v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Doriguello_J/0/1/0/all/0/1">Jo&#xe3;o F. Doriguello</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lim_D/0/1/0/all/0/1">Debbie Lim</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pun_C/0/1/0/all/0/1">Chi Seng Pun</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Rebentrost_P/0/1/0/all/0/1">Patrick Rebentrost</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Vaidya_T/0/1/0/all/0/1">Tushar Vaidya</a></p>
<p>We present a novel quantum high-dimensional linear regression algorithm with
an $\ell_1$-penalty based on the classical LARS (Least Angle Regression)
pathwise algorithm. Similarly to available classical numerical algorithms for
Lasso, our quantum algorithm provides the full regularisation path as the
penalty term varies, but quadratically faster per iteration under specific
conditions. A quadratic speedup on the number of features/predictors $d$ is
possible by using the simple quantum minimum-finding subroutine from D\"urr and
Hoyer (arXiv'96) in order to obtain the joining time at each iteration. We then
improve upon this simple quantum algorithm and obtain a quadratic speedup both
in the number of features $d$ and the number of observations $n$ by using the
recent approximate quantum minimum-finding subroutine from Chen and de Wolf
(ICALP'23). As one of our main contributions, we construct a quantum unitary
based on quantum amplitude estimation to approximately compute the joining
times to be searched over by the approximate quantum minimum finding. Since the
joining times are no longer exactly computed, it is no longer clear that the
resulting approximate quantum algorithm obtains a good solution. As our second
main contribution, we prove, via an approximate version of the KKT conditions
and a duality gap, that the LARS algorithm (and therefore our quantum
algorithm) is robust to errors. This means that it still outputs a path that
minimises the Lasso cost function up to a small error if the joining times are
only approximately computed. Finally, in the model where the observations are
generated by an underlying linear model with an unknown coefficient vector, we
prove bounds on the difference between the unknown coefficient vector and the
approximate Lasso solution, which generalises known results about convergence
rates in classical statistical learning theory analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2105.08526">Transformers \`a Grande Vitesse. (arXiv:2105.08526v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arthaud_F/0/1/0/all/0/1">Farid Arthaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Lecoeur_G/0/1/0/all/0/1">Guillaume Lecoeur</a>, <a href="http://arxiv.org/find/cs/1/au:+Pierre_A/0/1/0/all/0/1">Alban Pierre</a></p>
<p>Robust travel time predictions are of prime importance in managing any
transportation infrastructure, and particularly in rail networks where they
have major impacts both on traffic regulation and passenger satisfaction. We
aim at predicting the travel time of trains on rail sections at the scale of an
entire rail network in real-time, by estimating trains' delays relative to a
theoretical circulation plan.
</p>
<p>Predicting the evolution of a given train's delay is a uniquely hard problem,
distinct from mainstream road traffic forecasting problems, since it involves
several hard-to-model phenomena: train spacing, station congestion and
heterogeneous rolling stock among others. We first offer empirical evidence of
the previously unexplored phenomenon of delay propagation at the scale of a
railway network, leading to delays being amplified by interactions between
trains and the network's physical limitations.
</p>
<p>We then contribute a novel technique using the transformer architecture and
pre-trained embeddings to make real-time massively parallel predictions for
train delays at the scale of the whole rail network (over 3000 trains at peak
hours, making predictions at an average horizon of 70 minutes). Our approach
yields very positive results on real-world data when compared to currently-used
and experimental prediction techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.00824">KSD Aggregated Goodness-of-fit Test. (arXiv:2202.00824v6 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Schrab_A/0/1/0/all/0/1">Antonin Schrab</a>, <a href="http://arxiv.org/find/stat/1/au:+Guedj_B/0/1/0/all/0/1">Benjamin Guedj</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a></p>
<p>We investigate properties of goodness-of-fit tests based on the Kernel Stein
Discrepancy (KSD). We introduce a strategy to construct a test, called KSDAgg,
which aggregates multiple tests with different kernels. KSDAgg avoids splitting
the data to perform kernel selection (which leads to a loss in test power), and
rather maximises the test power over a collection of kernels. We provide
non-asymptotic guarantees on the power of KSDAgg: we show it achieves the
smallest uniform separation rate of the collection, up to a logarithmic term.
For compactly supported densities with bounded model score function, we derive
the rate for KSDAgg over restricted Sobolev balls; this rate corresponds to the
minimax optimal rate over unrestricted Sobolev balls, up to an iterated
logarithmic term. KSDAgg can be computed exactly in practice as it relies
either on a parametric bootstrap or on a wild bootstrap to estimate the
quantiles and the level corrections. In particular, for the crucial choice of
bandwidth of a fixed kernel, it avoids resorting to arbitrary heuristics (such
as median or standard deviation) or to data splitting. We find on both
synthetic and real-world data that KSDAgg outperforms other state-of-the-art
quadratic-time adaptive KSD-based goodness-of-fit testing procedures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.14203">Latent Combinational Game Design. (arXiv:2206.14203v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Anurag Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cooper_S/0/1/0/all/0/1">Seth Cooper</a></p>
<p>We present latent combinational game design -- an approach for generating
playable games that blend a given set of games in a desired combination using
deep generative latent variable models. We use Gaussian Mixture Variational
Autoencoders (GMVAEs) which model the VAE latent space via a mixture of
Gaussian components. Through supervised training, each component encodes levels
from one game and lets us define blended games as linear combinations of these
components. This enables generating new games that blend the input games as
well as controlling the relative proportions of each game in the blend. We also
extend prior blending work using conditional VAEs and compare against the GMVAE
and additionally introduce a hybrid conditional GMVAE (CGMVAE) architecture
which lets us generate whole blended levels and layouts. Results show that
these approaches can generate playable games that blend the input games in
specified combinations. We use both platformers and dungeon-based games to
demonstrate our results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.02998">ThoraX-PriorNet: A Novel Attention-Based Architecture Using Anatomical Prior Probability Maps for Thoracic Disease Classification. (arXiv:2210.02998v3 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hossain_M/0/1/0/all/0/1">Md. Iqbal Hossain</a>, <a href="http://arxiv.org/find/eess/1/au:+Zunaed_M/0/1/0/all/0/1">Mohammad Zunaed</a>, <a href="http://arxiv.org/find/eess/1/au:+Ahmed_M/0/1/0/all/0/1">Md. Kawsar Ahmed</a>, <a href="http://arxiv.org/find/eess/1/au:+Hossain_S/0/1/0/all/0/1">S. M. Jawwad Hossain</a>, <a href="http://arxiv.org/find/eess/1/au:+Hasan_A/0/1/0/all/0/1">Anwarul Hasan</a>, <a href="http://arxiv.org/find/eess/1/au:+Hasan_T/0/1/0/all/0/1">Taufiq Hasan</a></p>
<p>Objective: Computer-aided disease diagnosis and prognosis based on medical
images is a rapidly emerging field. Many Convolutional Neural Network (CNN)
architectures have been developed by researchers for disease classification and
localization from chest X-ray images. It is known that different thoracic
disease lesions are more likely to occur in specific anatomical regions
compared to others. This article aims to incorporate this disease and
region-dependent prior probability distribution within a deep learning
framework. Methods: We present the ThoraX-PriorNet, a novel attention-based CNN
model for thoracic disease classification. We first estimate a
disease-dependent spatial probability, i.e., an anatomical prior, that
indicates the probability of occurrence of a disease in a specific region in a
chest X-ray image. Next, we develop a novel attention-based classification
model that combines information from the estimated anatomical prior and
automatically extracted chest region of interest (ROI) masks to provide
attention to the feature maps generated from a deep convolution network. Unlike
previous works that utilize various self-attention mechanisms, the proposed
method leverages the extracted chest ROI masks along with the probabilistic
anatomical prior information, which selects the region of interest for
different diseases to provide attention. Results: The proposed method shows
superior performance in disease classification on the NIH ChestX-ray14 dataset
compared to existing state-of-the-art methods while reaching an area under the
ROC curve (%AUC) of 84.67. Regarding disease localization, the anatomy prior
attention method shows competitive performance compared to state-of-the-art
methods, achieving an accuracy of 0.80, 0.63, 0.49, 0.33, 0.28, 0.21, and 0.04
with an Intersection over Union (IoU) threshold of 0.1, 0.2, 0.3, 0.4, 0.5,
0.6, and 0.7, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.14404">Adversarial Purification with the Manifold Hypothesis. (arXiv:2210.14404v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaoyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartley_R/0/1/0/all/0/1">Richard Hartley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_P/0/1/0/all/0/1">Peter Tu</a></p>
<p>In this work, we formulate a novel framework for adversarial robustness using
the manifold hypothesis. This framework provides sufficient conditions for
defending against adversarial examples. We develop an adversarial purification
method with this framework. Our method combines manifold learning with
variational inference to provide adversarial robustness without the need for
expensive adversarial training. Experimentally, our approach can provide
adversarial robustness even if attackers are aware of the existence of the
defense. In addition, our method can also serve as a test-time defense
mechanism for variational autoencoders.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.01877">Convex Clustering through MM: An Efficient Algorithm to Perform Hierarchical Clustering. (arXiv:2211.01877v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Touw_D/0/1/0/all/0/1">Daniel J. W. Touw</a>, <a href="http://arxiv.org/find/stat/1/au:+Groenen_P/0/1/0/all/0/1">Patrick J. F. Groenen</a>, <a href="http://arxiv.org/find/stat/1/au:+Terada_Y/0/1/0/all/0/1">Yoshikazu Terada</a></p>
<p>Convex clustering is a modern method with both hierarchical and $k$-means
clustering characteristics. Although convex clustering can capture complex
clustering structures hidden in data, the existing convex clustering algorithms
are not scalable to large data sets with sample sizes greater than several
thousands. Moreover, it is known that convex clustering sometimes fails to
produce a complete hierarchical clustering structure. This issue arises if
clusters split up or the minimum number of possible clusters is larger than the
desired number of clusters. In this paper, we propose convex clustering through
majorization-minimization (CCMM) -- an iterative algorithm that uses cluster
fusions and a highly efficient updating scheme derived using diagonal
majorization. Additionally, we explore different strategies to ensure that the
hierarchical clustering structure terminates in a single cluster. With a
current desktop computer, CCMM efficiently solves convex clustering problems
featuring over one million objects in seven-dimensional space, achieving a
solution time of 51 seconds on average.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.02843">Unleashing the Power of Graph Data Augmentation on Covariate Distribution Shift. (arXiv:2211.02843v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1">Yongduo Sui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qitian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiancan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Q/0/1/0/all/0/1">Qing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Longfei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a></p>
<p>The issue of distribution shifts is emerging as a critical concern in graph
representation learning. From the perspective of invariant learning and stable
learning, a recently well-established paradigm for out-of-distribution
generalization, stable features of the graph are assumed to causally determine
labels, while environmental features tend to be unstable and can lead to the
two primary types of distribution shifts. The correlation shift is often caused
by the spurious correlation between environmental features and labels that
differs between the training and test data; the covariate shift often stems
from the presence of new environmental features in test data. However, most
strategies, such as invariant learning or graph augmentation, typically
struggle with limited training environments or perturbed stable features, thus
exposing limitations in handling the problem of covariate shift. To address
this challenge, we propose a simple-yet-effective data augmentation strategy,
Adversarial Invariant Augmentation (AIA), to handle the covariate shift on
graphs. Specifically, given the training data, AIA aims to extrapolate and
generate new environments, while concurrently preserving the original stable
features during the augmentation process. Such a design equips the graph
classification model with an enhanced capability to identify stable features in
new environments, thereby effectively tackling the covariate shift in data.
Extensive experiments with in-depth empirical analysis demonstrate the
superiority of our approach. The implementation codes are publicly available at
https://github.com/yongduosui/AIA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.07864">Federated Adaptive Prompt Tuning for Multi-domain Collaborative Learning. (arXiv:2211.07864v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1">Shangchao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Mingzhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xiangyang Xue</a></p>
<p>Federated learning (FL) enables multiple clients to collaboratively train a
global model without disclosing their data. Previous researches often require
training the complete model parameters. However, the emergence of powerful
pre-trained models makes it possible to achieve higher performance with fewer
learnable parameters in FL. In this paper, we propose a federated adaptive
prompt tuning algorithm, FedAPT, for multi-domain collaborative image
classification with powerful foundation models, like CLIP. Compared with direct
federated prompt tuning, our core idea is to adaptively unlock specific domain
knowledge for each test sample in order to provide them with personalized
prompts. To implement this idea, we design an adaptive prompt tuning module,
which consists of a meta prompt, an adaptive network, and some keys. The server
randomly generates a set of keys and assigns a unique key to each client. Then
all clients cooperatively train the global adaptive network and meta prompt
with the local datasets and the frozen keys. Ultimately, the global aggregation
model can assign a personalized prompt to CLIP based on the domain features of
each test sample. We perform extensive experiments on two multi-domain image
classification datasets across two different settings -- supervised and
unsupervised. The results show that FedAPT can achieve better performance with
less than 10\% of the number of parameters of the fully trained model, and the
global model can perform well in diverse client domains simultaneously.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.14236">Strategyproof Decision-Making in Panel Data Settings and Beyond. (arXiv:2211.14236v4 [econ.EM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Harris_K/0/1/0/all/0/1">Keegan Harris</a>, <a href="http://arxiv.org/find/econ/1/au:+Agarwal_A/0/1/0/all/0/1">Anish Agarwal</a>, <a href="http://arxiv.org/find/econ/1/au:+Podimata_C/0/1/0/all/0/1">Chara Podimata</a>, <a href="http://arxiv.org/find/econ/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a></p>
<p>We consider the problem of decision-making using panel data, in which a
decision-maker gets noisy, repeated measurements of multiple units (or agents).
We consider a setup where there is a pre-intervention period, when the
principal observes the outcomes of each unit, after which the principal uses
these observations to assign a treatment to each unit. Unlike this classical
setting, we permit the units generating the panel data to be strategic, i.e.
units may modify their pre-intervention outcomes in order to receive a more
desirable intervention. The principal's goal is to design a strategyproof
intervention policy, i.e. a policy that assigns units to their
utility-maximizing interventions despite their potential strategizing. We first
identify a necessary and sufficient condition under which a strategyproof
intervention policy exists, and provide a strategyproof mechanism with a simple
closed form when one does exist. Along the way, we prove impossibility results
for strategic multiclass classification, which may be of independent interest.
When there are two interventions, we establish that there always exists a
strategyproof mechanism, and provide an algorithm for learning such a
mechanism. For three or more interventions, we provide an algorithm for
learning a strategyproof mechanism if there exists a sufficiently large gap in
the principal's rewards between different interventions. Finally, we
empirically evaluate our model using real-world panel data collected from
product sales over 18 months. We find that our methods compare favorably to
baselines which do not take strategic interactions into consideration, even in
the presence of model misspecification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.11442">Communication-Efficient Collaborative Regret Minimization in Multi-Armed Bandits. (arXiv:2301.11442v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Karpov_N/0/1/0/all/0/1">Nikolai Karpov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qin Zhang</a></p>
<p>In this paper, we study the collaborative learning model, which concerns the
tradeoff between parallelism and communication overhead in multi-agent
multi-armed bandits. For regret minimization in multi-armed bandits, we present
the first set of tradeoffs between the number of rounds of communication among
the agents and the regret of the collaborative learning process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.13850">General Gaussian Noise Mechanisms and Their Optimality for Unbiased Mean Estimation. (arXiv:2301.13850v2 [math.ST] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Nikolov_A/0/1/0/all/0/1">Aleksandar Nikolov</a>, <a href="http://arxiv.org/find/math/1/au:+Tang_H/0/1/0/all/0/1">Haohua Tang</a></p>
<p>We investigate unbiased high-dimensional mean estimators in differential
privacy. We consider differentially private mechanisms whose expected output
equals the mean of the input dataset, for every dataset drawn from a fixed
bounded $d$-dimensional domain $K$. A classical approach to private mean
estimation is to compute the true mean and add unbiased, but possibly
correlated, Gaussian noise to it. In the first part of this paper, we study the
optimal error achievable by a Gaussian noise mechanism for a given domain $K$
when the error is measured in the $\ell_p$ norm for some $p \ge 2$. We give
algorithms that compute the optimal covariance for the Gaussian noise for a
given $K$ under suitable assumptions, and prove a number of nice geometric
properties of the optimal error. These results generalize the theory of
factorization mechanisms from domains $K$ that are symmetric and finite (or,
equivalently, symmetric polytopes) to arbitrary bounded domains.
</p>
<p>In the second part of the paper we show that Gaussian noise mechanisms
achieve nearly optimal error among all private unbiased mean estimation
mechanisms in a very strong sense. In particular, for every input dataset, an
unbiased mean estimator satisfying concentrated differential privacy introduces
approximately at least as much error as the best Gaussian noise mechanism. We
extend this result to local differential privacy, and to approximate
differential privacy, but for the latter the error lower bound holds either for
a dataset or for a neighboring dataset, and this relaxation is necessary.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.03616">Can gamification reduce the burden of self-reporting in mHealth applications? A feasibility study using machine learning from smartwatch data to estimate cognitive load. (arXiv:2302.03616v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Grzeszczyk_M/0/1/0/all/0/1">Michal K. Grzeszczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Adamczyk_P/0/1/0/all/0/1">Paulina Adamczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Marek_S/0/1/0/all/0/1">Sylwia Marek</a>, <a href="http://arxiv.org/find/cs/1/au:+Precikowski_R/0/1/0/all/0/1">Ryszard Pr&#x119;cikowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kus_M/0/1/0/all/0/1">Maciej Ku&#x15b;</a>, <a href="http://arxiv.org/find/cs/1/au:+Lelujko_M/0/1/0/all/0/1">M. Patrycja Lelujko</a>, <a href="http://arxiv.org/find/cs/1/au:+Blanco_R/0/1/0/all/0/1">Rosmary Blanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sitek_A/0/1/0/all/0/1">Arkadiusz Sitek</a>, <a href="http://arxiv.org/find/cs/1/au:+Malawski_M/0/1/0/all/0/1">Maciej Malawski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lisowska_A/0/1/0/all/0/1">Aneta Lisowska</a></p>
<p>The effectiveness of digital treatments can be measured by requiring patients
to self-report their state through applications, however, it can be
overwhelming and causes disengagement. We conduct a study to explore the impact
of gamification on self-reporting. Our approach involves the creation of a
system to assess cognitive load (CL) through the analysis of
photoplethysmography (PPG) signals. The data from 11 participants is utilized
to train a machine learning model to detect CL. Subsequently, we create two
versions of surveys: a gamified and a traditional one. We estimate the CL
experienced by other participants (13) while completing surveys. We find that
CL detector performance can be enhanced via pre-training on stress detection
tasks. For 10 out of 13 participants, a personalized CL detector can achieve an
F1 score above 0.7. We find no difference between the gamified and non-gamified
surveys in terms of CL but participants prefer the gamified version.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.11883">PIFON-EPT: MR-Based Electrical Property Tomography Using Physics-Informed Fourier Networks. (arXiv:2302.11883v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xinling Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Serralles_J/0/1/0/all/0/1">Jos&#xe9; E. C. Serrall&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannakopoulos_I/0/1/0/all/0/1">Ilias I. Giannakopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Daniel_L/0/1/0/all/0/1">Luca Daniel</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_R/0/1/0/all/0/1">Riccardo Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a></p>
<p>We propose Physics-Informed Fourier Networks for Electrical Properties (EP)
Tomography (PIFON-EPT), a novel deep learning-based method for EP
reconstruction using noisy and/or incomplete magnetic resonance (MR)
measurements. Our approach leverages the Helmholtz equation to constrain two
networks, responsible for the denoising and completion of the transmit fields,
and the estimation of the object's EP, respectively. We embed a random Fourier
features mapping into our networks to enable efficient learning of
high-frequency details encoded in the transmit fields. We demonstrated the
efficacy of PIFON-EPT through several simulated experiments at 3 and 7 tesla
(T) MR imaging, and showed that our method can reconstruct physically
consistent EP and transmit fields. Specifically, when only $20\%$ of the noisy
measured fields were used as inputs, PIFON-EPT reconstructed the EP of a
phantom with $\leq 5\%$ error, and denoised and completed the measurements with
$\leq 1\%$ error. Additionally, we adapted PIFON-EPT to solve the generalized
Helmholtz equation that accounts for gradients of EP between inhomogeneities.
This yielded improved results at interfaces between different materials without
explicit knowledge of boundary conditions. PIFON-EPT is the first method that
can simultaneously reconstruct EP and transmit fields from incomplete noisy MR
measurements, providing new opportunities for EPT research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.00586">FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling. (arXiv:2303.00586v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Ko_W/0/1/0/all/0/1">Wei-Yin Ko</a>, <a href="http://arxiv.org/find/stat/1/au:+Dsouza_D/0/1/0/all/0/1">Daniel D&#x27;souza</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1">Karina Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1">Randall Balestriero</a>, <a href="http://arxiv.org/find/stat/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a></p>
<p>Ensembling multiple Deep Neural Networks (DNNs) is a simple and effective way
to improve top-line metrics and to outperform a larger single model. In this
work, we go beyond top-line metrics and instead explore the impact of
ensembling on subgroup performances. Surprisingly, we observe that even with a
simple homogeneous ensemble -- all the individual DNNs share the same training
set, architecture, and design choices -- the minority group performance
disproportionately improves with the number of models compared to the majority
group, i.e. fairness naturally emerges from ensembling. Even more surprising,
we find that this gain keeps occurring even when a large number of models is
considered, e.g. $20$, despite the fact that the average performance of the
ensemble plateaus with fewer models. Our work establishes that simple DNN
ensembles can be a powerful tool for alleviating disparate impact from DNN
classifiers, thus curbing algorithmic harm. We also explore why this is the
case. We find that even in homogeneous ensembles, varying the sources of
stochasticity through parameter initialization, mini-batch sampling, and
data-augmentation realizations, results in different fairness outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.06058">A General Recipe for the Analysis of Randomized Multi-Armed Bandit Algorithms. (arXiv:2303.06058v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Baudry_D/0/1/0/all/0/1">Dorian Baudry</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_K/0/1/0/all/0/1">Kazuya Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Honda_J/0/1/0/all/0/1">Junya Honda</a></p>
<p>In this paper we propose a general methodology to derive regret bounds for
randomized multi-armed bandit algorithms. It consists in checking a set of
sufficient conditions on the sampling probability of each arm and on the family
of distributions to prove a logarithmic regret. As a direct application we
revisit two famous bandit algorithms, Minimum Empirical Divergence (MED) and
Thompson Sampling (TS), under various models for the distributions including
single parameter exponential families, Gaussian distributions, bounded
distributions, or distributions satisfying some conditions on their moments. In
particular, we prove that MED is asymptotically optimal for all these models,
but also provide a simple regret analysis of some TS algorithms for which the
optimality is already known. We then further illustrate the interest of our
approach, by analyzing a new Non-Parametric TS algorithm (h-NPTS), adapted to
some families of unbounded reward distributions with a bounded h-moment. This
model can for instance capture some non-parametric families of distributions
whose variance is upper bounded by a known constant.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10512">AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning. (arXiv:2303.10512v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minshuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukharin_A/0/1/0/all/0/1">Alexander Bukharin</a>, <a href="http://arxiv.org/find/cs/1/au:+Karampatziakis_N/0/1/0/all/0/1">Nikos Karampatziakis</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a></p>
<p>Fine-tuning large pre-trained language models on downstream tasks has become
an important paradigm in NLP. However, common practice fine-tunes all of the
parameters in a pre-trained model, which becomes prohibitive when a large
number of downstream tasks are present. Therefore, many fine-tuning methods are
proposed to learn incremental updates of pre-trained weights in a parameter
efficient way, e.g., low-rank increments. These methods often evenly distribute
the budget of incremental updates across all pre-trained weight matrices, and
overlook the varying importance of different weight parameters. As a
consequence, the fine-tuning performance is suboptimal. To bridge this gap, we
propose AdaLoRA, which adaptively allocates the parameter budget among weight
matrices according to their importance score. In particular, AdaLoRA
parameterizes the incremental updates in the form of singular value
decomposition. Such a novel approach allows us to effectively prune the
singular values of unimportant updates, which is essentially to reduce their
parameter budget but circumvent intensive exact SVD computations. We conduct
extensive experiments with several pre-trained models on natural language
processing, question answering, and natural language generation to validate the
effectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable
improvement over baselines, especially in the low budget settings. Our code is
publicly available at https://github.com/QingruZhang/AdaLoRA .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.14496">Learning with Explanation Constraints. (arXiv:2303.14496v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pukdee_R/0/1/0/all/0/1">Rattana Pukdee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sam_D/0/1/0/all/0/1">Dylan Sam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1">Maria-Florina Balcan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a></p>
<p>As larger deep learning models are hard to interpret, there has been a recent
focus on generating explanations of these black-box models. In contrast, we may
have apriori explanations of how models should behave. In this paper, we
formalize this notion as learning from explanation constraints and provide a
learning theoretic framework to analyze how such explanations can improve the
learning of our models. One may naturally ask, "When would these explanations
be helpful?" Our first key contribution addresses this question via a class of
models that satisfies these explanation constraints in expectation over new
data. We provide a characterization of the benefits of these models (in terms
of the reduction of their Rademacher complexities) for a canonical class of
explanations given by gradient information in the settings of both linear
models and two layer neural networks. In addition, we provide an algorithmic
solution for our framework, via a variational approximation that achieves
better performance and satisfies these constraints more frequently, when
compared to simpler augmented Lagrangian methods to incorporate these
explanations. We demonstrate the benefits of our approach over a large array of
synthetic and real-world experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17564">BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shijie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Irsoy_O/0/1/0/all/0/1">Ozan Irsoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Steven Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabravolski_V/0/1/0/all/0/1">Vadim Dabravolski</a>, <a href="http://arxiv.org/find/cs/1/au:+Dredze_M/0/1/0/all/0/1">Mark Dredze</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1">Sebastian Gehrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kambadur_P/0/1/0/all/0/1">Prabhanjan Kambadur</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1">David Rosenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_G/0/1/0/all/0/1">Gideon Mann</a></p>
<p>The use of NLP in the realm of financial technology is broad and complex,
with applications ranging from sentiment analysis and named entity recognition
to question answering. Large Language Models (LLMs) have been shown to be
effective on a variety of tasks; however, no LLM specialized for the financial
domain has been reported in literature. In this work, we present BloombergGPT,
a 50 billion parameter language model that is trained on a wide range of
financial data. We construct a 363 billion token dataset based on Bloomberg's
extensive data sources, perhaps the largest domain-specific dataset yet,
augmented with 345 billion tokens from general purpose datasets. We validate
BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite
of internal benchmarks that most accurately reflect our intended usage. Our
mixed dataset training leads to a model that outperforms existing models on
financial tasks by significant margins without sacrificing performance on
general LLM benchmarks. Additionally, we explain our modeling choices, training
process, and evaluation methodology. We release Training Chronicles (Appendix
C) detailing our experience in training BloombergGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.03907">Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic Embedding. (arXiv:2304.03907v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1">Tongzheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaolin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Haitong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Na Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a></p>
<p>This paper presents an approach, Spectral Dynamics Embedding Control (SDEC),
to optimal control for nonlinear stochastic systems. This method leverages an
infinite-dimensional feature to linearly represent the state-action value
function and exploits finite-dimensional truncation approximation for practical
implementation. To characterize the effectiveness of these finite dimensional
approximations, we provide an in-depth theoretical analysis to characterize the
approximation error induced by the finite-dimension truncation and statistical
error induced by finite-sample approximation in both policy evaluation and
policy optimization. Our analysis includes two prominent kernel approximation
methods: truncations onto random features and Nystrom features. We also
empirically test the algorithm and compare the performance with Koopman-based,
iLQR, and energy-based methods on a few benchmark problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.04273">Multimodal Brain-Computer Interface for In-Vehicle Driver Cognitive Load Measurement: Dataset and Baselines. (arXiv:2304.04273v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Angkan_P/0/1/0/all/0/1">Prithila Angkan</a>, <a href="http://arxiv.org/find/cs/1/au:+Behinaein_B/0/1/0/all/0/1">Behnam Behinaein</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_Z/0/1/0/all/0/1">Zunayed Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatti_A/0/1/0/all/0/1">Anubhav Bhatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodenburg_D/0/1/0/all/0/1">Dirk Rodenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Hungler_P/0/1/0/all/0/1">Paul Hungler</a>, <a href="http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1">Ali Etemad</a></p>
<p>Through this paper, we introduce a novel driver cognitive load assessment
dataset, CL-Drive, which contains Electroencephalogram (EEG) signals along with
other physiological signals such as Electrocardiography (ECG) and Electrodermal
Activity (EDA) as well as eye tracking data. The data was collected from 21
subjects while driving in an immersive vehicle simulator, in various driving
conditions, to induce different levels of cognitive load in the subjects. The
tasks consisted of 9 complexity levels for 3 minutes each. Each driver reported
their subjective cognitive load every 10 seconds throughout the experiment. The
dataset contains the subjective cognitive load recorded as ground truth. In
this paper, we also provide benchmark classification results for different
machine learning and deep learning models for both binary and ternary label
distributions. We followed 2 evaluation criteria namely 10-fold and
leave-one-subject-out (LOSO). We have trained our models on both hand-crafted
features as well as on raw data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06762">Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study. (arXiv:2304.06762v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1">Lawrence McAfee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1">Oleksii Kuchaiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a></p>
<p>Large decoder-only language models (LMs) can be largely improved in terms of
perplexity by retrieval (e.g., RETRO), but its impact on text generation
quality and downstream task accuracy is unclear. Thus, it is still an open
question: shall we pretrain large autoregressive LMs with retrieval? To answer
it, we perform a comprehensive study on a scalable pre-trained
retrieval-augmented LM (i.e., RETRO) compared with standard GPT and
retrieval-augmented GPT incorporated at fine-tuning or inference stages. We
first provide the recipe to reproduce RETRO up to 9.5B parameters while
retrieving a text corpus with 330B tokens. Based on that, we have the following
novel findings: i) RETRO outperforms GPT on text generation with much less
degeneration (i.e., repetition), moderately higher factual accuracy, and
slightly lower toxicity with a nontoxic retrieval database. ii) On the LM
Evaluation Harness benchmark, RETRO largely outperforms GPT on
knowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,
we introduce a simple variant of the model, RETRO++, which largely improves
open-domain QA results of original RETRO (e.g., EM score +8.6 on Natural
Question) and significantly outperforms retrieval-augmented GPT in both
fine-tuning and zero-shot evaluation settings. Our findings highlight the
promising direction of pretraining autoregressive LMs with retrieval as future
foundation models. We release our code and model at:
https://github.com/NVIDIA/Megatron-LM/blob/main/tools/retro/README.md
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.10549">A note on the connectedness property of union-free generic sets of partial orders. (arXiv:2304.10549v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schollmeyer_G/0/1/0/all/0/1">Georg Schollmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Blocher_H/0/1/0/all/0/1">Hannah Blocher</a></p>
<p>This short note describes and proves a connectedness property which was
introduced in Blocher et al. [2023] in the context of data depth functions for
partial orders. The connectedness property gives a structural insight into
union-free generic sets. These sets, presented in Blocher et al. [2023], are
defined by using a closure operator on the set of all partial orders which
naturally appears within the theory of formal concept analysis. In the language
of formal concept analysis, the property of connectedness can be vividly
proven. However, since within Blocher et al. [2023] we did not discuss formal
concept analysis, we outsourced the proof to this note.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05807">Even Small Correlation and Diversity Shifts Pose Dataset-Bias Issues. (arXiv:2305.05807v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bissoto_A/0/1/0/all/0/1">Alceu Bissoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Barata_C/0/1/0/all/0/1">Catarina Barata</a>, <a href="http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1">Eduardo Valle</a>, <a href="http://arxiv.org/find/cs/1/au:+Avila_S/0/1/0/all/0/1">Sandra Avila</a></p>
<p>Distribution shifts are common in real-world datasets and can affect the
performance and reliability of deep learning models. In this paper, we study
two types of distribution shifts: diversity shifts, which occur when test
samples exhibit patterns unseen during training, and correlation shifts, which
occur when test data present a different correlation between seen invariant and
spurious features. We propose an integrated protocol to analyze both types of
shifts using datasets where they co-exist in a controllable manner. Finally, we
apply our approach to a real-world classification problem of skin cancer
analysis, using out-of-distribution datasets and specialized bias annotations.
Our protocol reveals three findings: 1) Models learn and propagate correlation
shifts even with low-bias training; this poses a risk of accumulating and
combining unaccountable weak biases; 2) Models learn robust features in high-
and low-bias scenarios but use spurious ones if test samples have them; this
suggests that spurious correlations do not impair the learning of robust
features; 3) Diversity shift can reduce the reliance on spurious correlations;
this is counter intuitive since we expect biased models to depend more on
biases when invariant features are missing. Our work has implications for
distribution shift research and practice, providing new insights into how
models learn and rely on spurious correlations under different types of shifts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11650">Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v5 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1">Mingtian Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Hawkins_Hooker_A/0/1/0/all/0/1">Alex Hawkins-Hooker</a>, <a href="http://arxiv.org/find/stat/1/au:+Paige_B/0/1/0/all/0/1">Brooks Paige</a>, <a href="http://arxiv.org/find/stat/1/au:+Barber_D/0/1/0/all/0/1">David Barber</a></p>
<p>Energy-Based Models (EBMs) offer a versatile framework for modeling complex
data distributions. However, training and sampling from EBMs continue to pose
significant challenges. The widely-used Denoising Score Matching (DSM) method
for scalable EBM training suffers from inconsistency issues, causing the energy
model to learn a `noisy' data distribution. In this work, we propose an
efficient sampling framework: (pseudo)-Gibbs sampling with moment matching,
which enables effective sampling from the underlying clean model when given a
`noisy' model that has been well-trained via DSM. We explore the benefits of
our approach compared to related methods and demonstrate how to scale the
method to high-dimensional datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14961">Deep Learning for Survival Analysis: A Review. (arXiv:2305.14961v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wiegrebe_S/0/1/0/all/0/1">Simon Wiegrebe</a>, <a href="http://arxiv.org/find/stat/1/au:+Kopper_P/0/1/0/all/0/1">Philipp Kopper</a>, <a href="http://arxiv.org/find/stat/1/au:+Sonabend_R/0/1/0/all/0/1">Raphael Sonabend</a>, <a href="http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1">Bernd Bischl</a>, <a href="http://arxiv.org/find/stat/1/au:+Bender_A/0/1/0/all/0/1">Andreas Bender</a></p>
<p>The influx of deep learning (DL) techniques into the field of survival
analysis in recent years has led to substantial methodological progress; for
instance, learning from unstructured or high-dimensional data such as images,
text or omics data. In this work, we conduct a comprehensive systematic review
of DL-based methods for time-to-event analysis, characterizing them according
to both survival- and DL-related attributes. In summary, the reviewed methods
often address only a small subset of tasks relevant to time-to-event data -
e.g., single-risk right-censored data - and neglect to incorporate more complex
settings. Our findings are summarized in an editable, open-source, interactive
table: https://survival-org.github.io/DL4Survival. As this research area is
advancing rapidly, we encourage community contribution in order to keep this
database up to date.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15194">DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models. (arXiv:2305.15194v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungnyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junsoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1">Kibeom Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Daesik Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_N/0/1/0/all/0/1">Namhyuk Ahn</a></p>
<p>In this study, we aim to extend the capabilities of diffusion-based
text-to-image (T2I) generation models by incorporating diverse modalities
beyond textual description, such as sketch, box, color palette, and style
embedding, within a single model. We thus design a multimodal T2I diffusion
model, coined as DiffBlender, by separating the channels of conditions into
three types, i.e., image forms, spatial tokens, and non-spatial tokens. The
unique architecture of DiffBlender facilitates adding new input modalities,
pioneering a scalable framework for conditional image generation. Notably, we
achieve this without altering the parameters of the existing generative model,
Stable Diffusion, only with updating partial components. Our study establishes
new benchmarks in multimodal generation through quantitative and qualitative
comparisons with existing conditional generation methods. We demonstrate that
DiffBlender faithfully blends all the provided information and showcase its
various applications in the detailed image synthesis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15616">Reversible and irreversible bracket-based dynamics for deep graph neural networks. (arXiv:2305.15616v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gruber_A/0/1/0/all/0/1">Anthony Gruber</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kookjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Trask_N/0/1/0/all/0/1">Nathaniel Trask</a></p>
<p>Recent works have shown that physics-inspired architectures allow the
training of deep graph neural networks (GNNs) without oversmoothing. The role
of these physics is unclear, however, with successful examples of both
reversible (e.g., Hamiltonian) and irreversible (e.g., diffusion) phenomena
producing comparable results despite diametrically opposed mechanisms, and
further complications arising due to empirical departures from mathematical
theory. This work presents a series of novel GNN architectures based upon
structure-preserving bracket-based dynamical systems, which are provably
guaranteed to either conserve energy or generate positive dissipation with
increasing depth. It is shown that the theoretically principled framework
employed here allows for inherently explainable constructions, which
contextualize departures from theory in current architectures and better
elucidate the roles of reversibility and irreversibility in network
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16150">Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1">Jean-Yves Franceschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gartrell_M/0/1/0/all/0/1">Mike Gartrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1">Ludovic Dos Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Issenhuth_T/0/1/0/all/0/1">Thibaut Issenhuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1">Emmanuel de B&#xe9;zenac</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Micka&#xeb;l Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1">Alain Rakotomamonjy</a></p>
<p>Particle-based deep generative models, such as gradient flows and score-based
diffusion models, have recently gained traction thanks to their striking
performance. Their principle of displacing particle distributions using
differential equations is conventionally seen as opposed to the previously
widespread generative adversarial networks (GANs), which involve training a
pushforward generator network. In this paper we challenge this interpretation,
and propose a novel framework that unifies particle and adversarial generative
models by framing generator training as a generalization of particle models.
This suggests that a generator is an optional addition to any such generative
model. Consequently, integrating a generator into a score-based diffusion model
and training a GAN without a generator naturally emerge from our framework. We
empirically test the viability of these original models as proofs of concepts
of potential applications of our framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18900">One-Line-of-Code Data Mollification Improves Optimization of Likelihood-based Generative Models. (arXiv:2305.18900v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tran_B/0/1/0/all/0/1">Ba-Hien Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Franzese_G/0/1/0/all/0/1">Giulio Franzese</a>, <a href="http://arxiv.org/find/cs/1/au:+Michiardi_P/0/1/0/all/0/1">Pietro Michiardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Filippone_M/0/1/0/all/0/1">Maurizio Filippone</a></p>
<p>Generative Models (GMs) have attracted considerable attention due to their
tremendous success in various domains, such as computer vision where they are
capable to generate impressive realistic-looking images. Likelihood-based GMs
are attractive due to the possibility to generate new data by a single model
evaluation. However, they typically achieve lower sample quality compared to
state-of-the-art score-based diffusion models (DMs). This paper provides a
significant step in the direction of addressing this limitation. The idea is to
borrow one of the strengths of score-based DMs, which is the ability to perform
accurate density estimation in low-density regions and to address manifold
overfitting by means of data mollification. We connect data mollification
through the addition of Gaussian noise to Gaussian homotopy, which is a
well-known technique to improve optimization. Data mollification can be
implemented by adding one line of code in the optimization loop, and we
demonstrate that this provides a boost in generation quality of
likelihood-based GMs, without computational overheads. We report results on
image data sets with popular likelihood-based GMs, including variants of
variational autoencoders and normalizing flows, showing large improvements in
FID score.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01423">Improving Gradient-Trend Identification: Fast-Adaptive Moment Estimation with Finance-Inspired Triple Exponential Moving Average. (arXiv:2306.01423v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peleg_R/0/1/0/all/0/1">Roi Peleg</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazebnik_T/0/1/0/all/0/1">Teddy Lazebnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoogi_A/0/1/0/all/0/1">Assaf Hoogi</a></p>
<p>The performance improvement of deep networks significantly depends on their
optimizers. With existing optimizers, precise and efficient recognition of the
gradients trend remains a challenge. Existing optimizers predominantly adopt
techniques based on the first-order exponential moving average (EMA), which
results in noticeable delays that impede the real-time tracking of gradients
trend and consequently yield sub-optimal performance. To overcome this
limitation, we introduce a novel optimizer called fast-adaptive moment
estimation (FAME). Inspired by the triple exponential moving average (TEMA)
used in the financial domain, FAME leverages the potency of higher-order TEMA
to improve the precision of identifying gradient trends. TEMA plays a central
role in the learning process as it actively influences optimization dynamics;
this role differs from its conventional passive role as a technical indicator
in financial contexts. Because of the introduction of TEMA into the
optimization process, FAME can identify gradient trends with higher accuracy
and fewer lag issues, thereby offering smoother and more consistent responses
to gradient fluctuations compared to conventional first-order EMA. To study the
effectiveness of our novel FAME optimizer, we conducted comprehensive
experiments encompassing six diverse computer-vision benchmarks and tasks,
spanning detection, classification, and semantic comprehension. We integrated
FAME into 15 learning architectures and compared its performance with those of
six popular optimizers. Results clearly showed that FAME is more robust and
accurate and provides superior performance stability by minimizing noise (i.e.,
trend fluctuations). Notably, FAME achieves higher accuracy levels in
remarkably fewer training epochs than its counterparts, clearly indicating its
significance for optimizing deep networks in computer-vision tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03173">Linear Distance Metric Learning with Noisy Labels. (arXiv:2306.03173v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alishahi_M/0/1/0/all/0/1">Meysam Alishahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Little_A/0/1/0/all/0/1">Anna Little</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1">Jeff M. Phillips</a></p>
<p>In linear distance metric learning, we are given data in one Euclidean metric
space and the goal is to find an appropriate linear map to another Euclidean
metric space which respects certain distance conditions as much as possible. In
this paper, we formalize a simple and elegant method which reduces to a general
continuous convex loss optimization problem, and for different noise models we
derive the corresponding loss functions. We show that even if the data is
noisy, the ground truth linear metric can be learned with any precision
provided access to enough samples, and we provide a corresponding sample
complexity bound. Moreover, we present an effective way to truncate the learned
model to a low-rank model that can provably maintain the accuracy in loss
function and in parameters -- the first such results of this type. Several
experimental observations on synthetic and real data sets support and inform
our theoretical results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09200">ChessGPT: Bridging Policy Learning and Language Modeling. (arXiv:2306.09200v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xidong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yicheng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hongrui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Mengyue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_K/0/1/0/all/0/1">Kun Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mguni_D/0/1/0/all/0/1">David Mguni</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yali Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a></p>
<p>When solving decision-making tasks, humans typically depend on information
from two key sources: (1) Historical policy data, which provides interaction
replay from the environment, and (2) Analytical insights in natural language
form, exposing the invaluable thought process or strategic considerations.
Despite this, the majority of preceding research focuses on only one source:
they either use historical replay exclusively to directly learn policy or value
functions, or engaged in language model training utilizing mere language
corpus. In this paper, we argue that a powerful autonomous agent should cover
both sources. Thus, we propose ChessGPT, a GPT model bridging policy learning
and language modeling by integrating data from these two sources in Chess
games. Specifically, we build a large-scale game and language dataset related
to chess. Leveraging the dataset, we showcase two model examples ChessCLIP and
ChessGPT, integrating policy learning and language modeling. Finally, we
propose a full evaluation framework for evaluating language model's chess
ability. Experimental results validate our model and dataset's effectiveness.
We open source our code, model, and dataset at
https://github.com/waterhorse1/ChessGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00764">Hierarchical Open-vocabulary Universal Image Segmentation. (arXiv:2307.00764v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xudong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shufan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kallidromitis_K/0/1/0/all/0/1">Konstantinos Kallidromitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kato_Y/0/1/0/all/0/1">Yusuke Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozuka_K/0/1/0/all/0/1">Kazuki Kozuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a></p>
<p>Open-vocabulary image segmentation aims to partition an image into semantic
regions according to arbitrary text descriptions. However, complex visual
scenes can be naturally decomposed into simpler parts and abstracted at
multiple levels of granularity, introducing inherent segmentation ambiguity.
Unlike existing methods that typically sidestep this ambiguity and treat it as
an external factor, our approach actively incorporates a hierarchical
representation encompassing different semantic-levels into the learning
process. We propose a decoupled text-image fusion mechanism and representation
learning modules for both "things" and "stuff". Additionally, we systematically
examine the differences that exist in the textual and visual features between
these types of categories. Our resulting model, named HIPIE, tackles
HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within a
unified framework. Benchmarked on over 40 datasets, e.g., ADE20K, COCO,
Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the
state-of-the-art results at various levels of image comprehension, including
semantic-level (e.g., semantic segmentation), instance-level (e.g.,
panoptic/referring segmentation and object detection), as well as part-level
(e.g., part/subpart segmentation) tasks. Our code is released at
https://github.com/berkeley-hipie/HIPIE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06971">Short Boolean Formulas as Explanations in Practice. (arXiv:2307.06971v2 [cs.LO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jaakkola_R/0/1/0/all/0/1">Reijo Jaakkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Janhunen_T/0/1/0/all/0/1">Tomi Janhunen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuusisto_A/0/1/0/all/0/1">Antti Kuusisto</a>, <a href="http://arxiv.org/find/cs/1/au:+Rankooh_M/0/1/0/all/0/1">Masood Feyzbakhsh Rankooh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vilander_M/0/1/0/all/0/1">Miikka Vilander</a></p>
<p>We investigate explainability via short Boolean formulas in the data model
based on unary relations. As an explanation of length k, we take a Boolean
formula of length k that minimizes the error with respect to the target
attribute to be explained. We first provide novel quantitative bounds for the
expected error in this scenario. We then also demonstrate how the setting works
in practice by studying three concrete data sets. In each case, we calculate
explanation formulas of different lengths using an encoding in Answer Set
Programming. The most accurate formulas we obtain achieve errors similar to
other methods on the same data sets. However, due to overfitting, these
formulas are not necessarily ideal explanations, so we use cross validation to
identify a suitable length for explanations. By limiting to shorter formulas,
we obtain explanations that avoid overfitting but are still reasonably accurate
and also, importantly, human interpretable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14367">Prot2Text: Multimodal Protein&#x27;s Function Generation with GNNs and Transformers. (arXiv:2307.14367v2 [q-bio.QM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Abdine_H/0/1/0/all/0/1">Hadi Abdine</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chatzianastasis_M/0/1/0/all/0/1">Michail Chatzianastasis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bouyioukos_C/0/1/0/all/0/1">Costas Bouyioukos</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Vazirgiannis_M/0/1/0/all/0/1">Michalis Vazirgiannis</a></p>
<p>The complex nature of big biological systems pushed some scientists to
classify its understanding under the inconceivable missions. Different leveled
challenges complicated this task, one of is the prediction of a protein's
function. In recent years, significant progress has been made in this field
through the development of various machine learning approaches. However, most
existing methods formulate the task as a multi-classification problem, i.e
assigning predefined labels to proteins. In this work, we propose a novel
approach, \textbf{Prot2Text}, which predicts a protein function's in a free
text style, moving beyond the conventional binary or categorical
classifications. By combining Graph Neural Networks(GNNs) and Large Language
Models(LLMs), in an encoder-decoder framework, our model effectively integrates
diverse data types including proteins' sequences, structures, and textual
annotations. This multimodal approach allows for a holistic representation of
proteins' functions, enabling the generation of detailed and accurate
descriptions. To evaluate our model, we extracted a multimodal protein dataset
from SwissProt, and demonstrate empirically the effectiveness of Prot2Text.
These results highlight the transformative impact of multimodal models,
specifically the fusion of GNNs and LLMs, empowering researchers with powerful
tools for more accurate prediction of proteins' functions. The code, the models
and a demo will be publicly released.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models. (arXiv:2307.15043v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1">Andy Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasr_M/0/1/0/all/0/1">Milad Nasr</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1">Matt Fredrikson</a></p>
<p>Because "out-of-the-box" large language models are capable of generating a
great deal of objectionable content, recent work has focused on aligning these
models in an attempt to prevent undesirable generation. While there has been
some success at circumventing these measures -- so-called "jailbreaks" against
LLMs -- these attacks have required significant human ingenuity and are brittle
in practice. In this paper, we propose a simple and effective attack method
that causes aligned language models to generate objectionable behaviors.
Specifically, our approach finds a suffix that, when attached to a wide range
of queries for an LLM to produce objectionable content, aims to maximize the
probability that the model produces an affirmative response (rather than
refusing to answer). However, instead of relying on manual engineering, our
approach automatically produces these adversarial suffixes by a combination of
greedy and gradient-based search techniques, and also improves over past
automatic prompt generation methods.
</p>
<p>Surprisingly, we find that the adversarial prompts generated by our approach
are quite transferable, including to black-box, publicly released LLMs.
Specifically, we train an adversarial attack suffix on multiple prompts (i.e.,
queries asking for many different types of objectionable content), as well as
multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting
attack suffix is able to induce objectionable content in the public interfaces
to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,
Pythia, Falcon, and others. In total, this work significantly advances the
state-of-the-art in adversarial attacks against aligned language models,
raising important questions about how such systems can be prevented from
producing objectionable information. Code is available at
github.com/llm-attacks/llm-attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00788">An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning. (arXiv:2308.00788v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihua Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanduri_P/0/1/0/all/0/1">Prashant Khanduri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsaknakis_I/0/1/0/all/0/1">Ioannis Tsaknakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuguang Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Mingyi Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a></p>
<p>Recently, bi-level optimization (BLO) has taken center stage in some very
exciting developments in the area of signal processing (SP) and machine
learning (ML). Roughly speaking, BLO is a classical optimization problem that
involves two levels of hierarchy (i.e., upper and lower levels), wherein
obtaining the solution to the upper-level problem requires solving the
lower-level one. BLO has become popular largely because it is powerful in
modeling problems in SP and ML, among others, that involve optimizing nested
objective functions. Prominent applications of BLO range from resource
allocation for wireless systems to adversarial machine learning. In this work,
we focus on a class of tractable BLO problems that often appear in SP and ML
applications. We provide an overview of some basic concepts of this class of
BLO problems, such as their optimality conditions, standard algorithms
(including their optimization principles and practical implementations), as
well as how they can be leveraged to obtain state-of-the-art results for a
number of key SP and ML applications. Further, we discuss some recent advances
in BLO theory, its implications for applications, and point out some
limitations of the state-of-the-art that require significant future research
efforts. Overall, we hope that this article can serve to accelerate the
adoption of BLO as a generic tool to model, analyze, and innovate on a wide
array of emerging SP and ML applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01196">Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability. (arXiv:2308.01196v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Paz_Ruza_J/0/1/0/all/0/1">Jorge Paz-Ruza</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_Betanzos_A/0/1/0/all/0/1">Amparo Alonso-Betanzos</a>, <a href="http://arxiv.org/find/cs/1/au:+Guijarro_Berdinas_B/0/1/0/all/0/1">Berta Guijarro-Berdi&#xf1;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Cancela_B/0/1/0/all/0/1">Brais Cancela</a>, <a href="http://arxiv.org/find/cs/1/au:+Eiras_Franco_C/0/1/0/all/0/1">Carlos Eiras-Franco</a></p>
<p>Recommender Systems have become crucial in the modern world, commonly guiding
users towards relevant content or products, and having a large influence over
the decisions of users and citizens. However, ensuring transparency and user
trust in these systems remains a challenge; personalized explanations have
emerged as a solution, offering justifications for recommendations. Among the
existing approaches for generating personalized explanations, using existing
visual content created by users is a promising option to maximize transparency
and user trust. State-of-the-art models that follow this approach, despite
leveraging highly optimized architectures, employ surrogate learning tasks that
do not efficiently model the objective of ranking images as explanations for a
given recommendation; this leads to a suboptimal training process with high
computational costs that may not be reduced without affecting model
performance. This work presents BRIE, a novel model where we leverage Bayesian
Pairwise Ranking to enhance the training process, allowing us to consistently
outperform state-of-the-art models in six real-world datasets while reducing
its model size by up to 64 times and its CO${_2}$ emissions by up to 75% in
training and inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.06338">Size Lowerbounds for Deep Operator Networks. (arXiv:2308.06338v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1">Anirbit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Amartya Roy</a></p>
<p>Deep Operator Networks are an increasingly popular paradigm for solving
regression in infinite dimensions and hence solve families of PDEs in one shot.
In this work, we aim to establish a first-of-its-kind data-dependent lowerbound
on the size of DeepONets required for them to be able to reduce empirical error
on noisy data. In particular, we show that for low training errors to be
obtained on $n$ data points it is necessary that the common output dimension of
the branch and the trunk net be scaling as $\Omega \left (
\sqrt[\leftroot{-1}\uproot{-1}6]{n} \right )$.
</p>
<p>This inspires our experiments with DeepONets solving the
advection-diffusion-reaction PDE, where we demonstrate the possibility that at
a fixed model size, to leverage increase in this common output dimension and
get monotonic lowering of training error, the size of the training data might
necessarily need to scale at least quadratically with it.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.06668">Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges. (arXiv:2308.06668v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiajia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingle Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1">Lirong Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weichao Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xunyuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhaojian Li</a></p>
<p>The past decade has witnessed the rapid development of ML and DL
methodologies in agricultural systems, showcased by great successes in variety
of agricultural applications. However, these conventional ML/DL models have
certain limitations: They heavily rely on large, costly-to-acquire labeled
datasets for training, require specialized expertise for development and
maintenance, and are mostly tailored for specific tasks, thus lacking
generalizability. Recently, foundation models have demonstrated remarkable
successes in language and vision tasks across various domains. These models are
trained on a vast amount of data from multiple domains and modalities. Once
trained, they can accomplish versatile tasks with just minor fine-tuning and
minimal task-specific labeled data. Despite their proven effectiveness and huge
potential, there has been little exploration of applying FMs to agriculture
fields. Therefore, this study aims to explore the potential of FMs in the field
of smart agriculture. In particular, we present conceptual tools and technical
background to facilitate the understanding of the problem space and uncover new
research directions in this field. To this end, we first review recent FMs in
the general computer science domain and categorize them into four categories:
language FMs, vision FMs, multimodal FMs, and reinforcement learning FMs.
Subsequently, we outline the process of developing agriculture FMs and discuss
their potential applications in smart agriculture. We also discuss the unique
challenges associated with developing AFMs, including model training,
validation, and deployment. Through this study, we contribute to the
advancement of AI in agriculture by introducing AFMs as a promising paradigm
that can significantly mitigate the reliance on extensive labeled datasets and
enhance the efficiency, effectiveness, and generalization of agricultural AI
systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.08638">Fair GANs through model rebalancing for extremely imbalanced class distributions. (arXiv:2308.08638v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Anubhav Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Memon_N/0/1/0/all/0/1">Nasir Memon</a>, <a href="http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1">Julian Togelius</a></p>
<p>Deep generative models require large amounts of training data. This often
poses a problem as the collection of datasets can be expensive and difficult,
in particular datasets that are representative of the appropriate underlying
distribution (e.g. demographic). This introduces biases in datasets which are
further propagated in the models. We present an approach to construct an
unbiased generative adversarial network (GAN) from an existing biased GAN by
rebalancing the model distribution. We do so by generating balanced data from
an existing imbalanced deep generative model using an evolutionary algorithm
and then using this data to train a balanced generative model. Additionally, we
propose a bias mitigation loss function that minimizes the deviation of the
learned class distribution from being equiprobable. We show results for the
StyleGAN2 models while training on the Flickr Faces High Quality (FFHQ) dataset
for racial fairness and see that the proposed approach improves on the fairness
metric by almost 5 times, whilst maintaining image quality. We further validate
our approach by applying it to an imbalanced CIFAR10 dataset where we show that
we can obtain comparable fairness and image quality as when training on a
balanced CIFAR10 dataset which is also twice as large. Lastly, we argue that
the traditionally used image quality metrics such as Frechet inception distance
(FID) are unsuitable for scenarios where the class distributions are imbalanced
and a balanced reference set is not available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.03291">Ultra-fast high-dynamic range imaging of Cygnus A with the R2D2 deep neural network series. (arXiv:2309.03291v2 [astro-ph.IM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/astro-ph/1/au:+A_A/0/1/0/all/0/1">Aghabiglou A</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+S_C/0/1/0/all/0/1">Chu C S</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+A_J/0/1/0/all/0/1">Jackson A</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+A_D/0/1/0/all/0/1">Dabbech A</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Y_W/0/1/0/all/0/1">Wiaux Y</a></p>
<p>We present a novel AI approach for high-resolution high-dynamic range
synthesis imaging by radio interferometry (RI) in astronomy. R2D2, standing for
``{R}esidual-to-{R}esidual {D}NN series for high-{D}ynamic range imaging'', is
a model-based data-driven approach relying on hybrid deep neural networks
(DNNs) and data-consistency updates. Its reconstruction is built as a series of
residual images estimated as the outputs of DNNs, each taking the residual
dirty image of the previous iteration as an input. The approach can be
interpreted as a learned version of a matching pursuit approach, whereby model
components are iteratively identified from residual dirty images, and of which
CLEAN is a well-known example. We propose two variants of the R2D2 model, built
upon two distinctive DNN architectures: a standard U-Net, and a novel unrolled
architecture. We demonstrate their use for monochromatic intensity imaging on
highly-sensitive observations of the radio galaxy Cygnus A at S band, from the
Very Large Array (VLA). R2D2 is validated against CLEAN and the recent RI
algorithms AIRI and uSARA, which respectively inject a learned implicit
regularization and an advanced handcrafted sparsity-based regularization into
the RI data. With only few terms in its series, the R2D2 model is able to
deliver high-precision imaging, superseding the resolution of CLEAN, and
matching the precision of AIRI and uSARA. In terms of computational efficiency,
R2D2 runs at a fraction of the cost of AIRI and uSARA, and is also faster than
CLEAN, opening the door to near real-time precision imaging in RI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07277">Limitations of Face Image Generation. (arXiv:2309.07277v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rosenberg_H/0/1/0/all/0/1">Harrison Rosenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Shimaa Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1">Guruprasad V Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinayak_R/0/1/0/all/0/1">Ramya Korlakai Vinayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Fawaz_K/0/1/0/all/0/1">Kassem Fawaz</a></p>
<p>Text-to-image diffusion models have achieved widespread popularity due to
their unprecedented image generation capability. In particular, their ability
to synthesize and modify human faces has spurred research into using generated
face images in both training data augmentation and model performance
assessments. In this paper, we study the efficacy and shortcomings of
generative models in the context of face generation. Utilizing a combination of
qualitative and quantitative measures, including embedding-based metrics and
user studies, we present a framework to audit the characteristics of generated
faces conditioned on a set of social attributes. We applied our framework on
faces generated through state-of-the-art text-to-image diffusion models. We
identify several limitations of face image generation that include faithfulness
to the text prompt, demographic disparities, and distributional shifts.
Furthermore, we present an analytical model that provides insights into how
training data selection contributes to the performance of generative models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12559">Invariant Learning via Probability of Sufficient and Necessary Causes. (arXiv:2309.12559v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Mengyue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zhen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yonggang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yali Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Furui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ton_J/0/1/0/all/0/1">Jean-Francois Ton</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a></p>
<p>Out-of-distribution (OOD) generalization is indispensable for learning models
in the wild, where testing distribution typically unknown and different from
the training. Recent methods derived from causality have shown great potential
in achieving OOD generalization. However, existing methods mainly focus on the
invariance property of causes, while largely overlooking the property of
\textit{sufficiency} and \textit{necessity} conditions. Namely, a necessary but
insufficient cause (feature) is invariant to distribution shift, yet it may not
have required accuracy. By contrast, a sufficient yet unnecessary cause
(feature) tends to fit specific data well but may have a risk of adapting to a
new domain. To capture the information of sufficient and necessary causes, we
employ a classical concept, the probability of sufficiency and necessary causes
(PNS), which indicates the probability of whether one is the necessary and
sufficient cause. To associate PNS with OOD generalization, we propose PNS risk
and formulate an algorithm to learn representation with a high PNS value. We
theoretically analyze and prove the generalizability of the PNS risk.
Experiments on both synthetic and real-world benchmarks demonstrate the
effectiveness of the proposed method. The details of the implementation can be
found at the GitHub repository: https://github.com/ymy4323460/CaSN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12815">Improving Generalization in Game Agents with Data Augmentation in Imitation Learning. (arXiv:2309.12815v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yadgaroff_D/0/1/0/all/0/1">Derek Yadgaroff</a>, <a href="http://arxiv.org/find/cs/1/au:+Sestini_A/0/1/0/all/0/1">Alessandro Sestini</a>, <a href="http://arxiv.org/find/cs/1/au:+Tollmar_K/0/1/0/all/0/1">Konrad Tollmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozcelikkale_A/0/1/0/all/0/1">Ayca Ozcelikkale</a>, <a href="http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1">Linus Gissl&#xe9;n</a></p>
<p>Imitation learning is an effective approach for training game-playing agents
and, consequently, for efficient game production. However, generalization - the
ability to perform well in related but unseen scenarios - is an essential
requirement that remains an unsolved challenge for game AI. Generalization is
difficult for imitation learning agents because it requires the algorithm to
take meaningful actions outside of the training distribution. In this paper we
propose a solution to this challenge. Inspired by the success of data
augmentation in supervised learning, we augment the training data so the
distribution of states and actions in the dataset better represents the real
state-action distribution. This study evaluates methods for combining and
applying data augmentations to observations, to improve generalization of
imitation learning agents. It also provides a performance benchmark of these
augmentations across several 3D environments. These results demonstrate that
data augmentation is a promising framework for improving generalization in
imitation learning agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13439">Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning. (arXiv:2309.13439v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1">Berken Utku Demirel</a>, <a href="http://arxiv.org/find/cs/1/au:+Holz_C/0/1/0/all/0/1">Christian Holz</a></p>
<p>The success of contrastive learning is well known to be dependent on data
augmentation. Although the degree of data augmentations has been well
controlled by utilizing pre-defined techniques in some domains like vision,
time-series data augmentation is less explored and remains a challenging
problem due to the complexity of the data generation mechanism, such as the
intricate mechanism involved in the cardiovascular system. Moreover, there is
no widely recognized and general time-series augmentation method that can be
applied across different tasks. In this paper, we propose a novel data
augmentation method for quasi-periodic time-series tasks that aims to connect
intra-class samples together, and thereby find order in the latent space. Our
method builds upon the well-known mixup technique by incorporating a novel
approach that accounts for the periodic nature of non-stationary time-series.
Also, by controlling the degree of chaos created by data augmentation, our
method leads to improved feature representations and performance on downstream
tasks. We evaluate our proposed method on three time-series tasks, including
heart rate estimation, human activity recognition, and cardiovascular disease
detection. Extensive experiments against state-of-the-art methods show that the
proposed approach outperforms prior works on optimal data generation and known
data augmentation techniques in the three tasks, reflecting the effectiveness
of the presented method. Source code:
https://github.com/eth-siplab/Finding_Order_in_Chaos
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00526">Are Graph Neural Networks Optimal Approximation Algorithms?. (arXiv:2310.00526v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1">Morris Yau</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_E/0/1/0/all/0/1">Eric Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Karalias_N/0/1/0/all/0/1">Nikolaos Karalias</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jessica Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1">Stefanie Jegelka</a></p>
<p>In this work we design graph neural network architectures that can be used to
obtain optimal approximation algorithms for a large class of combinatorial
optimization problems using powerful algorithmic tools from semidefinite
programming (SDP). Concretely, we prove that polynomial-sized message passing
algorithms can represent the most powerful polynomial time algorithms for Max
Constraint Satisfaction Problems assuming the Unique Games Conjecture. We
leverage this result to construct efficient graph neural network architectures,
OptGNN, that obtain high-quality approximate solutions on landmark
combinatorial optimization problems such as Max Cut and maximum independent
set. Our approach achieves strong empirical results across a wide range of
real-world and synthetic datasets against both neural baselines and classical
algorithms. Finally, we take advantage of OptGNN's ability to capture convex
relaxations to design an algorithm for producing dual certificates of
optimality (bounds on the optimal solution) from the learned embeddings of
OptGNN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02679">Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dinghuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Ricky T. Q. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Cheng-Hao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a></p>
<p>We tackle the problem of sampling from intractable high-dimensional density
functions, a fundamental task that often appears in machine learning and
statistics. We extend recent sampling-based approaches that leverage controlled
stochastic processes to model approximate samples from these target densities.
The main drawback of these approaches is that the training objective requires
full trajectories to compute, resulting in sluggish credit assignment issues
due to use of entire trajectories and a learning signal present only at the
terminal time. In this work, we present Diffusion Generative Flow Samplers
(DGFS), a sampling-based framework where the learning process can be tractably
broken down into short partial trajectory segments, via parameterizing an
additional "flow function". Our method takes inspiration from the theory
developed for generative flow networks (GFlowNets), allowing us to make use of
intermediate learning signals. Through various challenging experiments, we
demonstrate that DGFS achieves more accurate estimates of the normalization
constant than closely-related prior methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.03223">TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design. (arXiv:2310.03223v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1">Tony Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_M/0/1/0/all/0/1">Mohit Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">Jason Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherkasov_A/0/1/0/all/0/1">Artem Cherkasov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ester_M/0/1/0/all/0/1">Martin Ester</a></p>
<p>We seek to automate the generation of drug-like compounds conditioned to
specific protein pocket targets. Most current methods approximate the
protein-molecule distribution of a finite dataset and, therefore struggle to
generate molecules with significant binding improvement over the training
dataset. We instead frame the pocket-conditioned molecular generation task as
an RL problem and develop TacoGFN, a target conditional Generative Flow Network
model. Our method is explicitly encouraged to generate molecules with desired
properties as opposed to fitting on a pre-existing data distribution. To this
end, we develop transformer-based docking score prediction to speed up docking
score computation and propose TacoGFN to explore molecule space efficiently.
Furthermore, we incorporate several rounds of active learning where generated
samples are queried using a docking oracle to improve the docking score
prediction. This approach allows us to accurately explore as much of the
molecule landscape as we can afford computationally. Empirically, molecules
generated using TacoGFN and its variants significantly outperform all baseline
methods across every property (Docking score, QED, SA, Lipinski), while being
orders of magnitude faster.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09574">Reduced Policy Optimization for Continuous Control with Hard Constraints. (arXiv:2310.09574v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shutong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingya Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yali Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Ye Shi</a></p>
<p>Recent advances in constrained reinforcement learning (RL) have endowed
reinforcement learning with certain safety guarantees. However, deploying
existing constrained RL algorithms in continuous control tasks with general
hard constraints remains challenging, particularly in those situations with
non-convex hard constraints. Inspired by the generalized reduced gradient (GRG)
algorithm, a classical constrained optimization technique, we propose a reduced
policy optimization (RPO) algorithm that combines RL with GRG to address
general hard constraints. RPO partitions actions into basic actions and
nonbasic actions following the GRG method and outputs the basic actions via a
policy network. Subsequently, RPO calculates the nonbasic actions by solving
equations based on equality constraints using the obtained basic actions. The
policy network is then updated by implicitly differentiating nonbasic actions
with respect to basic actions. Additionally, we introduce an action projection
procedure based on the reduced gradient and apply a modified Lagrangian
relaxation technique to ensure inequality constraints are satisfied. To the
best of our knowledge, RPO is the first attempt that introduces GRG to RL as a
way of efficiently handling both equality and inequality hard constraints. It
is worth noting that there is currently a lack of RL environments with complex
hard constraints, which motivates us to develop three new benchmarks: two
robotics manipulation tasks and a smart grid operation control task. With these
benchmarks, RPO achieves better performance than previous constrained RL
algorithms in terms of both cumulative reward and constraint violation. We
believe RPO, along with the new benchmarks, will open up new opportunities for
applying RL to real-world problems with complex constraints.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09583">Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation. (arXiv:2310.09583v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shutong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_T/0/1/0/all/0/1">Tianyu Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingya Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Ye Shi</a></p>
<p>Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations
(Neural ODEs) are two branches of implicit models that have achieved remarkable
success owing to their superior performance and low memory consumption. While
both are implicit models, DEQs and Neural ODEs are derived from different
mathematical formulations. Inspired by homotopy continuation, we establish a
connection between these two models and illustrate that they are actually two
sides of the same coin. Homotopy continuation is a classical method of solving
nonlinear equations based on a corresponding ODE. Given this connection, we
proposed a new implicit model called HomoODE that inherits the property of high
accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs,
which explicitly solve an equilibrium-point-finding problem via Newton's
methods in the forward pass, HomoODE solves the equilibrium-point-finding
problem implicitly using a modified Neural ODE via homotopy continuation.
Further, we developed an acceleration method for HomoODE with a shared
learnable initial point. It is worth noting that our model also provides a
better understanding of why Augmented Neural ODEs work as long as the augmented
part is regarded as the equilibrium point to find. Comprehensive experiments
with several image classification tasks demonstrate that HomoODE surpasses
existing implicit models in terms of both accuracy and memory consumption.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19583">GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo. (arXiv:2310.19583v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vats_V/0/1/0/all/0/1">Vibhas K. Vats</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Sripad Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Crandall_D/0/1/0/all/0/1">David J. Crandall</a>, <a href="http://arxiv.org/find/cs/1/au:+Reza_M/0/1/0/all/0/1">Md. Alimoor Reza</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Soon-heung Jung</a></p>
<p>Traditional multi-view stereo (MVS) methods rely heavily on photometric and
geometric consistency constraints, but newer machine learning-based MVS methods
check geometric consistency across multiple source views only as a
post-processing step. In this paper, we present a novel approach that
explicitly encourages geometric consistency of reference view depth maps across
multiple source views at different scales during learning (see Fig. 1). We find
that adding this geometric consistency loss significantly accelerates learning
by explicitly penalizing geometrically inconsistent pixels, reducing the
training iteration requirements to nearly half that of other MVS methods. Our
extensive experiments show that our approach achieves a new state-of-the-art on
the DTU and BlendedMVS datasets, and competitive results on the Tanks and
Temples benchmark. To the best of our knowledge, GC-MVSNet is the first attempt
to enforce multi-view, multi-scale geometric consistency during learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05152">Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks. (arXiv:2311.05152v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duan_H/0/1/0/all/0/1">Haoyi Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Li Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jieming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhou Zhao</a></p>
<p>In recent years, the deployment of large-scale pre-trained models in
audio-visual downstream tasks has yielded remarkable outcomes. However, these
models, primarily trained on single-modality unconstrained datasets, still
encounter challenges in feature extraction for multi-modal tasks, leading to
suboptimal performance. This limitation arises due to the introduction of
irrelevant modality-specific information during encoding, which adversely
affects the performance of downstream tasks. To address this challenge, this
paper proposes a novel Dual-Guided Spatial-Channel-Temporal (DG-SCT) attention
mechanism. This mechanism leverages audio and visual modalities as soft prompts
to dynamically adjust the parameters of pre-trained models based on the current
multi-modal input features. Specifically, the DG-SCT module incorporates
trainable cross-modal interaction layers into pre-trained audio-visual
encoders, allowing adaptive extraction of crucial information from the current
modality across spatial, channel, and temporal dimensions, while preserving the
frozen parameters of large-scale pre-trained models. Experimental evaluations
demonstrate that our proposed model achieves state-of-the-art results across
multiple downstream tasks, including AVE, AVVP, AVS, and AVQA. Furthermore, our
model exhibits promising performance in challenging few-shot and zero-shot
scenarios. The source code and pre-trained models are available at
https://github.com/haoyi-duan/DG-SCT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07919">Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models. (arXiv:2311.07919v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chu_Y/0/1/0/all/0/1">Yunfei Chu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xiaohuan Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1">Qian Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Shiliang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Z/0/1/0/all/0/1">Zhijie Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a></p>
<p>Recently, instruction-following audio-language models have received broad
attention for audio interaction with humans. However, the absence of
pre-trained audio models capable of handling diverse audio types and tasks has
hindered progress in this field. Consequently, most existing works have only
been able to support a limited range of interaction capabilities. In this
paper, we develop the Qwen-Audio model and address this limitation by scaling
up audio-language pre-training to cover over 30 tasks and various audio types,
such as human speech, natural sounds, music, and songs, to facilitate universal
audio understanding abilities. However, directly co-training all tasks and
datasets can lead to interference issues, as the textual labels associated with
different datasets exhibit considerable variations due to differences in task
focus, language, granularity of annotation, and text structure. To overcome the
one-to-many interference, we carefully design a multi-task training framework
by conditioning on a sequence of hierarchical tags to the decoder for
encouraging knowledge sharing and avoiding interference through shared and
specified tags respectively. Remarkably, Qwen-Audio achieves impressive
performance across diverse benchmark tasks without requiring any task-specific
fine-tuning, surpassing its counterparts. Building upon the capabilities of
Qwen-Audio, we further develop Qwen-Audio-Chat, which allows for input from
various audios and text inputs, enabling multi-turn dialogues and supporting
various audio-central scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07967">Comparison of two data fusion approaches for land use classification. (arXiv:2311.07967v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cubaud_M/0/1/0/all/0/1">Martin Cubaud</a> (LaSTIG), <a href="http://arxiv.org/find/cs/1/au:+Bris_A/0/1/0/all/0/1">Arnaud Le Bris</a> (LaSTIG), <a href="http://arxiv.org/find/cs/1/au:+Jolivet_L/0/1/0/all/0/1">Laurence Jolivet</a> (LaSTIG), <a href="http://arxiv.org/find/cs/1/au:+Olteanu_Raimond_A/0/1/0/all/0/1">Ana-Maria Olteanu-Raimond</a> (LaSTIG)</p>
<p>Accurate land use maps, describing the territory from an anthropic
utilisation point of view, are useful tools for land management and planning.
To produce them, the use of optical images alone remains limited. It is
therefore necessary to make use of several heterogeneous sources, each carrying
complementary or contradictory information due to their imperfections or their
different specifications. This study compares two different approaches i.e. a
pre-classification and a post-classification fusion approach for combining
several sources of spatial data in the context of land use classification. The
approaches are applied on authoritative land use data located in the Gers
department in the southwest of France. Pre-classification fusion, while not
explicitly modeling imperfections, has the best final results, reaching an
overall accuracy of 97% and a macro-mean F1 score of 88%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.18260">Consensus, dissensus and synergy between clinicians and specialist foundation models in radiology report generation. (arXiv:2311.18260v3 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Tanno_R/0/1/0/all/0/1">Ryutaro Tanno</a>, <a href="http://arxiv.org/find/eess/1/au:+Barrett_D/0/1/0/all/0/1">David G.T. Barrett</a>, <a href="http://arxiv.org/find/eess/1/au:+Sellergren_A/0/1/0/all/0/1">Andrew Sellergren</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghaisas_S/0/1/0/all/0/1">Sumedh Ghaisas</a>, <a href="http://arxiv.org/find/eess/1/au:+Dathathri_S/0/1/0/all/0/1">Sumanth Dathathri</a>, <a href="http://arxiv.org/find/eess/1/au:+See_A/0/1/0/all/0/1">Abigail See</a>, <a href="http://arxiv.org/find/eess/1/au:+Welbl_J/0/1/0/all/0/1">Johannes Welbl</a>, <a href="http://arxiv.org/find/eess/1/au:+Singhal_K/0/1/0/all/0/1">Karan Singhal</a>, <a href="http://arxiv.org/find/eess/1/au:+Azizi_S/0/1/0/all/0/1">Shekoofeh Azizi</a>, <a href="http://arxiv.org/find/eess/1/au:+Tu_T/0/1/0/all/0/1">Tao Tu</a>, <a href="http://arxiv.org/find/eess/1/au:+Schaekermann_M/0/1/0/all/0/1">Mike Schaekermann</a>, <a href="http://arxiv.org/find/eess/1/au:+May_R/0/1/0/all/0/1">Rhys May</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_R/0/1/0/all/0/1">Roy Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Man_S/0/1/0/all/0/1">SiWai Man</a>, <a href="http://arxiv.org/find/eess/1/au:+Ahmed_Z/0/1/0/all/0/1">Zahra Ahmed</a>, <a href="http://arxiv.org/find/eess/1/au:+Mahdavi_S/0/1/0/all/0/1">Sara Mahdavi</a>, <a href="http://arxiv.org/find/eess/1/au:+Matias_Y/0/1/0/all/0/1">Yossi Matias</a>, <a href="http://arxiv.org/find/eess/1/au:+Barral_J/0/1/0/all/0/1">Joelle Barral</a>, <a href="http://arxiv.org/find/eess/1/au:+Eslami_A/0/1/0/all/0/1">Ali Eslami</a>, <a href="http://arxiv.org/find/eess/1/au:+Belgrave_D/0/1/0/all/0/1">Danielle Belgrave</a>, <a href="http://arxiv.org/find/eess/1/au:+Natarajan_V/0/1/0/all/0/1">Vivek Natarajan</a>, <a href="http://arxiv.org/find/eess/1/au:+Shetty_S/0/1/0/all/0/1">Shravya Shetty</a>, <a href="http://arxiv.org/find/eess/1/au:+Kohli_P/0/1/0/all/0/1">Pushmeet Kohli</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1">Po-Sen Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Karthikesalingam_A/0/1/0/all/0/1">Alan Karthikesalingam</a>, <a href="http://arxiv.org/find/eess/1/au:+Ktena_I/0/1/0/all/0/1">Ira Ktena</a></p>
<p>Radiology reports are an instrumental part of modern medicine, informing key
clinical decisions such as diagnosis and treatment. The worldwide shortage of
radiologists, however, restricts access to expert care and imposes heavy
workloads, contributing to avoidable errors and delays in report delivery.
While recent progress in automated report generation with vision-language
models offer clear potential in ameliorating the situation, the path to
real-world adoption has been stymied by the challenge of evaluating the
clinical quality of AI-generated reports. In this study, we build a
state-of-the-art report generation system for chest radiographs,
$\textit{Flamingo-CXR}$, by fine-tuning a well-known vision-language foundation
model on radiology data. To evaluate the quality of the AI-generated reports, a
group of 16 certified radiologists provide detailed evaluations of AI-generated
and human written reports for chest X-rays from an intensive care setting in
the United States and an inpatient setting in India. At least one radiologist
(out of two per case) preferred the AI report to the ground truth report in
over 60$\%$ of cases for both datasets. Amongst the subset of AI-generated
reports that contain errors, the most frequently cited reasons were related to
the location and finding, whereas for human written reports, most mistakes were
related to severity and finding. This disparity suggested potential
complementarity between our AI system and human experts, prompting us to
develop an assistive scenario in which Flamingo-CXR generates a first-draft
report, which is subsequently revised by a clinician. This is the first
demonstration of clinician-AI collaboration for report writing, and the
resultant reports are assessed to be equivalent or preferred by at least one
radiologist to reports written by experts alone in 80$\%$ of in-patient cases
and 60$\%$ of intensive care cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00137">The Multiverse of Dynamic Mode Decomposition Algorithms. (arXiv:2312.00137v2 [math.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Colbrook_M/0/1/0/all/0/1">Matthew J. Colbrook</a></p>
<p>Dynamic Mode Decomposition (DMD) is a popular data-driven analysis technique
used to decompose complex, nonlinear systems into a set of modes, revealing
underlying patterns and dynamics through spectral analysis. This review
presents a comprehensive and pedagogical examination of DMD, emphasizing the
role of Koopman operators in transforming complex nonlinear dynamics into a
linear framework. A distinctive feature of this review is its focus on the
relationship between DMD and the spectral properties of Koopman operators, with
particular emphasis on the theory and practice of DMD algorithms for spectral
computations. We explore the diverse "multiverse" of DMD methods, categorized
into three main areas: linear regression-based methods, Galerkin
approximations, and structure-preserving techniques. Each category is studied
for its unique contributions and challenges, providing a detailed overview of
significant algorithms and their applications as outlined in Table 1. We
include a MATLAB package with examples and applications to enhance the
practical understanding of these methods. This review serves as both a
practical guide and a theoretical reference for various DMD methods, accessible
to both experts and newcomers, and enabling readers to delve into their areas
of interest in the expansive field of DMD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01057">RLHF and IIA: Perverse Incentives. (arXiv:2312.01057v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wanqiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiuyuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_G/0/1/0/all/0/1">Grace Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zheng Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a></p>
<p>Existing algorithms for reinforcement learning from human feedback (RLHF) can
incentivize responses at odds with preferences because they are based on models
that assume independence of irrelevant alternatives (IIA). The perverse
incentives induced by IIA give rise to egregious behavior when innovating on
query formats or learning algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03763">Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and Editing. (arXiv:2312.03763v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yushi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_F/0/1/0/all/0/1">Feitong Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_D/0/1/0/all/0/1">Di Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiangeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Genova_K/0/1/0/all/0/1">Kyle Genova</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fanello_S/0/1/0/all/0/1">Sean Fanello</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_R/0/1/0/all/0/1">Rohit Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Funkhouser_T/0/1/0/all/0/1">Thomas Funkhouser</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinda Zhang</a></p>
<p>We present a novel framework for generating photorealistic 3D human head and
subsequently manipulating and reposing them with remarkable flexibility. The
proposed approach leverages an implicit function representation of 3D human
heads, employing 3D Gaussians anchored on a parametric face model. To enhance
representational capabilities and encode spatial information, we embed a
lightweight tri-plane payload within each Gaussian rather than directly storing
color and opacity. Additionally, we parameterize the Gaussians in a 2D UV space
via a 3DMM, enabling effective utilization of the diffusion model for 3D head
avatar generation. Our method facilitates the creation of diverse and realistic
3D human heads with fine-grained editing over facial features and expressions.
Extensive experiments demonstrate the effectiveness of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05964">ConSequence: Synthesizing Logically Constrained Sequences for Electronic Health Record Generation. (arXiv:2312.05964v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Theodorou_B/0/1/0/all/0/1">Brandon Theodorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shrusti Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Cao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a></p>
<p>Generative models can produce synthetic patient records for analytical tasks
when real data is unavailable or limited. However, current methods struggle
with adhering to domain-specific knowledge and removing invalid data. We
present ConSequence, an effective approach to integrating domain knowledge into
sequential generative neural network outputs. Our rule-based formulation
includes temporal aggregation and antecedent evaluation modules, ensured by an
efficient matrix multiplication formulation, to satisfy hard and soft logical
constraints across time steps. Existing constraint methods often fail to
guarantee constraint satisfaction, lack the ability to handle temporal
constraints, and hinder the learning and computational efficiency of the model.
In contrast, our approach efficiently handles all types of constraints with
guaranteed logical coherence. We demonstrate ConSequence's effectiveness in
generating electronic health records, outperforming competitors in achieving
complete temporal and spatial constraint satisfaction without compromising
runtime performance or generative quality. Specifically, ConSequence
successfully prevents all rule violations while improving the model quality in
reducing its test perplexity by 5% and incurring less than a 13% slowdown in
generation speed compared to an unconstrained model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07069">Context Matters: Data-Efficient Augmentation of Large Language Models for Scientific Applications. (arXiv:2312.07069v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoran Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Siyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Maravi_A/0/1/0/all/0/1">Anurag Maravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abram_M/0/1/0/all/0/1">Marcin Abram</a></p>
<p>In this paper, we explore the challenges inherent to Large Language Models
(LLMs) like GPT-4, particularly their propensity for hallucinations, logic
mistakes, and incorrect conclusions when tasked with answering complex
questions. The capacity of LLMs to present erroneous answers in a coherent and
semantically rigorous manner further complicates the detection of factual
inaccuracies. This issue is especially pronounced in fields that require
specialized expertise. Our work delves into these challenges, aiming to enhance
the understanding and mitigation of such errors, thereby contributing to the
improvement of LLM accuracy and reliability in scientific and other specialized
domains. Our findings reveal a non-linear relationship between the context's
relevancy and the answers' measured quality. In addition, we demonstrate that
with the correct calibration, it is possible to automate the grading procedure
-- a finding suggesting that, at least to some degree, the LLMs can be used to
self-examine the quality of their own performance. Finally, we describe an
experimental platform that can be seen as a proof-of-concept of the techniques
described in this work.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08887">SpeedUpNet: A Plug-and-Play Hyper-Network for Accelerating Text-to-Image Diffusion Models. (arXiv:2312.08887v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chai_W/0/1/0/all/0/1">Weilong Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">DanDan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jiajiong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiquan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changbao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chenguang Ma</a></p>
<p>Text-to-image diffusion models (SD) exhibit significant advancements while
requiring extensive computational resources. Though many acceleration methods
have been proposed, they suffer from generation quality degradation or extra
training cost generalizing to new fine-tuned models. To address these
limitations, we propose a novel and universal Stable-Diffusion (SD)
acceleration module called SpeedUpNet(SUN). SUN can be directly plugged into
various fine-tuned SD models without extra training. This technique utilizes
cross-attention layers to learn the relative offsets in the generated image
results between negative and positive prompts achieving classifier-free
guidance distillation with negative prompts controllable, and introduces a
Multi-Step Consistency (MSC) loss to ensure a harmonious balance between
reducing inference steps and maintaining consistency in the generated output.
Consequently, SUN significantly reduces the number of inference steps to just 4
steps and eliminates the need for classifier-free guidance. It leads to an
overall speedup of more than 10 times for SD models compared to the
state-of-the-art 25-step DPM-solver++, and offers two extra advantages: (1)
classifier-free guidance distillation with controllable negative prompts and
(2) seamless integration into various fine-tuned Stable-Diffusion models
without training. The effectiveness of the SUN has been verified through
extensive experimentation. Project Page:
https://williechai.github.io/speedup-plugin-for-stable-diffusions.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09131">Physics-Informed Neural Network Lyapunov Functions: PDE Characterization, Learning, and Verification. (arXiv:2312.09131v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Meng_Y/0/1/0/all/0/1">Yiming Meng</a>, <a href="http://arxiv.org/find/math/1/au:+Fitzsimmons_M/0/1/0/all/0/1">Maxwell Fitzsimmons</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_R/0/1/0/all/0/1">Ruikun Zhou</a></p>
<p>We provide a systematic investigation of using physics-informed neural
networks to compute Lyapunov functions. We encode Lyapunov conditions as a
partial differential equation (PDE) and use this for training neural network
Lyapunov functions. We analyze the analytical properties of the solutions to
the Lyapunov and Zubov PDEs. In particular, we show that employing the Zubov
equation in training neural Lyapunov functions can lead to approximate regions
of attraction close to the true domain of attraction. We also examine
approximation errors and the convergence of neural approximations to the unique
solution of Zubov's equation. We then provide sufficient conditions for the
learned neural Lyapunov functions that can be readily verified by
satisfiability modulo theories (SMT) solvers, enabling formal verification of
both local stability analysis and region-of-attraction estimates in the large.
Through a number of nonlinear examples, ranging from low to high dimensions, we
demonstrate that the proposed framework can outperform traditional
sums-of-squares (SOS) Lyapunov functions obtained using semidefinite
programming (SDP).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.09244">Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate Reward Hacking. (arXiv:2312.09244v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Eisenstein_J/0/1/0/all/0/1">Jacob Eisenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1">Chirag Nagpal</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Alekh Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1">Ahmad Beirami</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmour_A/0/1/0/all/0/1">Alex D&#x27;Amour</a>, <a href="http://arxiv.org/find/cs/1/au:+Dvijotham_D/0/1/0/all/0/1">DJ Dvijotham</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1">Adam Fisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1">Katherine Heller</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfohl_S/0/1/0/all/0/1">Stephen Pfohl</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_D/0/1/0/all/0/1">Deepak Ramachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaw_P/0/1/0/all/0/1">Peter Shaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1">Jonathan Berant</a></p>
<p>Reward models play a key role in aligning language model applications towards
human preferences. However, this setup creates an incentive for the language
model to exploit errors in the reward model to achieve high estimated reward, a
phenomenon often termed \emph{reward hacking}. A natural mitigation is to train
an ensemble of reward models, aggregating over model outputs to obtain a more
robust reward estimate. We explore the application of reward ensembles to
alignment at both training time (through reinforcement learning) and inference
time (through reranking). First, we show that reward models are
\emph{underspecified}: reward models that perform similarly in-distribution can
yield very different rewards when used in alignment, due to distribution shift.
Second, underspecification results in overoptimization, where alignment to one
reward model does not improve reward as measured by another reward model
trained on the same data. Third, overoptimization is mitigated by the use of
reward ensembles, and ensembles that vary by their \emph{pretraining} seeds
lead to better generalization than ensembles that differ only by their
\emph{fine-tuning} seeds, with both outperforming individual reward models.
However, even pretrain reward ensembles do not eliminate reward hacking: we
show several qualitative reward hacking phenomena that are not mitigated by
ensembling because all reward models in the ensemble exhibit similar error
patterns.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10423">Stochastic Bayesian Optimization with Unknown Continuous Context Distribution via Kernel Density Estimation. (arXiv:2312.10423v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaobin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Lei Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_K/0/1/0/all/0/1">Ke Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1">Chao Qian</a></p>
<p>Bayesian optimization (BO) is a sample-efficient method and has been widely
used for optimizing expensive black-box functions. Recently, there has been a
considerable interest in BO literature in optimizing functions that are
affected by context variable in the environment, which is uncontrollable by
decision makers. In this paper, we focus on the optimization of functions'
expectations over continuous context variable, subject to an unknown
distribution. To address this problem, we propose two algorithms that employ
kernel density estimation to learn the probability density function (PDF) of
continuous context variable online. The first algorithm is simpler, which
directly optimizes the expectation under the estimated PDF. Considering that
the estimated PDF may have high estimation error when the true distribution is
complicated, we further propose the second algorithm that optimizes the
distributionally robust objective. Theoretical results demonstrate that both
algorithms have sub-linear Bayesian cumulative regret on the expectation
objective. Furthermore, we conduct numerical experiments to empirically
demonstrate the effectiveness of our algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11460">Hybrid Internal Model: A Simple and Efficient Learner for Agile Legged Locomotion. (arXiv:2312.11460v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1">Junfeng Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zirui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Quanyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiawei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Liu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a></p>
<p>Robust locomotion control depends on accurate state estimations. However, the
sensors of most legged robots can only provide partial and noisy observations,
making the estimation particularly challenging, especially for external states
like terrain frictions and elevation maps. Inspired by the classical Internal
Model Control principle, we consider these external states as disturbances and
introduce Hybrid Internal Model (HIM) to estimate them according to the
response of the robot. The response, which we refer to as the hybrid internal
embedding, contains the robot's explicit velocity and implicit stability
representation, corresponding to two primary goals for locomotion tasks:
explicitly tracking velocity and implicitly maintaining stability. We use
contrastive learning to optimize the embedding to be close to the robot's
successor state, in which the response is naturally embedded. HIM has several
appealing benefits: It only needs the robot's proprioceptions, i.e., those from
joint encoders and IMU as observations. It innovatively maintains consistent
observations between simulation reference and reality that avoids information
loss in mimicking learning. It exploits batch-level information that is more
robust to noises and keeps better sample efficiency. It only requires 1 hour of
training on an RTX 4090 to enable a quadruped robot to traverse any terrain
under any disturbances. A wealth of real-world experiments demonstrates its
agility, even in high-difficulty tasks and cases never occurred during the
training process, revealing remarkable open-world generalizability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11462">Cascade Speculative Drafting for Even Faster LLM Inference. (arXiv:2312.11462v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Ziyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaocong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jiacheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chenkai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kevin Chen-Chuan Chang</a></p>
<p>Speculative decoding enhances the efficiency of large language models (LLMs)
by leveraging a draft model to draft for a larger target model to review.
However, drafting in speculative decoding involves slow autoregressive
generation and generating tokens of different importance with the same time
allocation. These two inefficiencies lead to its suboptimal performance. To
address this issue, we introduce Cascade Speculative Drafting (CS. Drafting), a
novel approach that employs two types of cascades. The Vertical Cascade
eliminates autoregressive generation from neural models. The Horizontal Cascade
constitutes efficient time allocation in drafting with its optimality supported
by our theoretical analysis. Combining both cascades, our CS. Drafting
algorithm has achieved up to 72 percent additional speedup over speculative
decoding in our experiments while keeping the same output distribution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11562">A Survey of Reasoning with Foundation Models: Concepts, Methodologies, and Outlook. (arXiv:2312.11562v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiankai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chuanyang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_R/0/1/0/all/0/1">Ruihang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiaqi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Mingyu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_M/0/1/0/all/0/1">Mengzhe Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junsong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhangyue Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaozhe Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jie Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Junxian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Wu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xihui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng Ann Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a></p>
<p>Reasoning, a crucial ability for complex problem-solving, plays a pivotal
role in various real-world settings such as negotiation, medical diagnosis, and
criminal investigation. It serves as a fundamental methodology in the field of
Artificial General Intelligence (AGI). With the ongoing development of
foundation models, there is a growing interest in exploring their abilities in
reasoning tasks. In this paper, we introduce seminal foundation models proposed
or adaptable for reasoning, highlighting the latest advancements in various
reasoning tasks, methods, and benchmarks. We then delve into the potential
future directions behind the emergence of reasoning abilities within foundation
models. We also discuss the relevance of multimodal learning, autonomous
agents, and super alignment in the context of reasoning. By discussing these
future research directions, we hope to inspire researchers in their exploration
of this field, stimulate further advancements in reasoning with foundation
models, and contribute to the development of AGI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11779">Are you talking to [&#x27;xem&#x27;] or [&#x27;x&#x27;, &#x27;em&#x27;]? On Tokenization and Addressing Misgendering in LLMs with Pronoun Tokenization Parity. (arXiv:2312.11779v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ovalle_A/0/1/0/all/0/1">Anaelia Ovalle</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrabi_N/0/1/0/all/0/1">Ninareh Mehrabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Palash Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamala_J/0/1/0/all/0/1">Jwala Dhamala</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1">Rahul Gupta</a></p>
<p>A large body of NLP research has documented the ways gender biases manifest
and amplify within large language models (LLMs), though this research has
predominantly operated within a gender binary-centric context. A growing body
of work has identified the harmful limitations of this gender-exclusive
framing; many LLMs cannot correctly and consistently refer to persons outside
the gender binary, especially if they use neopronouns. While data scarcity has
been identified as a possible culprit, the precise mechanisms through which it
influences LLM misgendering remain underexplored. Our work addresses this gap
by studying data scarcity's role in subword tokenization and, consequently, the
formation of LLM word representations. We uncover how the Byte-Pair Encoding
(BPE) tokenizer, a backbone for many popular LLMs, contributes to neopronoun
misgendering through out-of-vocabulary behavior. We introduce pronoun
tokenization parity (PTP), a novel approach to reduce LLM neopronoun
misgendering by preserving a token's functional structure. We evaluate PTP's
efficacy using pronoun consistency-based metrics and a novel syntax-based
metric. Through several controlled experiments, finetuning LLMs with PTP
improves neopronoun consistency from 14.5% to 58.4%, highlighting the
significant role tokenization plays in LLM pronoun consistency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12067">Optimistic Policy Gradient in Multi-Player Markov Games with a Single Controller: Convergence Beyond the Minty Property. (arXiv:2312.12067v2 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anagnostides_I/0/1/0/all/0/1">Ioannis Anagnostides</a>, <a href="http://arxiv.org/find/cs/1/au:+Panageas_I/0/1/0/all/0/1">Ioannis Panageas</a>, <a href="http://arxiv.org/find/cs/1/au:+Farina_G/0/1/0/all/0/1">Gabriele Farina</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1">Tuomas Sandholm</a></p>
<p>Policy gradient methods enjoy strong practical performance in numerous tasks
in reinforcement learning. Their theoretical understanding in multiagent
settings, however, remains limited, especially beyond two-player competitive
and potential Markov games. In this paper, we develop a new framework to
characterize optimistic policy gradient methods in multi-player Markov games
with a single controller. Specifically, under the further assumption that the
game exhibits an equilibrium collapse, in that the marginals of coarse
correlated equilibria (CCE) induce Nash equilibria (NE), we show convergence to
stationary $\epsilon$-NE in $O(1/\epsilon^2)$ iterations, where $O(\cdot)$
suppresses polynomial factors in the natural parameters of the game. Such an
equilibrium collapse is well-known to manifest itself in two-player zero-sum
Markov games, but also occurs even in a class of multi-player Markov games with
separable interactions, as established by recent work. As a result, we bypass
known complexity barriers for computing stationary NE when either of our
assumptions fails. Our approach relies on a natural generalization of the
classical Minty property that we introduce, which we anticipate to have further
applications beyond Markov games.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12337">pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction. (arXiv:2312.12337v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Charatan_D/0/1/0/all/0/1">David Charatan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sizhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_A/0/1/0/all/0/1">Andrea Tagliasacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1">Vincent Sitzmann</a></p>
<p>We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D
radiance fields parameterized by 3D Gaussian primitives from pairs of images.
Our model features real-time and memory-efficient rendering for scalable
training as well as fast 3D reconstruction at inference time. To overcome local
minima inherent to sparse and locally supported representations, we predict a
dense probability distribution over 3D and sample Gaussian means from that
probability distribution. We make this sampling operation differentiable via a
reparameterization trick, allowing us to back-propagate gradients through the
Gaussian splatting representation. We benchmark our method on wide-baseline
novel view synthesis on the real-world RealEstate10k and ACID datasets, where
we outperform state-of-the-art light field transformers and accelerate
rendering by 2.5 orders of magnitude while reconstructing an interpretable and
editable 3D radiance field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12450">Can It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions. (arXiv:2312.12450v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cassano_F/0/1/0/all/0/1">Federico Cassano</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Luisa Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_A/0/1/0/all/0/1">Akul Sethi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shinn_N/0/1/0/all/0/1">Noah Shinn</a>, <a href="http://arxiv.org/find/cs/1/au:+Brennan_Jones_A/0/1/0/all/0/1">Abby Brennan-Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozhkov_A/0/1/0/all/0/1">Anton Lozhkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_C/0/1/0/all/0/1">Carolyn Jane Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_A/0/1/0/all/0/1">Arjun Guha</a></p>
<p>A significant amount of research is focused on developing and evaluating
large language models for a variety of code synthesis tasks. These include
synthesizing code from natural language instructions, synthesizing tests from
code, and synthesizing explanations of code. In contrast, the behavior of
instructional code editing with LLMs is understudied. These are tasks in which
the model is instructed to update a block of code provided in a prompt. The
editing instruction may ask for a feature to added or removed, describe a bug
and ask for a fix, ask for a different kind of solution, or many other common
code editing tasks.
</p>
<p>We introduce a carefully crafted benchmark of code editing tasks and use it
evaluate several cutting edge LLMs. Our evaluation exposes a significant gap
between the capabilities of state-of-the-art open and closed models. For
example, even GPT-3.5-Turbo is 8.8% better than the best open model at editing
code.
</p>
<p>We also introduce a new, carefully curated, permissively licensed training
set of code edits coupled with natural language instructions. Using this
training set, we show that we can fine-tune open Code LLMs to significantly
improve their code editing capabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12464">Towards Better Serialization of Tabular Data for Few-shot Classification with Large Language Models. (arXiv:2312.12464v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jaitly_S/0/1/0/all/0/1">Sukriti Jaitly</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_T/0/1/0/all/0/1">Tanay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Shugani_A/0/1/0/all/0/1">Ashish Shugani</a>, <a href="http://arxiv.org/find/cs/1/au:+Grewal_R/0/1/0/all/0/1">Razik Singh Grewal</a></p>
<p>We present a study on the integration of Large Language Models (LLMs) in
tabular data classification, emphasizing an efficient framework. Building upon
existing work done in TabLLM (<a href="/abs/2210.10723">arXiv:2210.10723</a>), we introduce three novel
serialization techniques, including the standout LaTeX serialization method.
This method significantly boosts the performance of LLMs in processing
domain-specific datasets, Our method stands out for its memory efficiency and
ability to fully utilize complex data structures. Through extensive
experimentation, including various serialization approaches like feature
combination and importance, we demonstrate our work's superiority in accuracy
and efficiency over traditional models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12655">Can Transformers Learn Sequential Function Classes In Context?. (arXiv:2312.12655v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Campbell_R/0/1/0/all/0/1">Ryan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1">Emma Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">Evan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vir_R/0/1/0/all/0/1">Reya Vir</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsiao_E/0/1/0/all/0/1">Ethan Hsiao</a></p>
<p>In-context learning (ICL) has revolutionized the capabilities of transformer
models in NLP. In our project, we extend the understanding of the mechanisms
underpinning ICL by exploring whether transformers can learn from sequential,
non-textual function class data distributions. We introduce a novel sliding
window sequential function class and employ toy-sized transformers with a GPT-2
architecture to conduct our experiments. Our analysis indicates that these
models can indeed leverage ICL when trained on non-textual sequential function
classes. Additionally, our experiments with randomized y-label sequences
highlights that transformers retain some ICL capabilities even when the label
associations are obfuscated. We provide evidence that transformers can reason
with and understand sequentiality encoded within function classes, as reflected
by the effective learning of our proposed tasks. Our results also show that the
performance deteriorated with increasing randomness in the labels, though not
to the extent one might expect, implying a potential robustness of learned
sequentiality against label noise. Future research may want to look into how
previous explanations of transformers, such as induction heads and task
vectors, relate to sequentiality in ICL in these toy examples. Our
investigation lays the groundwork for further research into how transformers
process and perceive sequential data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.12863">Federated Learning While Providing Model as a Service: Joint Training and Inference Optimization. (arXiv:2312.12863v2 [cs.DC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_P/0/1/0/all/0/1">Pengchao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yang Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianwei Huang</a></p>
<p>While providing machine learning model as a service to process users'
inference requests, online applications can periodically upgrade the model
utilizing newly collected data. Federated learning (FL) is beneficial for
enabling the training of models across distributed clients while keeping the
data locally. However, existing work has overlooked the coexistence of model
training and inference under clients' limited resources. This paper focuses on
the joint optimization of model training and inference to maximize inference
performance at clients. Such an optimization faces several challenges. The
first challenge is to characterize the clients' inference performance when
clients may partially participate in FL. To resolve this challenge, we
introduce a new notion of age of model (AoM) to quantify client-side model
freshness, based on which we use FL's global model convergence error as an
approximate measure of inference performance. The second challenge is the tight
coupling among clients' decisions, including participation probability in FL,
model download probability, and service rates. Toward the challenges, we
propose an online problem approximation to reduce the problem complexity and
optimize the resources to balance the needs of model training and inference.
Experimental results demonstrate that the proposed algorithm improves the
average inference accuracy by up to 12%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13032">NodeMixup: Tackling Under-Reaching for Graph Neural Networks. (arXiv:2312.13032v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Weigang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1">Ziyu Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Long Jin</a></p>
<p>Graph Neural Networks (GNNs) have become mainstream methods for solving the
semi-supervised node classification problem. However, due to the uneven
location distribution of labeled nodes in the graph, labeled nodes are only
accessible to a small portion of unlabeled nodes, leading to the
\emph{under-reaching} issue. In this study, we firstly reveal under-reaching by
conducting an empirical investigation on various well-known graphs. Then, we
demonstrate that under-reaching results in unsatisfactory distribution
alignment between labeled and unlabeled nodes through systematic experimental
analysis, significantly degrading GNNs' performance. To tackle under-reaching
for GNNs, we propose an architecture-agnostic method dubbed NodeMixup. The
fundamental idea is to (1) increase the reachability of labeled nodes by
labeled-unlabeled pairs mixup, (2) leverage graph structures via fusing the
neighbor connections of intra-class node pairs to improve performance gains of
mixup, and (3) use neighbor label distribution similarity incorporating node
degrees to determine sampling weights for node mixup. Extensive experiments
demonstrate the efficacy of NodeMixup in assisting GNNs in handling
under-reaching. The source code is available at
\url{https://github.com/WeigangLu/NodeMixup}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13136">Molecular Hypergraph Neural Networks. (arXiv:2312.13136v2 [physics.chem-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Chen_J/0/1/0/all/0/1">Junwu Chen</a>, <a href="http://arxiv.org/find/physics/1/au:+Schwaller_P/0/1/0/all/0/1">Philippe Schwaller</a></p>
<p>Graph neural networks (GNNs) have demonstrated promising performance across
various chemistry-related tasks. However, conventional graphs only model the
pairwise connectivity in molecules, failing to adequately represent
higher-order connections like multi-center bonds and conjugated structures. To
tackle this challenge, we introduce molecular hypergraphs and propose Molecular
Hypergraph Neural Networks (MHNN) to predict the optoelectronic properties of
organic semiconductors, where hyperedges represent conjugated structures. A
general algorithm is designed for irregular high-order connections, which can
efficiently operate on molecular hypergraphs with hyperedges of various orders.
The results show that MHNN outperforms all baseline models on most tasks of
OPV, OCELOTv1 and PCQM4Mv2 datasets. Notably, MHNN achieves this without any 3D
geometric information, surpassing the baseline model that utilizes atom
positions. Moreover, MHNN achieves better performance than pretrained GNNs
under limited training data, underscoring its excellent data efficiency. This
work provides a new strategy for more general molecular representations and
property prediction tasks related to high-order connections.
</p>
</p>
</div>

    </div>
    </body>
    